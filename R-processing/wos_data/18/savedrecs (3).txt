FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Pham, PT
   Deschacht, K
   Tuytelaars, T
   Moens, MF
AF Pham, Phi The
   Deschacht, Koen
   Tuytelaars, Tinne
   Moens, Marie-Francine
TI Naming persons in video: Using the weak supervision of textual stories
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-media mining; Video annotation; Expectation Maximization;
   Unsupervised alignment
ID FACES
AB In this paper, we focus on the problem of automated video annotation. We report on the application of naming faces in soap series by using the weak supervision of narrative texts that describe the events in the video and that are drafted by fans. Several unsupervised methods that operate without any manual labeling of exemplar faces, and methods that use a limited number of labeled exemplars are presented and evaluated. All methods exploit the multiple co-occurrences between faces shown in the video and names mentioned in the texts to compute the strength of the linking and reinforce this coupling by means of an Expectation Maximization algorithm. We show that the unsupervised methods attain competitive results without any prior human effort. The results show F1 values between 80% and 86% for the recognition of the face-name pairs without any human supervision. These figures rise only slightly when a number of faces were manually labeled beforehand. The study gives insights in the benefits and bottlenecks of the proposed approaches, and an error analysis results in guidelines for the choice of a certain technique. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Pham, Phi The; Moens, Marie-Francine] Katholieke Univ Leuven, Dept Comp Sci, B-3001 Louvain, Belgium.
   [Tuytelaars, Tinne] Katholieke Univ Leuven, ESAT PSI, IMinds, B-3001 Louvain, Belgium.
C3 KU Leuven; IMEC; KU Leuven
RP Pham, PT (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, Celestijnenlaan 200A, B-3001 Louvain, Belgium.
EM PhiThe.Pham@cs.kuleuven.be; koendeschacht@gmail.com;
   Tinne.Tuytelaars@esat.kuleuven.be; Sien.Moens@cs.kuleuven.be
RI Moens, Marie-Francine/B-8378-2014; Tuytelaars, Tinne/B-4319-2015
OI Tuytelaars, Tinne/0000-0003-3307-9723
FU IWT [SBO 060051]; EU [FP7 287532]; ERC [240359]
FX The research was financed by the IWT (SBO 060051) project AMASS++
   (Advanced Multimedia Alignment and Structured Summarization) and the EU
   (FP7 287532) project TOSCA-MP (Task-Oriented Search and Content
   Annotation for Media Production). Tinne Tuytelaars was partially funded
   by the ERC starting grant Cognimund (240359).
CR [Anonymous], P 1 C N AM ASS COMP
   [Anonymous], P RIAO 2000 CONT BAS
   [Anonymous], 2006, CVPR
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], CVPR 06
   [Anonymous], EUR C COMP VIS
   [Anonymous], MULTIMEDIA 05
   Berg TL, 2004, PROC CVPR IEEE, P848
   Cao L., 2008, Proc. ACM Multimedia, P121
   DESCHACHT K, 2007, P 45 ANN M ASS COMP, P1000
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Everingham M., 2006, P BRIT MACHINE VISIO
   Forsyth, 2005, ADV NEURAL INFORM PR, V17, P137
   Huang TS, 2008, P IEEE, V96, P648, DOI 10.1109/JPROC.2008.916364
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Pham PT, 2011, IEEE MULTIMEDIA, V18, P44, DOI 10.1109/MMUL.2011.22
   Ramanan D., 2007, P 2007 IEEE INT C CO, P1
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Tian AB, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P145
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang J., 2004, P 12 ANN ACM INT C M, P580
NR 23
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 944
EP 955
DI 10.1016/j.jvcir.2013.06.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700019
DA 2024-07-18
ER

PT J
AU Hamidouche, W
   Olivier, C
   Pousset, Y
   Perrine, C
AF Hamidouche, Wassim
   Olivier, Christian
   Pousset, Yannis
   Perrine, Clency
TI Optimal resource allocation for Medium Grain Scalable video transmission
   over MIMO channels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Joint source-channel coding; Wireless video streaming; Optimal resource
   allocation; H.264/SVC; Rate-distortion optimization; MIMO channels;
   IEEE802.11n; QoS
ID JOINT SOURCE; CONVOLUTIONAL-CODES; EXTENSION; PRECODER; DISTANCE
AB In this paper we investigate an optimal solution for adaptive H.264/SVC video transmission over Multiple-Input Multiple-Output (MIMO) channels.
   We first write the end-to-end distortion of the H.264/SVC video transmission over a diagonal MIMO channel. The total distortion is expressed following three physical layer parameters: power allocation, modulation spectral efficiency and Error Code Correction (ECC) code rate. Minimizing the total distortion is considered as an optimization problem containing both discrete and continuous variables.
   We use the Lagrangian method associated with Karush-Kuhn and Tucker conditions to find out the optimal continuous physical layer parameters. Concerting the discrete modulation spectral efficiency and ECC code rate, we exploit information of the MIMO system to remove all suboptimal configurations. Therefore, the optimal power allocation is computed only for a reduced number of discrete configurations.
   The performance of the proposed solution is evaluated over both statistical and realistic MIMO channels. Results show that the proposed solution performs an optimal resource allocation to achieve the best QoS regardless the channel conditions. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Hamidouche, Wassim; Olivier, Christian; Pousset, Yannis; Perrine, Clency] Univ Poitiers, CNRS, Dept Signal Image & Commun, XLIM Lab,UMR 7252, Poitiers, France.
C3 Universite de Poitiers; Centre National de la Recherche Scientifique
   (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS)
RP Hamidouche, W (corresponding author), Univ Poitiers, CNRS, Dept Signal Image & Commun, XLIM Lab,UMR 7252, Poitiers, France.
EM hamidouche@sic.sp2mi.univ-poitiers.fr
FU French National Research Agency as a part of CAIMAN (Advanced fixed
   image coding and new services) project
FX This work is supported by the French National Research Agency as a part
   of CAIMAN (Advanced fixed image coding and new services) project. .
CR Alter O, 2000, P NATL ACAD SCI USA, V97, P10101, DOI 10.1073/pnas.97.18.10101
   [Anonymous], OPTIMIZED SCANNING O
   [Anonymous], 2007, MIMO Wireless Communications
   [Anonymous], WIRELESS COMMUNICATI
   [Anonymous], IEEE STANDARD FOR IN
   [Anonymous], JSVM SOFTWARE VERSIO
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cheung G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P767, DOI 10.1109/ICIP.1996.560839
   Chung WH, 2010, IEEE ICC
   Collin L, 2004, IEEE T SIGNAL PROCES, V52, P617, DOI 10.1109/TSP.2003.822365
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   Hamidouche W, 2011, J VIS COMMUN IMAGE R, V22, P563, DOI 10.1016/j.jvcir.2011.02.003
   Holliday T, 2008, IEEE T INFORM THEORY, V54, P1393, DOI 10.1109/TIT.2008.917725
   Hormis R, 2009, IEEE T SIGNAL PROCES, V57, P3624, DOI 10.1109/TSP.2009.2020051
   Jubran MK, 2009, IEEE T IMAGE PROCESS, V18, P106, DOI 10.1109/TIP.2008.2006600
   Kim YT, 2008, IEEE J SEL AREA COMM, V26, P1556, DOI 10.1109/JSAC.2008.081021
   Kondi LP, 2002, IEEE T IMAGE PROCESS, V11, P1043, DOI 10.1109/TIP.2002.802507
   LEE LHC, 1994, IEEE T COMMUN, V42, P3073, DOI 10.1109/26.339824
   Love DJ, 2008, IEEE J SEL AREA COMM, V26, P1341, DOI 10.1109/JSAC.2008.081002
   Mohammed SK, 2010, IEEE INT SYMP INFO, P2143, DOI 10.1109/ISIT.2010.5513455
   Sampath H, 2001, IEEE T COMMUN, V49, P2198, DOI 10.1109/26.974266
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Stoufs M, 2008, IEEE T CIRC SYST VID, V18, P1657, DOI 10.1109/TCSVT.2008.2004922
   Telatar E, 1999, EUR T TELECOMMUN, V10, P585, DOI 10.1002/ett.4460100604
   VITERBI AJ, 1971, IEEE T COMMUN TECHN, VCO19, P751, DOI 10.1109/TCOM.1971.1090700
   Vrigneau B, 2008, IEEE J-STSP, V2, P135, DOI 10.1109/JSTSP.2008.922476
   Wright S.J., 2004, Primal-Dual Interior-Point Methods
   Xu J, 2010, IEEE J SEL AREA COMM, V28, P456, DOI 10.1109/JSAC.2010.100416
   Zheng LZ, 2003, IEEE T INFORM THEORY, V49, P1073, DOI 10.1109/TIT.2003.810646
NR 29
TC 7
Z9 7
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 373
EP 387
DI 10.1016/j.jvcir.2013.01.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200014
DA 2024-07-18
ER

PT J
AU Gong, MM
   Pedersen, M
AF Gong, Mingming
   Pedersen, Marius
TI Spatial pooling for measuring color printing quality attributes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pooling; Image quality; Metrics; Color quality; Print quality; Quality
   attributes; Spatial pooling; Image quality assessment
AB Many objective image quality assessment algorithms firstly apply quality metrics in local regions that results in a quality map, and then pool the quality values in the quality map into a single quality score. The simplest pooling method is the average of quality values, which assumes that all the quality values are independent and equally important. However, visual perception is so complex that the assumption underlying average pooling might be too strict. There is an agreement that some regions in the images might be more perceptually significant, which leads to more advanced spatial pooling methods. In this work we evaluate existing spatial pooling methods for five important quality attributes, which are proposed to reduce the complexity of image quality assessment. The results show that: (1) more advanced spatial pooling methods are generally better than simple average; (2) spatial pooling depends on both image quality metrics and the attributes of the image. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Gong, Mingming; Pedersen, Marius] Gjovik Univ Coll, Gjovik, Norway.
   [Gong, Mingming] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
C3 Norwegian University of Science & Technology (NTNU); Huazhong University
   of Science & Technology
RP Pedersen, M (corresponding author), Gjovik Univ Coll, Gjovik, Norway.
EM marius.pedersen@hig.no
RI Pedersen, Marius/AFT-7128-2022
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2004, TC803 CIE
   [Anonymous], ICIP
   Bai J, 2006, IEICE T FUND ELECTR, VE89A, P2955, DOI 10.1093/ietfec/e89-a.11.2955
   Baranczuk Z, 2009, SEVENTEENTH COLOR IMAGING CONFERENCE - COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P21
   DERIDDER H, 1992, P SOC PHOTO-OPT INS, V1666, P16, DOI 10.1117/12.135953
   Green P., 2004, J ELECTRON IMAGING, V13, P663
   Gu XD, 2012, TELECOMMUN SYST, V49, P63, DOI 10.1007/s11235-010-9353-8
   Hae Jong Seo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204207
   International telecommunication union, 2009, TECHNICAL REPORT
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Keelan BW, 2004, P SOC PHOTO-OPT INS, V5294, P181
   Larson EC, 2008, IEEE IMAGE PROC, P2572, DOI 10.1109/ICIP.2008.4712319
   Le Callet P, 2003, PROC SPIE, V5150, P1573, DOI 10.1117/12.503106
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HT, 2009, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2009.5414466
   Ma L, 2010, IEEE SIGNAL PROC LET, V17, P627, DOI 10.1109/LSP.2010.2048726
   Moorthy A. K., 2009, P SOC PHOTO-OPT INS, V7240
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Nielsen Birgitte, 2008, Critical Reviews in Oncogenesis, V14, P89
   Pai M, 2004, NATL MED J INDIA, V17, P86
   Pedersen Marius, 2008, CGIV 2008/MCS'08. 4th European Conference on Colour in Graphics, Imaging and Vision. 10th International Symposium on Multispectral Colour Science, P120
   Pedersen M., 2011, P SPIE
   Pedersen M., 2010, 5 EUR C COL GRAPH IM, P75
   Pedersen M, 2008, PROC SPIE, V6806, DOI 10.1117/12.764468
   Pedersen M, 2011, FOUND TRENDS COMPUT, V7, P1, DOI 10.1561/0600000037
   Pedersen M, 2011, LECT NOTES COMPUT SC, V6688, P317, DOI 10.1007/978-3-642-21227-7_30
   Pedersen M, 2010, COLOR IMAG CONF, P68
   Pedersen M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3277145
   Rajashekar U, 2008, IEEE T IMAGE PROCESS, V17, P564, DOI 10.1109/TIP.2008.917218
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   SIMONE G, 2009, 11 C INT COL ASS AIC
   Simone G., 2009, SPIE, V7240
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZH, 2009, SEVENTEENTH COLOR IMAGING CONFERENCE - COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P27
   Wang Z, 2006, IEEE IMAGE PROC, P2945, DOI 10.1109/ICIP.2006.313136
   Xin F, 2008, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2008.4712316
   Zhang X., 1997, Journal of the Society for Information Display, V5, P61, DOI 10.1889/1.1985127
NR 42
TC 11
Z9 11
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 685
EP 696
DI 10.1016/j.jvcir.2012.03.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400001
DA 2024-07-18
ER

PT J
AU Seo, B
   Zimmermann, R
AF Seo, Beomjoo
   Zimmermann, Roger
TI Quantitative analysis of visibility determinations for networked virtual
   environments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visibility determinations; Interest management; Area-Of-Interest;
   Virtual reality; Object popping problem; Visual acuity model;
   Client-server object streaming; Visible relevance
AB The Area-Of-Interest (AOI) model is a simple and popular technique used in many applications to determine the region which needs to be considered and processed for each entity (e.g., user). One example application is object visibility determination around user-representing avatars in virtual environments or networked games. There exist a number of variations of the AOI model and in our prior work we have demonstrated how object-oriented visibility determination is more suitable for networked virtual environments than conventional user-oriented visibility determination. Here we extend our work to study a unified and comprehensive analytical model that reveals fundamental properties about the different visibility determination techniques under a variety of virtual environment settings. We also present what the best operational scenarios are for each different approach. Although our discussion and analytical results are focused on the visibility domain, the arguments and conclusions can be extended to various applications or services where spatial attributes are required. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Seo, Beomjoo; Zimmermann, Roger] Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
C3 National University of Singapore
RP Seo, B (corresponding author), Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
EM beomjoo90@gmail.com; rogerz@comp.nus.edu.sg
RI Zimmermann, Roger/D-7944-2015
OI Zimmermann, Roger/0000-0002-7410-2590
CR ABRAMS H, 1998, VRST 98, P125
   Akenine-Moller T., 2019, Real-time rendering
   [Anonymous], ECSCW93 P 3 EUR C CO
   Bartlett N.R., 1965, VISION VISUAL PERCEP
   Chim J, 2003, IEEE T MULTIMEDIA, V5, P503, DOI 10.1109/TMM.2003.819094
   Cohen-Or D, 2003, IEEE T VIS COMPUT GR, V9, P412, DOI 10.1109/TVCG.2003.1207447
   Kienzle J., 2006, P 5 ACM WORKSH NETW
   OHSHIMA T, 1996, VRAIS, P103
   PFAUTZ J, 2000, THESIS U CAMBRIDGE
   Seo B., 2006, MULTIMEDIA 06, P402
   TELER E, 2001, COMPUTER GRAPHICS FO, V20
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
NR 12
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 705
EP 718
DI 10.1016/j.jvcir.2012.03.007
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400003
DA 2024-07-18
ER

PT J
AU Hu, Y
   Pearlman, WA
AF Hu, Yang
   Pearlman, William A.
TI Motion differential set partition coding for image sequence and video
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Image sequence coding; Motion coding; Set partition
   coding; Significance map; SPIHT; Random access; Lossless coding
ID EFFICIENT
AB Efficient image sequence coding exploits both intra- and inter-frame correlations. Set partition coding (SPC) is efficient in intra-frame de-correlation for still images. Based on SPC, a novel image sequence coding system, called motion differential SPC (M-D-SPC), is presented in this paper. It removes inter-frame redundancy by re-using the significance map of a previously SPC coded frame. Every frame is encoded and decoded separate from other frames. Furthermore, there is no reconstruction of encoded frames in the encoder, as is done with interframe prediction methods. The M-D-SPC exhibits an auxiliary key frame coding framework, which achieves higher coding efficiency compared to the all-intra-coding schemes and meanwhile maintains the beneficial features of SPC all-intra-coding, such as computational simplicity, rate scalability, error non-propagation, and random frame access. SPIHT-based simulations on hyperspectral images, 3D/4D medical images, and video show greater compression efficiency than the standard intraframe coding method of motion JPEG2000. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Hu, Yang; Pearlman, William A.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Rensselaer Polytechnic Institute
RP Pearlman, WA (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
EM yanghuyh@gmail.com; pearlw@ecse.rpi.edu
OI Pearlman, William/0000-0002-4978-6812
FU Office of Naval Research [N00014-05-1-0507]
FX We gratefully acknowledge the support of the Office of Naval Research
   under Contract No. N00014-05-1-0507.
CR Andrew J, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P658, DOI 10.1109/ICIP.1997.632207
   [Anonymous], 1449610 ITUT ISOIEC
   [Anonymous], 2000, 154441 ISOIEC
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Calderbank AR, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P596, DOI 10.1109/ICIP.1997.647983
   Cho SD, 2003, PROC SPIE, V5022, P125, DOI 10.1117/12.476433
   Chrysafis C, 2000, INT CONF ACOUST SPEE, P2035, DOI 10.1109/ICASSP.2000.859233
   Consultative Committee for Space Data Systems (CCSDS), 2005, IM DAT COMPR CCSDS 1
   Hsiang S.- T., 2002, THESIS RENSSELAER PO
   Hu Y, 2010, INT CONF ACOUST SPEE, P894, DOI 10.1109/ICASSP.2010.5495263
   *ISO IEC, 2001, 154443 ISOIEC
   *ISO IEC, 2001, 154442 ISOIEC
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P157, DOI 10.1109/LSP.2005.862604
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Pearlman WA, 2008, FOUND TRENDS SIGNAL, V2, P181, DOI 10.1561/2000000014
   Pearlman WA, 2008, FOUND TRENDS SIGNAL, V2, P95, DOI 10.1561/2000000013
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   TEUHOLA J, 1978, INFORM PROCESS LETT, V7, P308, DOI 10.1016/0020-0190(78)90024-8
   Wang BB, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/42761
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Xu JZ, 2001, APPL COMPUT HARMON A, V10, P290, DOI 10.1006/acha.2000.0345
   Yeh PS, 2005, AEROSP CONF PROC, P4138
NR 24
TC 4
Z9 6
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 634
EP 641
DI 10.1016/j.jvcir.2012.02.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500005
DA 2024-07-18
ER

PT J
AU Chen, DY
   Chen, CH
AF Chen, Duan-Yu
   Chen, Chia-Hsun
TI Salient video cube guided nighttime vehicle braking event detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video cube; Brake light detection; 3D Nakagami; Visual salient; Nakagami
   m-distribution; Advanced vehicle safety; Vehicle taillight analysis;
   Rear-view vehicle analysis
AB In nighttime driving brake lights are particularly important because they offer a warning signal to prevent potential collisions. In this work, we propose a novel visual-based approach for nighttime brake light detection using three-dimensional Nakagami imaging to analyze tail lights of vehicles in front. Rather than heuristic features, such as symmetry of taillights and appearance of the third brake light, the proposed approach extracts invariant features by modeling the scattering of brake lights, thus allowing detection to proceed in a part-based manner. Experiments from extensive datasets show that the proposed system can effectively detect vehicle braking under different lighting and traffic conditions, making it a realistic option for real-world applications. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Chen, Duan-Yu; Chen, Chia-Hsun] Yuan Ze Univ, Dept Elect Engn, Chungli, Taiwan.
C3 Yuan Ze University
RP Chen, DY (corresponding author), Yuan Ze Univ, Dept Elect Engn, Chungli, Taiwan.
EM dychen@saturn.yzu.edu.tw; s970509@mail.yzu.edu.tw
CR CHARASH U, 1979, IEEE T COMMUN, V27, P657, DOI 10.1109/TCOM.1979.1094444
   Chen YL, 2006, INT C PATT RECOG, P687
   Gong J. W., 2010, P IEEE INT VEH S
   KIM SY, 2005, P IEEE RSJ INT C INT
   Nakagami M., 1960, Statistical Method of Radio Propagation
   O'Malley R, 2010, IEEE T INTELL TRANSP, V11, P453, DOI 10.1109/TITS.2010.2045375
   Park J. H., 2008, P INT C FUT GEN COMM
   Schamm T., 2010, P IEEE INT VEH S
   Shankar PM, 2000, IEEE T ULTRASON FERR, V47, P727, DOI 10.1109/58.842062
   Shen W., 2009, P INT C COMP SCI INF
   Srinivasa N., 2002, P IEEE INT VEH S
   Stover J.C., 1995, OPTICAL SCATTERING M, VSecond
   Sun Z., 2006, P IEEE T IM PROC
   Takahashi H, 2007, IEEE T IND ELECTRON, V54, P781, DOI 10.1109/TIE.2007.891651
   Thammakaroon P, 2009, P IEEE INT S IND EL
   Tseng Stephen P., 2009, 2009 International Conference on Networking, Sensing and Control, P823, DOI 10.1109/ICNSC.2009.4919386
   Wang C. C., 2005, P IEEE RSJ INT C INT
   Xu G.S., 2009, P IEEE INT C INF COM
   Yelal M. R., 2006, P IEEE INT C VID SIG
NR 19
TC 11
Z9 12
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 586
EP 597
DI 10.1016/j.jvcir.2012.01.013
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800015
DA 2024-07-18
ER

PT J
AU Rosales-Silva, AJ
   Gallegos-Funes, FJ
   Ponomaryov, VI
AF Rosales-Silva, Alberto J.
   Gallegos-Funes, Francisco J.
   Ponomaryov, Volodymyr I.
TI Fuzzy Directional (FD) Filter for impulsive noise reduction in colour
   video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fuzzy logic; Directional processing; Video colour sequences; Impulsive
   noise; Movement detection; Noise estimator; Spatio-temporal filtering;
   Processing time
AB This paper presents a novel Fuzzy Directional (FD) Filter for suppression of impulsive noise in colour video sequences. The proposed approach consists in the estimation of fuzzy levels to detect movement and noise presence in the neighbourhood frames, permitting to preserve the edges, fine details and chromaticity characteristics in colour images and video sequences. The new framework has been justified applying commonly used objective criteria, such as, Peak Signal to Noise Ratio (PSNR), Mean Absolute Error (MAE) and Normalized Colour Difference (NCD), as well subjective perception by human viewer showing better performance in comparison with known methods presented in the literature. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Rosales-Silva, Alberto J.; Gallegos-Funes, Francisco J.; Ponomaryov, Volodymyr I.] Natl Polytech Inst Mexico, Mech & Elect Engn Higher Sch, UPALM SEPI Elect, Mexico City 07738, DF, Mexico.
C3 Instituto Politecnico Nacional - Mexico
RP Rosales-Silva, AJ (corresponding author), Natl Polytech Inst Mexico, Mech & Elect Engn Higher Sch, UPALM SEPI Elect, Av IPN S-N,Edif Z Acceso 3,3Er Piso, Mexico City 07738, DF, Mexico.
EM arosaless@ipn.mx; fgallegosf@ipn.mx; vponomar@ipn.mx
RI Ponomaryov, Volodymyr/AAK-1537-2021; PONOMARYOV,
   VOLODYMYR/AAF-2858-2021; Rosales, Alberto/S-6146-2019; Gallegos-Funes,
   Francisco J./ABC-1160-2020
OI Ponomaryov, Volodymyr/0000-0003-4477-4676; Rosales,
   Alberto/0000-0001-8436-3025; Gallegos-Funes, Francisco
   J./0000-0002-4854-6438
FU National Polytechnic Institute of Mexico; CONACYT [81599]
FX The authors would thank National Polytechnic Institute of Mexico and
   CONACYT (project 81599) for their support to realize this work.
CR Ghazal M, 2007, IEEE T CIRC SYST VID, V17, P1690, DOI 10.1109/TCSVT.2007.903805
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   Melange T, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2992065
   Plataniotis KN, 1997, IEEE T IMAGE PROCESS, V6, P933, DOI 10.1109/83.597269
   Ponomaryov VI, 2005, J IMAGING SCI TECHN, V49, P205
   Ponomaryov V, 2007, IEICE T COMMUN, VE90B, P429, DOI 10.1093/ietcom/e90-b.2.429
   Schulte S, 2007, IEEE T IMAGE PROCESS, V16, P2565, DOI 10.1109/TIP.2007.904960
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Yin HB, 2007, IEEE T CIRC SYST VID, V17, P1714, DOI 10.1109/TCSVT.2007.904590
   ZLOKOLICA V, 2002, P 3 IEEE BEN SIGN PR, P221
   Zlokolica V, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2201548
NR 12
TC 20
Z9 23
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 143
EP 149
DI 10.1016/j.jvcir.2011.09.007
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100014
DA 2024-07-18
ER

PT J
AU Yu, N
   Hua, KA
   Cheng, H
AF Yu, Ning
   Hua, Kien A.
   Cheng, Hao
TI A Multi-Directional Search technique for image annotation propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image annotation; Annotation propagation; Image retrieval; Relevance
   feedback; Bridge semantic gap; Multi-directional search; Dynamic
   clustering; Relevance history
AB Image annotation has attracted lots of attention due to its importance in image understanding and search areas. In this paper, we propose a novel Multi-Directional Search framework for semi-automatic annotation propagation. In this system, the user interacts with the system to provide example images and the corresponding annotations during the annotation propagation process. In each iteration, the example images are clustered and the corresponding annotations are propagated separately to each cluster: images in the local neighborhood are annotated. Furthermore, some of those images are returned to the user for further annotation. As the user marks more images, the annotation process goes into multiple directions in the feature space. The query movements can be treated as multiple path navigation. Each path could be further split based on the user's input. In this manner, the system provides accurate annotation assistance to the user - images with the same semantic meaning but different visual characteristics can be handled effectively. From comprehensive experiments on Corel and U. of Washington image databases, the proposed technique shows accuracy and efficiency on annotating image databases. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Yu, Ning; Hua, Kien A.; Cheng, Hao] Univ Cent Florida, Dept Elect Engn & Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Yu, N (corresponding author), Univ Cent Florida, Dept Elect Engn & Comp Sci, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM nyu@cs.ucf.edu
RI cai, bo/G-1491-2010
CR [Anonymous], 2003, PROC ACM SPECIAL INT, DOI [10.1145/872757.872829, DOI 10.1145/872757.872829]
   [Anonymous], P INT C MULT EXP
   [Anonymous], P NIPS
   [Anonymous], P ACM SIGIR
   [Anonymous], P ACM C IM VID RETR
   [Anonymous], P ACM MULT
   [Anonymous], P ACM MULT
   [Anonymous], P ACM MULT
   [Anonymous], P CVPR
   [Anonymous], P CVPR
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], P MULT INF RETR
   [Anonymous], P ACM SIGIR
   [Anonymous], P ACM MULT
   [Anonymous], P KNOWL MARK SEM ANN
   [Anonymous], CONTENT BASED IMAGE
   [Anonymous], P CVPR
   [Anonymous], 2008, P CVPR
   [Anonymous], P INT C WORLD WID WE
   [Anonymous], P ACM MULT
   [Anonymous], P INT C DAT ENG
   [Anonymous], J MACHINE LEARNING R
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   French JC, 2004, LECT NOTES COMPUT SC, V3115, P252
   Hoi SCH, 2006, IEEE T KNOWL DATA EN, V18, P509, DOI 10.1109/TKDE.2006.1599389
   Ishikawa Y., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P218
   Lavrenko V., 2003, MODEL LEARNING SEMAN
   Mairal Julien., 2008, Supervised dictionary learning
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Porkaew K, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P235, DOI 10.1145/319463.319613
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Zhang SL, 2010, PATTERN RECOGN, V43, P470, DOI 10.1016/j.patcog.2009.03.009
NR 34
TC 5
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 237
EP 244
DI 10.1016/j.jvcir.2011.10.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100023
DA 2024-07-18
ER

PT J
AU Chaikalis, D
   Sgouros, NP
   Maroulis, D
AF Chaikalis, D.
   Sgouros, N. P.
   Maroulis, D.
TI A real-time FPGA architecture for 3D reconstruction from integral images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three-dimensional; Integral image; Image reconstruction; Image
   representation; Autostereoscopy; Architecture; Real-time; Hardware; FPGA
ID SCHEME; VIDEO
AB In this paper, we present a hardware architecture for real-time three-dimensional (3D) surface model reconstruction from Integral Images (InIms). The proposed parallel digital system realizes a number of computational-heavy calculations in order to achieve real-time operation. The processing elements are deployed in a systolic architecture and operate on multiple image areas simultaneously. Moreover, memory organization allows random access to image data and copes with the increased processing throughput of the system. Operating results reveal that the proposed architecture is able to process 3D data at a real-time rate. The proposed system can handle large sized InIms in real time and outputs 3D scenes of enhanced depth and detailed texture, which apply to emerging 3D applications. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Chaikalis, D.; Sgouros, N. P.; Maroulis, D.] Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.
C3 National & Kapodistrian University of Athens
RP Chaikalis, D (corresponding author), Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.
EM dhaik@di.uoa.gr; nsg@di.uoa.gr; dmarou@di.uoa.gr
RI Sgouros, Nicholas/AAZ-9852-2021
OI Maroulis, Dimitris/0000-0002-2721-9219; Sgouros,
   Nicholas/0000-0001-8945-3492
FU Research and Technology, Greece; European Social Fund
FX This work was realized under the framework 8.3 of the Reinforcement
   Programme of Human Research Manpower (VENED 2003"-03ED656), co-funded
   25% by the General Secretariat for Research and Technology, Greece, 75%
   by the European Social Fund, and by the private sector.
CR Chaikalis D, 2008, J VIS COMMUN IMAGE R, V19, P1, DOI 10.1016/j.jvcir.2007.09.003
   Chaikalis D, 2008, LECT NOTES COMPUT SC, V5112, P336, DOI 10.1007/978-3-540-69812-8_33
   Falcou J., 2005, PARCO 2005 PARALLEL, P663
   Frauel Y, 2002, APPL OPTICS, V41, P5488, DOI 10.1364/AO.41.005488
   HO YS, 2008, P IEICE 23 INT TECHN
   Kishk S, 2003, OPT EXPRESS, V11, P3528, DOI 10.1364/OE.11.003528
   Kolar A, 2006, IEEE I C ELECT CIRC, P144, DOI 10.1109/ICECS.2006.379740
   Lippmann G, 1908, CR HEBD ACAD SCI, V146, P446
   Maroulis D, 2006, IEEE INT SYMP CIRC S, P5579, DOI 10.1109/ISCAS.2006.1693899
   Park JH, 2004, OPT EXPRESS, V12, P6020, DOI 10.1364/OPEX.12.006020
   Park JH, 2004, APPL OPTICS, V43, P4882, DOI 10.1364/AO.43.004882
   Passalis G, 2007, APPL OPTICS, V46, P5311, DOI 10.1364/AO.46.005311
   Schreer O, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P1, DOI 10.1002/0470022736
   Shin DH, 2005, JPN J APPL PHYS 1, V44, P8016, DOI 10.1143/JJAP.44.8016
   Son JY, 2005, J DISP TECHNOL, V1, P125, DOI 10.1109/JDT.2005.853354
   Torres-Huitzil C, 2004, REAL-TIME IMAGING, V10, P177, DOI 10.1016/j.rti.2004.06.001
   Wong S, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P449, DOI 10.1109/FPT.2002.1188733
   *XIL, XIL VERT 5 DAT
NR 18
TC 8
Z9 8
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 9
EP 16
DI 10.1016/j.jvcir.2009.09.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200002
DA 2024-07-18
ER

PT J
AU Yang, CH
   Weng, CY
   Wang, SJ
   Sun, HM
AF Yang, Cheng-Hsing
   Weng, Chi-Yao
   Wang, Shiuh-Jeng
   Sun, Hung-Min
TI Grouping strategies for promoting image quality of watermarking on the
   basis of vector quantization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vector quantization; Watermarking; Image quality; Copyright protection;
   Robustness; Stego-image; Bipartite-matching; Peak-signal-noise-ratio
ID EMBEDDING TECHNIQUES; DIGITAL IMAGE; SCHEME; VQ; ALGORITHM
AB In this paper, a novel vector quantization (VQ)-based digital image watermarking scheme is proposed which retains high image quality even after embedding. The general scheme of watermarking is to embed a representative digital watermark in the protected image to claim the ownership. The robustness of watermark is important; however, the imperceptibility of embedded images also cannot be ignored. In previous papers, existing greedy technique to group codewords often results in low quality of stego-images. As an improvement to the existing techniques, two new grouping strategies, codebook-sort grouping and bipartite-match grouping are proposed in this paper to improve the quality of stego-images. Moreover, a new VQ encoder, called as shortest-group encoding method is proposed to replace the traditional VQ encoder in the purpose of embedding. Finally, in order to improve the grouping flexibility, two kinds of weights are considered in our approach. Experimental results show that all of the above approaches can improve the quality of stego-images on VQ-based watermarking. Crown Copyright (C) 2009 Published by Elsevier Inc. All rights reserved.
C1 [Yang, Cheng-Hsing] Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 900, Taiwan.
   [Weng, Chi-Yao; Sun, Hung-Min] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Tao Yuan 333, Taiwan.
C3 National Pingtung University; National Tsing Hua University
RP Wang, SJ (corresponding author), Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 900, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019
FU National Science Council of the Republic of China [NSC
   98-2221-E-153-001, NSC 962219-E-006-009, NSC 98-2221-E-015-001-MY3]
FX This research was partially supported by the National Science Council of
   the Republic of China under the Grant NSC 98-2221-E-153-001, National
   Science Council under the Grants NSC 962219-E-006-009 and NSC
   98-2221-E-015-001-MY3.
CR Agreste S, 2008, J COMPUT APPL MATH, V221, P274, DOI 10.1016/j.cam.2007.10.057
   [Anonymous], 1982, COMBINATORIAL OPTIMI
   Chang CC, 2006, IEE P-VIS IMAGE SIGN, V153, P589, DOI 10.1049/ip-vis:20050153
   Chang CT, 2008, PATTERN RECOGN, V41, P2956, DOI 10.1016/j.patcog.2008.02.008
   Chang CC, 2008, INFORM SCIENCES, V178, P3543, DOI 10.1016/j.ins.2008.05.003
   Chang CC, 2008, J SYST SOFTWARE, V81, P1118, DOI 10.1016/j.jss.2007.07.036
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Chang CC, 2007, FUND INFORM, V77, P217
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Lin CC, 2006, FUND INFORM, V71, P443
   Lin CC, 2009, INFORM SCIENCES, V179, P140, DOI 10.1016/j.ins.2008.09.001
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Pi MH, 2006, IEEE T MULTIMEDIA, V8, P488, DOI 10.1109/TMM.2006.870738
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002
   Wu HC, 2005, COMPUT SECUR, V24, P460, DOI 10.1016/j.cose.2005.05.001
NR 18
TC 2
Z9 3
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 49
EP 55
DI 10.1016/j.jvcir.2009.10.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200006
DA 2024-07-18
ER

PT J
AU Heu, JH
   Kim, CS
   Lee, SU
AF Heu, Jun-Hee
   Kim, Chang-Su
   Lee, Sang-Uk
TI SNR and temporal scalable coding of 3-D mesh sequences using singular
   value decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3-D mesh coding; Scalable coding; Rate-distortion optimization; Singular
   value decomposition; SNR scalability; Temporal scalability; Bit plane
   coding; Mesh sequence
ID COMPRESSION
AB A signal-to-noise ratio (SNR) and temporal scalable coding algorithm for 3-D mesh sequences using singular value decomposition (SVD) is proposed in this work. The proposed algorithm employs SVD to represent a mesh sequence with a small number of basis vectors, and encodes those basis vectors with a bit plane coder. We analytically derive the contribution of each bit plane to the reconstructed mesh quality, and transmit the bit planes in the decreasing order of their amounts of contribution. As the decoder receives more bit planes, it reconstructs higher quality mesh sequences progressively. Moreover, we develop a temporal prediction mode to improve the rate-distortion (R-D) performance further, which also supports temporal scalability. Simulation results demonstrate that the proposed algorithm yields significantly better R-D performance than conventional SVD-based coders. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Kim, Chang-Su] Korea Univ, Dept Elect & Comp Engn, Sch Elect Engn, Seoul, South Korea.
   [Heu, Jun-Hee; Lee, Sang-Uk] Seoul Natl Univ, Sch Elect Engn, Signal Proc Lab, Seoul, South Korea.
   [Heu, Jun-Hee; Lee, Sang-Uk] Seoul Natl Univ, INMC, Seoul, South Korea.
C3 Korea University; Seoul National University (SNU); Seoul National
   University (SNU)
RP Kim, CS (corresponding author), Korea Univ, Dept Elect & Comp Engn, Sch Elect Engn, 5-1 Anam Dong, Seoul, South Korea.
EM hjun77@ipl.snu.ac.kr; changsukim@korea.ac.kr; sanguk@ipl.snu.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU Ministry of Knowledge Economy (MKE), Korea; IITA
   [IITA-2009-C1090-09020018]; Korean Government [KRF-2008-331-D00420];
   MKE, Korea [IITA2009-C1090-0902-0017]
FX The work of J.-H. Heu and S.-U. Lee was supported by the Ministry of
   Knowledge Economy (MKE), Korea, under the ITRC support program
   supervised by the IITA (Grant No. IITA-2009-C1090-09020018). The work of
   C.-S. Kim was supported partly by the Korea Research Foundation Grant
   funded by the Korean Government (KRF-2008-331-D00420) and partly by the
   MKE, Korea, under the ITRC support program supervised by the IITA (Grant
   No. IITA2009-C1090-0902-0017).
CR Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   DAVIS G, 1999, APPL COMPUT CONTROL, V1, P1
   Gersho A., 2003, Vector Quantization and Signal Compression
   GIGNONI P, 2001, COMPUT GRAPH FORUM, V17, P167
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gross JT., 1999, Graph Theory and Its Applications
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Heu J, 2006, ELECTRON LETT, V42, P799, DOI 10.1049/el:20060869
   IBARRIA L, 2003, P 2003 ACM SIGGRAPH, P126
   Jang ES, 2004, IEEE T CIRC SYST VID, V14, P989, DOI 10.1109/TCSVT.2004.830670
   Kalman D., 1996, Coll. Math. J, V27, P2, DOI [DOI 10.1080/07468342.1996.11973744, 10.1080/07468342.1996.11973744]
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Lengyel J. E., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P89, DOI 10.1145/300523.300533
   Mamou K, 2006, COMPUT ANIMAT VIRT W, V17, P337, DOI 10.1002/cav.137
   Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429
   Payan F, 2007, COMPUT GRAPH-UK, V31, P77, DOI 10.1016/j.cag.2006.09.009
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Sattler M., 2005, P 2005 ACM SIGGRAPH, P209
   Sayood K, 2017, Introduction to data compression
   Stefanatos N., 2007, EUR WIND ENERGY C EX, V7-10, P1
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   Wang Y., 2001, VIDEO PROCESSING COM
   Yang JH, 2006, IEEE T IMAGE PROCESS, V15, P2531, DOI 10.1109/TIP.2006.877413
   YANG JH, 2000, IEEE T CIRCUITS SYST, V12, P1178
NR 26
TC 11
Z9 11
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2009
VL 20
IS 7
BP 439
EP 449
DI 10.1016/j.jvcir.2009.05.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 559DJ
UT WOS:000274800800001
DA 2024-07-18
ER

PT J
AU Hsia, SC
   Wang, SH
AF Hsia, Shih-Chang
   Wang, Szu-Hong
TI Adaptive video coding control for real-time H.264/AVC encoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Coding control; Initial QP; Rate control; Adaptive GOP; Scene
   change; Constant bitrate; Video coding
ID RATE CONTROL SCHEME; DISTORTION
AB In this paper, we present a new adaptive video coding control for real-time H. 264/AVC encoding system. The main techniques include: (1) the initial quantization parameter (QP) decision scheme is based on Laplacian of Gaussian (LoG) operators; (2) the MB-level QP calculation is based on the spatio-temporal correlation, in which the computation is less than the quadratic model used by H. 264/AVC; (3) the adaptive GOP structure is proposed, in which the I-frame is adaptively replaced by an enhancement P-frame to improve the coding efficiency; (4) the scene change is detected with the complexity of adjacent interframes and the appropriate QP is re-calculated for the scene-change frame. The proposed algorithm is not only to save the computational complexity but also to improve coding quality. Compared to the JM12.4 reference under various sequences testing, the proposed algorithm can decrease coding time by 64.5% and improve PSNR by 1.52 dB while keeping the same bit-rate. Crown Copyright (C) 2009 Published by Elsevier Inc. All rights reserved.
C1 [Hsia, Shih-Chang; Wang, Szu-Hong] Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
   [Hsia, Shih-Chang] Natl Kaohsiung First Univ Sci & Technol, Dept Elect Engn, Kaohsiung 824, Taiwan.
C3 National Kaohsiung University of Science & Technology; National
   Kaohsiung University of Science & Technology
RP Wang, SH (corresponding author), Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
EM hsia@ccms.nkfust.edu.tw; szuhong@hotmail.com
FU National Science Council, Taiwan, ROC [NSC NSC94-2213-E-327-004]
FX This work was supported by the National Science Council, Taiwan, ROC,
   under NSC NSC94-2213-E-327-004.
CR Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Ding JR, 2008, IET IMAGE PROCESS, V2, P85, DOI 10.1049/iet-ipr:20070014
   Hsia SC, 2003, EURASIP J APPL SIG P, V2003, P244, DOI 10.1155/S1110865703210040
   *ISO IEC, 2003, ISOIECJTC1SC29WG11
   *ISO IEC, 1993, ISOIECJTC1SC29WG1193
   Jiang X, 2006, J GENE MED, V8, P477, DOI 10.1002/jgm.868
   KIM MJ, 2008, P IEEE ICACT 3, P1875
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lee C, 2007, IEEE T CONSUM ELECTR, V53, P1084, DOI 10.1109/TCE.2007.4341589
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   Lim SC, 2007, SIGNAL PROCESS-IMAGE, V22, P39, DOI 10.1016/j.image.2006.11.001
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Sharifi M, 2002, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P117, DOI 10.1109/ITCC.2002.1000371
   Shih-Chang Hsia, 2008, 2008 International Conference on Communications, Circuits and Systems, P742, DOI 10.1109/ICCCAS.2008.4657878
   Tu YK, 2007, IEEE T CIRC SYST VID, V17, P530, DOI 10.1109/TCSVT.2007.894041
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P140, DOI 10.1109/TCSVT.2007.913757
   Wiegand T., 2005, JVTO079
   WIEGAND T, 2003, H264ISOIEC1449610AVC
   Yuan W, 2006, IEEE T CIRC SYST VID, V16, P705, DOI 10.1109/TCSVT.2006.875215
   Zhou SM, 2007, IEEE T CIRC SYST VID, V17, P996, DOI 10.1109/TCSVT.2007.903123
NR 20
TC 6
Z9 7
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2009
VL 20
IS 7
BP 463
EP 477
DI 10.1016/j.jvcir.2009.06.003
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 559DJ
UT WOS:000274800800003
DA 2024-07-18
ER

PT J
AU Sousa, P
   Fonseca, MJ
AF Sousa, Pedro
   Fonseca, Manuel J.
TI Geometric matching for clip-art drawing retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geometric matching; Drawing retrieval; Sketch-based retrieval;
   Topological description; Topology graph; Clip-art drawing; Complex
   drawings; Query-by-Sketch; Graph spectrum; Graph Comparison
ID SIMILARITY RETRIEVAL
AB Currently, there are large collections of clip-art vector drawings from which users can select the desired figures to insert in their documents. However, to locate a particular drawing among thousands is not easy. Although there are some solutions for drawing retrieval, almost all of them are designed to retrieve simple and not complex drawings as for instance clip-arts. In our prior work we proposed an approach to index and retrieve complex vector drawings by content, using topological and geometric information automatically extracted from figures. In this paper, we present a new algorithm to improve the geometric matching of two drawings, which takes into account the drawing as a whole and each of the shapes in it. We developed a web search engine for clip-art drawings, where we included this new technique. Experimental evaluation reveals that this new geometric matching algorithm conducts to better retrieval results than the prior matching solution. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Sousa, Pedro; Fonseca, Manuel J.] Univ Tecn Lisboa, Dept Comp Sci & Engn, INESC ID IST, P-1000029 Lisbon, Portugal.
C3 INESC-ID; Universidade de Lisboa
RP Fonseca, MJ (corresponding author), Univ Tecn Lisboa, Dept Comp Sci & Engn, INESC ID IST, R Alves Redol 9, P-1000029 Lisbon, Portugal.
EM pedrocrs@gmail.com; mjf@inesc-id.pt
RI Fonseca, Manuel J./D-5120-2011
OI Fonseca, Manuel J./0000-0002-3559-828X
CR [Anonymous], IMAGE COLLECTIONS DE
   [Anonymous], THESIS TECHNICAL U L
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 1996, P ACM C HUMAN FACTOR
   [Anonymous], QUANTITATIVE MEASURE
   [Anonymous], P 17 INT C PATT REC
   [Anonymous], AVI 04 P WORK C ADV
   [Anonymous], P 9 IEEE C FUZZ SYST
   [Anonymous], P ASS COMP AID DES A
   [Anonymous], P 2002 AAAI SPRING S
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P INT WORKSH VIS LAN
   [Anonymous], P MACHINE LEARNING C
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], TECHNICAL DRAWING RE
   Berchtold S., 1997, PROC SIGMOD 97, P564
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   Cvetkovic Dragos, 1997, Eigenspaces of graphs
   EGENHOFER MJ, 1992, LECT NOTES COMPUT SC, V639, P196
   Fonseca MJ, 2005, INT J COMPUT APPL T, V23, P86, DOI 10.1504/IJCAT.2005.006467
   Fonseca MJ, 2003, EIGHTH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PROCEEDINGS, P267, DOI 10.1109/DASFAA.2003.1192391
   Hou SY, 2008, COMPUT AIDED DESIGN, V40, P94, DOI 10.1016/j.cad.2007.08.007
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Muller S., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P697, DOI 10.1109/ICDAR.1999.791883
   Nabil M, 1996, IEEE T KNOWL DATA EN, V8, P533, DOI 10.1109/69.536246
   Park JH, 1999, PATTERN RECOGN LETT, V20, P591, DOI 10.1016/S0167-8655(99)00022-7
   Pu JT, 2006, COMPUT AIDED DESIGN, V38, P249, DOI 10.1016/j.cad.2005.10.009
NR 27
TC 14
Z9 17
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 71
EP 83
DI 10.1016/j.jvcir.2008.11.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800002
DA 2024-07-18
ER

PT J
AU Chung, KL
   Yang, WJ
   Yan, WM
AF Chung, Kuo-Liang
   Yang, Wei-Jen
   Yan, Wen-Ming
TI Efficient edge-preserving algorithm for color contrast enhancement with
   application to color image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CIE color model; color contrast enhancement; color edge detection; color
   histogram moment; color image segmentation; color saturation and
   desaturation; edge-preservation effect; seed-based region growing
   approach
ID RETRIEVAL; EXTRACTION
AB In this paper, a new and efficient edge-preserving algorithm is presented for color contrast enhancement in CIE Lu'v' color space. The proposed algorithm not only can enhance the color contrast as the previous algorithm does, but also has an edge-preservation effect. In addition, the spurious edge points occurred due to the color contrast enhancement can be well reduced using the proposed algorithm. This is the first edge-preserving algorithm for color contrast enhancement in color space. Furthermore, a novel color image segmentation algorithm is presented to justify the edge-preservation benefit of the proposed color contrast enhancement algorithm. Based on some real images, experimental results demonstrate the advantages of color contrast enhancement, edge-preservation effect, and segmentation result in our proposed algorithm. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Chung, Kuo-Liang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Chilung 10672, Taiwan.
   [Yang, Wei-Jen; Yan, Wen-Ming] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Chilung 10672, Taiwan.
EM k.l.chung@mail.ntust.edu.tw
RI cai, bo/G-1491-2010; Chung, Kuo-Liang/H-6207-2011
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], P SOC PHOTO-OPT INS
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   CANCLES EJ, 1999, CURVE SURFACE FITTIN
   Chen DY, 2005, J VIS COMMUN IMAGE R, V16, P212, DOI 10.1016/j.jvcir.2004.08.003
   Chen JQ, 2005, IEEE T IMAGE PROCESS, V14, P1524, DOI 10.1109/TIP.2005.852204
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hsieh IS, 2001, IEEE T IMAGE PROCESS, V10, P938, DOI 10.1109/83.923290
   Hsieh JW, 2003, IEEE T IMAGE PROCESS, V12, P1404, DOI 10.1109/TIP.2003.816013
   Hunt R.W.G., 1995, MEASURING COLOUR
   Lezoray O, 2002, IEEE T IMAGE PROCESS, V11, P783, DOI 10.1109/TIP.2002.800889
   Lucchese L, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1077, DOI 10.1109/ICIP.2001.958684
   Lucchese L, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P500, DOI 10.1109/ICIP.2000.899463
   Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Navon E, 2005, IMAGE VISION COMPUT, V23, P69, DOI 10.1016/j.imavis.2004.05.011
   Paschos G, 2003, IEEE T KNOWL DATA EN, V15, P1069, DOI 10.1109/TKDE.2003.1232264
   Pei SC, 2004, IEEE T IMAGE PROCESS, V13, P414, DOI 10.1109/TIP.2003.821347
   Pei SC, 1999, IEEE T CIRC SYST VID, V9, P501, DOI 10.1109/76.754779
   Pratt W.K., 1977, DIGITAL IMAGE PROCES
   Sangwine S. J., 1998, The colour image processing handbook
   Scharcanski J, 1997, IEEE T CIRC SYST VID, V7, P397, DOI 10.1109/76.564116
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Theoharatos C, 2005, PATTERN RECOGN, V38, P603, DOI 10.1016/j.patcog.2004.09.009
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P259, DOI 10.1109/83.217230
   Trémeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950
   Zaharescu E, 2003, SCS 2003: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, PROCEEDINGS, P145
NR 32
TC 15
Z9 17
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2008
VL 19
IS 5
BP 299
EP 310
DI 10.1016/j.jvcir.2008.02.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 318LO
UT WOS:000257093400002
OA Green Published
DA 2024-07-18
ER

PT J
AU Wang, XY
   Cui, CY
AF Wang, Xiang-Yang
   Cui, Chang-Ying
TI A novel image watermarking scheme against desynchronization attacks by
   SVR revision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE digital image watermarking; desynchronization attacks; support vector
   regression; revision; sum; variance image block; neighboring pixel
AB In digital image watermarking, the watermark's vulnerability to desynchronization attacks has long been a difficult problem. On the basis of support vector regression (SVR) theory and local image characteristics, a novel image watermarking scheme against desynchronization attacks by SVR revision is proposed in this paper. First, some pixels are randomly selected and the sum and variance of their neighboring pixels are calculated; second, the sum and variance are regarded as the training features and the pixel values as the training objective; third, the appropriate kernel function is chosen and trained, a SVR training model will be obtained. Finally, the sum and variance of all pixels' neighboring pixels are selected as input vectors, the actual output can be obtained by using the well-trained SVR, and the digital watermark can be recovered by judging the output vector. Experimental results show that the proposed scheme is invisible and robust against common signals processing such as median filtering, sharpening, noise adding, and JPEG compression, etc., and robust against clesynchronization attacks such as rotation, translation, scaling, row or column removal, shearing, local random bend, etc. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Wang, Xiang-Yang; Cui, Chang-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
C3 Liaoning Normal University; Nanjing University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, 850 Huanghe Rd,Shahekou Dist, Dalian 116029, Peoples R China.
EM wxy37@126.com
CR BAS P, 2002, IEEE T SIGNAL PROCES, V9, P1014
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Cox IJ., 2007, DIGITAL WATERMARKING
   FU YG, 2004, IEE ELECT LETT, V16, P986
   JOSEPH JK, 1997, SIGNAL PROCESS, V3, P303
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   Li CD, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P183
   Li CH, 2005, PROC INT C TOOLS ART, P466
   LI CL, 2005, J IMAGE GRAPHICS, V4, P403
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   LIU JF, 2004, J ELECT TECHNOLOGY, V9, P1495
   PEREIRA S, 1999, IST SPIE ELECT IMAGE
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   SUN HZ, 2006, CONT DIGITAL IMAGE P
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   WU JZ, 2006, J SHANGHAI JT U, V3, P481
   Xin YQ, 2004, INT C PATT RECOG, P861, DOI 10.1109/ICPR.2004.1333908
NR 19
TC 5
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2008
VL 19
IS 5
BP 334
EP 342
DI 10.1016/j.jvcir.2008.03.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 318LO
UT WOS:000257093400005
DA 2024-07-18
ER

PT J
AU Chen, YW
   Hsiao, MH
   Chen, HT
   Liu, CY
   Lee, SY
AF Chen, Yi-Wen
   Hsiao, Ming-Ho
   Chen, Hua-Tsung
   Liu, Chi-Yu
   Lee, Suh-Yin
TI Content-aware fast motion estimation algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE motion estimation; successive elimination algorithm; integral frame;
   search range; H.264/AVC; SAD; motion vector; computational complexity
ID SUCCESSIVE ELIMINATION ALGORITHM; SEARCH
AB In this paper, we propose the Content-Aware Fast Motion Estimation Algorithm (CAFME) that can reduce computation complexity of motion estimation (ME) in H.264/AVC while maintaining almost the same coding efficiency. Motion estimation can be divided into two phases: searching phase and matching phase. In searching phase.. we propose the Simple Dynamic Search Range Algorithm (SDSR) based on video characteristics to reduce the number of search points (SP). In matching phase, we integrate the Successive Elimination Algorithm (SEA) and the integral frame to develop a new SEA for H.264/AVC video compression standard, called Successive Elimination Algorithm with Integral Frame (SEAIF). Besides, we also propose the Early Termination Algorithm (ETA) to early terminate the motion estimation of current block.
   We implement the proposed algorithm in the reference software JM9.4 of H.264/AVC and the experimental results show that our proposed algorithm can reduce the number of search points about 93.1%, encoding time about 42%, while maintaining almost the same bitrate and PSNR. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Chen, Yi-Wen; Hsiao, Ming-Ho; Chen, Hua-Tsung; Liu, Chi-Yu; Lee, Suh-Yin] Natl Chiao Tung Univ, Coll Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, YW (corresponding author), Natl Chiao Tung Univ, Coll Comp Sci, 1001 Ta Hsueh Rd, Hsinchu, Taiwan.
EM ewchen@csie.nctu.edu.tw; mhhsiao@csie.nctu.edu.tw;
   huatsung@csie.nctu.edu.tw; liucy@csie.nctu.edu.tw;
   sylee@csie.nctu.edu.tw
CR [Anonymous], 200101 CRL
   Chen Z., 2002, JVTF017 ITUT
   FENG J, 1995, ELECTRON LETT, V31, P1542, DOI 10.1049/el:19951047
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   Hosur PI, 2003, IEEE T CONSUM ELECTR, V49, P1330, DOI 10.1109/TCE.2003.1261237
   JEON B, 2003, JVTJ033 ITUT
   KOGA T, 1981, P NAT TEL C NEW OR L
   Lee LW, 1993, IEEE T CIRC SYST VID, V3, P85, DOI 10.1109/76.180692
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   LIM KP, 2005, JVTN046 ITUT
   Lin SS, 2004, 2004 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS DESIGN AND IMPLEMENTATION, PROCEEDINGS, P239
   MINOCHA J, 1999, IEEE WORKSH MULT SIG, P685
   Nguyen VA, 2004, IEEE SIGNAL PROC LET, V11, P744, DOI 10.1109/LSP.2004.833500
   Saponara S, 2004, IEE P-COMPUT DIG T, V151, P51, DOI 10.1049/ip-cdt:20030858
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 15
TC 4
Z9 7
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2008
VL 19
IS 4
BP 256
EP 269
DI 10.1016/j.jvcir.2008.01.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 311MK
UT WOS:000256604100004
DA 2024-07-18
ER

PT J
AU Masood, A
   Haq, SA
AF Masood, Asif
   Haq, Shaiq A.
TI A novel approach to polygonal approximation of digital curves
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE dominant points; break points; polygonal approximation; DP table; near
   optimal algorithm
ID PIECEWISE LINEAR-APPROXIMATION; DOMINANT POINTS; CHAIN CODES; SHAPE;
   REPRESENTATION; ALGORITHM
AB A new approach to polygonal approximation is presented in this paper. It starts from an initial set of dominant points (break points), where the integral square error from a given shape is zero. The proposed algorithm iteratively deletes most redundant dominant points till required approximation is achieved. Stabilization algorithm after elimination of each dominant point ensures high quality of approximation. Results of proposed algorithm are compared with classical algorithms. The proposed algorithm has additional benefits like polygonal approximation with any number of dominant points and up to any error value and robustness of results. (c) 2007 Elsevier Inc. All rights reserved.
C1 Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
C3 University of Engineering & Technology Lahore
RP Masood, A (corresponding author), Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
EM asif@uet.edu.pk; sh@shaiq.com
CR ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472
   [Anonymous], IND C VIS GRAPH IM P
   ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O
   ARCELLI C, 1993, PATTERN RECOGN, V26, P1563, DOI 10.1016/0031-3203(93)90161-O
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   BANERJEE S, 1996, 10007 RJ IBM RES DIV
   Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154
   Chau CP, 2001, IEE P-VIS IMAGE SIGN, V148, P363, DOI 10.1049/ip-vis:20010576
   CHUNG PC, 1994, PATTERN RECOGN, V27, P1505, DOI 10.1016/0031-3203(94)90128-7
   Cronin TM, 1999, PATTERN RECOGN LETT, V20, P617, DOI 10.1016/S0167-8655(99)00025-2
   DALLAIRE S, 1966, P SOC PHOTO-OPT INS, V2950, P294
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   GRUMBACH S, 1998, P ACM SIGMOD INT C M, P213
   Guru DS, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P417, DOI 10.1109/CCCRV.2004.1301477
   HELD A, 1994, IEEE T SYST MAN CYB, V24, P942, DOI 10.1109/21.293514
   HU XP, 1994, IEEE T PATTERN ANAL, V16, P1041, DOI 10.1109/34.329004
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   KANEKO T, 1985, IEEE T COMMUN, V33, P697, DOI 10.1109/TCOM.1985.1096361
   KARTIKEYAN B, 1989, IEEE T PATTERN ANAL, V11, P977, DOI 10.1109/34.35501
   KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390
   KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644
   KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075
   KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 2000, J ELECTRON IMAGING, V9, P317, DOI 10.1117/1.482748
   Latecki LJ, 1999, LECT NOTES COMPUT SC, V1682, P398
   LOURAKIS M, 1998, BRIT MACH VIS C, V1, P94
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   NEUHOFF DL, 1985, IEEE T INFORM THEORY, V31, P53, DOI 10.1109/TIT.1985.1056998
   Neumann R, 2002, PATTERN RECOGN, V35, P1447, DOI 10.1016/S0031-3203(01)00145-5
   Pal NR, 1998, INT J SYST SCI, V29, P207, DOI 10.1080/00207729808929513
   Park H, 2005, COMPUTER GRAPHICS, IMAGING AND VISION: NEW TRENDS, P437
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D
   RAY BK, 1993, PATTERN RECOGN, V26, P505, DOI 10.1016/0031-3203(93)90106-7
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P443, DOI 10.1016/0167-8655(92)90051-Z
   Rosin PL, 2003, PATTERN RECOGN, V36, P505, DOI 10.1016/S0031-3203(02)00076-6
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3, P533, DOI 10.1109/TPAMI.1981.4767146
   Sarfraz M, 2004, IEEE INFOR VIS, P991, DOI 10.1109/IV.2004.1320262
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   SATO Y, 1992, PATTERN RECOGN, V25, P1535, DOI 10.1016/0031-3203(92)90126-4
   SEMYONOV PA, 1990, 12 IEEE INT C ENG ME, P779
   SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Yin PY, 1999, INT J PATTERN RECOGN, V13, P1061, DOI 10.1142/S0218001499000598
   YUEN PC, 1993, ELECTRON LETT, V29, P2023, DOI 10.1049/el:19931350
NR 54
TC 39
Z9 43
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 264
EP 274
DI 10.1016/j.jvcir.2006.12.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300006
DA 2024-07-18
ER

PT J
AU Chung, KL
   Liu, YW
   Yan, WM
AF Kuo-Liang Chung
   Yau-Wen Liu
   Wen-Ming Yan
TI A hybrid gray image representation using spatial- and DCT-based approach
   with application to moment computation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DCT; gray image representation; linear interpolation; moment
   computation; PSNR; spatial data structures
ID COMPRESSION; QUADTREE; RETRIEVAL; CODE; TREE
AB In this paper, a novel hybrid gray image representation using spatial- and DCT-based approach is presented. In the first phase, according to the bintree decomposition principle under the specified error, an S-tree spatial data structure (SDS) is used to represent the decomposed bintree of the input gray image. In the constructed S-tree SIDS, the leaves are partitioned into two types, namely the homogeneous leaves and the norhomogeneous leaves. The homogeneous leaf is used to represent one rectangular or square homogeneous subimage with smooth, i.e., low frequency, content and the nonhomogeneous leaf is used to represent one norhomogeneous subimage with nonsmooth, i.e., high frequency, content. In the second phase, each nonhomogeneous leaf is encoded by the DCT-based coding scheme for reducing the memory requirement. Based on some real gray images, experimental results show that our proposed gray image representation over the previously published S-tree- and shading-based SIDS has about 63.08% memory-saving improvement ratio in average. Finally, we investigate the computational benefit when computing moments on our proposed gray image representation directly. (C) 2006 Elsevier Inc. All rights reserved.
C1 Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM klchung@csie.ntust.edu.tw
RI Chung, Kuo-Liang/H-6207-2011
CR [Anonymous], 1990, The design and analysis of spatial data structures
   [Anonymous], 1998, Image processing, analysis, and machine vision
   Chan YK, 2004, IMAGE VISION COMPUT, V22, P391, DOI 10.1016/j.imavis.2003.12.003
   Chang CC, 2004, IMAGING SCI J, V52, P106, DOI 10.1179/136821904225011591
   Chen PM, 2002, PATTERN RECOGN LETT, V23, P1253, DOI 10.1016/S0167-8655(02)00060-0
   Chen Z, 2001, IMAGE VISION COMPUT, V19, P413, DOI 10.1016/S0262-8856(00)00080-9
   Chung KL, 2000, IEEE T COMMUN, V48, P748, DOI 10.1109/26.843184
   Chung KL, 2005, PATTERN RECOGN, V38, P2578, DOI 10.1016/j.patcog.2005.04.004
   Distasi R, 1997, IEEE T COMMUN, V45, P1095, DOI 10.1109/26.623074
   Flusser J, 2000, IEEE T IMAGE PROCESS, V9, P1977, DOI 10.1109/83.877219
   Foley J.D., 1990, Computer graphics: Principles and practice
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   JONGE WD, 1994, CVGIP-IMAG UNDERSTAN, V59, P265
   Kachris C, 2003, INT J PARALLEL PROG, V31, P489, DOI 10.1023/B:IJPP.0000004512.53221.ff
   KAWAGUCHI E, 1980, IEEE T PATTERN ANAL, V2, P27, DOI 10.1109/TPAMI.1980.4766967
   Lin TW, 1997, IMAGE VISION COMPUT, V15, P833, DOI 10.1016/S0262-8856(97)00031-0
   Lin TW, 1997, PATTERN RECOGN, V30, P1239, DOI 10.1016/S0031-3203(97)83108-1
   Paschos G, 2003, IEEE T KNOWL DATA EN, V15, P1069, DOI 10.1109/TKDE.2003.1232264
   Pei SC, 1999, IEEE T IMAGE PROCESS, V8, P1831, DOI 10.1109/83.806629
   PEI SC, 1994, IMAGE VISION COMPUT, V12, P475, DOI 10.1016/0262-8856(94)90001-9
   Samet H., 1990, The Design and Analysis of Spatial Data Structures
   Spiliotis IM, 1998, IEEE T IMAGE PROCESS, V7, P1609, DOI 10.1109/83.725368
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wan X, 1998, IEEE T CIRC SYST VID, V8, P628, DOI 10.1109/76.718509
   Yang CK, 1997, IEEE T COMMUN, V45, P1513, DOI 10.1109/26.650223
NR 29
TC 23
Z9 28
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1209
EP 1226
DI 10.1016/j.jvcir.2006.01.002
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200006
OA Green Published
DA 2024-07-18
ER

PT J
AU Micheloni, C
   Foresti, GL
AF Micheloni, Christian
   Foresti, Gian Luca
TI Real-time image processing for active monitoring of wide areas
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE mobile camera; active tracking; feature selection; object detection
ID TRACKING; ALGORITHMS
AB A real-time active system able to monitor wide areas by processing video sequences acquired by a pan, tilt, and zoom (PTZ) camera is presented. The system is able to compensate background changes due to camera motion, to detect and to maintain the gaze on objects moving in the scene. Two novelties to speed up the performance of the system and to fit the real-time constraints have been introduced. The first speed-up consists on a new feature clustering method studied to reject badly tracked features. Such method is used to compute a simple yet efficient transformation model for image alignment. The second improvement relies on the introduction of a reference map, containing well trackable features, that is used to select features in a fast and reliable way. The map is maintained and updated continuously by introducing new features related to new regions appeared in the current frame. To detect moving objects, the previous and current frame, after compensation, are processed by a change detection method. Finally, a standard Kalman filter is applied to track objects and to determine the pan and tilt angles that the camera has to perform in order to maintain the gaze on the target. (C) 2005 Elsevier Inc. All rights reserved.
C1 Univ Udine, Dept Math & Comp Sci, I-33100 Udine, Italy.
C3 University of Udine
RP Micheloni, C (corresponding author), Univ Udine, Dept Math & Comp Sci, Via Sci 206, I-33100 Udine, Italy.
EM michelon@dimi.uniud.it
RI Micheloni, Christian/E-5427-2012
OI Micheloni, Christian/0000-0003-4503-7483
CR Araki S, 2000, IEICE T INF SYST, VE83D, P1583
   ARSENIO A, 1997, 9 PORT C PATT REC CO
   Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Collins R., 2000, CMURITR0012
   DAVIS YYL, 1997, P DARPA97 IM UND WOR, P19
   DAVISON A, 1999, P 6 BRIT MACH VIS C
   Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Foresti G.L., 2000, MULTIMEDIA VIDEO BAS
   FORESTI GL, 2003, ELECT LETT COMPUT VI, V1, P21
   Gandhi T, 2005, MACH VISION APPL, V16, P85, DOI 10.1007/s00138-004-0168-z
   Gluckman J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P999, DOI 10.1109/ICCV.1998.710838
   GUO G, 2005, IEEE INT C COMP VIS, V2, P274
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HOWARTH R, 1996, ECCV96 2, P321
   Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770
   KANADE T, 1998, P DARPA IM UND WORKS, V1, P3
   KANATANI K, 1986, IEEE INT C COMP VIS
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P1128, DOI 10.1109/TCSVT.2002.806813
   KOHLER M, 1996, 3D IMAGE ANAL SYNTHE, P147
   Kumar P, 2005, IEEE T INTELL TRANSP, V6, P43, DOI 10.1109/TITS.2004.838219
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Matsuyama T, 2002, P IEEE, V90, P1136, DOI 10.1109/JPROC.2002.801442
   MURRAY D, 1994, IEEE T PATTERN ANAL, V16, P449, DOI 10.1109/34.291452
   OKADA R, 1996, IEEE INT C MULT FUS, P565
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Regazzoni CS, 2001, P IEEE, V89, P1355, DOI 10.1109/5.959335
   Rosin PL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P274, DOI 10.1109/ICCV.1998.710730
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sugaya Y, 2003, IEICE T INF SYST, VE86D, P1095
   SUGAYA Y, 2004, 10 S SENS IM INF YOK, P279
   Tomasi C, 1991, DETECTION TRACKING P
   Tommasini T, 1998, PROC CVPR IEEE, P178, DOI 10.1109/CVPR.1998.698606
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   Ye YM, 2000, MACH VISION APPL, V12, P32, DOI 10.1007/s001380050122
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 38
TC 19
Z9 21
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 589
EP 604
DI 10.1016/j.jvcir.2005.08.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300006
DA 2024-07-18
ER

PT J
AU Yu, AC
   Ngi, NK
   Martin, GR
AF Yu, Andy C.
   Ngi, Ngan King
   Martin, Graham R.
TI Efficient intra- and inter-mode selection algorithms for H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; intra-frame mode selection; inter-frame mode selection;
   Lagrangian rate-distortion optimisation
ID ALLOCATION
AB Intra-frame mode selection and inter-frame mode selection are new features introduced in the H.264 standard. Intra-frame mode selection dramatically reduces spatial redundancy in I-frames, while inter-frame mode selection significantly affects the output quality of P-/B-frames by selecting an optimal block size with motion vector(s) or a mode for each macroblock. Unfortunately, this feature requires a myriad amount of encoding time especially when a brute force full-search method is utilised. In this paper, we propose fast mode selection algorithms tailored for both intra-frames and inter-frames. The success of the intra-frame algorithm is achieved by reducing the computational complexity of the Lagrangian rate-distortion optimisation evaluation. Two proposed fast inter-frame mode algorithms incorporate several robust and reliable predictive factors, including intrinsic complexity of the macroblock, mode knowledge from the previous frame(s), temporal similarity detection and the detection of different moving features within a macroblock. This information is used to reduce the number of search operations. Extensive simulations on different classes of test sequences demonstrate a speed up in encoding time of up to 86% compared with the H.264 benchmark. This is achieved without any significant degradation in picture quality and compression ratio. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 University of Warwick; Chinese University of Hong Kong
RP Yu, AC (corresponding author), Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
EM andycyu@dcs.warwick.ac.uk; knngan@ee.cuhk.edu.hk; grm@dcs.warwick.ac.uk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   *ISO IEC, 2003, 14496102003 ISOIEC
   *JOINT MOD, 2002, JVTA003 JOINT MOD
   KANKANHALLI M, CONTENT BASED WATERM
   LIM KP, 2003, JVTI020
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Wiegand T., 2001, MULTIFRAME MOTION CO
   YU A, 2004, P INT C AC SPEECH SI, V3, P17
NR 10
TC 12
Z9 15
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 322
EP 344
DI 10.1016/j.jvcir.2005.05.006
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, CN
   Liu, CM
   Chiang, TH
AF Wang, CN
   Liu, CM
   Chiang, TH
TI Perceptual dithering for octave subband image coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image coding; perceptual image coding; perceptual dithering; perceptual
   dithering coding; perceptual correlation; interband correlation; wavelet
   transform; octave decomposition; octave subband coding; MPEG-4 visual
   texture coding (VTC)
AB Octave subband coding has been used as an efficient image coding approach for various well-known standards such as MPEG-4 and JPEG-2000. Although the sub-images in the octave subband representation have low statistical correlation, the visual similarity among the sub-images indicates that there exists some unexploited perceptual redundancy between sibling bands in addition to the parent-child redundancy. In this paper, we show that the original image can be perceptually dithered to form a visually equivalent image with increased interband correlation that can be used to achieve more compression. To remove the redundancy among the sibling subbands of an image, we provide a novel perceptual dithering approach that is based on entropy reduction technique with perceptual model. The theoretical basis for the entropy reduction is proven by a theorem for Gaussian distributed signals. The use of our dithering technique is demonstrated for an MPEG-4 compliant encoder with improved coding efficiency using MPEG-4 Visual Texture Coding (VTC) based on zerotree entropy coding. Our results show that there exists a perceptual interband redundancy even though the original interband correlation is small. For a perceptually transparent image quality, our approach can achieve bit savings over MPEG-4 VTC by 11-30%, while maintaining compatibility with the MPEG-4 standards. (C) 2003 Elsevier Inc. All rights reserved.
C1 NCTU, Dept & Inst Comp Sci & Informat Engn, Hsinchu 30050, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Liu, CM (corresponding author), NCTU, Dept & Inst Comp Sci & Informat Engn, Hsinchu 30050, Taiwan.
EM cmliu@csie.nctue.du.tw
CR ANDREW JP, 1995, IEE P-VIS IMAGE SIGN, V142, P133, DOI 10.1049/ip-vis:19951938
   ANDREW JP, 1994, P ICIP 94, V3, P348
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Berger Toby, 1971, RATE DISTORTION THEO
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   daSilva EAB, 1996, IEEE T IMAGE PROCESS, V5, P689, DOI 10.1109/83.495953
   Daubechies I., 1992, CBMS-NSF Regional Conf. Series in Appl. Math., V61
   JOHNSEN O, 1990, P IEEE ICASSP, P2097
   KRONANDER T, 1989, THESIS DELFT U TECHN
   LIU CM, 1998, P ISCAS MONT LA US M, V4, P166
   Mallat S.G. A., 1989, IEEE T PATTERN ANAL, V11, P7
   MOHSENIAN N, 1994, IEEE T CIRC SYST VID, V4, P53, DOI 10.1109/76.276172
   *MPEG VID GROUP, 1990, INF TECHN COD AUD VI
   Press W.H., 1990, NUMERICAL RECIPES C
   Safranek R.J., 1989, PROC IEEE INT C ACOU, V3, P1945, DOI DOI 10.1109/ICASSP.1989.266837
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   VAIDYANATHAN PP, 1988, IEEE T ACOUST SPEECH, V36, P81, DOI 10.1109/29.1491
   VAISEY J, 1995, IEEE T COMMUN, V43, P216, DOI 10.1109/26.380038
   WANG CN, 2001, P 2 IEEE PAC RIM C M, P134
   WOODS JW, 1986, IEEE T ACOUST SPEECH, V34, P1278, DOI 10.1109/TASSP.1986.1164962
NR 20
TC 6
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 163
EP 184
DI 10.1016/j.jvcir.2003.07.003
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800004
DA 2024-07-18
ER

PT J
AU Caetano, R
   da Silva, EAB
AF Caetano, R
   da Silva, EAB
TI A bit allocation scheme for a class of embedded wavelet video encoders
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE rate control; video coding; wavelet transforms; embedded encoders;
   vector quantization; MPEG-4
ID SET
AB In this paper, we investigate bit allocation strategies for a class of embedded wavelet video encoders. They take advantage of the precise control that such coders have over the bit-rate of each frame. We first show that a piecewise-linear model suits the rate x distortion characteristics of these encoders better than an exponential model, specially in low bit-rate applications. Then, we use an effective iterative procedure for dealing with the problem of frame dependency which yields improved rate x distortion results. Two types of embedded wavelet coders, using scalar and vector quantization, are tested. The results are encouraging, showing that the adoption of an adequate rate-control strategy can improve both objective and subjective quality of video sequences encoded using such embedded wavelet video encoders. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Univ Fed Rio de Janeiro, PEE, COPPE, DEL,EE, BR-21945970 Rio De Janeiro, Brazil.
C3 Universidade Federal do Rio de Janeiro
RP Univ Fed Rio de Janeiro, PEE, COPPE, DEL,EE, Cx P 68504, BR-21945970 Rio De Janeiro, Brazil.
EM caetano@lps.ufrj.br; eduardo@lps.ufrj.br
RI da Silva, Eduardo A B/M-8012-2018; SILVA, EDUARDO/IQS-1403-2023
OI da Silva, Eduardo A B/0000-0001-7755-6988; 
CR Bell T. C., 1990, TEXT COMPRESSION
   Cheng PY, 1997, IEEE T CIRC SYST VID, V7, P696, DOI 10.1109/76.611180
   Conway J H., 1988, GRUNDLEHREN MATH WIS
   daSilva EAB, 1996, IEEE T IMAGE PROCESS, V5, P299, DOI 10.1109/83.480765
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Hsu CY, 1997, IEEE J SEL AREA COMM, V15, P1016, DOI 10.1109/49.611156
   *ISO IEC, 1997, JTC1SC29WG11 ISOIEC
   *ISO IEC, 1999, JTC1SC29WG1 ISOIEC
   LAN TH, 1999, P 1999 INT C IM PROC
   Lin LJ, 1998, IEEE T CIRC SYST VID, V8, P446, DOI 10.1109/76.709411
   MUKHERJEE D, 1998, 1998 IEEE INT C IM P
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   OTHA M, 1993, IEEE T SIGNAL PROCES, V41, P3416
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P533, DOI 10.1109/83.334987
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SAMPSON DG, 1995, IEE P-VIS IMAGE SIGN, V142, P141, DOI 10.1049/ip-vis:19951920
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Taubman D., 1999, 1999 IEEE INT C IM P
NR 19
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2003
VL 14
IS 2
BP 136
EP 149
DI 10.1016/S1047-3203(03)00020-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 680AJ
UT WOS:000182953900004
DA 2024-07-18
ER

PT J
AU Chen, BJ
   Nie, YX
   Yang, JH
AF Chen, Beijing
   Nie, Yuxin
   Yang, Jianhua
TI Toward high imperceptibility deep JPEG steganography based on sparse
   adversarial attack
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE JPEG; Steganography; Adversarial attack; Deep neural network;
   Steganalysis
AB JPEG steganography is an important branch of information hiding. However, with the development of deep learning-based steganalysis models, steganography is facing great challenges. To better resist these steganalysis models, this paper proposes a deep JPEG steganography framework based on sparse adversarial attacks. According to the vulnerability of deep steganalysis models to adversarial attacks, sparse adversarial attacks are introduced into the deep JPEG steganographic structure to improve the security of stego images. In addition, to resist steganalysis from JPEG and spatial domains, both JPEG and spatial domain steganalysis models are involved in adversarial training. Finally, to further enhance the imperceptibility of adversarial stego images, the visual perception loss is designed from the perspective of human eyes. Experimental results indicate that compared with the existing methods, the proposed method has higher imperceptibility and security and can resist modern deep steganalysis models in both JPEG and spatial domains to a certain extent. The source code is available at https://github.com/imagecbj/SAE-JS.
C1 [Chen, Beijing; Nie, Yuxin] Nanjing Univ Informat Sci & Technol, Engn Res Ctr Digital Forens, Minist Educ, Nanjing 210044, Peoples R China.
   [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Yang, Jianhua] Guangdong Polytech Normal Univ, Guangzhou 510635, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Guangdong Polytechnic
   Normal University
RP Yang, JH (corresponding author), Guangdong Polytech Normal Univ, Guangzhou 510635, Peoples R China.
EM yangjh86@gpnu.edu.cn
FU National Natural Science Foundation of China [62072251, 62102462];
   Guangdong Basic and Applied Basic Research Foundation [2022A1515010108];
   Research Project of Guangdong Polytechnic Normal University
   [2022SDKYA027]
FX <BOLD>Acknowledgements</BOLD> This work was supported partly by the
   National Natural Science Foundation of China (Grant No. 62072251,
   62102462) , partly by the Guangdong Basic and Applied Basic Research
   Foundation (Grant No. 2022A1515010108) and partly by the Research
   Project of Guangdong Polytechnic Normal University (Grant No.
   2022SDKYA027) .
CR akebia, About us
   Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen KJ, 2019, IEEE T INF FOREN SEC, V14, P1052, DOI 10.1109/TIFS.2018.2869353
   Chen MH, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103646
   Cogranne Remi, 2020, IH&MMSec '20: Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia Security, P161, DOI 10.1145/3369412.3395075
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   He Z., 2022, P IEEE CVF C COMP VI, P14963
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Li WX, 2020, IEEE T CIRC SYST VID, V30, P2288, DOI 10.1109/TCSVT.2019.2925118
   Liao Q., 2021, 2021 IEEE INT C MULT, P1
   Liu H, 2021, Arxiv, DOI arXiv:2010.06855
   Qin C., 2022, IEEE Trans. Artif. Intell.., P1029
   Qin CA, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103325
   Shang F, 2023, NEURAL NETWORKS, V163, P219, DOI 10.1016/j.neunet.2023.03.037
   Song TT, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2695, DOI 10.1109/ICASSP39728.2021.9414723
   Song XF, 2022, MULTIMED TOOLS APPL, V81, P36453, DOI 10.1007/s11042-022-13525-4
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Su WK, 2022, SIGNAL PROCESS, V190, DOI 10.1016/j.sigpro.2021.108319
   Su WK, 2018, IEEE T CIRC SYST VID, V28, P3545, DOI 10.1109/TCSVT.2018.2865537
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Volkhonskiy D., 2016, Generative adversarial networks for image steganography
   Wang YF, 2020, IEEE T INF FOREN SEC, V15, P2081, DOI 10.1109/TIFS.2019.2956590
   Wang Zi-chi, 2018, Journal of Applied Sciences - Electronics and Information Engineering, V36, P819, DOI 10.3969/j.issn.0255-8297.2018.05.009
   Wei KK, 2022, IEEE T INF FOREN SEC, V17, P3022, DOI 10.1109/TIFS.2022.3196265
   Wei QD, 2018, MULTIMED TOOLS APPL, V77, P17875, DOI 10.1007/s11042-017-5053-7
   Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang J., 2023, Security and Communication, Networks
   Yang JH, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P37, DOI 10.1145/3335203.3335713
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Yuan C, 2022, MULTIMED TOOLS APPL, V81, P6681, DOI 10.1007/s11042-021-11778-z
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
NR 40
TC 0
Z9 0
U1 4
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103977
DI 10.1016/j.jvcir.2023.103977
EA NOV 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y7NK8
UT WOS:001107090100001
DA 2024-07-18
ER

PT J
AU Yao, H
   Miao, J
   Zheng, YL
   Zhang, GX
   Chu, J
AF Yao, Hui
   Miao, Jun
   Zheng, Yilin
   Zhang, Guoxiang
   Chu, Jun
TI Undirected graph representing strategy for general room layout
   estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Indoor layout estimation; CNN; Undirected graph; Cuboid room; Non-cuboid
   room
AB Room layout estimation aims to predict the spatial structure of a room from a single image. Most existing methods relying on 2D cues are suitable for cuboid rooms, but non-cuboid rooms. 3D layout estimation methods can reconstruct 3D models of general rooms, but they are trained with depth information on high collection costs, consume large computation resources, and run slowly. This paper considers an undirected graph representation method of the general room layouts, which includes cuboid and non-cuboid rooms consisting of a single ceiling, a single floor, and multiple walls. To this end, we first predict the positions of the layout vertices and then use the network automatically learn the connection relationship between the vertices. The final layout is obtained through a simple layout inference post-processing algorithm. The experimental results both on cuboid and non-cuboid datasets validate the effectiveness and efficiency of our method. The code is available at https://github. com/Hui-Yao/2D-graph-layout-estimation.
C1 [Yao, Hui; Miao, Jun; Zheng, Yilin; Chu, Jun] Nanchang Hangkong Univ, Inst Comp Vis, Nanchang 330063, Jiangxi, Peoples R China.
   [Miao, Jun] Chinese Acad Sci, Key Lab Lunar & Deep Space Explorat, Beijing 100101, Peoples R China.
   [Zhang, Guoxiang] Univ Calif Merced, Merced, CA 95343 USA.
C3 Nanchang Hangkong University; Chinese Academy of Sciences; University of
   California System; University of California Merced
RP Miao, J (corresponding author), Nanchang Hangkong Univ, Inst Comp Vis, Nanchang 330063, Jiangxi, Peoples R China.; Miao, J (corresponding author), Chinese Acad Sci, Key Lab Lunar & Deep Space Explorat, Beijing 100101, Peoples R China.
EM miaojun@nchu.edu.cn
RI Yao, Hui/X-3312-2018
OI Yao, Hui/0000-0001-8735-5207
FU National Natural Science Founda- tion of China [62162045, 62366032]; Key
   Laboratory of Lunar and Deep Space Exploration, CAS [LDSE202301]
FX This study was supported by the National Natural Science Founda- tion of
   China under Grants (62162045 and 62366032) and by the Key Laboratory of
   Lunar and Deep Space Exploration, CAS, under Grant (LDSE202301) .
CR Coughlan JM, 2001, ADV NEUR IN, V13, P845
   Dasgupta S, 2016, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2016.73
   Del Pero L, 2013, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2013.27
   DeTone D, 2016, Arxiv, DOI arXiv:1606.03798
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Hirzer M, 2020, IEEE WINT CONF APPL, P2901, DOI [10.1109/WACV45572.2020.9093451, 10.1109/wacv45572.2020.9093451]
   Hsiao CW, 2019, Arxiv, DOI arXiv:1905.12571
   Izadinia H, 2017, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2017.260
   Khan F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082272
   Lee CY, 2017, IEEE I CONF COMP VIS, P4875, DOI 10.1109/ICCV.2017.521
   Lin HJ, 2018, INT C PATT RECOG, P842, DOI 10.1109/ICPR.2018.8546278
   Liu C, 2019, PROC CVPR IEEE, P4445, DOI 10.1109/CVPR.2019.00458
   Liu C, 2018, PROC CVPR IEEE, P2579, DOI 10.1109/CVPR.2018.00273
   Mallya A, 2015, IEEE I CONF COMP VIS, P936, DOI 10.1109/ICCV.2015.113
   Mirowski P, 2017, Arxiv, DOI arXiv:1611.03673
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie YY, 2020, PROC CVPR IEEE, P52, DOI 10.1109/CVPR42600.2020.00013
   Ren YZ, 2017, LECT NOTES COMPUT SC, V10115, P36, DOI 10.1007/978-3-319-54193-8_3
   Schwing AG, 2012, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2012.6248006
   Stekovic Sinisa, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P187, DOI 10.1007/978-3-030-58517-4_12
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Wang HY, 2010, LECT NOTES COMPUT SC, V6314, P497
   Weidong Zhang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P632, DOI 10.1007/978-3-030-58517-4_37
   Yang C., 2022, P IEEE CVF WINT C AP, P2534
   Zhang, 2015, LARGESCALE SCENE UND
   Zhang J, 2013, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2013.161
   Zhang WD, 2017, IEEE T MULTIMEDIA, V19, P935, DOI 10.1109/TMM.2016.2642780
   Zhao H, 2017, PROC CVPR IEEE, P870, DOI 10.1109/CVPR.2017.99
   Zhou YC, 2019, IEEE I CONF COMP VIS, P962, DOI 10.1109/ICCV.2019.00105
NR 31
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103963
DI 10.1016/j.jvcir.2023.103963
EA OCT 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y3AW5
UT WOS:001104037200001
DA 2024-07-18
ER

PT J
AU Luo, J
   He, PS
   Liu, JY
   Wang, HX
   Wu, CW
   Zhou, SL
AF Luo, Jie
   He, Peisong
   Liu, Jiayong
   Wang, Hongxia
   Wu, Chunwang
   Zhou, Shenglie
TI Reversible adversarial steganography for security enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Reversible adversarial attack; Universal stego
   post-processing; Deep learning-based stganalysis
ID IMAGE; STEGANALYSIS; FRAMEWORK
AB In adaptive steganography, existing universal stego post-processing methods can enhance security, but suffer from incorrect extraction of messages and undesired visual defects, especially in flat regions. To address this issue, a reversible adversarial steganography method is proposed by modifying the LSB or 2ndLSB of stego-images, which has promising visual quality and security. To that end, the content-adaptive adversarial perturbations are first generated, which consider image texture with noise residual features to counter deep learning-based steganalyzers. Then, a data compression strategy of adversarial perturbations is designed by applying lossless run-length encoding based on the sparse nature of non-zero elements in the perturbations to reduce the perturbation's quantity. Finally, reversible data hiding based on ternary coding is applied to embed and extract stego images with compressed adversarial perturbations. Extensive experimental results demonstrate that the proposed method can effectively enhance security and visual quality compared with state-of-the-art methods.
C1 [Luo, Jie; He, Peisong; Liu, Jiayong; Wang, Hongxia; Wu, Chunwang; Zhou, Shenglie] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610065, Peoples R China.
   [Wu, Chunwang] Chengdu Univ Informat Technol, Sch Cybersecur, Chengdu 610225, Peoples R China.
C3 Sichuan University; Chengdu University of Information Technology
RP He, PS (corresponding author), Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610065, Peoples R China.
EM gokeyhps@scu.edu.cn; ljy@scu.edu.cn
RI LIU, JIAYONG/JKJ-6473-2023; Wang, Hongxia/AAE-2135-2022
OI LIU, JIAYONG/0000-0002-1834-0877; He, Peisong/0000-0003-3121-0599
FU National Key Research and Development Program for Young Scientists
   [2022YFB4501300]
FX <B>Acknowledgments</B> This work is supported by National Key Research
   and Development Program for Young Scientists under Grant 2022YFB4501300.
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2007, Bows-2
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen BL, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102664
   Chen Y, 2022, IEEE T DEPEND SECURE, V19, P2405, DOI 10.1109/TDSC.2021.3058134
   Deng XQ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P230, DOI 10.1145/3335203.3335739
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow I.J., 2015, PROC 3 INT C LEARN R
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li WJ, 2023, IEEE T MULTIMEDIA, V25, P8320, DOI 10.1109/TMM.2023.3234812
   Liu JY, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109048
   Luo J, 2023, APPL INTELL, V53, P16059, DOI 10.1007/s10489-022-04321-6
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qin CA, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103325
   Tang WX, 2021, IEEE T INF FOREN SEC, V16, P952, DOI 10.1109/TIFS.2020.3025438
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yin ZX, 2023, PATTERN RECOGN LETT, V166, P1, DOI 10.1016/j.patrec.2022.12.018
   Yin Zhaoxia, 2021, INT WORKSH SAF SEC D
   Zha HY, 2019, IEEE IMAGE PROC, P2284, DOI [10.1109/icip.2019.8804415, 10.1109/ICIP.2019.8804415]
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zou Y, 2019, J VIS COMMUN IMAGE R, V60, P266, DOI 10.1016/j.jvcir.2019.02.034
NR 33
TC 1
Z9 1
U1 5
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103935
DI 10.1016/j.jvcir.2023.103935
EA SEP 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X0RQ8
UT WOS:001095614300001
DA 2024-07-18
ER

PT J
AU Trujillo-Pino, A
   Alemán-Flores, M
   Santana-Cedrés, D
   Monzón, N
AF Trujillo-Pino, Agustin
   Aleman-Flores, Miguel
   Santana-Cedres, Daniel
   Monzon, Nelson
TI Accurate subvoxel location and characterization of edges in 3D images
   based on the Partial Volume Effect
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D images; Edge detection; Subvoxelaccuracy; Partial volume effect;
   Feature extraction
ID SURFACE EXTRACTION; TOMOGRAPHY; DETECTOR
AB An accurate estimation of the position, orientation, principal curvatures, and change in intensity of the edges in a 3D image provides highly useful information for many applications. The use of derivative operators to compute the gradient vector and the Hessian matrix in each voxel usually generates inaccurate results. This paper presents a new edge detector which is derived from the Partial Volume Effect (PVE). Instead of assuming continuity in the image values, edge features are extracted from the distribution of intensities within a neighborhood of each edge voxel. First, the influence of the intensities of the voxels in first-and second-order edges is analyzed to demonstrate that these types of edges can be precisely characterized from the intensity distribution. Afterward, this approach is extended to especially demanding situations by considering how adverse conditions can be tackled. This extension includes filtering noisy images, characterizing edges in blurred regions, and using windows with floating limits for close edges. The proposed technique has been tested on synthetic and real images, including some particularly difficult objects, and achieving a highly accurate subvoxel characterization of the edges. An open source implementation of our method is provided.
C1 [Trujillo-Pino, Agustin; Aleman-Flores, Miguel; Santana-Cedres, Daniel; Monzon, Nelson] Univ Las Palmas De Gran Canaria ULPGC, Inst Univ Cibernet Empresa & Soc IUCES, Ctr Tecnol Imagen CTIM, Campus Univ Tafira, Las Palmas Gran Canaria 35017, Las Palmas, Spain.
C3 Universidad de Las Palmas de Gran Canaria
RP Trujillo-Pino, A (corresponding author), Univ Las Palmas De Gran Canaria ULPGC, Inst Univ Cibernet Empresa & Soc IUCES, Ctr Tecnol Imagen CTIM, Campus Univ Tafira, Las Palmas Gran Canaria 35017, Las Palmas, Spain.
EM agustin.trujillo@ulpgc.es
RI Santana-Cedrés, Daniel/J-5868-2019
OI Santana-Cedrés, Daniel/0000-0003-2032-5649; Monzon,
   Nelson/0000-0003-0571-9068
FU Vicepresidencia Primera, Consejeria de Vicepresidencia Primera y de
   Obras Publicas, Infraestructuras, Transporte y Movilidad from Cabildo de
   Gran Canaria [45/2021]
FX This work was partially supported by Vicepresidencia Primera, Consejeria
   de Vicepresidencia Primera y de Obras Publicas, Infraestructuras,
   Transporte y Movilidad from Cabildo de Gran Canaria, through the project
   of reference Resolution No. 45/2021.
CR Abràmoff MD, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0107763
   Martínez-Mera JA, 2015, COMPUT BIOL MED, V57, P74, DOI 10.1016/j.compbiomed.2014.11.018
   Bähnisch C, 2009, LECT NOTES COMPUT SC, V5748, P111, DOI 10.1007/978-3-642-03798-6_12
   Bhattacharya P, 1996, COMPUT BIOL MED, V26, P315, DOI 10.1016/0010-4825(96)00003-0
   Bouma H, 2005, IEEE T PATTERN ANAL, V27, P1501, DOI 10.1109/TPAMI.2005.174
   Brejl M, 2000, COMPUT VIS IMAGE UND, V77, P84, DOI 10.1006/cviu.1999.0811
   Busch M, 2022, PROD ENG-RES DEV, V16, P411, DOI 10.1007/s11740-021-01100-z
   Gonzalez Ballester MA, 2002, MED IMAGE ANAL, V6, P389, DOI 10.1016/S1361-8415(02)00061-0
   Hafiz Dina A., 2011, Journal of Computer Sciences, V7, P475, DOI 10.3844/jcssp.2011.475.487
   Hamitouche C., 1995, Computer Vision, Virtual Reality and Robotics in Medicine. First International Conference, CVRMed '95. Proceedings, P523, DOI 10.1007/BFb0034995
   Heng PA, 2001, PROC SPIE, V4322, P407, DOI 10.1117/12.431112
   Hirano Y., 2006, IEICE TECH REP, V105, P305
   Ibanez L, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P277, DOI 10.1109/ICIP.1996.560807
   Kim D, 2021, IEEE T VIS COMPUT GR, V27, P29, DOI 10.1109/TVCG.2020.3016327
   Lim J.-Y., 2002, HIGHER DIMENSIONAL M
   Liu T, 2019, INT CONF INFO SCI, P128, DOI [10.1109/icist.2019.8836866, 10.1109/ICIST.2019.8836866]
   LUO LM, 1993, IEEE T BIO-MED ENG, V40, P693, DOI 10.1109/10.237699
   Ma TC, 2012, STUD COMPUT INTELL, V413, P89
   Monga O., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P28, DOI 10.1109/CVPR.1989.37825
   Ontiveros S, 2013, PROCEDIA ENGINEER, V63, P710, DOI 10.1016/j.proeng.2013.08.263
   Ontiveros S, 2018, MATERIALS, V11, DOI 10.3390/ma11081461
   Qiusha Min, 2012, 2012 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES 2012), P717, DOI 10.1109/IECBES.2012.6498131
   Schug D.A., 2012, THESIS U MARYLAND CO
   Shah A., 2020, DIABETES RETINOPATHY, P69
   Shah A, 2019, MED IMAGE ANAL, V54, P63, DOI 10.1016/j.media.2019.02.004
   Soret M, 2007, J NUCL MED, V48, P932, DOI 10.2967/jnumed.106.035774
   Stopp J., 2020, SURFACE POINT DETERM
   Tahoces PG, 2019, INT J COMPUT ASS RAD, V14, P345, DOI 10.1007/s11548-018-1861-0
   Toriwaki Junichiro, 2009, Fundamentals of three-dimensional digital image processing
   Trujillo-Pino A, 2013, IMAGE VISION COMPUT, V31, P72, DOI 10.1016/j.imavis.2012.10.005
   van Hespen KM, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101818
   Vinhais C, 2018, SIG P ALGO ARCH ARR, P180, DOI 10.23919/SPA.2018.8563388
   Wang K., 2006, 2006 7 INT C COMP AI, P1
   Wang LS, 2007, IEEE T INF TECHNOL B, V11, P668, DOI 10.1109/TITB.2006.889675
   Wang LS, 2014, IEEE T VIS COMPUT GR, V20, P1490, DOI 10.1109/TVCG.2014.2312015
   Wang LS, 2001, INTERNATIONAL WORKSHOP ON MEDICAL IMAGING AND AUGMENTED REALITY, PROCEEDINGS, P286, DOI 10.1109/MIAR.2001.930305
   Wu XG, 1999, P SOC PHOTO-OPT INS, V3586, P319, DOI 10.1117/12.339907
   Yagüe-Fabra JA, 2013, CIRP ANN-MANUF TECHN, V62, P531, DOI 10.1016/j.cirp.2013.03.016
   Young D., 2023, CANNY EDGE DETECTION
   ZHAN SM, 1994, CVGIP-IMAG UNDERSTAN, V59, P242, DOI 10.1006/cviu.1994.1018
   ZUCKER SW, 1981, IEEE T PATTERN ANAL, V3, P324, DOI 10.1109/TPAMI.1981.4767105
NR 41
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103928
DI 10.1016/j.jvcir.2023.103928
EA AUG 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA S5IY7
UT WOS:001071514500001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Shi, L
   Zhao, K
   Fu, ZY
AF Shi, Lei
   Zhao, Kai
   Fu, Zhenyong
TI Boosting separated softmax with discrimination for class incremental
   learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Incremental learning; Discrimination enhancement; Discriminative
   separated softmax
AB Deep neural networks (DNNs) suffer from catastrophic forgetting when learning new classes continually and tend to classify old samples to new classes. Existing methods like exemplar-memory and knowledge distillation alleviate forgetting, but face prediction bias due to data imbalance. Separated softmax (Ahn et al., 2021) was proposed to solve this problem. However, they ignore the discrimination between old classes and new classes, which greatly limits the performance of DNNs. To enhance model's discrimination, we propose discriminative separated softmax. We divide new samples into two parts: one combined with old samples to build a balanced dataset of all seen classes, and the other combined with old samples as an imbalanced dataset. Furthermore, we apply mixup for these two datasets respectively to enhance discrimination. We evaluate our method on CIFAR100 and ImageNet100. Experimental results show that our method can effectively improve the discrimination and achieves superior performance compared with separated softmax, while outperforming state-of-the-art methods.
C1 [Shi, Lei; Zhao, Kai; Fu, Zhenyong] Nanjing Univ Sci & Technol, Sch comp sci & engn, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Fu, ZY (corresponding author), Nanjing Univ Sci & Technol, Sch comp sci & engn, Nanjing 210094, Peoples R China.
EM shilei31415@njust.edu.cn; zhaokai@njust.edu.cn; z.fu@njust.edu.cn
OI shi, lei/0009-0008-1722-5608
FU National Natural Science Founda-tion of China [62276132, 61876085];
   China Post-doctoral Science Foundation [2017M621748, 2019T120430]
FX This work was supported by the National Natural Science Founda-tion of
   China (Grant No. 62276132 and 61876085) and the China Post-doctoral
   Science Foundation (Grant No. 2017M621748 and 2019T120430) .
CR Ahn H., 2021, ICCV, P844
   Aljundi R, 2018, LECT NOTES COMPUT SC, V11207, P144, DOI 10.1007/978-3-030-01219-9_9
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bang J, 2021, PROC CVPR IEEE, P8214, DOI 10.1109/CVPR46437.2021.00812
   Belouadah E, 2019, IEEE I CONF COMP VIS, P583, DOI 10.1109/ICCV.2019.00067
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bowen Zhao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13205, DOI 10.1109/CVPR42600.2020.01322
   Castro FM, 2018, LECT NOTES COMPUT SC, V11216, P241, DOI 10.1007/978-3-030-01258-8_15
   Cha J., 2021, ICCV, P9516
   Chaudhry A, 2018, LECT NOTES COMPUT SC, V11215, P556, DOI 10.1007/978-3-030-01252-6_33
   Douillard Arthur, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P86, DOI 10.1007/978-3-030-58565-5_6
   Fang Z., 2021, CoRR, Vabs/2112.09339
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hou SH, 2019, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2019.00092
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lopez-Paz D, 2017, ADV NEUR IN, V30
   Mittal S, 2021, IEEE COMPUT SOC CONF, P3508, DOI 10.1109/CVPRW53098.2021.00390
   Prabhu Ameya, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P524, DOI 10.1007/978-3-030-58536-5_31
   Rebuffi SA, 2017, PROC CVPR IEEE, P5533, DOI 10.1109/CVPR.2017.587
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Slim H, 2022, P IEEECVF WINTER C A, P483
   Tang YM, 2022, PROC CVPR IEEE, P9539, DOI 10.1109/CVPR52688.2022.00933
   Wu Y, 2019, PROC CVPR IEEE, P374, DOI 10.1109/CVPR.2019.00046
   Xiang Y, 2019, IEEE I CONF COMP VIS, P6618, DOI 10.1109/ICCV.2019.00672
   Xiaoyu Tao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P254, DOI 10.1007/978-3-030-58529-7_16
   Yaoyao Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12242, DOI 10.1109/CVPR42600.2020.01226
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhao K., 2022, APPL INTELL, P1
   Zhu F, 2021, PROC CVPR IEEE, P5867, DOI 10.1109/CVPR46437.2021.00581
NR 33
TC 0
Z9 0
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103899
DI 10.1016/j.jvcir.2023.103899
EA JUL 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P4BD9
UT WOS:001050107200001
DA 2024-07-18
ER

PT J
AU Xie, F
   Lu, P
   Liu, XY
AF Xie, Feng
   Lu, Pei
   Liu, Xiaoyong
TI Multi-scale convolutional attention network for lightweight image
   super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image super-resolution; Convolutional neural network; Lightweight;
   Attention mechanism
AB Convolutional neural network (CNN) based methods have recently achieved extraordinary performance in single image super-resolution (SISR) tasks. However, most existing CNN-based approaches increase the model's depth by stacking massive kernel convolutions, bringing expensive computational costs and limiting their application in mobile devices with limited resources. Furthermore, large kernel convolutions are rarely used in lightweight super-resolution designs. To alleviate the above problems, we propose a multi-scale convolutional attention network (MCAN), a lightweight and efficient network for SISR. Specifically, a multi-scale convolutional attention (MCA) is designed to aggregate the spatial information of different large receptive fields. Since the contextual information of the image has a strong local correlation, we design a local feature enhancement unit (LFEU) to further enhance the local feature extraction. Extensive experimental results illustrate that our proposed MCAN can achieve better performance with lower model complexity compared with other state-of-the-art lightweight methods.
C1 [Lu, Pei] Guilin Univ Technol, Sch Informat Sci & Engn, Guilin 541004, Peoples R China.
   Guilin Univ Technol, Guangxi Key Lab Embedded Technol & Intelligent Sys, Guilin 541006, Peoples R China.
C3 Guilin University of Technology; Guilin University of Technology
RP Lu, P (corresponding author), Guilin Univ Technol, Sch Informat Sci & Engn, Guilin 541004, Peoples R China.
EM 2019175@glut.edu.cn
OI Xie, Feng/0009-0002-4235-992X; Lu, Pei/0000-0002-6284-5805
FU National Natural Science Foundation of China [62066011]; Natural Science
   Foundation of Guangxi Zhuang Autonomous Region [2022GXNSFAA035640,
   2023GXNSFAA026057]; National Key Research and Development Program of
   China [2020AAA0105802]; Research Startup Foundation of Guilin University
   of Technology [GUTQDJJ2019175, GUTQDJJ2019176, GUTQDJJ2019180]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 62066011 and the Natural Science Foundation of Guangxi
   Zhuang Autonomous Region under Grant 2022GXNSFAA035640, Grant
   2023GXNSFAA026057 and partly supported by the National Key Research and
   Development Program of China under Grant 2020AAA0105802 and the Ph.D.
   Research Startup Foundation of Guilin University of Technology under
   Grant GUTQDJJ2019175, Grant GUTQDJJ2019176, Grant GUTQDJJ2019180.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen LL, 2021, OPTIK, V239, DOI 10.1016/j.ijleo.2021.166818
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Feng H, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109376
   Fu Y, 2021, NEUROCOMPUTING, V427, P201, DOI 10.1016/j.neucom.2020.11.010
   Gao GW, 2022, AAAI CONF ARTIF INTE, P661
   Guo MH, 2022, Arxiv, DOI [arXiv:2209.08575, DOI 10.48550/ARXIV.2209.08575, 10.48550/arXiv.2209.08575]
   He ZB, 2020, IEEE IMAGE PROC, P518, DOI [10.1109/icip40778.2020.9190917, 10.1109/ICIP40778.2020.9190917]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang YW, 2017, PROC CVPR IEEE, P5787, DOI 10.1109/CVPR.2017.613
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kong FY, 2022, IEEE COMPUT SOC CONF, P765, DOI 10.1109/CVPRW56347.2022.00092
   Kong LH, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103659
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li W., 2020, ADV NEURAL INF PROCE, V33, P20343
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu FQ, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103730
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sun L., 2022, Adv. Neural Inf. Process. Syst., V35, P17314
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wang Z., 2021, P 2021 IEEE INT C MU, P1, DOI 10.1109/DTPI52967.2021.9540074
   Wang ZX, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3569900
   Wen RM, 2022, NEUROCOMPUTING, V504, P240, DOI 10.1016/j.neucom.2022.07.050
   Xiao H, 2022, MICROPROCESS MICROSY, V93, DOI 10.1016/j.micpro.2022.104568
   Zang YS, 2022, OPTIK, V255, DOI 10.1016/j.ijleo.2022.168648
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang DY, 2021, IEEE T GEOSCI REMOTE, V59, P5183, DOI 10.1109/TGRS.2020.3009918
   Zhang XD, 2022, LECT NOTES COMPUT SC, V13677, P649, DOI 10.1007/978-3-031-19790-1_39
   Zhang XD, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4034, DOI 10.1145/3474085.3475291
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao H, 2020, COMPUTER VISION ECCV, P56, DOI DOI 10.1007/978-3-030-67070-23
NR 44
TC 3
Z9 3
U1 13
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103889
DI 10.1016/j.jvcir.2023.103889
EA JUL 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O9GV4
UT WOS:001046839800001
DA 2024-07-18
ER

PT J
AU Chen, H
   Sun, JD
   Zhang, SX
   Yuan, H
   Zhang, HX
   Zhang, J
AF Chen, Hao
   Sun, Jiande
   Zhang, Shanxin
   Yuan, Hui
   Zhang, Huaxiang
   Zhang, Jia
TI 3D pedestrian localization fusing via monocular camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular camera; Pedestrian localization; Pseudo-LiDAR
AB In the field of intelligent transportation, autonomous driving technologies, especially visual sensing solutions have attracted increasing attention in recent years. There are still some challenges in pedestrian location based on the monocular camera, as the pedestrian is a non-rigid object and its depth information cannot be obtained from the monocular camera easily and accurately. In this paper, a pedestrian location framework based on monocular cameras is proposed. The framework consists of three parts: coarse positioning, auxiliary information generation and information fusion. In the part of coarse positioning, the human skeleton information is obtained from the monocular images and a light-weight feed-forward neural network is used to predict the pedestrian position based on the skeleton information. In the part of auxiliary information generation, pseudo-LiDAR points with pedestrian depth information are generated from the monocular images through an auxiliary network. Finally, the outputs of the above two parts are fused to achieve the pedestrian location. The experimental results on KITTI dataset show that our method has achieved better performance than other methods.
C1 [Chen, Hao; Sun, Jiande; Zhang, Shanxin; Zhang, Huaxiang; Zhang, Jia] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
   [Yuan, Hui] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
C3 Shandong Normal University; Shandong University
RP Sun, JD; Zhang, J (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250358, Peoples R China.
EM jiandesun@hotmail.com; zhangjia@sdnu.edu.cn
RI Yuan, Hui/HDO-3699-2022
OI Yuan, Hui/0000-0001-5212-3393
FU Natural Science Outstand-ing Youth Foundation of Shandong Province
   [JQ201718]; Taishan Scholar Project of Shandong, China; Joint Project
   for Smart Computing of Shandong Natural Science Foundation
   [ZR2020LZH015]; Major Fundamental Research Project of Shandong, China
   [ZR2019ZD03]
FX This work was supported in part by the Natural Science Outstand-ing
   Youth Foundation of Shandong Province (JQ201718) , in part by Taishan
   Scholar Project of Shandong, China (No. ts20190924) , Joint Project for
   Smart Computing of Shandong Natural Science Foundation (ZR2020LZH015) ,
   and in part by the Major Fundamental Research Project of Shandong, China
   (No. ZR2019ZD03) .
CR Beltran J., 2018, P 21 INT C INT TRANS, P4
   Bertoni L, 2019, IEEE I CONF COMP VIS, P6860, DOI 10.1109/ICCV.2019.00696
   Brazil G, 2020, Arxiv, DOI arXiv:2007.09548
   Cai YJ, 2020, AAAI CONF ARTIF INTE, V34, P10478
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chen H., 2021, 2021 IEEE INT S CIRC, P1
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Fidler S., 2012, NEURIPS, P611
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   J”rgensen E, 2019, Arxiv, DOI arXiv:1906.08070
   Kendall A., 2017, Advances in Neural Information Processing Systems, V30, P5574
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liu YX, 2021, IEEE ROBOT AUTOM LET, V6, P919, DOI 10.1109/LRA.2021.3052442
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Pan HJ, 2020, Arxiv, DOI arXiv:2006.12015
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qin ZY, 2019, AAAI CONF ARTIF INTE, P8851
   Roddick T, 2018, Arxiv, DOI arXiv:1811.08188
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Weng XS, 2019, IEEE INT CONF COMP V, P857, DOI 10.1109/ICCVW.2019.00114
   Wirges S., 2018 21 INT C INT TR
   Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhu M, 2020, Arxiv, DOI arXiv:2008.10436
NR 33
TC 0
Z9 0
U1 3
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103871
DI 10.1016/j.jvcir.2023.103871
EA JUN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L6VT2
UT WOS:001024625000001
DA 2024-07-18
ER

PT J
AU Phaphuangwittayakul, A
   Ying, FL
   Guo, Y
   Santisookrat, S
AF Phaphuangwittayakul, Aniwat
   Ying, Fangli
   Guo, Yi
   Santisookrat, Surachai
TI Adaptive adversarial prototyping network for few-shot prototypical
   translation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Prototyping network; Few-shot image translation; Meta-learning;
   Generative adversarial network
AB Translating multiple real-world source images to a single prototypical image is a challenging problem. Notably, these source images belong to unseen categories that did not exist during model training. We address this problem by proposing an adaptive adversarial prototype network (AAPN) and enhancing existing one-shot classification techniques. To overcome the limitations that traditional works cannot extract samples from novel categories, our method tends to solve the image translation task of unseen categories through a metalearner. We train the model in an adversarial learning manner and introduce a style encoder to guide the model with an initial target style. The encoded style latent code enhances the performance of the network with conditional target style images. The AAPN outperforms the state-of-the-art methods in one-shot classification of brand logo dataset and achieves the competitive accuracy in the traffic sign dataset. Additionally, our model improves the visual quality of the reconstructed prototypes in unseen categories. Based on the qualitative and quantitative analysis, the effectiveness of our model for few-shot classification and generation is demonstrated.
C1 [Phaphuangwittayakul, Aniwat; Guo, Yi] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.
   [Ying, Fangli] East China Univ Sci & Technol, Dept Comp Sci & Engn, State Key Lab Bioreactor Engn, Shanghai 200237, Peoples R China.
   [Guo, Yi] Natl Engn Lab Big Data Distribut & Exchange Techno, Business Intelligence & Visualizat Res Ctr, Shanghai 200436, Peoples R China.
   [Guo, Yi] Shanghai Engn Res Ctr Big Data & Internet Audience, Shanghai 200072, Peoples R China.
   [Santisookrat, Surachai] Chiang Mai Univ, Innovat Coll North, 169 Moo3, Chiang Mai 50230, Thailand.
   [Phaphuangwittayakul, Aniwat] Chiang Mai Univ, Int Coll Digital Innovat, Chiang Mai 50200, Thailand.
C3 East China University of Science & Technology; East China University of
   Science & Technology; Chiang Mai University; Chiang Mai University
RP Ying, FL (corresponding author), East China Univ Sci & Technol, Dept Comp Sci & Engn, State Key Lab Bioreactor Engn, Shanghai 200237, Peoples R China.
EM yfangli@ecust.edu.cn
OI Phaphuangwittayakul, Aniwat/0000-0002-2289-3116
FU National Key Research and Development Program of China [2018YFC0807105,
   2020YFA0907800]; Open Funding Project of the State Key Laboratory of
   Bioreactor Engineering, East China University of Science and Technology,
   Shanghai, China; Science and Technology Committee of Shanghai
   Municipality (STCSM) [17DZ1101003, 18511106602, 18DZ2252300];
   International College of Digital Innovation (ICDI), Chiang Mai
   University, Thailand
FX This research is financially supported by National Key Research and
   Development Program of China (No. 2020YFA0907800) ; Partially Supported
   by Open Funding Project of the State Key Laboratory of Bioreactor
   Engineering, East China University of Science and Technology, Shanghai,
   China; is also supported by The National Key Research and Development
   Program of China (grant number 2018YFC0807105) and Science and
   Technology Committee of Shanghai Municipality (STCSM) (under grant
   numbers 17DZ1101003, 18511106602 and 18DZ2252300) ; and International
   College of Digital Innovation (ICDI) , Chiang Mai University, Thailand.
CR Andrychowicz M., 2016, ARXIV
   [Anonymous], 2011, P ANN M COGN SCI SOC
   [Anonymous], 2009, P 17 ACM INT C MULTI, DOI DOI 10.1145/1631272.1631361
   Arcos-García A, 2018, NEURAL NETWORKS, V99, P158, DOI 10.1016/j.neunet.2018.01.005
   Finn C, 2017, PR MACH LEARN RES, V70
   Goodfellow I, 2017, Arxiv, DOI [arXiv:1701.00160, DOI 10.48550/ARXIV.1701.00160]
   Hensel M, 2017, ADV NEUR IN, V30
   Jetley Saumya, 2015, P BRIT MACH VIS C, P1, DOI DOI 10.5244/C.29.120
   Kim J, 2018, AAAI CONF ARTIF INTE, P6975
   Kim J, 2019, PROC CVPR IEEE, P9454, DOI 10.1109/CVPR.2019.00969
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma DP., 2014, ADAM METHOD STOCHAST
   Koch G., 2015, P ICML DEEP LEARN WO, V2
   Lian J., 2020, IEEE 30 INT WORKSHOP, P1
   Mishra N., 2018, INT C LEARNING REPRE
   Nichol A, 2018, ARXIV
   Phaphuangwittayakul A, 2022, IEEE T MULTIMEDIA, V24, P2205, DOI 10.1109/TMM.2021.3077729
   Romberg S., 2011, P 1 ACM INT C MULT R, P1
   Santoro A, 2016, PR MACH LEARN RES, V48
   Satorras V.G., 2018, P INT C LEARN REPR V
   Snell J, 2017, ADV NEUR IN, V30
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Su H, 2017, IEEE WINT CONF APPL, P530, DOI 10.1109/WACV.2017.65
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang YZ, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392456
   Wang JX, 2017, Arxiv, DOI arXiv:1611.05763
   Xiao C., 2021, P IEEECVF WINTER C A, P2252
   Xing C., 2019, Advances in Neural Information Processing Systems, P4847
   Zhang BQ, 2021, PROC CVPR IEEE, P3753, DOI 10.1109/CVPR46437.2021.00375
   Zhang XS, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2487, DOI 10.1145/3292500.3330779
   Zhou SC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107160
   Zhou T., 2022, arXiv
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 35
TC 0
Z9 0
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103845
DI 10.1016/j.jvcir.2023.103845
EA MAY 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I3OV7
UT WOS:001001915200001
DA 2024-07-18
ER

PT J
AU Huang, ZL
   Jing, HY
   Chen, AD
   Hong, C
   Shang, XN
AF Huang, Zilong
   Jing, Hongyuan
   Chen, Aidong
   Hong, Chen
   Shang, Xinna
TI Efficient image dehazing algorithm using multiple priors constraints
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Atmospheric scattering model; Atmospheric light
   estimation; Multiple prior constraints
AB In this study, a robust and efficient image dehazing technique based on the atmospheric scattering model is proposed, which effectively overcomes the limitations of a single prior condition. It is composed of a transmission estimation module and an atmospheric light estimation module. The transmission estimation module integrates multiple dehazing prior strategies and effectively optimises transmission estimation and application range. The atmospheric light estimation module uses the fuzzy C-means clustering algorithm (FCM) to estimate the atmospheric light of different scenes in an image. Unlike in the previous work, the atmospheric light in this module is a nonglobal value, and a pixel-level atmospheric light value matrix is obtained. Numerous experiments show that the proposed dehazing algorithm is superior to state-of-the-art methods.
C1 [Huang, Zilong; Jing, Hongyuan; Chen, Aidong; Hong, Chen; Shang, Xinna] Beijing Union Univ, Coll Robot, Beijing 100101, Peoples R China.
   [Jing, Hongyuan; Chen, Aidong; Shang, Xinna] Coll Robot, Beijing Key Lab Informat Serv Engn, Beijing 100101, Peoples R China.
   [Chen, Aidong; Hong, Chen; Shang, Xinna] Beijing Union Univ, Multiagent Syst Res Ctr, Beijing 100101, Peoples R China.
C3 Beijing Union University; Beijing Union University
RP Jing, HY (corresponding author), Beijing Union Univ, Coll Robot, Beijing 100101, Peoples R China.
EM jqrhongyuan@buu.edu.cn
RI Hong, Chen/HZH-3706-2023; Huang, Zilong/AAW-6071-2021
OI jing, hongyuan/0000-0002-5613-1216
CR Ancuti C.O., 2018, P IEEE C COMPUTER VI, P754
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Calkins H, 2017, J ARRYTHM, V33, P369, DOI 10.1016/j.joa.2017.08.001
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Feng X, 2021, IEEE T IMAGE PROCESS, V30, P4867, DOI 10.1109/TIP.2021.3076589
   Gao Y, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103868
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jing Hongyuan, 2022, SPIE, V12083, P194
   Ju MY, 2022, IEEE T CIRC SYST VID, V32, P4867, DOI 10.1109/TCSVT.2021.3101503
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   [鞠铭烨 Ju Mingye], 2016, [自动化学报, Acta Automatica Sinica], V42, P1367
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li CE, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157900
   Li ZG, 2021, IEEE T IMAGE PROCESS, V30, P9270, DOI 10.1109/TIP.2021.3123551
   Liu W, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.001
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Namer Einav, 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5888, P588805, DOI 10.1117/12.617464
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Ngo D, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142233
   ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417
   Park D, 2014, IEEE IMAGE PROC, P4037, DOI 10.1109/ICIP.2014.7025820
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Rong Z, 2014, OPTIK, V125, P3064, DOI 10.1016/j.ijleo.2013.12.077
   Salazar-Colores S, 2019, IEEE T IMAGE PROCESS, V28, P2357, DOI 10.1109/TIP.2018.2885490
   Sulami M, 2014, IEEE INT CONF COMPUT
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang QF, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103086
   Tang YC, 2022, STRUCTURES, V37, P426, DOI 10.1016/j.istruc.2021.12.055
   Wang WC, 2016, IEEE IMAGE PROC, P2241, DOI 10.1109/ICIP.2016.7532757
   Wu HY, 2020, IEEE COMPUT SOC CONF, P1975, DOI 10.1109/CVPRW50498.2020.00247
   Wu Ruobing, 2020, J IMAGE PROCESS THEO, V3, P1
   Yang M, 2021, ACS APPL MATER INTER, V13, P38647, DOI 10.1021/acsami.1c05751
   Yu HF, 2022, SIGNAL IMAGE VIDEO P, V16, P83, DOI 10.1007/s11760-021-01960-z
   Yuan H, 2017, IEEE ACCESS, V5, P1735, DOI 10.1109/ACCESS.2017.2660302
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zheng LR, 2021, Arxiv, DOI arXiv:2106.02809
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 45
TC 1
Z9 1
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103694
DI 10.1016/j.jvcir.2022.103694
EA NOV 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200007
DA 2024-07-18
ER

PT J
AU Zhu, Y
   Wang, C
   Geng, SZ
   Yu, Y
   Hao, XK
AF Zhu, Ye
   Wang, Chao
   Geng, Shuze
   Yu, Yang
   Hao, Xiaoke
TI Multi-scale gradient attention guidance and adaptive style fusion for
   image inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Style transfer; Gradient attention; Multi-scale
   gradient loss
ID OBJECT REMOVAL; DIFFUSION
AB Image inpainting aims to fill in the missing regions of damaged images with plausible content. Existing inpainting methods tend to produce ambiguous artifacts and implausible structures. To address the above issues, our method aims to fully utilize the information of known regions to provide style and structural guidance for missing regions. Specifically, the Adaptive Style Fusion (ASF) module reduces artifacts by transferring visual style features from known regions to missing regions. The Gradient Attention Guidance (GAG) module generates accurate structures by aggregating semantic information along gradient boundary regions. In addition, the Multi-scale Attentional Feature Extraction (MAFE) module extracts global contextual information and enhances the representation of image features. The sufficient experimental results on the three datasets demonstrate that our proposed method has superior performance in terms of visual plausibility and structural consistency compared to state-of-the-art inpainting methods.
C1 [Zhu, Ye; Wang, Chao; Yu, Yang; Hao, Xiaoke] Hebei Univ Technol, Tianjin 300401, Peoples R China.
   [Geng, Shuze] Tianjin Univ Technol & Educ, Tianjin 300222, Peoples R China.
C3 Hebei University of Technology; Tianjin University of Technology &
   Education
RP Hao, XK (corresponding author), Hebei Univ Technol, Tianjin 300401, Peoples R China.
EM haoxiaoke@hebut.edu.cn
OI geng, Shuze/0000-0003-4157-1128; Zhu, Ye/0000-0002-6004-9303
FU National Natural Science Founda-tion of China; Natu-ral Science
   Foundation of Hebei Province; Technol-ogy Project of Hebei Education
   Department;  [62102129];  [62276088];  [F2021202030];  [F2019202381]; 
   [F2019202464];  [QN2020185]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Grant 62102129 and Grant 62276088, the
   Natu-ral Science Foundation of Hebei Province under Grant F2021202030,
   Grant F2019202381 and Grant F2019202464, Science and the Technol-ogy
   Project of Hebei Education Department under Grant QN2020185.
CR Bai X, 2018, PATTERN RECOGN, V75, P136, DOI 10.1016/j.patcog.2017.03.020
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Helbert D, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102614
   Hensel M, 2017, ADV NEUR IN, V30
   Hongyu Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P725, DOI 10.1007/978-3-030-58536-5_43
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P3050, DOI 10.1109/TIFS.2017.2730822
   Li JY, 2019, IEEE I CONF COMP VIS, P5961, DOI 10.1109/ICCV.2019.00606
   Li KS, 2016, SOFT COMPUT, V20, P885, DOI 10.1007/s00500-014-1547-7
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Luo HY, 2022, INFORMATION, V13, DOI 10.3390/info13020071
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Shao H, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103231
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sridevi G, 2019, CIRC SYST SIGNAL PR, V38, P3802, DOI 10.1007/s00034-019-01029-w
   Sun QR, 2018, PROC CVPR IEEE, P5050, DOI 10.1109/CVPR.2018.00530
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu T, 2020, AAAI CONF ARTIF INTE, V34, P12733
   Zhang JF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1870, DOI 10.1145/3343031.3350912
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 42
TC 0
Z9 0
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103681
DI 10.1016/j.jvcir.2022.103681
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600005
DA 2024-07-18
ER

PT J
AU Yu, QQ
   Cao, G
   Shi, H
   Zhang, YQ
   Fu, P
AF Yu, Qiqiong
   Cao, Guo
   Shi, Hao
   Zhang, Youqiang
   Fu, Peng
TI EPLL image restoration with a bounded asymmetrical Student?s-t mixture
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE EPLL image restoration; Finite mixture model; Bounded
   asymmetricalStudent?s-t mixture; model; Anisotropic nonlocal
   self-similarity; Regularization parameters
ID PATCH LOG LIKELIHOOD; EM; SEGMENTATION; SPARSE
AB The expected patch log-likelihood (EPLL) model is a patch prior-based image restoration method which received extensive attention in image processing in recent years for its outstanding ability to preserve the detail and structure. However, due to using the Gaussian mixture model (GMM) with the noise sensitivity as the local prior, the EPLL model suffers from undesired artifact and poor robustness frequently. In this paper, to restrain the generation of artifact of EPLL model, we replace the GMM with a bounded asymmetrical Student's-t mixture model (BASMM), which is sufficiently flexible to fit different shapes of image data, such as non-Gaussian, non -symmetric, and bounded support data. Then, the anisotropic nonlocal self-similarity (ANSS) based regularization parameters are designed to improve the robustness of the proposed model. Experimental results demonstrate the competitiveness of our proposed model compared with that of state-of-the-art methods in performance both visually and quantitatively.
C1 [Yu, Qiqiong; Cao, Guo; Shi, Hao; Fu, Peng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Zhang, Youqiang] Nanjing Univ Posts & Telecommun, Jiangsu Key Lab Broadband Wireless Commun & Intern, Nanjing 210003, Peoples R China.
   [Zhang, Youqiang] Nanjing Univ Posts & Telecommun, Sch Internet Things, Nanjing 210003, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of Posts
   & Telecommunications; Nanjing University of Posts & Telecommunications
RP Cao, G (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
EM yu_qiqiong@163.com
RI Shi, Hao/JFS-5082-2023; Zhang, Youqiang/ISV-0771-2023
OI Zhang, Youqiang/0000-0002-4761-4726
FU Natural Science Foundation of Jiangsu Province [BK20191284]; National
   Natural Science Foundation of China [61801222]; National Key R & D
   Program of China
FX This work was supported in part by the Natural Science Foundation of
   Jiangsu Province under Grant BK20191284, in part by the National Natural
   Science Foundation of China under Grant 61801222, and in part by the
   National Key R & D Program of China.
CR Cha S, 2019, IEEE I CONF COMP VIS, P4159, DOI 10.1109/ICCV.2019.00426
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dhaka A., 2021, IEEE ACCESS, V9
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elguebaly T, 2011, SIGNAL PROCESS, V91, P801, DOI 10.1016/j.sigpro.2010.08.014
   Feng JZ, 2013, IEEE IMAGE PROC, P1056, DOI 10.1109/ICIP.2013.6738218
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo BY, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102851
   Hao WL, 2015, ELECTRON LETT, V51, P1740, DOI 10.1049/el.2015.2551
   He W, 2019, IEEE T CONTR SYST T, V27, P790, DOI 10.1109/TCST.2017.2780055
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Jia XX, 2021, INFORM SCIENCES, V572, P263, DOI 10.1016/j.ins.2021.05.001
   Jin Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102661
   Kuang XD, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2717948
   Li X., 2020, J VIS COMMUN IMAGE R, V71
   Li XX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102774
   Lin HB, 2018, IEEE IMAGE PROC, P1103, DOI 10.1109/ICIP.2018.8451773
   Lin TI, 2010, STAT COMPUT, V20, P343, DOI 10.1007/s11222-009-9128-9
   LIU CH, 1995, STAT SINICA, V5, P19
   Liu J, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P71, DOI 10.1109/SIPROCESS.2018.8600477
   Liu XW, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108247
   Luo EM, 2016, IEEE T IMAGE PROCESS, V25, P4489, DOI 10.1109/TIP.2016.2590318
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Ou Y, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102895
   Pang ZF, 2019, SIGNAL PROCESS-IMAGE, V74, P140, DOI 10.1016/j.image.2019.02.003
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Peng YL, 2019, NEUROCOMPUTING, V345, P67, DOI 10.1016/j.neucom.2018.12.075
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   Sfikas G, 2007, IEEE IMAGE PROC, P273
   Shandoosti HR, 2019, SIGNAL PROCESS, V159, P20, DOI 10.1016/j.sigpro.2019.01.017
   Sulam J, 2015, LECT NOTES COMPUT SC, V8932, P99, DOI 10.1007/978-3-319-14612-6_8
   Sun JX, 2004, INT C PATT RECOG, P596
   Tang YB, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P442, DOI 10.1109/ICDSP.2016.7868596
   Nguyen TM, 2014, IEEE T CYBERNETICS, V44, P857, DOI 10.1109/TCYB.2013.2273714
   Wang SF, 2018, J INF PROCESS SYST, V14, P552, DOI 10.3745/JIPS.02.0085
   Wang SF, 2018, LECT NOTES ELECTR EN, V474, P299, DOI 10.1007/978-981-10-7605-3_49
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Xu P., 2020, J INTERNET THINGS, V2, P13, DOI [10.32604/jiot.2020.09073, DOI 10.32604/JIOT.2020.09073]
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zha ZY, 2019, IEEE IMAGE PROC, P1119, DOI [10.1109/icip.2019.8804272, 10.1109/ICIP.2019.8804272]
   Zhang JW, 2017, LECT NOTES ELECTR EN, V421, P285, DOI 10.1007/978-981-10-3023-9_46
   Zhang JW, 2017, MULTIMED TOOLS APPL, V76, P11471, DOI 10.1007/s11042-016-4214-4
   Zhang JW, 2016, J INTERNET TECHNOL, V17, P1117, DOI 10.6138/JIT.2016.17.6.20160603
   Zhang J, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108165
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zheng YF, 2021, IEEE T DEPEND SECURE, V18, P1261, DOI 10.1109/TDSC.2019.2907081
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 53
TC 0
Z9 0
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103611
DI 10.1016/j.jvcir.2022.103611
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2FV
UT WOS:000859982300006
DA 2024-07-18
ER

PT J
AU Ren, FL
   Zhou, HB
   Yang, L
   Liu, FL
   He, X
AF Ren, Fenglei
   Zhou, Haibo
   Yang, Lu
   Liu, Fulong
   He, Xin
TI ADPNet: Attention based dual path network for lane detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lane detection; Semantic segmentation; Attention mechanism; Lane fitting
AB Recently, the task of lane detection has been greatly improved with the rapid development of deep learning and autonomous driving. However, there exist limitations like the challenging complex scenarios and real-time ef-ficiency. In this paper, we present a novel Attention Based Dual Path Network (ADPNet) to handle the task of lane detection. The ADPNet treat the process of lane detection as a task of binary semantic segmentation, where the Detail Path is designed to capture detailed low-level information and the Semantic Path with dual attention module is designed to capture contextual high-level information. We use the Feature Aggregation Module to fuse the information of the two paths, followed by the process of lane fitting to get a parametric description of lanes. The proposed ADPNet achieves good trade-off between the accuracy and real-time efficiency on TuSimple and CULane, which are two popular lane detection benchmark datasets. The results demonstrate that our architecture outperforms the current state-of-the-art methods.
C1 [Ren, Fenglei; Zhou, Haibo; Yang, Lu; Liu, Fulong] Tianjin Univ Technol, Sch Mech Engn, Tianjin Key Lab Adv Mechatron Syst Design & Intell, Tianjin 300384, Peoples R China.
   [Ren, Fenglei; Zhou, Haibo; Yang, Lu; Liu, Fulong] Tianjin Univ Technol, Natl Demonstrat Ctr Expt Mech & Elect Engn Educ, Tianjin 300384, Peoples R China.
   [He, Xin] Chinese Acad Sci, Changchun Inst Opt, Fine Mech & Phys, Changchun 130033, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology;
   Chinese Academy of Sciences; Changchun Institute of Optics, Fine
   Mechanics & Physics, CAS
RP Ren, FL (corresponding author), Tianjin Univ Technol, Sch Mech Engn, Tianjin Key Lab Adv Mechatron Syst Design & Intell, Tianjin 300384, Peoples R China.
EM renfenglei15@mails.ucas.edu.cn
RI He, Xin/JYQ-1624-2024; Zhao, Hang/KCL-7278-2024; Wang,
   Jinyang/JXN-8650-2024
FU National Nature Science Foundation of China [51275209]; key projects of
   Tianjin Nature Foundation [17JCZDJC30400]; Development Projects in Key
   Areas of Guangdong Province [2019B090922022]
FX This work is supported by the National Nature Science Foundation of
   China (51275209), and the key projects of Tianjin Nature Foundation
   (17JCZDJC30400), and the Development Projects in Key Areas of Guangdong
   Province (2019B090922022).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bai M, 2018, IEEE INT C INT ROBOT, P3102, DOI 10.1109/IROS.2018.8594388
   Berriel RF, 2017, IMAGE VISION COMPUT, V68, P64, DOI 10.1016/j.imavis.2017.07.005
   Borkar A, 2012, IEEE T INTELL TRANSP, V13, P365, DOI 10.1109/TITS.2011.2173196
   Borkar A, 2009, IEEE IMAGE PROC, P3261, DOI 10.1109/ICIP.2009.5413980
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen ZP, 2019, IEEE INT VEH SYM, P2563, DOI [10.1109/IVS.2019.8813778, 10.1109/ivs.2019.8813778]
   Chiu KY, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P706
   Deusch H, 2012, IEEE INT C INTELL TR, P270, DOI 10.1109/ITSC.2012.6338772
   Fastdraw P.J, 2019, PROC IEEE C COMPUT V, P11582
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Garnett N, 2019, IEEE I CONF COMP VIS, P2921, DOI 10.1109/ICCV.2019.00301
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2004, IEEE T INTELL TRANSP, V5, P309, DOI 10.1109/TITS.2004.838221
   Hong Y., 2021, ARXIV PREPRINT ARXIV
   Hou Y., 2020, C COMP VIS PATT REC, P12486
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hur J, 2013, IEEE INT VEH SYM, P1297, DOI 10.1109/IVS.2013.6629645
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jung H, 2013, IEEE INT VEH SYM, P976, DOI 10.1109/IVS.2013.6629593
   Kim J, 2017, IEEE COMPUT SOC CONF, P1194, DOI 10.1109/CVPRW.2017.158
   Lee C, 2018, IEEE T INTELL TRANSP, V19, P4043, DOI 10.1109/TITS.2018.2791572
   Li X, 2020, IEEE T INTELL TRANSP, V21, P248, DOI 10.1109/TITS.2019.2890870
   Liu RJ, 2021, IEEE WINT CONF APPL, P3693, DOI 10.1109/WACV48630.2021.00374
   Liu T, 2020, IEEE INT VEH SYM, P1394, DOI 10.1109/IV47402.2020.9304613
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Luo S, 2021, IEEE T INTELL TRANSP, V22, P7597, DOI 10.1109/TITS.2020.3005396
   Neven D, 2018, IEEE INT VEH SYM, P286
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Paszke A., 2016, ARXIV160602147
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tabelini L, 2021, PROC CVPR IEEE, P294, DOI 10.1109/CVPR46437.2021.00036
   Tabelini L, 2021, INT C PATT RECOG, P6150, DOI 10.1109/ICPR48806.2021.9412265
   Tang JG, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107623
   Van Gansbeke W, 2019, IEEE INT CONF COMP V, P905, DOI 10.1109/ICCVW.2019.00119
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Yang WJ, 2019, IEEE ACCESS, V7, P173148, DOI 10.1109/ACCESS.2019.2957053
   Yoo S, 2020, IEEE COMPUT SOC CONF, P4335, DOI 10.1109/CVPRW50498.2020.00511
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu Changqian, 2020, ARXIV200402147
   Yuan Y., 2018, ARXIV PREPRINT ARXIV
   Zequn Qin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P276, DOI 10.1007/978-3-030-58586-0_17
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zou Q, 2020, IEEE T VEH TECHNOL, V69, P41, DOI 10.1109/TVT.2019.2949603
NR 54
TC 1
Z9 2
U1 1
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103574
DI 10.1016/j.jvcir.2022.103574
EA JUN 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100003
DA 2024-07-18
ER

PT J
AU Fan, ZY
   Yi, SH
   Wu, D
   Song, Y
   Cui, MJ
   Liu, ZW
AF Fan, Zheyi
   Yi, Shuhan
   Wu, Di
   Song, Yu
   Cui, Mengjie
   Liu, Zhiwen
TI Video anomaly detection using CycleGan based on skeleton features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomaly detection; Cycle-consistent adversarial networks; Pose
   estimation; Dynamic skeleton feature; Reconstruction error
ID ABNORMAL EVENT DETECTION; LOCALIZATION
AB Anomaly detection is a challenging task in the field of intelligent video surveillance. It aims to identify anomalous events by monitoring the video captured by visual sensors. The main difficulty of this task is that the definition of anomalies is ambiguous. In recent years, most anomaly detection methods use a two-stage learning strategy, i.e., feature extraction and model building. In this paper, with the idea of refactoring, we propose an end-to-end anomaly detection framework using cyclic consistent adversarial networks (CycleGAN). Dynamic skeleton features are used as network constraints to alleviate the inaccuracy of feature extraction algorithms of a single generative adversarial network. In the training phase, only normal video frames and the corresponding skeleton features are used to train the generator and discriminator. In the testing phase, anomalous behaviors with high reconstruction errors can be filtered out by manually set thresholds. To the best of our knowledge, this is the first time CycleGAN has been used for video anomaly detection. Experimental results on challenging datasets show that our method can accurately detect anomalous behaviors in videos collected by video surveillance systems and is comparable to the current state-of-the-art methods.
C1 [Fan, Zheyi; Yi, Shuhan; Wu, Di; Song, Yu; Cui, Mengjie; Liu, Zhiwen] Beijing Inst Technol, Inst Signal & Image Proc, Sch Informat & Elect, 5 South Zhongguancun St, Beijing, Peoples R China.
C3 Beijing Institute of Technology
RP Fan, ZY (corresponding author), Beijing Inst Technol, Inst Signal & Image Proc, Sch Informat & Elect, 5 South Zhongguancun St, Beijing, Peoples R China.
EM funye@bit.edu.cn; yishuhan0701@163.com; wudi1123@foxmail.com;
   songyu_727@163.com; universeno1@126.com; zwliu@bit.edu.cn
RI wu, di/IYS-9217-2023
FU National Natural Science Founda-tion of Beijing [L192036]; National
   Natural Science Foundation of China [61701029];
   Industry-University-Research Innovation Foundation of the Science and
   Technol-ogy Development Center of the Ministry of Education [2018A02012]
FX Funding This work was supported by the National Natural Science
   Founda-tion of Beijing [grant numbers L192036] ; the National Natural
   Science Foundation of China [grant number 61701029] ; and the
   Industry-University-Research Innovation Foundation of the Science and
   Technol-ogy Development Center of the Ministry of Education [grant
   number 2018A02012] .
CR Ahmadi M, 2019, LECT NOTES COMPUT SC, V11843, P94, DOI 10.1007/978-3-030-32281-6_10
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Burgos-Artizzu XP, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.58
   Cai RC, 2021, AAAI CONF ARTIF INTE, V35, P938
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen XJ, 2015, PROC CVPR IEEE, P3945, DOI 10.1109/CVPR.2015.7299020
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kingma D. P., 2014, arXiv
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Pang G., 2020, SELF TRAINED DEEP OR
   Pourreza M, 2021, IEEE WINT CONF APPL, P2002, DOI 10.1109/WACV48630.2021.00205
   Rodrigues R., 2020, 2020 IEEE WINTER C A
   Rodrigues R, 2020, IEEE WINT CONF APPL, P2615, DOI [10.1109/WACV45572.2020.9093633, 10.1109/wacv45572.2020.9093633]
   Sabokrou M, 2021, IEEE T NEUR NET LEAR, V32, P675, DOI 10.1109/TNNLS.2020.2979049
   Sabokrou M, 2019, IEEE I CONF COMP VIS, P8009, DOI 10.1109/ICCV.2019.00810
   Sabokrou M, 2019, LECT NOTES COMPUT SC, V11366, P488, DOI 10.1007/978-3-030-20876-9_31
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Ulyanov Dmitry, 2016, arXiv
   Wang T, 2018, MULTIMED TOOLS APPL, V77, P17375, DOI 10.1007/s11042-017-5309-2
   Wang Ziming, 2020, 28 ACM INT C MULTIME
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xu D., 2015, arXiv preprint arXiv:1510.01553
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhang Y, 2016, PATTERN RECOGN, V59, P302, DOI 10.1016/j.patcog.2015.11.018
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 55
TC 5
Z9 5
U1 4
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103508
DI 10.1016/j.jvcir.2022.103508
EA APR 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600002
DA 2024-07-18
ER

PT J
AU Bhalla, K
   Koundal, D
   Sharma, B
   Hu, YC
   Zaguia, A
AF Bhalla, Kanika
   Koundal, Deepika
   Sharma, Bhisham
   Hu, Yu-Chen
   Zaguia, Atef
TI A fuzzy convolutional neural network for enhancing multi-focus image
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Fusion; Fuzzy sets; Multi-focus images
ID ENHANCEMENT; ENSEMBLE
AB The images captured by the cameras contain distortions, misclassified pixels, uncertainties and poor contrast. Therefore, the multi-focus image fusion (MFIF) integrates various input image features to produce a single fused image using all its objects in focus. However, it is computationally complex, which leads to inconsistency. Hence, the MFIF method is employed to generate the fused image by integrating the fuzzy sets (FS) and convolutional neural network (CNN) to detect focused and unfocused parts in both source images. It is also compared with other competing six MFIF methods like Neutrosophic set based stationary wavelet transform (NSWT), guided filters, CNN, ensemble CNN, image fusion-based CNN and deep regression pair learning (DRPL). Benchmark datasets validate the superiority of the proposed FCNN method in terms of four non-reference assessment measures having mutual information (1.1678), edge information (0.7281), structural similarity (0.9850) and human perception (0.8020) and two reference metrics such as Peak signal-to-noise ratio (57.23) and root mean square error (1.814).
C1 [Bhalla, Kanika] Natl Taipei Univ Technol, Dept Elect Engn & Comp Sci, Taipei 10608, Taiwan.
   [Koundal, Deepika] Univ Petr & Energy Studies, Sch Comp Sci, Dept Syst, Dehra Dun, India.
   [Sharma, Bhisham] Chitkara Univ, Chitkara Univ Sch Engn & Technol, Chandigarh, Himachal Prades, India.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
   [Zaguia, Atef] Taif Univ, Coll Comp & Informat Technol, Dept Comp Sci, PO BOX 11099, At Taif 21944, Saudi Arabia.
C3 National Taipei University of Technology; University of Petroleum &
   Energy Studies (UPES); Chitkara University, Punjab; Providence
   University - Taiwan; Taif University
RP Koundal, D (corresponding author), Univ Petr & Energy Studies, Sch Comp Sci, Dept Syst, Dehra Dun, India.
EM kanikabhalla1594@gmail.com; dkoundal@ddn.upes.ac.in;
   bhisham.sharma@chitkarauniversity.edu.in; ychu@pu.edu.tw;
   zaguia.atef@tu.edu.sa
RI bhalla, kanika/ITT-0604-2023; Sharma, Bhisham/AAB-7076-2020; Zaguia,
   Atef/ABF-2031-2021; Hu, Yu-Chen/AAT-5264-2020; Koundal,
   Deepika/I-9927-2019; bhalla, kanika/IQT-6265-2023
OI bhalla, kanika/0000-0001-8663-5813; Sharma, Bhisham/0000-0002-3400-3504;
   Zaguia, Atef/0000-0001-9519-3391; Hu, Yu-Chen/0000-0002-5055-3645;
   Koundal, Deepika/0000-0003-1688-8772; bhalla, kanika/0000-0001-8663-5813
FU Taif University, Taif, Saudi Arabia [TURSP-2020/114]
FX This work was supported by Taif University Researchers Supporting
   Project Number (TURSP-2020/114), Taif University, Taif, Saudi Arabia.
CR Aja-Fernández S, 2015, KNOWL-BASED SYST, V83, P1, DOI 10.1016/j.knosys.2015.02.029
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Bhalla Kanika, 2021, 2021 International Conference on System Science and Engineering (ICSSE), P328, DOI 10.1109/ICSSE52999.2021.9538470
   Bhalla K, 2022, CMC-COMPUT MATER CON, V70, P5503, DOI 10.32604/cmc.2022.021125
   Bhalla K, 2019, PROCEEDINGS OF THE 2019 6TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P535
   Bhat S, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107307
   Bhat S, 2021, ARTIF INTELL REV, V54, P5735, DOI 10.1007/s10462-021-09961-7
   Biswas B, 2019, INFORM SCIENCES, V500, P67, DOI 10.1016/j.ins.2019.05.069
   Dai LY, 2021, INFRARED PHYS TECHN, V114, DOI 10.1016/j.infrared.2020.103621
   Di Martino F, 2019, SOFT COMPUT, V23, P2113, DOI 10.1007/s00500-017-2929-4
   Du CB, 2019, OPTIK, V176, P567, DOI 10.1016/j.ijleo.2018.09.089
   Farid MS, 2019, INFORM FUSION, V45, P96, DOI 10.1016/j.inffus.2018.01.009
   Fu GP, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102760
   Gai D, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107681
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   Huang YP, 2021, INT J FUZZY SYST, V23, P1600, DOI 10.1007/s40815-021-01053-6
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaur Harpreet, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0758, DOI 10.1109/ICCSP.2019.8697967
   Kaur H., 2021, ARCH COMPUT METHOD E, V24, P1
   Kaur H., 2021, J ARTIF INTELL SYST, V3, P68, DOI [10.33969/AIS.2021.31005, DOI 10.33969/AIS.2021.31005]
   Koundal D, 2019, P ICRIC, P533
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai R, 2019, IEEE ACCESS, V7, P114385, DOI 10.1109/ACCESS.2019.2935006
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JX, 2021, IEEE T IMAGE PROCESS, V30, P3748, DOI 10.1109/TIP.2021.3065171
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   Nan LD, 2019, J VIS COMMUN IMAGE R, V62, P359, DOI 10.1016/j.jvcir.2019.06.009
   Ning Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P617, DOI 10.1007/978-3-030-58607-2_36
   Panigrahy C, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106141
   Peng H, 2021, COMPUT VIS IMAGE UND, V210, DOI 10.1016/j.cviu.2021.103228
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun S, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102704
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Wang C, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106253
   Wang YC, 2021, SIGNAL PROCESS-IMAGE, V96, DOI 10.1016/j.image.2021.116295
   Wu YC, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102878
   Xiaodong Cun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P747, DOI 10.1007/978-3-030-58601-0_44
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang K, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103124
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhao WD, 2021, IEEE T IMAGE PROCESS, V30, P5426, DOI 10.1109/TIP.2021.3084101
   Zhao WD, 2020, IEEE T IMAGE PROCESS, V29, P1356, DOI 10.1109/TIP.2019.2942505
   Zhao WD, 2020, IEEE T PATTERN ANAL, V42, P1884, DOI 10.1109/TPAMI.2019.2906588
   Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325
NR 49
TC 18
Z9 18
U1 6
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103485
DI 10.1016/j.jvcir.2022.103485
EA MAR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7SL
UT WOS:000779615900001
DA 2024-07-18
ER

PT J
AU Soreng, AV
   Kandar, S
AF Soreng, Aswini Vinay
   Kandar, Shyamalendu
TI Verifiable varying sized<i> (m,</i><i> n,</i><i> n)</i> multi-image
   secret sharing with combiner verification and cheater identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-image secret sharing; Varying sized; Verifiable multi image secret
   sharing; Dealer authentication; Cheater identification; Combiner
   verification
ID SCHEME; SECURE; EFFICIENT
AB In conventional multi-image secret sharing schemes (MISSS) images are shared by the trusted dealer and the shares are sent to the set of participants through a secure channel. During reconstruction, the participants submit shares to a trusted combiner. But the method will collapse if any of the actors perform cheating. This brings verifiable image secret sharing in the research arena. Verifying the trustworthiness of the dealer by the shareholders before accepting shares (dealer verification), examining the genuineness of the shares submission request received from a combiner (combiner verification), checking the authenticity of the shares received from participants by the combiner (cheating detection/ cheater identification) are techniques related to verifiable secret sharing. Medical images, images used at the military or diplomatic level; contain sensible information. Thus the authenticity of the reconstructed images should be checked beforehand. In the case of multi-image secret sharing, the researchers use bit padding if the plaintext images are of different sizes. This adds an extra level of burden during sharing and retrieval.A verifiable varying size (m, n, n) multi-image secret sharing is addressed in this article. Here m (where m < n) varying sized images are shared among n participants and during reconstruction all the shares are required. The major contribution of the addressed technique is that it has the capability of dealer authentication, combiner verification, and cheater identification. Another advancement is that most of the communication can be made through a public channel. The test results generate noise like images and statistical analysis, security analysis say in favor of the claims. Comparison with some state-of-the-art techniques gives it a stable platform in verifiable multi-image secret sharing.
C1 [Soreng, Aswini Vinay; Kandar, Shyamalendu] Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, Howrah, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Kandar, S (corresponding author), Indian Inst Engn Sci & Technol, Dept Informat Technol, Sibpur 711103, Howrah, India.
EM aswini.soreng@yahoo.com; shyamalenduk@it.iiests.ac.in
CR Abbas SQ, 2021, MULTIMED TOOLS APPL, V80, P9849, DOI 10.1007/s11042-020-10135-w
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Bai L, 2006, DASC 2006: 2ND IEEE INTERNATIONAL SYMPOSIUM ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P31
   Bhattacharjee T, 2012, PROC TECH, V4, P619, DOI 10.1016/j.protcy.2012.05.099
   Biswas P, 2020, MULTIMED TOOLS APPL, V79, P31715, DOI 10.1007/s11042-020-09497-y
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Chang CC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20133802
   Chattopadhyay AK, 2021, MULTIMED TOOLS APPL, V80, P35051, DOI 10.1007/s11042-020-09174-0
   Chen CC, 2017, J INF SECUR APPL, V33, P45, DOI 10.1016/j.jisa.2017.01.006
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen TH, 2020, MULTIMED TOOLS APPL, V79, P13247, DOI 10.1007/s11042-019-08524-x
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Deshmukh M, 2019, KNOWL INF SYST, V60, P1377, DOI 10.1007/s10115-018-1268-9
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Dong L, 2012, SCI CHINA INFORM SCI, V55, P1151, DOI 10.1007/s11432-011-4302-z
   Drmic A, 2017, 2017 40TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P995, DOI 10.23919/MIPRO.2017.7973569
   Feldman P., 1987, 28th Annual Symposium on Foundations of Computer Science (Cat. No.87CH2471-1), P427, DOI 10.1109/SFCS.1987.4
   Gao H, 2018, INT J DIGIT CRIME FO, V10, P24, DOI 10.4018/IJDCF.2018010103
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Hamid H, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106648
   He Y, 2020, J AMB INTEL HUM COMP, V11, P5103, DOI 10.1007/s12652-020-01814-5
   Hsu CF, 2020, MOB INF SYST, V2020, DOI 10.1155/2020/1039898
   Hu CQ, 2012, THEOR COMPUT SCI, V445, P52, DOI 10.1016/j.tcs.2012.05.006
   Imai J, 2018, 2018 SIXTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING WORKSHOPS (CANDARW 2018), P405, DOI 10.1109/CANDARW.2018.00081
   Kabirirad S, 2019, J INF SECUR APPL, V47, P16, DOI 10.1016/j.jisa.2019.03.018
   Kabirirad S, 2018, J VIS COMMUN IMAGE R, V57, P39, DOI 10.1016/j.jvcir.2018.10.014
   Kandar S, 2020, J INF SECUR APPL, V51, DOI 10.1016/j.jisa.2019.102430
   Kandar S, 2019, J INF SECUR APPL, V44, P117, DOI 10.1016/j.jisa.2018.12.003
   Li K, 2017, IEEE T PATTERN ANAL, V39, P1825, DOI 10.1109/TPAMI.2016.2610969
   Liu JJ, 2021, MATH BIOSCI ENG, V18, P2473, DOI 10.3934/mbe.2021126
   Liu YX, 2018, INFORM SCIENCES, V453, P21, DOI 10.1016/j.ins.2018.04.043
   [柳毅 Liu Yi], 2010, [计算机科学, Computer Science], V37, P80
   Ma Z, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00529-z
   Meghrajani YK, 2019, J INF SECUR APPL, V47, P267, DOI 10.1016/j.jisa.2019.05.010
   MIGNOTTE M, 1983, LECT NOTES COMPUT SC, V149, P371
   Mishra K, 2020, MULTIMED TOOLS APPL, V79, P33233, DOI 10.1007/s11042-020-09619-6
   Nag A, 2020, MULTIMED TOOLS APPL, V79, P16219, DOI 10.1007/s11042-019-07807-7
   Patil S, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P225, DOI 10.1109/CSCITA.2014.6839263
   Patil SD, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1238, DOI 10.1109/ICICCT.2018.8473200
   PEDERSEN TP, 1992, LECT NOTES COMPUT SC, V576, P129
   Qin S., 2021, SECUR COMMUN NETW, P1
   Rajabi Bahman., 2019, INFORM SCIENTIST, P655
   Rao J., 2016, COMM AUT ICCCA INT C, P1
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rose AA, 2015, PROCEDIA COMPUT SCI, V58, P140, DOI 10.1016/j.procs.2015.08.042
   Roy Rituraj, 2015, COMMUNICATIONS INFOR
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shao J, 2014, INFORM SCIENCES, V278, P104, DOI 10.1016/j.ins.2014.03.025
   Shivani S., 2020, J REAL-TIME IMAGE PR, P1
   SIMMONS GJ, 1990, LECT NOTES COMPUT SC, V403, P390
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Tompa M., 1988, Journal of Cryptology, V1, P133
   Verma OP, 2020, ARAB J SCI ENG, V45, P2395, DOI 10.1007/s13369-019-03992-7
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wang XJ, 2016, PROC CVPR IEEE, P2018, DOI 10.1109/CVPR.2016.222
   Yadav GS, 2014, ADV INTELL SYST, V248, P765, DOI 10.1007/978-3-319-03107-1_84
   Yan XH, 2021, IEEE T CIRC SYST VID, V31, P2896, DOI 10.1109/TCSVT.2020.3025527
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Zhang J, 2015, FUTURE GENER COMP SY, V52, P109, DOI 10.1016/j.future.2014.11.013
   Zhang T, 2015, PROC CVPR IEEE, P4548, DOI 10.1109/CVPR.2015.7299085
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
NR 64
TC 3
Z9 3
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103466
DI 10.1016/j.jvcir.2022.103466
EA FEB 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7YP
UT WOS:000779631900005
DA 2024-07-18
ER

PT J
AU Rezaei, A
   Le Hégarat-Mascle, S
   Aldea, E
   Dondi, P
   Malagodi, M
AF Rezaei, Alireza
   Le Hegarat-Mascle, Sylvie
   Aldea, Emanuel
   Dondi, Piercarlo
   Malagodi, Marco
TI A-contrario framework for detection of alterations in varnished surfaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE A-contrario framework; Defect detection; Preventive conservation;
   Historical violins
ID LINE SEGMENT DETECTOR; PREVENTIVE CONSERVATION; CLUSTERING-ALGORITHM;
   ROBUST; IMAGES; IDENTIFICATION; INSTRUMENTS; PRINCIPLE; FUZZY
AB Preventive conservation is the constant monitoring of the state of conservation of an artwork to reduce the risk of damages and so to minimize the necessity of restorations. Many methods have been proposed during time, generally including a mix of different analytical techniques. In this work, we present a probabilistic approach based on the a-contrario framework for the detection of alterations on varnished surfaces, in particular those of historical musical instruments. Our method is a one step Number of False Alarms (NFA) clustering solution which considers simultaneously gray-level and spatial density information in a single background model. The proposed approach is robust to noise and avoids parameter tuning as well as any assumption about the shape and size of the worn-out areas. Tests have been conducted on UV induced fluorescence (UVIFL) image sequences included in the "Violins UVIFL imagery"dataset. UVIFL photography is a well known diagnostic technique used to see details of a surface not perceivable with visible light. The obtained results prove the capability of the algorithm to properly detect the altered regions. Comparisons with other the state-of-the-art clustering methods show improvement in both precision and recall.
C1 [Rezaei, Alireza; Le Hegarat-Mascle, Sylvie; Aldea, Emanuel] Univ Paris Saclay, SATIE Lab, Rue Noetzlin, F-91190 Gif Sur Yvette, France.
   [Dondi, Piercarlo] Univ Pavia, Dept Elect Comp & Biomed Engn, Via Ferrata 5, I-27100 Pavia, Italy.
   [Malagodi, Marco] Univ Pavia, Dept Musicol & Cultural Heritage, Corso Garibaldi 178, I-26100 Cremona, Italy.
   [Dondi, Piercarlo; Malagodi, Marco] Univ Pavia, CISRiC Arvedi Lab Noninvas Diagnost, Via BellAspa 3, I-26100 Cremona, Italy.
C3 Universite Paris Cite; Universite Paris Saclay; University of Pavia;
   University of Pavia; University of Pavia
RP Rezaei, A (corresponding author), Univ Paris Saclay, SATIE Lab, Rue Noetzlin, F-91190 Gif Sur Yvette, France.
EM alireza.rezaei@universite-paris-saclay.fr
RI sylvie, le hégarat-mascle/AAB-9960-2022
OI sylvie, le hégarat-mascle/0000-0001-8494-2289; Dondi,
   Piercarlo/0000-0002-0624-073X; Rezaei, Alireza/0000-0001-5067-2030
FU French-Italian Galileo PHC partnership [44391VL/G20-160]
FX Acknowledgments The authors gratefully acknowledge support from the
   French-Italian Galileo PHC partnership (project 44391VL/G20-160, MUSical
   Instru-ment Conservation with Optical Monitoring (MUSICOM) ) .
CR Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Aldea E, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.061119
   Arthur D., 2006, ADVANTAGES CAREFUL S
   Bradley S, 2005, J AM INST CONSERV, V44, P159, DOI 10.1179/019713605806082248
   Campello RJGB, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2733381
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576
   Desolneux A, 2000, INT J COMPUT VISION, V40, P7, DOI 10.1023/A:1026593302236
   Desolneux A., 2007, GESTALT THEORY IMAGE, V34
   Dibos F, 2009, SIAM J IMAGING SCI, V2, P1, DOI 10.1137/070710500
   Dondi Piercarlo, 2019, New Trends in Image Analysis and Processing - ICIAP 2019. ICIAP International Workshops BioFor, PatReCH, e-BADLE, DeepRetail, and Industrial Session. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11808), P81, DOI 10.1007/978-3-030-30754-7_9
   Dondi P, 2018, MULTIMED TOOLS APPL, V77, P28309, DOI 10.1007/s11042-018-6046-x
   Dondi P, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3051472
   Dondi P, 2016, J CULT HERIT, V22, P968, DOI 10.1016/j.culher.2016.05.010
   Dondi P, 2015, LECT NOTES COMPUT SC, V9281, P103, DOI 10.1007/978-3-319-23222-5_13
   Fichera GV, 2018, STUD CONSERV, V63, P351, DOI 10.1080/00393630.2018.1499853
   Flenner A, 2011, SIAM J IMAGING SCI, V4, P243, DOI 10.1137/090772344
   Grosjean B, 2009, J MATH IMAGING VIS, V33, P313, DOI 10.1007/s10851-008-0111-4
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Hu CF, 2020, IEEE T IND ELECTRON, V67, P10922, DOI 10.1109/TIE.2019.2962437
   Invernizzi C, 2018, MICROCHEM J, V138, P273, DOI 10.1016/j.microc.2018.01.021
   Janssens K., 2004, Non-destructive Micro Analysis of Cultural Heritage Materials", VXLII
   Khelifi L, 2020, IEEE ACCESS, V8, P126385, DOI 10.1109/ACCESS.2020.3008036
   Kim WJ, 2005, ETRI J, V27, P814, DOI 10.4218/etrij.05.0205.0013
   Le Hégarat-Mascle S, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0429-4
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li MD, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0255-1
   Lisani JL, 2003, IEEE IMAGE PROC, P941
   Liu G, 2019, IEEE T GEOSCI REMOTE, V57, P3904, DOI 10.1109/TGRS.2018.2888985
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucchi E, 2018, J CULT HERIT, V29, P180, DOI 10.1016/j.culher.2017.09.003
   Luo MR, 2001, COLOR RES APPL, V26, P340, DOI 10.1002/col.1049
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mandal M, 2022, IEEE T INTELL TRANSP, V23, P6101, DOI [10.1109/TITS.2021.3077883, 10.3233/IP-200233]
   Martorell O, 2021, IEEE ACCESS, V9, P25554, DOI 10.1109/ACCESS.2021.3056795
   McLachlan G. J., 1988, MIXTURE MODELS INFER, V38
   Michaelsen E, 2016, PATTERN RECOGN LETT, V83, P169, DOI 10.1016/j.patrec.2016.06.004
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20
   Mullner Daniel, 2011, ARXIV11092378, DOI DOI 10.1109/LSP.2012.2188026
   Myaskouvskey A, 2013, INT J COMPUT VISION, V101, P22, DOI 10.1007/s11263-012-0543-6
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Palma G, 2014, PATTERN RECOGN, V47, P2467, DOI 10.1016/j.patcog.2014.01.009
   Patraucean V, 2017, IEEE T PATTERN ANAL, V39, P788, DOI 10.1109/TPAMI.2016.2558150
   Rezaee MJ, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106672
   Rezaei A, 2021, INT C PATT RECOG, P9348, DOI 10.1109/ICPR48806.2021.9412129
   Rezaei A, 2019, PROC SPIE, V11172, DOI 10.1117/12.2521702
   Robin A, 2010, IEEE T PATTERN ANAL, V32, P1977, DOI 10.1109/TPAMI.2010.37
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Rousseau F, 2007, P ANN INT IEEE EMBS, P2069, DOI 10.1109/IEMBS.2007.4352728
   Rovetta T, 2019, J ARCHAEOL SCI-REP, V23, P443, DOI 10.1016/j.jasrep.2018.11.010
   Rovetta T, 2018, X-RAY SPECTROM, V47, P159, DOI 10.1002/xrs.2825
   Soille P., 2013, MORPHOLOGICAL IMAGE
   Sturari M, 2017, 2017 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR)
   Thoury M, 2007, APPL SPECTROSC, V61, P1275, DOI 10.1366/000370207783292064
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Varghese A, 2019, LECT NOTES COMPUT SC, V11130, P129, DOI 10.1007/978-3-030-11012-3_10
   Veit T, 2006, INT J COMPUT VISION, V68, P163, DOI 10.1007/s11263-006-6661-2
   Veit T, 2007, IEEE INT CONF ROBOT, P33, DOI 10.1109/ROBOT.2007.363761
   Verma S, 2021, IEEE COMPUT SOC CONF, P1052, DOI 10.1109/CVPRW53098.2021.00116
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang ZQ, 2018, IEEE T CYBERNETICS, V48, P1383, DOI 10.1109/TCYB.2017.2695218
   Widynski N., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P421, DOI 10.1109/ICSIPA.2011.6144087
   Yan YJ, 2018, PATTERN RECOGN, V79, P65, DOI 10.1016/j.patcog.2018.02.004
   Zair S, 2016, IEEE T INTELL TRANSP, V17, P1354, DOI 10.1109/TITS.2015.2502279
   Zhu XT, 2014, PROC CVPR IEEE, P1450, DOI 10.1109/CVPR.2014.188
NR 67
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103357
DI 10.1016/j.jvcir.2021.103357
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800008
DA 2024-07-18
ER

PT J
AU Hadjadji, B
   Saumard, M
   Aron, M
AF Hadjadji, Bilal
   Saumard, Matthieu
   Aron, Michael
TI Multi-oriented run length based static and dynamic features fused with
   Choquet fuzzy integral for human fall detection in videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-oriented run length; Static and dynamic features; Choquet fuzzy
   integral; Tree architecture; Human fall detection
ID NEURAL-NETWORKS; SIMULATED DATA; IDENTIFICATION; SURVEILLANCE;
   AGGREGATION; RECOGNITION; CLASSIFIERS; SELECTION; DESIGN; SYSTEM
AB Since a huge part of elderly people are living alone, assisted-living tools have become an essential in-home telemonitoring device. Hence, this paper proposes an automatic human fall detection in videos. In order to improve the system reliability, a new shape descriptor called multi-oriented run length (MORL) is proposed. This descriptor is exploited in a proposed scheme to generate static and dynamic features to represent human falls with complementary information. The generated static and dynamic features are fused through the Choquet fuzzy integral. Experimental results conducted on three well-known datasets containing almost 1300 video segments show an interesting adaptation of the proposed approaches. More precisely, the proposed MORL descriptor shows its superiority against known descriptors such as LBP and HOG. Moreover, Choquet fuzzy integral significantly improves the results versus standard combiners. In general, the obtained results highlight the reliability of the proposed system versus recent studies for human fall detection.
C1 [Hadjadji, Bilal; Saumard, Matthieu; Aron, Michael] ISEN Yncrea Ouest, Vis AD Team, L BISEN, 2 Rue Robert Arbrissel, F-35065 Rennes, France.
RP Hadjadji, B (corresponding author), ISEN Yncrea Ouest, Vis AD Team, L BISEN, 2 Rue Robert Arbrissel, F-35065 Rennes, France.
EM bilal.hadjadji@isen-ouest.yncrea.fr;
   matthieu.saumard@isen-ouest.yncrea.fr; michael.aron@isen-ouest.yncrea.fr
RI Saumard, Matthieu/AAG-8798-2019
OI Saumard, Matthieu/0000-0001-7615-707X
FU Region ofBretagne [970]
FX This research has been done with the support of the " Region ofBretagne
   " project SAD No. 970" welcoming international researchers who perusing
   a post doctorate degree.
CR Anderson Derek, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6388
   Arivazhagan S, 2019, COGN SYST RES, V58, P94, DOI [10.1016/j.cogsys.2019.05.002, 10.1016/j.cogsys.2019.15.002]
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Baldewijns G, 2016, HEALTHC TECHNOL LETT, V3, P6, DOI 10.1049/htl.2015.0047
   Ban T, 2006, IEEE IJCNN, P327
   Boehm O, 2011, INT J MACH LEARN CYB, V2, P125, DOI 10.1007/s13042-011-0030-3
   Bouamra W, 2018, EXPERT SYST APPL, V107, P182, DOI 10.1016/j.eswa.2018.04.035
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Bowman KO., 1998, Encyclopedia of Statistical Sciences, P2092
   Boyu Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P1078, DOI 10.1109/CVPR42600.2020.00116
   Chacon Mario I. M., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P474, DOI 10.1109/IJCNN.2009.5178632
   Charfi I, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041106
   Chen YT, 2021, APPL INTELL, V51, P3460, DOI 10.1007/s10489-020-01971-2
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   CHO SB, 1995, IEEE T SYST MAN CYB, V25, P380, DOI 10.1109/21.364825
   CHO SB, 1995, INT J APPROX REASON, V13, P359, DOI 10.1016/0888-613X(95)00059-P
   Chua JL, 2015, SIGNAL IMAGE VIDEO P, V9, P623, DOI 10.1007/s11760-013-0493-7
   Cyganek B, 2012, J MATH IMAGING VIS, V42, P103, DOI 10.1007/s10851-011-0304-0
   Debard Glen, 2012, Outdoor and Large-Scale Real-World Scene Analysis. 15th International Workshop on Theoretical Foundations of Computer Vision. Revised Selected Papers, P356, DOI 10.1007/978-3-642-34091-8_16
   Debard G, 2016, J AMB INTEL SMART EN, V8, P149, DOI 10.3233/AIS-160369
   Dimuro GP, 2020, INFORM FUSION, V57, P27, DOI 10.1016/j.inffus.2019.10.005
   Echi AK, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P85, DOI 10.1109/ASAR.2017.8067765
   Fan KB, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717707418
   Fan YX, 2017, NEUROCOMPUTING, V260, P43, DOI 10.1016/j.neucom.2017.02.082
   Feng Q, 2017, I S INTELL SIG PROC, P341, DOI 10.1109/ISPACS.2017.8266500
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Foroughi Homa, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1499, DOI 10.1109/ICOSP.2008.4697417
   Foroughi H, 2008, 2008 11TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY: ICCIT 2008, VOLS 1 AND 2, P540
   Goh KS, 2005, IEEE T KNOWL DATA EN, V17, P1333, DOI 10.1109/TKDE.2005.170
   Hadjadji B, 2019, PATTERN ANAL APPL, V22, P99, DOI 10.1007/s10044-018-0735-y
   Hadjadji B, 2018, PATTERN RECOGN, V82, P147, DOI 10.1016/j.patcog.2018.05.001
   Hadjadji B, 2017, NEUROCOMPUTING, V265, P66, DOI 10.1016/j.neucom.2017.01.108
   Hung D.H., 2012, Proc. of 18th Japan-Korea Joint Workshop on Frontier in Computer Vision, P33
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jansen B., 2006, PERVASIVE HLTH C WOR, P1, DOI DOI 10.1109/PCTHEALTH.2006.361657
   Jolliffe IT, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0202
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Kong YQ, 2019, J VIS COMMUN IMAGE R, V59, P215, DOI 10.1016/j.jvcir.2019.01.024
   Kuncheva Ludmila I., 2004, COMBINING PATTERN CL
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Li HJ, 2021, MULTIMED TOOLS APPL, V80, P1883, DOI 10.1007/s11042-020-09708-6
   Liao YT, 2012, PATTERN RECOGN, V45, P24, DOI 10.1016/j.patcog.2011.04.017
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Maldonado C, 2016, INT CONF ELECTR COMM, P94, DOI 10.1109/CONIELECOMP.2016.7438558
   Miaou SG, 2006, 1ST TRANSDISCIPLINARY CONFERENCE ON DISTRIBUTED DIAGNOSIS AND HOME HEALTHCARE, CONFERENCE PROCEEDINGS, P39, DOI 10.1109/DDHH.2006.1624792
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Nadi M, 2014, 2014 14TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P23, DOI 10.1109/HIS.2014.7086169
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qian HM, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1567, DOI 10.1109/ICARCV.2008.4795758
   Rabaoui A, 2008, IEEE T INF FOREN SEC, V3, P763, DOI 10.1109/TIFS.2008.2008216
   Rougier C, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P875, DOI 10.1109/ainaw.2007.181
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Ryoo M.S., 2019, ARXIV PREPRINT ARXIV
   Sarabia-Jácome D, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100185
   Sehairi K., 2018, 2018 International Conference on Intelligent Systems and Computer Vision, P1, DOI 10.1109/ISACV.2018.8354084
   Sharma S, 2016, Chemical process retrofitting and revamping: techniques and Applications
   Shyu ML, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P353
   Simonyan K, 2014, ADV NEUR IN, V27
   Su SZ, 2016, MULTIMED TOOLS APPL, V75, P8469, DOI 10.1007/s11042-015-2766-3
   Sultana A, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030328
   Tax D.M.J., 2001, THESIS DELFT U TECHN
   Tran TH, 2017, COMPUT METH PROG BIO, V146, P151, DOI 10.1016/j.cmpb.2017.05.007
   Toreyin B., 2005, 2005 13 EUROPEAN SIG, P1
   Wang K, 2016, IEEE INT C BIOINFORM, P1228, DOI 10.1109/BIBM.2016.7822694
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Yang DL, 2015, MED PHYS, V42, P6725, DOI 10.1118/1.4934373
   Yeh CY, 2009, APPL ARTIF INTELL, V23, P297, DOI 10.1080/08839510902787397
   Yu XG, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P42, DOI 10.1109/HEALTH.2008.4600107
   Yun YX, 2016, NEUROCOMPUTING, V207, P726, DOI 10.1016/j.neucom.2016.05.058
   Zhao JJ, 2019, PROC CVPR IEEE, P9927, DOI 10.1109/CVPR.2019.01017
NR 74
TC 5
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103375
DI 10.1016/j.jvcir.2021.103375
EA NOV 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD3WF
UT WOS:000722642900001
DA 2024-07-18
ER

PT J
AU Tao, SY
   Dong, WD
   Xu, J
   Lu, JF
   Xu, GL
   Chen, YT
AF Tao, Shuyin
   Dong, Wende
   Xu, Jian
   Lu, Jianfeng
   Xu, Guili
   Chen, Yueting
TI An adaptive two phase blind image deconvolution algorithm for an
   iterative regularization model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image deconvolution; L0-norm gradient regularization; TV
   regularization
ID EDGE METHOD; FIELDS
AB This paper proposes a blind image deconvolution method which consists of two sequential phases, i.e., blur kernel estimation and image restoration. In the first phase, we adopt the L0-norm of image gradients and total variation (TV) to regularize the latent image and blur kernel, respectively. Then we design an alternating optimization algorithm which jointly incorporates the estimation of intermediately restored image, blur kernel and regularization parameters into account. In the second phase, we propose to take the mixture of L0-norm of image gradients and TV to regularize the latent image, and design an efficient non-blind deconvolution algorithm to achieve the restored image. Experimental results on both a benchmark image dataset and real-world blurred images show that the proposed method can effectively restore image details while suppress noise and ringing artifacts, the result is of high quality which is competitive with some state of the art methods.
C1 [Tao, Shuyin; Lu, Jianfeng] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Dong, Wende; Xu, Jian; Xu, Guili] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 211106, Peoples R China.
   [Chen, Yueting] Zhejiang Univ, Coll Opt Sci & Engn, Hangzhou 310007, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Aeronautics & Astronautics; Zhejiang University
RP Dong, WD (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 211106, Peoples R China.
EM dongwende@nuaa.edu.cn
FU National Key Research and Development Program [2018YFB2003803]; National
   Natural Science Foundation of China [61905112, 61905114]; Foundation for
   Start-up of New Teacher of Nanjing University of Aeronautics and
   Astronautics [YAH18066, YAH18108]; Fundamental Research Foundation for
   the Central Universities [NZ2020005, NT2021013]; Natural Science
   Foundation of Jiangsu Province [BK20190405]
FX The authors are grateful for support through the following grants:
   National Key Research and Development Program (2018YFB2003803), National
   Natural Science Foundation of China (61905112, 61905114), Foundation for
   Start-up of New Teacher of Nanjing University of Aeronautics and
   Astronautics (YAH18066, YAH18108), Fundamental Research Foundation for
   the Central Universities (NZ2020005, NT2021013), Natural Science
   Foundation of Jiangsu Province (BK20190405).
CR Bertero M., 1998, Introduction to Inverse Problems in Imaging
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Cai JF, 2009, PROC CVPR IEEE, P1566, DOI 10.1109/CVPRW.2009.5206711
   Carlavan M, 2012, IEEE T IMAGE PROCESS, V21, P1834, DOI 10.1109/TIP.2011.2175934
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   Chen JW, 2013, OPTIK, V124, P3601, DOI 10.1016/j.ijleo.2012.11.004
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   Dong WD, 2012, OPT COMMUN, V285, P5051, DOI 10.1016/j.optcom.2012.08.041
   Dong WD, 2012, OPT COMMUN, V285, P2276, DOI 10.1016/j.optcom.2011.12.105
   Fang HZ, 2013, OPT LETT, V38, P389, DOI 10.1364/OL.38.000389
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Krishnan Dilip., 2009, NIPS, V22, P1
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan JS, 2019, IEEE T PATTERN ANAL, V41, P1412, DOI 10.1109/TPAMI.2018.2832125
   Pan JS, 2017, IEEE T PATTERN ANAL, V39, P342, DOI 10.1109/TPAMI.2016.2551244
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4
   Perrone D, 2016, IEEE T PATTERN ANAL, V38, P1041, DOI 10.1109/TPAMI.2015.2477819
   Qi JJ, 2015, LECT NOTES COMPUT SC, V9242, P603, DOI 10.1007/978-3-319-23989-7_61
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shao WZ, 2015, J VIS COMMUN IMAGE R, V33, P42, DOI 10.1016/j.jvcir.2015.08.017
   Shao WZ, 2016, PATTERN RECOGN, V51, P402, DOI 10.1016/j.patcog.2015.09.034
   Shao WZ, 2018, LECT NOTES COMPUT SC, V11256, P490, DOI 10.1007/978-3-030-03398-9_42
   Tao SY, 2017, PR IEEE I C PROGR IN, P190, DOI 10.1109/PIC.2017.8359540
   Tao SY, 2013, OPTIK, V124, P6599, DOI 10.1016/j.ijleo.2013.05.068
   Tikhonov A. N., 1995, NUMERICAL METHODS SO
   Viallefont-Robinet F, 2010, OPT EXPRESS, V18, P20845, DOI 10.1364/OE.18.020845
   Viallefont-Robinet F, 2010, OPT EXPRESS, V18, P3531, DOI 10.1364/OE.18.003531
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Xu ZM, 2009, OPT LETT, V34, P1453, DOI 10.1364/OL.34.001453
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673
NR 43
TC 1
Z9 1
U1 4
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103370
DI 10.1016/j.jvcir.2021.103370
EA NOV 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD4BM
UT WOS:000722656700002
DA 2024-07-18
ER

PT J
AU Yang, X
   Li, SY
   Ma, J
   Liu, H
   Yan, J
AF Yang, Xi
   Li, Shaoyi
   Ma, Jun
   Liu, Hao
   Yan, Jie
TI Multi-frame co-saliency spatio-temporal regularization correlation
   filters for object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Correlation filter; Co-saliency; Spatio-temporal
   regularization; Heterogeneous fusion
ID VISUAL TRACKING; ROBUST
AB The spatial regularization weight of the correlation filter is not related to the object content and the model degradation in the tracking process. To solve this problem, a new multi-frame co-saliency spatio-temporal regularization correlation filters (MCSRCF) is proposed for visual object tracking. To the best our knowledge, this is the first application of co-saliency regularization to CF-based tracking. In MCSRCF, grayscale features, directional gradient histogram (HOG) features and CNN features are extracted to improve the tracking precision of the tracker. Secondly, the three-dimensional spatial saliency and semantic saliency are introduced to obtain the initial weight of the spatial regularization with object content information. Then, the heterogeneous saliency fusion method is exploited to add a co-saliency spatial regularization term to the objective function to make the spatial penalty weight learn the change of the object region. In additional, the temporal saliency regularization is introduced to learn the information between adjacent frames, which reduces the overfitting effect caused by inaccurate samples. A variety of evaluations are conducted on public benchmarks, and the experimental results show that the proposed tracker achieves good robustness against many state-of-the-art trackers in various complex scenarios.
C1 [Yang, Xi; Li, Shaoyi; Yan, Jie] Northwestern Polytech Univ, 127 Youyi West Rd, Xian 710072, Peoples R China.
   [Ma, Jun] Xian Modern Control Technol Res Inst, 10 Zhangba East Rd, Xian 710065, Peoples R China.
   [Liu, Hao] China Elect Technol Grp Corp, Res Inst 10, Chengdu 610036, Peoples R China.
C3 Northwestern Polytechnical University; China Electronics Technology
   Group
RP Li, SY (corresponding author), Northwestern Polytech Univ, 127 Youyi West Rd, Xian 710072, Peoples R China.
EM NWPUYX@163.com; amlishaoyi2008@163.com
RI yan, jie/HNJ-0097-2023; yan, jy/ISS-1790-2023; 杨, 曦/IQT-4525-2023; Yang,
   Xi/IQT-4525-2023
OI 杨, 曦/0000-0001-6861-1391; Yang, Xi/0000-0003-1230-9315
CR Akin O, 2016, J VIS COMMUN IMAGE R, V38, P763, DOI 10.1016/j.jvcir.2016.04.018
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chung-Chi Tsai, 2018, IEEE T IMAGE PROCESS
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Feng W, 2019, IEEE T IMAGE PROCESS, V28, P3232, DOI 10.1109/TIP.2019.2895411
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hsu KJ, 2018, LECT NOTES COMPUT SC, V11209, P502, DOI 10.1007/978-3-030-01228-1_30
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Jacobs D.E., 2010, ACM S USER INTERFACE, P219
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li Z, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3313874
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang Y., 2021, ARXIV210603772
   Zhang DW, 2015, PROC CVPR IEEE, P2994, DOI 10.1109/CVPR.2015.7298918
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 49
TC 1
Z9 1
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103329
DI 10.1016/j.jvcir.2021.103329
EA OCT 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700007
DA 2024-07-18
ER

PT J
AU Xiao, JJ
   Oussalah, M
AF Xiao, Jingjing
   Oussalah, Mourad
TI Robust model adaption for colour-based particle filter tracking with
   contextual information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Video Analysis; Scale modification; Background learning
ID REAL-TIME TRACKING; OBJECT TRACKING; VISUAL TRACKING; GEOMETRY
AB Color-based particle filters have emerged as an appealing method for targets tracking. As the target may undergo rapid and significant appearance changes, the template (i.e. scale of the target, color distribution histogram) also needs to be updated. Traditional updates without learning contextual information may imply a high risk of distorting the model and losing the target. In this paper, a new algorithm utilizing the environmental information to update both the scale of the tracker and the reference appearance model for the purpose of object tracking in video sequences has been put forward. The proposal makes use of the well-established color-based particle filter tracking while differentiating the foreground and background particles according to their matching score. A roaming phenomenon that yields the estimation to shrink and diverge is investigated. The proposed solution is tested using both simulated and publicly available benchmark datasets where a comparison with six state-of-theart trackers has been carried out. The results demonstrate the feasibility of the proposal and lie down foundations for further research on tackling complex visual tracking problems.
C1 [Xiao, Jingjing] Univ Birmingham, Sch Engn, Birmingham, W Midlands, England.
   [Xiao, Jingjing] Xinqiao Hosp, Dept Med Engn, Chongqing, Peoples R China.
   [Oussalah, Mourad] Univ Oulu, Fac Informat Technol & Elect Engn, CMVS, Oulu, Finland.
C3 University of Birmingham; Army Medical University; University of Oulu
RP Oussalah, M (corresponding author), Univ Oulu, Fac Informat Technol & Elect Engn, CMVS, Oulu, Finland.
EM Mourad.Oussalah@oulu.fi
RI xiao, jing/HRB-7391-2023
FU China of Academy of Science; University of Oulu; Academy of Finland
   [326291]
FX The first author would like to thank China of Academy of Science for
   Financial Support during his stay at University of Birmingham. The
   second author also thanks University of Oulu and the Academy of Finland
   Profi5 project #326291 for supporting thesis work that helped perform
   some programming tasks in this paper.
CR [Anonymous], 2011, 16 COMP VIS WINT WOR
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   Carpenter J, 1999, IEE P-RADAR SON NAV, V146, P2, DOI 10.1049/ip-rsn:19990255
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Doucet A., 2012, The Oxford Handbook of Nonlinear Filtering, P656
   Felsberg M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P121, DOI 10.1109/ICCVW.2013.22
   Hager GD, 1996, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.1996.517104
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Hariharakrishnan K, 2005, IEEE T MULTIMEDIA, V7, P853, DOI 10.1109/TMM.2005.854437
   Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741
   Heng CK, 2012, PROC CVPR IEEE, P3250, DOI 10.1109/CVPR.2012.6248061
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Khan Z, 2009, P ICIP
   King O, 2000, LECT NOTES COMPUT SC, V1842, P695
   Kristan M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P98, DOI 10.1109/ICCVW.2013.20
   Kristan M, 2010, IEEE T SYST MAN CY B, V40, P1505, DOI 10.1109/TSMCB.2010.2041662
   Li J, 2007, IMAGE VISION COMPUT, V25, P544, DOI 10.1016/j.imavis.2006.05.001
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Martínez-del-Rincón J, 2011, PATTERN RECOGN LETT, V32, P210, DOI 10.1016/j.patrec.2010.08.006
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nihei T., 2013, P SICE TOH
   Nouar O.-D., 2006, 2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings, IEEE, V2, pII
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Olson CF, 2000, PROC CVPR IEEE, P52, DOI 10.1109/CVPR.2000.854735
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Weng SK, 2006, J VIS COMMUN IMAGE R, V17, P1190, DOI 10.1016/j.jvcir.2006.03.004
   Stolkin R., 2012, 2012 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2012), P192, DOI 10.1109/MFI.2012.6343021
   Szczodrak M., 2010, 2010 2nd International Conference on Information Technology (ICIT 2010), P31
   Takada H, 2016, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2016.7899899
   Talha M, 2014, IEEE SENS J, V14, P159, DOI 10.1109/JSEN.2013.2271561
   Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760
   VOT, CHALL
   Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]
   Wang JY, 2005, PROC CVPR IEEE, P1037
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao JJ, 2016, IEEE SENS J, V16, P2639, DOI 10.1109/JSEN.2016.2514704
   Xiao JJ, 2016, IEEE T CIRC SYST VID, V26, P304, DOI 10.1109/TCSVT.2015.2406193
   Xiao JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P137, DOI 10.1109/ICCVW.2013.24
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang RF, 2017, FRONT INFORM TECH EL, V18, P545, DOI 10.1631/FITEE.1601464
   Zhaowei Cai, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P86, DOI 10.1007/978-3-642-37431-9_7
   Zhong ST, 2008, FCST: 2008 JAPAN-CHINA JOINT WORKSHOP ON FRONTIER OF COMPUTER SCIENCE AND TECHNOLOGY, PROCEEDINGS, P163, DOI 10.1109/FCST.2008.9
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 57
TC 2
Z9 2
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103270
DI 10.1016/j.jvcir.2021.103270
EA AUG 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800006
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Shang, K
   Kong, WQ
   Qu, T
   Hu, ZJ
   Wu, JJ
   Pedrycz, W
AF Shang, Kun
   Kong, Wanqiu
   Qu, Tan
   Hu, Zejun
   Wu, Jiaji
   Pedrycz, Witold
TI A generic, cluster-centred lossless compression framework for joint
   auroral data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Joint auroral observation; Lossless compression; Hierarchical
   clustering; Auroral spectral data; DMSP SSJ5; DMSP SSUSI
ID EFFICIENT ALGORITHM; DECORRELATION
AB Studying the well-known phenomenon "aurora"plays a pivotal role in investigating the solar-terrestrial coupling mechanism. A special auroral spectrograph in Antarctic Zhongshan Station constitutes a auroral observation joint system with satellite-borne sensors of the Defense Meteorological Satellite Program. Multipoint observation by this system provides more essential information for relevant studies than single observation by each instrument, but also results in a multifold increased volume of data that are difficult to be either stored or transmitted. To address this difficulty, we develop a clustering-based, generic lossless data compression framework that combines the usage of various ultimate compressors with a hierarchical clustering algorithm to exert the strength of all the compressors in data reduction. This framework achieves an always-best compression performance for different-sized datasets with a reasonable time consumption, which promises the design of pipelines using it for real-time data transmission.
C1 [Shang, Kun; Qu, Tan; Wu, Jiaji] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Kong, Wanqiu] Xidian Univ, State Key Lab Integrated Serv Network, Xian 710071, Peoples R China.
   [Kong, Wanqiu] Xidian Univ, Collaborat Innovat Ctr Informat Sensing & Underst, Xian 710071, Peoples R China.
   [Hu, Zejun] Polar Res Inst China, MNR Key Lab Polar Sci, Shanghai 200136, Peoples R China.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 1H9, Canada.
C3 Xidian University; Xidian University; Xidian University; Polar Research
   Institute of China; University of Alberta
RP Kong, WQ (corresponding author), Xidian Univ, State Key Lab Integrated Serv Network, Xian 710071, Peoples R China.
EM kshang@xidian.edu.cn; wqkong@xidian.edu.cn; tqu@xidian.edu.cn;
   huzejun@pric.org.cn; wujj@mail.xidian.edu.cn; wpedrycz@ualberta.ca
RI Hu, Ze-Jun/X-8090-2019; kong, wanqiu/E-4341-2016
OI Hu, Ze-Jun/0000-0003-2448-2094; kong, wanqiu/0000-0002-9814-2028
FU National Natural Science Foundation of China [61775175, 61601355,
   41874195, 41831072]; National Key Research and Development Program of
   China [2018YFC 1407303]; Space Science Pilot Project of the Chinese
   Academy of Sciences [XDA15350202]; International Cooperation Advance
   Research on Key Scientific Issues of the International Meridian Project,
   China [A131901W14]; Meridian Space Weather Monitoring Project of China
FX This work was funded by the National Natural Science Foundation of China
   (No. 61775175, 61601355, 41874195, 41831072) , National Key Research and
   Development Program of China (No. 2018YFC 1407303) , Space Science Pilot
   Project of the Chinese Academy of Sciences (No. XDA15350202) ,
   International Cooperation Advance Research on Key Scientific Issues of
   the International Meridian Project, China (No. A131901W14) . ASD used in
   this paper are acquired by ASG located at ZHS, aka the National
   Observation and Research Station in Ice and Space Environment, for
   Chinese National Antarctic Research Expeditions. ASG is funded by
   Meridian Space Weather Monitoring Project of China. Its relevant data
   products are available from the website of Chinese National Arctic and
   Antarctic Data Center (https:// www.chinare.org. cn) . On the other
   hand, the derivative data products of SSUSI and SSJ5 can be downloaded
   from the website of DMSP Space Environment Data Access
   (https://satdat.ngdc.noaa.gov/dmsp/data) .
CR Amrani N, 2016, IEEE T GEOSCI REMOTE, V54, P5616, DOI 10.1109/TGRS.2016.2569485
   [Anonymous], 2007, INT J MATH MODELS ME
   Aryal S, 2018, J GEOPHYS RES-SPACE, V123, P4257, DOI 10.1029/2018JA025229
   Chavent M, 2007, COMPUT STAT DATA AN, V52, P687, DOI 10.1016/j.csda.2007.03.013
   DEFAYS D, 1977, COMPUT J, V20, P364, DOI 10.1093/comjnl/20.4.364
   Gil-García R, 2010, PATTERN RECOGN LETT, V31, P469, DOI 10.1016/j.patrec.2009.11.011
   Grubbs G, 2018, J GEOPHYS RES-SPACE, V123, P993, DOI 10.1002/2017JA025026
   Grubbs G, 2018, GEOPHYS RES LETT, V45, P15, DOI 10.1002/2017GL075873
   Hu ZJ, 2017, POLAR SCI, V14, P1, DOI 10.1016/j.polar.2017.09.001
   Huang BM, 2006, PROC SPIE, V6365, DOI 10.1117/12.690659
   Kadinsky-Cade K., 2004, AGU SPRING M
   Kaufman L., 2009, FINDING GROUPS DATA
   Knight HK, 2008, J GEOPHYS RES-SPACE, V113, DOI 10.1029/2007JA012728
   Kong W., 2020, REMOTE SENS-BASEL, V12
   Kong WQ, 2019, J VIS COMMUN IMAGE R, V62, P174, DOI 10.1016/j.jvcir.2019.05.006
   Kong WQ, 2017, INFORM SCIENCES, V381, P33, DOI 10.1016/j.ins.2016.11.008
   Kwon TM, 2003, TRANSPORT RES REC, P111
   Liu JW, 2005, LECT NOTES ARTIF INT, V3518, P826
   Magli E, 2004, IEEE GEOSCI REMOTE S, V1, P21, DOI 10.1109/LGRS.2003.822312
   Mahoney M., 2020, GENERIC COMPRESSION
   Marshall R.A., 2020, DYNAMIC LOSS EARTHS, P199
   Mathews G.J, 1995, P SCI INF MAN DAT CO P SCI INF MAN DAT CO
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P157, DOI 10.1109/LSP.2005.862604
   Mielikainen J, 2003, IEEE T GEOSCI REMOTE, V41, P2943, DOI 10.1109/TGRS.2003.820885
   Mielikainen J, 2012, IEEE GEOSCI REMOTE S, V9, P1118, DOI 10.1109/LGRS.2012.2191531
   Motta G, 2006, HYPERSPECTRAL DATA COMPRESSION, P107, DOI 10.1007/0-387-28600-4_5
   Noor N.R.M., 2016, THESIS U LEICESTER THESIS U LEICESTER
   Omholt Anders., 2012, The optical aurora, V4
   Patnaik AK, 2016, ALEX ENG J, V55, P407, DOI 10.1016/j.aej.2015.11.003
   Paxton L. J., 1992, P SPIE INT SOC OPT E, V1764, P161, DOI [DOI 10.1117/12.140846, 10.1117/12.140846]
   Paxton LJ, 2001, P SOC PHOTO-OPT INS, V4485, P338
   Pfitzner D, 2009, KNOWL INF SYST, V19, P361, DOI 10.1007/s10115-008-0150-6
   Piwowar J.M, 2001, CARTOUCHE, V41
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   ROBINSON AH, 1967, PR INST ELECTR ELECT, V55, P356, DOI 10.1109/PROC.1967.5493
   Runsas S, 2020, NANOZIP
   Sârbu C, 2007, CHEMOMETR INTELL LAB, V86, P121, DOI 10.1016/j.chemolab.2006.08.015
   SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30
   SOLOMON SC, 1988, J GEOPHYS RES, V93, P9867, DOI 10.1029/JA093iA09p09867
   Solomon SC, 2017, J GEOPHYS RES-SPACE, V122, P7834, DOI 10.1002/2017JA024314
   Song CH, 2011, PROC SPIE, V8157, DOI 10.1117/12.895421
   SULLIVAN W, 1958, B ATOM SCI, V14, P68, DOI 10.1080/00963402.1958.11453804
   Summerhayes CP, 2008, POLAR REC, V44, P321, DOI 10.1017/S0032247408007468
   Tanaka K, 1998, METHOD APPARATUS COM
   Tang X, 2006, HYPERSPECTRAL DATA COMPRESSION, P273, DOI 10.1007/0-387-28600-4_10
   Wang Chi, 2010, Chinese Journal of Space Science, V30, P382
   Wells D. C., 1981, Astronomy & Astrophysics Supplement Series, V44, P363
   Wong WC, 2002, ENABLING SOCIETY WITH INFORMATION TECHNOLOGY, P101
   Wu JJ, 2015, IEEE SIGNAL PROC LET, V22, P2194, DOI 10.1109/LSP.2015.2443913
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P994, DOI 10.1109/83.846242
   Xiong TK, 2012, DATA MIN KNOWL DISC, V24, P103, DOI 10.1007/s10618-011-0221-2
NR 52
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103185
DI 10.1016/j.jvcir.2021.103185
EA JUN 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500002
DA 2024-07-18
ER

PT J
AU Li, BW
   Tian, M
   Zhang, WX
   Yao, HT
   Wang, XP
AF Li, Bowen
   Tian, Meng
   Zhang, Weixia
   Yao, Hongtai
   Wang, Xianpei
TI Learning to predict the quality of distorted-then-compressed images via
   a deep neural network*,**
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Convolutional neural network; Full-reference
   IQA; No-reference IQA; Distorted-then-compressed
ID NATURAL SCENE; STATISTICS; INDEX
AB Being captured by amateur photographers, reciprocally propagated through multimedia pipelines, and compressed with different levels, real-world images usually suffer from a wide variety of hybrid distortions. Faced with this scenario, full-reference (FR) image quality assessment (IQA) algorithms can not deliver promising predictions due to the inferior references. Meanwhile, existing no-reference (NR) IQA algorithms remain limited in their efficacy to deal with different distortion types. To address this obstacle, we explore a NR-IQA metric by predicting the perceptual quality of distorted-then-compressed images using a deep neural network (DNN). First, we propose a novel two-stream DNN to handle both authentic distortions and synthetic compressions and adopt effective strategies to pre-train the two branches of the network. Specifically, we transfer the knowledge learned from in-the-wild images to account for authentic distortions by utilizing a pre-trained deep convolutional neural network (CNN) to provide meaningful initializations. Meanwhile, we build a CNN for synthetic compressions and pre-train it on a dataset including synthetic compressed images. Subsequently, we bilinearly pool these two sets of features as the image representation. The overall network is fine-tuned on an elaborately-designed auxiliary dataset, which is annotated by a reliable objective quality metric. Furthermore, we integrate the output of the authentic-distortion-aware branch with that of the overall network following a two-step prediction manner to boost the prediction performance, which can be applied in the distorted-then-compressed scenario when the reference image is available. Extensive experimental results on several databases especially on the LIVE Wild Compressed Picture Quality Database show that the proposed method achieves state-of-the-art performance with good generalizability and moderate computational complexity.
C1 [Li, Bowen; Tian, Meng; Yao, Hongtai; Wang, Xianpei] Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.
   [Zhang, Weixia] Shanghai Jiao Tong Univ, Artificial Intelligence Inst, Shanghai 200240, Peoples R China.
C3 Wuhan University; Shanghai Jiao Tong University
RP Tian, M (corresponding author), Wuhan Univ, Elect Informat Sch, Wuhan 430072, Peoples R China.
EM mengtian@whu.edu.cn
RI Wang, Xianpei/ABF-3388-2021; Yao, Hongtai/ABF-3385-2021
OI Wang, Xianpei/0000-0002-7969-5882; 
FU National Natural Science Foundation of China [61901262, 51707135]
FX This document is the results of the research project funded in part by
   the National Natural Science Foundation of China under Grant 61901262
   and Grant 51707135.
CR [Anonymous], 2016, PRUNING CONVOLUTIONA
   [Anonymous], 2019, The Paper
   Athar S, 2019, IEEE ACCESS, V7, P140030, DOI 10.1109/ACCESS.2019.2943319
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan YZ, 2018, LECT NOTES COMPUT SC, V11165, P361, DOI 10.1007/978-3-030-00767-6_34
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gao F, 2018, PATTERN RECOGN, V81, P432, DOI 10.1016/j.patcog.2018.04.016
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Gu K, 2013, IEEE WORKSHOP SIG, P241, DOI 10.1109/SiPS.2013.6674512
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hosu Vlad, 2019, P INT WORKSH QUAL MU, P1
   Jakhetiya V, 2019, IEEE T IND INFORM, V15, P4120, DOI 10.1109/TII.2018.2888861
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kingma D. P., 2014, arXiv
   Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li Bowen, 2020, IEEE ACCESS, V8
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Lin H., 2020, ARXIV200108113
   Lin H., 2018, CORR
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Ma KD, 2019, IEEE IMAGE PROC, P2344, DOI [10.1109/ICIP.2019.8803390, 10.1109/icip.2019.8803390]
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Ma Kede, 2020, P IEEE INT C IM PROC
   Min XK, 2019, IEEE T INTELL TRANSP, V20, P2879, DOI 10.1109/TITS.2018.2868771
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3805, DOI 10.1109/TIP.2020.2966082
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Min XK, 2018, SIGNAL PROCESS, V145, P127, DOI 10.1016/j.sigpro.2017.10.025
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Sadaka NG, 2008, IEEE IMAGE PROC, P369, DOI 10.1109/ICIP.2008.4711768
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Sheskin D.J., 2003, HDB PARAMETRIC NONPA, DOI [DOI 10.4324/9780203489536, 10.4324/9780203489536]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   VQEG, 2000, VQEG M OTT CAN MAR
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wu QL, 2020, IMMUNOPHARM IMMUNOT, V42, P473, DOI 10.1080/08923973.2020.1810271
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Wu QB, 2015, IEEE IMAGE PROC, P339, DOI 10.1109/ICIP.2015.7350816
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Ye P, 2014, PROC CVPR IEEE, P4241, DOI 10.1109/CVPR.2014.540
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Yu XX, 2019, IEEE T IMAGE PROCESS, V28, P5757, DOI 10.1109/TIP.2019.2922850
   Yue GH, 2019, DIGIT SIGNAL PROCESS, V91, P21, DOI 10.1016/j.dsp.2018.12.007
   Zeng H, 2018, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2018.8451285
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
   Zhang Weixia, ABS200513983 CORR
   Zhou BL, 2014, ADV NEUR IN, V27
NR 77
TC 5
Z9 5
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103004
DI 10.1016/j.jvcir.2020.103004
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700005
DA 2024-07-18
ER

PT J
AU Tek, FB
   Çam, I
   Karli, D
AF Tek, F. Boray
   Cam, Ilker
   Karli, Deniz
TI Adaptive convolution kernel for artificial neural networks?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive convolution; Multi-scale convolution; Image classification;
   Residual networks
AB Many deep neural networks are built by using stacked convolutional layers of fixed and single size (often 3 ? 3) kernels. This paper describes a method for learning the size of convolutional kernels to provide varying size kernels in a single layer. The method utilizes a differentiable, and therefore backpropagation-trainable Gaussian envelope which can grow or shrink in a base grid. Our experiments compared the proposed adaptive layers to ordinary convolution layers in a simple two-layer network, a deeper residual network, and a U-Net architecture. The results in the popular image classification datasets such as MNIST, MNIST-CLUTTERED, CIFAR-10, Fashion, and ?Faces in the Wild?showed that the adaptive kernels can provide statistically significant improvements on ordinary convolution kernels. A segmentation experiment in the Oxford-Pets dataset demonstrated that replacing ordinary convolution layers in a U-shaped network with 7 ? 7 adaptive layers can improve its learning performance and ability to generalize.
C1 [Tek, F. Boray; Cam, Ilker] Isik Univ, Dept Comp Engn, TR-34980 Sile Istanbul, Turkey.
   [Karli, Deniz] Isik Univ, Dept Math, TR-34980 Sile Istanbul, Turkey.
C3 Isik University; Isik University
RP Tek, FB (corresponding author), Isik Univ, Dept Comp Engn, TR-34980 Sile Istanbul, Turkey.
EM boray.tek@isikun.edu.tr
RI Karli, Deniz/GPX-6441-2022; Tek, Faik Boray/H-3423-2012
OI Karli, Deniz/0000-0002-5639-0648; Tek, Faik Boray/0000-0002-8649-6013
FU Scientific and Technological Research Council of Turkey programme
   [TUBITAK-1001, 118E722]; Isik University BAP programme, Turkey [16A202];
   NVIDIA
FX This work was supported by The Scientific and Technological Research
   Council of Turkey programme (TUBITAK-1001 no: 118E722), Isik University
   BAP programme, Turkey (no: 16A202), and NVIDIA hardware donation of a
   Tesla K40 GPU unit, Turkey.
CR [Anonymous], 2016, ICLR
   Cam, 2019, LEARNING FILTER SCAL
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F, 2015, KERAS
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo BY, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102851
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kim J., 2017, IEEE CVPR
   Kindermans P.-J., 2018, ARXIV CSLG 180804260
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102611
   Li X., 2017, ICLR
   Lindeberg T, 2011, J MATH IMAGING VIS, V40, P36, DOI 10.1007/s10851-010-0242-2
   Luo WJ, 2016, ADV NEUR IN, V29
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Poggio T., 2013, SCHOLARPEDIA, V8, P3516, DOI [DOI 10.4249/SCHOLARPEDIA.3516, 10.4249/scholarpedia.3516]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Smola A., 2020, ARXIV CORR 200408955
   Spinoulas L, 2015, IEEE COMPUT SOC CONF
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tek F.B., 2019, BILISIM TEKNOL DERG, V12, P307
   Tek F.B., NEUROCOMPUTING, V419, P306
   Tek F.B., 2018, ARXIV PREPRINT ARXIV
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   van der Walt S, 2014, PEERJ, V2, DOI 10.7717/peerj.453
   Vinyals, 2016, ARXIV CORR ABS160903
   Vollgraf R., 2017, ARXIV CSLG170807747
   Weiler M, 2018, PROC CVPR IEEE, P849, DOI 10.1109/CVPR.2018.00095
   Yu F, 2017, IEEE INT SYMP ELEC
   Zhang N., 2007, Tech. Rep. 07-49, P7
NR 40
TC 8
Z9 8
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103015
DI 10.1016/j.jvcir.2020.103015
EA JAN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BX
UT WOS:000633494400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yao, YZ
   Yu, NH
AF Yao, Yuanzhi
   Yu, Nenghai
TI Motion vector modification distortion analysis-based payload allocation
   for video steganography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video steganography; Motion vector; Payload allocation; Motion vector
   modification distortion; Residue deviation propagation
ID H.264/AVC VIDEO; SCHEME
AB Video steganography forms a covert communication channel by data embedding in cover elements. To consider inter-frame mutual embedding impacts, this paper proposes a payload allocation strategy in video steganography based on motion vector modification distortion analysis. Firstly, the motion vector modification distortion caused by data embedding is analyzed. Then, a rate-distortion model reflecting the residue deviation propagation in successive inter-coded frames is derived. According to this model, the residue deviation propagation weight of each inter-coded frame can be computed. Finally, an inter-frame payload allocation strategy is designed in order to restrain the residue deviation propagation. Experimental results demonstrate that the proposed payload allocation strategy can enhance existing motion vector-based video steganographic methods in terms of undetectability and video coding performance. Besides, the lower computational complexity can be achieved.
C1 [Yao, Yuanzhi; Yu, Nenghai] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Yao, YZ (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.
EM yaoyz@ustc.edu.cn; ynh@ustc.edu.cn
RI Yao, Yuanzhi/JZS-9170-2024
OI Yao, Yuanzhi/0000-0003-1965-7670
FU National Natural Science Foundation of China [61802357]; National Key
   Research and Development Program of China [2018YFB0804102]; Fundamental
   Research Funds for the Central Universities [WK3480000009]
FX The authors would like to sincerely thank the editors and the anonymous
   reviewers for their valuable comments. This work was supported in part
   by the National Natural Science Foundation of China under Grant
   61802357, in part by the National Key Research and Development Program
   of China under Grant 2018YFB0804102, and in part by the Fundamental
   Research Funds for the Central Universities under Grant WK3480000009.
CR [Anonymous], 2006, H 264 AVC JOINT MODE
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   Cao Y, 2015, IEEE COMMUN LETT, V19, P203, DOI 10.1109/LCOMM.2014.2387160
   Cao Y, 2012, IEEE SIGNAL PROC LET, V19, P35, DOI 10.1109/LSP.2011.2176116
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker AD, 2014, IEEE T INF FOREN SEC, V9, P1424, DOI 10.1109/TIFS.2014.2336380
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Wang KR, 2014, IEEE T INF FOREN SEC, V9, P741, DOI 10.1109/TIFS.2014.2308633
   Wang PP, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P123, DOI 10.1145/3082031.3083245
   Wang Y, 2017, LECT NOTES COMPUT SC, V10431, P163, DOI 10.1007/978-3-319-64185-0_13
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZC, 2020, IEEE SIGNAL PROC LET, V27, P71, DOI 10.1109/LSP.2019.2956416
   Wang ZC, 2018, IEEE SIGNAL PROC LET, V25, P1530, DOI 10.1109/LSP.2018.2865888
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xue YM, 2019, SIGNAL PROCESS-IMAGE, V76, P22, DOI 10.1016/j.image.2019.04.012
   Yao H, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102795
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yao YZ, 2015, MULTIMED TOOLS APPL, V74, P11163, DOI 10.1007/s11042-014-2223-8
   Yin XL, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102816
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhang H., 2014, P 2 ACM WORKSH INF H, P115
   Zhang H, 2017, IEEE T INF FOREN SEC, V12, P465, DOI 10.1109/TIFS.2016.2623587
   Zhang H, 2016, MULTIMED TOOLS APPL, V75, P13503, DOI 10.1007/s11042-015-2743-x
   ZHAO Y, 2015, PROC INT WORKSHOP DI, P119
   Zhou H, 2019, IEEE T MULTIMEDIA, V21, P1384, DOI 10.1109/TMM.2018.2882088
   Zhu BL, 2018, IEEE IMAGE PROC, P1678, DOI 10.1109/ICIP.2018.8451214
NR 31
TC 11
Z9 11
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102986
DI 10.1016/j.jvcir.2020.102986
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900006
DA 2024-07-18
ER

PT J
AU Cheng, JY
   Liu, YH
   Ma, YM
AF Cheng, Jinyong
   Liu, Yihui
   Ma, Yuming
TI Protein secondary structure prediction based on integration of CNN and
   LSTM model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Protein secondary structure prediction; Convolution neural networks;
   Long short-term memory; Softmax; Random forest
ID NEURAL-NETWORKS
AB Protein structure prediction is an important issue in computational biology, and protein secondary structure prediction is the basis for protein three-dimensional structure prediction. A protein secondary structure prediction method based on convolutional neural networks (CNN) and Long Short-Term Memory (LSTM) is proposed in this paper. The architecture of CNN has two convolutional layers, one max-pooling layer and one ReLU activation layer. The feature maps extracted from second convolutional layer are used to feed to softmax classifier, and the first probability output is obtained. The LSTM model has a sequence layer and a last layer. The feature is extracted from last layer and input to random forest classifier to get the second probability output. The two probabilistic outputs are weighted and integrated to obtain the prediction model EN-CSLR in this paper. Based on the advantages of integration of the two models, cross-validation experiments are performed on the 25pdb dataset, and Q(3) reaches 80.18%, which is higher than using only one model. The experimental results show that the features extracted from CNN and LSTM models can effectively improve the accuracy of protein secondary structure prediction. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Cheng, Jinyong; Liu, Yihui; Ma, Yuming] Qilu Univ Technol, Shandong Acad Sci, Sch Comp Sci & Technol, Jinan, Peoples R China.
C3 Qilu University of Technology
RP Liu, YH (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM cjy@qlu.edu.com; yxl@qlu.edu.com; mym@qlu.edu.com
FU National Natural Science Foundation of China [61375013]; Natural Science
   Foundation of Shandong Province [ZR2013FM020]
FX The research work is supported by the National Natural Science
   Foundation of China (Grant No. 61375013), and Natural Science Foundation
   of Shandong Province (ZR2013FM020), China.
CR Bidargaddi NP, 2009, NEUROCOMPUTING, V72, P3943, DOI 10.1016/j.neucom.2009.04.017
   Chen C, 2007, TALANTA, V71, P2069, DOI 10.1016/j.talanta.2006.09.015
   Cheng Jianlin, 2008, IEEE Rev Biomed Eng, V1, P41, DOI 10.1109/RBME.2008.2008239
   CHOU PY, 1974, BIOCHEMISTRY-US, V13, P222, DOI 10.1021/bi00699a002
   Garnier J, 1996, METHOD ENZYMOL, V266, P540
   Guo YB, 2018, J BIOINF COMPUT BIOL, V16, DOI 10.1142/S021972001850021X
   Heffernan R, 2018, J COMPUT CHEM, V39, P2210, DOI 10.1002/jcc.25534
   Islam MN, 2016, J THEOR BIOL, V389, P60, DOI 10.1016/j.jtbi.2015.10.015
   Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091
   Liu YH, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P1771, DOI 10.1109/CISP-BMEI.2016.7853004
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Ma YH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18422-7
   Malekpour SA, 2009, MATH BIOSCI, V217, P145, DOI 10.1016/j.mbs.2008.11.001
   Qian YM, 2016, IEEE-ACM T AUDIO SPE, V24, P2263, DOI 10.1109/TASLP.2016.2602884
   Tan YT, 2015, NEUROCOMPUTING, V148, P409, DOI 10.1016/j.neucom.2014.06.001
   Wang S, 2016, SCI REP-UK, V6, DOI 10.1038/srep18962
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Yang BR, 2011, KNOWL-BASED SYST, V24, P304, DOI 10.1016/j.knosys.2010.10.002
   Yao XQ, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-49
   Yepes AJ, 2017, J BIOMED INFORM, V73, P137, DOI 10.1016/j.jbi.2017.08.001
   Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K
NR 23
TC 23
Z9 26
U1 3
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102844
DI 10.1016/j.jvcir.2020.102844
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900004
DA 2024-07-18
ER

PT J
AU Lie, WN
   Chiu, ST
   Chen, YK
   Chiang, JC
AF Lie, Wen-Nung
   Chiu, Shao-Ting
   Chen, Yi-Kai
   Chiang, Jui-Chiu
TI Semi-automatic 2D-to-3D video conversion based on background sprite
   generation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo video conversion; Depth propagation; Graph cut; Background sprite
   model
ID DEPTH PROPAGATION; 2D; EXTRACTION; SEQUENCES; FIELD
AB This paper presents a technique for semi-automatic 2D-to-3D stereo video conversion, which is known to provide user intervention in assigning foreground/background depths for key frames and then get depth maps for non-key frames via automatic depth propagation. Our algorithm treats foreground and background separately. For foregrounds, kernel pixels are identified and then used as the seeds for graph-cut segmentation for each non-key frame independently, resulting in results not limited by objects' motion activity. For backgrounds, all video frames, after foregrounds being removed, are integrated into a common background sprite model (BSM) based on a relay-frame-based image registration algorithm. Users can then draw background depths for BSM in an integrated manner, thus reducing human efforts significantly. Experimental results show that our method is capable of retaining more faithful foreground depth boundaries (by 1.6-2.7 dB) and smoother background depths than prior works. This advantage is helpful for 3D display and 3D perception. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Lie, Wen-Nung; Chiu, Shao-Ting; Chen, Yi-Kai; Chiang, Jui-Chiu] Natl Chung Cheng Univ, Dept Elect Engn, Chiayi, Taiwan.
   [Lie, Wen-Nung; Chiang, Jui-Chiu] Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat AIM HI, Chiayi, Taiwan.
   [Lie, Wen-Nung; Chiang, Jui-Chiu] Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, Chiayi, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University;
   National Chung Cheng University
RP Lie, WN (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Chiayi, Taiwan.; Lie, WN (corresponding author), Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat AIM HI, Chiayi, Taiwan.; Lie, WN (corresponding author), Natl Chung Cheng Univ, Ctr Innovat Res Aging Soc CIRAS, Chiayi, Taiwan.
EM ieewnl@ccu.edu.tw
RI Lie, Wen-Nung/AFP-1266-2022
OI Lie, Wen-Nung/0000-0002-8166-2844
FU Advanced Institute of Manufacturing with High-tech Innovations (AIM-HI)
   from The Featured Areas Research Center Program by the Ministry of
   Education (MOE) in Taiwan; Center for Innovative Research on Aging
   Society (CIRAS) from The Featured Areas Research Center Program by the
   Ministry of Education (MOE) in Taiwan
FX This work was partially supported by the Advanced Institute of
   Manufacturing with High-tech Innovations (AIM-HI) and Center for
   Innovative Research on Aging Society (CIRAS) from The Featured Areas
   Research Center Program within the framework of the Higher Education
   Sprout Project by the Ministry of Education (MOE) in Taiwan.
CR [Anonymous], 2013, PROC 2013 VIS COMMUN, DOI DOI 10.1109/VCIP.2013.6706419
   [Anonymous], 2019, Methodologies for the subjective assessment of the quality of television images, rec.itu-r bt.500
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cao X, 2011, IEEE T BROADCAST, V57, P491, DOI 10.1109/TBC.2011.2127650
   Chenglei Wu, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P65
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guttmann M, 2009, IEEE I CONF COMP VIS, P136, DOI 10.1109/ICCV.2009.5459158
   Han DX, 2018, J VIS COMMUN IMAGE R, V56, P287, DOI 10.1016/j.jvcir.2018.10.004
   Harman P, 2002, PROC SPIE, V4660, P78, DOI 10.1117/12.468020
   Hsu CT, 2004, SIGNAL PROCESS-IMAGE, V19, P81, DOI 10.1016/j.image.2003.10.001
   Jeyabharathi D, 2018, J VIS COMMUN IMAGE R, V55, P434, DOI 10.1016/j.jvcir.2018.06.024
   Joonsoo Kim, 2011, 2011 International Conference on ICT Convergence, P360, DOI 10.1109/ICTC.2011.6082616
   Ju KY, 2016, INT CONF ACOUST SPEE, P1696, DOI 10.1109/ICASSP.2016.7471966
   Jung C, 2015, IEEE IMAGE PROC, P3515, DOI 10.1109/ICIP.2015.7351458
   Li Q, 2009, MICRO NANO LETT, V4, P1, DOI 10.1049/mnl:20080036
   Lie WN, 2011, ELECTRON LETT, V47, P319, DOI 10.1049/el.2010.2912
   Lie WN, 2018, IEEE T MULTIMEDIA, V20, P1075, DOI 10.1109/TMM.2017.2763319
   Lie Wen-Nung, 2016, P AS PAC SIGN INF PR
   Lin GS, 2017, J VIS COMMUN IMAGE R, V43, P127, DOI 10.1016/j.jvcir.2016.12.002
   LIN JT, 2012, EURASIP J ADV SIG PR, V2012
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2003, IEEE T CIRC SYST VID, V13, P394, DOI 10.1109/TCSVT.2003.811607
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   Phan R, 2014, IEEE T MULTIMEDIA, V16, P122, DOI 10.1109/TMM.2013.2283451
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Su YB, 2005, IEEE T CIRC SYST VID, V15, P232, DOI 10.1109/TCSVT.2004.841656
   Varekamp C., 2007, European Conference on Visual Media Production, P1, DOI DOI 10.1049/CP:20070061
   Wang L, 2014, IEEE T MULTIMEDIA, V16, P1905, DOI 10.1109/TMM.2014.2341599
   Yao C, 2014, IEEE T BROADCAST, V60, P394, DOI 10.1109/TBC.2014.2321671
   Yousif H, 2018, J VIS COMMUN IMAGE R, V55, P802, DOI 10.1016/j.jvcir.2018.08.013
NR 32
TC 0
Z9 0
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102801
DI 10.1016/j.jvcir.2020.102801
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900016
DA 2024-07-18
ER

PT J
AU Song, Y
   Li, J
   Chen, X
   Zhang, DY
   Tang, Q
   Yang, K
AF Song, Yun
   Li, Jie
   Chen, Xi
   Zhang, Dengyong
   Tang, Qiang
   Yang, Kun
TI An efficient tensor completion method via truncated nuclear norm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tensor completion; Tensor singular value decomposition; Truncated tensor
   nuclear norm; Visual data restoration
ID LOW-RANK; REGULARIZATION; FACTORIZATION; RECOVERY
AB Tensor completion aims to recover missing entries from partial observations for multi-dimensional data. Traditional tensor completion algorithms process the dimensional data by unfolding the tensor into matrices, which breaks the inherent correlation and dependencies in multiple channels and lead to critical information loss. In this paper, we propose a novel tensor completion model for visual multidimensional data completion under the tensor singular value decomposition (t-SVD) framework. In the proposed method, tensor is treated as a whole and a truncated nuclear norm regularization is employed to exploit the structural properties in a tensor and hidden information existing among the adjacent channels of a tensor. Besides, we introduce a weighted tensor to adjust the residual error of each frontal slices in consideration of their different recovery statistics. It does enhance the sparsity of all unfoldings of the tensor and accelerates the convergence of the proposed method. Experimental results on various visual datasets demonstrate the promising performance of the proposed method in comparison with the state-of-the-art tensor completion methods. (C) 2020 Published by Elsevier Inc.
C1 [Song, Yun; Li, Jie; Chen, Xi; Zhang, Dengyong; Tang, Qiang] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410014, Peoples R China.
   [Song, Yun; Li, Jie; Chen, Xi; Zhang, Dengyong; Tang, Qiang] Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha 410014, Peoples R China.
   [Yang, Kun] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Changsha University of Science & Technology; University of Essex
RP Chen, X (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410014, Peoples R China.
EM chenxi_cscu@csust.edu.cn
FU National Natural Science Foundation of China [61772087, 61504013,
   61303043]; State Scholarship Fund of China Scholarship Council
   [201808430236]; "Double First-class"International Cooperation and
   Development Scientific Research Project of Changsha University of
   Science and Technology [2018IC23, 2018IC25]; Natural Science Foundation
   of Hunan Province [2019JJ50648, 2016JJ2005]; CERNET Innovation Project
   [NGII20160203]; Outstanding Youth Project of Hunan Province Education
   Department [18B162]; Open Project of Hunan Provincial Key Laboratory of
   Intelligent Processing of Big Data on Transportation
FX This work is partly supported by the National Natural Science Foundation
   of China (No. 61772087, 61504013, 61303043), the State Scholarship Fund
   of China Scholarship Council (No. 201808430236), the "Double
   First-class"International Cooperation and Development Scientific
   Research Project of Changsha University of Science and Technology (No.
   2018IC23, 2018IC25), the Natural Science Foundation of Hunan Province
   (No. 2016JJ2005, 2019JJ50648), the CERNET Innovation Project (No.
   NGII20160203), the Outstanding Youth Project of Hunan Province Education
   Department (No. 18B162), the Natural Science Foundation of Hunan
   Province (No. 2019JJ50648) and the Open Project of Hunan Provincial Key
   Laboratory of Intelligent Processing of Big Data on Transportation.
CR [Anonymous], 1937, SOME MATRIX INEQUALI
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Candès EJ, 2008, ANN ALLERTON CONF, P806, DOI 10.1109/ALLERTON.2008.4797640
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Chen X, 2019, IEEE ACCESS, V7, P117088, DOI 10.1109/ACCESS.2019.2934890
   Gandy S, 2011, INVERSE PROBL, V27, DOI 10.1088/0266-5611/27/2/025010
   Ge Q, 2017, IEEE T IMAGE PROCESS, V26, P3098, DOI 10.1109/TIP.2016.2639781
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hong B, 2016, NEUROCOMPUTING, V175, P216, DOI 10.1016/j.neucom.2015.10.052
   Hu WR, 2017, IEEE T NEUR NET LEAR, V28, P2961, DOI 10.1109/TNNLS.2016.2611525
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Jia CC, 2018, IEEE T IMAGE PROCESS, V27, P1878, DOI 10.1109/TIP.2017.2781299
   Kilmer ME, 2011, LINEAR ALGEBRA APPL, V435, P641, DOI 10.1016/j.laa.2010.09.020
   Li S, 2016, IEEE T NEUR NET LEAR, V27, P2160, DOI 10.1109/TNNLS.2015.2464090
   Liu GC, 2019, IEEE T IMAGE PROCESS, V28, P5161, DOI 10.1109/TIP.2019.2917857
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Liu LC, 2017, IEEE T CYBERNETICS, V47, P600, DOI 10.1109/TCYB.2016.2521428
   Liu Q, 2016, IEEE T IMAGE PROCESS, V25, P316, DOI 10.1109/TIP.2015.2503238
   Liu XY, 2016, PROC SPIE, V9848, DOI 10.1117/12.2224039
   Lu C., 2018, IEEE T PATTERN ANAL, V35, P208
   Lu C, 2018, P 27 INT JOINT C ART
   Lu CY, 2016, PROC CVPR IEEE, P5249, DOI 10.1109/CVPR.2016.567
   Martin CD, 2013, SIAM J SCI COMPUT, V35, pA474, DOI 10.1137/110841229
   Peng YG, 2014, IEEE T CYBERNETICS, V44, P2418, DOI 10.1109/TCYB.2014.2307854
   Rauhut H, 2015, 2015 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P397, DOI 10.1109/SAMPTA.2015.7148920
   Shang FH, 2016, JMLR WORKSH CONF PRO, V51, P620
   Tomioka Ryota, 2013, P NEUR INF PROC SYST, V26, P1331
   Wang L, 2019, NEURAL NETWORKS, V117, P201, DOI 10.1016/j.neunet.2019.05.007
   Xu YY, 2015, INVERSE PROBL IMAG, V9, P601, DOI 10.3934/ipi.2015.9.601
   Xue SK, 2018, INT C PATT RECOG, P2600, DOI 10.1109/ICPR.2018.8546008
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P485, DOI 10.1109/TCYB.2016.2519532
   Zhang S., 2013, 27 AAAI C ART INT
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhang Z, 2019, IEEE DATA MINING, P846, DOI 10.1109/ICDM.2019.00095
   Zhang Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1569, DOI 10.1145/3343031.3351023
   Zhang Z, 2017, IEEE T IMAGE PROCESS, V26, P1607, DOI 10.1109/TIP.2017.2654163
   Zhang Z, 2016, IEEE T IMAGE PROCESS, V25, P2429, DOI 10.1109/TIP.2016.2547180
   Zhang Z, 2014, NEURAL NETWORKS, V53, P81, DOI 10.1016/j.neunet.2014.01.001
   Zhou P, 2018, IEEE T IMAGE PROCESS, V27, P1152, DOI 10.1109/TIP.2017.2762595
NR 40
TC 19
Z9 19
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102791
DI 10.1016/j.jvcir.2020.102791
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900009
DA 2024-07-18
ER

PT J
AU Peng, F
   Qin, L
   Long, M
AF Peng, Fei
   Qin, Le
   Long, Min
TI Face presentation attack detection based on chromatic co-occurrence of
   local binary pattern and ensemble learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Presentation attack detection; Face recognition; Color distortion;
   Chromatic co-occurrence of local binary pattern; Ensemble learning
ID SPOOFING DETECTION; IMAGE QUALITY; COLOR; NETWORK; COUNT
AB To counter face presentation attacks in face recognition (FR), color texture has been successfully used for face presentation attack detection (PAD) in recent years. However, the existing research does not fully consider the correlation between different color channels as well as the optimization of classification for face PAD. To resolve these limitations, a face PAD scheme based on chromatic co-occurrence of local binary pattern (CCoLBP) and ensemble learning (EL) is proposed in this paper. A color distortion-based face PAD model is first built, and then the chromatic discrepancies between bona fide faces and artefacts are analyzed. After that, CCoLBP is extracted as the feature to characterize these discrepancies. Meanwhile, an EL based classifier is put forward to reduce the effect of class imbalance and to improve the generalization ability. Experimental results and analysis indicate that the proposed scheme can achieve an overall good performance. Moreover, it can achieve significant improvement in the cross-database test, and its computational complexity can meet the requirement of real time applications. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Peng, Fei; Qin, Le] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410014, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM eepengf@gmail.com
RI Long, Min/AGW-6059-2022; Peng, Fei/H-6951-2017
OI Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [U1936115, 61572182]; Hunan
   Provincial Natural Science Foundation of China [15112007]
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant No. U1936115, 61572182), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No. 15112007).
CR Akhtar Z, 2015, IEEE SECUR PRIV, V13, P63, DOI 10.1109/MSP.2015.116
   [Anonymous], 2018, ARXIV181200408
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], ACM COMPUT SURV CSUR
   [Anonymous], 2012, P AS C COMP VIS
   [Anonymous], 1978, ACM SIGGRAPH COMPUT, DOI [10.1145/800248.807361, DOI 10.1145/965139.807361]
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], JPEG FILE INTERCHANG
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], 2018, IAPR INT C BIOM ICB
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   [Anonymous], NETW DISTR SYST SEC
   Arashloo SR, 2017, IEEE ACCESS, V5, P13868, DOI 10.1109/ACCESS.2017.2729161
   Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651
   Biggio B, 2017, IEEE T PATTERN ANAL, V39, P561, DOI 10.1109/TPAMI.2016.2558154
   Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688, DOI 10.1109/BTAS.2017.8272758
   Boulkenafet Z, 2018, IMAGE VISION COMPUT, V77, P1, DOI 10.1016/j.imavis.2018.04.007
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Chingovska I., 2012, BIOSIG
   Chingovska I, 2013, IEEE COMPUT SOC CONF, P98, DOI 10.1109/CVPRW.2013.22
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Edmunds T, 2018, J VIS COMMUN IMAGE R, V50, P314, DOI 10.1016/j.jvcir.2017.12.004
   Edmunds T, 2018, IET BIOMETRICS, V7, P27, DOI 10.1049/iet-bmt.2017.0077
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Jourabloo A., 2018, EUR C COMP VIS ECCV
   Komulainen Jukka, 2012, P AS C COMP VIS, P146
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Li L, 2019, IEEE T INF FOREN SEC, V14, P2246, DOI 10.1109/TIFS.2019.2895212
   Li L, 2018, J VIS COMMUN IMAGE R, V54, P182, DOI 10.1016/j.jvcir.2018.05.009
   Li XY, 2016, IEEE IMAGE PROC, P3573, DOI 10.1109/ICIP.2016.7533025
   Li Y, 2018, IEEE T DEPEND SECURE, V15, P231, DOI 10.1109/TDSC.2016.2550459
   Li Y, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1558, DOI 10.1145/2810103.2813612
   Lin C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P814
   Liu J, 2017, IEEE INT CONF SENS, P1
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Liu ZM, 2008, IEEE T IMAGE PROCESS, V17, P1975, DOI 10.1109/TIP.2008.2002837
   Losson O, 2013, COMPUT VIS IMAGE UND, V117, P747, DOI 10.1016/j.cviu.2013.03.001
   Lu Z, 2017, INT CONF ACOUST SPEE, P1857, DOI 10.1109/ICASSP.2017.7952478
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Peng F, 2019, IEEE ACCESS, V7, P75122, DOI 10.1109/ACCESS.2019.2920713
   Peng F, 2018, 2018 27TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN)
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Pereira TD, 2013, INT CONF BIOMETR
   Qi XB, 2015, IMAGE VISION COMPUT, V43, P16, DOI 10.1016/j.imavis.2015.07.005
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Rehman YAU, 2019, J VIS COMMUN IMAGE R, V59, P574, DOI 10.1016/j.jvcir.2019.02.014
   Rehman YAU, 2018, EXPERT SYST APPL, V108, P159, DOI 10.1016/j.eswa.2018.05.004
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Sepas-Moghaddam A, 2018, IEEE T INF FOREN SEC, V13, P1696, DOI 10.1109/TIFS.2018.2799427
   Shao R, 2019, IEEE T INF FOREN SEC, V14, P923, DOI 10.1109/TIFS.2018.2868230
   Song X, 2019, PATTERN RECOGN, V85, P220, DOI 10.1016/j.patcog.2018.08.019
   Sotoodeh M, 2019, EXPERT SYST APPL, V127, P342, DOI 10.1016/j.eswa.2019.03.020
   Sun ZL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1538, DOI 10.1109/ICASSP.2018.8461942
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wang Y, 2017, J VIS COMMUN IMAGE R, V49, P332, DOI 10.1016/j.jvcir.2017.09.002
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang JW, 2015, IEEE T INF FOREN SEC, V10, P797, DOI 10.1109/TIFS.2015.2403306
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhou Z.-H., 2016, Machine Learning
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 81
TC 22
Z9 23
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102746
DI 10.1016/j.jvcir.2019.102746
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200017
DA 2024-07-18
ER

PT J
AU Singh, J
   Goyal, G
AF Singh, Jaiteg
   Goyal, Gaurav
TI Identifying biometrics in the wild - A time, erosion and neural inspired
   framework for gait identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; OU-ISIR; CASIA; Erosion; Silhouette
ID RECOGNITION
AB This paper evaluates the performance of contemporary gait identification systems. A time, erosion and neural inspired framework (TEN-FE) for gait identification was proposed to augment the performance of gait identification systems. Performance of TEN-FE framework was evaluated using CASIA and OU-ISIR large population dataset. Proposed framework relies on CNN and Reinforcement Learning to restrict the impact of confounding factors like baggage and bulky clothing on the accuracy of gait identification systems. Difference in gait signature due to time was also considered and normalized. The results observed a clear increase in system's performance with minimal complexity and least hardware requirements. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Singh, Jaiteg] Chitkara Univ, Inst Engn & Technol, Dept Comp Applicat, Rajpura 140401, Punjab, India.
   [Goyal, Gaurav] Chitkara Univ, Inst Engn & Technol, Dept Comp Sci & Engn, Rajpura 140401, Punjab, India.
C3 Chitkara University, Punjab; Chitkara University, Punjab
RP Singh, J (corresponding author), Chitkara Univ, Inst Engn & Technol, Dept Comp Applicat, Rajpura 140401, Punjab, India.
EM jaitegkhaira@gmail.com; Gaurav.goyal@chitkara.edu.in
RI Khaira, Jaiteg Singh/AFD-9547-2022
OI Singh, Jaiteg/0000-0002-2370-9384
CR Aggarwal H., 2016, COVARIATE CONSCIOUS
   Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004
   [Anonymous], J COMMUN APPL ELECT
   [Anonymous], PROC BRIT MACH VIS C
   [Anonymous], ARCH PHYS MED
   [Anonymous], SIGNAL IMAGE PROCESS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ADV STUDIES BIOMETRI, DOI DOI 10.1007/114936482
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], INTERSENSORY PERCEPT
   [Anonymous], LECT NOTES INFORM LN
   [Anonymous], 2016 IEEE 26 INT WOR
   [Anonymous], COMMUN APPL ELECT
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Benbow L, 2002, BMC GENOMICS, V3, DOI 10.1186/1471-2164-3-29
   Bouchrika I., 2008, Gait Analysis and Recognition for Automated Visual Surveillance
   Bouchrika I, 2016, MULTIMED TOOLS APPL, V75, P1201, DOI 10.1007/s11042-014-2364-9
   Charalambous C.C., 2016, DATA AUGMENTATION ME, p110.1
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Chen JY, 2014, SCI WORLD J, DOI 10.1155/2014/168275
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Cheng MH, 2008, PATTERN RECOGN, V41, P2541, DOI 10.1016/j.patcog.2007.11.021
   Chhatrala R, 2017, IET COMPUT VIS, V11, P153, DOI 10.1049/iet-cvi.2016.0280
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Condell J, 2018, STUD CONFL TERROR, V41, P151, DOI 10.1080/1057610X.2016.1249777
   Cuntoor N, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P113
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gafurov D, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/415817
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706
   Khamsemanan N, 2018, IEEE T INF FOREN SEC, V13, P119, DOI 10.1109/TIFS.2017.2738611
   Laszio J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P155, DOI 10.1145/237170.237231
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liu ZY, 2005, IEEE T SYST MAN CY B, V35, P170, DOI 10.1109/TSMCB.2004.842251
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   Simon SR, 2004, J BIOMECH, V37, P1869, DOI 10.1016/j.jbiomech.2004.02.047
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Sutherland DH, 2001, GAIT POSTURE, V14, P61, DOI 10.1016/S0966-6362(01)00100-X
   Takemura N, 2019, IEEE T CIRC SYST VID, V29, P2708, DOI 10.1109/TCSVT.2017.2760835
   Tang J, 2017, IEEE T IMAGE PROCESS, V26, P7, DOI 10.1109/TIP.2016.2612823
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   von Tscharner V, 2003, J ELECTROMYOGR KINES, V13, P253, DOI 10.1016/S1050-6411(02)00111-6
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xing XL, 2016, PATTERN RECOGN, V50, P107, DOI 10.1016/j.patcog.2015.08.011
   Xu WJ, 2018, PATTERN RECOGN LETT, V107, P75, DOI 10.1016/j.patrec.2017.10.033
NR 51
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102725
DI 10.1016/j.jvcir.2019.102725
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200008
DA 2024-07-18
ER

PT J
AU Huang, JC
   Huang, HC
   Chu, SH
AF Huang, Jui-Chan
   Huang, Hao-Chen
   Chu, Su-Hui
TI Research on image quality in decision management system and information
   system framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality; Quality model; Decision management; Information system;
   Decision support system
ID LUMP-KINK SOLUTIONS; SOLITON-SOLUTIONS
AB With the continuous development of society and the rapid advancement of science and technology, all walks of life are increasingly required to effectively manage their projects or affairs. Decision-making is the basis of project management, and the formation of decisions determines the formulation of corresponding programs, organizations and businesses. Decision-making is generated by decision makers based on the multi-faceted information they have, so decision management systems and information systems are inseparable in the management of projects and transactions. At present, research on decision management systems emphasizes management and decisions, and few researchers combine decision management and related information. In view of the current research deficiencies, and taking into account the needs of various industries for image applications, this paper introduces image quality evaluation methods, and systematically studies the decision management system and information system framework. The experiment part takes the intelligent image recognition and prevention system of citrus pests and diseases as an example, and the role of image quality in decision management system and information system from the perspective of practice. The results show that through the image quality evaluation system, in the identification and prevention of citrus pests and diseases, it can combine various aspects of information to make effective prevention and control decisions. The results show that the introduction of image quality evaluation can improve the comprehensiveness of information system. On this basis, decision-making system can help decision makers make correct decisions quickly and effectively. (C) 2019 Published by Elsevier Inc.
C1 [Huang, Jui-Chan] Yango Univ, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Hao-Chen] Natl Kaohsiung Univ Sci & Technol, Dept Publ Finance & Taxat, Kaohsiung 80778, Taiwan.
   [Chu, Su-Hui] Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 80778, Taiwan.
C3 National Kaohsiung University of Science & Technology; National
   Kaohsiung University of Science & Technology
RP Chu, SH (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 80778, Taiwan.
EM haochen@nkust.edu.tw; chu889856@gmail.com
CR [Anonymous], 2019, J IMAGE GRAPH, V24
   Chen JC, 2017, APPL MATH LETT, V73, P136, DOI 10.1016/j.aml.2017.05.002
   Cui GZ, 2015, NEUROCOMPUTING, V158, P194, DOI 10.1016/j.neucom.2015.01.048
   Cui HQ, 2012, COMPUT ELECTR ENG, V38, P652, DOI 10.1016/j.compeleceng.2011.10.012
   Feng Chao, 2018, FUTURE DEV
   Fu Y, 2017, DISCRETE CONT DYN-B, V22, P3439, DOI 10.3934/dcdsb.2017174
   Haining Wang, 2016, J ELECT ENG, V11, P30
   Huang YL, 2003, J NEUROVIROL, V9, P21, DOI 10.1080/713831415
   Jing Tian, 2007, COMPUT TECHNOL DEV, V17, P75
   Lai Mingqian, 2017, J KUNMING U SCI TECH, V2, P113
   Leng XN, 2017, J INEQUAL APPL, DOI 10.1186/s13660-017-1418-8
   Li Jiawei, 2017, MASS, V2, P53
   Li Linlin, 2016, INFORM EXPL, V1, P90
   LI WF, 2017, T CHINESE SOC AGR EN, V31, P174, DOI DOI 10.1111/FCP.12255
   Lin Lin, 2004, ANAL DESIGN REGIONAL
   Liu Fang, 2017, RES FAST FEATURE MAT
   Liu YQ, 2017, J NONLINEAR SCI APPL, V10, P4515, DOI 10.22436/jnsa.010.08.43
   Qi Chuanyu, 2017, APPL RES ENTERPRISE
   Qiu Yulian, 2017, FINANCE ACCOUNT NEWS, V7, P107
   Sen Tian, 2017, IND TECHNOL INNOV, V4, P159
   Wang Guohua, 2017, CHINA BUSINESS
   Wang X.R., 2018, SHOCK VIB, V1, P1
   Wu Xingwang, 2017, COMPUT TECHNOL DEV, V27, P159
   Xie Zhongqi, 2016, J HUBEI CORRES U, V29, P55
   Xin YM, 2015, NEUROCOMPUTING, V159, P84, DOI 10.1016/j.neucom.2015.02.017
   Xu Shaoping, 2018, J IMAGE GRAPH, V19, P201
   Xu XX, 2017, J NONLINEAR SCI APPL, V10, P3328, DOI 10.22436/jnsa.010.06.42
   Yan Ming, 2018, CHINA TOWNSHIP ENTER, V07, P292
   Yang JY, 2018, ANAL MATH PHYS, V8, P427, DOI 10.1007/s13324-017-0181-9
   Yao Yanmin, 2007, AREA RES DEV, V26, P112
   Yin Y., 2017, MODERN ELECT TECHNOL, V25, P108
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zeng QT, 2008, J SYST SOFTWARE, V81, P1491, DOI 10.1016/j.jss.2007.09.004
   Zeng QT, 2009, COMPUT EDUC, V53, P809, DOI 10.1016/j.compedu.2009.04.019
   Zhang JB, 2017, COMPUT MATH APPL, V74, P591, DOI 10.1016/j.camwa.2017.05.010
   Zhang XE, 2017, COMPUT MATH APPL, V74, P2341, DOI 10.1016/j.camwa.2017.07.004
   Zhao HQ, 2017, COMPUT MATH APPL, V74, P1399, DOI 10.1016/j.camwa.2017.06.034
NR 37
TC 0
Z9 1
U1 4
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102588
DI 10.1016/j.jvcir.2019.102588
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200020
DA 2024-07-18
ER

PT J
AU Yu, PJ
   Zhao, Y
   Zhang, J
   Xie, XY
AF Yu, Peijia
   Zhao, Yong
   Zhang, Jing
   Xie, Xiaoyao
TI Pedestrian detection using multi-channel visual feature fusion by
   learning deep quality model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural networks; Pedestrian detection; VGG-16 net; RA
   block; Faster R-CNN; Quality model
ID NETWORKS
AB Object detection has been widely applied in modern intelligent systems, especially using convolutional neural networks (CNNs). Pedestrian detection is a key technique in video surveillance, which could automatically locate special pedestrian. However, conventional CNN based methods such as Fast/Faster R-CNN cannot handle pedestrian detection effectively due to the extremely similar of positives and hard negatives. In this paper, in order to solve hard negative problem in pedestrian detection, we incorporate classifier enhancement and representational ability of CNNs. More specifically, we first fuse multi-channel visual features (color, texture, semantic) for quality assessment. Then, we propose "Reduction-adjustment" (RA) block which can enhance feature extraction and can be flexibly embedded into CNNs. In our implementation, we embed RA blocks into a base model such as VGG 16. Afterwards, we apply Faster R-CNN as a detection system to classify and locate pedestrians. Extensive experiments on Caltech, ETH and CityPersons datasets demonstrate that our deep model is feasible and effective for pedestrian detection. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yu, Peijia] Guizhou Univ, Coll Comp Sci & Technol, Guiyang, Guizhou, Peoples R China.
   [Zhao, Yong] Peking Univ, Shenzhen Grad Sch, Key Lab Integrated Microsyst, Shenzhen, Peoples R China.
   [Zhang, Jing] Guizhou Univ, Elect Engn Coll, Guiyang, Guizhou, Peoples R China.
   [Xie, Xiaoyao] Guizhou Normal Univ, Key Lab Informat & Comp Sci Guizhou Prov, Guiyang, Guizhou, Peoples R China.
C3 Guizhou University; Peking University; Guizhou University; Guizhou
   Normal University
RP Xie, XY (corresponding author), Guizhou Normal Univ, Key Lab Informat & Comp Sci Guizhou Prov, Guiyang, Guizhou, Peoples R China.
EM pjyu@gzu.edu.cn; zhaoyong@pkusz.edu.cn; zhangjing@gzu.edu.cn;
   xyx@gznu.edu.cn
FU key program of Guizhou Provincial Development and Reform Commission
   [0502213V0002]; Science and Technology Foundation of Guizhou Province
   [201611036]; Guizhou Province Reform Foundation for Postgraduate
   Education [[2016]02]; Science and Technology Foundation of Guizhou
   [J[2012]2135]; Natural Science Foundation of Shenzhen
   [JCYJ20160506172651253]; National Science and Technology Support Program
   [2015BAK01604]; Science and Technology Program of Shenzhen
   [JCYJ20170306091531561]
FX The work in this paper is supported in part by the key program of
   Guizhou Provincial Development and Reform Commission under Grant
   0502213V0002, in part by the Science and Technology Foundation of
   Guizhou Province under Grant [201611036, in part by the Guizhou Province
   Reform Foundation for Postgraduate Education under Grant [2016]02, in
   part by the Science and Technology Foundation of Guizhou under Grant
   J[2012]2135, in part by the Natural Science Foundation of Shenzhen under
   Grant JCYJ20160506172651253, in part by the National Science and
   Technology Support Program under Grant 2015BAK01604, in part by the
   Science and Technology Program of Shenzhen under Grant
   JCYJ20170306091531561.
CR [Anonymous], 1996, Learning and Example Selection for Object and Pattern Detection
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen HX, 2013, MECH SYST SIGNAL PR, V40, P469, DOI 10.1016/j.ymssp.2013.06.023
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cui YJ, 2013, FIXED POINT THEORY A, DOI 10.1186/1687-1812-2013-345
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Geng L, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.033020
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Keller CG, 2011, IEEE T INTELL TRANSP, V12, P1096, DOI 10.1109/TITS.2011.2143410
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Kwon SK, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.11.113112
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Ouyang WL, 2018, IEEE T PATTERN ANAL, V40, P1874, DOI 10.1109/TPAMI.2017.2738645
   Ouyang WL, 2016, INT J COMPUT VISION, V120, P14, DOI 10.1007/s11263-016-0890-9
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shirazi MS, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.051203
   Simonyan K., 2014, 14091556 ARXIV
   Sun JX, 2013, FIXED POINT THEOR-RO, V14, P185
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang Z, 2012, NEUROCOMPUTING, V83, P83, DOI 10.1016/j.neucom.2011.11.018
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200491
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhang ZY, 2014, IEEE T NEUR NET LEAR, V25, P1704, DOI 10.1109/TNNLS.2013.2288943
NR 46
TC 5
Z9 5
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102579
DI 10.1016/j.jvcir.2019.102579
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200008
DA 2024-07-18
ER

PT J
AU Xu, JH
   Cai, C
   Ning, JF
   Li, YS
AF Xu, Jiahong
   Cai, Cheng
   Ning, Jifeng
   Li, Yunsong
TI Robust correlation filter tracking via context fusion and subspace
   constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Correlation filter; Context fusion; Subspace
   constraint; Model update
ID VISUAL TRACKING; OBJECT TRACKING
AB In the trackers based on correlation filter, the limitation of tracking samples and the efficiency of the solution affect the performance of the trackers. Based on the Discriminative Scale Space Tracking(DSST), we proposed a new framework to improve correlation filter tracking via context fusion and subspace constraint. First, the target and background are jointly modeled to enhance the ability to distinguish between target and background. Second, to achieve higher robustness, subspace constraint is applied to DSST, and it can be solved efficiently by subspace-based alternating direction method of multipliers(SADMM). Finally, through the model update strategy, high-quality samples are selected to update. The proposed algorithm is validated on the OTB2013, OTB2015 and TC128. Experimental results show that compared with fast DSST(fDSST), success rate and accuracy of the proposed method are increased by 4.2% and 6.8% respectively. Compared with the state-of-the-art trackers, the proposed method achieves a competitive result with real-time speed. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xu, Jiahong; Cai, Cheng; Ning, Jifeng] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Xu, Jiahong; Ning, Jifeng; Li, Yunsong] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
C3 Northwest A&F University - China; Xidian University
RP Ning, JF (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM njf@nwsuaf.edu.cn
RI xu, jiahong/I-7302-2012
FU National Natural Science Foundation of China [61876153, 31501228]; State
   Key Laboratory of Integrated Services Networks Foundation [ISN17-08]
FX This work is supported by the National Natural Science Foundation of
   China under Grants 61876153, 31501228 and by the State Key Laboratory of
   Integrated Services Networks Foundation (ISN17-08).
CR [Anonymous], 2003, KALMAN FILTER PARTIC
   [Anonymous], 2016, ARXIV160106032
   [Anonymous], 2016, CVPR
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G., 2018, P EUR C COMP VIS ECC, P483
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chang M.-W., 2007, P 45 ANN M ASS COMPU, P280
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Collins R. T., 2003, P IEEE C COMP VIS PA, P11
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, P BRIT MACH VIS C
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Duffner S., 2015, IEEE T CIRCUITS SYST, P1
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lan L, 2018, IEEE T IMAGE PROCESS, V27, P4585, DOI 10.1109/TIP.2018.2843129
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li F, 2017, IEEE INT CONF COMP V, P2001, DOI 10.1109/ICCVW.2017.234
   Li F, 2016, IEEE T CIRC SYST VID, V26, P1697, DOI 10.1109/TCSVT.2015.2469171
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Song HH, 2017, ELECTRON LETT, V53, P20, DOI 10.1049/el.2016.3011
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang X, 2018, PROC CVPR IEEE, P4864, DOI 10.1109/CVPR.2018.00511
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yang TY, 2017, IEEE INT CONF COMP V, P2010, DOI 10.1109/ICCVW.2017.235
   Zhang BC, 2018, IEEE T IMAGE PROCESS, V27, P1038, DOI 10.1109/TIP.2017.2775060
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
   Zhang HL, 2015, IEEE SIGNAL PROC LET, V22, P1350, DOI 10.1109/LSP.2015.2404856
   Zhang KH, 2018, PATTERN RECOGN, V81, P147, DOI 10.1016/j.patcog.2018.03.029
   Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
NR 57
TC 4
Z9 4
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 182
EP 192
DI 10.1016/j.jvcir.2019.05.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600017
DA 2024-07-18
ER

PT J
AU Zhang, MH
   Zhang, FQ
   Liu, QG
   Wang, SS
AF Zhang, Minghui
   Zhang, Fengqin
   Liu, Qiegen
   Wang, Shanshan
TI VST-Net: Variance-stabilizing transformation inspired network for
   Poisson denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Poisson noise reduction; Deep learning; Variance-stabilizing
   transformation; Joint learning; Two-stage learning
ID ANSCOMBE TRANSFORMATION; OPTIMAL INVERSION; IMAGE; NOISE
AB Poisson noise occurs in various applications including medical imaging and night vision. There exist many traditional Poisson denoising algorithms, particularly, one class of impressive algorithm is based on variance-stabilizing transformation (VST). Inspired by the traditional VST scheme, in this paper we propose a novel Poisson denoising model based on convolutional neural network, called variance-stabilizing transform network (VST-Net). VST-Net inherits the structures and strengths of the traditional VST scheme via optimizing the nonlinear transformation by means of network design and supervised learning. The whole VST-Net network contains three sub-networks. The first and third sub-networks simulate the forward and inverse Anscombe transforms, respectively, Meanwhile, the second sub-network is devoted to playing the role of approximate Gaussian denoising. Joint learning strategy and two-stage progressive learning strategy are exploited to investigate the rationality and strength of the VST scheme. Experimental results verify the great potential of the VST-driven network. Code is available at: https://github.com/yqx7150/VST-Net. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Minghui; Zhang, Fengqin; Liu, Qiegen] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Wang, Shanshan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen 518055, Peoples R China.
C3 Nanchang University; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS
RP Liu, QG (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.; Wang, SS (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen 518055, Peoples R China.
EM zhangminghui@ncu.edu.cn; zhangfengqin@email.ncu.edu.cn;
   liuqiegen@ncu.edu.cn; sophiasswang@hotmail.com
RI Li, Yuanyuan/J-3539-2014; Wang, Shanshan/T-6972-2017
OI Li, Yuanyuan/0000-0001-6151-9306; Wang, Shanshan/0000-0002-0575-6523
FU National Natural Science Foundation of China [61871206, 61661031,
   61463035, 61601450]; Natural Science Foundation of Jiangxi Province
   [20181BAB202003]; Key Scientist Plan of Jiangxi Province, China
   [20171BBH80023]
FX The authors sincerely thank the anonymous reviewers for their valuable
   comments and constructive suggestions that are very helpful in the
   improvement of this paper. This work was supported in part by the
   National Natural Science Foundation of China under 61871206, 61661031,
   61463035, 61601450, the Natural Science Foundation of Jiangxi Province
   (20181BAB202003), and the Key Scientist Plan of Jiangxi Province, China
   (20171BBH80023).
CR [Anonymous], 2017, CVPR WORKSH
   [Anonymous], 2017, CVPR
   [Anonymous], 1993, P S APPL MATH, DOI DOI 10.1090/PSAPM/047/1268002
   [Anonymous], 2017, ARXIV170709135
   [Anonymous], 2016, CVPR
   ANSCOMBE FJ, 1948, BIOMETRIKA, V35, P246, DOI 10.2307/2332343
   Azzari L, 2016, IEEE SIGNAL PROC LET, V23, P1086, DOI 10.1109/LSP.2016.2580600
   Bae Woong, 2017, CVPR WORKSH
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Deledalle CA, 2010, IEEE IMAGE PROC, P801, DOI 10.1109/ICIP.2010.5653394
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dupé FX, 2009, IEEE T IMAGE PROCESS, V18, P310, DOI 10.1109/TIP.2008.2008223
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Foi A., 2005, P IEEE INT C IM PROC, V1, pI
   Fryzlewicz P, 2004, J COMPUT GRAPH STAT, V13, P621, DOI 10.1198/106186004X2697
   Giryes R, 2014, IEEE T IMAGE PROCESS, V23, P5057, DOI 10.1109/TIP.2014.2362057
   Harmany ZT, 2012, IEEE T IMAGE PROCESS, V21, P1084, DOI 10.1109/TIP.2011.2168410
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Le T, 2007, J MATH IMAGING VIS, V27, P257, DOI 10.1007/s10851-007-0652-y
   Lefkimmiatis S, 2009, IEEE T IMAGE PROCESS, V18, P1724, DOI 10.1109/TIP.2009.2022008
   Luisier F, 2010, SIGNAL PROCESS, V90, P415, DOI 10.1016/j.sigpro.2009.07.009
   Mäkitalo M, 2013, IEEE T IMAGE PROCESS, V22, P91, DOI 10.1109/TIP.2012.2202675
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nowak RD, 2000, IEEE T INFORM THEORY, V46, P1811, DOI 10.1109/18.857793
   Salmon J, 2012, INT CONF ACOUST SPEE, P1109, DOI 10.1109/ICASSP.2012.6288081
   Salmon J, 2014, J MATH IMAGING VIS, V48, P279, DOI 10.1007/s10851-013-0435-6
   Starck JL, 2001, IEEE SIGNAL PROC MAG, V18, P30, DOI 10.1109/79.916319
   Timmermann KE, 1999, IEEE T INFORM THEORY, V45, P846, DOI 10.1109/18.761328
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Willett RM, 2007, IEEE T INFORM THEORY, V53, P3171, DOI 10.1109/TIT.2007.903139
   Willett RM, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1192
   Willett RM, 2003, IEEE T MED IMAGING, V22, P332, DOI 10.1109/TMI.2003.809622
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P1093, DOI 10.1109/TIP.2008.924386
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 37
TC 18
Z9 20
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 12
EP 22
DI 10.1016/j.jvcir.2019.04.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600002
DA 2024-07-18
ER

PT J
AU Zhang, WJ
   Yao, YY
   Wang, JX
   Xiang, XY
   Shu, P
AF Zhang, Wenjie
   Yao, Yiyang
   Wang, Jinxiong
   Xiang, Xinyu
   Shu, Peng
TI RETRACTED: Image quality tendency modeling by fusing multiple visual
   cues (Retracted article. See vol. 69, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Machine learning; Multi-cue fusion; Aesthetic tendency; Flickr; Graph
   mining
ID SEGMENTATION; COMMUNITIES
AB Flickr is a photo/video hosting site with over 87 million user. Upload more than 3 million 500 thousand new photos every day at present there are no tools to organize these huge numbers of users aesthetic tendency. Although Flickr allows users manually adding different groups, they are difficult to maintain Updates should be made when new users are added or deleted. In this paper puts forward a series of Flickr users system. Each loop contains similar users aesthetic tendency. We observed: (1) an aesthetic model of thought should be flexible, because of different visual features typically represent different data sets, and (2) Significant differences in the number of photos from different Flickr users stay. In this work, a new probabilistic topic model is proposed describe the aesthetic interest of each Flickr user potential spatial distribution. After that, an affinity graph is similarity is described by aesthetics interests of Flickr users. Obviously, intensive users of Flickr are similar in taste. Thus, these users are divided into different Flickr bounds efficient dense graph discovery. Piping it is proposed that the Flickr bound discovery is fully automatic. Extensive we show that our proposed method is accurate for mine Flickr experiments 60,000 Flickr user community. (C) 2018 Published by Elsevier Inc.
C1 [Zhang, Wenjie; Yao, Yiyang] State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Jinxiong] State Grid Corp China, ICT Dept, Beijing, Peoples R China.
   [Xiang, Xinyu] State Grid Hangzhou Power Supply Co, Hangzhou, Zhejiang, Peoples R China.
   [Shu, Peng] State Grid Zhejiang Elect Power Res Inst, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China; State Grid Corporation of China; State
   Grid Corporation of China
RP Yao, YY (corresponding author), State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
EM yiyangyao156@sohu.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2010, ACM MULTIMEDIA
   [Anonymous], 2007, NUMERICAL RECIPES, V3rd
   Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189
   Bukal M, 2014, INFORM FUSION, V20, P136, DOI 10.1016/j.inffus.2014.01.003
   CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E
   Chen Y, 2014, INFORM FUSION, V20, P292, DOI 10.1016/j.inffus.2014.03.007
   Chen YW., 2005, Combining SVMs with Various Feature Selection Strategies
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Erlandsson T, 2014, INFORM FUSION, V20, P88, DOI 10.1016/j.inffus.2013.12.001
   Feng ZP, 2010, MECHANICAL ENGINEERING AND GREEN MANUFACTURING, PTS 1 AND 2, P671, DOI 10.4028/www.scientific.net/AMM.34-35.671
   Frank M, 2012, J MACH LEARN RES, V13, P459
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Fu C, 2014, INFORM FUSION, V17, P22, DOI 10.1016/j.inffus.2011.12.002
   Gao XH, 2017, INFORM FUSION, V36, P103, DOI 10.1016/j.inffus.2016.11.007
   Govaert G., 2007, IEEE T PAMI, V27, P643
   Govaert Gerard, 2013, COCLUSTERING MODELS
   Gregory S, 2008, LECT NOTES ARTIF INT, V5211, P408, DOI 10.1007/978-3-540-87479-9_45
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Herrera-Viedma E, 2014, INFORM FUSION, V17, P4, DOI 10.1016/j.inffus.2013.04.002
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Huang ZH, 2015, INFORM FUSION, V22, P95, DOI 10.1016/j.inffus.2014.06.001
   Jiang L, 2015, INFORM FUSION, V22, P85, DOI 10.1016/j.inffus.2014.06.002
   Kimura A., 2013, ACM MULTIMEDIA
   Kuhn H., 1956, NAVAL RES LOGIST Q, V3, P253, DOI [10.1002/nav.3800030404, https://doi.org/10.1002/nav.3800030404, DOI 10.1002/NAV.3800030404]
   Lancichinetti A, 2008, PHYS REV E, V78, DOI 10.1103/PhysRevE.78.046110
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Mahoney Michael, 2010, P 19 INT C WORLD WID, P631, DOI DOI 10.1145/1772690.1772755
   Mignotte M, 2014, INFORM FUSION, V20, P7, DOI 10.1016/j.inffus.2013.10.012
   Negoescu RA, 2010, IEEE T MULTIMEDIA, V12, P399, DOI 10.1109/TMM.2010.2050649
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Nishiyama M., 2009, P 17 ACM INT C MULTI, P669
   Ochoa SF, 2015, INFORM FUSION, V22, P71, DOI 10.1016/j.inffus.2013.05.009
   Papadimitriou S, 2008, LECT NOTES ARTIF INT, V5212, P170, DOI 10.1007/978-3-540-87481-2_12
   Poslad S, 2014, INFORM FUSION, V20, P225, DOI 10.1016/j.inffus.2014.02.003
   Shi Y, 2014, INFORM FUSION, V20, P213, DOI 10.1016/j.inffus.2014.02.005
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Tang X. T., 2014, ACM TIST, V5
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Yan XQ, 2015, INFORM FUSION, V22, P26, DOI 10.1016/j.inffus.2013.08.006
   Yang J, 2012, IEEE DATA MINING, P1170, DOI 10.1109/ICDM.2012.139
   Yang TB, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P927
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yin XC, 2014, INFORM FUSION, V20, P49, DOI 10.1016/j.inffus.2013.11.003
   Yoshida T, 2010, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2010.5651018
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang GQ, 2014, INFORM FUSION, V17, P46, DOI 10.1016/j.inffus.2012.01.006
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
NR 52
TC 1
Z9 1
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 117
EP 128
DI 10.1016/j.jvcir.2018.12.046
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600011
DA 2024-07-18
ER

PT J
AU Chen, YX
   Tan, HD
   Zhang, LM
   Zhou, J
   Lu, Q
AF Chen, Yanxiang
   Tan, Huadong
   Zhang, Luming
   Zhou, Jie
   Lu, Qiang
TI Hybrid image super-resolution using perceptual similarity from
   pre-trained network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Hybrid method; Adaptive weight; Pre-trained VGG
   network
ID OBJECT DETECTION; DEEP
AB The goal of super-resolution (SR) is to recover a high-resolution (HR) image from its corresponding low-resolution (LR) image. It is an ill-posed problem. Most recent methods are based on external training data. They can reconstruct pleasing HR results, especially when the input patch has a similar counterpart within the training dataset. Other methods are driven by self-similarity and are called internal methods. They can produce visually plausible HR images when the input images contain abundant regular structures. In this paper, we propose a hybrid method for image SR that exploits the complementary advantages of external and internal SR methods. Each input LR patch is first super-resolved using convolutional neural network (CNN) for external SR and self-similarity for internal SR. Then, we calculate the perceptual similarity between the feature representations from the pre-trained VGG network to learn an adaptive weight. Finally, our algorithm automatically selects the optimal method on the basis of the calculated adaptive weight. The experimental results of our visual and quantitative evaluations verify the effectiveness of the proposed method, by comparing it with state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Yanxiang; Tan, Huadong; Zhou, Jie; Lu, Qiang] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
   [Zhang, Luming] Zhejiang Univ, Coll Comp Sci, Hangzhou 310007, Zhejiang, Peoples R China.
C3 Hefei University of Technology; Zhejiang University
RP Tan, HD (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM Tanhuadong@hotmail.com
RI Lei, Ming/JAD-1050-2023; zhang, lu/GRO-2969-2022; Lu,
   Qiang/AAU-9248-2020
OI Chen, Yanxiang/0000-0002-1163-7926
FU National Nature Science Foundation of China [61672201]; Key Projects of
   Anhui Province Science and Technology Plan [15czz02074]
FX This work was partially supported by National Nature Science Foundation
   of China (61672201), and Key Projects of Anhui Province Science and
   Technology Plan (15czz02074).
CR [Anonymous], IEEE T SYST MAN CYBE
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bevilacqua M., 2012, LOWCOMPLEXITY SINGLE
   Capel David, 2004, OCEANS IEEE, V2, P653
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dai D, 2015, COMPUT GRAPH FORUM, V34, P95, DOI 10.1111/cgf.12544
   Dong C., 2014, LEARNING DEEP CONVOL
   Ebrahimi M., 2007, SOLVING INVERSE PROB
   Fang YM, 2017, IEEE T SYST MAN CY-S, V47, P2956, DOI 10.1109/TSMC.2016.2557225
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freedman G, 2011, ACM T GRAPHIC, V30, P474
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   HaCohen Y., 2010, ICCP, P1
   Han J., 2005, IEEE T CIRCUITS SYST, V16, P141
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hong R., 2016, IEEE T BIG DATA, V1, P152
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Singh A., 2014, SUPER RESOLUTION USI
   Singh A, 2014, INT C PATT RECOG, P4447, DOI 10.1109/ICPR.2014.761
   Sun JA, 2010, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2010.5540206
   Sun L, 2012, INT C COMP PHOT, P1, DOI DOI 10.1109/ICCPHOT.2012.6215221
   Timofte R., 2014, A ADJUSTED ANCHORED
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39
   Yang J, 2008, PROC CVPR IEEE, P173
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WB, 2018, IEEE T SYST MAN CY-S, V48, P755, DOI 10.1109/TSMC.2016.2616490
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 48
TC 1
Z9 1
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 229
EP 235
DI 10.1016/j.jvcir.2019.02.022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000025
DA 2024-07-18
ER

PT J
AU Xu, YJ
   Meng, PY
   Chen, JG
AF Xu, Yuanjin
   Meng, Pengyan
   Chen, Jianguo
TI Study on clues for gold prospecting in the Maizijing-Shulonggou area,
   Ningxia Hui autonomous region, China, using ALI, ASTER and WorldView-2
   imagery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Remote sensing; Mineral prospecting; Fracture; Hydrothermal alteration;
   Gold mineralization; Maizijing-Shulonggou area
ID HEAVY MINERALS; OBJECT DETECTION; DEEP; DISCRIMINATION; EXPLORATION;
   EXTRACTION; PROVENANCE; SEDIMENTS; HYPERION; DEPOSITS
AB Several gold occurrences have been discovered in the Maizijing-Shulonggou area, Ningxia Hui autonomous region, China. The clues for gold prospecting in this area may relate to fractures and hydrothermal alterations, but it is very difficult to conduct a field investigation on the clues because of the alpine valleys. To explore the clues for gold prospecting, this study extracted geological information related to fracture zones and hydrothermal alterations using ALI, ASTER, and WorldView-2 data, and subsequently, explored potential relationships between extracted geological characteristics and gold mineralization. The WorldView-2 image in the study area was used for fracture interpretation. The azimuth and density of linear fractures were investigated, and the results showed that linear fractures with NE direction were most common, the gold occurrences except Au2 were all located in NE fracture zones, and all gold occurrences located in high fracture density areas (level 1-3 areas) where NE and NW fractures were the most common observations. This suggests that the high fracture density and NE and NW fractures are important indicators of potential gold mineralization. Hydrothermal alteration minerals in exposed bedrocks were mapped using ALI and ASTER imagery. Based on the spectral analysis, ASTER image in the study area were used to map quartz, illite and chlorite, while ALI image were used to map limonite. The spatial distribution of alteration minerals revealed regional specific alteration mineral in gold mineralization. In the northern Maizijing region, the composition of alteration mineral in the surrounding of Aul was overwhelmed by quartz, while the alteration minerals in the surrounding of Aug-4 were dominated by limonite in the southern Shulonggou region, which showed different indicator minerals for gold prospecting in the two regions. As a result, the key areas for prospecting are the NE and NW fracture zones with quartz veins in the Maizijing region and the NE and NW fracture zones with limonitization in the Shulonggou region. In the Shulonggou region, pyrite in buried quartz-pyritization belt and illitization-pyritization belt is likely to be the precursor of limonite. Heavy mineral assemblages were analyzed for native gold content, and the results suggested high native gold content in the illitization-pyritization belt, followed by quartz-pyritization belt, which was consistent with the strong association of limonite and gold mineralization, thus the two belts shall be prioritized for gold prospecting in the Shulonggou region. (C) 2019 Published by Elsevier Inc.
C1 [Xu, Yuanjin; Chen, Jianguo] China Univ Geosci, Fac Earth Resources, Inst Math Geol & Remote Sensing Geol, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
   [Meng, Pengyan] Hubei Inst Land Surveying & Mapping, 199 Aomen Rd, Wuhan 430010, Hubei, Peoples R China.
C3 China University of Geosciences
RP Xu, YJ; Chen, JG (corresponding author), China Univ Geosci, Fac Earth Resources, Inst Math Geol & Remote Sensing Geol, 388 Lumo Rd, Wuhan 430074, Hubei, Peoples R China.
EM xuyj@cug.edu.cn; meng_pengyan@sina.com; jgchen@cug.edu.cn
RI Chen, Jianguo/P-6979-2019
OI Chen, Jianguo/0000-0001-5009-578X
FU National Natural Science Foundation of China [41872252]; National Key
   R&D Program of China [2017YFC0601504, 2017YFC0601500]
FX This study was financially supported by the National Natural Science
   Foundation of China (No. 41872252), and the National Key R&D Program of
   China (Nos. 2017YFC0601504 and 2017YFC0601500).
CR Amer R, 2012, ADV SPACE RES, V49, P121, DOI 10.1016/j.asr.2011.09.024
   Azizi H, 2010, ADV SPACE RES, V46, P99, DOI 10.1016/j.asr.2010.03.014
   Bedini E, 2011, ADV SPACE RES, V47, P60, DOI 10.1016/j.asr.2010.08.021
   Boardman J. W., 1995, JPL PUBLICATION, V95-1, P23
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Crósta AP, 2003, INT J REMOTE SENS, V24, P4233, DOI 10.1080/0143116031000152291
   CSILLAG F, 1987, J GEODYN, V8, P205, DOI 10.1016/0264-3707(87)90038-X
   Di Tommaso I, 2007, ORE GEOL REV, V32, P275, DOI 10.1016/j.oregeorev.2006.05.004
   Dill HG, 2014, ORE GEOL REV, V57, P29, DOI 10.1016/j.oregeorev.2013.08.023
   Farrand WH, 1997, REMOTE SENS ENVIRON, V59, P64, DOI 10.1016/S0034-4257(96)00080-6
   Fujisada H, 1995, P SOC PHOTO-OPT INS, V2583, P16, DOI 10.1117/12.228565
   Gabr S, 2010, ORE GEOL REV, V38, P59, DOI 10.1016/j.oregeorev.2010.05.007
   Gabr SS, 2015, ORE GEOL REV, V71, P1, DOI 10.1016/j.oregeorev.2015.04.021
   Galvao LS, 2005, INT J APPL EARTH OBS, V7, P107, DOI 10.1016/j.jag.2004.12.003
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   Hubbard BE, 2005, REMOTE SENS ENVIRON, V99, P173, DOI 10.1016/j.rse.2005.04.027
   Hubbard BE, 2003, IEEE T GEOSCI REMOTE, V41, P1401, DOI 10.1109/TGRS.2003.812906
   Krippner A, 2016, SEDIMENT GEOL, V336, P96, DOI 10.1016/j.sedgeo.2015.09.009
   Le Garzic E, 2011, J STRUCT GEOL, V33, P519, DOI 10.1016/j.jsg.2011.01.012
   Mange M. A., 2007, DEV SEDIMENTOL, V58, P1329
   Moore F, 2008, INT J REMOTE SENS, V29, P2851, DOI 10.1080/01431160701418989
   Morton A, 2010, SOC SEDIMENT GEOL SP, V94, P183
   Okay N, 2005, MAR GEOL, V216, P1, DOI 10.1016/j.margeo.2005.01.006
   Pour AB, 2011, J ASIAN EARTH SCI, V42, P1309, DOI 10.1016/j.jseaes.2011.07.017
   Robinson TP, 2016, INT J APPL EARTH OBS, V44, P23, DOI 10.1016/j.jag.2015.07.004
   Rowan LC, 2006, REMOTE SENS ENVIRON, V104, P74, DOI 10.1016/j.rse.2006.05.014
   Rowan LC, 2003, REMOTE SENS ENVIRON, V84, P350, DOI 10.1016/S0034-4257(02)00127-X
   Salama W, 2016, ORE GEOL REV, V72, P485, DOI 10.1016/j.oregeorev.2015.07.014
   [施海鹏 Shi Haipeng], 2015, [地质科技情报, Geological Science and Techology Information], V34, P71
   Tan J., 2013, GOLD, V34, P9
   Thamó-Bozsó E, 2014, QUATERN INT, V319, P11, DOI 10.1016/j.quaint.2013.04.030
   van der Meer FD, 2012, INT J APPL EARTH OBS, V14, P112, DOI 10.1016/j.jag.2011.08.002
   von Eynatten H, 2012, EARTH-SCI REV, V115, P97, DOI 10.1016/j.earscirev.2012.08.001
   [王大钊 Wang Dazhao], 2017, [大地构造与成矿学, Geotectonica et Metallogenia], V41, P491
   Wong FL, 2013, MAR GEOL, V345, P170, DOI 10.1016/j.margeo.2013.05.012
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 46
TC 4
Z9 5
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 192
EP 205
DI 10.1016/j.jvcir.2019.02.011
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000022
DA 2024-07-18
ER

PT J
AU Chen, ZB
   Shi, K
   Chen, N
   Shi, L
   Zhuang, XY
   Zhou, JQ
   Zhang, YS
   Wang, HQ
   Liu, XY
   Li, GN
AF Chen, Zhaobing
   Shi, Kui
   Chen, Ning
   Shi, Long
   Zhuang, Xinyu
   Zhou, Jiaqi
   Zhang, Yushuai
   Wang, Hongqi
   Liu, Xingyang
   Li, Guannan
TI The experimental study about laser-induced dizziness effect of
   medium-wave infrared seeker which based on image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Laser dizziness interference; Medium wave infrared
   detector; Photoelectric interference
AB In view of the problem of laser dizzy interference of medium-wave infrared seeker detector in the field of photoelectric confrontation, there is a lack of equidistant distance test to verify the problem. In this paper, a medium-wave infrared seeker for short-range precision guided missile CCD detector was used as the subject, and the 3.8 mu m wavelength medium wave laser was used as the laser source to study the calibration of the laser. In the experiment, two locations with a viewing distance of 14.5 km were selected to place the laser and missile seeker detectors respectively. The atmospheric transmittance was estimated using the MODTRAN software based on the meteorological parameters provided by the simple meteorological monitoring tool. Under the different target power density conditions, the simulation of the missile seeker head of the interference of the dizzy effect. By analyzing the interference images in the tracking state, the corresponding qualitative and quantitative dizziness interference results are obtained. After the calculation and analysis, it is considered that the laser energy output from the mid wave infrared laser is 0.08 mW/m(2) when the power density of the target surface of the detector is 0.08 mW/m(2), respectively, under medium meteorological conditions with a visibility of 0.625. Box cannot lock the original target, there cannot effectively extract the target dizzy effect. The experimental results show that the anti-jamming ability of the anti-jamming capability of the medium-wave infrared precision guidance probe is verified by the photoelectric countermeasure, and it is considered that the dodge power density is smaller when the interference laser wavelength matches the wavelength of the seeker detector. The experimental data can provide theoretical guidance for the inversion and determination of parameters in the study of the medium wave infrared photoelectric countermeasure. (C) 2018 Published by Elsevier Inc.
C1 [Chen, Zhaobing; Shi, Kui; Chen, Ning; Shi, Long; Zhuang, Xinyu; Zhou, Jiaqi; Zhang, Yushuai; Wang, Hongqi; Liu, Xingyang; Li, Guannan] Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Changchun 130033, Jilin, Peoples R China.
C3 Chinese Academy of Sciences; Changchun Institute of Optics, Fine
   Mechanics & Physics, CAS
RP Li, GN (corresponding author), Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Changchun 130033, Jilin, Peoples R China.
EM chenzhaobing2010@163.com; liguannan2018@163.com
RI Zhuang, Xinyu/KQU-2437-2024
CR Abidur R.M., 2014, IEEE 2014 17 INT C C, P358
   Chen GL, 2017, IEEE T SIGNAL PROCES, V65, P5716, DOI 10.1109/TSP.2017.2740198
   Chen WT, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2016.259
   Chen Zhaobing, 2013, Infrared and Laser Engineering, V42, P1700
   Chu X.L., 2011, INFRARED TECHNOL, V33, P449
   [初学莲 CHU Xuelian], 2011, [红外技术, Infrared Technology], V33, P440
   Gorur P., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P386, DOI 10.1109/AVSS.2011.6027356
   Harput S, 2014, IEEE INT ULTRA SYM, P440, DOI 10.1109/ULTSYM.2014.0109
   Hewish M., 1998, JANES INT DEF REV, V1, P35
   Larochelle V, 1999, P SOC PHOTO-OPT INS, V3698, P229, DOI 10.1117/12.354524
   [李海燕 Li Haiyan], 2010, [红外与激光工程, Infrared and Laser engineering], V39, P1038
   Liu T.W., 2010, TRANSDUCER MICROSYST, V29, P34
   Maguid E, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2017.27
   Merritt P, 1997, PROC SPIE, V3086, P2, DOI 10.1117/12.277173
   Pollak C, 2001, MICROSC MICROANAL, V7, P335, DOI 10.1007/s10005-001-0007-1
   Psillakis HE, 2017, IEEE T AUTOMAT CONTR, V62, P3993, DOI 10.1109/TAC.2016.2616645
   Psilodimitrakopoulos S, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/lsa.2018.5
   Sun W, 2017, IEEE T PATTERN ANAL, V39, P1401, DOI 10.1109/TPAMI.2016.2598344
   [王世勇 Wang Shiyong], 2002, [光学技术, Optical technology], V28, P28
   Wang VT, 2017, IEEE J OCEANIC ENG, V42, P901, DOI 10.1109/JOE.2016.2634078
   Wang Zhi, 2005, RES MULTIFRAME POSTP
   Xuehua Song, 2010, 2010 Proceedings of International Conference on Artificial Intelligence and Computational Intelligence (AICI 2010), P54, DOI 10.1109/AICI.2010.134
   Zhang Z, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2016.231
NR 23
TC 12
Z9 12
U1 1
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 401
EP 406
DI 10.1016/j.jvcir.2018.12.044
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600042
DA 2024-07-18
ER

PT J
AU Tang, JJ
   Qian, WJ
   Zhao, ZJ
   Liu, WL
   He, P
AF Tang, Jinjiang
   Qian, Weijie
   Zhao, Zhijun
   Liu, Weiliang
   He, Ping
TI Multi-view non-negative matrix factorization for scene recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-negative matrix factorization; Scene recognition; Multi-view
ID OBJECT RECOGNITION
AB Accurately discriminating complicated sceneries from different categories is a useful technique in multimedia and computer vision. In this work, we propose a novel multi-view non-negative matrix factorization to detect human gaze behavior, which is subsequently integrated into an image kernel machine for scene categorization. More specifically, we first project regions from each scenery into the so-called perceptual space, which is established by combining color, texture, and semantic features. Then, a novel non-negative matrix factorization (NMF) algorithm is developed which decomposes the regions' feature matrix into the product of the basis matrix and the sparse codes. The sparse codes indicate the saliency level of different regions which is used to constructed gaze shifting path. Thereby, the path from each scenery is derived and further incorporated into an image kernel for scene categorization. Comprehensive experiments on six scenery data sets have demonstrated the superiority of our method over a series of recognition models. (C) 2018 Published by Elsevier Inc.
C1 [Tang, Jinjiang; Qian, Weijie; Zhao, Zhijun; Liu, Weiliang; He, Ping] State Grid Zhejiang Jiaxing Elect Power Supply Co, Jiaxing, Peoples R China.
RP Tang, JJ (corresponding author), State Grid Zhejiang Jiaxing Elect Power Supply Co, Jiaxing, Peoples R China.
EM jinjiangtang66@163.com; qian_weijie@zj.sgcc.com.cn;
   zhao_zhijun@zj.sgcc.com.cn; liu_weiliang@zj.sgcc.com.cn;
   he_ping@zj.sgcc.com.cn
RI Zhao, Zhi-jun/AAE-9577-2020; He, Ping/H-5712-2013
CR [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Carcassoni Marco, 2003, CORRES MATCHING MODA, P1609
   Chen JY, 2018, LECT NOTES COMPUT SC, V10705, P327, DOI 10.1007/978-3-319-73600-6_28
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng Z., 2016, SIGIR
   Cheng Z., MMM 2013 FORM MULTIM
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y
   Everingham M., 2009, The PASCAL Visual Object Classes Challenge 2009 (VOC) Results
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb P.F., 2005, International Journal of Computer Vision
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Todorovic S, 2008, INT J COMPUT VISION, V78, P47, DOI 10.1007/s11263-007-0077-5
   Triggs B., 2005, HISTOGRAMS ORIENTED, P886
   WANG CH, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P440, DOI 10.1109/ICCV.1995.466906
   Wang X, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.208
   Xu YW, 2004, COMPUT VIS IMAGE UND, V95, P334, DOI 10.1016/j.cviu.2004.04.003
   Yao Benjamin, 2007, ENERGY MINIMIZATION
NR 33
TC 2
Z9 3
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 9
EP 13
DI 10.1016/j.jvcir.2018.12.040
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600002
DA 2024-07-18
ER

PT J
AU Yang, JJ
   Wan, LL
   Xu, WR
   Wang, SH
AF Yang, Jingjing
   Wan, Lili
   Xu, Wanru
   Wang, Shenghui
TI 3D human pose estimation from a single image via exemplar augmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human pose estimation; Human pose recovery; Exemplar-based; Pose
   retrieval; Pose synthesis; Monocular
AB 3D human pose estimation from a single image is a challenging problem due to occlusion, viewpoint variance, and the ill-posed nature of back projection. We follow a standard two-step pipeline which first detects 2D joint locations and uses them to infer 3D pose. For the first step, we use a recent deep learning-based detector. For the second step, we propose a novel exemplar-based algorithm to implicitly augment the exemplar set for 3D human pose estimation. The motivation of this algorithm is to well represent various poses in the real world with finite real exemplars. We achieve it by a strategy of synthesizing virtual candidate poses which ensures that the augmented exemplar set has much more variety. Moreover, we also present an effective approach to select the best exemplar from candidate set to well match the detected 2D pose. Experimental results show that our method achieves competitive performance on Human3.6M dataset. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yang, Jingjing; Wan, Lili; Xu, Wanru; Wang, Shenghui] Beijing jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Yang, Jingjing; Wan, Lili; Xu, Wanru; Wang, Shenghui] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Wan, LL (corresponding author), Beijing jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM llwan@bjtu.edu.cn
RI jing, yang/JDV-8487-2023; Yang, Jing/HZJ-2451-2023
OI Wan, Lili/0000-0002-9520-5425
FU National Natural Science Foundation of China [61572064, 61672089]
FX This work is supported by National Natural Science Foundation of China
   (61572064 and 61672089).
CR Belagiannis V, 2016, MACH VISION APPL, V27, P1035, DOI 10.1007/s00138-016-0792-4
   Belagiannis Vasileios, 2014, European Conference on Computer Vision, P742
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   Chen WZ, 2016, INT CONF 3D VISION, P479, DOI 10.1109/3DV.2016.58
   Ching-Hang Chen, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P5759, DOI 10.1109/CVPR.2017.610
   Everingham M., 2010, BMVC, V2, P5
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jiang H., 2010, ICPR, P1674, DOI DOI 10.1109/ICPR.2010.414
   Kostrikov I., 2014, BMVC, V1, P5
   Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Moreno-Noguer F, 2017, PROC CVPR IEEE, P1561, DOI 10.1109/CVPR.2017.170
   Mori G, 2002, LECT NOTES COMPUT SC, V2352, P666
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Thang ND, 2011, APPL INTELL, V35, P163, DOI 10.1007/s10489-009-0209-4
   Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Ramakrishna V, 2012, LECT NOTES COMPUT SC, V7575, P573, DOI 10.1007/978-3-642-33765-9_41
   Rogez G., 2016, Adv. Neural Inf. Process. Syst., P3116
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885
   Tekin B., 2015, ARXIV150408200, V2, P6
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
   Zhou XW, 2015, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2015.7299074
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 37
TC 5
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 371
EP 379
DI 10.1016/j.jvcir.2019.01.033
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600038
DA 2024-07-18
ER

PT J
AU Zhang, G
   Wang, JL
   Yan, CK
   Wang, S
AF Zhang, Ge
   Wang, Jianlin
   Yan, Chaokun
   Wang, Sheng
TI Application research of image compression and wireless network traffic
   video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compression; DASH; Streaming media; Wavelet transform;
   Noise-signal ratio
AB With the increasingly busy urban traffic and the development of modern communication technologies, traffic conditions need to be transmitted from major intersections to command and dispatch centers for analysis and processing, which raises a large number of problems of storing and transmitting static images of traffic conditions. Research on image compression of traffic conditions has also become a hot issue that people pay more and more attention to. In the process of traffic image research, due to the lack of essential attributes of the image, especially, the selection and use of compression methods has greater blindness. However, an overall analysis of the image prior to traffic image processing is a difficult task. This article selects the road traffic data, public transit data and orbital data first to compress the image. Then the streaming Media transmission System of DASH is introduced. In the specific application, the code of traffic data flow in this paper is converted into Real Media format through SDK. With the help of Helix Server, all traffic data flow files can be integrated into the synchronous Media integration language, based on the Internet of TCP/IP which is released in a stream through Real System. The experimental results show that the traffic conditions such as vehicle queuing, congestion and signal lights are directly mastered, the signal timing is timely adjusted or other means are adopted to ease the traffic, the distribution of traffic flow is changed, and ordinary terminal users are enabled to master the distribution of traffic flow through wireless network and choose the travel path actively. (C) 2018 Published by Elsevier Inc.
C1 [Zhang, Ge; Wang, Jianlin; Yan, Chaokun; Wang, Sheng] Henan Univ, Sch Comp & Informat Engn, Kaifeng, Peoples R China.
C3 Henan University
RP Yan, CK; Wang, S (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng, Peoples R China.
EM zhangge@henu.edu.cn; jlwang@henu.edu.cn; ckyan@henu.edu.cn;
   wansheng1910@163.edu.cn
RI wang, jian/GVS-0711-2022; Jiang, Yalin/ITV-2565-2023
OI Jiang, Yalin/0009-0003-3726-8828
FU NSFC [61802114, 61802113]; Scientific Research Foundation of the Higher
   Education Institutions of Henan Province [18A520021]; Henan University
   Foundation [2016YBZR018]
FX This work was supported by NSFC (No. 61802114, 61802113), Scientific
   Research Foundation of the Higher Education Institutions of Henan
   Province(18A520021), Henan University Foundation (2016YBZR018).
CR [Anonymous], ELECT DES ENG
   [Anonymous], J SUZHOU VOCATIONAL
   [Anonymous], ETHNIC ART STUD
   [Anonymous], MERGE FORWARD SELF O
   [Anonymous], COMPUT TECHNOL DEV
   [Anonymous], CONNECTED CAR EXAMPL
   [Anonymous], HIERARCHICAL MODELIN
   [Anonymous], J DONGHUA U
   [Anonymous], SHIP SCI TECHNOL
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], T BEIJING I TECHNOL
   [Anonymous], COMPUT ENG APPL
   [Anonymous], INT C BIG DAT AN DEE
   [Anonymous], DIGITAL RIGHTS MANAG
   [Anonymous], WIREL NETW
   [Anonymous], IMAGE COMPRESSION US
   [Anonymous], REAL TIME STREAM PRO
   [Anonymous], MANAGE TECHNOL SME
   [Anonymous], SPATIALLY ADAPTIVE I
   [Anonymous], LEARN IMAGE COMPRESS
   [Anonymous], IEEE T COMPUT
   [Anonymous], J ANHUI VOCATIONAL C
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Li Y., 2018, MULTIMEDIA TOOLS APP, P1
   Mehmood R, 2018, INT J HYDROGEN ENERG, V43, P7562, DOI 10.1016/j.ijhydene.2018.02.166
   Skupin R, 2017, IEEE IMAGE PROC, P4592, DOI 10.1109/ICIP.2017.8297155
   Torfason R, 2018, Towards image understanding from deep compression without decoding
   Wang J, 2018, IEEE INT CONF MOB CL, P79, DOI 10.1109/MobileCloud.2018.00020
   Zhang WP, 2017, SAUDI J BIOL SCI, V24, P563, DOI 10.1016/j.sjbs.2017.01.027
   Zhao L, 2019, INT J HYPERTHER, V35, P528, DOI 10.1080/02656736.2018.1511836
NR 30
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 168
EP 175
DI 10.1016/j.jvcir.2018.12.042
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600017
DA 2024-07-18
ER

PT J
AU Zhang, WH
   Kong, DH
   Wang, SF
   Wang, ZY
AF Zhang, Wenhui
   Kong, Dehui
   Wang, Shaofan
   Wang, Zhiyong
TI 3D human pose estimation from range images with depth difference and
   geodesic distance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human pose estimation; Superpixel; Geodesic distance; Random decision
   forest; Sparse representation
ID SUPERPIXELS
AB Depth difference, as a popularly used feature for characterizing pairwise pixels of range images, fails to precisely capture skeleton joints when human body possesses a wild and complicated articulation. As the geodesic distance of pairwise pixels is able to present a global connected property and adjacent pixels often belong to the same body component, we propose an effective and efficient framework for pose estimation from range images. Firstly, all the pixels of a range image are grouped into superpixels using an improved Simple Linear Iterative Clustering algorithm. Secondly, those superpixels are labelled as the components of a human body using the hybrid feature. Thirdly, componentwise cluster feature extraction is undertaken on skeleton joints of body components with K-means clustering algorithm. Finally, the feature points of each component are then stacked as a compact representation of human poses and mapped to the skeleton joints of a human body. Experimental results demonstrate that the proposed framework outperforms several state-of-the-art pose estimation methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Wenhui; Kong, Dehui; Wang, Shaofan] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
   [Zhang, Wenhui] Pingxiang Univ, Sch Informat & Comp Engn, Pingxiang 337055, Jiangxi, Peoples R China.
   [Wang, Zhiyong] Univ Sydney, Sch Informat Technol, Sydney, NSW, Australia.
C3 Beijing University of Technology; Pingxiang University; University of
   Sydney
RP Wang, SF (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing 100124, Peoples R China.
EM wangshaofan@bjut.edu.cn
RI liu, miao/KGL-7043-2024
FU National Natural Science Foundation of China [61772049, 61632006,
   61876012, U1811463]; International Research Cooperation Seed Fund of
   Beijing University of Technology [2018B05]
FX This work was supported by National Natural Science Foundation of China
   (61772049, 61632006, 61876012, U1811463) and the International Research
   Cooperation Seed Fund of Beijing University of Technology (2018B05).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Agoes AS, 2017, LECT NOTES COMPUT SC, V10117, P77, DOI 10.1007/978-3-319-54427-4_6
   [Anonymous], 2010, 2010 IEEE GLOBAL TEL
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   Baak A., 2013, Consumer Depth Camerasfor Computer Vision: Research Topics and Applications, P71, DOI DOI 10.1007/978-1-4471-4640-7_5
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1
   Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Girshick R, 2011, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2011.6126270
   Grest D, 2005, LECT NOTES COMPUT SC, V3663, P285
   Handrich S, 2013, IEEE SYS MAN CYBERN, P906, DOI 10.1109/SMC.2013.159
   He L, 2016, NEUROCOMPUTING, V203, P52, DOI 10.1016/j.neucom.2016.04.009
   He L, 2015, NEUROCOMPUTING, V164, P210, DOI 10.1016/j.neucom.2015.02.068
   Hernández-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742
   Jung HY, 2016, LECT NOTES COMPUT SC, V9909, P747, DOI 10.1007/978-3-319-46454-1_45
   Jung HY, 2015, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2015.7298861
   Kim H, 2015, SENSORS-BASEL, V15, P12410, DOI 10.3390/s150612410
   Krejov Philip, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163141
   Li F, 2015, IEEE J-STSP, V9, P384, DOI 10.1109/JSTSP.2015.2403794
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Nishi K, 2017, PATTERN RECOGN, V71, P402, DOI 10.1016/j.patcog.2017.06.006
   Pishchulin L, 2013, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2013.433
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sminchisescu C, 2003, PROC CVPR IEEE, P69
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Ye M, 2014, PROC CVPR IEEE, P2353, DOI 10.1109/CVPR.2014.301
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhu YD, 2010, SENSORS-BASEL, V10, P5280, DOI 10.3390/s100505280
NR 32
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 272
EP 282
DI 10.1016/j.jvcir.2019.01.028
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600028
DA 2024-07-18
ER

PT J
AU Zheng, Y
   Wang, RG
   Yang, J
   Xue, LX
   Hu, M
AF Zheng, Yan
   Wang, Ronggui
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Principal characteristic networks for few-shot learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Few-shot learning; Principal characteristic; Mixture loss function;
   Embedding network; Fine-tuning
AB Few-shot learning aims to build a classifier that recognizes unseen new classes given only a few samples of them. Previous studies like prototypical networks utilized the mean of embedded support vectors to represent the prototype that is the representation of class and yield satisfactory results. However, the importance of these different embedded support vectors is not studied yet, which are valuable factors that could be used to push the limit of the few-shot learning. We propose a principal characteristic network that exploits the principal characteristic to better express prototype, computed by distributing weights based on embedded vectors' different importance. The high-level abstract embedded vectors are extracted from our eResNet embedding network. In addition, we proposed a mixture loss function, which enlarges the inter-class distance in the embedding space for accurate classification. Extensive experimental results demonstrate that our network achieves state-of-the-art results on the Omniglot, minilmageNet and Cifar100 datasets. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zheng, Yan; Wang, Ronggui; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM yangjuan6985@163.com
RI Lin, Kuan-Yu/JXM-6653-2024
OI Zheng, Yan/0000-0001-7237-1570
FU National Natural Science Foundation of China [61672202]
FX We express our sincere thanks to the anonymous reviewers for their
   helpful comments and suggestions to raise the standard of our paper. We
   would also like to thank Yiqing Hu, Xuchen Yao, Tingting Yu for helpful
   discussions on the presentation. This work is partly supported by the
   National Natural Science Foundation of China under Grant No. 61672202.
CR [Anonymous], COGNIT SCI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, ICLR 2017 INT C LEAR
   [Anonymous], 2016, ARXIV161003017
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2017, ARXIV170308033
   [Anonymous], 2018, LEARNING COMP RELATI
   [Anonymous], 1997, P NATL C ARTIFICIAL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2018, IEEE T CYBERNETICS
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], 2017, Meta networks
   [Anonymous], ARXIV170802735
   [Anonymous], 2016, ARXIV160306147
   [Anonymous], 2014, NEURAL TURING MACHIN
   Atkeson CG, 1997, ARTIF INTELL REV, V11, P75, DOI 10.1023/A:1006511328852
   Banerjee A, 2005, J MACH LEARN RES, V6, P1705
   Bengio Y., 2012, UNSUPERVISED TRANSFE, V7, P19
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Dixit M., 2017, P IEEE C COMP VIS PA, P7455
   Finn C, 2017, PR MACH LEARN RES, V70
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kingma D.P., 2014, ARXIV14126980
   Koch G., 2015, P ICML DEEP LEARN WO, V2
   Krizhevsky A., 2010, CIFAR 10
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mishra Nikhil, 2017, ARXIV170703141
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Parisotto Emilio, 2015, ARXIV151106342
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A.A., 2018, P INT C LEARN REPR V
   Santoro A, 2016, PR MACH LEARN RES, V48
   Snell J, 2017, ADV NEUR IN, V30
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wong A, 2015, IEEE I CONF COMP VIS, P1197, DOI 10.1109/ICCV.2015.142
   Wu Yonghui, 2016, P C ASS MACH TRANSL
NR 44
TC 20
Z9 27
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 563
EP 573
DI 10.1016/j.jvcir.2019.02.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600058
DA 2024-07-18
ER

PT J
AU Thai, BC
   Mokraoui, A
   Matei, B
AF Thai, Ba Chien
   Mokraoui, Anissa
   Matei, Basarab
TI Contrast enhancement and details preservation of tone mapped high
   dynamic range images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range; Separable multiresolution; Lifting scheme; Optimized
   prediction; Cell-average interpolation; Tone mapping operators
ID REPRODUCTION
AB This paper proposes a Tone Mapping (TM) approach converting a High Dynamic Range (HDR) image into a Low Dynamic Range (LDR) image while preserving as much information of the HDR image as possible to ensure a good LDR image visual quality. This approach is based on a separable near optimal lifting scheme using an adaptive powerful prediction step. The latter relies on a linear weighted combination depending on the neighboring coefficients extracting then the relevant finest details in the HDR image at each resolution level. Moreover the approximation and detail coefficients are modified according to the entropy of each subband. The pixel's distribution of the coarse reconstructed LDR image is then adjusted according to a perceptual quantizer with respect to the human visual system using a piecewise linear function. Simulation results provide good results, both in terms of visual quality and TMQI metric, compared to existing competitive TM approaches. (C) 2018 Published by Elsevier Inc.
C1 [Thai, Ba Chien; Mokraoui, Anissa] Univ Paris 13, Inst Galilee, L2TI, Sorbonne Paris Cite, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
   [Matei, Basarab] Univ Paris 13, Inst Galilee, LIPN, Sorbonne Paris Cite, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
C3 Universite Paris 13; Universite Paris 13
RP Thai, BC (corresponding author), Univ Paris 13, Inst Galilee, L2TI, Sorbonne Paris Cite, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
EM bachien.thai@univ-paris13.fr; anissa.mokraoui@univ-paris13.fr;
   matei@lipn.univ-paris13.fr
RI MATEI, Basarab/HTS-4446-2023
OI MATEI, Basarab/0000-0001-7946-530X; THAI, Ba Chien/0000-0003-2341-4348
CR [Anonymous], ACM T GRAPH
   [Anonymous], 1994, Graph. Gems, DOI DOI 10.1016/B978-0-12-336156-1.50054-9
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   Claypoole RL, 2003, IEEE T IMAGE PROCESS, V12, P1449, DOI 10.1109/TIP.2003.817237
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Duan J, 2010, PATTERN RECOGN, V43, P1847, DOI 10.1016/j.patcog.2009.12.006
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Husseis A., 2017, 17 IEEE INT S SIGN P
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Mai ZC, 2010, IEEE IMAGE PROC, P1285, DOI 10.1109/ICIP.2010.5653283
   Newman E. A., 2012, RETINA APPROACHABLE, V87
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Schlick C., 1995, Quantization Techniques for Visualization of High Dynamic Range Pictures
   Thai BC, 2017, IEEE INT SYMP SIGNAL, P89, DOI 10.1109/ISSPIT.2017.8388688
   Thai BC, 2016, EUR SIGNAL PR CONF, P1891, DOI 10.1109/EUSIPCO.2016.7760577
   TUMBLIN J, 1993, IEEE COMPUT GRAPH, V13, P42, DOI 10.1109/38.252554
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   ZAIDI Q, 1992, VISION RES, V32, P1297, DOI 10.1016/0042-6989(92)90224-7
NR 19
TC 8
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 589
EP 599
DI 10.1016/j.jvcir.2018.12.024
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100057
DA 2024-07-18
ER

PT J
AU Chen, DJ
   Chen, HT
   Chang, LW
AF Chen, Ding-Jie
   Chen, Hwann-Tzong
   Chang, Long-Wen
TI Toward a unified scheme for fast interactive segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive; Image segmentation; Manifold ranking; Machine-assisted
ID IMAGE SEGMENTATION
AB This paper presents an efficient and effective interactive segmentation scheme for extracting the region of a foreground object in an image. Our goal is to design an interactive segmentation algorithm that unifies the bounding-box-based, seed-based, and query-based interaction mechanisms for pursuing (i) high efficiency in simple interaction mechanism, (ii) few interaction rounds, and (iii) short response time. The proposed algorithm starts with a user-provided bounding box and obtains candidate background superpixels for inferring the foreground object. Our algorithm tolerates imprecise bounding boxes and provides two kinds of interactions for acquiring correct labels from the user. The user can either input the seed/scribble annotations or label the algorithm-queried regions. Our algorithm selects the most uncertain region as a query, and this query-based interaction mechanism reduces the burden of the user on deciding suitable annotation locations. The average response time per-interaction of our algorithm is merely 0.014 s. Our experiments demonstrate that the algorithm achieves an efficient unified scheme for interactive image segmentation.
C1 [Chen, Ding-Jie; Chen, Hwann-Tzong; Chang, Long-Wen] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Chen, HT (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
EM htchen@cs.nthu.edu.tw
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alpert S., 2007, CVPR
   [Anonymous], 2004, ECCV
   [Anonymous], NIPS
   [Anonymous], CVPR
   [Anonymous], SIGGRAPH
   [Anonymous], 2001, ICCV
   [Anonymous], 2009, ICCV
   [Anonymous], CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], 2009, CVPR
   [Anonymous], 2013, CVPR
   [Anonymous], 2008, CVPR
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen D., 2016, ACCV
   Fowlkes CC, 2007, J VISION, V7, DOI 10.1167/7.8.2
   Freedman Daniel., 2005, CVPR
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Luo LK, 2017, J VIS COMMUN IMAGE R, V43, P138, DOI 10.1016/j.jvcir.2016.12.012
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Sorensen T.A., 1948, BIOL SKRIFTER, V5, P1
   Tang M., 2013, ICCV
   Nguyen TNA, 2013, J VIS COMMUN IMAGE R, V24, P477, DOI 10.1016/j.jvcir.2013.02.012
   Wang T, 2015, J VIS COMMUN IMAGE R, V33, P10, DOI 10.1016/j.jvcir.2015.08.013
   Zemene E., 2016, ECCV
NR 33
TC 3
Z9 3
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 393
EP 403
DI 10.1016/j.jvcir.2018.06.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100032
DA 2024-07-18
ER

PT J
AU Ghodsi, S
   Mohammadzade, H
   Korki, E
AF Ghodsi, Saeed
   Mohammadzade, Hoda
   Korki, Erfan
TI Simultaneous joint and object trajectory templates for human activity
   recognition from 3-D data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human activity recognition; RGB-D sensors; Trajectory-based
   representation; Action template; Dynamic time warping (DTW); Human
   object interaction
ID FEATURES; POSE; AFFORDANCES; LATENCY
AB Availability of low-cost range sensors and the development of relatively robust algorithms for the extraction of skeleton joint locations have inspired many researchers to develop human activity recognition methods using 3-D data. In this paper, an effective method for the recognition of human activities from the normalized joint trajectories is proposed. We represent the actions as multidimensional signals and introduce a novel method for generating action templates by averaging the samples in a "dynamic time" sense. Then, in order to deal with the variations in speed and style of performing actions, we warp the samples with action templates by an efficient algorithm and employ wavelet filters to extract meaningful spatiotemporal features. The proposed method is also capable of modeling the human-object interactions, by performing the template generation and temporal warping procedure via the joint and object trajectories simultaneously. Experimental evaluations on several challenging datasets demonstrates the effectiveness of our method compared to the state-of-the-arts as well as its robustness against different sources of noise. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Ghodsi, Saeed; Mohammadzade, Hoda; Korki, Erfan] Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Mohammadzade, H (corresponding author), Sharif Univ Technol, Dept Elect Engn, Tehran, Iran.
EM saeed.ghodsi@ee.sharif.edu; hoda@sharif.edu; erfan.korki@alum.sharif.edu
RI , Hoda/ABC-6387-2020
OI , Hoda/0000-0002-9852-5088; Ghodsi, Saeed/0000-0003-2593-0928
FU Iran National Science Foundation (INSF); Research Office of the Sharif
   University of Technology
FX This work was supported by grants from Iran National Science Foundation
   (INSF) and Research Office of the Sharif University of Technology.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2016, P AAAI
   Beh J, 2014, PATTERN RECOGN LETT, V36, P144, DOI 10.1016/j.patrec.2013.10.007
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bhavsar A., 2016, P IEEE C COMP VIS PA, P38
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chenxia Wu, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P4362, DOI 10.1109/CVPR.2015.7299065
   Cippitelli E, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/4351435
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Ding WW, 2015, J VIS COMMUN IMAGE R, V26, P329, DOI 10.1016/j.jvcir.2014.10.009
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Faria DR, 2014, IEEE ROMAN, P732, DOI 10.1109/ROMAN.2014.6926340
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Gasparrini S, 2016, ADV INTELL SYST, V399, P99, DOI 10.1007/978-3-319-25733-4_11
   Gong D, 2011, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2011.6126290
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Han F., 160101006 ARXIV
   Holt G. A., 2007, P 19 ANN C ADV SCH C, P1
   Hu NH, 2014, IEEE INT CONF ROBOT, P1048, DOI 10.1109/ICRA.2014.6906983
   Hussein, 2013, INT JOINT C ART INT
   Jiang XB, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P191, DOI 10.1109/CW.2013.37
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kerola Tommi., 2014, Asian Conference on Computer Vision, P417
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu GL, 2016, MULTIMED TOOLS APPL, V75, P3479, DOI 10.1007/s11042-015-2448-1
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Ottersten B., 2016, P IEEE WINT C APPL C, P1
   Parisi GI, 2015, FRONT NEUROROBOTICS, V9, P1, DOI 10.3389/fnbot.2015.00003
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Taha A., 2015, INT J SCI ENG RES, V6, P2229
   Tayyub J., 2014, Asian Conference on Computer Vision, P115
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wei P, 2013, IEEE I CONF COMP VIS, P3272, DOI 10.1109/ICCV.2013.406
   Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P439, DOI 10.1109/TCYB.2016.2519448
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhu GM, 2016, SIGNAL PROCESS-IMAGE, V42, P19, DOI 10.1016/j.image.2016.01.003
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 65
TC 11
Z9 11
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 729
EP 741
DI 10.1016/j.jvcir.2018.08.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100063
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lin, CW
AF Lin, Chih-Wei
TI Moving cast shadow detection using scale-relation multi-layer pooling
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shadow removal; Moving cast shadow; Scale-relation; Multi-layer pooling;
   Ensemble decision scheme
ID OBJECT DETECTION; MOTION; SEGMENTATION; SURVEILLANCE; REMOVAL
AB Moving cast shadows detection and removal are indispensable for object detection and are the problems in visual surveillance applications which have been studied over the years. However, finding an efficient model that can handle the issue of moving cast shadow in various situations is still challenging. Unlike prior methods, we use a data-driven method without strong parametric assumptions or complex models to address the problem of moving cast shadow. In this paper, we propose a novel feature-extracting framework called Scale-Relation MultiLayer Pooling Feature Extracting (SMPF) which includes two main tasks: (1) Scale-Relation Scheme (SRS), (2) Multi-Layer Pooling Scheme (MLPS). By leveraging the scale space, SRS firstly decomposes feature images of each shadow properties into various scales and further considers the relationship between adjacent scaled feature images of each shadow properties to extract the scale-relation features. Then, we design the multi-layer pooling scheme (MLPS) to integrate the features in a local region and to reduce the dimension of extracting features. After that, the density map is generated for various properties of shadow with low dimension. Finally, to seek the criteria for discriminating moving cast shadow, we use random forest algorithm as the ensemble decision scheme. The main contributions of this study are (1) we design the features with multi-scale which can provide abundant information to describe the moving cast shadow, (2) the multi-layer pooling scheme generates the density map to integrate and reduce the dimensions of features. Experiments on the popular benchmarks and the proposed dataset with benchmarks demonstrate that the proposed method can achieve the performances of the popular methodologies.
C1 [Lin, Chih-Wei] Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou, Fujian, Peoples R China.
   [Lin, Chih-Wei] Fujian Agr & Forestry Univ, Coll Forestry, Fuzhou, Fujian, Peoples R China.
   [Lin, Chih-Wei] Fujian Agr & Forestry Univ, Forestry Postdoctoral Stn, Fuzhou, Fujian, Peoples R China.
C3 Fujian Agriculture & Forestry University; Fujian Agriculture & Forestry
   University; Fujian Agriculture & Forestry University
RP Lin, CW (corresponding author), Fujian Agr & Forestry Univ, Coll Comp & Informat Sci, Fuzhou, Fujian, Peoples R China.
EM cwlin@fafu.edu.cn
RI Lin, Chih-Wei/AAD-7907-2019
FU Natural Science Foundation of Fujian Province of China [2016J01718];
   Fujian Provincial Department of Social and Technology [2015Y0042];
   Channel Post-doctoral Exchange Funding Scheme
FX An earlier version of this paper was presented at the 23th International
   Conference on Multimedia Modeling (MMM 2017). This work was supported by
   the Natural Science Foundation of Fujian Province of China [Grant Nos.
   2016J01718]; the Fujian Provincial Department of Social and Technology
   [Grant Nos. 2015Y0042]; and the Channel Post-doctoral Exchange Funding
   Scheme.
CR Al-Najdawi N, 2012, PATTERN RECOGN LETT, V33, P752, DOI 10.1016/j.patrec.2011.12.013
   Amato A, 2011, IEEE T IMAGE PROCESS, V20, P2954, DOI 10.1109/TIP.2011.2132728
   [Anonymous], 1999 IEEE COMP VIS P
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2010, Chinese Conference on Pattern Recognition, DOI DOI 10.1109/CCPR.2010.5659321
   [Anonymous], INVARIANT COLOR MODE
   Arbel E, 2011, IEEE T PATTERN ANAL, V33, P1202, DOI 10.1109/TPAMI.2010.157
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benedek C, 2008, IEEE T IMAGE PROCESS, V17, P608, DOI 10.1109/TIP.2008.916989
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bullkich E., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P146
   Choi J, 2010, COMPUT VIS IMAGE UND, V114, P1017, DOI 10.1016/j.cviu.2010.06.003
   Cucchiara R, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P360, DOI 10.1109/ICIAP.2001.957036
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Cucchiara R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P334, DOI 10.1109/ITSC.2001.948679
   Dai JY, 2015, OPTIK, V126, P5398, DOI 10.1016/j.ijleo.2015.09.099
   Fang LZ, 2008, PATTERN RECOGN LETT, V29, P2182, DOI 10.1016/j.patrec.2008.08.009
   Finlayson G., 2002, EUROPEAN C COMPUTER, P129
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Fung GSK, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P404, DOI 10.1109/ICIAP.2001.957043
   FUNKALEA G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P203, DOI 10.1109/ICCV.1995.466785
   Guan YP, 2010, IET COMPUT VIS, V4, P50, DOI 10.1049/iet-cvi.2008.0016
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Khan SH, 2014, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2014.249
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Lee J.T., 2015, Image and Video Technology, P299
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Lin CW, 2017, LECT NOTES COMPUT SC, V10133, P331, DOI 10.1007/978-3-319-51814-5_28
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martel-Brisson N., 2008, CVPR 2008 IEEE C COM, P1
   Martel-Brisson N, 2007, IEEE T PATTERN ANAL, V29, P1133, DOI 10.1109/TPAMI.2007.1039
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Salvador E, 2001, INT CONF ACOUST SPEE, P1545, DOI 10.1109/ICASSP.2001.941227
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Schreer O, 2002, PROCEEDINGS VIPROMCOM-2002, P371, DOI 10.1109/VIPROM.2002.1026685
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Song KT, 2007, P IEEE, V95, P413, DOI 10.1109/JPROC.2006.888403
   Tian JD, 2009, IEEE T IMAGE PROCESS, V18, P2355, DOI 10.1109/TIP.2009.2026682
   Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang SC, 2011, INT CONF ACOUST SPEE, P925
NR 52
TC 5
Z9 6
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 504
EP 517
DI 10.1016/j.jvcir.2018.06.028
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100044
DA 2024-07-18
ER

PT J
AU Marín-Jiménez, MJ
   Romero-Ramirez, FJ
   Muñoz-Salinas, R
   Medina-Carnicer, R
AF Marin-Jimenez, Manuel J.
   Romero-Ramirez, Francisco J.
   Munoz-Salinas, Rafael
   Medina-Carnicer, Rafael
TI 3D human pose estimation from depth maps using a deep combination of
   poses
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D human pose; Body limbs; Depth maps; ConvNets
AB Many real-world applications require the estimation of human body joints for higher-level tasks as, for example, human behaviour understanding. In recent years, depth sensors have become a popular approach to obtain three-dimensional information. The depth maps generated by these sensors provide information that can be employed to disambiguate the poses observed in two-dimensional images. This work addresses the problem of 3D human pose estimation from depth maps employing a Deep Learning approach. We propose a model, named Deep Depth Pose (DDP), which receives a depth map containing a person and a set of predefined 3D prototype poses and returns the 3D position of the body joints of the person. In particular, DDP is defined as a ConvNet that computes the specific weights needed to linearly combine the prototypes for the given input. We have thoroughly evaluated DDP on the challenging 'ITOP' and 'UBC3V' datasets, which respectively depict realistic and synthetic samples, defining a new state-of-the-art on them.
C1 [Marin-Jimenez, Manuel J.; Romero-Ramirez, Francisco J.; Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Univ Cordoba, Dept Informat & Anal Numer, Campus Rabanales, E-14071 Cordoba, Spain.
   [Marin-Jimenez, Manuel J.; Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Inst Maimonides Invest Biomed IMIBIC, Ave Menendez Pida1 S-N, Cordoba 14004, Spain.
C3 Universidad de Cordoba
RP Marín-Jiménez, MJ (corresponding author), Univ Cordoba, Dept Informat & Anal Numer, Campus Rabanales, E-14071 Cordoba, Spain.
EM mjmarin@uco.es; fj.romero@uco.es; rmsalinas@uco.es; rmedina@uco.es
RI Romero-Ramirez, Francisco J./JVE-2018-2024; Marin-Jimenez, Manuel
   J./AAS-9152-2020; Munoz-Salinas, Rafael/K-5999-2014; Medina-Carnicer,
   Rafael/G-3401-2015
OI Romero-Ramirez, Francisco J./0000-0002-9572-0128; Marin-Jimenez, Manuel
   J./0000-0001-9294-6714; Munoz-Salinas, Rafael/0000-0002-8773-8571;
   Medina-Carnicer, Rafael/0000-0003-4481-0614
FU (ISCIII) of Spain Ministry of Economy, Industry and Competitiveness
   [TIN2016-75279-P, IFI16/00033]; FEDER
FX This project has been funded under projects TIN2016-75279-P and
   IFI16/00033 (ISCIII) of Spain Ministry of Economy, Industry and
   Competitiveness, and FEDER. Thanks to NVidia for donating the GPU The
   authors declare that there is no conflict of interest. Titan Xp used for
   the experiments presented in this work. We also thank Shafaei and Little
   for providing their error and precision results used in Acknowledgements
   our comparative plots.
CR Achilles F., 2016, P INT C MED IM COMP
   Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Belagiannis V, 2016, MACH VISION APPL, V27, P1035, DOI 10.1007/s00138-016-0792-4
   Belagiannis Vasileios, 2014, European Conference on Computer Vision, P742
   Cherian A, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.302
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Ferrari V, 2009, PROC CVPR IEEE, P1, DOI 10.1109/CVPRW.2009.5206495
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Haque A, 2016, LECT NOTES COMPUT SC, V9905, P160, DOI 10.1007/978-3-319-46448-0_10
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hernández-Vela A, 2012, PROC CVPR IEEE, P726, DOI 10.1109/CVPR.2012.6247742
   Huo F., 2009, CASE WORKSHOP 3D ADV, P43
   Jiu MY, 2014, PATTERN RECOGN LETT, V50, P122, DOI 10.1016/j.patrec.2013.09.021
   Katircioglu I, 2018, INT J COMPUT VISION, V126, P1326, DOI 10.1007/s11263-018-1066-6
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   López-Quintero MI, 2017, IET COMPUT VIS, V11, P426, DOI 10.1049/iet-cvi.2016.0249
   López-Quintero MI, 2016, MACH VISION APPL, V27, P157, DOI 10.1007/s00138-015-0742-6
   Madadi M, 2015, PATTERN RECOGN LETT, V56, P14, DOI 10.1016/j.patrec.2015.01.012
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Moon G., P IEEE C COMP VIS PA
   Obdrzalek Stepan, 2012, Stud Health Technol Inform, V173, P320
   Rogez G., 2017, P IEEE C COMP VIS PA
   Shafaei A., 2016, P 13 C COMP ROB VIS
   Shen JF, 2011, PATTERN RECOGN LETT, V32, P2025, DOI 10.1016/j.patrec.2011.09.019
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tekin B., 2015, ARXIV150408200, V2, P6
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Zhu YY, 2014, LECT N MANAG SCI, V28, P408
NR 32
TC 25
Z9 25
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 627
EP 639
DI 10.1016/j.jvcir.2018.07.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100053
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ke, Y
   Zhang, MQ
   Liu, J
   Su, TT
   Yang, XY
AF Ke, Yan
   Zhang, Min-qing
   Liu, Jia
   Su, Ting-ting
   Yang, Xiao-yuan
TI A multilevel reversible data hiding scheme in encrypted domain based on
   LWE
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Information security; Reversible data hiding; Multilevel embedding;
   Public key cryptography; Learning with Error
ID DIFFERENCE; IMAGES
AB This paper proposes a multilevel reversible data hiding scheme in encrypted domain by utilizing the controllable redundancy of learning with error public key cryptography. Messages can be embedded into multilevel sub-regions of ciphertext by quantifying the encrypted domain and recoding its redundancy. We recode redundancy based on the characteristics of cipher's distribution. Extraction and decryption processes are separated by dividing the encrypted domain into multilevel sub-regions and introducing different quantification standards. Original plaintext can be losslessly recovered from the marked ciphertext by using the decryption key; with a specific level data-hiding key, only the message hiding in the corresponding level can be extracted, while plaintext and other messages remain secret. We provide theoretical analysis and experimental results on the feasibility, reversibility, and security of the proposed scheme. The capacity and encryption blow up factor are discussed. The experimental results demonstrate the maximum embedding rate can exceed 0.3000 bpb of ciphertext.
C1 [Ke, Yan; Zhang, Min-qing; Liu, Jia; Su, Ting-ting; Yang, Xiao-yuan] Engn Univ PAP, Key Lab Network & Informat Secur Chinese People A, Coll Cryptog Engn, Xian, Shaanxi, Peoples R China.
RP Ke, Y (corresponding author), Engn Univ PAP, Key Lab Network & Informat Secur Chinese People A, Coll Cryptog Engn, Xian, Shaanxi, Peoples R China.
EM 15114873390@163.com
RI Ke, Yan/HTS-4679-2023; Yan, Keyu/IXX-0343-2023
FU National Key R&D Program of China [2017YFB0802000]; National Natural
   Science Foundation of China [61379152, 61403417]
FX This work was supported by National Key R&D Program of China under Grant
   No. 2017YFB0802000, and the National Natural Science Foundation of China
   under Grant No.61379152 and Grant No.61403417. The authors also
   gratefully acknowledge the helpful comments and suggestions of the
   reviewers.
CR [Anonymous], IACR CRYPTOLOGY EPRI
   [Anonymous], P INT C PUBL KEY CRY
   [Anonymous], 2016, INT WORKSH DIG WAT I
   [Anonymous], 27 ANN INT C THEOR A
   [Anonymous], [No title captured]
   [Anonymous], 2012, PROC IWDW
   [Anonymous], IEEE T CIRCUITS SYST
   Barni M, 2013, IEEE SIGNAL PROC MAG, V30, P16, DOI 10.1109/MSP.2012.2229069
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Kuribayashi M, 2005, IEEE T IMAGE PROCESS, V14, P2129, DOI 10.1109/TIP.2005.859383
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Micciancio Daniele, 2011, Post-quantum Cryptography, P713, DOI 10.1007/978-1-4419-5906-5417
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao D, 2014, ELECTRON LETT, V50, P598, DOI 10.1049/el.2013.3806
   Yin ZX, 2014, SCI WORLD J, DOI 10.1155/2014/604876
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 33
TC 16
Z9 19
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 133
EP 144
DI 10.1016/j.jvcir.2018.05.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800012
DA 2024-07-18
ER

PT J
AU Santos, JM
   Assuncao, PAA
   Cruz, LAD
   Tavora, LMN
   Fonseca-Pinto, R
   Faria, SMM
AF Santos, Joao M.
   Assuncao, Pedro A. A.
   da Silva Cruz, Luis A.
   Tavora, Luis M. N.
   Fonseca-Pinto, Rui
   Faria, Sergio M. M.
TI Lossless coding of light field images based on minimum-rate predictors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image coding; Lossless compression; Light field coding
ID COMPRESSION
AB Recent developments in light field acquisition and computational photography are driving new research efforts on light field encoding methods, capable of exploiting the specific features of this type of visual data. This paper presents a research study of lossless light field image compression, using Minimum-Rate Predictors (MRP) and mainstream image and video encoders. The research is focused on three light field representation formats: lenslet images, stack of sub-aperture images and epipolar images. The main contributions of this work are the 'Spiral-blackend' serialization method and the use of MRP for the lossless compression of light fields with joint encoding of RGB data. The results show that the lenslet format yields lower compression efficiencies than other formats. Furthermore, it is demonstrated that the MRP algorithm consistently outperforms HEVC-RExt, JPEG2000, JPEG-LS and CALIC when light fields are represented by either a stack of sub-aperture or epipolar images.
C1 [Santos, Joao M.; Assuncao, Pedro A. A.; da Silva Cruz, Luis A.; Fonseca-Pinto, Rui; Faria, Sergio M. M.] Inst Telecomunicacoes, IPLeiria Campus 2, P-2411901 Leiria, Portugal.
   [Santos, Joao M.; da Silva Cruz, Luis A.] Univ Coimbra, Fac Sci & Technol, Dept Elect & Comp Engn, P-3030290 Coimbra, Portugal.
   [Assuncao, Pedro A. A.; Tavora, Luis M. N.; Fonseca-Pinto, Rui; Faria, Sergio M. M.] Inst Politecn Leiria, ESTG, P-2411901 Leiria, Portugal.
C3 Universidade de Coimbra; Polytechnic Institute of Leiria
RP Santos, JM (corresponding author), Inst Telecomunicacoes, IPLeiria Campus 2, P-2411901 Leiria, Portugal.
EM joao.santos@co.it.pt; amado@co.it.pt; luis.cruz@co.it.pt;
   luis.tavora@ipleiria.pt; rui.pinto@ipleiria.pt; sergio.faria@co.it.pt
RI da Silva Cruz, Luis A/A-9125-2011; Faria, Sérgio/C-5245-2011; Santos,
   João Miguel Pereira da Silva/ABH-2288-2021; Tavora, Luis/AAH-4736-2020;
   Assuncao, Pedro A. Amado/A-4827-2017; Fonseca-Pinto, Rui/K-9449-2014
OI da Silva Cruz, Luis A/0000-0003-1141-4404; Faria,
   Sérgio/0000-0002-0993-9124; Santos, João Miguel Pereira da
   Silva/0000-0002-4461-0041; Tavora, Luis/0000-0002-8580-1979; Assuncao,
   Pedro A. Amado/0000-0001-9539-8311; Fonseca-Pinto,
   Rui/0000-0001-6774-5363
FU Fundacao para a Ciencia e a Tecnologia (FCT), Portugal
   [SFRH/BD/114894/2016]; DERMOPLENO project in the scope of RD Unit
   [50008]; European Regional Development Fund (FEDER); Fundação para a
   Ciência e a Tecnologia [SFRH/BD/114894/2016] Funding Source: FCT
FX This work was supported in part by the Fundacao para a Ciencia e a
   Tecnologia (FCT), Portugal, under PhD Grant SFRH/BD/114894/2016 and by
   DERMOPLENO project in the scope of R&D Unit 50008, through national
   funds and when applicable co-funded by European Regional Development
   Fund (FEDER) - PT2020 partnership agreement.
CR Aggoun A., 2006, IEEE INT C AC SPEECH
   Aggoun A, 2011, J DISP TECHNOL, V7, P586, DOI 10.1109/JDT.2011.2159359
   [Anonymous], 2016, MDTV
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], 2016, Tech. Rep.
   Briano M., CALIC 3D CALIC M CAL
   Conti C, 2013, IEEE SIGNAL PROC LET, V20, P819, DOI 10.1109/LSP.2013.2267234
   Conti C, 2011, IEEE IMAGE PROC, P961, DOI 10.1109/ICIP.2011.6116721
   Dansereau D., Light Field Toolbox v0.4
   Dansereau DG, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2665074
   Donatsch D, 2014, VISUAL COMPUT, V30, P897, DOI 10.1007/s00371-014-0979-5
   Francisco NC, 2013, IEEE INT SYMP CIRC S, P1412, DOI 10.1109/ISCAS.2013.6572120
   Harris M, 2012, IEEE SPECTRUM, V49, P30, DOI 10.1109/MSPEC.2012.6156861
   Huang X, 2016, IEEE SIGNAL PROC MAG, V33, P130, DOI 10.1109/MSP.2016.2581847
   ITU ITU-T Recommendation T, 2007, ITU T REC T 812 INF
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Levoy M, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.270
   Lippmann G., 1908, J. Phys. Theor. Appl, V7, P821, DOI [DOI 10.1051/JPHYSTAP:019080070082100, 10.1051/jphystap:019080070082100]
   Lucas LER, 2014, EUR SIGNAL PR CONF, P11
   Martin G., 1979, PROC C VIDEO DATA RE
   Matsuda I., 2007, Systems and Computers in Japan, V38, P1, DOI 10.1002/scj.20630
   Matsuda I., 2007, Systems and Computers in Japan, V38, P90, DOI 10.1002/scj.10318
   Perra C, 2015, INT CONF ACOUST SPEE, P1231, DOI 10.1109/ICASSP.2015.7178166
   Rerabek M., 2016, INT C QUAL MULT EXPU
   Santos JM, 2016, PICT COD SYMP
   Shi S, 2011, IEEE IMAGE PROC, P137, DOI 10.1109/ICIP.2011.6115695
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Vieira A, 2015, INT CONF IMAG PROC, P494, DOI 10.1109/IPTA.2015.7367195
   Wanner S., 2011, GENERATING EPI REPRE
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zhou CY, 2011, IEEE T IMAGE PROCESS, V20, P3322, DOI 10.1109/TIP.2011.2171700
NR 33
TC 13
Z9 13
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 21
EP 30
DI 10.1016/j.jvcir.2018.03.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800003
DA 2024-07-18
ER

PT J
AU Chen, ZX
   Yao, SS
   Jia, YY
   Liu, CY
AF Chen, Zhenxue
   Yao, Saisai
   Jia, Yunyi
   Liu, Chengyun
TI Face sketch-photo synthesis and recognition: Dual-scale Markov Network
   and multi-information fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sketch face synthesis and recognition; Dual-scale Markov Network;
   Structural information; Feature information; Fusion
ID FEATURES
AB Sketch face recognition (SFR) has been widely and successfully applied in law enforcement, which attracts a growing number of researchers. In this paper, a face sketch-photo synthesis and recognition method is proposed. Our method has two parts: Firstly, according to the different synthesis results for different scales, a cascade sketch-photo synthesis method via dual-scale Markov Network is utilized for image synthesis; Secondly, structural information and feature information-based data fusion method has been presented for face recognition. It is inspired by the Face Recognition Cognitive Theory, which applies both structural information and feature information for recognition. The experimental results on different databases based on the proposed method, demonstrate the outperformance of our method compared with state-of-the-art methods both in synthesis and recognition processes.
C1 [Chen, Zhenxue; Yao, Saisai; Liu, Chengyun] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
   [Jia, Yunyi] Clemson Univ, Dept Automot Engn, Greenville, SC 29607 USA.
C3 Shandong University; Clemson University
RP Chen, ZX (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
EM chenzhenxue@sdu.edu.cn
RI gao, peng/KEI-1840-2024; luo, yuan/JLS-6416-2023; YAN,
   LING/JXY-6904-2024
OI Chen, Zhenxue/0000-0001-9637-5170
FU National Natural Science Foundation of China [61203261]; China
   Postdoctoral Science Foundation [2012M521335]; Jiangsu Key Laboratory of
   Big Data Analysis Technology/B-DAT (Nanjing University of Information
   Science Technology) [KXK1404]; Research Fund of Guangxi Key Lab of
   Multi-source Information Mining Security [MIMS16-02]; Shenzhen science
   and technology research and development funds [JCYJ20170307093018753];
   Fundamental Research Funds of Shandong University [2017JC043]
FX This work has been supported by National Natural Science Foundation of
   China (61203261), China Postdoctoral Science Foundation funded project
   (2012M521335), Jiangsu Key Laboratory of Big Data Analysis
   Technology/B-DAT (Nanjing University of Information Science &
   Technology, Grant No.: KXK1404), Research Fund of Guangxi Key Lab of
   Multi-source Information Mining & Security (MIMS16-02), Shenzhen science
   and technology research and development funds (JCYJ20170307093018753)
   and The Fundamental Research Funds of Shandong University (2017JC043).
   We would also like to thank the CUHK Database from Multimedia Laboratory
   of The Chinese University of Hong Kong, AR Database from A. Martinez and
   R. Benavente, respectively.
CR [Anonymous], SIGN INF PROC ASS AN
   [Anonymous], SOC PHOTOOPTICAL INS
   [Anonymous], INT C BIOM ICB
   [Anonymous], THESIS
   [Anonymous], 21 SIGN PROC COMM AP
   [Anonymous], INT J PATTERN RECOGN
   [Anonymous], THESIS
   [Anonymous], IEEE INT C AC SPEECH
   Balcan MF, 2006, MACH LEARN, V65, P79, DOI 10.1007/s10994-006-7550-1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Gao XB, 2012, IEEE T CIRC SYST VID, V22, P1213, DOI 10.1109/TCSVT.2012.2198090
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   Kalamkar KD, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1286, DOI 10.1109/ICCSP.2015.7322716
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Kukharev G. A., 2014, Pattern Recognition and Image Analysis, V24, P102, DOI 10.1134/S1054661814010076
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Liu Yao, 2011, Computer Engineering and Design, V32, P4119
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez A., 1998, AR FACE DATABASE
   Peng CL, 2017, IEEE T CIRC SYST VID, V27, P288, DOI 10.1109/TCSVT.2015.2502861
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Silva MAA, 2014, 2014 27TH SIBGRAPI CONFERENCE ON GRAPHICS, PATTERNS AND IMAGES (SIBGRAPI), P57, DOI 10.1109/SIBGRAPI.2014.24
   Song ML, 2012, INFORM SCIENCES, V193, P233, DOI 10.1016/j.ins.2012.01.004
   Tang X, 2002, IEEE IMAGE PROC, P257
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Wang Ke, 2015, Scalable resource management system software for extreme-scale distributed systems
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao B, 2009, SIGNAL PROCESS, V89, P1576, DOI 10.1016/j.sigpro.2009.02.008
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhang Y., 2008, 2 IEEE INT C BIOMETR, P1
   Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788
NR 40
TC 3
Z9 3
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 112
EP 121
DI 10.1016/j.jvcir.2017.12.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500011
DA 2024-07-18
ER

PT J
AU Manchanda, M
   Sharma, R
AF Manchanda, Meenu
   Sharma, Rajiv
TI An improved multimodal medical image fusion algorithm based on fuzzy
   transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimodal medical image fusion; Fuzzy transform; Fusion performance
   measures
AB Multimodal medical image fusion has become a powerful tool in clinical applications. The main aim is to fuse different multimodal medical images, obtained from different imaging modalities, into a single fused image that is extensively used by the physicians for explicit diagnosis and treatment of diseases. In this paper, an improved multimodal medical image fusion algorithm based on fuzzy transform (FTR) is proposed. The core idea behind the proposed algorithm is to improve the performance of multimodal medical image fusion algorithm by taking into consideration the error images obtained using FTR pair. Subjective as well as objective evaluations demonstrate that the fusion quality in terms of edge strength, standard deviation, feature mutual information, fusion factor, feature similarity and structural similarity has significantly improved in the proposed algorithm as compared to other state-of-art multimodal medical image fusion algorithms.
C1 [Manchanda, Meenu] Maharshi Dayanand Univ, Univ Inst Engn & Technol, Rohtak, Haryana, India.
   [Sharma, Rajiv] Guru Gobind Singh Indraprastha Univ GGSIPU, Northern India Engn Coll, New Delhi, India.
C3 Maharshi Dayanand University; GGS Indraprastha University
RP Manchanda, M (corresponding author), Maharshi Dayanand Univ, Univ Inst Engn & Technol, Rohtak, Haryana, India.
EM meenumanchanda73@gmail.com; rsap70@rediffmail.com
CR [Anonymous], 2015, INT J FUZZY COMPUTAT
   [Anonymous], T ROUGH SETS
   Arathi T, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P225, DOI 10.1109/ARTCom.2009.192
   Bede B, 2011, FUZZY SET SYST, V180, P20, DOI 10.1016/j.fss.2011.03.001
   Belohlavek O, 2005, NUCL MED REV, V8, P87
   Ben Hamza A, 2005, INTEGR COMPUT-AID E, V12, P135
   Ben Hamza A, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY - PROCEEDINGS, P257
   Bhatnagar G, 2015, NEUROCOMPUTING, V157, P143, DOI 10.1016/j.neucom.2015.01.025
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Bhatnagar G, 2013, EXPERT SYST APPL, V40, P1708, DOI 10.1016/j.eswa.2012.09.011
   Boss A, 2010, J NUCL MED, V51, P1198, DOI 10.2967/jnumed.110.074773
   Dankova M, 2006, J ELECT ENG, V7, P82
   Das S., 2011, Progress In Electromagnetics Research B, V30, P355
   Dogra A, 2017, PATTERN RECOGN LETT, V94, P189, DOI 10.1016/j.patrec.2017.03.002
   Dong J, 2009, SENSORS-BASEL, V9, P7771, DOI 10.3390/s91007771
   Ezzati R., 2012, INT J PHYS SCI, V7, P1578
   Gambhir D, 2015, INT J MACH LEARN CYB, V6, P935, DOI 10.1007/s13042-015-0374-1
   Ghantous M, 2013, J SIGNAL PROCESS SYS, V71, P41, DOI 10.1007/s11265-012-0679-1
   Holcapek M, 2011, FUZZY SET SYST, V180, P69, DOI 10.1016/j.fss.2011.05.028
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Li X., 2007, APPL NUMERICAL HARMO
   Liu Z, 2007, PATTERN RECOGN LETT, V28, P166, DOI 10.1016/j.patrec.2006.06.019
   Manchanda M, 2016, J VIS COMMUN IMAGE R, V40, P197, DOI 10.1016/j.jvcir.2016.06.021
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Nemec SF, 2007, EUR J RADIOL, V62, P192, DOI 10.1016/j.ejrad.2006.11.029
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Perfilieva I, 2005, ADV SOFT COMP, P221
   Perfilieva I, 2008, INT J APPROX REASON, V48, P36, DOI 10.1016/j.ijar.2007.06.003
   Perfilieva I, 2014, KNOWL-BASED SYST, V70, P55, DOI 10.1016/j.knosys.2014.04.007
   Perfilieva I, 2010, INFORM SCIENCES, V180, P3304, DOI 10.1016/j.ins.2010.04.029
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9
   Saeedi J, 2012, APPL SOFT COMPUT, V12, P1041, DOI 10.1016/j.asoc.2011.11.020
   Schillaci O, 2014, CLIN TRANSL IMAGING, V2, P477, DOI 10.1007/s40336-014-0091-x
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Stathaki T, 2011, Image fusion: algorithms and applications
   Stepnicka M, 2005, IEEE INT CONF FUZZY, P1104
   Stepnicka M, 2011, FUZZY SET SYST, V180, P164, DOI 10.1016/j.fss.2011.02.017
   Valipour M, 2016, METEOROL APPL, V23, P91, DOI 10.1002/met.1533
   Valipour M, 2015, METEOROL APPL, V22, P592, DOI 10.1002/met.1491
   Valipour M, 2013, J HYDROL, V476, P433, DOI 10.1016/j.jhydrol.2012.11.017
   Vlasanek P., 2013, 8TH CONFERENCE OF TH
   Vlasánek P, 2013, ADV FUZZY SYST, V2013, DOI 10.1155/2013/593694
   Wang L, 2013, IMAGING SCI J, V61, P529, DOI 10.1179/1743131X12Y.0000000016
   Wang L, 2014, INFORM FUSION, V19, P20, DOI 10.1016/j.inffus.2012.03.002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   Yonghong J., 1998, Remote Sensing Technology and Application, V13, P46
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao L, 2005, LECT NOTES ARTIF INT, V3613, P717
NR 53
TC 57
Z9 58
U1 7
U2 81
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 76
EP 94
DI 10.1016/j.jvcir.2017.12.011
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500008
DA 2024-07-18
ER

PT J
AU Yun, D
   Park, W
   Kim, SJ
   Chung, K
AF Yun, Dooyeol
   Park, Woonjoo
   Kim, Sun-Joong
   Chung, Kwangsue
TI HTTP adaptive streaming scheme for improving the quality of experience
   in multi-server environments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HTTP adaptive streaming; Multi-server environment; Quality of experience
ID VIDEO
AB Many studies have been conducted on multi-server HTTP Adaptive Streaming (HAS). The existing schemes can highly utilize the available bandwidth by aggregating the multipath bandwidth and improve the video quality by switching servers when network congestion occurs. However, these existing schemes have problems that adversely affect the Quality of Experience (QoE) in a multi-server environment. To cope with these problems, we analyze the existing HAS schemes in multi-server environments. Through simulation-based performance analysis, we prove that these existing schemes lead to playback stalling and frequent quality changes. Based on the analysis, we propose a new HAS scheme for multi-server environments. The proposed scheme improves the QoE by alleviating the problems of the existing schemes. Through the simulation results, we prove that the proposed scheme alleviates the shortcomings of the existing schemes and improves QoE metrics compared with the existing multi-server schemes.
C1 [Yun, Dooyeol; Chung, Kwangsue] Kwangwoon Univ, 447-1 Wolgye Dong, Seoul, South Korea.
   [Park, Woonjoo; Kim, Sun-Joong] ETRI, 218 Gajeong Ro, Daejeon, South Korea.
C3 Kwangwoon University; Electronics & Telecommunications Research
   Institute - Korea (ETRI)
RP Chung, K (corresponding author), Kwangwoon Univ, 447-1 Wolgye Dong, Seoul, South Korea.
EM kchung@kw.ac.kr
RI Kim, Jong-Hwa/ABB-3723-2021
OI Kim, Jong-Hwa/0000-0002-3343-4820
FU Electronics and Telecommunications Research Institute (ETRI) - Korean
   government [17ZH1600]
FX This work was supported by Electronics and Telecommunications Research
   Institute (ETRI) grant funded by the Korean government. [17ZH1600,
   Development of programmable interactive media creation service platform
   based on open scenario].
CR Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   [Anonymous], 2011, P IEEE INT C MULT EX
   [Anonymous], 2014, 230091 ISOIEC DIS
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], 2011, 26247 GPP TS
   [Anonymous], 2015, 1449612 ISOIEC
   [Anonymous], 2014, RFC7233 IETF
   Begen A., 2011, IEEE INTERNET COMPUT, V15, P44
   Claeys M, 2014, IEEE COMMUN LETT, V18, P716, DOI 10.1109/LCOMM.2014.020414.132649
   Delphinanto A, 2011, IEEE COMMUN MAG, V49, P134, DOI 10.1109/MCOM.2011.5783998
   Hossfeld Tobias, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P494, DOI 10.1109/ISM.2011.87
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Kim T, 2005, IEEE J SEL AREA COMM, V23, P344, DOI 10.1109/JSAC.2004.839390
   Lai C. F., 2011, IEEE WIREL COMMUN, V3, P62
   Lederer S., 2013, Proceedings of the 4th ACM Multimedia Systems Conference (MMSys '13), P131
   Liu C., 2011, P ACM MULT SYST FEBR, P167
   Liu L, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P5, DOI [10.1109/MHS.2014.7006157, 10.1109/VCIP.2014.7051490]
   Mok R.K., 2011, PROC ACM SIGCOMM WOR, P31, DOI DOI 10.1145/2018602.2018611
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Tian G., 2012, P 8 INT C EM NETW EX, P109
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Wang C, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P917, DOI 10.1109/CLOUD.2015.125
   Wu JY, 2014, J NETW COMPUT APPL, V44, P17, DOI 10.1016/j.jnca.2014.05.003
   Xu CQ, 2013, IEEE T MOBILE COMPUT, V12, P2193, DOI 10.1109/TMC.2012.189
   Zhang SK, 2015, IEEE ICC, P6849, DOI 10.1109/ICC.2015.7249417
   Zhou C, 2016, IEEE T MULTIMEDIA, V18, P738, DOI 10.1109/TMM.2016.2522650
   Zhou C, 2014, IEEE T CIRC SYST VID, V24, P681, DOI 10.1109/TCSVT.2013.2290580
NR 28
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 14
EP 22
DI 10.1016/j.jvcir.2018.01.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500002
DA 2024-07-18
ER

PT J
AU Wang, S
   Wang, CM
   Zhang, Q
   Liu, YP
   Zhu, C
   Duan, C
AF Wang, Shuai
   Wang, Chunmei
   Zhang, Qian
   Liu, Yipeng
   Zhu, Ce
   Duan, Chang
TI Extended smoothlets: An efficient multi-resolution adaptive transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Smoothlets; Wedgelets; Multiresolution; Adaptive transform;
   Approximation; Denoising
AB As a family of multiresolution adaptive transforms and a generalization of wedgelets, smoothlets are more efficient in representing images with various sharp edges than other "X-lets". Smoothlets use a horizon function to model an edge and define transition in a fixed axis direction. Furthermore, the conventional elliptical smoothlets (ES) use half of an ellipse to model edges. Various sharp edges of images may not be expressed well by half of an ellipse with transition only in a fixed axis direction. In this paper, we propose extended smoothlets (ExSmoothlets) framework by using more general characteristic functions with adaptive transition directions. Specifically, two methods of ExSmoothlets, the elliptical ExSmoothlets (EES) and homocentric elliptical ExSmoothlets (HEES) are developed and evaluated in the experiments against the ES. The results show that the proposed EES and HEES can effectively improve the image quality in image approximation and denoising in terms of PSNR.
C1 [Wang, Shuai; Zhang, Qian; Liu, Yipeng; Zhu, Ce; Duan, Chang] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Sichuan, Peoples R China.
   [Wang, Shuai; Liu, Yipeng; Zhu, Ce] Univ Elect Sci & Technol China, Ctr Robot, Chengdu, Sichuan, Peoples R China.
   [Wang, Chunmei] Wuhan Inst Technol, Sch Comp Sci & Engn, Wuhan, Hubei, Peoples R China.
   [Duan, Chang] South West Petr Univ, Sch Elect Engn & Informat, 8 Xindu Rd, Chengdu 610500, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Wuhan Institute of Technology;
   Southwest Petroleum University
RP Duan, C (corresponding author), South West Petr Univ, Sch Elect Engn & Informat, 8 Xindu Rd, Chengdu 610500, Sichuan, Peoples R China.
EM pertinax@163.com
RI Liu, Yipeng/M-5434-2016; Zhu, Ce/AEN-1875-2022
OI Liu, Yipeng/0000-0003-2084-8781; 
FU National Natural Science Foundation of China [61571102, U1733111];
   Scientific research project of Sichuan Provincial Department of
   Education [16ZA0057]; Fundamental Research Funds for the Central
   Universities [ZYGX2014Z003]; National High Technology Research and
   Development Program of China [2015AA015903]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61571102, U1733111, in part by
   Scientific research project of Sichuan Provincial Department of
   Education 16ZA0057, in part by the Fundamental Research Funds for the
   Central Universities under Grant ZYGX2014Z003, and in part by the
   National High Technology Research and Development Program of China under
   Grant 2015AA015903.
CR Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Candes E., 1999, CURVES SURFACE FITTI, P105
   Candes E.J., 1998, EJ RID THER AND APP
   Chandrasekaran V, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P563
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Do M., 2003, Studies in Computational Mathematics, V10, P83, DOI DOI 10.1016/S1570-579X(03)80032-0
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4119, P434, DOI 10.1117/12.408630
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Kiani V, 2016, SIGNAL PROCESS-IMAGE, V41, P115, DOI 10.1016/j.image.2015.12.005
   Kiani V, 2016, J VIS COMMUN IMAGE R, V34, P65, DOI 10.1016/j.jvcir.2015.10.009
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Liang SY, 2017, NMR BIOMED, V30, DOI 10.1002/nbm.3776
   Lisowka Agnieszka, 2005, THESIS
   Lisowska A., 2014, GEOMETRICAL MULTIRES, V545
   Lisowska A, 2007, EUROCON 2007: THE INTERNATIONAL CONFERENCE ON COMPUTER AS A TOOL, VOLS 1-6, P102
   Lisowska A, 2011, IEEE T IMAGE PROCESS, V20, P1777, DOI 10.1109/TIP.2011.2108662
   Lisowska A, 2011, J MATH IMAGING VIS, V39, P180, DOI 10.1007/s10851-010-0233-3
   Liu YP, 2017, IEEE T MED IMAGING, V36, P2148, DOI 10.1109/TMI.2017.2717502
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Meyer FG, 1997, APPL COMPUT HARMON A, V4, P147, DOI 10.1006/acha.1997.0208
   Prasad DK, 2013, PATTERN RECOGN, V46, P1449, DOI 10.1016/j.patcog.2012.11.007
   Wang Shuai, 2016, CN Patent, Patent No. [CN 201,610,623,894, 201610623894]
   Willett RM, 2003, IEEE T MED IMAGING, V22, P332, DOI 10.1109/TMI.2003.809622
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 26
TC 1
Z9 1
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 178
EP 185
DI 10.1016/j.jvcir.2017.11.018
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700018
DA 2024-07-18
ER

PT J
AU Kan, SC
   Cen, YG
   Cen, Y
   Wang, YH
   Voronin, V
   Mladenovic, V
   Zeng, M
AF Kan, Shi-Chao
   Cen, Yi-Gang
   Cen, Yi
   Wang, Yan-Hong
   Voronin, Viacheslav
   Mladenovic, Vladimir
   Zeng, Ming
TI SURF binarization and fast codebook construction for image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SURF binarization; Two-step clustering algorithm; Scalable overlapping
   partition; Image retrieval; Object search
ID NEAREST-NEIGHBOR; QUANTIZATION; SEARCH; CODES; VLAD
AB A new framework for image retrieval/object search is proposed based on the VLAD model and SURF descriptors to improve the codebook construction speed, the image matching accuracy, and the online retrieval speed and to reduce the data storage. First, SURF binarization and dimensionality reduction methods are proposed to convert a 64-dimensional SURF descriptor into an 8-dimensional descriptor. Second, a two-step clustering algorithm is proposed for codebook construction to significantly reduce the computational cost of clustering while maintaining the accuracy of the clustering results. Moreover, for object search, a scalable overlapping partition method is proposed to segment an image into 65 patches with different sizes so that the object can be matched quickly and efficiently. Finally, a feature fusion strategy is employed to compensate the performance degradation caused by the information loss of our proposed dimensionality reduction method. Experiments on the Holidays and Oxford datasets demonstrate the effectiveness and efficiency of the proposed algorithms. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Kan, Shi-Chao; Cen, Yi-Gang; Wang, Yan-Hong] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Kan, Shi-Chao; Cen, Yi-Gang; Wang, Yan-Hong] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Cen, Yi] Minzu Univ China, Sch Informat Engn, Beijing 100081, Peoples R China.
   [Voronin, Viacheslav] Don State Tech Univ, Dept Radioelect Syst, Rostov Na Donu 346500, Russia.
   [Mladenovic, Vladimir] Univ Kragujevac, Fac Tech Sci, Cacak, Serbia.
   [Zeng, Ming] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Minzu
   University of China; Don State Technical University; University of
   Kragujevac; South China University of Technology
RP Cen, YG (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM ygcen@bjtu.edu.cn
RI wang, yan/JBJ-7462-2023; Voronin, Viacheslav V/H-7334-2013; SUN,
   Ye/KBC-8159-2024; Zeng, Ming/GXF-3628-2022; Mladenovic,
   Vladimir/M-5716-2015; Wang, Yanbo/HFZ-8018-2022; Wang,
   Yin/HCI-9352-2022; wang, yan/GSE-6489-2022; wang, yi/GVT-8516-2022; Cen,
   Yigang/AAC-1999-2019; Wang, Yuan/HHC-1520-2022; wang,
   yiran/IAP-0414-2023; wangwangwang, yuanyaunyuan/HHN-6432-2022
OI Voronin, Viacheslav V/0000-0001-8114-6383; Zeng,
   Ming/0000-0003-2836-9240; Mladenovic, Vladimir/0000-0001-8530-2312; 
FU National Natural Science Foundation of China [61572067, 61602538];
   International (Regional) Project Cooperation and Exchanges of National
   Nature Science Foundation of China [61611530710]; Beijing Municipal
   Natural Science Foundation [4162050]; Natural Science Foundation of
   Guangdong Province [2016A030313708]; Fundamental Research Funds for the
   Central Universities [2017JBZ108]
FX This work was supported by National Natural Science Foundation of China
   (61572067, 61602538); International (Regional) Project Cooperation and
   Exchanges of National Nature Science Foundation of China (61611530710);
   Beijing Municipal Natural Science Foundation (4162050); The Natural
   Science Foundation of Guangdong Province (2016A030313708) and the
   Fundamental Research Funds for the Central Universities (2017JBZ108).
CR Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 2012, IM AN MULT INT SERV
   [Anonymous], 2012, P 20 ACM MULTIMEDIA
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Bo L., 2011, Neural Information Processing Systems, P2115
   Charikar M., 2002, P THIRY 4 ANN ACM S, P380
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Farquhar J.D. H., 2005, Improving "bag-of-keypoints" image categorisation: Generative models and pdf-kernels
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Huiskes M., 2010, Proceedings of the international conference on Multimedia information retrieval
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang Y., 2010, IEEE T IMAGE PROCESS, V21, P3080
   Jiang YN, 2015, IEEE T IMAGE PROCESS, V24, P1748, DOI 10.1109/TIP.2015.2405337
   Jiang YN, 2012, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2012.6248042
   Jiang YN, 2011, IEEE IMAGE PROC, P113, DOI 10.1109/ICIP.2011.6115629
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Liu Z, 2016, IEEE T CIRC SYST VID, V26, P375, DOI 10.1109/TCSVT.2015.2409693
   Liu Z, 2015, IEEE T MULTIMEDIA, V17, P538, DOI 10.1109/TMM.2015.2399851
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P2047, DOI 10.1109/TIP.2014.2312283
   Liu ZQ, 2016, NEUROCOMPUTING, V173, P1183, DOI 10.1016/j.neucom.2015.08.076
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makadia A, 2010, LECT NOTES COMPUT SC, V6315, P310, DOI 10.1007/978-3-642-15555-0_23
   Mikulk A., 2015, P 11 EUR C COMP VIS, P1
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8691, P660, DOI 10.1007/978-3-319-10578-9_43
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   Sun SY, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2818708
   Torii A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P102, DOI 10.1109/ICCVW.2011.6130230
   Wang YH, 2017, NEUROCOMPUTING, V236, P14, DOI 10.1016/j.neucom.2016.08.106
   Weiss Y., 2008, P NIPS, V282, P1753
   Yu FX, 2014, PR MACH LEARN RES, V32, P946
   Yuan Junsong., 2007, IEEE International Conference on Computer Vision (ICCV), P1
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhang SG, 2010, PROCEEDINGS OF THE ASME JOINT RAIL CONFERENCE, VOL 2, P501, DOI 10.1145/1873951.1874018
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
   Zhou QZ, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080311
NR 52
TC 17
Z9 20
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 104
EP 114
DI 10.1016/j.jvcir.2017.08.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800009
DA 2024-07-18
ER

PT J
AU Qureshi, MA
   Deriche, M
   Beghdadi, A
   Amin, A
AF Qureshi, Muhammad Ali
   Deriche, Mohamed
   Beghdadi, Azeddine
   Amin, Asjad
TI A critical survey of state-of-the-art image inpainting quality
   assessment metrics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Image quality assessment; Inpainting quality;
   Inpainting databases; Image inpainting quality assessment; Survey
ID OBJECT REMOVAL; FRAMEWORK; PRIORITY
AB Image inpainting is the process of restoring missing pixels in digital images in a plausible way. Research in image inpainting has received considerable attention in different areas, including restoration of old and damaged documents, removal of undesirable objects, computational photography, retouching applications, etc. The challenge is that the recovery processes themselves introduce noticeable artifacts within and around the restored image regions. As an alternative to subjective evaluation by humans, a number of approaches have been introduced to quantify inpainting processes objectively. Unfortunately, existing objective metrics have their own strengths and weaknesses as they use different criteria. This paper provides a thorough insight into existing metrics related to image inpainting quality assessment, developed during the last few years. The paper provides, under a new framework, a comprehensive description of existing metrics, their strengths, their weaknesses, and a detailed performance analysis on real images from public image inpainting database. The paper also outlines future research directions and applications of inpainting and inpainting-related quality assessment measures. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Qureshi, Muhammad Ali; Deriche, Mohamed; Amin, Asjad] KFUPM, Dhahran 31261, Saudi Arabia.
   [Qureshi, Muhammad Ali; Amin, Asjad] Islamia Univ Bahawalpur, Bahawalpur 63100, Pakistan.
   [Beghdadi, Azeddine] Univ Paris 13, Sorbonne Paris Cite, Inst Galilee, L2TI, Paris, France.
C3 King Fahd University of Petroleum & Minerals; Islamia University of
   Bahawalpur; Universite Paris 13
RP Qureshi, MA (corresponding author), KFUPM, Dhahran 31261, Saudi Arabia.
EM ali.qureshi@iub.edu.pk; mderiche@kfupm.edu.sa;
   azeddine.beghdadi@univ-paris13.fr; asjad.amin@iub.edu.pk
RI Beghdadi, Azeddine/ABF-9801-2022; Deriche, Mohamed/A-9871-2008; Qureshi,
   Muhammad Ali/C-3857-2012
OI Beghdadi, Azeddine/0000-0002-5595-0615; Deriche,
   Mohamed/0000-0002-5287-1874; Qureshi, Muhammad Ali/0000-0003-4390-2461
FU joint Center of Energy and Geoprocessing (CeGP) at King Fahd University
   of Petroleum & Minerals (KFUPM) [GTEC 1401-1402]; Georgia Tech
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments. The work presented here has been developed
   in collaboration with L2TI Research Lab, Univ. Paris 13. The research
   was supported in part by the project GTEC 1401-1402 under the joint
   Center of Energy and Geoprocessing (CeGP) at King Fahd University of
   Petroleum & Minerals (KFUPM) and Georgia Tech.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2006, PROC COLOR IMAG C
   Ardis P.A., 2009, P SOC PHOTO-OPT INS, V7257
   Ardis PA, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267088
   Arias P, 2012, MULTISCALE MODEL SIM, V10, P473, DOI 10.1137/110848281
   Beghdadi A, 2013, SIGNAL PROCESS-IMAGE, V28, P811, DOI 10.1016/j.image.2013.06.003
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Cao F, 2011, SIAM J IMAGING SCI, V4, P1143, DOI 10.1137/110823572
   Chan RH, 2008, SIAM J IMAGING SCI, V1, P273, DOI 10.1137/070711499
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P312, DOI 10.1016/j.jvcir.2016.06.029
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dang TT, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1019, DOI 10.1109/GlobalSIP.2014.7032275
   Dang TT, 2013, IEEE IMAGE PROC, P398, DOI 10.1109/ICIP.2013.6738082
   Dang TT, 2012, INT CONF IMAG PROC, P280, DOI 10.1109/IPTA.2012.6469544
   Frantc VA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2063664
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P147, DOI 10.5201/ipol.2012.g-tvi
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P539, DOI 10.1109/TIP.2005.863057
   Hardeberg JY, 2008, COLOR TECHNOL, V124, P243, DOI 10.1111/j.1478-4408.2008.00148.x
   Hays J, 2008, COMMUN ACM, V51, P87, DOI 10.1145/1400181.1400202
   Herling J, 2012, INT SYM MIX AUGMENT, P141, DOI 10.1109/ISMAR.2012.6402551
   Isogawa M, 2016, IEEE IMAGE PROC, P3538, DOI 10.1109/ICIP.2016.7533018
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Le Meur O, 2012, LECT NOTES COMPUT SC, V7577, P554, DOI 10.1007/978-3-642-33783-3_40
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Liu TJ, 2013, APSIPA TRANS SIGNAL, V2, DOI 10.1017/ATSIP.2013.5
   Ma XL, 2015, J VIS COMMUN IMAGE R, V32, P95, DOI 10.1016/j.jvcir.2015.08.003
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   Oliveira M. M., 2001, Visualization, Imaging, and Image Processing. Proceedings of the IASTED International Conference, P261
   Oncu AI, 2012, LECT NOTES COMPUT SC, V7583, P561, DOI 10.1007/978-3-642-33863-2_58
   Peterson I., 2002, SCI NEWS, V161, P299
   Qureshi M., 2016, EUR WORKSH VIS INF P, P1
   Qureshi MA, 2014, 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P979, DOI 10.1109/GlobalSIP.2014.7032267
   Qureshi MA, 2016, MULTIMED TOOLS APPL, V75, P6737, DOI 10.1007/s11042-015-2590-9
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Rodriguez-Sánchez R, 2013, PATTERN RECOGN LETT, V34, P1508, DOI 10.1016/j.patrec.2013.06.002
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Siegel S., 1956, Nonparametric statistics for the behavioral sciences
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Dang TT, 2013, 2013 COLOUR AND VISUAL COMPUTING SYMPOSIUM (CVCS)
   Thanh Trung Dang, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P76
   Tiefenbacher P, 2015, IEEE IMAGE PROC, P447, DOI 10.1109/ICIP.2015.7350838
   Trung D.T., 2013, 21 EUR SIGN PROC C E, P1
   Venkatesh MV, 2010, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2010.5653640
   Viacheslav V, 2014, INT CONF SIGN PROCES, P643, DOI 10.1109/ICOSP.2014.7015082
   Voronin V., 2015, WSCG 2015 Conference on Computer Graphics, Visualization and Computer Vision, P167
   Voronin V.V., 2015, P SOC PHOTO-OPT INS
   Wang S, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P786, DOI 10.1109/ICYCS.2008.461
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zhang Q, 2012, J INF SCI ENG, V28, P641
   Zhao Q, 2013, SIGNAL PROCESS, V93, P1401, DOI 10.1016/j.sigpro.2012.06.014
NR 56
TC 45
Z9 47
U1 1
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 177
EP 191
DI 10.1016/j.jvcir.2017.09.006
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800015
DA 2024-07-18
ER

PT J
AU Lin, BW
   Wang, FS
   Sun, Y
   Qu, W
   Chen, Z
   Zhang, S
AF Lin, Baowei
   Wang, Fasheng
   Sun, Yi
   Qu, Wen
   Chen, Zheng
   Zhang, Shuo
TI Boundary points based scale invariant 3D point feature
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D point clouds; Boundary points; Scale space; Scale invariant; 3D point
   feature
ID OBJECT RECOGNITION; SURFACE
AB In this paper, we propose a method for encoding scale invariant 3D point features. We extract a set of boundary points from a point cloud. Next, we apply the scale-space concept on the boundary points to detect the scale invariant point border. We confirm three orthometric axes as the local reference frames. Three distribution matrices are generated by implementing the strategy of SPIN image method, and one row-vector of descriptors are finally calculated. Experimental results on simulated and real scene point clouds demonstrate that the scale-invariant features of 3D point clouds can be effectively encoded by our method. (C) 2017 Published by Elsevier Inc.
C1 [Lin, Baowei; Wang, Fasheng; Sun, Yi; Qu, Wen; Chen, Zheng] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
   [Lin, Baowei; Wang, Fasheng] Dalian Neusoft Univ Informat, Dept Elect Engn, Dalian, Peoples R China.
   [Lin, Baowei; Zhang, Shuo] Alibaba Grp, AutoNavi, Dalian, Peoples R China.
C3 Dalian University of Technology; Alibaba Group
RP Sun, Y (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
EM lslwf@dlut.edu.cn
RI lin, baowei/AFA-9377-2022; Wang, Fasheng/AAD-9930-2020
OI lin, baowei/0000-0003-0427-4431; Wang, Fasheng/0000-0002-0946-0789
FU Liaoning Province Doctoral Research Foundation [201601315]; Dalian Youth
   Science and Technology Foundation [2015R092]; Natural Science Foundation
   of Liaoning Education Ministry [L2014575]; National Natural Science
   Foundation [61300082]; Liaoning Natural Science Foundation [2015020015]
FX This work was supported by Liaoning Province Doctoral Research
   Foundation, 201601315; Dalian Youth Science and Technology Foundation,
   No. 2015R092; Natural Science Foundation of Liaoning Education Ministry,
   No. L2014575; National Natural Science Foundation Granted, No. 61300082
   and Liaoning Natural Science Foundation, No. 2015020015.
CR [Anonymous], IEEJ T ELECTRO INF S
   [Anonymous], STAT SHAPE ANAL
   [Anonymous], ICIP
   [Anonymous], 2014, CVPR
   Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Castellani U, 2008, COMPUT GRAPH FORUM, V27, P643, DOI 10.1111/j.1467-8659.2008.01162.x
   Changchang Wu, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563037
   Cheung W, 2009, IEEE T IMAGE PROCESS, V18, P2012, DOI 10.1109/TIP.2009.2024578
   Crivellaro A., 2014, CVPR
   Darom T, 2012, IEEE T IMAGE PROCESS, V21, P2758, DOI 10.1109/TIP.2012.2183142
   Du S., 2007, ICIP
   Fang Y., 2015, CVPR
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Huang X, 2014, CVPR
   Hurley J. R., 1962, BEHAV SCI
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Knopp J., 2010, P ECCV, V2010
   Kortgen M., 2003, CENTRAL EUR SEMIN CO
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lin B., 2015, ICIP
   Lin BW, 2014, MACH VISION APPL, V25, P1989, DOI 10.1007/s00138-014-0633-2
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mellado N, 2016, IEEE T VIS COMPUT GR, V22, P2160, DOI 10.1109/TVCG.2015.2505287
   Rodolà E, 2013, INT J COMPUT VISION, V102, P129, DOI 10.1007/s11263-012-0568-x
   Rusu A. B., 2008, P IAS10, V16, P635
   Rusu RaduBogdan., 2010, IROS
   Rusu RB, 2009, P ICRA2009
   Rusu RB, 2009, ICCV
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Steder B., 2010, WORKSH DEF SOLV REAL
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Unnikrishnan Ranjith, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563030
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Wohlkinger Walter., 2011, ROBIO
   Yu Fisher, 2015, CVPR
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zinger T., 2005, INT C PATT REC IM PR
NR 47
TC 4
Z9 5
U1 2
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 136
EP 148
DI 10.1016/j.jvcir.2017.05.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700011
DA 2024-07-18
ER

PT J
AU Zhang, DY
   Yin, T
   Yang, GB
   Xia, M
   Li, LD
   Sun, XM
AF Zhang, Dengyong
   Yin, Ting
   Yang, Gaobo
   Xia, Ming
   Li, Leida
   Sun, Xingming
TI Detecting image seam carving with low scaling ratio using multi-scale
   spatial and spectral entropies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Content-aware image retargeting; Seam carving; Low
   scaling ratios; Spatial and frequency entropy; Object removal
ID QUALITY ASSESSMENT
AB Seam carving is the most popular content-aware image retargeting technique. However, it may also be used to correct poor photo composition in photography competition or to remove object from image for malicious purpose. A blind detection approach is presented for seam carved image with low scaling ratio (LSR). It exploits spatial and spectral entropies (SSE) on multi-scale images (candidate image and its down-sampled versions). We observe that when a few seams are deleted from an original image, its SSE distribution is greatly changed. Forty-two features are designed to unveil the statistical properties of SSE in terms of centralized tendency, dispersion tendency and distribution tendency. They are combined with the local binary pattern (LBP)-based energy features to form ninety-six features. Finally, support vector machine (SVM) is exploited as classifier to determine whether an image is original or suffered from seam carving. Experimental results show that the proposed approach achieves superior detection accuracy over the state-of-the-art works, especially for resized image by seam carving with LSRs. Moreover, it is robust against JPEG compression and seam insertion. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Zhang, Dengyong; Yin, Ting; Yang, Gaobo; Xia, Ming] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Zhang, Dengyong] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha 410114, Hunan, Peoples R China.
   [Li, Leida] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology; China
   University of Mining & Technology; Nanjing University of Information
   Science & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI li, li/HII-4157-2022; Sun, Xingming/AAD-1866-2019; Li, Li/AEM-3636-2022
FU National Natural Science Foundation of China [61572183, 61379143,
   61672222]; Scientific Research Fund of Hunan Provincial Education
   Department of China [15C0083, 14C0029]; Natural Science Foundation of
   Hunan Province [2016JJ2005, 2017JJ2291]
FX This work is supported in part by the National Natural Science
   Foundation of China (61572183, 61379143, 61672222), the Scientific
   Research Fund of Hunan Provincial Education Department of China
   (14C0029,15C0083), Natural Science Foundation of Hunan Province
   (2016E2005, 2017JJ2291).
CR Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Ferraro M, 1999, IEEE T PATTERN ANAL, V21, P1199, DOI 10.1109/34.809112
   Fillion C, 2010, IS T SPIE ELECT IMAG
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Karimi M, 2017, J VIS COMMUN IMAGE R, V43, P108, DOI 10.1016/j.jvcir.2016.12.011
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li K, 2015, SIGNAL PROCESS-IMAGE, V39, P509, DOI 10.1016/j.image.2015.07.005
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Liu D, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574674
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu QZ, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2560365
   Niu YZ, 2012, MULTIMED TOOLS APPL, V56, P485, DOI 10.1007/s11042-010-0613-0
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Ryu SJ, 2014, IEICE T INF SYST, VE97D, P1304, DOI 10.1587/transinf.E97.D.1304
   Sarkar A, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P107
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Wang J., MULTIMEDIA TOOLS APP
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Wattanachote K, 2015, IEEE T INF FOREN SEC, V10, P2477, DOI 10.1109/TIFS.2015.2464776
   Wei JD, 2014, PATTERN RECOGN LETT, V36, P100, DOI 10.1016/j.patrec.2013.09.026
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
   Yin T, 2015, COMPUT SECUR, V55, P130, DOI 10.1016/j.cose.2015.09.003
   Zhang YB, 2016, IEEE T IMAGE PROCESS, V25, P4286, DOI 10.1109/TIP.2016.2585884
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 29
TC 53
Z9 54
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 281
EP 291
DI 10.1016/j.jvcir.2017.07.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700022
DA 2024-07-18
ER

PT J
AU Dou, H
   Chan, YL
   Ji, KB
   Siu, WC
AF Dou, Huan
   Chan, Yui-Lam
   Ji, Ke-Bin
   Siu, Wan-Chi
TI Segment-based view synthesis optimization scheme in 3D-HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; 3D video coding; Depth coding; View synthesis optimization
   (VSO); Synthesized view distortion change (SVDC); Early skip mode
ID MULTIVIEW VIDEO; DEPTH; DISTORTION
AB The 3D extension of high efficiency video coding (3D-HEVC) adopts a view synthesis optimization (VSO) technique to improve the quality of synthesized views for depth map coding. The exact synthesized view distortion change (SVDC) is calculated in VSO which in turn brings huge coding complexity to the 3D-HEVC encoder due to the real view synthesis process. This work presents a scheme aimed at reducing coding complexity of the SVDC calculating process in the 3D-HEVC encoder. It skips line segments of pixels with variable lengths based on information from both of the textures and depth maps in the SVDC calculation. Experimental results demonstrate that the proposed scheme can reduce the coding complexity without any significant loss in rate distortion performance for the synthesized views. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Dou, Huan; Ji, Ke-Bin] Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing, Peoples R China.
   [Dou, Huan; Chan, Yui-Lam; Siu, Wan-Chi] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Beijing University of Technology; Hong Kong Polytechnic University
RP Chan, YL (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
EM douhuan88@gmail.com; enylchan@polyu.edu.hk; kebinj@bjut.edu.cn;
   enwcsiu@polyu.edu.hk
RI Chan, Yui-Lam/C-3799-2014
OI Chan, Yui-Lam/0000-0002-1473-094X
FU Central Research Grant of POLYU, China [PolyU 5119/13E]; Project for the
   National Natural Science Foundation of China [61672064]; Project for the
   key Project of Beijing Municipal Education Commission [KZ201610005007];
   Beijing Postdoctoral Research Foundation [2015ZZ-23]; China Postdoctoral
   Research Foundation [2015M580029, 2016T90022]; Computational
   Intelligence and Intelligent System of Beijing Key Laboratory Research
   Foundation [002000546615004]
FX This work was supported by Central Research Grant of POLYU, China (Grant
   PolyU 5119/13E), Project for the National Natural Science Foundation of
   China (Grant No. 61672064), the Project for the key Project of Beijing
   Municipal Education Commission (Grant KZ201610005007), Beijing
   Postdoctoral Research Foundation (Grant 2015ZZ-23),China Postdoctoral
   Research Foundation (Grant 2015M580029, 2016T90022), and Computational
   Intelligence and Intelligent System of Beijing Key Laboratory Research
   Foundation (Grant 002000546615004).
CR [Anonymous], JCT3VG1100 ITUT SG 1
   [Anonymous], 2012, INT C 3D IMAGING
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2012, P ASIA PAC SIG INF P
   [Anonymous], VCEGM33 ITUT Q6SG16
   [Anonymous], 2011, MPEG2011N12036 ISOIE
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kim W.S., 2010, P SPIE VISUAL INFORM
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li CY, 2014, IEEE IMAGE PROC, P3228, DOI 10.1109/ICIP.2014.7025653
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Ma R, 2013, IEEE IMAGE PROC, P1714, DOI 10.1109/ICIP.2013.6738353
   Ma SW, 2014, IEEE T MULTIMEDIA, V16, P266, DOI 10.1109/TMM.2013.2284751
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Oh B.T., 2012, JCT3VA0093 ITUT SG 1
   Oh BT, 2014, IEEE T CIRC SYST VID, V24, P1006, DOI 10.1109/TCSVT.2013.2290577
   Peng ZJ, 2015, J VIS COMMUN IMAGE R, V33, P309, DOI 10.1016/j.jvcir.2015.10.003
   Schwarz H, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P101, DOI 10.1109/PCS.2012.6213296
   Smolic A., 2007, JVTW100 ISOIECJTC1SC
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P25, DOI 10.1109/PCS.2012.6213277
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Zhang L, 2013, IEEE INT SYMP CIRC S, P1632, DOI 10.1109/ISCAS.2013.6572175
   Zhang T., 2012, P IEEE VIS COMM IM P, P1, DOI DOI 10.1109/VCIP.2012.6410848
   Zhang Y, 2014, IEEE T IMAGE PROCESS, V23, P4879, DOI 10.1109/TIP.2014.2355715
NR 29
TC 2
Z9 5
U1 2
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 104
EP 111
DI 10.1016/j.jvcir.2016.11.012
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200008
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhou, YY
   Lin, MS
   Xu, S
   Zang, H
   He, HS
   Li, Q
   Guo, J
AF Zhou, Yingyue
   Lin, Maosong
   Xu, Su
   Zang, Hongbin
   He, Hongsen
   Li, Qiang
   Guo, Jin
TI An image denoising algorithm for mixed noise combining nonlocal means
   filter and sparse representation technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Mixed noise; Nonlocal means; Noise classification;
   Complementary sparse coding; Sparse representation
ID IMPULSE NOISE; REMOVAL
AB Nonlocal means (NLM) filtering or sparse representation based denoising method has obtained a remarkable denoising performance. In order to integrate the advantages of two methods into a unified framework, we propose an image denoising algorithm through skillfully combining NLM and sparse representation technique to remove Gaussian noise mixed with random-valued impulse noise. In the non-Gaussian circumstance, we propose a customized blockwise NLM (CBNLM) filter to generate an initial denoised image. Based on it, we classify the different noisy pixels according to the three-sigma rule. Besides, an overcomplete dictionary is trained on the initial denoised image. Then, a complementary sparse coding technique is used to find the sparse vector for each input noisy patch over the overcomplete dictionary. Through solving a more reasonable variational denoising model, we can reconstruct the clean image. Experimental results verify that our proposed algorithm can obtain the best denoising performance, compared with some typical methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhou, Yingyue; Lin, Maosong; Xu, Su; He, Hongsen; Li, Qiang] Southwest Univ Sci & Technol, Sch Informat Engn, Robot Technol Used Special Environm Key Lab Sichu, Mianyang 621010, Sichuan, Peoples R China.
   [Zang, Hongbin] Southwest Univ Sci & Technol, Sch Mfg Sci & Engn, Mianyang 621010, Sichuan, Peoples R China.
   [Guo, Jin] Southwest Univ Finance & Econ, Tian Fu Coll, Mianyang 621010, Sichuan, Peoples R China.
C3 Southwest University of Science & Technology - China; Southwest
   University of Science & Technology - China; Southwestern University of
   Finance & Economics - China
RP Zhou, YY (corresponding author), Southwest Univ Sci & Technol, Sch Informat Engn, Robot Technol Used Special Environm Key Lab Sichu, Mianyang 621010, Sichuan, Peoples R China.
EM zhouyingyue@swust.edu.cn; lms@swust.edu.cn; 4571122@qq.com;
   zanghongb@163.com; hongsen.nju@gmail.com; 35717468@qq.com;
   49263957@qq.com
RI he, hongsen/KJL-7843-2024
FU National Natural Science Foundation of China [61401379, 61571376];
   General Project of Educational Commission of Sichuan Province in China
   [14ZB0107]; Doctoral Research Fund of Southwest University of Science
   and Technology in China [13zx7148]; Open Foundation Project of Robot
   Technology Used for Special Environment Key Laboratory of Sichuan
   Province in China [13zxtk07]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61401379 and 61571376); the General Project of
   Educational Commission of Sichuan Province in China (Grant No.
   14ZB0107); the Doctoral Research Fund of Southwest University of Science
   and Technology in China (Grant No. 13zx7148); the Open Foundation
   Project of Robot Technology Used for Special Environment Key Laboratory
   of Sichuan Province in China (Grant No. 13zxtk07). The authors would
   like to thank the anonymous reviewers for their valuable comments, which
   help to improve the quality of this paper. The authors would like to
   thank Renjie Tong from University of Science and Technology of China to
   modify the English description of this paper.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2018, Robust Statistics: Theory and Methods (with R)
   [Anonymous], 1998, P 6 INT C COMP VIS
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen CLP, 2015, IEEE T IMAGE PROCESS, V24, P4014, DOI 10.1109/TIP.2015.2456432
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Coupé P, 2009, IEEE T IMAGE PROCESS, V18, P2221, DOI 10.1109/TIP.2009.2024064
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gu YF, 2014, NEUROCOMPUTING, V124, P120, DOI 10.1016/j.neucom.2013.07.022
   Hu HJ, 2016, J SCI COMPUT, V67, P103, DOI 10.1007/s10915-015-0073-9
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Xiong B, 2012, IEEE T IMAGE PROCESS, V21, P1663, DOI 10.1109/TIP.2011.2172804
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou YY, 2012, IET IMAGE PROCESS, V6, P976, DOI 10.1049/iet-ipr.2011.0312
   Zhou YY, 2013, J VIS COMMUN IMAGE R, V24, P283, DOI 10.1016/j.jvcir.2013.01.004
NR 28
TC 16
Z9 17
U1 1
U2 49
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 74
EP 86
DI 10.1016/j.jvcir.2016.09.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000008
DA 2024-07-18
ER

PT J
AU Czaplewski, B
AF Czaplewski, Bartosz
TI Joint fingerprinting and decryption method for color images based on
   quaternion rotation with cipher quaternion chaining
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fingerprinting; Quaternions; Joint fingerprinting and decryption;
   Collusion attack; Traitor tracing
ID WATERMARKING; ENCRYPTION; ALGORITHM; SCHEME
AB This paper addresses the problem of unauthorized redistribution of multimedia content by malicious users (pirates). In this method three color channels of the image are considered a 3D space and each component of the image is represented as a point in this 3D space. The distribution side uses a symmetric cipher to encrypt perceptually essential components of the image with the encryption key and then sends the encrypted data via multicast transmission to all users. The encryption involves rotation, and translation of points in 3D color space using quaternion algebra. Each user has a unique decryption key which is different from the encryption key. The differences between the common encryption key and the individual user's decryption key cause the decrypted image to contain minor changes which are user's fingerprint. A computer-based simulation was conducted to examine the method's robustness against noise, compression, and collusion attacks. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Czaplewski, Bartosz] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Dept Teleinformat Networks, Gabriela Narutowicza 11-12, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Czaplewski, B (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Dept Teleinformat Networks, Gabriela Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM bartosz.czaplewski@eti.pg.gda.pl
RI Czaplewski, Bartosz/AFQ-1291-2022
OI Czaplewski, Bartosz/0000-0001-7904-5567
CR Adelsbach A, 2006, LECT NOTES COMPUT SC, V4058, P136
   Ammar M., 2000, P 10 INT WORKSH NETW
   Anderson R, 1997, LECT NOTES COMPUT SC, V1267, P107
   [Anonymous], 2014, J TELECOMMUN INF TEC
   Baker M.J., 2014, MATHS QUATERNIONS
   Celik MU, 2008, IEEE T INF FOREN SEC, V3, P475, DOI 10.1109/TIFS.2008.926988
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Choong-Hoon Lee, 1999, Proceedings of IEEE. IEEE Region 10 Conference. TENCON 99. `Multimedia Technology for Asia-Pacific Information Infrastructure' (Cat. No.99CH37030), P702, DOI 10.1109/TENCON.1999.818511
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Czaplewski B., 2014, TELECOMMUN REV TELEC, V8-9, P1170
   Czaplewski B., 2012, P ICT YOUNG 2012 C, P231
   Czaplewski B., 2011, GDANSK U TECHNOLOGY, V1, P237
   Czaplewski B., 2013, TELECOMMUN REV TELEC, V8-9, P830
   Czaplewski B, 2015, SIGNAL PROCESS, V111, P150, DOI 10.1016/j.sigpro.2014.12.026
   Czaplewski B, 2014, PATTERN RECOGN LETT, V46, P11, DOI 10.1016/j.patrec.2014.05.001
   Dimauro Giovanni, 2012, 2012 IEEE International Conference on Virtual Environments Human-Computer Interfaces and Measurement Systems (VECIMS), P69
   Dzwonkowski M., 2013, TELECOMMUN REV TELEC, V8-9, P1216
   Dzwonkowski M., 2012, P ICT YOUNG C GDANSK, P21
   Goldman R., 2009, An Integrated Introduction to Computer Graphics and Geometric Modeling
   Goldman R, 2011, GRAPH MODELS, V73, P21, DOI 10.1016/j.gmod.2010.10.004
   He S., 2006, IEEE T INF FORENSICS
   Katzenbeisser S, 2007, LECT NOTES COMPUT SC, V4567, P294
   Kedia D., 2012, INT J DISTRIB PARALL, V3, P63, DOI DOI 10.5121/IJDPS.2012.3307
   Kettunen K., 1997, LIC COURS SIGN PROC
   Kortun A., 2003, EE 574 DETECTION EST
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Kuribayashi M, 2011, EURASIP J INF SECUR, DOI 10.1155/2011/502782
   Li M, 2014, SIGNAL PROCESS, V99, P17, DOI 10.1016/j.sigpro.2013.12.011
   Li SJ, 2011, IEEE IMAGE PROC, P1537, DOI 10.1109/ICIP.2011.6115738
   Li X.W., 2011, J INF HIDING MULTIME, V2, P366
   Li XW, 2011, AEU-INT J ELECTRON C, V65, P942, DOI 10.1016/j.aeue.2011.03.005
   Lin CY, 2014, SIGNAL PROCESS, V98, P52, DOI 10.1016/j.sigpro.2013.11.011
   Lin CY, 2012, SIGNAL PROCESS, V92, P2159, DOI 10.1016/j.sigpro.2012.02.002
   Liu K. J. R., 2005, Multimedia Fingerprinting Forensics for Traitor Tracing
   Maity SP, 2007, PATTERN RECOGN LETT, V28, P350, DOI 10.1016/j.patrec.2006.04.004
   Mehan V., 2013, P 2013 IEEE INT C SI, P1
   Mishra A., 2012, P 2012 INT JOINT C N, P10
   Nagase T, 2004, IEEE INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES 2004 (ISCIT 2004), PROCEEDINGS, VOLS 1 AND 2, P74
   Nagase T, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2 (REGULAR PAPERS), PROCEEDINGS, P35
   Parviainen R, 2001, INT FED INFO PROC, V64, P149
   Prangjarote P, 2012, INT CONF GENET EVOL, P27, DOI 10.1109/ICGEC.2012.107
   Rawat S, 2012, SIGNAL PROCESS, V92, P1480, DOI 10.1016/j.sigpro.2011.12.006
   Rykaczewski R., 2010, GDANSK U TECHNOLOGY, V19, P231
   Suthaharan S, 2000, PATTERN RECOGN LETT, V21, P145, DOI 10.1016/S0167-8655(99)00141-5
   Tardos G., 2008, JACM, V55, P116
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wu M, 2004, IEEE SIGNAL PROC MAG, V21, P15
   Xu YY, 2014, J VIS COMMUN IMAGE R, V25, P805, DOI 10.1016/j.jvcir.2014.01.005
   Zhang F., 1997, QUATERNION MATRICES, P21
   Zhao HV, 2005, IEEE T IMAGE PROCESS, V14, P646, DOI 10.1109/TIP.2005.846035
NR 51
TC 8
Z9 9
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 1
EP 13
DI 10.1016/j.jvcir.2016.06.006
PN A
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500001
DA 2024-07-18
ER

PT J
AU Haweel, RT
   El-Kilani, WS
   Ramadan, HH
AF Haweel, Reem T.
   El-Kilani, Wail S.
   Ramadan, Hassan H.
TI Fast approximate DCT with GPU implementation for image compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Approximate DCT transforms; Fast algorithms; Image compression; GPU
ID TRANSFORM
AB Recent developments in image and video processing employed in multimedia and communication systems require fast 2-D Discrete Cosine Transforms (DCT). The DCT is widely employed in image compression for its high power compaction property. Approximate DCT transforms have been developed to proceed faster than the original DCT while maintaining comparative levels of power compaction. This paper introduces a multiplierless efficient and low complexity 8-point approximate DCT. A flow diagram is provided for the fast implementation of the proposed transform. Only 17 additions are required for both forward and backward transformations. A fast and efficient Graphics Processing Unit (GPU) implementation for the proposed transform is provided. Performance evaluation shows that the proposed transform outperforms other approximate DO' transforms in JPEG-like image compression. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Haweel, Reem T.; Ramadan, Hassan H.] Ain Shams Univ, Fac Comp & Informat Sci, Dept Basic Sci, Cairo 11566, Egypt.
   [El-Kilani, Wail S.] Ain Shams Univ, Fac Comp & Informat Sci, Comp Syst Dept, Cairo 11566, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian Knowledge
   Bank (EKB); Ain Shams University
RP Haweel, RT (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Dept Basic Sci, Cairo 11566, Egypt.
EM reem_tarek_@hotmail.com; wail.elkilani@gmail.com; hramadan@eun.eg
CR Abd-Elhafiez WM, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES'2012), P141, DOI 10.1109/ICCES.2012.6408500
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2009, 2009 INT C MICR ICM
   [Anonymous], IEEE T CIRC SYST
   [Anonymous], INT C COMP VIS SOFTW
   [Anonymous], LOW POWER HIGH QUALI
   [Anonymous], 2009, NVIDIA's Fermi : the first complete GPU computing architecture
   [Anonymous], INT J ADV RES ELECT
   [Anonymous], IEEE INT S CIRC SYST
   [Anonymous], NVIDA CUFFT LIB VERS
   [Anonymous], CUDA C PROGR GUID VE
   [Anonymous], 2008, 2008 2 INT C SIGN CI
   [Anonymous], ADV COMPUT INT J ACI
   [Anonymous], 9 IEEE INT C COMP EN
   [Anonymous], IEEE T ACOUST SPEECH
   Bouguezel S, 2008, ELECTRON LETT, V44, P1249, DOI 10.1049/el:20082239
   Bouguezel S, 2010, MIDWEST SYMP CIRCUIT, P509, DOI 10.1109/MWSCAS.2010.5548745
   Brahimi N., 2011, 2011 7th International Workshop on Systems, Signal Processing and their Applications (WOSSPA 2011), P71, DOI 10.1109/WOSSPA.2011.5931415
   Bramberger M, 2004, RTAS 2004: 10TH IEEE REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P174, DOI 10.1109/RTTAS.2004.1317262
   Cintra RJ, 2014, SIGNAL PROCESS, V99, P201, DOI 10.1016/j.sigpro.2013.12.027
   Cintra RJ, 2011, IEEE SIGNAL PROC LET, V18, P579, DOI 10.1109/LSP.2011.2163394
   CLARKE RJ, 1981, IEE PROC-F, V128, P359, DOI 10.1049/ip-f-1.1981.0061
   Haweel TI, 2001, SIGNAL PROCESS, V81, P2309, DOI 10.1016/S0165-1684(01)00106-2
   HOU HS, 1987, IEEE T ACOUST SPEECH, V35, P1455
   Lakhani G, 2013, IEEE T IMAGE PROCESS, V22, P1326, DOI 10.1109/TIP.2012.2228492
   Lin HY, 2009, IEEE IMAGE PROC, P4305, DOI 10.1109/ICIP.2009.5413665
   Magli E, 2003, INT GEOSCI REMOTE SE, P654
   Marsi S, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/80971
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Park IK, 2011, IEEE T PARALL DISTR, V22, P91, DOI 10.1109/TPDS.2010.115
   Rezaei M., 2005, 2005 IEEE 16th International Symposium on Personal, Indoor and Mobile Radio Communications (IEEE Cat. No. 05TH8889), P2284
   Saraswathy K, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P465, DOI 10.1109/iccsp.2013.6577097
   Senapati R, 2010, P ANN IEEE IND C IND, P1, DOI [10.1109/INDCON.2010.5712707, DOI 10.1109/INDCON.2010.5712707]
NR 33
TC 14
Z9 14
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 357
EP 365
DI 10.1016/j.jvcir.2016.07.003
PN A
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500031
DA 2024-07-18
ER

PT J
AU Boudine, B
   Kramm, S
   El Akkad, N
   Bensrhair, A
   Saaidi, A
   Satori, K
AF Boudine, Bouchra
   Kramm, Sebastien
   El Akkad, Nabil
   Bensrhair, Abdelaziz
   Saaidi, Abderahim
   Satori, Khalid
TI A flexible technique based on fundamental matrix for camera
   self-calibration with variable intrinsic parameters from two views
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Self-calibration; Variable intrinsic parameters; Fundamental matrix;
   Absolute conic; Unknown 3D scene
ID PARALLEL FRAMEWORK; AUTOCALIBRATION; RECONSTRUCTION; CONSTRAINTS
AB We propose a new self-calibration technique for cameras with varying intrinsic parameters that can be computed using only information contained in the images themselves. The method does not need any a priori knowledge on the orientations of the camera and is based on the use of a 3D scene containing an unknown isosceles right triangle. The importance of our approach resides at minimizing constraints on the self-calibration system and the use of only two images to estimate these parameters. This method is based on the formulation of a nonlinear cost function from the relationship between two matches which are the projection of two points representing vertices of an isosceles right triangle, and the relationship between the images of the absolute conic. The resolution of this function enables us to estimate the cameras intrinsic parameters. The algorithm is implemented and validated on several sets of synthetic and real image data. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Boudine, Bouchra; El Akkad, Nabil; Saaidi, Abderahim; Satori, Khalid] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Dept Math & Comp Sci, LIIAN, PO 1796, Fes, Morocco.
   [Boudine, Bouchra; Kramm, Sebastien; Bensrhair, Abdelaziz] INSA ROUEN, LITIS, Ave Univ, F-76801 Rouen, France.
   [Saaidi, Abderahim] Univ Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac, Dept Math Phys & Informat, LSI, PO 1223, Taza, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Universite de Rouen
   Normandie; Sidi Mohamed Ben Abdellah University of Fez
RP Boudine, B (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar El Mahraz, Dept Math & Comp Sci, LIIAN, PO 1796, Fes, Morocco.; Boudine, B (corresponding author), INSA ROUEN, LITIS, Ave Univ, F-76801 Rouen, France.
EM bouchra.boudine@gmail.com
RI AKKAD, Nabil EL/AAL-4049-2020; satori, khalid/GSE-3077-2022
OI AKKAD, Nabil EL/0000-0003-0277-8003; Saaidi,
   Abderrahim/0000-0003-1708-0468; SATORI, khalid/0000-0001-6055-4169
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   [Anonymous], 2002, Journal of Software, V13, P2286
   [Anonymous], 2005, ROBUST REGRESSION OU
   Beardsley P., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P683
   BOUFAMA B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1030, DOI 10.1109/ICCV.1995.466821
   Bougnoux S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P790, DOI 10.1109/ICCV.1998.710808
   Chandraker M, 2010, INT J COMPUT VISION, V90, P236, DOI 10.1007/s11263-009-0305-2
   de Agapito L., 1998, BRIT MACHINE VISION, P1
   De Agapito L., 1999, IEEE COMP SOC C COMP, V1
   Deriche R., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P567
   Di Stefano L, 2005, PATTERN RECOGN LETT, V26, P2129, DOI 10.1016/j.patrec.2005.03.022
   El Akkad N, 2014, VISUAL COMPUT, V30, P519, DOI 10.1007/s00371-013-0877-2
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fusiello A, 2004, IEEE T PATTERN ANAL, V26, P1633, DOI 10.1109/TPAMI.2004.125
   Harris C., 1988, ALVEY VISION C, V15, P5
   Hartley R., 1994, Applications of invariance in computer vision, P235, DOI 10.1007/3-540-58240-1_13
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley R. I., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P471
   HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P339, DOI 10.1109/ICPR.1996.546045
   Horaud R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P96, DOI 10.1109/ICCV.1998.710706
   Jiang ZT, 2012, J COMPUT, V7, P774, DOI 10.4304/jcp.7.3.774-778
   Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80
   Knight J., 2003, IEEE COMP SOC C COMP, V1, P1
   Kruppa Erwin, 1913, Zur Ermittlung eines Objektes aus zwei Perspektiven mit innerer Orientierung
   Leroy A., 1987, WILEY SERIES PROBABI, V1
   Lhuillier M, 2002, LECT NOTES COMPUT SC, V2351, P125
   Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233
   Luong Q.-T., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P589
   Luong Q.-T., 1992, THESIS, P11
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   Malis E, 2002, IEEE T PATTERN ANAL, V24, P1268, DOI 10.1109/TPAMI.2002.1033217
   Malis E, 2000, INT C PATT RECOG, P85, DOI 10.1109/ICPR.2000.905281
   Malis Ezio., 2000, EUROPEAN C COMPUTER, P610
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Muhlich M., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P305, DOI 10.1007/BFb0054749
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Pollefeys M, 1997, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.1997.609357
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Saaidi A., 2009, J GRAPH VIS IMAGE PR, V1687
   STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781
   Sturm P. F., 1999, IEEE COMP SOC C COMP, V1
   Torr P.H., 1994, BRIT MACH VIS C BMVC, P1
   Torr PHS, 1995, THESIS
   Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   Wang ZF, 2008, PROC CVPR IEEE, P887
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zeller C., 1996, Camera Self-Calibration from Video Sequences: the Kruppa Equations Revisited
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 57
TC 11
Z9 12
U1 0
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 40
EP 50
DI 10.1016/j.jvcir.2016.05.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900004
DA 2024-07-18
ER

PT J
AU Liu, YL
   Qu, XX
   Xin, GJ
AF Liu, Yuling
   Qu, Xinxin
   Xin, Guojiang
TI A ROI-based reversible data hiding scheme in encrypted medical images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; The medical image; ROI-based;
   LSB substitution
ID TAMPER DETECTION; WATERMARKING; ERROR
AB A novel ROI-based reversible data hiding scheme in encrypted medical images is proposed. Firstly, a content owner partitions an original medical image into the region of interest (ROI) and the region of noninterest (RONI), and then encrypts the image using an encryption key. A data-hider concatenates the least significant bits (LSB) of the encrypted ROI and Electronic Patient Record (EPR), and then embeds the concatenated data into the encrypted image by LSB substitution algorithm. With the encrypted medical image containing the embedded data, the receiver can extract the embedded data with the data-hiding key; if the receiver has the encryption key, a medical image similar to the original image can be obtained by directly decrypting the encrypted medical image; if the receiver has both the data-hiding key and the encryption key, the embedded data can be extracted without any error and ROI can be losslessly recovered after extracting the embedded data. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Yuling; Qu, Xinxin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Xin, Guojiang] Hunan Univ Chinese Med, Coll Management & Informat Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University; Hunan University of Chinese Medicine
RP Liu, YL (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM yuling_liu@126.com
RI Liu, Yuling/A-1216-2019
FU National Natural Science Foundation of China [61103215, 61303045,
   61373132, 61373133, 61402162]; Hunan Provincial Natural Science Key
   Foundation of China [13112031]; Youth Growth Plan of Hunan University
FX This work was partially supported by National Natural Science Foundation
   of China (Nos. 61103215, 61303045, 61373132, 61373133 and 61402162),
   Hunan Provincial Natural Science Key Foundation of China (No. 13112031),
   and Youth Growth Plan of Hunan University.
CR Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   Fujiyoshi M., 2013, P IEEE 17 INT S CONS, P93
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kundu M. K., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1457, DOI 10.1109/ICPR.2010.360
   Lavanya A, 2012, SADHANA-ACAD P ENG S, V37, P723, DOI 10.1007/s12046-012-0107-z
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Liu YL, 2015, IEICE T INF SYST, VE98D, P769, DOI 10.1587/transinf.2014ICP0001
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Qian Z.X., IEEE T CIRCUITS SYST
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Tan CK, 2011, J DIGIT IMAGING, V24, P528, DOI 10.1007/s10278-010-9295-4
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou J., IEEE T CIRCUITS SYST
NR 21
TC 46
Z9 49
U1 1
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 51
EP 57
DI 10.1016/j.jvcir.2016.05.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900005
DA 2024-07-18
ER

PT J
AU He, PS
   Jiang, XH
   Sun, TF
   Wang, SL
AF He, Peisong
   Jiang, Xinghao
   Sun, Tanfeng
   Wang, Shilin
TI Double compression detection based on local motion vector field analysis
   in static-background videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video forensics; Static-background videos; Double MPEG-4 compression;
   Background segmentation; Local motion vector field; Periodic analysis;
   GOP estimation; Bit-rate control mode
ID FORGERIES
AB Videos captured by stationary cameras are widely used in video surveillance and video conference. This kind of video often has static or gradually changed background. By analyzing the properties of static background videos, this work presents a novel approach to detect double MPEG-4 compression based on local motion vector field analysis in static-background videos. For a given suspicious video, the local motion vector field is used to segment background regions in each frame. According to the segmentation of backgrounds and the motion strength of foregrounds, the modified prediction residual sequence is calculated, which retains robust fingerprints of double compression. After post-processing, the detection and GOP estimation results are obtained by applying the temporal periodic analysis method to the final feature sequence. Experimental results have demonstrated better robustness and efficiency of the proposed method in comparison to several state-of-the-art methods. Besides, the proposed method is more robust to various rate control modes. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jiang, Xinghao] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200030, Peoples R China.
   Natl Engn Lab Informat Content Anal Tech, Shanghai GT036001, Peoples R China.
C3 Shanghai Jiao Tong University
RP Jiang, XH (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200030, Peoples R China.
EM gokeyhps@sjtu.edu.cn; xhjiang@sjtu.edu.cn; tfsun@sjtu.edu.cn;
   wsl@sjtu.edu.cn
RI He, Peisong/AAE-2082-2022; Tanfeng, Sun/J-7469-2015
FU National Natural Science Foundation of China [61272249, 61272439,
   61572320, 61572321]; Specialized Research Fund for the Doctoral Program
   of Higher Education [20120073110053]
FX The authors appreciate Dr. Bin Li for his great contribution to promote
   our work. This work was supported by the National Natural Science
   Foundation of China (Nos. 61272249, 61272439, 61572320, 61572321), and
   the Specialized Research Fund for the Doctoral Program of Higher
   Education (No. 20120073110053).
CR [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   Feng C, 2014, P 2 ACM WORKSH INF H, P171, DOI DOI 10.1145/2600918.2600923
   Gironi A., 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6226, DOI 10.1109/ICASSP.2014.6854801
   He PS, 2015, LECT NOTES ARTIF INT, V9227, P787, DOI 10.1007/978-3-319-22053-6_84
   Hosur P, 1999, P 2 INT C INF COMM S, P7
   Huang ZS, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P306, DOI 10.1109/ChinaSIP.2014.6889253
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Ke CH, 2015, MULTIMED TOOLS APPL, P1
   Labartino D, 2013, IEEE INT WORKSH MULT, P494, DOI 10.1109/MMSP.2013.6659338
   Liao D., 2011, IS T SPIE ELECT IMAG
   Luo W., 2008, ELECT IMAGING 2008
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Qin Yun-long, 2010, Acta Electronica Sinica, V38, P1597
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Su PC, 2015, J VIS COMMUN IMAGE R, V29, P103, DOI 10.1016/j.jvcir.2015.02.006
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Vazquez-Padin D., 2012, IEEE INT WORKSH INF
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Xu J., INT J PATTERN RECOGN, V27
NR 24
TC 28
Z9 31
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 55
EP 66
DI 10.1016/j.jvcir.2015.11.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600005
DA 2024-07-18
ER

PT J
AU Wang, DY
   Sun, Y
   Huang, YY
   Bai, MZ
   Li, HJ
AF Wang, Dayong
   Sun, Yu
   Huang, Yuanyuan
   Bai, Mingze
   Li, Hongjian
TI A fast mode decision algorithm applied in medium-grain quality scalable
   video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Temporal correlation; Spatial correlation; Inter-layer correlation;
   Correlation degree; Mode prediction; RD cost; Early termination; MGS
   coding
ID EFFICIENCY; EXTENSION
AB To increase the flexibility of bit stream adaptation in the H.264/Scalable Video Coding, Medium-Grain Scalable Video Coding (MGS), a variation of Coarse-Grain Scalable Video Coding (CGS), is included. The encoding structure of MGS is significantly different from that of CGS, and the encoding procedure of MGS is very complex. It is important to reduce encoding complexity without sacrificing MGS coding performance. In this paper, a fast mode decision algorithm is proposed for the enhancement layer of MGS based on its specific coding structure. First, the candidate modes and the coding sequence of the current macro-block (MB) are predicted based on mode correlations and correlation degrees. Next, early termination strategies, including Direct Mode, inter-layer, layer and spatial, and spatial-only, are proposed based on the coding structure of MGS and correlations. Finally, MBs are encoded in the order predicted with the four proposed early termination strategies to improve the coding speed. Experimental results show that the algorithm can achieve an average time saving of up to 85.44% with strong robustness and negligible loss in coding efficiency. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Dayong; Bai, Mingze] Chongqing Univ Posts & Telecommun, Sch Bioinformat, Chongqing, Peoples R China.
   [Sun, Yu] Univ Cent Arkansas, Dept Comp Sci, Conway, AR USA.
   [Huang, Yuanyuan] Chengdu Univ Informat Technol, Dept Network Engn, Chengdu, Peoples R China.
   [Li, Hongjian] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing, Peoples R China.
   [Wang, Dayong] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518057, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; University of
   Central Arkansas; Chengdu University of Information Technology;
   Chongqing University of Posts & Telecommunications; Tsinghua Shenzhen
   International Graduate School; Tsinghua University
RP Wang, DY (corresponding author), Chongqing Univ Posts & Telecommun, Sch Bioinformat, Chongqing, Peoples R China.
EM 18025441839@126.com
FU National Natural Science Foundation of China [61401247, 61501071]; China
   Postdoctoral Science Foundation [2013M540953]; Scientific and
   Technological Research Program of Chongqing Municipal Education
   Commission [KJ130514]; Nature Science Foundation Project of Chongqing
   [cstc2012-jjA40060]; Applied Basic Research Program of Sichuan Province
   [2014JY0168]
FX This work was supported by National Natural Science Foundation of China
   under Grant 61401247 and 61501071, China Postdoctoral Science Foundation
   under Grant 2013M540953, Scientific and Technological Research Program
   of Chongqing Municipal Education Commission under Grant KJ130514, Nature
   Science Foundation Project of Chongqing under Grant cstc2012-jjA40060,
   and the Applied Basic Research Program of Sichuan Province under Grant
   No. 2014JY0168.
CR Bjontegaard G., 2001, Document VCEG-M33
   Han WJ, 2010, IEEE T CIRC SYST VID, V20, P1709, DOI 10.1109/TCSVT.2010.2092612
   Jung SW, 2010, IEEE T CIRC SYST VID, V20, P201, DOI 10.1109/TCSVT.2009.2031387
   Kim ST, 2009, IEEE T CONSUM ELECTR, V55, P1572, DOI 10.1109/TCE.2009.5278029
   Li H., 2006, IEEE INT C AC SPEECH, V5, P545
   Li H, 2006, IEEE T CIRC SYST VID, V16, P889, DOI 10.1109/TCSVT.2006.877404
   Li XA, 2011, IEEE T BROADCAST, V57, P66, DOI 10.1109/TBC.2010.2082370
   Lin HC, 2010, IEEE T CIRC SYST VID, V20, P732, DOI 10.1109/TCSVT.2010.2045832
   Lin Hung-Chih, 2007, IEEE INT C IM PROC, V9, P289
   Liu PY, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P368, DOI 10.1109/ISDA.2008.263
   Lu X, 2013, IEEE T CIRC SYST VID, V23, P846, DOI 10.1109/TCSVT.2012.2226525
   Park CS, 2009, IEEE T CIRC SYST VID, V19, P1915, DOI 10.1109/TCSVT.2009.2031520
   REICHEL J, 2007, JVTY202
   Ren JF, 2008, IEEE T CONSUM ELECTR, V54, P877, DOI 10.1109/TCE.2008.4560174
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Shen LQ, 2010, IEEE IMAGE PROC, P4229, DOI 10.1109/ICIP.2010.5651298
   Shen LQ, 2010, IEEE SIGNAL PROC LET, V17, P887, DOI 10.1109/LSP.2010.2066966
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wang Dayong, J SIGNAL IM IN PRESS
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Wiegand T, 2010, IEEE T CIRC SYST VID, V20, P1661, DOI 10.1109/TCSVT.2010.2095692
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Yeh CH, 2010, IEEE T CIRC SYST VID, V20, P563, DOI 10.1109/TCSVT.2010.2041825
   Yu Chengwei, 2007, Journal of Tsinghua University (Science and Technology), V47, P1677
   Zhan B, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, VOLS 1-3, P485, DOI 10.1109/ISCIT.2007.4392067
   Zhao TS, 2012, IEEE T IMAGE PROCESS, V21, P2607, DOI 10.1109/TIP.2012.2186148
NR 28
TC 2
Z9 2
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 78
EP 88
DI 10.1016/j.jvcir.2015.10.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400007
DA 2024-07-18
ER

PT J
AU Zhou, ML
   Li, B
   Zhang, YF
AF Zhou, Mingliang
   Li, Bo
   Zhang, Yongfei
TI Content-adaptive parameters estimation for multi-dimensional rate
   control
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-dimensional rate control; Q-R-TQ; Video content-adaptive;
   Parameter estimation; Model coefficient; Update duration; Sliding
   window; Initial frame rate
ID PERCEPTUAL QUALITY ASSESSMENT; RATE CONTROL SCHEME; FRAME RATE; VIDEO
   QUALITY; BIT-RATE; QUANTIZATION; OPTIMIZATION; RESOLUTION; IMPACT
AB Multi-dimensional rate control schemes have been recently utilized to adapt video streams to dynamic network conditions and heterogeneous devices. However, current multi-dimensional rate control methods, which estimate the model coefficients using fixed update duration, usually yield inaccurate parameters for dynamically changing video content. To address this problem, a content-adaptive parameters estimation scheme is proposed for multi-dimensional rate control. Firstly, we propose to estimate the parameters using dynamical update duration based on video content and the update duration of the model coefficients is determined by jointly considering the varying picture complexity and feedback information from the actual encoding results, which can improve the model parameter estimation accuracy. Secondly, a coarse-to-fine initial parameter calculation method is proposed to refine the initial frame rate according to the channel condition and the video sequence characteristics. Extensive experimental results show that the proposed solutions outperform the state-of-the-art schemes, especially for video sequences with high temporal and spatial complexity. Furthermore, our algorithm also slightly reduces the computational complexity as compared to related algorithms. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhou, Mingliang; Li, Bo; Zhang, Yongfei] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Li, Bo; Zhang, Yongfei] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zhang, YF (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM zhangyf.ac@gmail.com
RI Li, Bo/AAA-8968-2020; Zhou, Mingliang/HPC-0298-2023; Li,
   bo/IWL-9318-2023; Zhang, Yongfei/A-1505-2010
OI Li, Bo/0000-0002-7294-6888; Zhang, Yongfei/0000-0002-5080-1733
FU National Science Fund for Distinguished Young Scholars [61125206];
   National Hi-Tech Research and Development Program (863 Program) of China
   [2014AA015102]; National Natural Science Foundation of China [61272502]
FX This work was partially supported by the National Science Fund for
   Distinguished Young Scholars (No. 61125206), National Hi-Tech Research
   and Development Program (863 Program) of China (2014AA015102) and
   National Natural Science Foundation of China (61272502).
CR [Anonymous], 2007, P 3 INT C NETW SERV
   BINH VP, 2013, COMPUTING MANAGEMENT, P225
   Chen JYC, 2007, IEEE T SYST MAN CY A, V37, P1063, DOI 10.1109/TSMCA.2007.904779
   Chien MC, 2012, IEEE T BROADCAST, V58, P200, DOI 10.1109/TBC.2011.2182550
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Feghali R, 2007, IEEE T BROADCAST, V53, P441, DOI 10.1109/TBC.2007.891700
   Gunawan IP, 2008, IEEE T BROADCAST, V54, P669, DOI 10.1109/TBC.2008.2000734
   Hsu CT, 2009, IEEE T BROADCAST, V55, P767, DOI 10.1109/TBC.2009.2032802
   Hu HM, 2011, J VIS COMMUN IMAGE R, V22, P504, DOI 10.1016/j.jvcir.2011.05.002
   Hu H, 2012, IEEE IMAGE PROC, P717, DOI 10.1109/ICIP.2012.6466960
   Hu SD, 2012, IEEE T IMAGE PROCESS, V21, P1911, DOI 10.1109/TIP.2011.2176347
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Janowski L, 2012, MULTIMED TOOLS APPL, V61, P769, DOI 10.1007/s11042-011-0932-9
   Jin SH, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P131, DOI 10.1109/MMSP.2007.4412835
   Kim CS, 2008, IEICE T COMMUN, VE91B, P1269, DOI 10.1093/ietcom/e91-b.5.1269
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Lu ZK, 2005, PROC SPIE, V5666, P554, DOI 10.1117/12.596845
   Ma Z, 2012, IEEE T CIRC SYST VID, V22, P671, DOI 10.1109/TCSVT.2011.2177143
   Maraj A, 2013, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (CONTEL 2013), P103
   Ou YF, 2014, IEEE T IMAGE PROCESS, V23, P2473, DOI 10.1109/TIP.2014.2303636
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   Wang DM, 2010, IEEE T BROADCAST, V56, P142, DOI 10.1109/TBC.2010.2043895
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yang ZX, 2010, IEEE T BROADCAST, V56, P418, DOI 10.1109/TBC.2010.2053970
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Zhan Ma, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3321, DOI 10.1109/ICIP.2011.6116382
   Zhang Y, 2013, 2013 VIS COMM IM PRO, P1
NR 32
TC 9
Z9 9
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 204
EP 218
DI 10.1016/j.jvcir.2015.11.011
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400018
DA 2024-07-18
ER

PT J
AU Li, LD
   Zhou, Y
   Wu, JJ
   Lin, WS
   Li, HL
AF Li, Leida
   Zhou, Yu
   Wu, Jinjian
   Lin, Weisi
   Li, Haoliang
TI GridSAR: Grid strength and regularity for robust evaluation of blocking
   artifacts in JPEG images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; No-reference; JPEG compression; Blocking
   artifacts; Block misalignment; Grid strength; Grid regularity; Human
   visual system
ID QUALITY ASSESSMENT; INFORMATION; VISIBILITY
AB Images are subject to blocking artifacts when they are compressed using the JPEG standard. Knowing the extent of blocking artifacts is thus necessary for such applications as automatic quality monitoring and restoration. The current blocking artifacts measures are based on a strong prior that the block boundaries are known in advance, which often does not hold in real-world applications. Therefore, their performances degrade significantly when block boundaries are misaligned. To address the problem, this paper presents a robust no-reference blocking artifacts evaluation metric for JPEG images based on grid strength and regularity (GridSAR). The underlying idea is to extract block grids from a JPEG image and quantify the grid image to evaluate the strength of blocking artifacts. To this end, a grid map of blocking artifacts is first extracted from the image in the spatial domain. Then the blocking artifacts of the image are evaluated by quantifying the strength and regularity of the grid image. Furthermore, in order to account for the varying sensitivities of human eyes to the blocking artifacts in smooth and textured areas, a masking function is also proposed. Experimental results on seven popular image quality databases demonstrate that GridSAR achieves the state-of-the-art performance, and is robust to block misalignments. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Li, Leida; Zhou, Yu] China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Peoples R China.
   [Wu, Jinjian] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Li, Haoliang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 China University of Mining & Technology; Xidian University; Nanyang
   Technological University; Nanyang Technological University
RP Li, LD (corresponding author), China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Peoples R China.
EM reader1104@hotmail.com
RI li, li/HII-4157-2022; Lin, Weisi/A-8011-2012; Wu, Jinjian/GQH-0222-2022;
   Li, Li/AEM-3636-2022; Lin, Weisi/A-3696-2011
OI Lin, Weisi/0000-0001-9866-1947; Li, Haoliang/0000-0002-8723-8112
FU National Natural Science Foundation of China [61379143]; Fundamental
   Research Funds for the Central Universities [2015QNA66]
FX This work is supported by National Natural Science Foundation of China
   (61379143), and Fundamental Research Funds for the Central Universities
   (2015QNA66).
CR [Anonymous], IEEE SIGNAL PROC LET
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], MICT image quality evaluation database
   Bovik AC, 2001, INT CONF ACOUST SPEE, P1725, DOI 10.1109/ICASSP.2001.941272
   Chang V, MULTIMED TOOLS APPL
   Chen CH, 2010, LECT NOTES COMPUT SC, V6297, P112, DOI 10.1007/978-3-642-15702-8_11
   Garcia-Alvarez JC, 2013, J VIS COMMUN IMAGE R, V24, P1316, DOI 10.1016/j.jvcir.2013.09.003
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Le Callet P., Subjective quality assessment IRCCyN/IVC database
   Lee S, 2012, SIGNAL PROCESS-IMAGE, V27, P31, DOI 10.1016/j.image.2011.08.002
   Li LD, 2014, IEICE T INF SYST, VE97D, P993, DOI 10.1587/transinf.E97.D.993
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P918, DOI 10.1109/LSP.2014.2320743
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P122, DOI 10.1109/LSP.2013.2294333
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu H, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/263540
   Ma L, 2013, CHINA COMMUN, V10, P62, DOI 10.1109/CC.2013.6520939
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Pan F, 2007, MULTIDIM SYST SIGN P, V18, P297, DOI 10.1007/s11045-006-0008-6
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N., 2009, Proceedings of the 4th International Workshop on Video Processing and Quality Metrics, P1
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Serir A, 2013, J VIS COMMUN IMAGE R, V24, P911, DOI 10.1016/j.jvcir.2013.06.002
   Shao L, 2011, J VIS COMMUN IMAGE R, V22, P23, DOI 10.1016/j.jvcir.2010.09.007
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Wang X, 2015, NEUROCOMPUTING, V151, P683, DOI 10.1016/j.neucom.2014.05.090
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wang Z, 2011, IEEE SIGNAL PROC MAG, V28, P137, DOI 10.1109/MSP.2011.942295
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu JJ, 2014, IEEE SIGNAL PROC LET, V21, P437, DOI 10.1109/LSP.2014.2304714
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P4892, DOI 10.1109/TIP.2013.2279934
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang Y, 2014, INFORM SCIENCES, V281, P601, DOI 10.1016/j.ins.2014.03.016
   Zaric A, 2011, ELMAR PROC, P105
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 43
TC 20
Z9 23
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 153
EP 163
DI 10.1016/j.jvcir.2015.04.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900014
DA 2024-07-18
ER

PT J
AU Sen, D
   Kankanhalli, M
AF Sen, Debashis
   Kankanhalli, Mohan
TI A bio-inspired center-surround model for salience computation in images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual salience; Human eye fixation; Center-surround model;
   Photoreceptor interaction; Nonlinear combination; Visual attention;
   Bio-inspired approach; Multi-scale filtering
ID VISUAL-ATTENTION; FREQUENCY
AB A center-surround model inspired by photoreceptor interactions and visual receptive field organization is presented in this paper for salience computation that predicts human eye fixation locations in images. The essence of photoreceptor interactions is implemented considering different nonlinear combinations of responses to stimuli given by values at nearby image pixels. These combinations are then fed to difference of Gaussian filtered outputs operation and Gabor filter based processes simulating visual receptive field organization. The proposed center-surround model is used in Itti et al.'s bio-inspired framework to perform salience computation. Analysis is carried out to present the information-theoretic aspect of the nonlinear combinations. Significance of the proposed center-surround model is shown both qualitatively and quantitatively by comparing its use in salience computation with the use of existing models considering different psychological patterns, and synthetic and real-life images. Quantitative and qualitative performance of salience computation using the novel center-surround model for three well-known datasets of images are also compared to that of relevant existing salience computation approaches to demonstrate the effectiveness of the proposed approach in generating salience maps closer to human eye fixation density maps. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Sen, Debashis; Kankanhalli, Mohan] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 National University of Singapore
RP Sen, D (corresponding author), Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
EM send@comp.nus.edu.sg; mohan@comp.nus.edu.sg
RI Sen, Debashis/R-3236-2016; Kankanhalli, Mohan/Q-9284-2019
OI Sen, Debashis/0000-0002-9756-1191; Kankanhalli,
   Mohan/0000-0002-4846-2015
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2008, NIPS
   Baluchi F, 2011, TRENDS NEUROSCI, V34, P210, DOI 10.1016/j.tins.2011.02.003
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Efron B., 1993, INTRO BOOTSTRAP, VVolume 914, DOI DOI 10.1007/978-1-4899-4541-9
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hae Jong Seo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204207
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Jessell TM., 2000, PRINCIPLES NEURAL SC
   Judd T., 2012, MIT CSAIL TR
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kootstra G, 2011, COGN COMPUT, V3, P223, DOI 10.1007/s12559-010-9089-5
   KUFFLER SW, 1953, J NEUROPHYSIOL, V16, P37, DOI 10.1152/jn.1953.16.1.37
   Lehmann E. L., 2008, TESTING STAT HYPOTHE
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Marr D., 1982, Visual perception
   Niebur E, 1998, ATTENTIVE BRAIN, P163
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Riche N, 2012, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2012.6466941
   RODIECK RW, 1965, J NEUROPHYSIOL, V28, P833, DOI 10.1152/jn.1965.28.5.833
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vikram T. N., 2011, 2011 IEEE WORKSH APP, P166
   Xu KM, 2006, MON WEATHER REV, V134, P1442, DOI 10.1175/MWR3133.1
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 39
TC 6
Z9 8
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 277
EP 288
DI 10.1016/j.jvcir.2015.04.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900025
DA 2024-07-18
ER

PT J
AU Feng, BW
   Lu, W
   Sun, W
AF Feng, Bingwen
   Lu, Wei
   Sun, Wei
TI Binary image steganalysis based on pixel mesh Markov transition matrix
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binary image; Steganalysis; Generalized embedding simulator;
   Connectivity; Smoothness; Pixel mesh; Texture consistency; Markov
   transition matrix
ID FRAMEWORK; CAPACITY
AB Binary image stego systems have already been well developed, which raises the requirement of a steganalytic method that detects these stego systems reliably. In this paper, a steganalytic method based on the pixel mesh Markov transition matrix (PMMTM) is presented to detect binary image steganography in the spatial domain. The proposed scheme measures the embedding distortion on the texture consistency. Further, the dependence among texture structures is organized as the Markov transition of pixel meshes. The final dimensionality-reduced feature set is formed by shrinking the obtained PMMTM according to its detection performance on the embedding simulators, which are developed to simulate practical stego systems. In the end, experimental results are reported, demonstrating that the proposed approach can effectively and reliably detect state-of-the-art binary image stego systems. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Feng, Bingwen; Lu, Wei] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Sun, W (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM bingwfeng@gmail.com; luwei3@mail.sysu.edu.cn; sunwei@mail.sysu.edu.cn
CR [Anonymous], 2011, INT J COMPUT SCI ENG
   Cao H., 2012, SIGN INF PROC ASS AN, P1
   Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang TC, 2006, IEEE T IMAGE PROCESS, V15, P1285, DOI 10.1109/TIP.2005.864162
   Cheng J, 2005, IEEE INT SYMP CIRC S, P4405
   Cheng J, 2005, INT CONF ACOUST SPEE, P689
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P683, DOI 10.1109/ARES.2010.65
   Chiew KL, 2010, FIFTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY: ARES 2010, PROCEEDINGS, P653, DOI 10.1109/ARES.2010.66
   CONNERS RW, 1980, IEEE T PATTERN ANAL, V2, P204, DOI 10.1109/TPAMI.1980.4767008
   Cover T. M., 2006, Elements of Information Theory, DOI DOI 10.1002/047174882X
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Feng B., 2013, INT WORKSH DIG WAT, P514
   Fillatre L, 2012, IEEE T SIGNAL PROCES, V60, P556, DOI 10.1109/TSP.2011.2174231
   Filler T., 2010, BOSS (Break Our Steganography System)
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2009, LECT NOTES COMPUT SC, V5806, P31, DOI 10.1007/978-3-642-04431-1_3
   Fridrich J, 2004, PROC SPIE, V5306, P23, DOI 10.1117/12.521350
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Ker A.D., 2008, ELECT IMAGING 2008 I
   Ker AD, 2005, LECT NOTES COMPUT SC, V3727, P296
   Lerch-Hostalot D, 2013, COMPUT SECUR, V32, P192, DOI 10.1016/j.cose.2012.11.005
   Liang Guang-lan, 2007, Journal of Shanghai University, V11, P272, DOI 10.1007/s11741-007-0317-2
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Mei Q, 2001, PROC SPIE, V4314, P369, DOI 10.1117/12.435420
   Meng Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1441, DOI 10.1109/ICPR.2010.356
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Povlow B. R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P642, DOI 10.1109/CVPR.1993.341048
   Shi Yun Q., 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P63, DOI 10.1007/978-3-642-36373-3_5
   Srinivasan GN, 2008, Proceedings of World Academy of Science, Engineering and Technology, V36, P1264
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Tuceryan M., 1993, HDB PATTERN RECOGNIT, V2, P207, DOI DOI 10.1142/9789814343138_0010
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Yang HJ, 2008, IEEE T MULTIMEDIA, V10, P339, DOI 10.1109/TMM.2008.917404
NR 41
TC 27
Z9 27
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 284
EP 295
DI 10.1016/j.jvcir.2014.10.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000026
DA 2024-07-18
ER

PT J
AU Tian, XL
   Jiao, LC
   Yi, L
   Guo, KW
   Zhang, XH
AF Tian, Xiaolin
   Jiao, Licheng
   Yi, Long
   Guo, Kaiwu
   Zhang, Xiaohua
TI The image segmentation based on optimized spatial feature of superpixel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Fuzzy c-means clustering; Superpixel; Wavelet;
   Spatial information; Particle swarm optimization; Synthetic aperture
   radar; Texture image; Natural image
ID FUZZY; ALGORITHM; INFORMATION; FCM
AB This paper proposes a method of image segmentation based on superpixels. The method is applied to achieve the segmentation of synthetic aperture radar (SAR) image. Firstly, the superpixels are extracted based on multi-scale features. Then, the fuzzy c-means (FCM) clustering based on superpixels is implemented, in which the influence of neighboring and similar superpixels is incorporated into FCM and the influential degree is optimized to improve segmentation performance. Experimental results show that the proposed method can achieve an impressive accuracy of SAR segmentation. For application extension, when we extract corresponding feature from several types of specific images, the proposed method is able to achieve better segmentation performance. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Tian, Xiaolin; Jiao, Licheng; Yi, Long; Guo, Kaiwu; Zhang, Xiaohua] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian 710071, Peoples R China.
C3 Xidian University
RP Tian, XL (corresponding author), Xidian Univ, Inst Intelligent Informat Proc, POB 224, Xian 710071, Peoples R China.
EM xltian@mail.xidian.edu.cn
RI Jiao, Licheng/JOZ-0842-2023
OI Jiao, Licheng/0000-0003-3354-9617
FU Natural Science Basic Research Plan in Shaanxi Province of China
   [2014JM8301]; Fundamental Research Funds for the Central Universities;
   National Natural Science Foundation of China [60972148, 61072106,
   61173092, 61271302, 61272282, 61001206, 61202176, 61271298]; Fund for
   Foreign Scholars in University Research and Teaching Programs (the 111
   Project) [B07048]; Program for Cheung Kong Scholars and Innovative
   Research Team in University [IRT1170]
FX This work is supported by the Project Supported by Natural Science Basic
   Research Plan in Shaanxi Province of China (Program No. 2014JM8301); The
   Fundamental Research Funds for the Central Universities; the National
   Natural Science Foundation of China under Grant Nos. 60972148, 61072106,
   61173092, 61271302, 61272282, 61001206, 61202176, and 61271298; The Fund
   for Foreign Scholars in University Research and Teaching Programs (the
   111 Project): No. B07048; the Program for Cheung Kong Scholars and
   Innovative Research Team in University: IRT1170.
CR Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], P INT C PATT REC
   [Anonymous], 2009, IEEE I CONF COMP VIS, DOI 10.1109/ICCV.2009.5459175
   [Anonymous], 2005, NEURIPS WORKSH THEOR
   [Anonymous], IEEE INT ADV COMP C
   [Anonymous], P INT S COMP SCI COM
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P3197, DOI 10.1016/j.patrec.2003.08.005
   Balla-Arabé S, 2013, IEEE T CYBERNETICS, V43, P910, DOI 10.1109/TSMCB.2012.2218233
   Bezdek James C., 1981, PATTERN RECOGN
   Bird S, 2006, IEEE C EVOL COMPUTAT, P843, DOI 10.1109/CEC.2006.1688399
   Cao HB, 2012, IEEE T FUZZY SYST, V20, P1, DOI 10.1109/TFUZZ.2011.2160025
   Chen L, 2011, IEEE T SYST MAN CY B, V41, P1263, DOI 10.1109/TSMCB.2011.2124455
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Despotovic I, 2013, IEEE SIGNAL PROC LET, V20, P295, DOI 10.1109/LSP.2013.2244080
   Eschrich S, 2003, IEEE T FUZZY SYST, V11, P262, DOI 10.1109/TFUZZ.2003.809902
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Graves D, 2010, FUZZY SET SYST, V161, P522, DOI 10.1016/j.fss.2009.10.021
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang HC, 2012, IEEE T FUZZY SYST, V20, P120, DOI 10.1109/TFUZZ.2011.2170175
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kwon MJ, 2003, INT J IMAG SYST TECH, V13, P115, DOI 10.1002/ima.10035
   Le Capitaine H, 2011, IEEE T FUZZY SYST, V19, P580, DOI 10.1109/TFUZZ.2011.2106216
   Leski JM, 2004, FUZZY SET SYST, V141, P259, DOI 10.1016/S0165-0114(03)00184-2
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Li X, 2003, P SOC PHOTO-OPT INS, V5032, P995, DOI 10.1117/12.481375
   Liapis S, 2004, J VIS COMMUN IMAGE R, V15, P1, DOI 10.1016/S1047-3203(03)00025-7
   Madhulatha T.S., 2012, An Overview O Clustering Methods, V2, P719, DOI 10.9790/3021-0204719725
   Mehrani Paria., 2010, BMVC, P1
   Ng EKK, 2005, IEEE T KNOWL DATA EN, V17, P369, DOI 10.1109/TKDE.2005.47
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pantofaru C, 2008, LECT NOTES COMPUT SC, V5304, P481, DOI 10.1007/978-3-540-88690-7_36
   Parsopoulos KE, 2004, IEEE T EVOLUT COMPUT, V8, P211, DOI 10.1109/tevc.2004.826076
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Sjahputera O, 2011, IEEE T GEOSCI REMOTE, V49, P4687, DOI 10.1109/TGRS.2011.2152847
   Sulaiman SN, 2010, IEEE T CONSUM ELECTR, V56, P2702, DOI 10.1109/TCE.2010.5681159
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Yang XW, 2011, IEEE T FUZZY SYST, V19, P105, DOI 10.1109/TFUZZ.2010.2087382
   Yu H, 2013, IEEE T GEOSCI REMOTE, V51, P995, DOI 10.1109/TGRS.2012.2203604
   Zhang DQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2189, DOI 10.1109/ICMLC.2003.1259869
   Zhang DQ, 2003, NEURAL PROCESS LETT, V18, P155, DOI 10.1023/B:NEPL.0000011135.19145.1b
   Zhang H, 2013, IEEE SIGNAL PROC LET, V20, P117, DOI 10.1109/LSP.2012.2230626
   Zhu CJ, 2014, J INDIAN SOC REMOTE, V42, P35, DOI 10.1007/s12524-013-0296-x
NR 49
TC 15
Z9 16
U1 0
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 146
EP 160
DI 10.1016/j.jvcir.2014.11.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000013
DA 2024-07-18
ER

PT J
AU Wang, C
   Ma, KK
AF Wang, Chen
   Ma, Kai-Kuang
TI Feature histogram equalization for feature contrast enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature histogram equalization; Feature contrast; Feature slice; SIFT;
   Feature descriptors; Feature correspondence; Image matching; Image
   histogram equalization; Mismatch removal
ID PATTERN DISCOVERY; IMAGE; RECOGNITION; FRAMEWORK
AB In this paper, a novel feature-descriptor post-processing method, called feature histogram equalization (FHE), is proposed for enhancing the feature contrast inherited in the generated feature descriptors. The fundamental idea of the FHE is in line with the well-known image histogram equalization (IHE); however, their application objectives are completely different. While the IHE is exploited to increase the visibility of image contents by altering the pixel-intensity values, the FHE aims to increase the discrimination among the generated feature descriptors by modifying their vector-component values through an equalization process. Unlike the IHE that operates on scalar data, the FHE deals with vector data. In our approach, the developed equalization operation will be conducted on each feature-vector dimension (denoted as a feature slice), independently. With equalization, the vector distances among the equalized feature descriptors will be increased to facilitate the pattern-discrimination process. Consequently, their associated feature points become more distinct among themselves for benefiting any pattern recognition oriented application. To demonstrate the potential and usage of the FHE, a robust equalization algorithm has been derived and exploited for a chosen image processing application-i.e., point-to-point correspondence between two images under matching. Extensive simulation results have shown that, with the use of our proposed FHE method, more accurate point-to-point correspondence links have been established. Lastly, it should be pointed out that the FHE is only effective to those images with low feature contrast in their image contents (e.g., with strong self-similarity) but achieving less or even no gain to those images that are inherited with high feature contrast already. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Chen] Intel China Res Ctr Ltd ICRC, Beijing 100190, Peoples R China.
   [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639789, Singapore.
C3 Intel Corporation; Nanyang Technological University
RP Ma, KK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639789, Singapore.
EM wangchen.hust@gmail.com; ekkma@ntu.edu.sg
RI Ma, Kai-Kuang/KBA-9411-2024
CR Agarwal S., P IEEE INT C COMP VI, V20, P72
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Borenstein E, 2004, LECT NOTES COMPUT SC, V3023, P315
   Cho MS, 2008, LECT NOTES COMPUT SC, V5305, P144
   Dreuw P., 2009, Proc. BMVC, p7.1, DOI [DOI 10.5244/C.23.7, 10.5244/C.23.7]
   Ferrari V, 2003, PROC CVPR IEEE, P718
   Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7
   Geng C, 2009, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2009.5413956
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Ke Y, 2004, PROC CVPR IEEE, P506
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Liu HR, 2010, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2010.5539780
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Russell B.C., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P1605, DOI DOI 10.1109/CVPR.2006.326
   Tan HK, 2005, IEEE I CONF COMP VIS, P1222
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Wang C, 2014, J VIS COMMUN IMAGE R, V25, P1416, DOI 10.1016/j.jvcir.2013.12.013
   Wang C, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2298973
NR 25
TC 3
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 255
EP 264
DI 10.1016/j.jvcir.2014.09.009
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000023
DA 2024-07-18
ER

PT J
AU Aguilera-Aguilera, EJ
   Carmona-Poyato, A
   Madrid-Cuevas, FJ
   Medina-Carnicer, R
AF Aguilera-Aguilera, E. J.
   Carmona-Poyato, A.
   Madrid-Cuevas, F. J.
   Medina-Carnicer, R.
TI The computation of polygonal approximations for 2D contours based on a
   concavity tree
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital planar curves; Polygonal approximation; Dominant points;
   Concavity tree; Breakpoints; Merge methods; Split methods; Convex hull
ID DOMINANT POINT DETECTION; DIGITAL PLANAR CURVES; DIGITIZED-CURVES;
   GENETIC ALGORITHMS; REPRESENTATION; CONVEX; SUPPRESSION
AB In this work, a new proposal to improve some methods based on the merge approach to obtain polygonal approximations in 2D contours is presented. These methods use a set of candidate dominant points (CDPs) to obtain a polygonal approximation. Then, redundant candidate dominant points of the set of CDPs are deleted, and the remaining dominant points will be the polygonal approximation of the original contour. The main drawback of most of these methods is that they use all breakpoints as CDPs and most of these breakpoints depict only the noise of the original contour.
   Our proposal, based on a concavity tree, obtains a more reduced and significant set of CDPs. When this proposal is used by some methods based on the merge approach (the Masood methods and the Carmona method), their computation times are reduced. The experimental results show that the new proposal is efficient and improves the tested methods. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Aguilera-Aguilera, E. J.; Carmona-Poyato, A.; Madrid-Cuevas, F. J.; Medina-Carnicer, R.] Univ Cordoba, Maimonides Inst Biomed Res IMIBIC, Dept Comp & Numer Anal, Cordoba, Spain.
C3 Universidad de Cordoba
RP Carmona-Poyato, A (corresponding author), Univ Cordoba, Maimonides Inst Biomed Res IMIBIC, Dept Comp & Numer Anal, Cordoba, Spain.
EM ma1capoa@uco.es
RI Medina-Carnicer, Rafael/G-3401-2015; Carmona-Poyato, Angel/G-1593-2015;
   Madrid-Cuevas, Francisco Jose/H-1396-2015
OI Medina-Carnicer, Rafael/0000-0003-4481-0614; Carmona-Poyato,
   Angel/0000-0002-8820-8396; Madrid-Cuevas, Francisco
   Jose/0000-0001-6557-7431
FU Science and Technology Ministry of Spain [TIN2012-32952]; FEDER
FX This work has been developed with the support of the Research Projects
   called TIN2012-32952 and BROCA both financed by Science and Technology
   Ministry of Spain and FEDER. We thank the reviewers for their valuable
   contributions to improve this work.
CR [Anonymous], 1999, INT J PATTERN RECOGN, V13, P1061
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   BATCHELOR BG, 1980, J CYBERNETICS, V10, P233, DOI 10.1080/01969728008927634
   BATCHELOR BG, 1980, J CYBERNETICS, V10, P205, DOI 10.1080/01969728008927632
   BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V63, P145, DOI 10.1006/cviu.1996.0010
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Carmona-Poyato A, 2012, IMAGE VISION COMPUT, V30, P513, DOI 10.1016/j.imavis.2012.05.003
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   El Badawy O, 2005, PATTERN RECOGN LETT, V26, P865, DOI 10.1016/j.patrec.2004.09.031
   Guru DS, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P417, DOI 10.1109/CCCRV.2004.1301477
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   Klette G, 2013, COMPUT VIS IMAGE UND, V117, P386, DOI 10.1016/j.cviu.2012.08.018
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   Masood A, 2007, J VIS COMMUN IMAGE R, V18, P264, DOI 10.1016/j.jvcir.2006.12.002
   Parvez MT, 2010, PATTERN RECOGN LETT, V31, P1997, DOI 10.1016/j.patrec.2010.06.007
   PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PIKAZ A, 1995, PATTERN RECOGN LETT, V16, P557, DOI 10.1016/0167-8655(95)80001-A
   PIKAZ A, 1995, PATTERN RECOGN, V28, P373, DOI 10.1016/0031-3203(94)00108-X
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RAY BK, 1994, PATTERN RECOGN LETT, V15, P161, DOI 10.1016/0167-8655(94)90045-0
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Roussillon T, 2011, PATTERN RECOGN, V44, P2693, DOI 10.1016/j.patcog.2011.03.018
   Salotti M, 2002, PATTERN RECOGN, V35, P435, DOI 10.1016/S0031-3203(01)00051-6
   Salotti M, 2001, PATTERN RECOGN LETT, V22, P215, DOI 10.1016/S0167-8655(00)00088-X
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   Sheu HT, 1996, PATTERN RECOGN, V29, P819, DOI 10.1016/0031-3203(95)00121-2
   SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X
   SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P1355, DOI 10.1109/T-C.1972.223507
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Toussaint G.T, 1988, MACHINE INTELLIGENCE, V6, P71
   Wang B, 2008, LECT NOTES COMPUT SC, V5226, P1149, DOI 10.1007/978-3-540-87442-3_142
   Wang B, 2009, J VIS COMMUN IMAGE R, V20, P45, DOI 10.1016/j.jvcir.2008.10.001
   Wang JH, 2009, EXPERT SYST APPL, V36, P9398, DOI 10.1016/j.eswa.2008.12.045
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Xiao Y, 2001, PATTERN RECOGN LETT, V22, P299, DOI 10.1016/S0167-8655(00)00138-0
   Xu JN, 1997, PATTERN RECOGN LETT, V18, P1009, DOI 10.1016/S0167-8655(97)00125-6
   Yin P.Y., 2007, VISION SYSTEMS SEGME, P451
NR 45
TC 8
Z9 8
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1905
EP 1917
DI 10.1016/j.jvcir.2014.09.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300010
DA 2024-07-18
ER

PT J
AU Chang, CC
   Nguyen, TS
   Lin, CC
AF Chang, Chin-Chen
   Thai Son Nguyen
   Lin, Chia-Chen
TI Reversible data embedding for indices based on histogram analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Image compression; Reversible; Steganography; VQ
   compression; Mapping function; Histogram analysis; High capacity
ID DATA HIDING SCHEME; SIDE MATCH; STEGANOGRAPHY; TABLE
AB Reversible data hiding is a technique that not only protects the hidden secrets but also recovers the cover media without any distortion after the secret data have been extracted. In this paper, a new reversible data hiding technique for VQ indices which are compressed streams based on the mapping function and histogram analysis of transformed VQ indices is introduced to enhance the performance of some earlier reversible data hiding schemes that are based on VQ indices. As a result, the proposed scheme achieves high embedding capacity and data compression simultaneously. Moreover, the original VQ-compressed image can be perfectly reconstructed after secret data extraction. To estimate the performance of the proposed scheme, variety of test images are used in the experimental testing. As can be seen in the experimental result, our scheme is superior to some previous schemes in term of compression rate and embedding rate while maintaining the reversibility. (C) 2014 Published by Elsevier Inc.
C1 [Chang, Chin-Chen; Thai Son Nguyen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Thai Son Nguyen] Travinh Univ, Dept Informat Technol, Travinh, Travinh Provinc, Vietnam.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
   [Chang, Chin-Chen] China Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung 40402, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
C3 Feng Chia University; Providence University - Taiwan; China Medical
   University Taiwan; Asia University Taiwan
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd, Taichung 43301, Taiwan.
EM ccc@cs.ccu.edu.tw; thaison@tvu.edu.vn; ally.cclin@gmail.com
RI Nguyen, Thai-Son/AGD-3594-2022; Chang, Ching-Chun/JAN-6210-2023
OI Nguyen, Thai-Son/0000-0001-7008-0462; Lin, Chia-Chen/0000-0003-4480-7351
CR Bausys R, 2006, PROCEEDINGS ELMAR-2006, P53, DOI 10.1109/ELMAR.2006.329513
   Chang CC, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P947
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2006, INFORM SCIENCES, V176, P3393, DOI 10.1016/j.ins.2006.02.008
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Chen WJ, 2009, DIGIT SIGNAL PROCESS, V19, P433, DOI 10.1016/j.dsp.2008.11.003
   Cox IJ., 2007, DIGITAL WATERMARKING
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Guorong Xuan, 2004, Digital Watermarking. Third International Workshop, IWDW 2004. Revised Selected Papers (Lecture Notes in Computer Science Vol. 3304), P115
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee CF, 2010, IMAGE VISION COMPUT, V28, P1293, DOI 10.1016/j.imavis.2010.01.006
   Lin Chih Yang, 2006, J COMPUT, V17, P3
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Saleh NA, 2010, DIGIT SIGNAL PROCESS, V20, P1629, DOI 10.1016/j.dsp.2010.02.004
   Wang John, 2008, International Journal of Information and Decision Sciences, V1, P1
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 30
TC 10
Z9 10
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1704
EP 1716
DI 10.1016/j.jvcir.2014.06.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100019
DA 2024-07-18
ER

PT J
AU Kim, NW
   Lee, J
   Lee, H
   Seo, J
AF Kim, Nam Wook
   Lee, Jeongjin
   Lee, Hyungmin
   Seo, Jinwook
TI Accurate segmentation of land regions in historical cadastral maps
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cadastral map; Historical geographical information system; Line
   reconstruction; Line extraction; Polygonal approximation; Land
   segmentation; Character recognition; Grid removal
ID TEXT/GRAPHICS SEPARATION; LINEAR FEATURES; GREAT-BRITAIN; VECTORIZATION;
   ALGORITHM; RECOGNITION; EXTRACTION; IMAGES; ROBUST; TEXT
AB Historical cadastral maps are valuable sources for historians to study social and economic background of changes in land uses or ownerships. In order to conduct large-scale historical research, it is essential to digitize the cadastral maps. As being established in antiquity, however, they suffer from significant noise artifacts attributed to hand-drawn cartography. In this paper, we propose a novel method of extracting land regions automatically in historical cadastral maps. First, we remove grid reference lines based on the density of the black pixel with the help of the uttering. Then, we remove land owner labels by considering morphological and geometrical characteristics of thinned image. We subsequently reconstruct land boundaries. Finally, the land regions of a user's interest are modeled by their polygonal approximations. Our segmentation results were compared with manually segmented results and showed that the proposed method extracted the land regions accurately for assisting cadastral mapping in historical research. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Kim, Nam Wook] LG Elect, Mobile Commun Res Ctr, Seoul 153801, South Korea.
   [Lee, Jeongjin] Soongsil Univ, Sch Engn & Comp Sci, Seoul 156743, South Korea.
   [Lee, Hyungmin; Seo, Jinwook] Seoul Natl Univ, Sch Engn & Comp Sci, Seoul 151742, South Korea.
C3 LG Electronics; Soongsil University; Seoul National University (SNU)
RP Lee, J (corresponding author), Soongsil Univ, Sch Engn & Comp Sci, 369 Sangdo Ro, Seoul 156743, South Korea.
EM namw.kim@samsung.com; leejeongjin@ssu.ac.kr; hmlee@hcil.snu.ac.kr;
   jwseo@hcil.snu.ac.kr
OI Kim, Nam Wook/0000-0003-4899-6671
FU IT R&D program of MSIP/KEIT [10044910]; National Research Foundation of
   Korea (NRF) - Korea government (MSIP) [2011-0030813]
FX This work was partly supported by the IT R&D program of MSIP/KEIT
   [10044910, Development of Multi-modality Imaging and 3D Simulation-Based
   Integrative Diagnosis-Treatment Support Software System for
   Cardiovascular Diseases] and by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIP) (No.
   2011-0030813).
CR Agrawal M, 2011, PROC INT CONF DOC, P17, DOI 10.1109/ICDAR.2011.13
   [Anonymous], COMPUTER ROBOT VISIO
   [Anonymous], J WSCG
   [Anonymous], 9 IAPR INT WORKSH GR
   Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845
   ARRIGHI P, 1999, P GEOV 99, V99, P1
   Baily B., 2007, E-perimetron, V2, P209
   Baily B, 2011, APPL GEOGR, V31, P959, DOI 10.1016/j.apgeog.2010.12.007
   Berman M.L., 2005, HIST GEOGRAPHY, V33, P118
   Bucha V., 2005, IEE International Conference on Visual Information Engineering (VIE 2005) (CP No.509), P115, DOI 10.1049/cp:20050079
   Cao RN, 2002, LECT NOTES COMPUT SC, V2390, P167
   Chang F, 2004, COMPUT VIS IMAGE UND, V93, P206, DOI 10.1016/j.cviu.2003.09.002
   Chen Y, 2006, IEEE T GEOSCI REMOTE, V44, P1048, DOI 10.1109/TGRS.2005.861478
   Chiang Y.-Y., 2013, EFFICIENT ROBUST GRA, P25
   Chiang Yao-Yi., 2010, Harvesting geographic features from heterogeneous raster maps
   Dhar DB, 2006, INT J DOC ANAL RECOG, V8, P232, DOI 10.1007/s10032-005-0010-9
   Dharmaraj G., 2005, ALGORITHMS AUTOMATIC
   Dori D, 1999, IEEE T PATTERN ANAL, V21, P202, DOI 10.1109/34.754586
   Eikvil L., 1995, IEEE INT C DOC AN RE, V2
   Ekamper P, 2010, HIST FAM, V15, P1, DOI 10.1016/j.hisfam.2010.01.003
   FIG, 1995, STAT CAD INT FED SUR, P22
   FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112
   Frischknecht S., 1998, International Archives of Photogrammetry and Remote Sensing, V32, P523
   Gonzalez RafaelC., 2009, Digital image processing using MATLAB, V2
   Gregory IN, 2002, CARTOGR J, V39, P37, DOI 10.1179/caj.2002.39.1.37
   Hancer E., 2011, IEEE INT C APPL INF
   Henderson T.C., 2014, SEGMENTATION VECTORI, P17
   Henssen J., 1995, P ON DAY SEM HELD AN, V7
   Henssen J.L.G., 1990, FED INT GEOM 19 INT
   Hilaire X, 2006, IEEE T PATTERN ANAL, V28, P890, DOI 10.1109/TPAMI.2006.127
   Hilaire X, 2002, LECT NOTES COMPUT SC, V2390, P273
   Hoang TV, 2010, P 9 IAPR INT WORKSH
   Hori O., 1993, IEEE INT C DOC AN RE
   Janssen R.D., 1993, IEEE INT C DOC AN RE
   Khotanzad A, 2003, IEEE T PATTERN ANAL, V25, P18, DOI 10.1109/TPAMI.2003.1159943
   Lacroix V., 2009, IEEE INT C ADV PATT
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Larsson G., 1991, Land Registration and Cadastral Systems: Tools for Land Information and Management
   Lee H., 2012, CHI 12, P463
   Lee KH, 2000, ENG APPL ARTIF INTEL, V13, P165, DOI 10.1016/S0952-1976(99)00049-4
   Leyk S., 2008, CARTOGR GEOGR INF SC
   Liu Wenyin, 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P230, DOI 10.1007/BFb0033241
   Liu WY, 1999, PATTERN ANAL APPL, V2, P10
   Miyajima H., 1997, COMP ANAL KWANGMU YA, P199
   Mou Zhenyu., 2012, Annals of GIS, V18, P147, DOI DOI 10.1080/19475683.2012.668560
   Pouderoux J, 2007, PROC INT CONF DOC, P779
   Roy PP, 2008, LECT NOTES COMPUT SC, V5046, P245, DOI 10.1007/978-3-540-88188-9_23
   Quackenbush LJ, 2004, PHOTOGRAMM ENG REM S, V70, P1383, DOI 10.14358/PERS.70.12.1383
   San L.M., 2004, IEEE INT C COMP GRAP
   Shereen S.A., 2011, INT J ENG TECHNOL, V3, P182
   Song JQ, 2002, INT C PATT RECOG, P135, DOI 10.1109/ICPR.2002.1047813
   Song JQ, 2000, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2000.855844
   Tombre K, 2002, LECT NOTES COMPUT SC, V2423, P200
   Tombre K., 2000, STABLE ROBUST VECTOR, P3
   Widiarti A.R., 2011, WORLD ACAD SCI ENG T, V78, P146
   Wu RQ, 2009, J COMPUT SCI TECHNOL, V9, P58
   Yang Y, 2012, INT ARCH PHOTOGRAMM, V39-B4, P103
   Zheng Y., 2003, IEEE WORKSH COMP VIS
   Zheng YF, 2003, PROC INT CONF DOC, P44
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 60
TC 14
Z9 15
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1262
EP 1274
DI 10.1016/j.jvcir.2014.01.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200050
DA 2024-07-18
ER

PT J
AU Liu, JX
   Liu, YW
   Ci, S
   Ye, Y
   Yao, RX
AF Liu, Jinxia
   Liu, Yanwei
   Ci, Song
   Ye, Yun
   Yao, Ruixiao
TI 3D visual experience oriented cross-layer optimized scalable texture
   plus depth based 3D video streaming over wireless networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D video; 3D visual experience; Cross-layer optimization; 3D video
   streaming; Texture plus depth; Scalable 3D video; Texture/depth rate
   allocation; Wireless network
ID QUALITY; DESIGN
AB 3D video streaming over the mobile Internet generally incurs the inferior 3D visual experience due to the time-varying characteristics of wireless channel. The conventional video streaming optimization methods generally neglect the harmony among different networking protocol layers. This paper proposes a cross-layer optimized texture plus depth based scalable 3D video streaming method to improve the expected 3D visual experience of the user by systematically considering the application layer texture-video/depth/FEC bit-rate allocation, MAC layer multi-channel allocation, and physical layer modulation and channel coding scheme (MCS) selection. In the cross-layer optimization, a networking-related 3D visual experience model which fuses the overlapped retinal view visual quality and depth sensation with mimicking human vision system is established to predict the 3D visual experience under the specific parameter configurations of different protocol layers. The efficiency and effectiveness of the proposed cross-layer optimized 3D video streaming method has been validated by subjective and objective experimental results. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Zhejiang, Peoples R China.
   [Liu, Yanwei; Ci, Song; Yao, Ruixiao] Chinese Acad Sci, Inst Acoust, Beijing, Peoples R China.
   [Ci, Song; Ye, Yun] Univ Nebraska Lincoln, Omaha, NE USA.
C3 Zhejiang Wanli University; Chinese Academy of Sciences; Institute of
   Acoustics, CAS; University of Nebraska System; University of Nebraska
   Lincoln
RP Liu, YW (corresponding author), Chinese Acad Sci, Inst Acoust, Beijing, Peoples R China.
EM liuyw@hpnl.ac.cn
RI Liu, Jinxia/H-1794-2011; liu, yanwei/L-2453-2019; Ci, Song/R-8324-2019
FU National Natural Science Foundation of China [61102077, 11161140319];
   Zhejiang Provincial Natural Science Foundation of China [LY13F010012];
   Public welfare projects of Zhejiang Province [2014C31072]; Domestic
   Visitor Foundation from the Education Commission of Zhejiang Province
   [FX2013118]; NSF [1145596, 0830493]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant Nos. 61102077 and 11161140319, Zhejiang Provincial
   Natural Science Foundation of China under Contract LY13F010012, Public
   welfare projects of Zhejiang Province under Contract 2014C31072,
   Domestic Visitor Foundation from the Education Commission of Zhejiang
   Province under Contract FX2013118, and NSF under Grant Nos. 1145596 and
   0830493. The authors would like to thank Nagoya University for providing
   3D video sequences of Balloons and Kendo, HHI for providing 3D video
   sequence of Book_arrival and ETRI for providing 3D video sequence of
   Lovebird1.
CR Adedoyin S, 2008, IEEE T CONSUM ELECTR, V54, P2045, DOI 10.1109/TCE.2008.4711271
   Ahmadi S, 2009, IEEE COMMUN MAG, V47, P84, DOI 10.1109/MCOM.2009.5116805
   Akman A., 2012, P 1 ROM WORKSH, P1
   [Anonymous], 2011 IEEE INT C COMM
   [Anonymous], IEEE COMSOC MMTC E L
   Benoit A, 2008, IEEE IMAGE PROC, P389, DOI 10.1109/ICIP.2008.4711773
   Borin JF, 2008, SIMUL MODEL PRACT TH, V16, P817, DOI 10.1016/j.simpat.2008.05.002
   Goyal V.K., 2011, IEEE SIGNAL PROCESS, V18, P73
   Hewage C.T. E. R., 2010, Future Network MobileSummit 2010 Conference Proceedings, P1
   Hewage CTER, 2013, IEEE COMMUN MAG, V51, P101, DOI 10.1109/MCOM.2013.6515053
   Karim HA, 2008, IEEE T CONSUM ELECTR, V54, P745, DOI 10.1109/TCE.2008.4560156
   Karimi H., 2007, P IEEE PES TAMP FL U, P1
   Karlsson LS, 2011, IEEE T CIRC SYST VID, V21, P742, DOI 10.1109/TCSVT.2011.2130350
   Kauff P., SIGNAL PROCESS IMAGE, V22
   Khalek AA, 2012, IEEE J SEL AREA COMM, V30, P1157, DOI 10.1109/JSAC.2012.120802
   Khan S, 2006, IEEE COMMUN MAG, V44, P122, DOI 10.1109/MCOM.2006.1580942
   Kompella S, 2007, IEEE J SEL AREA COMM, V25, P831, DOI 10.1109/JSAC.2007.070518
   Lebreton P, 2012, IEEE J-STSP, V6, P710, DOI 10.1109/JSTSP.2012.2213236
   Liu QW, 2004, IEEE T WIREL COMMUN, V3, P1746, DOI 10.1109/TWC.2004.833474
   Liu YW, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348821
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Liyuan Xing, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P373, DOI 10.1109/MMSP.2010.5662049
   Merkle P., 2009, 3DTV C TRUE VIS CAPT, P1
   Nasir S, 2009, IEEE IMAGE PROC, P4269, DOI 10.1109/ICIP.2009.5413687
   Niu YZ, 2012, IEEE T MULTIMEDIA, V14, P783, DOI 10.1109/TMM.2012.2186122
   Niyato D, 2007, IEEE WIREL COMMUN, V14, P72, DOI 10.1109/MWC.2007.314553
   Schwarz Heike., 2007, IEEE Transactions on Circuits and Systems for Video Technology, V17
   Setton E, 2005, IEEE WIREL COMMUN, V12, P59, DOI 10.1109/MWC.2005.1497859
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Shirmohammadi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348820
   Stockhammer T., 2002, P 4 INT WORKSH DISTR, P1
   Tan WT, 2001, IEEE T CIRC SYST VID, V11, P373, DOI 10.1109/76.911162
   Tanimoto M., 2008, MPEG2008M15377 ISOIE
   van der Schaar M., 2005, IEEE WIRELESS COMMUN, V12
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wu DL, 2007, IEEE J SEL AREA COMM, V25, P841, DOI 10.1109/JSAC.2007.070519
   Zhai F, 2005, SIGNAL PROCESS-IMAGE, V20, P371, DOI 10.1016/j.image.2005.02.002
   Zhao PH, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P210, DOI 10.1109/CCNC.2013.6488448
NR 39
TC 2
Z9 2
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1209
EP 1221
DI 10.1016/j.jvcir.2014.04.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200046
DA 2024-07-18
ER

PT J
AU Tanchenko, A
AF Tanchenko, Alexander
TI Visual-PSNR measure of image quality
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality; Objective measure of image quality; Peak signal-to-noise
   ratio; Block-based compression algorithm; Subjective image quality;
   Image database; Mean opinion score; Human visual system
AB Objective assessment of image quality is important in numerous image and video processing applications. Many objective measures of image quality have been developed for this purpose, of which peak signal-to-noise ratio PSNR is one of the simplest and commonly used. However, it sometimes does not match well with objective mean opinion scores (MOS). This paper presents a novel objective full-reference measure of image quality (VPSNR), which is a modified PSNR measure. It will be shown that VPSNR takes into account some features of the human visual system (HVS). The performance of VPSNR is validated using a data set of four image databases, and in this article it is shown that for images compressed by block-based compression algorithms (like JPEG) the proposed measure in the pixel domain matches well with MOS. (C) 2014 Elsevier Inc. All rights reserved.
C1 Synopsys Inc, St Petersburg 197376, Russia.
C3 Synopsys Inc
RP Tanchenko, A (corresponding author), Synopsys Inc, St Popova,App 23-D, St Petersburg 197376, Russia.
EM atanchen@synopsys.com
CR [Anonymous], 2003, THRITY 7 ASILOMAR C
   Gaubatz M., MeTriX MuX visual quality assessment package
   Ponomarenko N., TAMPERE IMAGE DATABA
   Sheikh H.R., 2006, IEEE T IMAGE PROCESS, V15, P3411
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   TEO PC, 1994, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.1994.413502
   Voloshynovskiy S, 2000, LECT NOTES COMPUT SC, V1768, P211
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
NR 10
TC 91
Z9 100
U1 3
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 874
EP 878
DI 10.1016/j.jvcir.2014.01.008
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200016
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Kang, LW
   Chiou, YW
   Lin, CW
   Jiang, SJF
AF Yeh, Chia-Hung
   Kang, Li-Wei
   Chiou, Yi-Wen
   Lin, Chia-Wen
   Jiang, Shu-Jhen Fan
TI Self-learning-based post-processing for image/video deblocking via
   sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blocking artifact; Deblocking; Sparse representation; Dictionary
   learning; Morphological component analysis; Image/video restoration;
   Image/video enhancement; Post-processing
ID IMAGE DECOMPOSITION; BLOCKING ARTIFACTS; TRANSFORM; REDUCTION; REMOVAL;
   DCT; ALGORITHM; FILTER
AB Blocking artifact, characterized by visually noticeable changes in pixel values along block boundaries, is a common problem in block-based image/video compression, especially at low bitrate coding. Various post-processing techniques have been proposed to reduce blocking artifacts, but they usually introduce excessive blurring or ringing effects. This paper proposes a self-learning-based post-processing framework for image/video deblocking by properly formulating deblocking as an MCA (morphological component analysis)-based image decomposition problem via sparse representation. Without the need of any prior knowledge (e.g., the positions where blocking artifacts occur, the algorithm used for compression, or the characteristics of image to be processed) about the blocking artifacts to be removed, the proposed framework can automatically learn two dictionaries for decomposing an input decoded image into its "blocking component" and "non-blocking component." More specifically, the proposed method first decomposes a frame into the low-frequency and high-frequency parts by applying BM3D (block-matching and 3D filtering) algorithm. The high-frequency part is then decomposed into a blocking component and a non-blocking component by performing dictionary learning and sparse coding based on MCA. As a result, the blocking component can be removed from the image/video frame successfully while preserving most original visual details. Experimental results demonstrate the efficacy of the proposed algorithm. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yeh, Chia-Hung; Chiou, Yi-Wen; Jiang, Shu-Jhen Fan] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 804, Taiwan.
   [Kang, Li-Wei] Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol, Doctoral Program, Yunlin 640, Taiwan.
   [Kang, Li-Wei] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Yunlin 640, Taiwan.
   [Lin, Chia-Wen] Natl Tsing Hua Univ, Dept Elect Engn, Hsinchu 300, Taiwan.
   [Lin, Chia-Wen] Natl Tsing Hua Univ, Inst Commun Engn, Hsinchu 300, Taiwan.
C3 National Sun Yat Sen University; National Yunlin University Science &
   Technology; National Yunlin University Science & Technology; National
   Tsing Hua University; National Tsing Hua University
RP Kang, LW (corresponding author), Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol, Doctoral Program, Yunlin 640, Taiwan.
EM lwkang@yuntech.edu.tw
RI Lin, Chia-Wen/ABH-6075-2020; Lin, Chia-Wen/M-4571-2013
OI Lin, Chia-Wen/0000-0002-9097-2318
FU National Science Council, Taiwan [NSC102-2221-E-110-032-MY3,
   NSC101-2221-E-110-093-MY2, NSC100-2218-E-224-017-MY3]
FX This work was supported in part by the National Science Council, Taiwan,
   under Grants NSC102-2221-E-110-032-MY3, NSC101-2221-E-110-093-MY2, and
   NSC100-2218-E-224-017-MY3. Our thanks to Wen-Hung Xu for executing the
   program on the test data in this work; his timely assistance is greatly
   appreciated.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Al-Fahoum AS, 2001, IEEE T IMAGE PROCESS, V10, P1288, DOI 10.1109/83.941853
   [Anonymous], P IEEE INT C MULT EX
   Averbuch AZ, 2005, IEEE T IMAGE PROCESS, V14, P200, DOI 10.1109/TIP.2004.840688
   Bobin J, 2007, IEEE T IMAGE PROCESS, V16, P2675, DOI 10.1109/TIP.2007.907073
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fadili MJ, 2010, P IEEE, V98, P983, DOI 10.1109/JPROC.2009.2024776
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Fowers SG, 2013, IEEE T CIRC SYST VID, V23, P756, DOI 10.1109/TCSVT.2012.2223631
   Gregor K., 2010, P 27 INT C INT C MAC, P399
   Hsung TC, 1998, IEEE T IMAGE PROCESS, V7, P1488, DOI 10.1109/83.718489
   Huang DA, 2014, IEEE T MULTIMEDIA, V16, P83, DOI 10.1109/TMM.2013.2284759
   Jafari MG, 2011, IEEE J-STSP, V5, P1025, DOI 10.1109/JSTSP.2011.2157892
   Jeong Y, 2000, IEEE T CIRC SYST VID, V10, P617, DOI 10.1109/76.845007
   Jung C, 2012, SIGNAL PROCESS-IMAGE, V27, P663, DOI 10.1016/j.image.2012.03.002
   Kang L. W., 2013, P IEEE INT WORKSH MU
   Kang LW, 2012, IEEE INT SYMP CIRC S, P1871
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim J, 2011, IEEE T CONSUM ELECTR, V57, P1944, DOI 10.1109/TCE.2011.6131175
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   Luo JB, 1996, IEEE T IMAGE PROCESS, V5, P1363, DOI 10.1109/83.535848
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   OZCELIK T, 1995, P IEEE, V83, P304, DOI 10.1109/5.364460
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Shen M.Y., 1988, J VIS COMMUN IMAGE R, V9, P2
   Sikora T, 2005, P IEEE, V93, P6, DOI 10.1109/JPROC.2004.839601
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tai SC, 2005, IEEE T CIRC SYST VID, V15, P733, DOI 10.1109/TCSVT.2005.848314
   Tsai C.-Y., 2012, P IEEE VIS COMM IM P
   Wiegand T, 2007, IEEE SIGNAL PROC MAG, V24, P148, DOI 10.1109/MSP.2007.323282
   WU SW, 1992, IEEE T COMMUN, V40, P251, DOI 10.1109/26.129187
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang YY, 1993, IEEE T CIRC SYST VID, V3, P421, DOI 10.1109/76.260198
   Yeh CH, 2012, IET IMAGE PROCESS, V6, P534, DOI 10.1049/iet-ipr.2010.0545
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P735, DOI 10.1109/TMM.2008.922849
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
   Zhang RQ, 2011, J VIS COMMUN IMAGE R, V22, P251, DOI 10.1016/j.jvcir.2010.12.007
NR 46
TC 36
Z9 38
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 891
EP 903
DI 10.1016/j.jvcir.2014.02.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200018
DA 2024-07-18
ER

PT J
AU Xu, DW
   Wang, RD
   Shi, YQ
AF Xu, Dawen
   Wang, Rangding
   Shi, Yun Q.
TI An improved reversible data hiding-based approach for intra-frame error
   concealment in H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error concealment; Video transmission; H.264/AVC; Reversible data
   hiding; Histogram shifting; Intra-frame; Motion vector; Embedding
   distortion
ID WATERMARKING SCHEME; VIDEO TRANSMISSION; IMAGE
AB As H.264/AVC video streams are highly compressed, they become sensitive to errors caused by unreliable transmission channels. In order to address this issue, an improved version of Chung et al.'s reversible data hiding-based approach for intra-frame error concealment is proposed for H.264/AVC codec. By using the histogram shifting technique, the original work reversibly embeds the motion vector (MV) of a macroblock (MB) into other MB within the same intra-frame. If an MB is corrupted at the decoder side, the embedded MV can be extracted from the corresponding MB for the recovery of the corrupted MB. However, Chung et al.'s work did not fully exploit the number of coefficients which need to be modified in order to reversibly hiding data, and did not consider many extra nonzero residual blocks produced by data hiding. These two issues could reduce the visual quality of the stego-video. This paper adopts MV data pre-processing, the selection of most suitable embedding region, and the minimum possible amount of histogram modification, which lead to higher PSNR of the stego-video for a given payload. Experimental results further reveal that the proposed method offers stego-video with better visual quality over Chung et al.'s work. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Xu, Dawen] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Zhejiang, Peoples R China.
   [Wang, Rangding] Ningbo Univ, CKC Software Lab, Ningbo 315211, Zhejiang, Peoples R China.
   [Shi, Yun Q.] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Ningbo University of Technology; Ningbo University; New Jersey Institute
   of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Zhejiang, Peoples R China.
EM dawenxu@126.com
RI Shi, Yun/JWP-3360-2024; xu, dawen/ABF-5343-2021
OI xu, dawen/0000-0002-9619-8407
FU K.C. Wong Education, Hong Kong; National Natural Science Foundation of
   China [61301247, 61170137]; Zhejiang Provincial Natural Science
   Foundation of China [LY13F020013]; Ningbo Natural Science Foundation
   [2013A610059, 2011A610182]
FX The authors gratefully acknowledge the support of K.C. Wong Education,
   Hong Kong. This work is also supported by the National Natural Science
   Foundation of China (61301247, 61170137), Zhejiang Provincial Natural
   Science Foundation of China (LY13F020013), and Ningbo Natural Science
   Foundation (2013A610059, 2011A610182).
CR Adsumilli CB, 2005, IEEE T CIRC SYST VID, V15, P1394, DOI 10.1109/TCSVT.2005.856933
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Chen SY, 2009, IEEE T CIRC SYST VID, V19, P422, DOI 10.1109/TCSVT.2009.2013504
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P300, DOI 10.1109/TCSVT.2005.861948
   Luo ZY, 2010, OPT ENG, V49, DOI 10.1117/1.3381178
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Phadikar A, 2012, TELECOMMUN SYST, V49, P239, DOI 10.1007/s11235-010-9371-6
   Phadikar A, 2010, IEEE T CONSUM ELECTR, V56, P971, DOI 10.1109/TCE.2010.5506028
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Sun TF, 2010, CHINA COMMUN, V7, P30
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yang M, 2009, IEEE T BROADCAST, V55, P190, DOI 10.1109/TBC.2009.2016491
   Yilmaz A, 2008, SIGNAL PROCESS-IMAGE, V23, P298, DOI 10.1016/j.image.2008.03.003
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
NR 19
TC 28
Z9 31
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 410
EP 422
DI 10.1016/j.jvcir.2013.12.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300017
DA 2024-07-18
ER

PT J
AU Thirumalai, V
   Frossard, P
AF Thirumalai, Vijayaraghavan
   Frossard, Pascal
TI Correlation estimation from compressed images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Linear measurements; Correlation estimation; Distributed image
   compression; Joint reconstruction; Graph cuts; Optimization;
   Quantization; Proximal splitting
ID ENERGY MINIMIZATION; RECONSTRUCTION
AB This paper addresses the problem of correlation estimation in sets of compressed images. We consider a framework where the images are represented under the form of linear measurements due to low complexity sensing or security requirements. We assume that the images are correlated through the displacement of visual objects due to motion or viewpoint change and the correlation is effectively represented by optical flow or motion field models. The correlation is estimated in the compressed domain by jointly processing the linear measurements. We first show that the correlated images can be efficiently related using a linear operator. Using this linear relationship we then describe the dependencies between images in the compressed domain. We further cast a regularized optimization problem where the correlation is estimated in order to satisfy both data consistency and motion smoothness objectives with a Graph Cut algorithm. We analyze in detail the correlation estimation performance and quantify the penalty due to image compression. Extensive experiments in stereo and video imaging applications show that our novel solution stays competitive with methods that implement complex image reconstruction steps prior to correlation estimation. We finally use the estimated correlation in a novel joint image reconstruction scheme that is based on an optimization problem with sparsity priors on the reconstructed images. Additional experiments show that our correlation estimation algorithm leads to an effective reconstruction of pairs of images in distributed image coding schemes that outperform independent reconstruction algorithms by 2-4 dB. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Thirumalai, Vijayaraghavan; Frossard, Pascal] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Thirumalai, V (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
EM vijayaraghavan.thirumalai@epfl.ch; pascal.frossard@epfl.ch
RI Frossard, Pascal/AAF-2268-2019
FU Swiss National Science Foundation [200021-118230]; Swiss National
   Science Foundation (SNF) [200021-118230] Funding Source: Swiss National
   Science Foundation (SNF)
FX This work has been partly supported by the Swiss National Science
   Foundation, under Grant 200021-118230. Part of this work has been
   presented in IEEE ICASSP 2011 [1].
CR [Anonymous], 1999, THESIS CORNELL U
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Baraniuk R., 2008, CONSTRUCTIVE APPROXI, V28
   Becker S., 2009, NESTA FAST ACCURATE
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Candes E.J., 2005, P SPIE COMP IM
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Combettes P.L., FIXED POINT ALGORITH
   Do T., 2008, P IEEE INT C AC SPEE
   Do T., 2009, P IEEE INT C AC SPEE
   Do T.T., 2009, P IEEE INT C IM PROC
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte M.F., 2006, P INF PROC SENS NETW
   Duarte M.F., 2005, P AS C SIGN SYST COM
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gan L., 2008, P EUR SIGN IM PROC C
   Goyal VK, 2008, IEEE SIGNAL PROC MAG, V25, P48, DOI 10.1109/MSP.2007.915001
   Hammond D.K., 2009, BASIS PURSUIT DEQUAN
   Jacques L, 2011, IEEE T INFORM THEORY, V57, P559, DOI 10.1109/TIT.2010.2093310
   Kang L.W., 2009, P IEEE INT C AC SPEE
   Li X, 2010, ELECTRON LETT, V46, P1548, DOI 10.1049/el.2010.2325
   Montagner Y.L., 2011, P IEEE INT S BIOL IM
   Mun S., 2009, P IEEE INT C IM PROC
   Nebot J.P., 2009, P PICT COD S
   Park J.Y., 2009, P PICT COD S
   Park J.Y., EURASIP J A IN PRESS
   Pudlewski S, 2012, IEEE T MOBILE COMPUT, V11, P1060, DOI 10.1109/TMC.2011.175
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Stankovic V., 2008, P EUR SIGN IM PROC C
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Thirumalai V., IEEE T IMAGE PROCESS
   Thirumalai V., 2011, P IEEE INT C AC SPEE
   Thirumalai V, 2011, IEEE IMAGE PROC
   Trocan M., 2010, P IEEE INT WORKSH MU
   Trocan M., 2010, P IEEE INT C MULT EX
   Vaswani N., 2008, P IEEE INT C IM PROC
   Zhang L, 2007, IEEE T PATTERN ANAL, V29, P331, DOI 10.1109/TPAMI.2007.36
NR 39
TC 11
Z9 14
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 649
EP 660
DI 10.1016/j.jvcir.2011.12.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900002
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Wang, K
   Shi, TL
   Liao, GL
   Xia, Q
AF Wang, Ke
   Shi, Tielin
   Liao, Guanglan
   Xia, Qi
TI Image registration using a point-line duality based line matching method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Line matching; Point matching; Point-line duality; Image registration;
   Least squares; Point merging; Rigid body transformation; Similarity
   measure
ID STEREO; INVARIANT
AB In the paper, a Point-Line Duality (PLD), i.e. a line in the image (x-y) space corresponds to a point in the dual (0-rho) space, based line matching method is proposed for image registration. First, edge points are detected in a template image and a target image. The edge points are linked and segmented into chains. The chains are fitted to lines, and the lines are mapped to dual points in the dual space. To improve stability and efficiency, a point merging algorithm is proposed to deal with the fragmentary line segments that should belong to a single line. As a result, a line matching problem is converted to a point pattern matching problem. Finally, a point pattern matching algorithm is proposed to determine registration parameters and to determine matched line pairs. Experimental results demonstrate that the proposed method is effective for images under rigid body transformation, occlusion, and illumination change. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Ke; Shi, Tielin; Liao, Guanglan; Xia, Qi] Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Xia, Q (corresponding author), Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan 430074, Peoples R China.
EM qxia@mail.hust.edu.cn
RI xia, qi/JBR-8998-2023
FU National Key Basic Research Special Fund of China [2009CB724204];
   National Natural Science Foundation of China [51105159]; Research Fund
   for the Doctoral Program of Higher Education of China [20110142120091]
FX This research work is partly supported by the National Key Basic
   Research Special Fund of China (Grant No. 2009CB724204), the National
   Natural Science Foundation of China (Grant No. 51105159), Research Fund
   for the Doctoral Program of Higher Education of China (Grant No.
   20110142120091), which the authors gratefully acknowledge. The comments
   of the reviewers are cordially appreciated.
CR AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751
   Bay H, 2005, PROC CVPR IEEE, P329
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang SH, 1997, PATTERN RECOGN, V30, P311, DOI 10.1016/S0031-3203(96)00076-3
   Fan B, 2010, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2010.5540186
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Khaleghi B, 2009, IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P78, DOI 10.1109/CIRA.2009.5423244
   KOCH MW, 1987, IEEE T PATTERN ANAL, V9, P483, DOI 10.1109/TPAMI.1987.4767936
   Li F, 2006, INT C PATT RECOG, P149
   Li Y, 2008, PROC SPIE, V6822, DOI 10.1117/12.765896
   LI ZN, 1994, IEEE T SYST MAN CYB, V24, P144, DOI 10.1109/21.259695
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502
   Song TC, 2013, IEEE SIGNAL PROC LET, V20, P59, DOI 10.1109/LSP.2012.2229273
   Steger C., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P148
   Wang L, 2009, IEEE I CONF COMP VIS, P1311, DOI 10.1109/ICCV.2009.5459316
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 27
TC 9
Z9 12
U1 2
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 615
EP 626
DI 10.1016/j.jvcir.2013.04.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900010
DA 2024-07-18
ER

PT J
AU Türkan, M
   Guillemot, C
AF Turkan, Mehmet
   Guillemot, Christine
TI Dictionary learning for image prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dictionary learning; Image prediction; Image compression; Sparse
   representations; Coding; Block transforms
ID K-SVD; SPARSE; REPRESENTATIONS; COMPRESSION; ALGORITHM
AB We present a dictionary learning algorithm which is tailored to the block-based image prediction problem. More precisely, we learn two related sub-dictionaries A(c) and A(t), the first one (A(c)) for approximating known samples in a causal neighborhood of the block to be predicted and the other one (A(t)) to approximate the block to be predicted. These two dictionaries are learned so that representation vectors computed by approximating the known samples using A(c) will lead to a good approximation of the block to be predicted when used together with A(t). Because of its simplicity, this method can be used for on-the-fly learning of dictionaries. The proposed method has first been evaluated for intra prediction. It has then been applied in a complete image compression algorithm. Experimental results show gains up to 3 dB in terms of prediction compared to the H.264/AVC intra modes and up to 2 dB in terms of rate-distortion performance. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Turkan, Mehmet; Guillemot, Christine] INRIA, F-35042 Rennes, France.
C3 Inria
RP Türkan, M (corresponding author), Technicolor R&D, Cesson Sevigne, France.
EM Mehmet.Turkan@gmail.com; Christine.Guillemot@inria.fr
RI Turkan, Mehmet/AGQ-8084-2022
OI Turkan, Mehmet/0000-0002-9780-9249; Guillemot,
   Christine/0000-0003-1604-967X
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Aharon M, 2008, SIAM J IMAGING SCI, V1, P228, DOI 10.1137/07070156X
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Blumensath T, 2006, IEEE T AUDIO SPEECH, V14, P50, DOI 10.1109/TSA.2005.860349
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Engan K, 2007, DIGIT SIGNAL PROCESS, V17, P32, DOI 10.1016/j.dsp.2006.02.002
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   Jenatton R, 2011, J MACH LEARN RES, V12, P2297
   Jost P., 2006, Acoustics, Speech and Signal Processing, IEEE International Conference on, V5, P857
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Monaci G, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P35
   Nakashizuka M, 2009, IEEE IMAGE PROC, P2145, DOI 10.1109/ICIP.2009.5414319
   Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Peotta L, 2006, SIGNAL PROCESS, V86, P444, DOI 10.1016/j.sigpro.2005.05.023
   Peyré G, 2009, J MATH IMAGING VIS, V34, P17, DOI 10.1007/s10851-008-0120-3
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Sallee Phil., 2003, Advances in Neural Information Processing Systems, V15, P1327
   Sezer OG, 2008, IEEE IMAGE PROC, P149, DOI 10.1109/ICIP.2008.4711713
   Skretting K, 2010, IEEE T SIGNAL PROCES, V58, P2121, DOI 10.1109/TSP.2010.2040671
   Sylvain L, 2005, INT CONF ACOUST SPEE, P293
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   Türkan M, 2010, IEEE IMAGE PROC, P789, DOI 10.1109/ICIP.2010.5652548
   Türkan M, 2009, IEEE IMAGE PROC, P25, DOI 10.1109/ICIP.2009.5413923
   Zepeda J., 2010, THESIS
   Zepeda J, 2011, IEEE J-STSP, V5, P1061, DOI 10.1109/JSTSP.2011.2135332
NR 37
TC 1
Z9 1
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 426
EP 437
DI 10.1016/j.jvcir.2013.02.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200018
DA 2024-07-18
ER

PT J
AU Wang, C
   Liu, WY
   Lai, ZY
   Wang, HY
AF Wang, Chun
   Liu, Wenyu
   Lai, Zhongyuan
   Wang, Hongyuan
TI Perceptually friendly shape decomposition by resolving segmentation
   points with minimum cost
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Part; Resolve; DCE; Relevance measure; Optimization; Protrusion; Human
   perception; Relation matrices
ID CONVEX DECOMPOSITION; VISUAL FORM; PARTS; REPRESENTATION; ORGANIZATION;
   RECOGNITION; COMPONENTS; OBJECTS
AB Organizing objects in terms of parts constructs a natural shape descriptor and provides a foundation for many shape-related applications, such as object detection and tracking. In this paper, we propose a part decomposition scheme that focuses on analyzing the relations between part cuts and segmentation points. Aiming at obtaining perceptually friendly parts, we take the human perception behavior into account when extracting candidate part cuts and defining their costs. The decomposition is to find a subset from candidate part cuts with minimum cost, while guarantee that all segmentation points are resolved. The theoretical and experimental results demonstrate that the proposed method is robust to occlusion, part movement and boundary distortion. We also show that our method can predict most of highly salient part cuts, and have a good performance in hand gesture recognition. Crown Copyright (c) 2013 Published by Elsevier Inc. All rights reserved.
C1 [Wang, Chun; Liu, Wenyu; Lai, Zhongyuan; Wang, Hongyuan] Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Liu, WY (corresponding author), Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Peoples R China.
EM wangchun1022@gmail.com; liuwy@mail.hust.edu.cn; laizhy@gmail.com;
   wythywl@public.wh.hb.cn
RI Liu, Wenyu/AAG-1426-2019
OI Liu, Wenyu/0000-0002-4582-7488
FU National Natural Science Foundations of China [61173120]
FX This work was supported in part by the National Natural Science
   Foundations of China under Grant No. 61173120.
CR [Anonymous], P 2 INT WORKSH VIS F
   [Anonymous], 1983, Advanced Computing Research: Computational Geometry
   [Anonymous], THESIS U SO CALIFORN
   [Anonymous], 2011, P ACM MULT
   August J, 1999, COMPUT VIS IMAGE UND, V76, P231, DOI 10.1006/cviu.1999.0802
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Barenholtz E, 2003, VISION RES, V43, P1655, DOI 10.1016/S0042-6989(03)00166-4
   Baylis G.C., 1994, VIS COGN, V1, P377, DOI [10.1080/13506289408401715, DOI 10.1080/13506289408401715]
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0
   BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302
   BRAUNSTEIN ML, 1989, PERCEPTION, V18, P817, DOI 10.1068/p180817
   Cohen EH, 2007, VISION RES, V47, P2825, DOI 10.1016/j.visres.2007.06.021
   De Winter J, 2006, COGNITION, V99, P275, DOI 10.1016/j.cognition.2005.03.004
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Giblin PJ, 2003, IEEE T PATTERN ANAL, V25, P895, DOI 10.1109/TPAMI.2003.1206518
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Katz RA, 2003, INT J COMPUT VISION, V55, P139, DOI 10.1023/A:1026183017197
   Keil M., 1998, Proceedings of the 10th Canadian Conference on Computational Geometry, P54
   Kim SH, 2009, J VISION, V9, DOI 10.1167/9.10.8
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 1998, PATTERN RECOGN, V31, P607, DOI 10.1016/S0031-3203(97)00071-X
   LEYTON M, 1989, COGNITIVE SCI, V13, P357, DOI 10.1016/0364-0213(89)90017-7
   Lien JM, 2006, COMP GEOM-THEOR APPL, V35, P100, DOI 10.1016/j.comgeo.2005.10.005
   Liu HR, 2010, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2010.5540225
   Macrini D, 2011, COMPUT VIS IMAGE UND, V115, P1044, DOI 10.1016/j.cviu.2010.12.011
   MARR D, 1978, PROC R SOC SER B-BIO, V200, P269, DOI 10.1098/rspb.1978.0020
   Mi X., 2007, IEEE 11 INT C COMPUT, P1
   PALMER SE, 1977, COGNITIVE PSYCHOL, V9, P441, DOI 10.1016/0010-0285(77)90016-0
   Ren Z, 2011, IEEE I CONF COMP VIS, P303, DOI 10.1109/ICCV.2011.6126256
   ROM H, 1993, IEEE T PATTERN ANAL, V15, P973, DOI 10.1109/34.254054
   Rosin PL, 2000, IEEE T SYST MAN CY A, V30, P202, DOI 10.1109/3468.833102
   Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9
   SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189
   Siddiqi K, 1996, PERCEPTION, V25, P399, DOI 10.1068/p250399
   Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P636, DOI 10.3758/BF03205536
   Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P943, DOI 10.3758/BF03206908
   Singh M., 2001, in Psychology, VVolume 130, P401
   Tanase Mirela., 2003, SCG 03, P58
   Ulupinar F., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P147, DOI 10.1109/ICPR.1990.118080
   Xu JA, 2010, IEEE IMAGE PROC, P3257, DOI 10.1109/ICIP.2010.5651179
   Zeng JT, 2008, LECT NOTES COMPUT SC, V5359, P682, DOI 10.1007/978-3-540-89646-3_67
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 46
TC 11
Z9 13
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 270
EP 282
DI 10.1016/j.jvcir.2013.01.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA 120CU
UT WOS:000317149200006
DA 2024-07-18
ER

PT J
AU Aptoula, E
AF Aptoula, Erchan
TI Comparative study of moment based parameterization for morphological
   texture description
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Texture analysis; Morphological Covariance; Granulometry;
   Parameterization; Statistical moments; Moment invariants; Fourier
   transform; Noise robustness
ID GRAY-SCALE; PATTERN SPECTRUM; CLASSIFICATION; IMAGES; RECOGNITION;
   INVARIANTS; COVARIANCE; ROTATION
AB The two principal morphological texture descriptors, granulometry and morphological covariance, rely on the common principle of successive filtering of an image using a variety of structuring elements, from which feature vectors are subsequently computed. A crucial stage of their computation is the numerical characterization or parameterization of each of the filtered images. In this regard, the zero-th statistical moment is the traditional measure, while the use of higher order moments has also been reported. In this paper, we present the results of a comparative study, concentrating on the potential of various statistical moments for the task of parameterization, while additionally investigating the contribution of Fourier transform moments. The experiments are conducted with focus on texture description effectiveness and on noise robustness, using publicly available texture collections: Outex, CUReT and KTH-TIPS2b, where it is shown that the combination of moments leads to superior classification performance even at high noise levels. (c) 2012 Elsevier Inc. All rights reserved.
C1 Okan Univ, TR-34959 Istanbul, Turkey.
C3 Okan University
RP Aptoula, E (corresponding author), Okan Univ, TR-34959 Istanbul, Turkey.
EM erchan.aptoula@okan.edu.tr
RI Aptoula, Erchan/AAI-1070-2020
OI Aptoula, Erchan/0000-0001-6168-2883
CR Ahonen T., SCAND C IM AN OSL NO, V5575, P61
   [Anonymous], RANDOM SETS INTEGRAL
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   Aptoula E., INT S MATH MORPH RIO
   Aptoula E, 2006, LECT NOTES COMPUT SC, V4105, P522
   Aptoula E, 2012, PATTERN RECOGN, V45, P4524, DOI 10.1016/j.patcog.2012.06.004
   Aptoula E, 2011, ADV IMAG ELECT PHYS, V169, P1, DOI 10.1016/B978-0-12-385981-5.00001-X
   Caputo B., INT C COMP VIS BEIJ, V2, P1597
   CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552
   Cheng F, 1992, IEEE T IMAGE PROCESS, V1, P533, DOI 10.1109/83.199924
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Dougherty E. R., 1994, TUTORIAL TEXTS OPTIC, VTT 16, P175
   DOUGHERTY ER, 1992, PATTERN RECOGN, V25, P1181, DOI 10.1016/0031-3203(92)90020-J
   Finlayson G, 2005, PATTERN RECOGN, V38, P179, DOI 10.1016/j.patcog.2004.04.010
   Flusser J, 2006, IEEE T IMAGE PROCESS, V15, P3784, DOI 10.1109/TIP.2006.884913
   Ghadiali M, 1996, ELECTRON LETT, V32, P1772, DOI 10.1049/el:19961176
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hanbury A, 2005, COMPUT IMAGING VIS, V30, P377
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Land S, 2009, LECT NOTES COMPUT SC, V5720, P92, DOI 10.1007/978-3-642-03613-2_9
   Lefèvre S, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3099707
   Li W, 1997, PATTERN RECOGN, V30, P1081, DOI 10.1016/S0031-3203(96)00146-X
   Liao S., INT C IM PROC HONG K, P4589
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   Ojala T., INT C PATT REC QUEB, V1, P701
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Tzafestas CS, 2002, J MATH IMAGING VIS, V17, P109, DOI 10.1023/A:1020629402912
   Urbach ER, 2007, IEEE T PATTERN ANAL, V29, P272, DOI 10.1109/TPAMI.2007.28
   Vácha P, 2011, PATTERN RECOGN LETT, V32, P771, DOI 10.1016/j.patrec.2011.01.002
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Wilkinson M.H.F., INT C PATT REC QUEB, V1, P21
   Yu H., INT C IM PROC NEW YO, P929
   Zhou F., INT C IM PROC THESS, V2, P610
NR 34
TC 8
Z9 8
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1213
EP 1224
DI 10.1016/j.jvcir.2012.08.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300005
DA 2024-07-18
ER

PT J
AU Chen, HT
   Chou, CL
   Tsai, WC
   Lee, SY
   Lin, BSP
AF Chen, Hua-Tsung
   Chou, Chien-Li
   Tsai, Wei-Chin
   Lee, Suh-Yin
   Lin, Bao-Shuh P.
TI HMM-based ball hitting event exploration system for broadcast baseball
   video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia system; Highlight detection; Baseball even recognition;
   Features extraction; HMM; Scene classification; Sports video analysis;
   Pattern recognition
ID TRACKING
AB With the dramatic growth of fandom population, a considerable amount of research efforts have been devoted to baseball video processing. However, little work focuses on the detailed follow-ups of ball hitting events. This paper proposes a HMM-based ball hitting event exploration system for broadcast baseball video. Utilizing the strictly-defined layout of the baseball field, the proposed system first detects the game-specific spatial patterns in the field, such as the field lines, the bases, the pitch mound, etc. Then, the play region the currently camera-focused region of the baseball field is identified for frame type classification. Since the temporal patterns of presenting the game progress follow a prototypical order, we consider the classified frame types as observation symbols and recognize ball hitting events using HMM. Experiments conducted on broadcast baseball video show encouraging results in frame type classification and ball hitting event recognition. Three practical applications, including highlight clip extraction by user-designated query, storyboard construction, and similar event retrieval, are introduced to address the applicability of our system. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Chen, Hua-Tsung; Lin, Bao-Shuh P.] Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
   [Chou, Chien-Li; Tsai, Wei-Chin; Lee, Suh-Yin; Lin, Bao-Shuh P.] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung
   University
RP Chen, HT (corresponding author), Natl Chiao Tung Univ, Informat & Commun Technol Lab, Hsinchu 300, Taiwan.
EM huatsung@cs.nctu.edu.tw
FU "Aim for the Top University Plan" of the National Chiao Tung University
   and Ministry of Education, Taiwan, R.O.C.; National Science Council of
   R.O.C. [98-2221-E-009-091-MY3, 101-2218-E-009-004-]
FX This work is supported in part by "Aim for the Top University Plan" of
   the National Chiao Tung University and Ministry of Education, Taiwan,
   R.O.C., and in part by National Science Council of R.O.C. under the
   Grant Nos. 98-2221-E-009-091-MY3 and 101-2218-E-009-004-.
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE ACOUSTICS SPEEC
   [Anonymous], 2005, P 2005 INT C IM PROC
   [Anonymous], ICIP2005
   [Anonymous], 2011, IEEE INT C MULT EXP
   [Anonymous], SPIE STORAGE RETRIEV
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], P INT COMP S
   Chang P, 2002, IEEE IMAGE PROC, P609
   Chen HT, 2010, MULTIMED TOOLS APPL, V47, P239, DOI 10.1007/s11042-009-0321-9
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Cheng CC, 2006, IEEE T MULTIMEDIA, V8, P585, DOI 10.1109/TMM.2006.870726
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   FLEISCHMAN M, 2007, P 15 INT C MULT, P333
   Gong YH, 2004, COMPUT VIS IMAGE UND, V96, P181, DOI 10.1016/j.cviu.2004.02.002
   Guéziec A, 2002, COMPUTER, V35, P38, DOI 10.1109/2.989928
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hu MC, 2011, IEEE T MULTIMEDIA, V13, P266, DOI 10.1109/TMM.2010.2100373
   Jahne B., 2002, DIGITAL IMAGE PROCES
   Kijak E, 2006, MULTIMED TOOLS APPL, V30, P289, DOI 10.1007/s11042-006-0031-5
   Lien CC, 2007, J VIS COMMUN IMAGE R, V18, P1, DOI 10.1016/j.jvcir.2006.09.002
   Liu S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/32135
   NELSON RC, 1994, IEEE T PATTERN ANAL, V16, P519, DOI 10.1109/34.291445
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181
   Wang JJ, 2008, MULTIMEDIA SYST, V14, P179, DOI 10.1007/s00530-008-0112-6
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
   Yu XG, 2009, COMPUT VIS IMAGE UND, V113, P643, DOI 10.1016/j.cviu.2008.01.006
   Zhu G., 2006, Proc. ACM Multimedia, P431, DOI [DOI 10.24963/IJCAI.2018/227, DOI 10.1145/1180639.1180728, 10.1145/1180639.1180728]
   Zhu GY, 2009, IEEE T MULTIMEDIA, V11, P49, DOI 10.1109/TMM.2008.2008918
NR 33
TC 6
Z9 7
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 767
EP 781
DI 10.1016/j.jvcir.2012.03.006
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400008
DA 2024-07-18
ER

PT J
AU Liu, D
   Sun, XY
   Wu, F
AF Liu, Dong
   Sun, Xiaoyan
   Wu, Feng
TI Inpainting with image patches for compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Assistant information; Displacement vector; Image compression; Image
   patches; lnpainting; Intra prediction; Non-parametric; Rate-distortion
   optimization; Texture synthesis
ID TEXTURE SYNTHESIS
AB We propose a patch-based image compression framework inspired by the inpainting techniques. The repeated patterns in one image are exploited for compression in a non-parametric manner, i.e., directly sampling image patches and encoding the similarity between them. We show how this idea leads to an assisted inpainting method, and how the inpainting method can be integrated into a patch-based image compression framework in a rate-distortion (R-D) optimal fashion. Two specific techniques - assisted inpainting for decoding, and R-D optimization for encoding by mode selection or image analysis - are presented in this paper. Experimental results show that compared with standard H.264 intra coding, our system (I) achieves up to 0.85 dB gain when optimized for objective quality and (2) saves as much as 25% bit-rate at similar subjective quality levels. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Liu, Dong] Univ Sci & Technol China, Hefei 230027, Peoples R China.
   [Liu, Dong; Sun, Xiaoyan; Wu, Feng] Microsoft Res Asia, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft Research Asia; Microsoft
RP Liu, D (corresponding author), Nokia Res Ctr, Beijing 100176, Peoples R China.
EM dong.e.liu@nokia.com; xysun@microsoft.com; fengwu@microsoft.com
RI Liu, Dong/K-7488-2012; Wu, Feng/KCY-3017-2024
OI Liu, Dong/0000-0001-9100-2906
CR [Anonymous], 3 M JOINT VID TEAM J
   [Anonymous], MSRTR200404
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], PROC CVPR IEEE
   Balle Johannes, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P93
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bjontegaard G, 2001, 13 M VID COD EXP GRO
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Carlsson G, 2008, INT J COMPUT VISION, V76, P1, DOI 10.1007/s11263-007-0056-x
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Drori I, 2003, ACM T GRAPHIC, V22, P303, DOI 10.1145/882262.882267
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Ferzli R, 2006, IEEE IMAGE PROC, P2949, DOI 10.1109/ICIP.2006.312925
   Freeman W. T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1182, DOI 10.1109/ICCV.1999.790414
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Höntsch I, 2000, IEEE T IMAGE PROCESS, V9, P1472, DOI 10.1109/83.862622
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   *JM, JM VER 12 4
   Jojic N, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P34
   *KAK, KAK VER 6 0
   KANNAN A, 2006, ADV NEURAL INFORM PR, V19, P657
   KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184
   Kwatra V, 2005, ACM T GRAPHIC, V24, P795, DOI 10.1145/1073204.1073263
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Pan F, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1491, DOI 10.1109/ICME.2004.1394519
   QUI GP, 1995, P SOC PHOTO-OPT INS, V2488, P218, DOI 10.1117/12.211992
   Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264
   Reid MM, 1997, ACM COMPUT SURV, V29, P3, DOI 10.1145/248621.248622
   SUZUKI Y, 2007, P IEEE INT C IM PROC, V3, P409
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   WEI LY, 2008, ACM T GRAPH SIGGRAPH, V27
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
   Zheng YF, 2008, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2008.4711707
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
NR 45
TC 12
Z9 13
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 100
EP 113
DI 10.1016/j.jvcir.2011.09.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100010
DA 2024-07-18
ER

PT J
AU Lee, JH
   Ho, YS
AF Lee, Jong-Ho
   Ho, Yo-Sung
TI High-quality non-blind image deconvolution with adaptive regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deblurring; Non-blind image deconvolution; Ringing artifacts;
   Noise amplification; Local characteristics; Adaptive regularization;
   Fast deconvolution; Boundary artifacts reduction
ID RESTORATION; RECOVERY; MINIMIZATION; ALGORITHM; CAMERA
AB Non-blind image deconvolution is a process that obtains a sharp latent image from a blurred image when a point spread function (PSF) is known. However, ringing and noise amplification are inevitable artifacts in image deconvolution since perfect PSF estimation is impossible. The conventional regularization to reduce these artifacts cannot preserve image details in the deconvolved image when PSF estimation error is large, so strong regularization is needed. We propose a non-blind image deconvolution method which preserves image details, while suppressing ringing and noise artifacts by controlling regularization strength according to local characteristics of the image. In addition, the proposed method is performed fast with fast Fourier transforms so that it can be a practical solution to image deblurring problems. From experimental results, we have verified that the proposed method restored the sharp latent image with significantly reduced artifacts and it was performed fast compared to other non-blind image deconvolution methods. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Lee, Jong-Ho; Ho, Yo-Sung] GIST, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Lee, JH (corresponding author), GIST, 1 Oryong Dong, Kwangju 500712, South Korea.
EM purmod@imrc.kist.re.kr; hoyo@gist.ac.kr
FU MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center); NIPA (National IT Industry
   Promotion Agency) [NIPA-2010-(C1090-1011-0003)]; Ministry of Public
   Safety & Security (MPSS), Republic of Korea [C1090-1011-0003] Funding
   Source: Korea Institute of Science & Technology Information (KISTI),
   National Science & Technology Information Service (NTIS)
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   support program supervised by the NIPA (National IT Industry Promotion
   Agency) (NIPA-2010-(C1090-1011-0003)).
CR [Anonymous], P SPIE ELECT IMAGING
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], P IEEE C COMP VIS PA
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Cho TS, 2010, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2010.5540214
   Dey N, 2006, MICROSC RES TECHNIQ, V69, P260, DOI 10.1002/jemt.20294
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   Joshi N, 2009, PROC CVPR IEEE, P1550, DOI 10.1109/CVPRW.2009.5206802
   Kim SK, 1998, ELECTRON LETT, V34, P1217, DOI 10.1049/el:19980762
   Krishnan Dilip., 2009, NIPS, V22, P1
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Lou YF, 2010, J SCI COMPUT, V42, P185, DOI 10.1007/s10915-009-9320-2
   LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605
   Shan Q., 2008, ACM T GRAPHICS, V27
   Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028
   Tikhonov A. N., 1943, Dokl. Akad. Nauk SSSR, V39, P195
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Weiss Y., 2007, P IEEE C COMPUTER VI, P1
   Wiener N., 1964, Extrapolation, interpolation, and smoothing of stationary time series: with engineering applications
   Yitzhaky Y, 1998, J OPT SOC AM A, V15, P1512, DOI 10.1364/JOSAA.15.001512
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673
NR 26
TC 24
Z9 29
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 653
EP 663
DI 10.1016/j.jvcir.2011.07.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800008
DA 2024-07-18
ER

PT J
AU Liu, Q
   Li, HL
   Ngan, KN
AF Liu, Qiang
   Li, Hongliang
   Ngan, King Ngi
TI Automatic body segmentation with graph cut and self-adaptive
   initialization level set (SAILS)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face detection; Motion estimation and compensation; Body segmentation;
   Object segmentation; Graph cut; Level set; Background contrast removal;
   Object detection
ID VIDEO OBJECT SEGMENTATION; FACE SEGMENTATION; TRACKING
AB In this paper, we propose an automatic human body segmentation system which mainly consists of human body detection and object segmentation. Firstly, an automatic human body detector is designed to provide hard constraints on the object and background for segmentation. And a coarse-to-fine segmentation strategy is employed to deal with the situation of partly detected object. Secondly, background contrast removal (BCR) and self-adaptive initialization level set (SAILS) are proposed to solve the tough segmentation problems of the high contrast at object boundary and/or similar colors existing in the object and background. Finally, an object updating scheme is proposed to detect and segment new object when it appears in the scene. Experimental results demonstrate that our body segmentation system works very well in the live video and standard sequences with complex background. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Liu, Qiang; Ngan, King Ngi] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
   [Li, Hongliang] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610054, Peoples R China.
C3 Chinese University of Hong Kong; University of Electronic Science &
   Technology of China
RP Liu, Q (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM qliu@ee.cuhk.edu.hk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
CR [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2002, SURFACES
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   Atzpadin N, 2004, IEEE T CIRC SYST VID, V14, P321, DOI 10.1109/TCSVT.2004.823391
   BOURDEV L, 2009, ICCV, P5
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen WC, 2010, J VIS COMMUN IMAGE R, V21, P427, DOI 10.1016/j.jvcir.2010.03.004
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Erdem CE, 2005, SIGNAL PROCESS-IMAGE, V20, P151, DOI 10.1016/j.image.2004.10.005
   Erdem CE, 2007, SIGNAL PROCESS-IMAGE, V22, P891, DOI 10.1016/j.image.2007.09.001
   Evans L., 1998, PARTIAL DIFFERENTIAL
   Ji XP, 2006, J VIS COMMUN IMAGE R, V17, P647, DOI 10.1016/j.jvcir.2005.07.004
   KIM C, 2002, IEEE T CIRC SYST VID, V12
   Kolmogorov V, 2005, PROC CVPR IEEE, P1186
   Li CM, 2005, PROC CVPR IEEE, P430
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2007, IEEE T CIRC SYST VID, V17, P1742, DOI 10.1109/TCSVT.2007.903326
   Li HL, 2007, IEEE COMMUN MAG, V45, P27, DOI 10.1109/MCOM.2007.284535
   Li HL, 2009, IEEE T MULTIMEDIA, V11, P77, DOI 10.1109/TMM.2008.2008922
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Li Y., 2004, P ACM SIGGRAPH
   Luo HT, 2002, SIGNAL PROCESS-IMAGE, V17, P559, DOI 10.1016/S0923-5965(02)00036-X
   Patras I, 2003, SIGNAL PROCESS-IMAGE, V18, P51, DOI 10.1016/S0923-5965(02)00092-9
   Rother C., 2004, P ACM SIGGRAPH
   Sethian J., 1999, LEVEL SET METHODS FA
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sun J., 2004, P ACM SIGGRAPH
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   TUZEL O, 2005, IEEE WORKSH MACH VIS, V3, P58
   Vemuri B, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P251, DOI 10.1007/0-387-21810-6_14
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
   WANG J, 1993, IEEE C COMP VIS PATT, P361
   WANG J, 2004, ACM SIGGRAPH 2004 PA
   Wills J, 2003, PROC CVPR IEEE, P37
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhang QA, 2010, J VIS COMMUN IMAGE R, V21, P453, DOI 10.1016/j.jvcir.2009.09.005
NR 39
TC 8
Z9 11
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 367
EP 377
DI 10.1016/j.jvcir.2011.03.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800001
DA 2024-07-18
ER

PT J
AU Zagoris, K
   Ergina, K
   Papamarkos, N
AF Zagoris, Konstantinos
   Ergina, Kavallieratou
   Papamarkos, Nikos
TI Image retrieval systems based on compact shape descriptor and relevance
   feedback information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Retrieval system; Document retrieval; Handwritten words; Word spotting;
   MPEG-7; Relevance feedback; Support Vector Machines; Shape
AB One of the most important and most used low-level image feature is the shape employed in a variety of systems such as document image retrieval through word spotting. In this paper an MPEG-like descriptor is proposed that contains conventional contour and region shape features with a wide applicability from any arbitrary shape to document retrieval through word spotting. Its size and storage requirements are kept to minimum without limiting its discriminating ability. In addition to that, a relevance feedback technique based on Support Vector Machines is provided that employs the proposed descriptor with the purpose to measure how well it performs with it. In order to evaluate the proposed descriptor it is compared against different descriptors at the MPEG-7 CE1 Set B database. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Zagoris, Konstantinos; Papamarkos, Nikos] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
   [Ergina, Kavallieratou] Univ Aegean, Dept Informat & Commun Syst Engn, Samos 83100, Greece.
C3 Democritus University of Thrace; University of Aegean
RP Zagoris, K (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
EM kzagoris@ee.duth.gr
RI Kavallieratou, Ergina/KDP-0788-2024
FU Greek Ministry of Development - General Secretariat of Research and
   Technology; E.U.
FX This paper is part of the 03E triangle 679 research project, implemented
   within the framework of the Reinforcement Programme of Human Research
   Manpower (PENED) and co-financed by National and Community Funds (25%)
   from the Greek Ministry of Development - General Secretariat of Research
   and Technology and (75%) from the E.U. - European Social Fund.
CR Adamek T, 2007, INT J DOC ANAL RECOG, V9, P153, DOI 10.1007/s10032-006-0024-y
   Aly M, 2009, IEEE IMAGE PROC, P777, DOI 10.1109/ICIP.2009.5414235
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   BADEKAS E, 2005, 10 IBEROAMERICAN C P
   Belongie S, 2001, ADV NEUR IN, V13, P831
   BHARDWAJ A, 2008, CLIA, P48
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chakrabarti K, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P709, DOI 10.1109/ICME.2000.871460
   CHATZICHRISTOFI.SA, 2008, P 9 INT WORKSH IM AN, P191, DOI DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2010, INT J PATTERN RECOGN, V24, P207, DOI 10.1142/S0218001410007890
   CHI Z, 1996, ADV FUZZY SYSTEMS AP, V10
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   GONZALEZ R, 2002, DIGITAL IMAGE PROC
   Gustafson D. E., 1979, Proceedings of the 1978 IEEE Conference on Decision and Control Including the 17th Symposium on Adaptive Processes, P761
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kavallieratou E., 2002, International Journal on Document Analysis and Recognition, V4, P226, DOI 10.1007/s100320200079
   Kim HK, 2000, SIGNAL PROCESS-IMAGE, V16, P87, DOI 10.1016/S0923-5965(00)00018-7
   Lavrenko V, 2004, FIRST INTERNATIONAL WORKSHOP ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P278, DOI 10.1109/DIAL.2004.1263256
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MANMATHA R, 1997, WORD SPOTTING INDEXI, P43
   MARTINEZ J, 2005, MPEG 7 OVERVIEW VERS
   Popescu A., 2009, ACM MULTIMEDIA, P657
   SAUVOLA J, 1997, INT C DOC AN REC, V1, P147
   Zagoris K, 2010, ENG APPL ARTIF INTEL, V23, P872, DOI 10.1016/j.engappai.2010.03.002
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   2000, SIGNAL PROCESSING IM, V16, P95
NR 30
TC 19
Z9 21
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 378
EP 390
DI 10.1016/j.jvcir.2011.03.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800002
DA 2024-07-18
ER

PT J
AU Li, MD
   Chen, ZZ
   Tan, YP
AF Li, Maodong
   Chen, Zhenzhong
   Tan, Yap-Peng
TI Cross-layer optimization for SVC video delivery over the IEEE 802.11e
   wireless networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video communication; Scalable video; SVC; Packet prioritization; Quality
   of Service; QoS mapping; Interface queue control; Wireless LAN; IEEE
   802.11e network
AB The Scalable Video Coding (SVC) standard extends the H.264/AVC with scalability support and is effective to adapt bitrate to the time-varying wireless channel bandwidth. In this paper, we propose a cross-layer optimization scheme, which includes packet prioritization and QoS mapping, for the delivery of SVC over the IEEE 802.11e wireless networks. The proposed structure enables interaction among different network layers, providing differentiated services for video packets. Our cross-layer optimization performs with the following information: (i) SVC packet prioritization at the application layer, (ii) service differentiation at the MAC layer, and (iii) interface queue (IFQ) occupation status at the link layer. We formulate the QoS mapping problem as a joint optimization of access category (AC) assignment and IFQ control. A novel and efficient solution is proposed to reduce the computational complexity of the joint optimization problem. Simulation results show that the proposed approach achieves notable improvement when compared to conventional methods. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Li, Maodong; Chen, Zhenzhong; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
C3 Nanyang Technological University
RP Li, MD (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
EM e080002@ntu.edu.sg; zzchen@ntu.edu.sg; eyptan@ntu.edu.sg
RI Chen, Zhenzhong/C-2529-2015; Chen, Zhenzhong/B-3110-2011; Tan,
   Yap-Peng/A-5158-2011; 陈, 震中/C-6857-2014
FU Agency for Science, Technology and Research (A*STAR), Singapore
FX This research is partially supported by a research grant awarded by The
   Agency for Science, Technology and Research (A*STAR), Singapore, under
   the Mobile Media Thematic Strategic Research Programme of the Science
   and Engineering Research Council.
CR [Anonymous], 80211A1999 IEEE
   [Anonymous], 802111999 IEEE
   [Anonymous], NETWORK SIMULATOR NS
   [Anonymous], IEEE COMPUTER COMMUN
   [Anonymous], 2003, ADV VID COD GEN AUD
   Bianchi G, 2000, IEEE J SEL AREA COMM, V18, P535, DOI 10.1109/49.840210
   Chen CM, 2007, J VIS COMMUN IMAGE R, V18, P191, DOI 10.1016/j.jvcir.2007.02.001
   Chen ZZ, 2010, IEEE SIGNAL PROC LET, V17, P675, DOI 10.1109/LSP.2010.2046193
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   CI S, 2008, ADV MULTIMEDIA, P1
   Ferguson Paul., 1998, Quality of service : delivering QoS on the Internet and in corporate networks
   Foh CH, 2007, IEEE T CIRC SYST VID, V17, P1665, DOI 10.1109/TCSVT.2007.903808
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Hsing-Lung Chen, 2008, Fourth International Conference on Wireless and Mobile Communications. ICWMC 2008, P241, DOI 10.1109/ICWMC.2008.35
   Hu J, 2008, IEEE ICC, P241, DOI 10.1109/ICC.2008.52
   Huang HC, 2007, IEEE COMMUN MAG, V45, P68, DOI 10.1109/MCOM.2007.284540
   *IEEE, 80211E2005 IEEE
   *ISO IEC, 1999, 144962 ISO IEC
   KELLERER DPH, 2005, KNAPSACK PROBLEMS
   Kim YG, 2004, IEEE T CIRC SYST VID, V14, P256, DOI 10.1109/TCSVT.2003.819186
   KUANG KY, 2005, J VIS COMMUN IMAGE R, V16, P475
   Liu YW, 2010, J VIS COMMUN IMAGE R, V21, P523, DOI 10.1016/j.jvcir.2010.02.004
   Marfia G, 2010, IEEE INT CON MULTI, P1376, DOI 10.1109/ICME.2010.5583267
   REICHEL J, 2007, JSVM 9 8 SOFTWARE
   Romdhani L, 2007, 3 IEEE INT C WIR MOB, P68
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   TURNER JS, 1986, IEEE COMMUN MAG, V24, P8, DOI 10.1109/MCOM.1986.1092946
   van der Schaar M., 2007, MULTIMEDIA IP WIRELE
   WIETHOLTER S, 2006, TKN06003
   Xiao S, 2010, J VIS COMMUN IMAGE R, V21, P871, DOI 10.1016/j.jvcir.2010.08.001
   Xiao Y, 2005, IEEE T WIREL COMMUN, V4, P1506, DOI 10.1109/TWC.2005.850328
NR 31
TC 14
Z9 16
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 284
EP 296
DI 10.1016/j.jvcir.2011.01.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300008
DA 2024-07-18
ER

PT J
AU Yang, L
   Hao, PW
   Wu, DP
AF Yang, Lei
   Hao, Pengwei
   Wu, Dapeng
TI Stabilization and optimization of PLUS factorization and its application
   in image coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE PLUS factorization; Stable algorithm; Optimization; Transform coding;
   Image compression; Integer reversible transform; Lapped Transform;
   Discrete cosine transform; Lifting factorization
ID EVERY UNIT MATRIX; TRANSFORM; DCT
AB A recently developed PLUS factorization holds great promise in image coding due to its simplicity and integer reversibility. However, existing PLUS factorizations did not consider stability and optimality. To address these problems, we propose methodologies to design stable and optimal PLUS factorization algorithms. Firstly, we propose three stable PLUS factorization algorithms, prove the stability theorem under no perturbation and analyze stability under perturbation. Furthermore, we obtain a closed-form formula for transform error, and use the formula to design an algorithm for optimal PLUS factorization. Then, we apply the PLUS factorization to image coding. The integer DCTs implemented with the optimal PLUS factorizations found by our algorithms outperform the integer DCT with expansion factors in terms of entropy. The optimal PLUS factorizations are superior to the lifting factorization in JPEG-XR. The experimental results agree with analytical results of PLUS factorization, and show superior performance of our algorithms in image coding. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Yang, Lei; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32608 USA.
   [Hao, Pengwei] Peking Univ, Dept Machine Intelligence, Beijing 100871, Peoples R China.
   [Hao, Pengwei] Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
C3 State University System of Florida; University of Florida; Peking
   University; University of London; Queen Mary University London
RP Yang, L (corresponding author), Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32608 USA.
EM leiyang@ufl.edu
OI Wu, Dapeng/0000-0003-1755-0183
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], IEEE T SIGNAL PROCES
   [Anonymous], 1996, Accuracy and Stability of Numerical Algorithms
   [Anonymous], GILL TEXT ISOIEC FCD
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P IEEE PAC RIM C COM
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 1990, Matrix Perturbation Theory
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], IEEE STAND SPEC IMPL
   [Anonymous], P IEEE INT C IM PROC
   CASSEREAU PM, 1989, IEEE T COMMUN, V37, P189, DOI 10.1109/26.20089
   Chang XW, 1998, BIT, V38, P486, DOI 10.1007/BF02510255
   Chen BQ, 2000, GRAPH MODELS, V62, P308, DOI 10.1006/gmod.2000.0525
   Cheng LZ, 2002, IEE P-VIS IMAGE SIGN, V149, P91, DOI 10.1049/ip-vis:20020132
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Galántai A, 2003, LINEAR MULTILINEAR A, V51, P175, DOI 10.1080/0308108031000069155
   Glover F., 1990, TABU SEARCH TUTORIAL, P1
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hao PW, 2004, LINEAR ALGEBRA APPL, V382, P135, DOI 10.1016/j.laa.2003.12.023
   Liang J, 2000, PROC SPIE, V4115, P384, DOI 10.1117/12.411606
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Malvar H., 1992, SIGNAL PROCESSING LA
   MALVAR HS, 1989, IEEE T ACOUST SPEECH, V37, P553, DOI 10.1109/29.17536
   Plonka G, 2004, APPL COMPUT HARMON A, V16, P90, DOI 10.1016/j.acha.2003.10.004
   Rao K.R, 2014, DISCRETE COSINE TRAN
   She YY, 2006, IEEE T SIGNAL PROCES, V54, P4675, DOI 10.1109/TSP.2006.881227
   She YY, 2005, LINEAR ALGEBRA APPL, V400, P193, DOI 10.1016/j.laa.2004.11.024
   She YY, 2004, SCI CHINA SER F, V47, P421, DOI 10.1360/02yf0499
   Strang G, 1997, LINEAR ALGEBRA APPL, V265, P165
   Strang G., 1997, WAVELETS FILTER BANK
   Toffoli T, 1997, LINEAR ALGEBRA APPL, V259, P31, DOI 10.1016/S0024-3795(96)00240-6
   Tran TD, 2003, IEEE T SIGNAL PROCES, V51, P1557, DOI 10.1109/TSP.2003.811222
   Tran TD, 2000, IEEE SIGNAL PROC LET, V7, P145, DOI 10.1109/97.844634
   Tu CJ, 2008, P SOC PHOTO-OPT INS, V7073, DOI 10.1117/12.797097
   Wang L., 2001, Intelligent optimization algorithms with applications
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang L, 2009, IEEE T SIGNAL PROCES, V57, P2594, DOI 10.1109/TSP.2009.2018631
NR 42
TC 1
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 9
EP 22
DI 10.1016/j.jvcir.2010.09.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Celik, T
AF Celik, Turgay
TI Image change detection using Gaussian mixture model and genetic
   algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gaussian mixture model; Genetic algorithm; Parameter estimation;
   Bayesian inference; Change detection; Difference image; Log-ratio image;
   Remote sensing; Optical image; Advanced synthetic aperture radar
ID UNSUPERVISED CHANGE DETECTION; SATELLITE IMAGES; EM ALGORITHM
AB In this paper, we propose a novel method for unsupervised change detection in multi-temporal satellite images of the same scene using Gaussian mixture model (GMM) and genetic algorithm (GA). The difference image data computed from multi-temporal satellite images of the same scene is modelled by using N components GMM. GA is used to estimate the parameters of the GMM. Then, the GMM of the difference image data is partitioned into two sets of distributions representing data distributions of "changed" and "unchanged" pixels by minimizing a cost function using GA. Bayesian inference is exploited together with the estimated data distributions of "changed" and "unchanged" pixels to achieve the final change detection result. The proposed method does not need any parameter tuning process, and is completely automatic. As a case study for the unsupervised change detection, multi-temporal advanced synthetic aperture radar (ASAR) images acquired by ESA Envisat on the recent flooding area in Bangladesh and parts of India brought on by two weeks of persistent rain and multi-temporal optical images acquired by Landsat 5 TM on a part of Alaska are considered. Change detection results are shown on real data and comparisons with the state-of-the-art techniques are provided. (c) 2010 Elsevier Inc. All rights reserved.
C1 Natl Univ Singapore, A STAR, Comp Vis & Pattern Discovery Grp, Fac Sci,Dept Chem,Bioinformat Inst, Singapore 117548, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR -
   Bioinformatics Institute (BII); National University of Singapore
RP Celik, T (corresponding author), Natl Univ Singapore, A STAR, Comp Vis & Pattern Discovery Grp, Fac Sci,Dept Chem,Bioinformat Inst, Singapore 117548, Singapore.
EM celikturgay@gmail.com
RI Celik, Turgay/Q-9713-2018
OI Celik, Turgay/0000-0001-6925-6010
FU Singapore Ministry of Education [R-143-000-358-112]
FX This work was supported by the Singapore Ministry of Education under
   Grant R-143-000-358-112.
CR Bovolo F, 2005, IEEE T GEOSCI REMOTE, V43, P2963, DOI 10.1109/TGRS.2005.857987
   Bruzzone L, 2000, IEEE T GEOSCI REMOTE, V38, P1171, DOI 10.1109/36.843009
   Celik T, 2010, IEEE T GEOSCI REMOTE, V48, P1199, DOI 10.1109/TGRS.2009.2029095
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P820, DOI 10.1109/LGRS.2009.2026188
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Kasetkasem T, 2002, IEEE T GEOSCI REMOTE, V40, P1815, DOI 10.1109/TGRS.2002.802498
   Koza J.R., 1992, GENETIC PROGRAMMING, VVolume 1
   Leprince S, 2007, IEEE T GEOSCI REMOTE, V45, P1529, DOI 10.1109/TGRS.2006.888937
   Pernkopf F, 2005, IEEE T PATTERN ANAL, V27, P1344, DOI 10.1109/TPAMI.2005.162
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Shah CA, 2008, IEEE T GEOSCI REMOTE, V46, P3908, DOI 10.1109/TGRS.2008.2000636
   Törmä M, 2007, INT GEOSCI REMOTE SE, P1947, DOI 10.1109/IGARSS.2007.4423208
NR 13
TC 25
Z9 27
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 965
EP 974
DI 10.1016/j.jvcir.2010.09.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500019
DA 2024-07-18
ER

PT J
AU Küçüktunç, O
   Bastan, M
   Güdükbay, U
   Ulusoy, Ö
AF Kucuktunc, Onur
   Bastan, Muhammet
   Gudukbay, Ugur
   Ulusoy, Ozgur
TI Video copy detection using multiple visual cues and MPEG-7 descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based copy detection; Video copy detection; Visual ques; MPEG-7;
   Activity matching; Face detection; Time series analysis; Subsequence
   matching
AB We propose a video copy detection framework that detects copy segments by fusing the results of three different techniques: facial shot matching, activity subsequence matching, and non-facial shot matching using low-level features. In facial shot matching part, a high-level face detector identifies facial frames/shots in a video clip. Matching faces with extended body regions gives the flexibility to discriminate the same person (e.g., an anchor man or a political leader) in different events or scenes. In activity subsequence matching part, a spatio-temporal sequence matching technique is employed to match video clips/segments that are similar in terms of activity. Lastly, the non-facial shots are matched using low-level MPEG-7 descriptors and dynamic-weighted feature similarity calculation. The proposed framework is tested on the query and reference dataset of CBCD task of TRECVID 2008. Our results are compared with the results of top-8 most successful techniques submitted to this task. Promising results are obtained in terms of both effectiveness and efficiency. Published by Elsevier Inc.
C1 [Kucuktunc, Onur] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
   [Bastan, Muhammet; Gudukbay, Ugur; Ulusoy, Ozgur] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 University System of Ohio; Ohio State University; Ihsan Dogramaci
   Bilkent University
RP Küçüktunç, O (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
EM kucuktunc.1@osu.edu; bastan@cs.bilkent.edu.tr;
   gudukbay@cs.bilkent.edu.tr; oulusoy@cs.bilkent.edu.tr
RI Gudukbay, Ugur/F-1012-2011; Ulusoy, Ozgur/KVY-4530-2024
OI Gudukbay, Ugur/0000-0003-2462-6959; Ulusoy, Ozgur/0000-0002-6887-3778
CR [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P INT WORKSH MULT IN
   [Anonymous], P INT C IM PROC
   Ardizzone E, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P725, DOI 10.1109/MMCS.1999.778574
   Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bertini M, 2006, LECT NOTES COMPUT SC, V4071, P133
   DOUZE M, 2008, P TREC VID RETR EV T
   Duan L., 2006, International Multimedia Conference, P201
   GENGEMBRE N, 2008, P TREC VID RETR EV T
   Hampapur A, 2002, P SOC PHOTO-OPT INS, V4676, P194
   HAMPAPUR A, 2001, P IEEE INT C MULT EX, P737
   Hsu WH, 2006, IEEE IMAGE PROC, P141, DOI 10.1109/ICIP.2006.312379
   Joly A, 2003, LECT NOTES COMPUT SC, V2728, P414
   JOLY A, 2005, P INT C DAT ENG WORK, P1285
   JOLY A, 2008, P TREC VID RETR EV T
   JOLY A, 2005, P IEEE INT C IM PROC, V1, P505
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   JUNEE R, 2009, ZOINKS 20 HOURS VIDE
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Law-To J, 2006, INT C PATT RECOG, P232
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   LAWTO J, 2006, P 14 ANN ACM INT C M, P201
   LIANG Y, 2008, P TREC VID RETR EV T
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mohan R, 1998, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.1998.679686
   MOUNT DM, 2009, ANN APPROXIMATE NEAR
   Ren HM, 2009, IEEE INT CON MULTI, P1382, DOI 10.1109/ICME.2009.5202761
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   Satoh S, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P69, DOI 10.1109/ICME.2002.1035720
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WILLEMS G, 2008, MIR 08, P283
   Wu X, 2008, COMPUT VIS IMAGE UND, V110, P418, DOI 10.1016/j.cviu.2007.09.015
   WU Z, 2009, P ACM MULT C, P549
   Yeh MC, 2009, P ACM INT C IM VID R
   ZHAI Y, 2005, P 13 ACM INT C MULT, P2
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
   2009, BUILDING VIDEO QUERI
   2009, CONTENT BASED COPY D
   2008, TRECVID 2008 FINAL L
NR 44
TC 17
Z9 22
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 838
EP 849
DI 10.1016/j.jvcir.2010.07.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Colleu, T
   Pateux, S
   Morin, L
   Labit, C
AF Colleu, T.
   Pateux, S.
   Morin, L.
   Labit, C.
TI A polygon soup representation for multiview coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D video; Multiview video plus depth; Polygon soup; Quadtree; Multiview
   coding; View synthesis; Redundancy simplification; Ghosting artifact
ID 3D VIDEO
AB This paper presents a polygon soup representation for multiview data. Starting from a sequence of multiview video plus depth (MVD) data, the proposed quad-based representation takes into account, in a unified manner, different issues such as compactness, compression, and intermediate view synthesis. The representation is extracted from MVD data in two steps. First, a set of 3D quads is extracted thanks to quadtree decomposition performed on depth maps. Second, a selective elimination of the quads is performed in order to reduce inter-view redundancies and thus provide a compact representation. Moreover, the proposed methodology for extracting the representation allows to reduce ghosting artifacts. Finally, an adapted compression technique is proposed that limits coding artifacts. The results presented on two real sequences show that the proposed representation provides a good trade-off between rendering quality and data compactness. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Colleu, T.; Pateux, S.] FT IMG RD TECH OPERA CVA, Orange Labs, F-35512 Cesson Sevigne, France.
   [Colleu, T.; Labit, C.] IRISA, INRIA Rennes Bretagne Atlantique, F-35042 Rennes, France.
   [Morin, L.] IETR INSA Rennes, F-35043 Rennes, France.
C3 Orange SA; Universite de Rennes; Universite de Rennes
RP Pateux, S (corresponding author), FT IMG RD TECH OPERA CVA, Orange Labs, 4 Rue Clos Courtel,BP 91226, F-35512 Cesson Sevigne, France.
EM thomas.colleu@irisa.fr; stephane.pateux@orange-ftgroup.com;
   luce.morin@insa-rennes.fr; claude.labit@irisa.fr
CR [Anonymous], 2008, N9978 ISOIEC JTC1SC2
   Bruls WHA, 2007, IEEE IMAGE PROC, P89
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   EVERSSENNE J, 2004, C VIS MED PROD CVMP
   Fehn C., 2002, PROC INT BROADCAST C, P357
   Gargallo P, 2005, PROC CVPR IEEE, P885
   *ISO IEC ITU T, 2003, H264 ISOIEC ITUT JOI
   KOBAYASHI T, 2000, 3 DIMENSIONAL IMAGE, P252
   MAITRE, 2009, PICT COD S CHIC US
   MERKLE, 2008, 3DTV C
   Merkle P, 2007, IEEE IMAGE PROC, P201
   MULLER K, 2008, MULT SIGN PROC 2008, P34
   OH, 2009, PICT COD S CHIC US
   Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   SMOLIC A, 2009, PICT COD S CHIC US
   Smolic A, 2008, IEEE IMAGE PROC, P2448, DOI 10.1109/ICIP.2008.4712288
   TANIMOTO M, 2008, M15377 ISOIEC JTC1SC
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   YEA S, 2009, PICT COD S CHIC US
   ZHAO Y, 2009, MPEG2009M16584 ISOIE
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 24
TC 4
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 561
EP 576
DI 10.1016/j.jvcir.2010.01.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Jiang, GY
   Yu, M
   Yang, Y
   Peng, ZJ
   Chen, K
AF Zhang, Yun
   Jiang, Gangyi
   Yu, Mei
   Yang, You
   Peng, Zongju
   Chen, Ken
TI Depth perceptual region-of-interest based multiview video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three-dimensional television; Multiview video coding; Multiview video
   plus depth; Depth perceptual region-of-interest; Bit allocation;
   Inter-view correlation; Hierarchical B picture; Human visual system
ID EXTRACTION; ATTENTION; SCHEME
AB MultiView Video (MVV) has attracted considerable attention recently since it is capable of providing users with three-dimensional perception and interactive functionalities. However, these MVV data require large mount of storage and bandwidth in network transmission. In this paper, we present a novel Depth Perceptual Region-Of-Interest (DP-ROI) based Multiview Video Coding (RMVC) scheme to extensively improve data compression efficiency by exploiting redundancies in depth perception. Firstly, we define DP-ROI according to the three-dimensional depth sensation of human visual system. Then, a framework of RMVC is developed to improve compression efficiency by properly segmenting the MW into different macroblock wise DP-ROIs and encoding them separately. And then, we propose three fast depth based DP-ROI extraction and tracking algorithms by jointly using motion, texture, depth as well as previous extracted DP-ROIs. Finally, on the basis of the extracted DP-ROI, bit allocation optimization model is proposed to allocate more bits on DP-ROIs for high image quality and fewer bits on background regions for high compression ratio. Experimental results show that the presented RMVC scheme achieves significant coding gains at high rate while comparing with original joint multiview video model. To be specific, up to 14.22-23.32% bit-rate are saved while 0.16-0.68 dB coding gains are achieved in DP-ROIs at the cost of the image quality degradation in background. Crown Copyright (C) 2010 Published by Elsevier Inc. All rights reserved.
C1 [Zhang, Yun; Jiang, Gangyi; Yu, Mei; Peng, Zongju; Chen, Ken] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Zhang, Yun; Jiang, Gangyi; Yang, You] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Grad Sch, Beijing 100080, Peoples R China.
C3 Ningbo University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM jianggangyi@126.com
RI Lin, Weisi/A-3696-2011; Yang, You/A-9497-2019; Zhang, Yun/V-7261-2019;
   jiang, gang/KII-8233-2024; Peng, Zongju/AAA-2914-2020; Yang,
   You/O-5723-2019
OI Lin, Weisi/0000-0001-9866-1947; Zhang, Yun/0000-0001-9457-7801; Peng,
   Zongju/0000-0001-8286-538X; 
CR Bjontegaard G., 2001, VCEGM33 ITUT
   Chi MC, 2008, SIGNAL PROCESS-IMAGE, V23, P127, DOI 10.1016/j.image.2007.12.001
   Engelke U, 2008, INT CONF ACOUST SPEE, P869, DOI 10.1109/ICASSP.2008.4517748
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   HO YS, 2007, P INT WORKSH SYST SI, P5
   *ISO IEC JTC1 SC29, 2005, N6909 ISOIEC JTC1SC2
   Izquierdo ME, 1999, IEEE T CIRC SYST VID, V9, P589, DOI 10.1109/76.767125
   Kaminsky E, 2008, J VIS COMMUN IMAGE R, V19, P56, DOI 10.1016/j.jvcir.2007.05.002
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kitahara M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P97, DOI 10.1109/ICME.2006.262559
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Marugame A, 2000, IEEE T CIRC SYST VID, V10, P530, DOI 10.1109/76.844998
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Müueller K, 2007, IEEE SIGNAL PROC MAG, V24, P58, DOI 10.1109/MSP2007.905697
   OHM JR, 1999, IEEE SIGNAL PROCESSI, V16, P47
   OKA S, 2004, DYNAMIC RAY SPACE CO, P15
   Smolic A, 2005, P IEEE, V93, P98, DOI 10.1109/JPROC.2004.839608
   SMOLIC A, 2007, JVTW100 MPEG ITUT SG
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Takagi K, 2003, PROC SPIE, V5150, P914, DOI 10.1117/12.503316
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Vetro A, 2008, PROC SPIE, V7073, DOI 10.1117/12.797353
   Wang Y, 2005, IEEE T IMAGE PROCESS, V14, P937, DOI 10.1109/TIP.2005.849330
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   YEA S, 2009, IMAGE COMMUNICATION, V24, P89
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   YU M, 2007, STAT ANAL MACROBLOCK
   Zhang Y, 2009, ETRI J, V31, P151, DOI 10.4218/etrij.09.0108.0350
NR 30
TC 12
Z9 16
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 498
EP 512
DI 10.1016/j.jvcir.2010.03.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600012
DA 2024-07-18
ER

PT J
AU Tian, J
   Ma, KK
AF Tian, Jing
   Ma, Kai-Kuang
TI Stochastic super-resolution image reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Image reconstruction; Bayesian inference; Markov chain
   Monte Carlo; Sample generation; Gibbs sampler; Metropolis-Hastings
   algorithm; Bilateral filter
ID RESTORATION; CONVERGENCE; ALGORITHMS; MCMC
AB The objective of super-resolution (SR) imaging is to reconstruct a single higher-resolution image based on a set of lower-resolution images that were acquired from the same scene to overcome the limitations of image acquisition process for facilitating better visualization and content recognition. In this paper, a stochastic Markov chain Monte Carlo (MCMC) SR image reconstruction approach is proposed. First, a Bayesian inference formulation, which is based on the observed low-resolution images and the prior high-resolution image model, is mathematically derived. Second, to exploit the MCMC sample-generation technique for the stochastic SR image reconstruction, three fundamental issues are observed as follows. First, since the hyperparameter value of the prior image model controls the degree of regularization and intimately affects the quality of the reconstructed high-resolution image, how to determine an optimal hyperparameter value for different low-resolution input images becomes a very challenging task. Rather than exploiting the exhaustive search, an iterative updating approach is developed in this paper by allowing the value of hyperparameter being simultaneously updated in each sample-generation iteration. Second, the samples generated during the so-called burn-in period (measured in terms of the number of samples initially generated) of the MCMC-based sample-generation process are considered unreliable and should be discarded. To determine the length of the burn-in period for each set of low-resolution input images, a time-period bound in closed form is mathematically derived. Third, image artifacts could be incurred in the reconstructed high-resolution image, if the number of samples (counting after the burn-in period) generated by the MCMC-based sample-generation process is insufficient. For that, a variation-sensitive bilateral filter is proposed as a 'complementary' post-processing scheme, to improve the reconstructed high-resolution image quality, when the number of samples is insufficient. Extensive simulation results have clearly shown that the proposed stochastic SR image reconstruction method consistently yields superior performance. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Tian, Jing] Nanyang Technol Univ, Temasek Labs, Singapore 637553, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Ma, KK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM pg05061499@ntu.edu.sg; ekkma@ntu.edu.sg
RI Tian, Jing/ABI-2886-2020; Ma, Kai-Kuang/KBA-9411-2024
OI Tian, Jing/0000-0002-4084-6911; 
CR [Anonymous], 1984, ADV COMPUTER VISION
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], EURASIP J APPL SIGNA
   [Anonymous], 2003, Image analysis, random fields and Markov chain Monte Carlo methods: a mathematical introduction
   [Anonymous], 1995, Markov random field modeling in computer vision
   Bertero M., 1998, Introduction to Inverse Problems in Imaging
   Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509
   BORMAN S, 1998, SPATIAL 1 RESOLUTION
   Bose NK, 2004, INT J IMAG SYST TECH, V14, P35, DOI 10.1002/ima.20005
   BOSE NK, 2001, P INT S CIRC SYST, V2, P433
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Dongarra J, 2000, COMPUT SCI ENG, V2, P22, DOI 10.1109/MCISE.2000.814652
   Doucet A, 2005, IEEE SIGNAL PROC MAG, V22, P152, DOI 10.1109/MSP.2005.1550195
   Figueiredo MAT, 2001, IEEE T IMAGE PROCESS, V10, P1322, DOI 10.1109/83.941856
   Fitzgerald WJ, 2001, SIGNAL PROCESS, V81, P3, DOI 10.1016/S0165-1684(00)00187-0
   Galatsanos NP, 2000, IEEE T IMAGE PROCESS, V9, P1784, DOI 10.1109/83.869189
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gibbs AL, 2004, STOCH MODELS, V20, P473, DOI 10.1081/STM-200033117
   Gilks Walter R., 1995, Markov chain Monte Carlo in practice
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   He H, 2006, IEEE T IMAGE PROCESS, V15, P592, DOI 10.1109/TIP.2005.860599
   He H, 2004, J ELECTRON IMAGING, V13, P586, DOI 10.1117/1.1762889
   He Y, 2009, IMAGE VISION COMPUT, V27, P364, DOI 10.1016/j.imavis.2008.05.010
   Humblot F, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/36971
   Jalobeanu A, 2002, PATTERN RECOGN, V35, P341, DOI 10.1016/S0031-3203(00)00178-3
   Kang MG, 2003, IEEE SIGNAL PROC MAG, V20, P19
   Katsaggelos AggelosK., 2007, SUPER RESOLUTION IMA
   Kokaram AC, 2002, IEEE T SIGNAL PROCES, V50, P189, DOI 10.1109/78.978375
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Ng M, 2007, MULTIDIM SYST SIGN P, V18, P57, DOI 10.1007/s11045-007-0021-4
   Pham TQ, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/83268
   Pickup L.C., 2006, P ADV NEURAL INFORM, P1089
   Rue Havard, 2005, Gaussian Markov Random Fields: Theory and Applications, DOI DOI 10.1201/9780203492024
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   TIAN J, 2005, P IEEE INT C IM PROC, P45
   Tian J, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P940
   Tian J, 2006, LECT NOTES COMPUT SC, V4261, P287
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
NR 40
TC 59
Z9 65
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 232
EP 244
DI 10.1016/j.jvcir.2010.01.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400005
DA 2024-07-18
ER

PT J
AU Luo, HY
   Ci, S
   Wu, DL
   Tang, H
AF Luo, Haiyan
   Ci, Song
   Wu, Dalei
   Tang, Hui
TI End-to-end optimized TCP-friendly rate control for real-time video
   streaming over wireless multi-hop networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rate control; TCP-Friendly Rate Control (TFRC); Cross-layer;
   User-perceived video quality; Adaptive Modulation and Coding (AMC);
   Video distortion; Real-time video streaming; Video transmission;
   Wireless multi-hop networks; Video over wireless
AB Rate control is an important issue in video streaming applications. The most popular rate control scheme over wired networks is TCP-Friendly Rate Control (TFRC), which is designed to provide optimal transport service for unicast multimedia delivery based on the TCP Reno's throughput equation. It assumes perfect link quality, treating network congestion as the only reason for packet losses. Therefore, when used in wireless environment, it suffers significant performance degradation because of packet losses arising from time-varying link quality. Most Current research focuses on enhancing the TFRC protocol itself, ignoring the tightly coupled relation between the transport layer and other network layers. In this paper, we propose a new approach to address this problem, integrating TFRC with the application layer and the physical layer to form a holistic design for real-time video streaming over wireless multi-hop networks. The proposed approach can achieve the best user-perceived video quality by jointly optimizing system parameters residing in different network layers, including real-time video coding parameters at the application layer, packet sending rate at the transport layer, and modulation and coding scheme at the physical layer. The problem is formulated and solved as to find the optimal combination of parameters to minimize the end-to-end expected video distortion constrained by a given video playback delay, or to minimize the video playback delay constrained by a given end-to-end video distortion. Experimental results have validated 2-4 dB PSNR performance gain of the proposed approach in wireless multi-hop networks by using H.264/AVC and NS-2. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Luo, Haiyan; Ci, Song; Wu, Dalei] Univ Nebraska Lincoln, Dept Comp & Elect Engn, Omaha, NE 68182 USA.
   [Tang, Hui] Chinese Acad Sci, High Performance Network Lab, IOA, Beijing 100864, Peoples R China.
C3 University of Nebraska System; University of Nebraska Lincoln; Chinese
   Academy of Sciences
RP Ci, S (corresponding author), Univ Nebraska Lincoln, Dept Comp & Elect Engn, 1110 S 67th ST, Omaha, NE 68182 USA.
EM sci@engr.unl.edu
RI Ci, Song/R-8324-2019; Wu, Dalei/A-6884-2012
OI , Dalei/0000-0002-9362-3906
FU National Science Foundation [0830493]; Division of Computing and
   Communication Foundations; Direct For Computer & Info Scie & Enginr
   [0830493] Funding Source: National Science Foundation
FX This material is based upon work supported by the National Science
   Foundation under Grant No. 0830493.
CR *3GPP, 2004, 25848V400 3GPP TR
   Alouini MS, 2000, WIRELESS PERS COMMUN, V13, P119, DOI 10.1023/A:1008979107539
   ALSUHAIL G, 2006, CONTROL AUTOMATION R, P1
   ARGYRIOU A, 2007, ELSEVIER SIGNAL PROC, V22
   BAE S, 2002, GLOBAL TELECOMMUN C, V2, P1794
   CHAUDHARY R, 2003, COMPUT COMMUN NETWOR, P599
   CHEN K, 2004, WORKSH WIR AD HOC NE
   CHEN M, 2005, IEEE WIRELESSCOM
   Chen MH, 2006, IEEE T MULTIMEDIA, V8, P1045, DOI 10.1109/TMM.2006.879837
   COTE G, 2000, IEEE J SELECT AREAS, V18
   CROWCROFT J, 1998, ACM COMPUT COMMUN RE, V28
   Doufexi A, 2002, IEEE COMMUN MAG, V40, P172, DOI 10.1109/35.1000232
   Floyd S, 1999, IEEE ACM T NETWORK, V7, P458, DOI 10.1109/90.793002
   Floyd S., 2000, P ACM SIGCOMM AUG
   Fu Z., 2004, IEEE JSAC
   *IEEE, 2002, 80216 IEEE WORK GROU
   *ITU T, 2003, H264IISOIEC1449610AV
   KHANLOO S, 2008, ICWMC, P7
   LI M, 2004, DISTRIBUTED MULTIMED
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Luo H., 2008, IEEE GLOBECOM
   LUO H, 2009, IEEE ICC
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   PYUN J, 2003, IEEE T CONSUMER ELEC, V49
   Schuster G., 1997, RATE DISTORTION BASE
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WU D, 2000, IEEE T CIRCUITS SYST, V10
   Wu DL, 2007, IEEE J SEL AREA COMM, V25, P841, DOI 10.1109/JSAC.2007.070519
   Yang F, 2004, IEEE INFOCOM SER, P2142
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   ZHOU B, 2007, ICNP, P216
NR 31
TC 14
Z9 17
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 98
EP 106
DI 10.1016/j.jvcir.2009.06.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800004
DA 2024-07-18
ER

PT J
AU Zhai, GT
   Lin, WS
   Cai, JF
   Yang, XK
   Zhang, WJ
AF Zhai, Guangtao
   Lin, Weisi
   Cai, Jianfei
   Yang, Xiaokang
   Zhang, Wenjun
TI Efficient quadtree based block-shift filtering for deblocking and
   deringing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deblocking; Image deringing; Block-shift filtering; Quadtree
   decomposition; Image post-processing; Image restoration; Image
   compression; Perceptual quality
ID ARTIFACTS SUPPRESSION; CONSTRAINT SET; REDUCTION; IMAGES
AB The existing implementations of block-shift based filtering algorithms for deblocking are hard to achieve good smoothing performance and low computation complexity simultaneously due to their fixed block size and small shifting range. In this paper, we propose to integrate quadtree (QT) decomposition with the block-shift filtering for cleblocking. By incorporating the QT decomposition, we can easily find the locations of uniform regions and determine the corresponding suitable block sizes. The variable block sizes generated by the QT decomposition facilitate the later block-shift filtering with low computational cost. In addition, large block based shift filtering can provide better deblocking results because the smoothing range of large blocks spans over the conventional 8 x 8 block size. Furthermore, we extend the proposed QT based block-shifting algorithm for deringing JPEG2000 coded images. Experimental results show the superior performance of our proposed algorithms. (C) 2009 Published by Elsevier Inc.
C1 [Lin, Weisi; Cai, Jianfei] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Zhai, Guangtao; Yang, Xiaokang; Zhang, Wenjun] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
C3 Nanyang Technological University; Shanghai Jiao Tong University
RP Cai, JF (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave BLK N4, Singapore 639798, Singapore.
EM zhaiguangtao@sjtu.edu.cn; wslin@sjtu.edu.cn; asjfcai@sjtu.edu.cn;
   xkyang@sjtu.edu.cn; zhangwenjun@sjtu.edu.cn
RI Liu, Anmin/A-4730-2012; Zhai, Guangtao/X-5949-2019; Yang,
   Xiaokang/C-6137-2009; Zhang, Wenjun/GNH-2095-2022; Lin,
   Weisi/A-8011-2012; Lin, Weisi/A-3696-2011; Cai, Jianfei/A-3691-2011
OI Zhai, Guangtao/0000-0001-8165-9322; Yang, Xiaokang/0000-0003-4029-3322;
   Zhang, Wenjun/0000-0002-5282-3725; Lin, Weisi/0000-0001-9866-1947; Cai,
   Jianfei/0000-0002-9444-3763
CR Al-Fahoum AS, 2001, IEEE T IMAGE PROCESS, V10, P1288, DOI 10.1109/83.941853
   [Anonymous], 2000, JPEG 2000 IMAGE COMP
   Apostolopoulos JG, 1999, IEEE T IMAGE PROCESS, V8, P1125, DOI 10.1109/83.777093
   Banister BA, 2001, IEEE T CIRC SYST VID, V11, P3, DOI 10.1109/76.894278
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen T, 2001, IEEE T CIRC SYST VID, V11, P594, DOI 10.1109/76.920189
   Fan GL, 2001, IEEE T CIRC SYST VID, V11, P1263, DOI 10.1109/76.974680
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   JARSKE T, 1994, IEEE T CONSUM ELECTR, V40, P521, DOI 10.1109/30.320837
   Li X, 2005, IEEE T CIRC SYST VID, V15, P108, DOI 10.1109/TCSVT.2004.836743
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1583, DOI 10.1109/TCSVT.2005.858613
   Liew AWC, 2005, IEEE T CIRC SYST VID, V15, P795, DOI 10.1109/TCSVT.2005.848303
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   Luo JB, 1996, IEEE T IMAGE PROCESS, V5, P1363, DOI 10.1109/83.535848
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Nosratinia A, 2003, IEEE SIGNAL PROC LET, V10, P296, DOI 10.1109/LSP.2003.817179
   Oguz SH, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P628, DOI 10.1109/MMSP.1998.739051
   Park SH, 1999, IEEE T IMAGE PROCESS, V8, P1361, DOI 10.1109/83.791962
   Rhee I, 2000, IEEE T CIRC SYST VID, V10, P42, DOI 10.1109/76.825857
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   Shen MY, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P480, DOI 10.1109/MMSP.1998.738998
   SULLIVAN GJ, 1994, IEEE T IMAGE PROCESS, V3, P327, DOI 10.1109/83.287030
   Szeliski R, 1996, IEEE T PATTERN ANAL, V18, P1199, DOI 10.1109/34.546257
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
   Zou JJ, 2005, IEEE T CIRC SYST VID, V15, P430, DOI [10.1109/TCSVT.2004.842610, 10.1109/TCVST.2004.842610]
NR 28
TC 23
Z9 28
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 595
EP 607
DI 10.1016/j.jvcir.2009.06.004
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400009
DA 2024-07-18
ER

PT J
AU Ababneh, S
   Ansari, R
   Khokhar, A
AF Ababneh, Sufyan
   Ansari, Rashid
   Khokhar, Ashfaq
TI Iterative compensation schemes for multimedia content authentication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Authentication; Convex sets; POCS; Watermarking; Compensated signature
   embedding; Image integrity; Multimedia authentication; Signature
   embedding
ID WATERMARKING
AB Multimedia content authentication can be achieved by deriving a fragile content-based signature from a media signal and embedding it robustly back into the signal. The perturbation due to embedding needs to be compensated with mechanisms that lead to producing the original signature. Closed form solutions for compensation are not always feasible. In this paper, we propose two iterative compensation schemes to address such scenarios. The first is based on a set-theoretic approach by using projections onto convex sets (POCS), where signature generation and signal fidelity are modeled as convex constraint sets. The other scheme uses an additive iterative approach used in the cases where the POCS approach is not applicable. Examples of successful image authentication are presented to demonstrate the effectiveness of the proposed schemes over a range of watermark-embedding robustness. A comparison with the closed-form compensation scheme, when feasible, is also presented. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Ababneh, Sufyan; Ansari, Rashid; Khokhar, Ashfaq] Univ Illinois, Dept Elect & Comp Engn, Chicago, IL 60607 USA.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital
RP Ababneh, S (corresponding author), Univ Illinois, Dept Elect & Comp Engn, 851 S Morgan St, Chicago, IL 60607 USA.
EM ababneh@acm.org; ansari@ece.uic.edu; ashfaq@uic.edu
CR ABABNEH S, 2008, IEEE INT C AC SPEECH
   ABABNEH S, 2008, P SPIE
   Ababneh S, 2007, IEEE IMAGE PROC, P393
   Altun O, 2006, IEEE T INF FOREN SEC, V1, P479, DOI 10.1109/TIFS.2006.885018
   [Anonymous], IEEE 6 INT S MULT SO
   Bhattacharjee S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P435, DOI 10.1109/ICIP.1998.723518
   Celik MU, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P502, DOI 10.1109/ICIP.2001.958538
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chu YP, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 1, P726, DOI 10.1109/IMSCCS.2006.112
   COMBETTES PL, 1993, P IEEE, V81, P182, DOI 10.1109/5.214546
   Cox I. J., 2002, Digital Watermarking
   Hasan YMY, 2004, Proceedings of the Fourth IEEE International Symposium on Signal Processing and Information Technology, P530, DOI 10.1109/ISSPIT.2004.1434408
   LIN CY, 2000, P SPIE, V3971
   Lin PL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P963, DOI 10.1109/ICME.2004.1394362
   Liu HM, 2005, IEEE INT SYMP CIRC S, P4014
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Painter T, 2000, P IEEE, V88, P451, DOI 10.1109/5.842996
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Stark Henry, 1998, WILEY S TEL
   Thangavel P, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1755, DOI 10.1109/ISIE.2007.4374871
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
   Watson A. B., 1993, DIGITAL IMAGES HUMAN
   Wolfgang RaymondB., 1999, Perceptual Watermarks for Digital Images and Video, P40
   Youla D C, 1982, IEEE Trans Med Imaging, V1, P81, DOI 10.1109/TMI.1982.4307555
NR 25
TC 16
Z9 16
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2009
VL 20
IS 5
BP 303
EP 311
DI 10.1016/j.jvcir.2009.03.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 547LX
UT WOS:000273891500001
DA 2024-07-18
ER

PT J
AU Zhuang, YT
   Lu, WM
   Wu, JQ
AF Zhuang, Yueting
   Lu, Weiming
   Wu, Jiangqin
TI Latent Style Model: Discovering writing styles for calligraphy works
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Latent Style Model; Calligraphic style; Style representation; Style
   similarity; Calligraphic style browser
AB Chinese calligraphy works is a valuable part of the Chinese culture heritage. More and more calligraphy works images are digitized, preserved and exhibited in digital library. Users always want to appreciate the style-similar works simultaneously. To satisfy their need, calligraphic style representation and browsing calligraphy works by its style are the most important problems to be addressed. This paper proposes calligraphic style representation which is a multinomial probability distribution over visual words, and Latent Style Model to discover the style of calligraphy works and organize the works by style. In our experiments, we evaluated various factors that influence the model, and proved the effectiveness of the style representation and the model. At last, we illustrate the Calligraphic Style Browser to organize and exhibit the resource according to the styles. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Zhuang, Yueting; Lu, Weiming; Wu, Jiangqin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Lu, WM (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310003, Zhejiang, Peoples R China.
EM yzhuang@cs.zju.edu.cn; luwm@cs.zju.edu.cn; wujq@cs.zju.edu.cn
FU National Natural Science Foundation of China [60533090, 60525108,
   60773176]; Key Technology RD Program [2006BAH02A13-4, 2007BAH11B01];
   Program for Changjiang Scholars and Innovative Research Team in
   University [IRT0652]; China-US Million Book Digital Library Project
FX This work is supported by National Natural Science Foundation of China
   (Nos. 60533090, 60525108, and 60773176), Key Technology R&D Program
   (2006BAH02A13-4 and 2007BAH11B01), Program for Changjiang Scholars and
   Innovative Research Team in University (IRT0652 and PCSIRT) and China-US
   Million Book Digital Library Project (www.cadal.zju.edu.cn).
CR ANDRZEJEWSKI D, 2007, P 18 EUR C MACH LEAR
   [Anonymous], 1999, CLAIMING PLACE P 15
   BHATTACHARYA I, 2006, 6 SIAM C DAT MIN SIA
   Blei D.M., 2004, ADV NEURAL INFORM PR
   Blei David M, 2007, ANN APPL STAT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Boyd-Graber J, 2007, P 2007 JOINT C EMP M
   BROOK S, 2008, P 7 WSEAS INT C ART
   CHEMUDUGUNTA C, 2006, ADV NEURAL INFORM PR, V19
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Gazzah S, 2007, PROC INT CONF DOC, P1133
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   He J., 2002, INFORM RETRIEVAL CLU
   JAIN V, 2007, INT C COMP VIS ICCV
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Liu D, 2007, IEEE I CONF COMP VIS, P191
   McCallum A., 2004, AUTHOR RECIPIENT TOP
   MIKOLAJCZYK K, 2006, P IEEE CVPR NEW YORK
   NEWMAN D, 2007, JCDL 07, P366
   Romeo-Pakker K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P874, DOI 10.1109/ICDAR.1995.602040
   SAM TS, 2006, INT C PATT REC ICPR2
   SIVIC J, 2005, AIM2005005 MIT AI LA
   Steyvers M., 2004, P 2004 ACM SIGKDD IN, DOI [DOI 10.1145/1014052.1014087, 10.1145/1014052, DOI 10.1145/1014052]
   WICK M, 2007, P 9 INT C DOC AN REC
   Wu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2073, DOI 10.1109/ICME.2006.262642
   Xu SH, 2005, IEEE INTELL SYST, V20, P32, DOI 10.1109/MIS.2005.41
   XU SH, 2007, P 22 AAAI C ART INT
   YOSEF IB, 2004, P DIAL, V23, P299
   Zhai C., 2001, Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR'01, P334, DOI DOI 10.1145/383952.384019
   Zhang XF, 2007, LECT NOTES COMPUT SC, V4351, P354
   ZHUANG YT, 2005, P 4 INT C WEB BAS LE, P186
NR 32
TC 21
Z9 24
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 84
EP 96
DI 10.1016/j.jvcir.2008.11.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA 414JD
UT WOS:000263858800003
DA 2024-07-18
ER

PT J
AU Jung, B
   Jeon, B
AF Jung, Bongsoo
   Jeon, Byeungwoo
TI Adaptive slice-level parallelism for H.264/AVC encoding using pre
   macroblock mode selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Parallelism; Parallel processing; Thread-level parallelism; Slice-level
   parallelism; H.264/AVC; Fast inter mode selection; Fast mode decision;
   Selective intra coding
ID MOTION ESTIMATION; IMPLEMENTATION; MPEG-4
AB In order to achieve high computational performance and low power consumption, many modern microprocessors are equipped with special multimedia instructions and multi-core processing capabilities. The number of cores on a single chip increases double every three years. Therefore, besides complexity reduction by smart algorithms such as fast macroblock mode selection, an effective algorithm for parallelizing H.264/AVC is also very crucial in implementing a real-time encoder on a multi-core system. This algorithm serves to uniformly distribute workloads for H.264/AVC encoding over several slower and simpler processor cores on a single chip. In this paper, we propose a new adaptive slice-size selection technique for efficient slice-level parallelism of H.264/AVC encoding on a multi-core processor using fast macroblock mode selection as a pre-processing step. For this we propose an estimation method for the computational complexity of each macroblock using pre macroblock mode selection. Simulation results, with a number of test video sequences, show that, without any noticeable degradation, the proposed fast macroblock mode selection reduces the total encoding time by about 57.30%. The proposed adaptive slice-level parallelism has good parallel performance compared to conventional fixed slice-size parallelism. The proposed method can be applied to many multi-core systems for real-time H.264 video encoding. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Jung, Bongsoo; Jeon, Byeungwoo] Sungkyunkwan Univ, Dept Elect & Elect Engn, Suwon 440746, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Jeon, B (corresponding author), Sungkyunkwan Univ, Dept Elect & Elect Engn, 300 Chunchun Dong, Suwon 440746, South Korea.
EM bjeon@skku.edu
RI Jeon, Byeungwoo/AAS-1096-2021
OI Jeon, Byeungwoo/0000-0002-5650-2881
FU Korea Science and Engineering Foundation (KOSEF) NRL Program; Korea
   government (MEST) [ROA-2006-000-10826-0(2008)]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) NRL Program grant funded by the Korea government (MEST)
   (ROA-2006-000-10826-0(2008)).
CR Ahmad I, 2002, PARALLEL COMPUT, V28, P1039, DOI 10.1016/S0167-8191(02)00100-X
   Bilas A, 1997, IPPS PROC, P197, DOI 10.1109/IPPS.1997.580889
   Bjontegaard G., 2001, Document VCEG-M33
   Chen MJ, 2006, IEEE T MULTIMEDIA, V8, P478, DOI 10.1109/TMM.2006.870739
   Chen YK, 2006, J VIS COMMUN IMAGE R, V17, P509, DOI 10.1016/j.jvcir.2005.05.004
   CHEN Z, 2003, JVTGO16
   Choi I, 2006, IEEE T CIRC SYST VID, V16, P1557, DOI 10.1109/TCSVT.2006.883506
   Fernández JC, 2002, LECT NOTES COMPUT SC, V2400, P830
   *ITU T, 2003, JVTG050R1
   IWATA E, 1998, CSLTR98771 STANF U C
   Jacobs TR, 2006, IEEE T CONSUM ELECTR, V52, P269
   JEON B, 2003, JVTJO03 ISOIEC
   JUNG B, 2007, IEEE TENCON 2007 200, V10, P1
   Kim H, 2004, IEEE IMAGE PROC, P765
   Liang YF, 2005, IEEE T CIRC SYST VID, V15, P1594, DOI 10.1109/TCSVT.2005.856909
   MEENDERINCK CH, 2008, P 1 WORKSH PROGR ISS
   Roitzsch M., 2007, EMSOFT '07, P269
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   YIN P, 2003, IEEE INT C IM PROC I
   Zhang N, 1997, IEEE T IND ELECTRON, V44, P726, DOI 10.1109/41.633481
NR 20
TC 22
Z9 30
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 558
EP 572
DI 10.1016/j.jvcir.2008.09.004
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300009
DA 2024-07-18
ER

PT J
AU Roitzsch, M
   Pohlack, M
AF Roitzsch, Michael
   Pohlack, Martin
TI Video quality and system resources: Scheduling two opponents
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Real-time; Video decoding; Adaptation; H.264; MPEG; Prediction; Decoding
   time prediction; Visual quality; Error propagation
AB In this article we present three key ideas which together form a flexible framework for maximizing user-perceived quality under given resources with modern video codecs (H.264). First, we present a method to predict resource usage for video decoding online. For this, we develop and discuss a video decoder model using key metadata from the video stream. Second, we explain a light-weight method for providing replacement content for a given region of a frame. We use this method for online adaptation. Third, we select a metric modeled after human image perception which we extend to quantify the consequences of available online adaptation decisions. Together, these three parts allow us, to the best of our knowledge for the first time, to maximize user-perceived quality in video playback under given resource constraints. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Roitzsch, Michael; Pohlack, Martin] Tech Univ Dresden, Fak Informat, D-01062 Dresden, Germany.
C3 Technische Universitat Dresden
RP Roitzsch, M (corresponding author), Tech Univ Dresden, Fak Informat, D-01062 Dresden, Germany.
EM mroi@os.inf.tu-dresden.de
OI Roitzsch, Michael/0000-0002-2416-6537
FU European Commission [FP6]
FX This work was partially funded by the European Commission through the
   ROBIN FP6 project. Further thanks go to the anonymous reviewers for
   their comments.
CR AFINKEL R, 1974, ACTA INFORM, V4, P1
   [Anonymous], FFmpeg Project
   [Anonymous], 2010, JM REFERENCE SOFTWAR
   *APPL INC, QUICK TIM HD GALL SY
   Calvin JM, 2003, OPER RES LETT, V31, P202, DOI 10.1016/S0167-6377(02)00222-5
   Girod Bernd, 1993, P207
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   *IEEE T CIRC SYST, 2003, CONT BAS AD BIN ARIT
   *ISO IEC, 2005, 1449610 ISOIEC 10
   *ISO IEC, 2000, 138182 ISOIEC 2
   *ISO IEC, 1993, 111722 ISOIEC 2
   *ISO IEC, 2004, 144962 ISOIEC 2
   ISOVIT D, 2004, P 16 EUR C REAL TIM
   LEE SW, 2007, P IEEE INT C IM PROC, V5, P313
   RIETZSCHEL C, 2003, VERNER VIDEO ENKODE
   ROITZSCH M, 2005, PRINCIPLES PREDICT 2
   ROITZSCH M, 2006, P 27 IEEE REAL TIM S
   ROITZSCH M, 2006, THESIS
   SCHWARZ H, 2005, IEEE INT C MULT EXP
   Schwarz H, 2006, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2006.312374
   STOR J, 1980, INTRO NUMERICAL ANAL
   van der Schaar M, 2005, IEEE T MULTIMEDIA, V7, P471, DOI 10.1109/TMM.2005.846790
   VATOLIN D, 2006, CS MSU GRAPHICS  JAN
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WUST CC, 2005, P 15 EUR C REAL TIM
   YONG W, 2006, P IEEE INT C AC SPEE
   ZHOU W, 2004, VIDEO QUALITY ASSESS, P121
   BBC MOTION GALLERY R
   FASTVDO TEST VIDEOS
   PEAK SIGNAL NOISE RA
   HIGH DEFINITION TEST
NR 32
TC 4
Z9 4
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 473
EP 488
DI 10.1016/j.jvcir.2008.09.007
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, Y
   Feng, J
   Lo, KT
   Zhang, XD
AF Chen, Yu
   Feng, Jian
   Lo, Kwok Tung
   Zhang, Xudong
TI Content analysis based smart macroblock rearrangement for error
   resilience in wireless video transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilience; content analysis; resynchronization mark; error
   protection; wireless video transmission
ID H.264/AVC VIDEO
AB Transmission of compressed video is very sensitive to channel error. The use of resynchronization marks is an efficient method in improving the error resilient performance of a video stream in error-prone environment. In this paper, a smart macroblock rearrangement (SMR) method is proposed to enhance the performance of the resynchronization mark insertion technique for intracoded frames in wireless video transmission. The proposed method makes use of content analysis to rearrange and encode macroblocks between adjacent resynchronization marks. Experiments using the SMR method in both H.263+ and H.264 codecs show that the proposed method outperforms some existing algorithms in both PSNR performance and visual quality. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Chen, Yu; Lo, Kwok Tung] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
   [Chen, Yu; Zhang, Xudong] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Feng, Jian] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University; Tsinghua University; Hong Kong Baptist
   University
RP Lo, KT (corresponding author), Hong Kong Polytech Univ, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
EM enktlo@inet.polyu.edu.hk
RI zhang, xiaoyu/HJI-4374-2023; zhang, xian/JAC-5480-2023; zhang,
   xu/GYE-3558-2022; zhang, xiaofei/JCD-9045-2023; Wang, Jin/GYA-2019-2022;
   Zhang, xiaoyu/GXA-3206-2022; Lo, Kwok Tung KT/O-2143-2013; zhang,
   xian/GYA-0290-2022; zhang, xiaofei/HJA-9117-2022; zhang,
   xu/GRX-9733-2022
FU Hong Kong Baptist University [FRG/06-07/11-06]
FX The work of Kwok-Tung Lo was supported by the Hong Kong Polytechnic
   University under Grant A/C G-YE93. The work of Jian Feng was supported
   by the Hong Kong Baptist University under Grant No. FRG/06-07/11-06.
CR Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chen Y, 2006, IEICE T COMMUN, VE89B, P633, DOI 10.1093/ietcom/e89-b.2.633
   Etoh M, 2005, P IEEE, V93, P111, DOI 10.1109/JPROC.2004.839605
   Gao SS, 2003, IEEE T CIRC SYST VID, V13, P182, DOI 10.1109/TCSVT.2002.808434
   GAO SS, 2003, P IEEE ICCT 2003 SEP, V2, P1133
   *ISO IEC, 2001, JTC1SC29WG11 ISOIEC
   Kang LW, 2005, J VIS COMMUN IMAGE R, V16, P93, DOI 10.1016/j.jvcir.2004.04.003
   Katsaggelos AK, 2005, P IEEE, V93, P135, DOI 10.1109/JPROC.2004.839621
   Stockhammer T, 2005, IEEE WIREL COMMUN, V12, P6, DOI 10.1109/MWC.2005.1497853
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   TANG F, 2005, IEEE T MULTIMEDIA, V7, P1021
   Vetro A, 2005, IEEE WIREL COMMUN, V12, P14, DOI 10.1109/MWC.2005.1497854
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yoo KY, 1998, ELECTRON LETT, V34, P2084, DOI 10.1049/el:19981458
   Zeng WJ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P113
NR 16
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2008
VL 19
IS 6
BP 343
EP 354
DI 10.1016/j.jvcir.2008.06.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 343KS
UT WOS:000258853100001
DA 2024-07-18
ER

PT J
AU Kesidis, AL
   Papamarkos, N
AF Kesidis, A. L.
   Papamarkos, N.
TI Exact image reconstruction from a limited number of projections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image reconstruction; algebraic reconstruction; inverse problems; image
   projections; Radon transform; accumulator array; Fourier slice; back
   projection
ID INVERSE HOUGH TRANSFORM; RADON-TRANSFORM; TOMOGRAPHY
AB A new method for the exact reconstruction of any gray-scale image from its projections is proposed. The original image is projected into several view angles and the projection samples are stored in an accumulator array. In order to reconstruct the image, the accumulator array is considered as an accumulation of sinusoidal contributions each one corresponding to a certain pixel of the original image. The proposed method defines conditions for the necessary number of projections and the density of ray samples on the projection axis. These conditions insure that, for each pixel, there is at least one sample in the accumulator array where only this particular pixel contributes. This characteristic projection sample is used during the reconstruction phase to determine the coordinates and the gray-scale value of the corresponding image pixel. A variation of the method is also proposed where the reconstruction is performed using a limited number of projection samples in certain view angles. Specifically, the number of necessary samples equals at most the overall number of pixels in the original image. This approach leads to a significant reduction of memory and processing time requirements since it provides exact image reconstruction using one projection sample per pixel. (c) 2008 Elsevier Inc. All rights reserved.
C1 [Papamarkos, N.] Democritus Univ Thrace, Dept Elect & Comp Engn, Image Proc & Multimedia Lab, GR-67100 Xanthi, Greece.
   [Kesidis, A. L.] Natl Ctr Sci Res Demokritos, Inst Informat & Telecommun, Athens, Greece.
C3 Democritus University of Thrace; National Centre of Scientific Research
   "Demokritos"
RP Papamarkos, N (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Image Proc & Multimedia Lab, GR-67100 Xanthi, Greece.
EM papamark@ee.duth.gr
RI Kesidis, Anastasios/ABF-9609-2021
OI Kesidis, Anastasios/0000-0002-8912-7352
CR DEANS SR, 1981, IEEE T PATTERN ANAL, V3, P185, DOI 10.1109/TPAMI.1981.4767076
   GORDON R, 1974, IEEE T NUCL SCI, V21, P21
   HERMAN GT, 1991, IEEE T MED IMAGING, V10, P336, DOI 10.1109/42.97583
   Jain A., 1989, Fundamental of digital image processing
   Kak A.C. Slaney M., 1999, PRINCIPLES COMPUTERI
   Kesidis AL, 2000, IMAGE VISION COMPUT, V18, P607, DOI 10.1016/S0262-8856(99)00067-0
   Kesidis AL, 1999, IEEE T PATTERN ANAL, V21, P1329, DOI 10.1109/34.817411
   Liang Z., 2000, IEEE PRESS SERIES BI
   LLACER J, 1985, IEEE T NUCL SCI, V32, P855, DOI 10.1109/TNS.1985.4336955
   LUDWIG D, 1966, COMMUN PUR APPL MATH, V19, P49
   MERSEREAU RM, 1974, P IEEE, V62, P1319, DOI 10.1109/PROC.1974.9625
   MURTY KG, 1976, LINEAR COMBINATORIAL
   OLLINGER J, 1997, IEEE SIGNAL PROC MAG, P43
   Perantonis SJ, 1999, PATTERN RECOGN, V32, P811, DOI 10.1016/S0031-3203(98)00125-3
   Sezan M, 1984, IEEE Trans Med Imaging, V3, P91, DOI 10.1109/TMI.1984.4307661
   SHEPP LA, 1974, IEEE T NUCL SCI, V21, P185
   SWINDELL W, 1977, PHYS TODAY, V30, P32, DOI 10.1063/1.3037825
   WOLSEY L, 1989, MATH PROGRAM, V45, P173, DOI 10.1007/BF01589102
NR 18
TC 6
Z9 6
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2008
VL 19
IS 5
BP 285
EP 298
DI 10.1016/j.jvcir.2008.03.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 318LO
UT WOS:000257093400001
DA 2024-07-18
ER

PT J
AU Chen, YY
   Chang, YW
   Yen, WC
AF Chen, Yen-Yu
   Chang, Ying-Wen
   Yen, Wen-Chien
TI Design a deblocking filter with three separate modes in DCT-based coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE blocking effects; HVS; deblocking filter; image compression;
   post-processing; DCT; perceptual quality; objective quality; PSNR; SSIM
ID BLOCKING ARTIFACTS; CODED IMAGES; REDUCTION; COMPRESSION
AB The reconstructed images from highly compressed data have noticeable image degradations, such as blocking artifacts near the block boundaries. Post-processing appears to be the most feasible solution because it does not require any existing standards to be changed. Markedly reducing blocking effects can increase compression ratios for a particular image quality or improve the quality of equally compressed images. In this work, a novel deblocking algorithm is proposed based on three filtering modes in terms of the activity across block boundaries. By properly considering the masking effect of the HVS (Human Visual System), an adaptive filtering decision is integrated into the deblocking process. According to three different deblocking modes appropriate for local regions with different characteristics, the perceptual and objective quality are improved without excessive smoothing the image details or insufficiently reducing the strong blocking effect on a flat region. According to the simulation results, the proposed method outperforms other deblocking algorithms in respect to PSNR (Peak Signal-to-Noise Ratio) and SSIM (Structural SIMilarity). (c) 2008 Elsevier Inc. All rights reserved.
C1 [Chen, Yen-Yu; Chang, Ying-Wen; Yen, Wen-Chien] ChungChou Inst Technol, Dept Informat Management, Yuanlin, Changhwa, Taiwan.
RP Chen, YY (corresponding author), ChungChou Inst Technol, Dept Informat Management, 6,Lane 2,Sect 3,Shan Chiao Rd, Yuanlin, Changhwa, Taiwan.
EM miscyy@tcts1.seed.net.tw
CR HSU YF, 1993, IEEE T CONSUM ELECTR, V2, P91
   JARSKE T, 1994, IEEE T CONSUM ELECTR, V39, P510
   Jeong Y, 2000, IEEE T CIRC SYST VID, V10, P617, DOI 10.1109/76.845007
   Le Gall D. J., 1992, Signal Processing: Image Communication, V4, P129, DOI 10.1016/0923-5965(92)90019-C
   Lee YL, 1998, IEEE T IMAGE PROCESS, V7, P229, DOI 10.1109/83.661000
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   LIU TS, 1995, IEEE T IMAGE PROCESS, V4, P1032, DOI 10.1109/83.392346
   Luo JB, 1996, IEEE T IMAGE PROCESS, V5, P1363, DOI 10.1109/83.535848
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   *MPEG VID GROUP, 1997, ISOIECJTC1SC29WG11
   OROURKE TP, 1995, IEEE T CIRCUITS SYST, V5, P298
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   SINGH S, 2002, IEEE SIGNAL PROCESS, V9, P81
   Triantafyllidis GA, 2002, IEEE T CIRC SYST VID, V12, P877, DOI 10.1109/TCSVT.2002.804880
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang YY, 1997, IEEE T IMAGE PROCESS, V6, P1345, DOI 10.1109/83.624945
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zeng B, 1999, SIGNAL PROCESS, V79, P205, DOI 10.1016/S0165-1684(99)00094-8
NR 18
TC 11
Z9 15
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2008
VL 19
IS 4
BP 231
EP 244
DI 10.1016/j.jvcir.2008.02.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 311MK
UT WOS:000256604100002
DA 2024-07-18
ER

PT J
AU Muñoz-Salinas, R
   García-Silvente, M
   Carnicer, RM
AF Munoz-Salinas, Rafael
   Garcia-Silvente, Miguel
   Carnicer, Rafael Medina
TI Adaptive multi-modal stereo people tracking without background modelling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE people tracking; stereo vision; particle filtering; real-time imaging;
   confidence measure; colour processing
ID INTEGRATED PERSON TRACKING; COLOR
AB Detecting and tracking persons in the sequences of monocular images are the important and difficult problems in computer vision and have been well studied in these two decades. Recently, the methods based on stereo vision have attracted great attentions since 3D information can be exploited. This paper presents an approach for multiple-people detection and tracking using stereo vision. Tracking is carried out using a multiple particle filtering approach that combines depth, colour and gradient information. We modify the degree of confidence assigned to depth information, according to the amount of it found in the disparity map, using a novel confidence measure. The greater the amount of disparity information found, the higher the degree of confidence assigned to depth information in the final particles weights is. In the worst case (total absence of disparity), the proposed algorithm makes use of the information available (colour and gradient) to track, thus performing as a pure colour-based tracking algorithm. People are detected combining an adaboost classifier with stereo information. In order to test the validity of our proposal, it is evaluated in several sequences of colour and disparity images where people interact in complex situations: walk at different distances, shake hands, cross their paths, jump, run, embrace each other and even swap their positions quickly trying to confuse the system. The experimental results show that the proposal is able to deal with occlusions and to effectively determine both the 3D position of the people being tracked and their 2D head locations in the camera image, and everything is realized in real time. Besides, as the proposed method does not require the use of a background model, it can be considered particularly appropriate for applications that must run on mobile devices. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Munoz-Salinas, Rafael; Carnicer, Rafael Medina] Univ Granada, Dept Comp Sci & Numerical Anal, Cordoba 14071, Spain.
   [Garcia-Silvente, Miguel] Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.
C3 University of Granada; University of Granada
RP Muñoz-Salinas, R (corresponding author), Univ Granada, Dept Comp Sci & Numerical Anal, Cordoba 14071, Spain.
EM rmsalinas@uco.es; Silvente@decsai.ugr.es; rmedina@uco.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Garcia-Silvente, Miguel/C-2409-2012;
   Medina-Carnicer, Rafael/G-3401-2015
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Garcia-Silvente,
   Miguel/0000-0002-5467-6159; Medina-Carnicer, Rafael/0000-0003-4481-0614
CR Aherne F., 1997, KYBERNETIKA, V32, P1
   [Anonymous], OPENCV OP SOURC COMP
   Argyros AA, 2004, APPL OPTICS, V43, P366, DOI 10.1364/AO.43.000366
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   BAUMBERG A, 1994, IEEE WORKSH MOT NONR, P194
   BEYMER D, 1999, P INT C COMP VIS
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   Böhme HJ, 2003, ROBOT AUTON SYST, V44, P83, DOI 10.1016/S0921-8890(03)00012-5
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   CIPOLLA R, 1990, IMAGE VISION COMPUT, V8, P85, DOI 10.1016/0262-8856(90)90061-9
   Colombo C, 2003, IEEE T SYST MAN CY B, V33, P677, DOI 10.1109/TSMCB.2003.814281
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Darrell T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P628, DOI 10.1109/ICCV.2001.937685
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   Du W, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P165
   Eklundh Janolof., 1996, BMVC, P1
   Foley J.D., 1982, Fundamentals of interactive computer graphics
   FRANKLIN D, 1996, INT C AUT FAC GEST R, P14
   Fritsch J, 2003, ROBOT AUTON SYST, V43, P133, DOI 10.1016/S0921-8890(02)00355-X
   Ghidary SS, 2000, IEEE SYS MAN CYBERN, P1360, DOI 10.1109/ICSMC.2000.886043
   GORDON N, 1995, J GUID CONTROL DYNAM, V18, P1434, DOI 10.2514/3.21565
   Grest D, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P387
   Haritaoglu I, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P175, DOI 10.1109/MOTION.2002.1182231
   Harville M, 2004, PROC CVPR IEEE, P398
   Harville M, 2004, IMAGE VISION COMPUT, V22, P127, DOI 10.1016/j.imavis.2003.07.009
   Hayashi K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P681, DOI 10.1109/AFGR.2004.1301613
   Hirai N, 2003, IEEE ASME INT C ADV, P527, DOI 10.1109/AIM.2003.1225150
   Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1996, ECCV, P343
   Kahn RE, 1996, PROC CVPR IEEE, P734, DOI 10.1109/CVPR.1996.517154
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Kwolek B, 2002, ROMOCO'02: PROCEEDINGS OF THE THIRD INTERNATIONAL WORKSHOP ON ROBOT MOTION AND CONTROL, P375, DOI 10.1109/ROMOCO.2002.1177135
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Malis E, 1999, IEEE T ROBOTIC AUTOM, V15, P238, DOI 10.1109/70.760345
   Martinkauppi B, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P652, DOI 10.1109/ICIAP.2003.1234124
   Menser B, 2000, CONF REC ASILOMAR C, P49, DOI 10.1109/ACSSC.2000.910916
   MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708
   Moreno F, 2002, INT C PATT RECOG, P368, DOI 10.1109/ICPR.2002.1044727
   Muñoz-Salinas R, 2007, IMAGE VISION COMPUT, V25, P995, DOI 10.1016/j.imavis.2006.07.012
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   PATIL R, 2004, IEEE RSJ INT C INT R, P1323
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P467, DOI 10.1109/34.55106
   SAITO H, 2002, 41 SICE ANN C SICE 2, V5, P2721
   SALINAS RM, 2005, LNCS, V3789, P337
   SALINAS RM, 2005, 2 INT C MACH INT ACI, P574
   SCHLEGEL C, 1998, 9 BRIT MACH VIS C BM, V1, P418
   SHAPIRO LG, OBJECT CONCEPT RECOG
   Sidenbladh H, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P670, DOI 10.1109/ROBOT.1999.770052
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Snidaro L, 2005, IEEE T SYST MAN CY A, V35, P133, DOI 10.1109/TSMCA.2004.838478
   Vermaak J, 2005, IEEE T AERO ELEC SYS, V41, P309, DOI 10.1109/TAES.2005.1413764
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   VIEUX WE, 1999, INT C COMP VIS SYST, P151
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wilhelm T, 2004, ROBOT AUTON SYST, V48, P31, DOI 10.1016/j.robot.2004.05.004
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151
NR 63
TC 19
Z9 23
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2008
VL 19
IS 2
BP 75
EP 91
DI 10.1016/j.jvcir.2007.07.004
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 264MD
UT WOS:000253290600001
DA 2024-07-18
ER

PT J
AU Kiderlen, M
AF Kiderlen, Markus
TI Estimating the Euler Characteristic of a planar set from a digital image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Euler characteristic; digital morphology; convex ring; digitized image;
   multigrid convergence; Betti number
ID NUMBER
AB A new estimator (approximation) for the Euler-Poincare characteristic of a planar set K in the extended convex ring is suggested. As input, it uses only the digital image of K, which is modeled as the set of all points of a regular lattice falling in K. The key idea is to estimate the two planar Betti numbers of K (number of connected components and number of holes) by approximating K and its complement by polygonal sets derived from the digitization. In contrast to earlier methods, only certain connected components of these approximations are counted. The estimator of the Euler characteristic is then defined as the difference of the estimators for the two Betti numbers. Under rather weak regularity assumptions oil K, it is shown that all three estimators yield the correct result, whenever the resolution of the image is sufficiently high. (C) 2006 Elsevier Inc. All rights reserved.
C1 Univ Aarhus, Dept Math Sci, DK-8000 Aarhus C, Denmark.
C3 Aarhus University
RP Kiderlen, M (corresponding author), Univ Aarhus, Dept Math Sci, DK-8000 Aarhus C, Denmark.
EM kiderlen@imf.au.dk
RI Kiderlen, Markus/ITW-0301-2023
OI Kiderlen, Markus/0000-0003-2858-6659
CR [Anonymous], 1994, Morphological Image Operators
   BIERI H, 1984, COMPUT VISION GRAPH, V28, P166, DOI 10.1016/S0734-189X(84)80019-5
   BOYCE RW, 1995, BONE, V16, P637, DOI 10.1016/8756-3282(95)00116-U
   DYER CR, 1980, COMPUT VISION GRAPH, V13, P270, DOI 10.1016/0146-664X(80)90050-7
   Hadwiger H., 1957, Vorlesungen ueber Inhalt, Oberflache und Isoperimetrie, Die Grundlehren der mathematischen Wissenschaften
   KIDERLEN M, 2006, UNPUB ESTIMATION SPE
   Klette R., 2004, DIGITAL GEOMETRY
   LEE CN, 1991, CVGIP-GRAPH MODEL IM, V53, P522, DOI 10.1016/1049-9652(91)90003-3
   LEVITZ PE, 2002, HDB POROUS SOLIDS, V1, P37
   Mecke KR, 1996, J PHYS-CONDENS MAT, V8, P9663, DOI 10.1088/0953-8984/8/47/080
   Michielsen K, 2002, ADV IMAG ELECT PHYS, V125, P119
   MOLCHANOV IS, 1996, STAT BOOLEAN MODEL P
   Ohser J, 1996, J MICROSC-OXFORD, V184, P117
   Ohser J, 2002, LECT NOTES PHYS, V600, P275
   Ohser J., 2003, IMAGE ANAL STEREOL, V22, P11
   Ohser J., 2000, Statistical Analysis of Microstructures in Materials Science
   ROSENFEL.A, 1966, J ACM, V13, P471
   ROSENFELD A, 1979, DIGITAL PICTURE PROC
   Russ J.C., 1999, IMAGE PROCESSING HDB, V3rd, DOI DOI 10.1201/9780203881095
   SCHNEIDER R, 1993, CONVEX BODIES BRUNNM
   Schneider R., 2000, Stochastische Geometrie
   Serra J., 1982, IMAGE ANAL MATH MORP
   VOSS K, 1992, ALGORITHMS COMBINATO, V11
   West D.B., 2001, INTRO GRAPH THEORY
NR 24
TC 17
Z9 17
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1237
EP 1255
DI 10.1016/j.jvcir.2006.05.001
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cai, JF
   He, ZH
   Chen, CW
AF Cai, Jianfei
   He, Zhihai
   Chen, Chang Wen
TI A novel frame-level bit allocation based on two-pass video encoding for
   low bit rate video streaming applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Image Processing
CY SEP 22-25, 2002
CL ROCHESTER, NY
SP IEEE Signal Proc Soc
DE bit allocation; rate control; rate-distortion function; frame dropping;
   offline video coding
AB Current rate control schemes in video coding standards do not have efficient frame-level bit allocation due to the limitation of real-time encoding. In this paper, by taking advantage of offline video encoding, we proposed a frame-level bit allocation scheme based on a latest developed rate-distortion (R-D) model, the rho-domain R-D model [IEEE Trans. Circuits Syst. Video Technol. (2001) 928], for low bit rate streaming applications. Specifically, at the encoder, we code each video sequence twice. In the first pass, we generate the R-D information of video sequences. Then, in the second pass, according to the available channel bandwidth, by exploiting the pre-generated R-D information we are able to implement frame-level bit allocation in an optimal way so that video sequences can be coded at low bit rate with an improved quality. We apply the proposed bit allocation scheme for both offline video coding and rate-reduction transcoding. Experimental results demonstrate the proposed scheme is able to achieve not only reduced average distortion but also much smoother visual quality. (C) 2004 Elsevier Inc. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   Univ Missouri, Dept Elect Engn, Columbia, MO 65211 USA.
   Florida Inst Technol, Dept Elect & Comp Engn, Melbourne, FL 32901 USA.
C3 Nanyang Technological University; University of Missouri System;
   University of Missouri Columbia; Florida Institute of Technology
RP Cai, JF (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave,BLK N4, Singapore 639798, Singapore.
EM asjfcai@ntu.edu.sg; HeZhi@missouri.edu; cchen@fit.edu
RI He, Zhihai/A-5885-2019; Cai, Jianfei/A-3691-2011
OI Cai, Jianfei/0000-0002-9444-3763
CR Barth R., 2001, IEEE T CIRCUITS SYST
   Chen JJ, 1997, IEEE J SEL AREA COMM, V15, P1002, DOI 10.1109/49.611155
   CHENG P, 1997, IEEE T CIRCUITS SYST, P696
   CHIANG T, 1997, IEEE T CIRCUITS SYST, P246
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   Hamdi M, 1997, IEEE J SEL AREA COMM, V15, P1040, DOI 10.1109/49.611158
   *ISO IEC DIS, 1994, 13818 ISOIEC DIS
   *ISO IEC JTC, 1999, 1SC29WG11 ISOIEC JTC
   Lakshman TV, 1998, P IEEE, V86, P952, DOI 10.1109/5.664282
   LAKSHMAN TV, 1992, IEEE T CIRCUITS SYST, P361
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Lin L.-J., 1995, P IEEE ICIP 1995 OCT, P392
   PAO IM, 2001, IEEE T CIRCUITS SYST, P199
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P533, DOI 10.1109/83.334987
   Ribas-Corbera J, 2000, IEEE T CIRC SYST VID, V10, P1154, DOI 10.1109/76.875518
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Song HJ, 2001, IEEE T CIRC SYST VID, V11, P512, DOI 10.1109/76.915357
   Wang Q, 2002, IEEE SIGNAL PROC LET, V9, P33, DOI 10.1109/97.991132
   WEI D, 1997, IEEE T CIRCUITS SYST, P266
   YUE Y, 2001, IEEE T CIRCUITS  MAR, P345
   Zhang XM, 2003, IEEE T CIRC SYST VID, V13, P121, DOI 10.1109/TCSVT.2002.808437
NR 21
TC 8
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 783
EP 798
DI 10.1016/j.jvcir.2004.11.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 105JZ
UT WOS:000242027500007
DA 2024-07-18
ER

PT J
AU Lambert, P
   De Neve, W
   Dhondt, Y
   Van De Walle, R
AF Lambert, P.
   De Neve, W.
   Dhondt, Y.
   Van de Walle, R.
TI Flexible macroblock ordering in H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; FMO; error resilience; video coding
AB H.264/AVC is a new standard for digital video compression jointly developed by ITU-T's Video Coding Experts Group (VCEG) and ISO/IEC's Moving Picture Experts Group (MPEG). Besides the numerous tools for efficient video coding, the H.264/AVC specification defines some new error resilience tools. One of them is flexible macroblock ordering (FMO) which is the main focus of this paper. An in-depth overview is given of the internals of FMO. Experiments are presented that demonstrate the benefits of FMO as an error resilience tool in case of packet loss over IP networks. The flexibility of FMO comes with a certain overhead or cost. A quantitative assessment of this cost is presented for a number of scenarios. FMO can, besides for pure error resilience, also be used for other purposes. This is also addressed in this paper. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Ghent, IBBT, Multimedia Lab, Dept Elect & Informat Syst, B-9000 Ghent, Belgium.
C3 Ghent University
RP Lambert, P (corresponding author), Univ Ghent, IBBT, Multimedia Lab, Dept Elect & Informat Syst, Sint Pietersnieuwstr 41, B-9000 Ghent, Belgium.
EM peter.lambert@ugent.be
RI De Neve, Wesley Marcel/C-6480-2008; Lambert, Peter/D-7776-2016
OI De Neve, Wesley Marcel/0000-0002-8190-3839; Lambert,
   Peter/0000-0001-5313-4158
CR DUYSBURGH B, 2004, THESIS GHENT U
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   Perkins C, 1998, IEEE NETWORK, V12, P40, DOI 10.1109/65.730750
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   VANHASTEL S, 1999, 7 IFIP ATM IP WORKSH
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   WENGER S, 2002, INT WORKSH DIG COMM
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 8
TC 76
Z9 102
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 358
EP 375
DI 10.1016/j.jvcir.2005.05.008
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000010
OA Green Published
DA 2024-07-18
ER

PT J
AU Fahmy, GF
   Panchanathan, S
AF Fahmy, GF
   Panchanathan, S
TI A lifting based system for compression and classification trade off in
   the JPEG2000 framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
AB In this paper, we propose a design for a novel lifting based wavelet system that achieves the best trade off between compression and classification performances. The proposed system is based on bi-orthogonal filters and can operate in a scalable compression framework. In the proposed system, the trade off point between compression and classification is determined by the system, however, the user can also fine-tune the relative performance using two controllers (one for compression and one for classification). Extensive simulations have been performed to demonstrate the compression and/or classification performance of our system in the context of the recent image compression standard, namely JPEG2000. Our simulation results show that the lifting based kernels, generated from the proposed system, are capable of achieving superior compression performance compared to the default kernels adopted in the JPEG2000 standard (at a classification rate of 70%). The generated kernels can also achieve a comparable compression quality with the JPEG2000 kernels whilst providing a 99% classification performance. In other words, the proposed lifting based system achieves the best trade off between compression and classification performance at the compressed bit-stream level in the wavelet domain. (C) 2003 Elsevier Inc. All rights reserved.
C1 Arizona State Univ, Dept Comp Sci & Engn, Visual Comp & Commun Lab, Res Ctr Ubiquitous Comp, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Fahmy, GF (corresponding author), Arizona State Univ, Dept Comp Sci & Engn, Visual Comp & Commun Lab, Res Ctr Ubiquitous Comp, Tempe, AZ 85287 USA.
EM fahmy@asu.edu; panch@asu.edu
CR ANOTONINI M, 1992, IEEE T IMAGE PROCESS, V1
   Baras JS, 1999, IEEE T INFORM THEORY, V45, P1911, DOI 10.1109/18.782112
   BHALOD J, 2001, MULTIRESOLUTION AUTO
   Bhalod J., 2001, JOINT COMPRESSION IN
   BHALOD J, 2000, THESIS ARIZONA STATE
   BHALOD J, 2000, INDEXING SPATIAL CON
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   COHEN A, 1992, COMM PURE APPLMATH
   FAHMY GF, 2002, ICASSP ORL FL
   FAHMY GF, 2002, INT S CIRC SYST ISCA
   FAHMY M, 2001, DESIGN BIORTHOGONAL
   Goswami J.C., 1999, WILEY MICRO
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   *ISO IEC JTC 1SC 2, 2000, JPEG2000 VER MOD 8 5
   *ISO IEC JTC1 SC29, 2000, N3445 ISOIEC JTC1SC2
   *ISO IEC JTC1 SC29, 1998, N2502 ISOIEC JTC1SC2
   LI J, 1999, JOINT IMAGE COMPRESS
   Liang KC, 1999, IEEE T IMAGE PROCESS, V8, P1619, DOI 10.1109/83.799889
   LIU CP, 2000, IMAGE INDEXING JPEG
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mandal MK, 1997, P SOC PHOTO-OPT INS, V3022, P380, DOI 10.1117/12.263426
   MANDAL MK, 1998, THESIS U OTTAWA
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   PERMUTTER K, 1996, IEEE T IMAGE PROCESS, V5
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE DAT COMPR C SNO, P214
   SRINIVASAMURTHY N, 2001, SPIE VCIP
   SWELDENS W, 1995, P SOC PHOTO-OPT INS, V2569, P68, DOI 10.1117/12.217619
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P572, DOI 10.1109/83.334984
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Vetterli Martin, 1995, Wavelets and Subband Coding
NR 32
TC 0
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 145
EP 162
DI 10.1016/j.jvcir.2003.07.002
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800003
DA 2024-07-18
ER

PT J
AU Chen, LH
   Su, CW
   Liao, HYM
   Shih, CC
AF Chen, LH
   Su, CW
   Liao, HYM
   Shih, CC
TI On the preview of digital movies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video content analysis; video segmentation; movie trailer
AB In this paper, a new technique is proposed for the automatic generation of a preview sequence of a feature film. The input video is decomposed into a number of basic components called shots. In this step, the proposed shot change detection algorithm is able to detect both the abrupt and gradual transition boundary. Then, shots are grouped into semantic-related scenes by taking into account the visual characteristics and temporal dynamics of video. Finally, by making use of an empirically motivated approach, the intense-interaction and action scenes are extracted to form the abstracting video. Compared with related works which integrate visual and audio information, our visual-based approach is computationally simple yet effective. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   Natl Cent Univ, Inst Comp Sci & Informat Engn, Chungli, Taiwan.
   Acad Sinica, Inst Informat Sci, Taipei, Taiwan.
C3 Fu Jen Catholic University; National Central University; Academia Sinica
   - Taiwan
RP Fu Jen Catholic Univ, Dept Comp Sci & Informat Engn, Hsinchuang, Taipei, Taiwan.
EM lchen@csie.fju.edu.tw
RI Liao, Hong-Yuan Mark/AAQ-5514-2021
CR [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   CHRISTEL MG, 1998, ACM CHI 98 LOS ANG C, P171
   DEMENTHON D, 1998, ACM INT C MULT, P212
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Gong YH, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1559, DOI 10.1109/ICME.2000.871066
   Hanjalic A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P710, DOI 10.1109/MMCS.1999.778571
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   JAIN AK, 1988, ALGORITHMS CLUSTERTI
   NAM J, 1999, IEEE 3 WORKSH MULT S, P117
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   SWANBERG D, 1993, SPIE C STOR RETR IM, P173
   TOKLU C, 2000, INT C MULT EXP NEW Y, P1333
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
NR 19
TC 8
Z9 12
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 358
EP 368
DI 10.1016/S1047-3203(03)00036-1
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200008
DA 2024-07-18
ER

PT J
AU Stone, HS
   Tao, B
   McGuire, M
AF Stone, HS
   Tao, B
   McGuire, M
TI Analysis of image registration noise due to rotationally dependent
   aliasing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE aliasing; image searching; image registration; Fourier transform; scale
   invariance; translation invariance; rotation invariance
ID SUBPIXEL REGISTRATION; ALGORITHM; TRANSFORMS
AB This paper investigates factors that degrade the precision of image registration based on phase correlation. The major sources of error are interpolation error and rotationally dependent aliasing. The latter error stems from the fact that the discrete-Fourier transform does not commute with the rotation of sampled-images, whereas in the continuous domain the corresponding operations do commute. We show through a series of examples how much the various sources of error contribute to phase-correlation registration, and we demonstrate constructive techniques for improving precision and signal to noise ratio in the registration process. Since rotationally dependent aliasing is exacerbated by the presence of high frequencies, the examples demonstrate that the use of a Blackman window removes spurious high frequencies in the spectral leakage created by the image boundary and greatly reduces aliasing effects. Since remaining aliasing effects are strongest in the low frequencies of the Fourier transform, their effects can be reduced to a negligible amount by removing frequencies within a radius of N/4 of the Fourier domain origin. A third technique is to perform phase correlation over half the Fourier plane rather than over the full plane, which more than doubles the signal-to-noise ratio of phase correlation. For an example image, the combination of techniques improved the phase-correlation signal-to-noise ratio from 8.5 to 172 and raised the peak from 0.348 to 0.885, which are substantially higher values than previously reported. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 NEC Res Inst, Princeton, NJ 08540 USA.
   Streaming21, Los Gatos, CA 95032 USA.
   Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
C3 NEC Corporation; Brown University
RP Stone, HS (corresponding author), NEC Res Inst, 4 Independence Way, Princeton, NJ 08540 USA.
CR Alliney S, 1996, PATTERN RECOGN, V29, P131, DOI 10.1016/0031-3203(95)00070-4
   ALLINEY S, 1986, IEEE T PATTERN ANAL, V8, P222, DOI 10.1109/TPAMI.1986.4767775
   [Anonymous], 1997, 7 CENTURY LAW PROTEC
   [Anonymous], 1975, PROC INT C CYBERN SO
   Bracewell R.N., 1956, Australian Journal of Physics, V9, P297
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Chang SH, 1997, PATTERN RECOGN, V30, P311, DOI 10.1016/S0031-3203(96)00076-3
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Dasgupta B, 1996, J I EL TELECOM ENG, V42, P3
   DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966
   HARRIS FJ, 1978, P IEEE, V66, P1
   LUCCHESE L, 1997, P ISCAS, V2, P1181
   Oppenheim A. V., 1975, Digital signal processing
   PAPADIMITRIOU DV, 1994, ELECTRON LETT, V30, P1475, DOI 10.1049/el:19941001
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Stone HS, 2001, IEEE T GEOSCI REMOTE, V39, P2235, DOI 10.1109/36.957286
   Thevenaz P, 1998, IEEE T IMAGE PROCESS, V7, P27, DOI 10.1109/83.650848
   WU M, 1999, 1999 ICASP MARCH, V4, P2065
NR 18
TC 43
Z9 58
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2003
VL 14
IS 2
BP 114
EP 135
DI 10.1016/S1047-3203(03)00002-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 680AJ
UT WOS:000182953900003
DA 2024-07-18
ER

PT J
AU Yang, XH
   Gou, TK
   Lv, ZY
   Li, LD
   Jin, HY
AF Yang, Xiuhong
   Gou, Tiankun
   Lv, Zhiyong
   Li, Leida
   Jin, Haiyan
TI Weakly-supervised cloud detection and effective cloud removal for remote
   sensing images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cloud detection; Cloud removal; Markov discriminator; Priority-driven
   reconstruction loss
ID NETWORK
AB We propose a one-stop automatic cloud processing scheme for RSI, including weakly supervised cloud detection and effective cloud removal. First, to avoid using massive expensive paired-labeled data, we use the idea of adversarial training to detect clouds, that is, randomly selecting some unpaired cloud and cloudless images to alternatively train a spectral-normalized Markov discriminator to obtain cloud masks. Second, a two-stage downsampling-restoring-upsampling-refining scheme is used to remove detected clouds. In order to further improve the rationality and fineness, we construct a fractional-order anisotropic filter kernel and design a convolution process to impose spatial regularization constraints on the loss construction at each stage, taking to account confidence values and structural priorities. Comprehensive experimental results show that our proposed networks are superior to the SOTA methods in terms of objective indicators and subjective performance. In addition, the performance of our one-stop approach in automatically detecting and eliminating clouds is also very satisfactory.
C1 [Yang, Xiuhong; Gou, Tiankun; Lv, Zhiyong; Jin, Haiyan] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Yang, Xiuhong; Lv, Zhiyong; Jin, Haiyan] Xian Univ Technol, Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Shaanxi, Peoples R China.
   [Li, Leida] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Xi'an University of Technology; Xidian
   University
RP Yang, XH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.; Yang, XH (corresponding author), Xian Univ Technol, Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Shaanxi, Peoples R China.
RI Lv, ZhiYong/J-4055-2019
FU Applied Technology Research and Development Project of Beilin District
   in 2021 [GX2104]; National Natural Science Foundation of China
   [61801380]
FX Applied Technology Research and Development Project of Beilin District
   in 2021: GX2104, National Natural Science Foundation of China: 61801380.
CR Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Ding Y, 2021, IEEE J-STARS, V14, P4561, DOI 10.1109/JSTARS.2021.3074469
   Eryilmaz Zubeyr Furkan, 2019, Image completion using patch-match algorithm
   FUKUSHIMA K, 1983, IEEE T SYST MAN CYB, V13, P826, DOI 10.1109/TSMC.1983.6313076
   Guo JH, 2021, IEEE T GEOSCI REMOTE, V59, P700, DOI 10.1109/TGRS.2020.2991398
   Hong DF, 2020, ISPRS J PHOTOGRAMM, V167, P12, DOI 10.1016/j.isprsjprs.2020.06.014
   Ji TY, 2018, IEEE T GEOSCI REMOTE, V56, P3047, DOI 10.1109/TGRS.2018.2790262
   Kuznetsov A., 2020, 8th international symposium on digital forensics and security, ISDFS 2020, P1, DOI [10.1109/ISDFS49300.2020.9116347, DOI 10.1109/ISDFS49300.2020.9116347]
   Lata Kusam, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P186, DOI 10.1109/ICECA.2019.8822195
   Li HA, 2022, J CIRCUIT SYST COMP, V31, DOI 10.1142/S0218126622502097
   Li J, 2022, REMOTE SENS ENVIRON, V280, DOI 10.1016/j.rse.2022.113197
   Li W., 2011 INT WORKSH MULT, P1, DOI [10.1109/M2RSM.2011.5697419, DOI 10.1109/M2RSM.2011.5697419]
   Li YS, 2020, REMOTE SENS ENVIRON, V250, DOI 10.1016/j.rse.2020.112045
   Liu D, 2022, LECT NOTES COMPUT SC, V13435, P485, DOI 10.1007/978-3-031-16443-9_47
   [刘紫涵 Liu Zihan], 2017, [国土资源遥感, Remote Sensing for Land & Resources], V29, P6
   Lou SL, 2018, IAPR WORKS PATTERN
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Miyato T, 2018, INT C LEARN REPR
   Mohajerani S, 2021, IEEE J-STARS, V14, P4254, DOI 10.1109/JSTARS.2021.3070786
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ng MKP, 2017, IEEE T GEOSCI REMOTE, V55, P3367, DOI 10.1109/TGRS.2017.2670021
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Parvaz R., 2021, arXiv
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao MW, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3021116
   Xu T, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103430
   Xu Y., 2020, IEEE Trans. Neural Networks Learning Syst.
   Yang XH, 2022, IET IMAGE PROCESS, V16, P3684, DOI 10.1049/ipr2.12585
   Yi Z., 2020, C COMP VIS PATT REC, DOI [10.1109/CVPR42600.2020.00753[P], DOI 10.1109/CVPR42600.2020.00753[P]]
   Yi ZL, 2020, Arxiv, DOI arXiv:2005.09704
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang J, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3105424
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou ZC, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3072618
NR 39
TC 1
Z9 1
U1 11
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104006
DI 10.1016/j.jvcir.2023.104006
EA DEC 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EG4X7
UT WOS:001137767200001
DA 2024-07-18
ER

PT J
AU Liu, SC
   Fan, QC
   Li, SQ
   Zhao, CJ
AF Liu, Sicong
   Fan, Qingcheng
   Li, Shuqin
   Zhao, Chunjiang
TI MAPoseNet: Animal pose estimation network via multi-scale convolutional
   attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Animal pose estimation; Attention mechanism; Asymmetric convolution;
   Feature pyramid
ID IDENTIFICATION
AB Animal pose estimation serves as an upstream task for recognizing and understanding animal behavior. Over the last year, the accuracy of the deep learning-based method has steadily improved, but at the expense of the model's inference speed. This paper uses an efficient and powerful model to improve inference speed and accuracy. The classic encoder-decoder architecture is chosen. For estimating animal pose, our model based on a feature pyramid and a multi-scale asymmetric convolution attention mechanism is developed and named MAPoseNet (Animal Pose Estimation Network Via Multi-scale Convolutional Attention). MAPoseNet consists of an encoder and a decoder. Rather than typical self-attention, the encoder's attention mechanism comprises multi-scale, asymmetric convolutions that are lightweight and instrumental in improving inference speed. A feature pyramid and a feature balance module make up the decoder. The public dataset AP-10K is used to train and test MAPoseNet. A series of experimental results demonstrate that the MAPoseNet model provides cutting-edge performance. MAPoseNet outperforms HRFormer by 1.3 AP and 0.8 AR, with 33.7% fewer FLOPs and 66% faster inference speed. And our model surpasses HRNet and HRFormer on the Animal Pose dataset as well. Our model has achieved a win-win situation regarding inference speed and accuracy.
C1 [Liu, Sicong; Fan, Qingcheng; Li, Shuqin; Zhao, Chunjiang] Northwest A&F Univ, Coll Informat Engn, 3 Taicheng Rd, Yangling 712100, Peoples R China.
   [Zhao, Chunjiang] Beijing Acad Agr & Forestry Sci, Res Ctr Informat Technol, Beijing 100097, Peoples R China.
C3 Northwest A&F University - China; Beijing Academy of Agriculture &
   Forestry Sciences (BAAFS)
RP Zhao, CJ (corresponding author), Northwest A&F Univ, Coll Informat Engn, 3 Taicheng Rd, Yangling 712100, Peoples R China.; Zhao, CJ (corresponding author), Beijing Acad Agr & Forestry Sci, Res Ctr Informat Technol, Beijing 100097, Peoples R China.
EM liusicong@nwafu.edu.cn; fanqingcheng@nwafu.edu.cn;
   liusicong@nwafu.edu.cn; zhaocj@nercita.org.cn
CR Cao JK, 2019, Arxiv, DOI arXiv:1908.05806
   Cheng Ming-Ming, 2022, On the connection between local attention and dynamic depth-wise convolution, V25, P25
   Cordonnier JB, 2020, Arxiv, DOI arXiv:1911.03584
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Fang C, 2021, COMPUT ELECTRON AGR, V180, DOI 10.1016/j.compag.2020.105863
   Gan HM, 2021, COMPUT ELECTRON AGR, V188, DOI 10.1016/j.compag.2021.106357
   Guo MH, 2022, Arxiv, DOI [arXiv:2209.08575, DOI 10.48550/ARXIV.2209.08575, 10.48550/arXiv.2209.08575]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JJ, 2020, Arxiv, DOI arXiv:1911.07524
   Jiang-Jiang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10093, DOI 10.1109/CVPR42600.2020.01011
   Labuguen R, 2021, FRONT BEHAV NEUROSCI, V14, DOI 10.3389/fnbeh.2020.581154
   Lauer J, 2022, NAT METHODS, V19, P496, DOI 10.1038/s41592-022-01443-0
   Li SY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2590, DOI 10.1145/3394171.3413569
   Li XY, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104885
   Lin TY, 2017, Arxiv, DOI [arXiv:1612.03144, DOI 10.48550/ARXIV.1612.03144]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105761
   Mathis A, 2021, IEEE WINT CONF APPL, P1858, DOI 10.1109/WACV48630.2021.00190
   Nasiri A, 2022, COMPUT ELECTRON AGR, V197, DOI 10.1016/j.compag.2022.106931
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pang JM, 2019, Arxiv, DOI arXiv:1904.02701
   Pereira TD, 2019, NAT METHODS, V16, P117, DOI 10.1038/s41592-018-0234-5
   Shooter M, 2021, Arxiv, DOI arXiv:2108.00249
   Szegedy C, 2015, Arxiv, DOI arXiv:1512.00567
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wen CL, 2015, BIOSYST ENG, V136, P117, DOI 10.1016/j.biosystemseng.2015.06.002
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xie EZ, 2021, ADV NEUR IN, V34
   Xu LM, 2021, Arxiv, DOI arXiv:2105.10154
   Ng XL, 2022, PROC CVPR IEEE, P19001, DOI 10.1109/CVPR52688.2022.01844
   Yang YX, 2022, Arxiv, DOI arXiv:2206.05683
   Yu Hang, 2021, arXiv
   Yuan Yuhui, 2021, NEURIPS 2021
NR 34
TC 0
Z9 0
U1 6
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103989
DI 10.1016/j.jvcir.2023.103989
EA NOV 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CV1P7
UT WOS:001127923400001
DA 2024-07-18
ER

PT J
AU Chang, CC
   Liu, JC
   Gao, K
AF Chang, Chin-Chen
   Liu, Jui-Chuan
   Gao, Kai
TI Cryptanalysis of iterative encryption and image sharing scheme based on
   the VQ attack
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Cryptanalysis; Vector quantization; CNN;
   Security
ID PERMUTATION
AB Reversible data hiding in encrypted images (RDHEI) is widely employed to protect privacy in images stored on cloud storage. Recently, Yu et al. [22] proposed an effective image encryption scheme called iterative encryption and image sharing (IEIS), which is highly compatible with RDHEI. In this study, we analyze the characteristics of IEIS and present a cryptanalysis scheme based on vector quantization (VQ) attack. To capture the pixel-changing pattern of an image block, the concept of pixel difference matrix (PDM) is introduced. VQ attack is subsequently utilized to estimate the ciphertext block. Furthermore, we employ a well-trained convolutional neural network (CNN) based discriminator to identify the proper block permutation sequence within the secret key space. Experimental results demonstrate the efficacy of our proposed cryptanalysis scheme. Based on our study, we conclude that the IEIS scheme raises security concerns.
C1 [Chang, Chin-Chen; Liu, Jui-Chuan; Gao, Kai] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
C3 Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
EM alan3c@gmail.com; p1200318@o365.fcu.edu.tw; kaigao.phd@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Gao K, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103481
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kingma D. P., 2014, arXiv
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Liu ZL, 2022, IEEE T DEPEND SECURE, V19, P1382, DOI 10.1109/TDSC.2020.3011838
   National Institute of Standards and Technology, 1979, FIPS-46: Data Encryption Standard (DES)
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Qu LF, 2022, IEEE T MULTIMEDIA, V24, P2924, DOI 10.1109/TMM.2021.3090588
   Qu LF, 2020, MULTIMED TOOLS APPL, V79, P29451, DOI 10.1007/s11042-020-09379-3
   Wang Y.M., 1288, IEEE Trans. Multimedia, V24
   Wang YM, 2021, IEEE T MULTIMEDIA, V23, P1466, DOI 10.1109/TMM.2020.2999187
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Yu C.Q., 2023, IEEE Trans. Circuits Syst. Video Technol
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 29
TC 0
Z9 0
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103973
DI 10.1016/j.jvcir.2023.103973
EA NOV 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IG2L7
UT WOS:001165110300001
DA 2024-07-18
ER

PT J
AU Song, D
   Ling, YT
   Li, TB
   Wang, T
   Li, XY
AF Song, Dan
   Ling, Yuting
   Li, Tianbao
   Wang, Teng
   Li, Xuanya
TI Hierarchical deep semantic alignment for cross-domain 3D model retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D model retrieval; Unsupervised domain adaptation; Representation
   learning
ID CONVOLUTIONAL NEURAL-NETWORK; SHAPE; VIEW
AB With the development of deep learning and the widespread application of 3D modeling technology, image -based cross-domain 3D model retrieval has attracted more and more researchers' attention. Existing methods have achieved success by aligning the feature distributions from different domains. However, previous methods just statistically align the domain-level or class-level feature distributions, leaving sample discriminability a margin to be improved for retrieval. To address this issue, this paper proposes a Hierarchical Deep Semantic Alignment Network (HDSAN) for cross-domain 3D model retrieval, which combines the proposed sample -level semantic enhancement with global domain alignment and class semantic alignment. Concretely, we adopt adversarial domain adaptation at the domain level and dynamically align the class centers of two domains at the class level. To further improve sample discriminability, we design intra-domain and cross -domain triplet center alignment to enhance the semantic representation ability at the sample level. Experiments on two commonly-used cross-domain 3D model retrieval datasets MI3DOR-1 and MI3DOR-2 demonstrate the effectiveness of the proposed method.
C1 [Song, Dan; Ling, Yuting] Tianjin Univ, Tianjin Int Engn Inst, Tianjin, Peoples R China.
   [Song, Dan; Li, Tianbao; Wang, Teng] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
   [Li, Xuanya] Baidu Inc, Beijing, Peoples R China.
C3 Tianjin University; Tianjin University; Baidu
RP Li, TB (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM litianbao@tju.edu.cn
FU National Nature Science Foundation of China [61902277]; China
   Postdoctoral Science Foun-dation [2021T140511, 2020M680884]; Baidu
   Program
FX Acknowledgments This work was supported in part by the National Nature
   Science Foundation of China (61902277) , the China Postdoctoral Science
   Foun-dation (2021T140511, 2020M680884) and the Baidu Program.
CR Biasotti S, 2016, VISUAL COMPUT, V32, P217, DOI 10.1007/s00371-015-1146-3
   Biasotti Silvia, 2017, EUROGRAPHICS
   Chen CQ, 2019, PROC CVPR IEEE, P627, DOI 10.1109/CVPR.2019.00072
   Chen F, 2019, J VIS COMMUN IMAGE R, V58, P261, DOI 10.1016/j.jvcir.2018.11.046
   Chen H, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3362065
   Dai GX, 2018, IEEE T IMAGE PROCESS, V27, P3374, DOI 10.1109/TIP.2018.2817042
   Dai WD, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102925
   Dominguez M, 2021, INT C PATT RECOG, P7439, DOI 10.1109/ICPR48806.2021.9413220
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Ganin Y., 2015, ICML
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Han ZZ, 2019, AAAI CONF ARTIF INTE, P126
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Hu N, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103426
   Husnain M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010107
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Jiao SC, 2020, IEEE ACCESS, V8, P121584, DOI 10.1109/ACCESS.2020.3006585
   Le TN, 2019, PATTERN RECOGN LETT, V125, P249, DOI 10.1016/j.patrec.2019.04.025
   Li B, 2021, MULTIMED TOOLS APPL, V80, P9569, DOI 10.1007/s11042-020-10033-1
   Liang J, 2019, IEEE T PATTERN ANAL, V41, P1027, DOI 10.1109/TPAMI.2018.2832198
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2018, ADV NEUR IN, V31
   Nie WZ, 2022, IEEE T CIRC SYST VID, V32, P992, DOI 10.1109/TCSVT.2021.3070969
   Paszke A, 2019, ADV NEUR IN, V32
   Rodola Emanuele, 2017, EUROGRAPHICS
   Rozantsev A, 2019, IEEE T PATTERN ANAL, V41, P801, DOI 10.1109/TPAMI.2018.2814042
   Savva M., 2017, P WORKSH 3D OBJ RETR, P39, DOI DOI 10.2312/3DOR.20171050
   Sedaghat Nima, 2017, BRIT MACHINE VISION
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Song D, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104482
   Song D, 2022, IEEE T CYBERNETICS, V52, P8114, DOI 10.1109/TCYB.2021.3051016
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun SL, 2021, IEEE ACCESS, V9, P3451, DOI 10.1109/ACCESS.2020.3047820
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Xu C, 2019, IEEE I CONF COMP VIS, P3731, DOI 10.1109/ICCV.2019.00383
   Xu Y, 2021, IEEE T IMAGE PROCESS, V30, P5299, DOI 10.1109/TIP.2021.3082310
   Yang HR, 2022, MULTIMEDIA SYST, V28, P761, DOI 10.1007/s00530-021-00871-w
   You HX, 2019, AAAI CONF ARTIF INTE, P9119
   Yuan YM, 2020, PATTERN RECOGN LETT, V136, P251, DOI 10.1016/j.patrec.2020.06.007
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhang K., 2019, arXiv
   Zhao SC, 2021, INT J COMPUT VISION, V129, P2399, DOI 10.1007/s11263-021-01479-3
   Zhou HY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P925, DOI 10.1145/3394171.3413631
   Zhou HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1667, DOI 10.1145/3343031.3351011
   Zhu J, 2019, PATTERN RECOGN LETT, V119, P24, DOI 10.1016/j.patrec.2017.09.041
NR 48
TC 0
Z9 0
U1 4
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103895
DI 10.1016/j.jvcir.2023.103895
EA JUL 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P1RU5
UT WOS:001048491900001
DA 2024-07-18
ER

PT J
AU Xiang, XZ
   Zhang, KX
   Qiao, YL
   El Saddik, A
AF Xiang, Xuezhi
   Zhang, Kaixu
   Qiao, Yulong
   El Saddik, Abdulmotaleb
TI EMHIFormer: An Enhanced Multi-Hypothesis Interaction Transformer for 3D
   human estimation in video✩
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D human pose estimation; Transformer; Cross-hypothesis; Enhanced
   regression head
AB Monocular 3D human pose estimation is a challenging task because of depth ambiguity and occlusion. Recent methods exploit spatio-temporal information and generate different hypotheses for simulating diverse solutions to alleviate these problems. However, these methods do not fully extract spatial and temporal information and the relationship of each hypothesis. To ease these limitations, we propose EMHIFormer (Enhanced Multi-Hypothesis Interaction Transformer) to model 3D human pose with better performance. In detail, we build connections between different Transformer layers so that our model is able to integrate spatio-temporal information from the previous layer and establish more comprehensive hypotheses. Furthermore, a cross-hypothesis model consisting of a parallel Transformer is proposed to strengthen the relationship between various hypotheses. We also design an enhanced regression head which adaptively adjusts the channel weights to export the final 3D human pose. Extensive experiments are conducted on two challenging datasets: Human3.6M and MPI-INF-3DHP to evaluate our EMHIFormer. The results show that EMHIFormer achieves competitive performance on Human3.6M and state-of-the-art performance on MPI-INF-3DHP. Compared with the closest counterpart, MHFormer, our model outperforms it by 0.6% P-MPJPE and 0.5% MPJPE on Human3.6M dataset and 46.0% MPJPE on MPI-INF-3DHP.
C1 [Xiang, Xuezhi; Zhang, Kaixu; Qiao, Yulong] Harbin Engn Univ, Sch Informat & Commun Engn, Harbin 150001, Peoples R China.
   [Xiang, Xuezhi; Qiao, Yulong] Minist Ind & Informat Technol, Key Lab Adv Marine Commun & Informat Technol, Harbin 150001, Peoples R China.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.
C3 Harbin Engineering University; University of Ottawa
RP Xiang, XZ (corresponding author), Harbin Engn Univ, Sch Informat & Commun Engn, Harbin 150001, Peoples R China.
EM xiangxuezhi@hrbeu.edu.cn
FU National Natural Science Foundation of China [62271160, 61871-442];
   Natural Science Foundation of Heilongjiang Province of China
   [LH2021F011]; Fundamental Research Funds for the Central Universities of
   China [3072022TS0801]; Chinese Association for Artificial Intelligence
   (CAAI) Huawei MindSpore Open Fund; Key Laboratory of Advanced Marine
   Communication and Information Technology Open Fund [AMCIT2103-03]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62271160 and 61871-442, in part by the
   Natural Science Foundation of Heilongjiang Province of China under Grant
   LH2021F011, in part by the Fundamental Research Funds for the Central
   Universities of China under Grant 3072022TS0801, in part by Chinese
   Association for Artificial Intelligence (CAAI) Huawei MindSpore Open
   Fund, in part by the Key Laboratory of Advanced Marine Communication and
   Information Technology Open Fund under Grant AMCIT2103-03
CR Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   [Anonymous], 2011, Wireless Communications and Signal Processing (WCSP), 2011 International Conference on
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen TL, 2022, IEEE T CIRC SYST VID, V32, P198, DOI 10.1109/TCSVT.2021.3057267
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Gong KH, 2021, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR46437.2021.00847
   Guo CX, 2013, IEEE INT CONF ROBOT, P2935, DOI 10.1109/ICRA.2013.6630984
   Gyeongsik Moon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P752, DOI 10.1007/978-3-030-58571-6_44
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He RN, 2021, Arxiv, DOI arXiv:2012.11747
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jahangiri E, 2017, IEEE INT CONF COMP V, P805, DOI 10.1109/ICCVW.2017.100
   Jingbo Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P764, DOI 10.1007/978-3-030-58601-0_45
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li C, 2019, PROC CVPR IEEE, P9879, DOI 10.1109/CVPR.2019.01012
   Li SC, 2020, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR42600.2020.00621
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Li WH, 2022, Arxiv, DOI arXiv:2206.06420
   Li WH, 2022, PROC CVPR IEEE, P13137, DOI 10.1109/CVPR52688.2022.01280
   Li Wenhao, 2022, IEEE Trans. Multimed.
   Lin J., 2019, arXiv
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Ma XX, 2021, PROC CVPR IEEE, P6234, DOI 10.1109/CVPR46437.2021.00617
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Opromolla R, 2015, ACTA ASTRONAUT, V110, P287, DOI 10.1016/j.actaastro.2014.11.003
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Sharma S, 2019, IEEE I CONF COMP VIS, P2325, DOI 10.1109/ICCV.2019.00241
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wehrbein T., 2021, ICCV, P11199
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Zeng AL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11416, DOI 10.1109/ICCV48922.2021.01124
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zou Z., 2021, IEEECVF INT C COMPUT, p11 477
NR 49
TC 0
Z9 0
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103890
DI 10.1016/j.jvcir.2023.103890
EA JUL 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O9XS9
UT WOS:001047280600001
DA 2024-07-18
ER

PT J
AU Yang, YJ
   Wang, YF
   Zhang, H
AF Yang, Yingjie
   Wang, Yongfang
   Zhang, Han
TI DRBR-HDR: Dual-Branch recursive band reconstruction network for HDR with
   large motions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inverse tone mapping; Band reconstruction; Global features; High dynamic
   range images
ID DYNAMIC-RANGE; IMAGES
AB Ghosting artifacts due to misaligned imaging and missing content of the moving regions are major challenges of synthesizing high dynamic range (HDR) images from multiple low-dynamic range (LDR) with different exposures in dynamic scenes. Therefore, it hopes the HDR reconstruction model can align the LDRs' features and restore the missing content without artifacts. In the paper, a new dual-branch recursive band reconstruction network for high dynamic range (DRBR-HDR) is proposed to generate credible result in missing content regions, which not only uses global features as supplementary information to help local features from different receptive fields for efficient feature alignment but also designs a series of coarse-to-fine band representation to better repair missing areas in the process of recursion. In addition, we introduce an interactive attention mechanism for local branches to alleviate ghosting artifacts. The experimental results demonstrate that DRBR-HDR achieves state-of-the-art performance compared with that of the prevailing HDR reconstruction methods in various challenging scenes.
C1 [Yang, Yingjie; Wang, Yongfang; Zhang, Han] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wang, Yongfang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Wang, YF (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Wang, YF (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM yfw@shu.edu.cn
RI wang, yingying/JSK-6741-2023; cheng, cheng/JBR-8359-2023; xin,
   liang/JFS-5770-2023; Cheng, Yuan/JKJ-0794-2023
FU Natural Science Foundation of China;  [61671283];  [U2033218]
FX Acknowledgements This work was supported by Natural Science Foundation
   of China under Grant No. 61671283, U2033218.
CR Bogoni L, 2000, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2000.903475
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Deng YP, 2021, INT C PATT RECOG, P8976, DOI 10.1109/ICPR48806.2021.9412973
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   GROSCH T, 2006, VISION MODELING VISU, P277
   Heo YS, 2011, LECT NOTES COMPUT SC, V6495, P486, DOI 10.1007/978-3-642-19282-1_39
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23
   Jinno T, 2008, IEEE IMAGE PROC, P1304, DOI 10.1109/ICIP.2008.4712002
   Kalantari NK, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073609
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Marnerides D, 2018, COMPUT GRAPH FORUM, V37, P37, DOI 10.1111/cgf.13340
   Niu YZ, 2021, IEEE T IMAGE PROCESS, V30, P3885, DOI 10.1109/TIP.2021.3064433
   Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338
   Pece F., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P1, DOI 10.1109/CVMP.2010.8
   Reinhard E., 2010, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Yan QS, 2022, INT J COMPUT VISION, V130, P76, DOI 10.1007/s11263-021-01535-y
   Yan QS, 2020, IEEE T IMAGE PROCESS, V29, P4308, DOI 10.1109/TIP.2020.2971346
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
   Yan QS, 2019, PATTERN RECOGN LETT, V127, P66, DOI 10.1016/j.patrec.2018.10.008
   Yan QS, 2017, NEUROCOMPUTING, V269, P160, DOI 10.1016/j.neucom.2017.03.083
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zimmer H, 2011, COMPUT GRAPH FORUM, V30, P405, DOI 10.1111/j.1467-8659.2011.01870.x
NR 28
TC 1
Z9 1
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103713
DI 10.1016/j.jvcir.2022.103713
EA DEC 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7L0QG
UT WOS:000905680500001
DA 2024-07-18
ER

PT J
AU Lin, J
   Zhang, K
   Yang, X
   Cheng, XZ
   Li, CH
AF Lin, Jian
   Zhang, Kai
   Yang, Xi
   Cheng, Xiangzheng
   Li, Chenhui
TI Infrared dim and small target detection based on U-Transformer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Infrared small and dim target detection; Swin transformer; Anchor free;
   Object detection; Heatmap
ID LOCAL CONTRAST METHOD
AB Infrared dim and small target detection is a key technology for space-based infrared search and tracking systems. Traditional detection methods have a high false alarm rate and fail to handle complex background and high-noise scenarios. Also, the methods cannot effectively detect targets on a small scale. In this paper, a U-Transformer method is proposed, and a transformer is introduced into the infrared dim and small target detection. First, a U-shaped network is constructed. In the encoder part, the self-attention mechanism is used for infrared dim and small target feature extraction, which helps to solve the problems of losing dim and small target features of deep networks. Meanwhile, by using the encoding and decoding structure, infrared dim and small target features are filtered from the complex background while the shallow features and semantic information of the target are retained. Experiments show that anchor-free and transformer have great potential for infrared dim and small target detection. On the datasets with a complex background, our method outperforms the state-of-the-art detectors and meets the real-time requirement. The code is publicly available at https://github.com/Linaom1214/U-Transformer.
C1 [Lin, Jian; Zhang, Kai] Northwestern Polytech Univ, Unmanned Syst Res Inst, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Yang, Xi] Northwestern Polytech Univ, Sch Astronaut, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
   [Cheng, Xiangzheng] Key Lab Optoelect Countermeasures Test & Evaluat T, Luoyang 471003, Henan, Peoples R China.
   [Li, Chenhui] Aviat Ind Corp China, Xian Aeronaut Comp Tech Res Inst, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Aviation Industry Corporation of China (AVIC); Xi'an
   Aeronautical Institute
RP Lin, J (corresponding author), Northwestern Polytech Univ, Unmanned Syst Res Inst, 127 West Youyi Rd, Xian 710072, Shaanxi, Peoples R China.
EM linaom1214@mail.nwpu.edu.cn; singlechip@163.com; NWPUYX@163.com;
   846248088@qq.com; chlee1996@163.com
RI Li, Chenhui/AAR-3682-2020; Lin, Jian/HGA-8876-2022
OI Li, Chenhui/0000-0001-9835-2650; Lin, Jian/0000-0001-8964-8871
FU Key Laboratory of Optoelectronic Countermeasures Test and Evaluation
   Technology Fund;  [GKCP2021002]
FX ?? Supported by the Key Laboratory of Optoelectronic Countermeasures
   Test and Evaluation Technology Fund (GKCP2021002) .
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen J, 2020, INFRARED PHYS TECHN, V111, DOI 10.1016/j.infrared.2020.103516
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Correia AD, 2021, Arxiv, DOI arXiv:2103.16775
   Dai YM, 2021, IEEE T GEOSCI REMOTE, V59, P9813, DOI 10.1109/TGRS.2020.3044958
   Dai YM, 2021, IEEE WINT CONF APPL, P949, DOI 10.1109/WACV48630.2021.00099
   Ding LH, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102949
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Du J., 2021, IET IMAGE PROCESS
   Fan ZL, 2018, NEUROCOMPUTING, V272, P396, DOI 10.1016/j.neucom.2017.07.017
   Gao ZS, 2019, J VIS COMMUN IMAGE R, V62, P206, DOI 10.1016/j.jvcir.2019.05.013
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Han JH, 2020, IEEE GEOSCI REMOTE S, V17, P1822, DOI 10.1109/LGRS.2019.2954578
   Han JH, 2018, IEEE GEOSCI REMOTE S, V15, P612, DOI 10.1109/LGRS.2018.2790909
   Hu JF, 2021, Arxiv, DOI arXiv:2109.02079
   Huang L, 2021, INFRARED PHYS TECHN, V116, DOI 10.1016/j.infrared.2021.103755
   Ju MR, 2021, INFRARED PHYS TECHN, V114, DOI 10.1016/j.infrared.2021.103659
   Lee K, 2024, Arxiv, DOI arXiv:2107.04589
   Li BY, 2022, Arxiv, DOI arXiv:2106.00487
   Li D, 2021, PROC CVPR IEEE, P12316, DOI 10.1109/CVPR46437.2021.01214
   Li J, 2021, INFRARED PHYS TECHN, V117, DOI 10.1016/j.infrared.2021.103768
   Li YS, 2021, INFRARED PHYS TECHN, V115, DOI 10.1016/j.infrared.2021.103657
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, Arxiv, DOI [arXiv:2103.14030, DOI 10.48550/ARXIV.2103.14030]
   Moradi S, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107727
   Qian K, 2021, INFRARED PHYS TECHN, V118, DOI 10.1016/j.infrared.2021.103882
   Redmon A., 2017, P IEEE C COMP VIS PA, P7263, DOI 10.1109/cvpr.2017.690
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2019, IEEE I CONF COMP VIS, P8508, DOI 10.1109/ICCV.2019.00860
   Wei YT, 2016, PATTERN RECOGN, V58, P216, DOI 10.1016/j.patcog.2016.04.002
   Zhang M, 2021, INFRARED PHYS TECHN, V119, DOI 10.1016/j.infrared.2021.103940
   Zhang S, 2019, J VIS COMMUN IMAGE R, V60, P180, DOI 10.1016/j.jvcir.2019.02.018
   Zhang TF, 2021, Arxiv, DOI arXiv:2111.03580
   Zhao B, 2021, IEEE T GEOSCI REMOTE, V59, P4481, DOI 10.1109/TGRS.2020.3012981
   Zhao D, 2020, INFRARED PHYS TECHN, V104, DOI 10.1016/j.infrared.2019.103116
   Zhao MX, 2019, Arxiv, DOI arXiv:2001.05852
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 47
TC 10
Z9 10
U1 23
U2 69
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103684
DI 10.1016/j.jvcir.2022.103684
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600008
DA 2024-07-18
ER

PT J
AU Vishwakarma, AK
   Bhurchandi, KM
AF Vishwakarma, Anish Kumar
   Bhurchandi, Kishor M.
TI No-Reference Video Quality Assessment using novel hybrid features and
   two-stage hybrid regression for score level fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human visual system; No-reference video quality assessment; 3D steerable
   DWT; Perceptual features; User generated content; Support vector
   regression
AB This paper presents a novel No-Reference Video Quality Assessment (NR-VQA) model that utilizes proposed 3D steerable wavelet transform-based Natural Video Statistics (NVS) features as well as human perceptual features. Additionally, we proposed a novel two-stage regression scheme that significantly improves the overall performance of quality estimation. In the first stage, transform-based NVS and human perceptual features are separately passed through the proposed hybrid regression scheme: Support Vector Regression (SVR) followed by Polynomial curve fitting. The two visual quality scores predicted from the first stage are then used as features for the similar second stage. This predicts the final quality scores of distorted videos by achieving score level fusion. Extensive experiments were conducted using five authentic and four synthetic distortion databases. Experimental results demonstrate that the proposed method outperforms other published state-of-the-art benchmark methods on synthetic distortion databases and is among the top performers on authentic distortion databases. The source code is available at https://github.com/anishVNIT/two-stage-vqa.
C1 [Vishwakarma, Anish Kumar; Bhurchandi, Kishor M.] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Vishwakarma, AK (corresponding author), Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur, India.
EM anish.vishwakarma10@gmail.com; bhurchandikm@ece.vnit.ac.in
RI Vishwakarma, Anish Kumar/JXY-3431-2024
OI Vishwakarma, Anish Kumar/0000-0003-4881-3409
CR [Anonymous], 2013, CSIQ VID DAT
   [Anonymous], 2019, CISCO VISUAL NETWORK
   Bonnineau C, 2022, IEEE T BROADCAST, V68, P246, DOI 10.1109/TBC.2022.3140710
   Brunnström K, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053013
   CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574
   Chenouard N, 2012, IEEE T IMAGE PROCESS, V21, P4522, DOI 10.1109/TIP.2012.2206044
   Dendi SVR, 2020, IEEE T IMAGE PROCESS, V29, P5612, DOI 10.1109/TIP.2020.2984879
   Deng J., 2009, IEEE C COMP VIS PATT
   Ebenezer J. P., 2020, IEEE INT WORKSH MULT, P1, DOI [DOI 10.1109/mmsp48831.2020.9287151, 10.1109/MMSP48831.2020.9287151]
   Ghadiyaram D, 2018, IEEE T CIRC SYST VID, V28, P2061, DOI 10.1109/TCSVT.2017.2707479
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Han H, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103296
   Hosu V, 2017, INT WORK QUAL MULTIM
   Jafari-Khouzani K, 2005, IEEE T IMAGE PROCESS, V14, P783, DOI 10.1109/TIP.2005.847302
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P224, DOI 10.1007/978-3-030-01246-5_14
   Korhonen J, 2019, IEEE T IMAGE PROCESS, V28, P5923, DOI 10.1109/TIP.2019.2923051
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Li DQ, 2021, INT J COMPUT VISION, V129, P1238, DOI 10.1007/s11263-020-01408-w
   Li DQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2351, DOI 10.1145/3343031.3351028
   Li XL, 2016, IEEE T IMAGE PROCESS, V25, P3329, DOI 10.1109/TIP.2016.2568752
   Liu WT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P546, DOI 10.1145/3240508.3240643
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nuutinen M, 2016, IEEE T IMAGE PROCESS, V25, P3073, DOI 10.1109/TIP.2016.2562513
   Ögmen H, 2010, P IEEE, V98, P479, DOI 10.1109/JPROC.2009.2039028
   Phenomena, 2022, PHENOMENA GLOBAL INT
   Pimpalkhute VA, 2021, IEEE T IMAGE PROCESS, V30, P1962, DOI 10.1109/TIP.2021.3049961
   Saad MA, 2014, IEEE T IMAGE PROCESS, V23, P1352, DOI 10.1109/TIP.2014.2299154
   Sekuler R., 2002, Perception of visual motion
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sinno Z, 2019, IEEE T IMAGE PROCESS, V28, P612, DOI 10.1109/TIP.2018.2869673
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Tu ZZ, 2021, IEEE T IMAGE PROCESS, V30, P4449, DOI 10.1109/TIP.2021.3072221
   Unser M, 2009, IEEE T IMAGE PROCESS, V18, P2402, DOI 10.1109/TIP.2009.2027628
   Vapnik V., 1999, NATURE STAT LEARNING
   Vishwakarma AK, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167774
   Vranjes M, 2012, ELMAR PROC, P13
   Wang YL, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901772
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   You JY, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103399
   You JY, 2019, IEEE IMAGE PROC, P2349, DOI [10.1109/icip.2019.8803395, 10.1109/ICIP.2019.8803395]
   Zhu KF, 2013, PROC SPIE, V8755, DOI 10.1117/12.2015594
NR 47
TC 1
Z9 1
U1 4
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103676
DI 10.1016/j.jvcir.2022.103676
EA NOV 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600006
DA 2024-07-18
ER

PT J
AU Lin, CY
   Zheng, ZS
   Nie, L
   Liao, K
   Zhao, Y
AF Lin, Chunyu
   Zheng, Zishuo
   Nie, Lang
   Liao, Kang
   Zhao, Yao
TI Bi-projection for 360° image object detection bridged by RoI Searcher?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 360? image; Object detection; Equirectangular; Cubemap
AB Object detection on 360 degrees images is a vital component of 3D environment perception. The existing methods either treat panoramic images (usually represented in equirectangular projection-ERP) as normal FoV images and endure the distortions or project them into the less-distortion format and narrow the FoV, leading to unsatisfactory performance in practical applications. To solve this problem, we propose a dual-projection 360 degrees object detection network named Bip R-CNN, consisting of three modules: a bi-projection feature extractor, a cross-projection region-of-interest (RoI) searcher, and a classification and regression predictor. Specifically, we extract the equirectangular and corresponding dual-cubemap features simultaneously from the input images. Besides, Projection-Inter Feature Fusion and Projection-Intra Feature Fusion are designed to allow the mutual interaction between the bi-projective features and promote the integration of features at different scales, respectively. In the proposed cross-projection RoI Searcher, we search for the bounding box (BBox) locations on cubemap from the corresponding ERP spherical proposals, bridging the RoIs of two different projection formats at feature level. Finally, the cube proposals are used to detect objects in the last predictor module. Considering the scarceness of the existing panoramic dataset (only indoor scenes), we propose an efficient approach to convert conventional datasets into annotated panoramic datasets without manual intervention, increasing the diversity of panoramic datasets. Extensive experiments are conducted on the synthetic and real-world datasets with spherical criteria, demonstrating our superiority to other state-of-the-art solutions.
C1 [Lin, Chunyu; Zheng, Zishuo; Nie, Lang; Liao, Kang; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Lin, CY (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
EM cylin@bjtu.edu.cn
RI Liao, Kang/ADB-6353-2022; Lin, Chunyu/AAI-5185-2021
OI Lin, Chunyu/0000-0003-2847-0349
FU National Natural Science Founda-tion of China;  [62172032]; 
   [62120106009]
FX This work was supported by the National Natural Science Founda-tion of
   China (No. 62172032, No. 62120106009) .
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao M, 2022, Arxiv, DOI arXiv:2202.03176
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chou Shih-Han, 2020, P IEEE CVF WINT C AP, P845
   Coors B, 2018, LECT NOTES COMPUT SC, V11213, P525, DOI 10.1007/978-3-030-01240-3_32
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   de La Garanderie GP, 2018, LECT NOTES COMPUT SC, V11217, P812, DOI 10.1007/978-3-030-01261-8_48
   GREENE N, 1986, IEEE COMPUT GRAPH, V6, P21, DOI 10.1109/MCG.1986.276658
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongkai Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P260, DOI 10.1007/978-3-030-58555-6_16
   Hu HN, 2017, PROC CVPR IEEE, P1396, DOI 10.1109/CVPR.2017.153
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khasanova R, 2017, IEEE INT CONF COMP V, P860, DOI 10.1109/ICCVW.2017.106
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee Y, 2019, PROC CVPR IEEE, P9173, DOI 10.1109/CVPR.2019.00940
   Lin T.-Y., 2014, CoRR, P740
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Cohen TS, 2018, Arxiv, DOI arXiv:1801.10130
   Shengnan Zhu, 2021, 2021 IEEE 8th Workshop on Wide Bandgap Power Devices and Applications (WiPDA), P1, DOI 10.1109/WiPDA49284.2021.9645100
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su YC, 2017, ADV NEUR IN, V30
   Su YC, 2019, PROC CVPR IEEE, P9434, DOI 10.1109/CVPR.2019.00967
   Su YC, 2017, LECT NOTES COMPUT SC, V10114, P154, DOI 10.1007/978-3-319-54190-7_10
   Su YC, 2017, PROC CVPR IEEE, P1368, DOI 10.1109/CVPR.2017.150
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang KH, 2019, INT CONF ACOUST SPEE, P3642, DOI [10.1109/icassp.2019.8683093, 10.1109/ICASSP.2019.8683093]
   Yang KL, 2021, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR46437.2021.00143
   Yang WY, 2018, INT C PATT RECOG, P2190, DOI 10.1109/ICPR.2018.8546070
   Yu DW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112622
   Zhao PY, 2020, AAAI CONF ARTIF INTE, V34, P12959
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 37
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
DI 10.1016/j.jvcir.2022.103660
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500009
DA 2024-07-18
ER

PT J
AU Battiato, S
   Giudice, O
   Guarnera, F
   Puglisi, G
AF Battiato, Sebastiano
   Giudice, Oliver
   Guarnera, Francesco
   Puglisi, Giovanni
TI CNN-based first quantization estimation of double compressed JPEG
   images?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE First quantization estimation; Multimedia forensics; JPEG; Image
   tampering
ID STATISTICAL-MODEL; MATRIX ESTIMATION
AB Multiple JPEG compressions leave artifacts in digital images: residual traces that could be exploited in forensics investigations to recover information about the device employed for acquisition or image editing software. In this paper, a novel First Quantization Estimation (FQE) algorithm based on convolutional neural networks (CNNs) is proposed. In particular, a solution based on an ensemble of CNNs was developed in conjunction with specific regularization strategies exploiting assumptions about neighboring element values of the quantization matrix to be inferred. Mostly designed to work in the aligned case, the solution was tested in challenging scenarios involving different input patch sizes, quantization matrices (both standard and custom) and datasets (i.e., RAISE and UCID collections). Comparisons with state-of-the-art solutions confirmed the effectiveness of the presented solution demonstrating for the first time to cover the widest combinations of parameters of double JPEG compressions.
C1 [Battiato, Sebastiano; Guarnera, Francesco] Univ Catania, Dept Math & Comp Sci, Viale Andrea Doria 6, I-95125 Catania, Italy.
   [Giudice, Oliver] Banca Italia, Rome, Italy.
   [Puglisi, Giovanni] Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.
C3 University of Catania; European Central Bank; Bank of Italy; University
   of Cagliari
RP Guarnera, F (corresponding author), Univ Catania, Dept Math & Comp Sci, Viale Andrea Doria 6, I-95125 Catania, Italy.
EM battiato@dmi.unict.it; oliver.giudice@bancaditalia.it;
   francesco.guarnera@unict.it; puglisi@unica.it
RI Giudice, Oliver/V-7713-2019; Battiato, Sebastiano/ABI-1584-2020
OI Giudice, Oliver/0000-0002-8343-2049; Battiato,
   Sebastiano/0000-0001-6127-2470; Guarnera, Francesco/0000-0002-7703-3367
CR Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], 2017, IEEE INT WORKSHOP IN
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Battiato Sebastiano, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P573, DOI 10.1007/978-3-030-68780-9_45
   Battiato S, 2021, INT C PATT RECOG, P5951, DOI 10.1109/ICPR48806.2021.9412528
   Battiato S, 2021, IEEE ACCESS, V9, P73110, DOI 10.1109/ACCESS.2021.3080576
   Battiato S, 2021, EURASIP J INF SECUR, V2021, DOI 10.1186/s13635-021-00120-7
   Bianchi T., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1929, DOI 10.1109/ICIP.2011.6115848
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Dalmia N, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010067
   Dalmia N, 2018, SIGNAL PROCESS-IMAGE, V61, P9, DOI 10.1016/j.image.2017.10.011
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Farid H., 2008, Tech. Rep. TR2008-638
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Galvan F, 2014, IEEE T INF FOREN SEC, V9, P1299, DOI 10.1109/TIFS.2014.2330312
   Giudice O, 2019, LECT NOTES COMPUT SC, V11752, P716, DOI 10.1007/978-3-030-30645-8_65
   Giudice O, 2017, LECT NOTES COMPUT SC, V10485, P625, DOI 10.1007/978-3-319-68548-9_57
   Hussain I, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103269
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P1471, DOI 10.1109/TIP.2015.2405477
   Moltisanti M, 2015, LECT NOTES COMPUT SC, V9280, P506, DOI 10.1007/978-3-319-23234-8_47
   Niu YK, 2022, IEEE T CIRC SYST VID, V32, P3279, DOI 10.1109/TCSVT.2021.3097351
   Niu YK, 2020, IEEE SIGNAL PROC LET, V27, P191, DOI 10.1109/LSP.2019.2962997
   Park J, 2018, LECT NOTES COMPUT SC, V11209, P656, DOI 10.1007/978-3-030-01228-1_39
   Piva A., 2013, ISRN SIGNAL PROCESS, V2013, DOI [10.1155/2013/496701, DOI 10.1155/2013/496701]
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Thai TH, 2019, IEEE ACCESS, V7, P76203, DOI 10.1109/ACCESS.2019.2921324
   Thai TH, 2014, IEEE T IMAGE PROCESS, V23, P1980, DOI 10.1109/TIP.2014.2310126
   Tondi B, 2021, EURASIP J INF SECUR, V2021, DOI 10.1186/s13635-021-00119-0
   Varghese G., 2016, INT J INNOV RES SCI, V3, P175
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Yang JQ, 2021, IEEE T CIRC SYST VID, V31, P1661, DOI 10.1109/TCSVT.2020.3003653
   Yao H, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102795
NR 39
TC 4
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103635
DI 10.1016/j.jvcir.2022.103635
EA SEP 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5K3LX
UT WOS:000869631900003
OA hybrid
DA 2024-07-18
ER

PT J
AU Deng, JH
   Chen, HM
   Yuan, ZM
   Gu, GS
   Xu, SH
   Weng, SW
   Wang, H
AF Deng, Jiehang
   Chen, Haomin
   Yuan, Zhongming
   Gu, Guosheng
   Xu, Shihe
   Weng, Shaowei
   Wang, Hao
TI An enhanced image quality assessment by synergizing superpixels and
   visual saliency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Full reference; Image quality assessment; Visual saliency; Superpixel
   segmentation; Limitations; Complementary
ID SIMILARITY
AB Superpixel and saliency-based evaluation methods play important roles in full reference image quality assess-ment (FR IQA). However, we find that these methods have one complementary principle and three limitations: (1) the weighted maps of superpixel-based methods conflict with the perception of the human visual system; (2) saliency-based methods are inefficient in terms of the block distortion; (3) the general two-direction gradient extraction factor must be extended to be multidirectional. To address these limitations, we propose an enhanced image quality assessment by synergizing superpixels and visual saliency. Specifically, the calculation of a newly proposed framework involves three similarities and two strategies: the saliency, superpixel and multidirectional gradient similarities of the neighborhoods, and the saliency pooling strategy, the fusion strategy of these simi-larities. Theoretical analysis and experimental results show that the proposed method can effectively address the limitations noted above and outperform the existing methods.
C1 [Deng, Jiehang; Chen, Haomin; Yuan, Zhongming; Gu, Guosheng] Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Peoples R China.
   [Xu, Shihe] Zhao Qing Univ, Sch Math & Stat, Zhaoqing 526061, Peoples R China.
   [Weng, Shaowei] Fujian Univ Technol, Sch Informat Sci & Engn, Fuzhou 350118, Peoples R China.
   [Wang, Hao] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway.
C3 Guangdong University of Technology; Zhaoqing University; Fujian
   University of Technology; Norwegian University of Science & Technology
   (NTNU)
RP Gu, GS (corresponding author), Guangdong Univ Technol, Sch Comp, Guangzhou 510006, Peoples R China.
EM gsgu@gdut.edu.cn
RI Wang, Hao/B-3650-2019
OI Wang, Hao/0000-0001-9301-5989
FU National NSF of China [61872095, 61571139, 61872128, 61202267];
   International Scientific and Technological Cooperation of Guangdong
   Province [2019A050513012]; Open Project Program of Shenzhen Key
   Laboratory of Media Security [ML -2018-03]; Fujian Science Fund for
   Distin- guished Young Scholars [2020J06043]; National Key R & D Program
   of China [2016YFB0200602]; Science and Technology Program of Guangzhou
   [201807010058]
FX Acknowledgements This work was supported in part by the National NSF of
   China under Grant 61872095, Grant 61571139, Grant 61872128, Grant
   61202267, in part by International Scientific and Technological
   Cooperation of Guangdong Province under Grant 2019A050513012, in part by
   the Open Project Program of Shenzhen Key Laboratory of Media Security
   under Grant ML -2018-03, in part by Fujian Science Fund for Distin-
   guished Young Scholars under Grant 2020J06043, in part by National Key R
   & D Program of China under Grant 2016YFB0200602, in part by the Science
   and Technology Program of Guangzhou under Grant 201807010058.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2011, MICT Image Quality Evaluation Database
   Banitalebi-Dehkordi M, 2019, MULTIMED TOOLS APPL, V78, P11507, DOI 10.1007/s11042-018-6700-3
   Chandler D.M., 2007, VSNR VISUAL SIGNAL T
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Gkioulekas I, 2010, IEEE IMAGE PROC, P1081, DOI 10.1109/ICIP.2010.5650991
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He LH, 2014, INT J COMPUT MATH, V91, P2374, DOI 10.1080/00207160.2013.816415
   Hu WJ, 2019, J VIS COMMUN IMAGE R, V59, P407, DOI 10.1016/j.jvcir.2019.01.039
   Jia HZ, 2018, IEEE ACCESS, V6, P65885, DOI 10.1109/ACCESS.2018.2878739
   Khosravi MH, 2019, J VIS COMMUN IMAGE R, V60, P217, DOI 10.1016/j.jvcir.2018.11.019
   Kim DO, 2010, IEEE T CONSUM ELECTR, V56, P930, DOI 10.1109/TCE.2010.5506022
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lin RJ, 2014, J VISION, V14, DOI 10.1167/14.9.1
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu LL, 2009, ENVIRON SCI ENG TECH, P1
   Lu T, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120947
   Ma H., 2021, J AMBIENT INTELL HUM, V1, P1
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Ninassi A., 2012, SUBJECTIVE QUALITY A
   Niu YZ, 2018, IEEE T CIRC SYST VID, V28, P849, DOI 10.1109/TCSVT.2016.2634590
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Soundararajan R, 2011, INT CONF ACOUST SPEE, P1149
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Tong YB, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.3.030503
   Wang HL, 2017, IEEE T IMAGE PROCESS, V26, P915, DOI 10.1109/TIP.2016.2639451
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wu MH, 2019, J AMB INTEL HUM COMP, V10, P3307, DOI 10.1007/s12652-018-1057-z
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang JC, 2021, IEEE T IMAGE PROCESS, V30, P6801, DOI 10.1109/TIP.2021.3098245
   Yang JC, 2022, IEEE T CYBERNETICS, V52, P2798, DOI 10.1109/TCYB.2020.3024627
   Yang JF, 2020, IEEE ACCESS, V8, P179702, DOI 10.1109/ACCESS.2020.3028282
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
   Zepernick H., 2010, WIRELESS IMAGING QUA
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 48
TC 1
Z9 1
U1 4
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103610
DI 10.1016/j.jvcir.2022.103610
EA SEP 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2FV
UT WOS:000859982300001
DA 2024-07-18
ER

PT J
AU Ubhi, JS
   Aggarwal, AK
   Mallika, AK
AF Ubhi, Jagpal Singh
   Aggarwal, Ashwani Kumar
   Mallika, Ashwani Kumar
TI Neural Style Transfer for image within images and conditional GANs for
   destylization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image security; Convolutional neural network; Information hiding;
   StegoExpose; Steganography
ID STEGANOGRAPHIC METHOD
AB In this paper, the feature representation of an image by CNN is used to hide the secret image into the cover image. The style of the cover image hides the content of the secret image and produce a stego image using Neural Style Transfer (NST) algorithm, which resembles the cover image and also contains the semantic content of secret image. The main technical contributions are to hide the content of the secret image in the in-between hidden layered style features of the cover image, which is the first of its kind in the present state-of-art technique. Also, to recover the secret image from the stego image, destylization is done with the help of conditional generative adversarial networks (GANs) using Residual in Residual Dense Blocks (RRDBs). Further, stego images from different layer combinations of content and style features are obtained and evaluated. Evaluation is based on the visual similarity and quality loss between the cover-stego pair and the secret reconstructed secret pair of images. From the experiments, it has been observed that the proposed algorithm has 43.95 dB Peak Signal-to-Noise Ratio (PSNR)), .995 Structural Similarity Index (SSIM), and .993 Visual Information Fidelity (VIF) for the ImageNet dataset. The proposed algorithm is found to be more robust against StegExpose than the traditional methods.
C1 [Mallika, Ashwani Kumar] Indian Inst Technol Roorkee, Elect & Commun Engn Dept, Roorkee, India.
   [Ubhi, Jagpal Singh] Sant Longowal Inst Engn & Technol, Elect & Commun Engn Dept, Longowal, Punjab, India.
   [Aggarwal, Ashwani Kumar] Sant Longowal Inst Engn & Technol, Elect & Instrumentat Engn Dept, Longowal, Punjab, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Sant Longowal Institute of Engineering &
   Technology (SLIET); Sant Longowal Institute of Engineering & Technology
   (SLIET)
RP Mallika, AK (corresponding author), Indian Inst Technol Roorkee, Elect & Commun Engn Dept, Roorkee, India.
EM js_ubhi@yahoo.com; ashwani.ist@gmail.com; mallika@ec.iitr.ac.in
RI Aggarwal, Ashwani Kumar/E-9682-2015; Ubhi, Jagpal/GNW-6280-2022; Ubhi,
   Jagpal Singh/GNW-5461-2022
OI Aggarwal, Ashwani Kumar/0000-0002-8748-0785; Ubhi,
   Jagpal/0000-0002-4881-552X; 
CR [Anonymous], 2019, ARXIV PREPRINT ARXIV
   [Anonymous], 2013, J COMPUT COMMUN
   Babaheidarian P., 2019, ARXIV PREPRINT ARXIV
   Baluja S, 2017, ADV NEURAL INFORM PR, P2069
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Bhattacharyya S., 2011, Proceedings of the 2011 World Congress on Information and Communication Technologies (WICT), P36, DOI 10.1109/WICT.2011.6141214
   Biradar RL, 2016, SURVEY PAPER STEGANO, V4
   Boehm B., 2014, Stegexpose-a tool for detecting lsb steganography
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen HY, 2020, IEEE WINT CONF APPL, P2152, DOI [10.1109/WACV45572.2020.9093489, 10.1109/wacv45572.2020.9093489]
   Chu Casey, 2017, NIPS 2017 WORKSH MAC
   Duan XT, 2020, IEEE ACCESS, V8, P170174, DOI 10.1109/ACCESS.2020.3024193
   Duan XT, 2019, IEEE ACCESS, V7, P9314, DOI 10.1109/ACCESS.2019.2891247
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Dumitrescu S, 2003, LECT NOTES COMPUT SC, V2578, P355
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Hayes J, 2017, ADV NEUR IN, V30
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kadhim IJ, 2020, COGN SYST RES, V60, P20, DOI 10.1016/j.cogsys.2019.11.002
   Ke Y, 2019, MULTIMED TOOLS APPL, V78, P13805, DOI 10.1007/s11042-018-6640-y
   Li SH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1716, DOI 10.1145/3123266.3123425
   Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Li YJ, 2017, ADV NEUR IN, V30
   Lin ZN, 2018, IEEE T INF FOREN SEC, V13, P1854, DOI 10.1109/TIFS.2018.2806741
   Liu SG, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102636
   Meng RH, 2018, CMC-COMPUT MATER CON, V55, P1, DOI 10.3970/cmc.2018.055.001
   Noda H, 2006, PATTERN RECOGN LETT, V27, P455, DOI 10.1016/j.patrec.2005.09.008
   Radford A., 2015, ARXIV
   Rahim Rafia, 2018, P EUROPEAN C COMPUTE
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Setiadi DIM, 2019, INT J ELECTRON TELEC, V65, P287, DOI 10.24425/ijet.2019.126312
   Sharifzadeh M, 2020, IEEE T INF FOREN SEC, V15, P867, DOI 10.1109/TIFS.2019.2929441
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Shiri F., 2017, International Conference on Digital Image Computing: Techniques and Applications (DICTA), P1
   Sun Y, 2019, J REAL-TIME IMAGE PR, V16, P635, DOI 10.1007/s11554-019-00849-y
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tang H, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P774, DOI 10.1145/3240508.3240704
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Van TP, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P410, DOI [10.1109/ISCIT.2019.8905216, 10.1109/iscit.2019.8905216]
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wang ZH, 2019, LECT NOTES COMPUT SC, V11954, P3, DOI 10.1007/978-3-030-36711-4_1
   Weng XY, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P87, DOI 10.1145/3323873.3325011
   Wengrowski E, 2019, PROC CVPR IEEE, P1515, DOI 10.1109/CVPR.2019.00161
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xintao D., 2019, ARXIV PREPRINT ARXIV
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhao HT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102921
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhou Zhi-li, 2016, Journal of Applied Sciences - Electronics and Information Engineering, V34, P527, DOI 10.3969/j.issn.0255-8297.2016.05.005
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 65
TC 35
Z9 35
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103483
DI 10.1016/j.jvcir.2022.103483
EA MAR 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600004
DA 2024-07-18
ER

PT J
AU Hu, YL
   Luo, CC
   Gao, JB
   Wang, BY
   Sun, YF
   Yin, BC
AF Hu, Yongli
   Luo, Cuicui
   Gao, Junbin
   Wang, Boyue
   Sun, Yanfeng
   Yin, Baocai
TI Shareability-Exclusivity Representation on Product Grassmann Manifolds
   for Multi-camera video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-camera video clustering; Grassmann manifolds; Product Grassmann
   manifolds
AB With the rapid popularity of multi-camera networks, one human action is usually captured by multiple cameras located at different angles simultaneously. Multi-camera videos contain the distinct perspectives of one action, therefore multiple views can overcome the impacts of illumination and occlusion. In this paper, we propose a novel multi-camera video clustering model, named Shareability-Exclusivity Representation on Product Grassmann Manifolds (PGM-SER), to address two key issues in traditional multi-view clustering methods (MVC): (1) Most MVC methods directly construct a shared similarity matrix by fusing multi-view data or their corresponding similarity matrices, which ignores the exclusive information in each view; (2) Most MVC methods are designed for multi-view vectorial data, which cannot handle the nonlinear manifold structure hidden in multi-camera videos. The proposed PGM-SER firstly adopts Product Grassmann Manifolds to represent multi-camera videos, then simultaneously learn their shared and exclusive information in global structures to achieve multi-camera video clustering. We provide an effective optimization algorithm to solve PGM-SER and present the corresponding convergence analysis. Finally, PGM-SER is tested on three multi-camera human action video datasets and obtain satisfied experimental results.
C1 [Hu, Yongli; Luo, Cuicui; Wang, Boyue; Sun, Yanfeng; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
   [Gao, Junbin] Univ Sydney, Univ Sydney Business Sch, Discipline Business Analyt, Sydney, NSW 2006, Australia.
   [Yin, Baocai] Dalian Univ Technol, Coll Comp Sci & Technol, Fac Elect Informat & Elect Engn, Dalian 116620, Peoples R China.
C3 Beijing University of Technology; University of Sydney; Dalian
   University of Technology
RP Wang, BY (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Municipal Key Lab Multimedia & Intelligen, Beijing 100124, Peoples R China.
EM wby@bjut.edu.cn
RI Gao, Junbin/C-6566-2008; Wang, Jinyang/JXN-8650-2024; zhao,
   hang/JVM-8270-2024; zhou, chen/KBC-4023-2024; Ying, Zhang/JWA-0560-2024
OI Hu, Yongli/0000-0003-0440-438X
FU National Natural Science Foundation of China [61906011, U21B2038,
   U19B2039]; Beijing Municipal Science and Technology Project
   [KM202010005014]
FX Acknowledgments The research project is partially supported by National
   Natural Science Foundation of China under Grant No. 61906011, U21B2038
   and U19B2039; Beijing Municipal Science and Technology Project No.
   KM202010005014.
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   [Anonymous], 2015, AAAI C ART INT
   [Anonymous], 2016, COMPUTER VISION PATT
   Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai X., 2013, 23 INT JOINT C ART I, P2598
   Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   Cortes C, 2009, P ADV NEUR INF PROC, P396
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M, 2013, IEEE I CONF COMP VIS, P3120, DOI 10.1109/ICCV.2013.387
   Huang ZW, 2015, PROC CVPR IEEE, P140, DOI 10.1109/CVPR.2015.7298609
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Lin ZC, 2011, PROG MOL BIOL TRANSL, V98, P1, DOI 10.1016/B978-0-12-385506-0.00001-6
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu J., 2013, P 2013 SIAM INT C DA, P252, DOI DOI 10.1137/1.9781611972832.28
   Liu T, 2017, ARXIV171106382V1
   Luo SR, 2018, AAAI CONF ARTIF INTE, P3730
   Nie FP, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2564
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Oh TH, 2016, IEEE T PATTERN ANAL, V38, P744, DOI 10.1109/TPAMI.2015.2465956
   Pan H., 2018, J VIS COMMUN IMAGE R
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tao ZQ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2843
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Tzortzis G, 2012, IEEE DATA MINING, P675, DOI 10.1109/ICDM.2012.43
   Wang B., 2014, AS C COMP VIS
   Wang BY, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3092690
   Wang BY, 2016, AAAI CONF ARTIF INTE, P2122
   Wang BY, 2017, IEEE T CIRC SYST VID, V27, P554, DOI 10.1109/TCSVT.2016.2609760
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wei L, 2016, J VIS COMMUN IMAGE R, V38, P386, DOI 10.1016/j.jvcir.2016.03.017
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Xiaobo Wang, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P1, DOI 10.1109/CVPR.2017.8
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   Yang ZY, 2019, IEEE T IMAGE PROCESS, V28, P5147, DOI 10.1109/TIP.2019.2913096
   Zhan K., 2017, J VIS COMMUN IMAGE R
   Zhan K, 2019, IEEE T IMAGE PROCESS, V28, P1261, DOI 10.1109/TIP.2018.2877335
   Zhan K, 2018, IEEE T CYBERNETICS, V48, P2887, DOI 10.1109/TCYB.2017.2751646
   Zhang CQ, 2017, PROC CVPR IEEE, P4333, DOI 10.1109/CVPR.2017.461
   Zhang CQ, 2015, IEEE I CONF COMP VIS, P1582, DOI 10.1109/ICCV.2015.185
   Zhang HM, 2019, IEEE T CYBERNETICS, V49, P1722, DOI 10.1109/TCYB.2018.2811764
   Zhang J., 2018, ARXIV180802229V2
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao HD, 2017, AAAI CONF ARTIF INTE, P2921
   Zong LL, 2017, NEURAL NETWORKS, V88, P74, DOI 10.1016/j.neunet.2017.02.003
NR 47
TC 1
Z9 1
U1 3
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103457
DI 10.1016/j.jvcir.2022.103457
EA MAR 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7YP
UT WOS:000779631900003
DA 2024-07-18
ER

PT J
AU You, JY
   Korhonen, J
AF You, Junyong
   Korhonen, Jari
TI Attention integrated hierarchical networks for no-reference image
   quality assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Attention; Hierarchical networks; Image quality assessment (IQA);
   Perceptual mechanisms; Quality perception
ID VISUAL-ATTENTION; DATABASE
AB Quality assessment of natural images is influenced by perceptual mechanisms, e.g., attention and contrast sensitivity, and quality perception can be generated in a hierarchical process. This paper proposes an architecture of Attention Integrated Hierarchical Image Quality networks (AIHIQnet) for no-reference quality assessment. AIHIQnet consists of three components: general backbone network, perceptually guided neck network, and head network. Multi-scale features extracted from the backbone network are fused to simulate image quality perception in a hierarchical manner. The attention and contrast sensitivity mechanisms modelled by an attention module capture essential information for quality perception. Considering that image rescaling potentially affects perceived quality, appropriate pooling methods in the non-convolution layers in AIHIQnet are employed to accept images with arbitrary resolutions. Comprehensive experiments on publicly available databases demonstrate outstanding performance of AIHIQnet compared to state-of-the-art models. Ablation experiments were performed to investigate the variants of the proposed architecture and reveal importance of individual components.
C1 [You, Junyong] NORCE Norwegian Res Ctr AS, Bergen, Norway.
   [Korhonen, Jari] Shenzhen Univ, Shenzhen, Peoples R China.
C3 Norwegian Research Centre (NORCE); Shenzhen University
RP You, JY (corresponding author), NORCE Norwegian Res Ctr AS, Bergen, Norway.
EM junyong.you@norceresearch.no
RI Korhonen, Jari/I-3033-2016
OI Korhonen, Jari/0000-0003-4354-5310; You, Junyong/0000-0002-4288-5244
FU basic grant (Grunnbevilgning) of NORCE - Research Council of Norway;
   National Natural Science Foundation of China [61772348]; Guangdong
   "Pearl River Talent Recruitment Program" [2019ZT08X603]; Shenzhen
   Fundamental Research Program [JCYJ20200109110410133]
FX This work is in part supported by the basic grant (Grunnbevilgning) of
   NORCE funded by the Research Council of Norway, and in part by National
   Natural Science Foundation of China under Grant 61772348, Guangdong
   "Pearl River Talent Recruitment Program" under Grant 2019ZT08X603, and
   Shenzhen Fundamental Research Program under Grant JCYJ20200109110410133.
CR Gutiérrez PA, 2016, IEEE T KNOWL DATA EN, V28, P127, DOI 10.1109/TKDE.2015.2457911
   Bianco S, 2018, SIGNAL IMAGE VIDEO P, V12, P355, DOI 10.1007/s11760-017-1166-8
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Chen DQ, 2020, IEEE T IMAGE PROCESS, V29, P6496, DOI 10.1109/TIP.2020.2990342
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Dosovitskiy A., 2021, ICLR
   Engelke U, 2011, IEEE SIGNAL PROC MAG, V28, P50, DOI 10.1109/MSP.2011.942473
   Fang YM, 2020, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR42600.2020.00373
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gao F, 2018, PATTERN RECOGN, V81, P432, DOI 10.1016/j.patcog.2018.04.016
   Geisler WS, 1998, P SOC PHOTO-OPT INS, V3299, P294, DOI 10.1117/12.320120
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hemami SS, 2010, SIGNAL PROCESS-IMAGE, V25, P469, DOI 10.1016/j.image.2010.05.009
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   ITU-T, 2008, ITU T P910 SUBJECTIV
   Jung A.B., IMGAUG
   Kang L, 2014, PROC CVPR IEEE, P4034, DOI 10.1109/CVPR.2014.514
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li YM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P685, DOI 10.1109/ICDSP.2016.7868646
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mallat S, 1996, P IEEE, V84, P604, DOI 10.1109/5.488702
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Müller R, 2019, ADV NEUR IN, V32
   Petras K, 2019, NEUROIMAGE, V186, P103, DOI 10.1016/j.neuroimage.2018.10.086
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   ROBSON JG, 1966, J OPT SOC AM, V56, P1141, DOI 10.1364/JOSA.56.001141
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh H.R., 2004, Ph.D. dissertation
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Simonyan K., 2014, CORR
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Vaswani A, 2017, ADV NEUR IN, V30
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JJ, 2020, IEEE T IMAGE PROCESS, V29, P7414, DOI 10.1109/TIP.2020.3002478
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   Yang S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1383, DOI 10.1145/3343031.3350990
   Ying ZQ, 2020, PROC CVPR IEEE, P3572, DOI 10.1109/CVPR42600.2020.00363
   You, 2012, P IEEE INT C MULT EX
   You J., 2021, P IEEE INT C IM PROC
   You JY, 2019, IEEE IMAGE PROC, P2349, DOI [10.1109/icip.2019.8803395, 10.1109/ICIP.2019.8803395]
   You JY, 2014, IEEE T IMAGE PROCESS, V23, P200, DOI 10.1109/TIP.2013.2287611
   You JY, 2011, IEEE T MULTIMEDIA, V13, P1269, DOI 10.1109/TMM.2011.2172591
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng H, 2018, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2018.8451285
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhang WX, 2020, IEEE T CIRC SYST VID, V30, P36, DOI 10.1109/TCSVT.2018.2886771
NR 65
TC 19
Z9 19
U1 2
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103399
DI 10.1016/j.jvcir.2021.103399
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0SO
UT WOS:000783933400002
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Li, ZW
   Hu, AS
   Wang, XF
   Hu, J
   Zhang, GJ
AF Li, Zhangwei
   Hu, Anshun
   Wang, Xiaofei
   Hu, Jun
   Zhang, Guijun
TI Learning to capture dependencies between global features of different
   convolution layers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Object detection; Non-local neural network; Global
   features dependencies
AB NLNet has been considered as one milestone in the study of capturing long-range dependencies. Many recent studies modify the internal structure of NLNet directly and apply them to video object detection and semantic segmentation tasks. The dependencies between local and global features have been well developed, but the dependencies between global features of different convolution layers are rarely considered. Convolution is a local operation, so the global features of different convolution layers cannot be directly related, resulting in the loss of dependencies between global features. Given the vulnerability, this study designs a network that can efficiently capture the dependencies between the global features of different convolution layers, potentially further improving the accuracy. Furthermore, for the calculation of the dependency matrix, based on the Dot-product used in NLNet, we propose RELU-Dot-product, which can achieve higher accuracy. We evaluate the proposed method on image classification and object detection tasks. The data sets involved are CIFAR10, CIFAR100, Tinyimagenet, VOC2007, VOC2012 and MS COCO. Experiments show that our method can significantly improve network performance by introducing a few parameters.
C1 [Li, Zhangwei; Hu, Anshun; Wang, Xiaofei; Hu, Jun; Zhang, Guijun] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Li, ZW (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
EM lzw@zjut.edu.cn
RI Zhang, Guijun/H-2135-2012; Li, Zhangwei/H-4492-2012
CR [Anonymous], 2015, Tiny ImageNet classification with convolutional neural networks
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen Jiaqi, 2019, ARXIV PREPRINT ARXIV
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen YP, 2018, ADV NEUR IN, V31
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Geng YB, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102914
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky G., 2009, Learning multiple layers of features fromtiny images
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4345
   Shokri M, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102769
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang H., 2020, PATTERN RECOGN, V110
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu F., 2015, ARXIV
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou X., 2019, COMPUT VISION PATTER
NR 40
TC 1
Z9 1
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103360
DI 10.1016/j.jvcir.2021.103360
EA NOV 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700002
DA 2024-07-18
ER

PT J
AU Tian, CZ
   Chai, XL
   Shao, F
AF Tian, Chongzhen
   Chai, Xiongli
   Shao, Feng
TI Stitched image quality assessment based on local measurement errors and
   global statistical properties
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image stitching; Stitched image quality assessment; Structural
   distortion; Geometric error; Quality aggregation
ID GRADIENT MAGNITUDE
AB ABS T R A C T Image stitching is developed to generate wide-field images or panoramic images for virtual reality applications. However, the quality assessment of stitched images with respect to various stitching algorithms has been less studied. Effective stitched image quality assessment (SIQA) is advantageous to evaluate the performance of various stitching methods and optimize the design of stitching methods. In this paper, we propose a novel SIQA method by exploiting local measurement errors and global statistical properties for feature extraction. Comprehensive image attributes including ghosting, misalignment, structural distortion, geometric error, chro-matic aberrations and blur are considered either locally or globally. The extracted local and global features are aggregated into an overall quality via regression. Experimental results on two benchmark databases demonstrate the superiority of the proposed metric over both the state-of-the-art quality models designed for natural images and stitched images.
C1 [Tian, Chongzhen; Chai, Xiongli; Shao, Feng] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
EM shaofeng@nbu.edu.cn
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harville M., 2006, P C COMP VIS PATT RE, P5, DOI DOI 10.1109/CVPRW.2006.161
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Kong YQ, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115779
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu YC, 2014, IEEE IMAGE PROC, P1827, DOI 10.1109/ICIP.2014.7025366
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu SJ, 2007, DOCENG'07: PROCEEDINGS OF THE 2007 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P3
   Madhusudana PC, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2921858
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Perfecto C, 2020, IEEE T COMMUN, V68, P2491, DOI 10.1109/TCOMM.2020.2965527
   Qureshi HS, 2012, IET IMAGE PROCESS, V6, P1348, DOI 10.1049/iet-ipr.2011.0641
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2021, IEEE T SYST MAN CY-S, V51, P3053, DOI 10.1109/TSMC.2019.2917496
   Ullah H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226457
   Wang XJ, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103051
   Wang Y., 2010, P INT C COMP APPL SY
   Xiaoyin Duanmu, 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P200, DOI 10.1109/ITNG.2010.231
   Xu Jing, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P173, DOI 10.1109/CSAE.2012.6272573
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yan B, 2019, IEEE T MULTIMEDIA, V21, P2957, DOI 10.1109/TMM.2019.2914883
   Yan WQ, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107541
   Yang LY, 2017, IEEE INT CONF COMP V, P2487, DOI 10.1109/ICCVW.2017.293
   Yue GH, 2019, IEEE T IND ELECTRON, V66, P3784, DOI 10.1109/TIE.2018.2851984
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YB, 2016, IEEE T IMAGE PROCESS, V25, P4286, DOI 10.1109/TIP.2016.2585884
   Zhigang Liu, 2011, 2011 International Conference on Multimedia Technology, P3785
   Zhou XS, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P46, DOI 10.1109/ICISCE.2017.20
NR 34
TC 7
Z9 7
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103324
DI 10.1016/j.jvcir.2021.103324
EA OCT 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700006
DA 2024-07-18
ER

PT J
AU Wu, YR
   Liu, WX
   Wan, SH
AF Wu, Yirui
   Liu, Wenxiang
   Wan, Shaohua
TI Multiple attention encoded cascade R-CNN for scene text detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cascade R-CNN; Deep representation learning; Applications to robust
   image recognition; Multiple attention encoding; Scene text detection;
   Multi-oriented text
AB Inspired by instance segmentation algorithms, researchers have proposed quantity of segmentation-based methods for text detection, achieving remarkable results on scene text with arbitrary orientation and large aspect ratios. Following their success, we believe cascade architecture and extracting contextual information in multiple aspects are powerful to boost performance on the basis of segmentation-based methods, especially in decreasing false positive texts in complex natural scene. Based on such consideration, we propose a multiple-context-aware and cascade CNN structure, which appropriately encodes multiple categories of context information into a cascade R-CNN framework. Specifically, the proposed method consists of two stages, i.e., feature generation and cascade detection. During the first stage, we define ISTK (Isolated Selective Text Kernel) module to refine feature map, which sequentially encodes channel-wise and kernel-size attention information by designing multiple branches and different kernel sizes in isolate form. Afterwards, we build long-range spatial dependencies in feature map via non-local operations. Built on contextual feature map, Cascade Mask R-CNN structure progressively refines accurate boundaries of text instances with multi-stage framework. We conduct comparative experiments on ICDAR2015 and 2017-MLT datasets, where the proposed method outperform comparative methods in terms of effectiveness and efficiency measurements.
C1 [Wu, Yirui; Liu, Wenxiang] Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, Fochengxi Rd, Nanjing 210093, Peoples R China.
   [Wu, Yirui; Liu, Wenxiang] Hohai Univ, Coll Comp & Informat, Fochengxi Rd, Nanjing 210093, Peoples R China.
   [Wan, Shaohua] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, South Nanhu Rd, Wuhan 430073, Peoples R China.
   [Wan, Shaohua] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Peoples R China.
C3 Hohai University; Hohai University; Zhongnan University of Economics &
   Law; Nanjing University
RP Wan, SH (corresponding author), Hohai Univ, Coll Comp & Informat, Fochengxi Rd, Nanjing 210093, Peoples R China.
EM wuyirui@hhu.edu.cn; lwxhhu@hhu.edu.cn; shaohua.wan@ieee.org
RI Wu, Yirui/HGD-2965-2022; Wan, Shaohua/L-8492-2019; Wan,
   Shaohua/B-9243-2014
OI Wu, Yirui/0000-0003-3022-3718; Wan, Shaohua/0000-0001-7013-9081
FU National Key RAMP;D Program of China [2018YFC0407901]; Fundamental
   Research Funds for the Central Universities [B200202177, 31412111303,
   31512111310]; State Key Laboratory for Novel Software Technology,
   Nanjing University [KFKT2019B17]; National Natural Science Foundation of
   China [61702160, 62172438]
FX This work was supported by National Key R&D Program of China under Grant
   No. 2018YFC0407901, the Fundamental Research Funds for the Central
   Universities under Grant No. B200202177, 31412111303, 31512111310, the
   open project from the State Key Laboratory for Novel Software
   Technology, Nanjing University, under Grant No. KFKT2019B17, and the
   National Natural Science Foundation of China under Grant No. 61702160,
   62172438.
CR Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Cheng CK, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415611
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He WH, 2018, IEEE T IMAGE PROCESS, V27, P5406, DOI 10.1109/TIP.2018.2855399
   Hu J., 2017, CoRR
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Long SB, 2018, LECT NOTES COMPUT SC, V11206, P19, DOI 10.1007/978-3-030-01216-8_2
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Minghui Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P706, DOI 10.1007/978-3-030-58621-8_41
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wei L, 2020, IEEE INT CONF MULTI, DOI 10.1109/icmew46912.2020.9105953
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Xu XL, 2020, IEEE INTERNET THINGS, V7, P7919, DOI [10.1109/TITS.2020.2995622, 10.1109/JIOT.2020.3000871]
   Xu XX, 2020, AQUACULT NUTR, V26, P432, DOI 10.1111/anu.13005
   Xu Y., 2019, ABS191109358 CORR
   Yao Xiao, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P695, DOI 10.1109/ICDAR.2019.00116
   Ye J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P516
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zhang CQ, 2019, PROC CVPR IEEE, P10544, DOI 10.1109/CVPR.2019.01080
   Zhang Z, 2021, NEURAL NETWORKS, V139, P77, DOI 10.1016/j.neunet.2021.02.005
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 39
TC 10
Z9 10
U1 3
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103261
DI 10.1016/j.jvcir.2021.103261
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA3DL
UT WOS:000702769700004
DA 2024-07-18
ER

PT J
AU Xu, C
   Yuen, P
   Lang, WX
   Xin, R
   Mao, KC
   Jiang, HY
AF Xu, Can
   Yuen, Peter
   Lang, Wenxi
   Xin, Rui
   Mao, Kaichen
   Jiang, Haiyan
TI Generative detect for occlusion object based on occlusion generation and
   feature completing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Occlusion; Object detection; Feature completing; Generative adversarial
   networks
AB Detecting the object with external occlusion has always been a hot topic in computer version, while its accuracy is always limited due to the loss of original object information and increase of new occlusion noise. In this paper, we propose a occluded object detection algorithm named GC-FRCN (Generative feature completing Faster RCNN), which consists of the OSGM (Occlusion Sample Generation Module) and OSIM (Occlusion Sample Inpainting Module). Specifically, the OSGM mines and discards the feature points with high category response on the feature map to enhance the richness of occlusion scenes in the training data set. OSIM learns an implicit mapping relationship from occluded feature map to real feature map adversarially, which aims at improving feature quality by repair the noisy object feature. Extensive experiments and ablation studies have been conducted on four different datasets. All the experiments demonstrate the GC-FRCN can effectively detect objects with local external occlusion and has good robustness for occlusion at different scales.
C1 [Xu, Can; Mao, Kaichen; Jiang, Haiyan] Nanjing Agr Univ, Coll Artificial Intelligence, Nanjing 210095, Jiangsu, Peoples R China.
   [Jiang, Haiyan] Nanjing Agr Univ, Natl Engn & Technol Ctr Informat Agr, Nanjing 210095, Jiangsu, Peoples R China.
   [Yuen, Peter] Cranfield Univ, Ctr Elect Warfare Informat & Cyber CEWIC, Electroopt & Remote Sensing, Swindon, Wilts, England.
   [Lang, Wenxi] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
   [Xin, Rui] Univ Durham, Dept Comp Sci, Durham, England.
C3 Nanjing Agricultural University; Nanjing Agricultural University;
   Cranfield University; Nanjing University of Aeronautics & Astronautics;
   Durham University
RP Jiang, HY (corresponding author), Nanjing Agr Univ, Coll Artificial Intelligence, Nanjing 210095, Jiangsu, Peoples R China.; Jiang, HY (corresponding author), Nanjing Agr Univ, Natl Engn & Technol Ctr Informat Agr, Nanjing 210095, Jiangsu, Peoples R China.
EM jianghy@njau.edu.cn
RI Li, Hang/ABA-3237-2021
OI Li, Hang/0000-0002-9179-3741; Xu, Can/0000-0001-5374-3818; Yuen,
   Peter/0000-0003-2493-2534
FU National Natural Science Foundation of China [31872847]; Key Research
   and Development Plan of Jiangsu Province of China [BE2019383]
FX This paper is supported in part by the National Natural Science
   Foundation of China (No. 31872847) ; and the Key Research and
   Development Plan of Jiangsu Province of China (Modern Agriculture,
   BE2019383) .
CR [Anonymous], 2018, COMPUTER VISION PATT
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2014, ARXIV14126537
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Dai J., 2016, ADV NEUR IN, P379
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fernandez-Gallego JA, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0289-4
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Lahiri A., 2017, ARXIV171106106
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li Y., 2016, ADV NEUR IN, P4898
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Loshchilov I., 2015, ARXIV151106343
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Mathias M, 2013, IEEE I CONF COMP VIS, P1505, DOI 10.1109/ICCV.2013.190
   Noh J, 2018, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2018.00107
   Ouyang WL, 2015, IEEE T PATTERN ANAL, V37, P1875, DOI 10.1109/TPAMI.2014.2377734
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pepik B, 2013, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2013.422
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wang XL, 2015, IEEE I CONF COMP VIS, P2794, DOI 10.1109/ICCV.2015.320
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Xiang P, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1851, DOI 10.1109/CompComm.2017.8322859
   Xiong X, 2017, PLANT METHODS, V13, DOI 10.1186/s13007-017-0254-7
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zhou CL, 2017, IEEE I CONF COMP VIS, P3506, DOI 10.1109/ICCV.2017.377
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
NR 51
TC 2
Z9 2
U1 4
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103189
DI 10.1016/j.jvcir.2021.103189
EA JUN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500005
DA 2024-07-18
ER

PT J
AU Dutta, S
AF Dutta, Saikat
TI Depth-aware blending of smoothed images for Bokeh effect generation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bokeh effect; Blur kernel; AIM 2019; Deep learning
AB Bokeh effect is used in photography to capture images where the closer objects look sharp and everything else stays out-of-focus. Bokeh photos are generally captured using Single Lens Reflex cameras using shallow depth-of-field. Most of the modern smartphones can take bokeh images by leveraging dual rear cameras or a good auto-focus hardware. However, for smartphones with single-rear camera without a good auto-focus hardware, we have to rely on software to generate bokeh images. This kind of system is also useful to generate bokeh effect in already captured images. In this paper, an end-to-end deep learning framework is proposed to generate high-quality bokeh effect from images. The original image and different versions of smoothed images are blended to generate Bokeh effect with the help of a monocular depth estimation network. The model is trained through three phases to generate visually pleasing bokeh effect. The proposed approach is compared against a saliency detection based baseline and a number of approaches proposed in AIM 2019 Challenge on Bokeh Effect Synthesis. Extensive experiments are shown in order to understand different parts of the proposed algorithm. The network is lightweight and can process an HD image in 0.03 s. This approach ranked second in AIM 2019 Bokeh effect challenge-Perceptual Track.
C1 [Dutta, Saikat] Indian Inst Technol Madras, Comp Vis Lab, Chennai 600036, Tamil Nadu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Dutta, S (corresponding author), Indian Inst Technol Madras, Comp Vis Lab, Chennai 600036, Tamil Nadu, India.
EM saikat@smail.iitm.ac.in
OI Dutta, Saikat/0000-0001-6021-5407
CR Atapour-Abarghouei A, 2018, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2018.00296
   Chen W, 2016, ADV NEUR IN, V29
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Ignatov A, 2020, IEEE COMPUT SOC CONF, P1676, DOI 10.1109/CVPRW50498.2020.00217
   Ignatov A, 2019, IEEE INT CONF COMP V, P3591, DOI 10.1109/ICCVW.2019.00444
   King DB, 2015, ACS SYM SER, V1214, P1
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778802
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu SF, 2017, ADV NEUR IN, V30
   Liu SF, 2016, LECT NOTES COMPUT SC, V9908, P560, DOI 10.1007/978-3-319-46493-0_34
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Niklaus S, 2017, PROC CVPR IEEE, P2270, DOI 10.1109/CVPR.2017.244
   Paszke A, 2019, ADV NEUR IN, V32
   Purohit K, 2019, IEEE INT CONF COMP V, P3417, DOI 10.1109/ICCVW.2019.00424
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Soler C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516529
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Wadhwa N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201329
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu JZ, 2010, VISUAL COMPUT, V26, P555, DOI 10.1007/s00371-010-0459-5
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yu XA, 2010, COMPUT GRAPH FORUM, V29, P2099, DOI 10.1111/j.1467-8659.2010.01797.x
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 36
TC 10
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103089
DI 10.1016/j.jvcir.2021.103089
EA MAR 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SF9SQ
UT WOS:000653087000005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gautam, S
   Gandhi, TK
   Panigrahi, BK
AF Gautam, Sidharth
   Gandhi, Tapan Kumar
   Panigrahi, B. K.
TI A Model-based dehazing scheme for unmanned aerial vehicle system using
   radiance boundary constraint and graph model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Remote sensing; Satellite imaging; Unmanned aerial vehicle imaging;
   Image restoration; Image enhancement; Image dehazing
ID IMAGE; CONTRAST; REMOVAL
AB Unmanned aerial vehicle system (UAVs) imaging has become a challenging area of research due to the dynamic atmospheric environment. The images captured by UAVs are often deteriorated by factors such as clouds occlusion, poor atmospheric illumination, and limited capability of the imaging system. To tackle problems, this paper presents a novel visibility restoration scheme for UAVs images by considering the following two assumptions: (1) The actual scene radiance of a UAVs image is bounded. (2) Pixels sharing the same appearance must have the same transmission value in a local neighborhood. Inspired by above assumptions, an image boundary constraint utilizing the median filter has been imposed on the RGB channel for the rough estimation of transmission-map in aerial images. Furthermore, a graph-model based optimization technique has been used for the transmission-map refinement. The experimental results demonstrate the efficiency of the proposed method in terms of metrics correspond to the human-visual-system (HVS).
C1 [Gautam, Sidharth; Gandhi, Tapan Kumar; Panigrahi, B. K.] Indian Inst Technol, New Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Gautam, S (corresponding author), Indian Inst Technol, New Delhi, India.
EM sidharthgautam02@gmail.com
RI Panigrahi, Bijaya Ketan/G-1005-2010; Gautam, Sidharth/AAB-7467-2021
OI Gautam, Sidharth/0000-0001-8223-8642; Gandhi, Tapan
   Kumar/0000-0002-3532-9389
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], 2019, USC SIPI SATELLITE D
   [Anonymous], 2017, CORR
   [Anonymous], 2019, QUICKBIRD SATELLITE
   [Anonymous], 2019, PLEIADES SATELLITE D
   Asari KV, 2006, LECT NOTES COMPUT SC, V4338, P240
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Carr P, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P103, DOI 10.1109/DICTA.2009.25
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Chen XW, 2013, PROC CVPR IEEE, P1902, DOI 10.1109/CVPR.2013.248
   Cheng G, 2014, ISPRS J PHOTOGRAMM, V98, P119, DOI 10.1016/j.isprsjprs.2014.10.002
   Cheng Y, 2016, ADV METEOROL, V2016, DOI 10.1155/2016/5297158
   Du Y, 2002, IEEE T GEOSCI REMOTE, V40, P210, DOI 10.1109/36.981363
   Du YX, 2018, IEEE COMPUT SOC CONF, P843, DOI 10.1109/CVPRW.2018.00116
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gautam S, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293431
   Gautam S, 2018, IEEE IMAGE PROC, P1757, DOI 10.1109/ICIP.2018.8451248
   Geisler WS, 2011, J VISION, V11, DOI 10.1167/11.12.14
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hird J. N, 2017, REMOTE SENS, V9
   Huang LD, 2015, IET IMAGE PROCESS, V9, P908, DOI 10.1049/iet-ipr.2015.0150
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang YQ, 2016, CHINESE J AERONAUT, V29, P502, DOI 10.1016/j.cja.2016.01.012
   Hunt E. Raymond Jr, 2005, Precision Agriculture, V6, P359, DOI 10.1007/s11119-005-2324-5
   Jang JH, 2011, IEEE GEOSCI REMOTE S, V8, P983, DOI 10.1109/LGRS.2011.2146227
   Karacan L, 2017, IEEE T IMAGE PROCESS, V26, P4523, DOI 10.1109/TIP.2017.2718664
   Kwok N, 2015, INT CONF MACH LEARN, P322, DOI 10.1109/ICMLC.2015.7340942
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Ponomarenko N.N., 2007, P 2 INT WORKSH VID P, V4
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ren Wenqi, 2018, IEEE C COMP VIS PATT
   Shen CT, 2009, IEEE IMAGE PROC, P3141, DOI 10.1109/ICIP.2009.5414427
   Sidike P, 2018, IEEE GEOSCI REMOTE S, V15, P404, DOI 10.1109/LGRS.2018.2790899
   Singh D, 2018, IET COMPUT VIS, V12, P208, DOI 10.1049/iet-cvi.2017.0044
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Vanegas CA, 2009, IEEE T VIS COMPUT GR, V15, P424, DOI 10.1109/TVCG.2008.193
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang MM, 2018, IEEE T MULTIMEDIA, V20, P3008, DOI 10.1109/TMM.2018.2820327
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI [10.1145/1869790.1869829, DOI 10.1145/1869790.1869829]
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2017, PROC CVPR IEEE, P5226, DOI 10.1109/CVPR.2017.555
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao XT, 2018, IET IMAGE PROCESS, V12, P88, DOI 10.1049/iet-ipr.2017.0060
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 54
TC 3
Z9 3
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102993
DI 10.1016/j.jvcir.2020.102993
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900005
DA 2024-07-18
ER

PT J
AU Sran, PK
   Gupta, S
   Singh, S
AF Sran, Paramveer Kaur
   Gupta, Savita
   Singh, Sukhwinder
TI Integrating saliency with fuzzy thresholding for brain tumor extraction
   in MR images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency; Fuzzy; Segmentation; ROI; Medical Images
ID C-MEANS ALGORITHM; CAROTID-ARTERY WALL; SEGMENTATION; FRAMEWORK
AB The automatic detection and extraction of tumor area in Magnetic Resonance Imaging (MRI) is an important and challenging task. This paper presents a fully automatic and unsupervised method for fast and accurate extraction of brain tumor area from MR images. The proposed method named as Saliency Based Segmentation (SBS) is based on visual saliency. The saliency model detects the pathologically important area and then fuzzy thresholding is used for extraction of the detected region. The performance of SBS is compared with Adaptively Regularized Kernel-Based Fuzzy C-Means Clustering, Mean Shift and Fuzzy C-Means clustering with Level Set Method. The experimental evaluation validated on BRATS database using Jaccard index (0.84 +/- 0.04), Dice Index (0.91 +/- 0.02), Execution time (2.99 +/- 0.29), Precision (0.82 +/- 0.16), Recall (0.97 +/- 0.03) and F-measure (0.88 +/- 0.10) demonstrates that SBS achieves better segmentation results even in the presence of noise and uneven illumination in images.
C1 [Sran, Paramveer Kaur; Gupta, Savita; Singh, Sukhwinder] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Sran, PK (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM paramsran@gmail.com
RI Singh, Sukhwinder/JGL-7957-2023
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Aja-Fernández S, 2015, KNOWL-BASED SYST, V83, P1, DOI 10.1016/j.knosys.2015.02.029
   Ayachi R, 2009, LECT NOTES COMPUT SC, V5590, P736, DOI 10.1007/978-3-642-02906-6_63
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Bauer S, 2011, LECT NOTES COMPUT SC, V6893, P354, DOI 10.1007/978-3-642-23626-6_44
   Bauer S, 2010, IEEE ENG MED BIO, P4080, DOI 10.1109/IEMBS.2010.5627302
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Daoqiang Zhang, 2012, Multimodal Brain Image Analysis. Proceedings Second International Workshop, MBIA 2012. Held in Conjunction with MICCAI 2012, P94, DOI 10.1007/978-3-642-33530-3_8
   Farhi L, 2017, J VIS COMMUN IMAGE R, V46, P303, DOI 10.1016/j.jvcir.2017.04.013
   Frintrop S., 2007, P INT C COMP VIS SYS
   Gao ZF, 2018, IEEE T MED IMAGING, V37, P273, DOI 10.1109/TMI.2017.2746879
   Gao ZF, 2017, MED IMAGE ANAL, V37, P1, DOI 10.1016/j.media.2017.01.004
   Ghosh P, 2018, J VIS COMMUN IMAGE R, V54, P63, DOI 10.1016/j.jvcir.2018.04.007
   Gliomas D.A., 2009, RECENT RESULTS CANC
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Hou X., SALIENCY DETECTION S
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kanas V. G., 2012, ARTIF INTELL, V382, P26, DOI DOI 10.1007/978-3-642-33412-2_3
   Kenesei J., 2015, INTERPRETABILITY COM, DOI [10.1007/978-3- 319-21942-4, DOI 10.1007/978-3-319-21942-4]
   Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037
   Koehler K, 2014, J VISION, V14, DOI 10.1167/14.3.14
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li Ruoyu, LECT NOTES COMPUTER, V9467
   Lötjönen JMP, 2010, NEUROIMAGE, V49, P2352, DOI 10.1016/j.neuroimage.2009.10.026
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Pan C, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/5098973
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   van der Lijn F, 2012, IEEE T MED IMAGING, V31, P276, DOI 10.1109/TMI.2011.2168420
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yang MS, 2008, PATTERN RECOGN LETT, V29, P1713, DOI 10.1016/j.patrec.2008.04.016
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
NR 39
TC 8
Z9 8
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102964
DI 10.1016/j.jvcir.2020.102964
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OJ
UT WOS:000613150700002
DA 2024-07-18
ER

PT J
AU Feng, MZ
   Song, KC
   Wang, YY
   Liu, J
   Yan, YH
AF Feng, Mingzheng
   Song, Kechen
   Wang, Yanyan
   Liu, Jie
   Yan, Yunhui
TI Learning discriminative update adaptive spatial-temporal regularized
   correlation filter for RGB-T tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Correlation filters; Adaptive spatial-temporal
   regularization; ADMM; Model updating
ID VISUAL TRACKING; FUSION TRACKING; ROBUST; SIAMESE
AB The RGB-T trackers based on correlation filter framework have been extensively investigated for that they can track targets more accurately in most complex scenes. However, the performance of these trackers is limited when facing some specific challenging scenarios, such as occlusion and background clutter. For different tracking targets, most of these trackers utilize fixed regularization constraint to build the filter model, which is obviously unreasonable to effectively present the appearance changes and characteristics of a specific target. In addition, they adopt a simple model update mechanism based on linear interpolation, which can easily lead to model degradation in challenging scenarios, resulting in tracker drift. To solve the above problems, we propose a novel adaptive spatial-temporal regularized correlation filter model to learn an appropriate regularization for achieving robust tracking and a relative peak discriminative method for model updating to avoid the model degradation. Besides, to make better integrate the unique advantages of the two modes and adapt the changing appearance of the target, an adaptive weighting ensemble scheme and a multi-scale search mechanism are adopted, respectively. To optimize the proposed model, we designed an efficient ADMM algorithm, which greatly improved the efficiency. Extensive experiments have been carried out on two available datasets, RGBT234 and RGBT210, and the experimental results indicate that the tracker proposed by us performs favorably in both accuracy and robustness against the state-of-the-art RGB-T trackers.
C1 [Feng, Mingzheng; Song, Kechen; Wang, Yanyan; Liu, Jie; Yan, Yunhui] Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
   [Feng, Mingzheng; Song, Kechen; Wang, Yanyan; Liu, Jie; Yan, Yunhui] Energy Saving Met Equipment & Intelligent Detect, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Song, KC; Yan, YH (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
EM songkc@me.neu.edu.cn; yanyh@mail.neu.edu.cn
RI Song, Kechen/T-1896-2019; Yan, Yunhui/HDL-7343-2022
OI Song, Kechen/0000-0002-7636-3460; Yan, Yunhui/0000-0001-7121-2367; Wang,
   Yanan/0000-0001-7935-5960
FU National Natural Science Foundation of China [51805078]; National Key
   Research and Development Program of China [2017YFB0304200]
FX This work is supported by the National Natural Science Foundation of
   China (51805078), the National Key Research and Development Program of
   China (2017YFB0304200).
CR Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cai TW, 2019, FUNCT MATER LETT, V12, DOI 10.1142/S1793604719500024
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Ding M, 2020, IEEE ACCESS, V8, P36948, DOI 10.1109/ACCESS.2020.2975224
   Ding M, 2018, SIGNAL PROCESS-IMAGE, V68, P13, DOI 10.1016/j.image.2018.06.019
   Du F, 2018, SIGNAL PROCESS-IMAGE, V67, P58, DOI 10.1016/j.image.2018.05.013
   Gao Y., 2019, P 2019 INT C IND, P1, DOI 10.1101/2020.05.19.101592
   Gao Y, 2019, IEEE INT CONF COMP V, P91, DOI 10.1109/ICCVW.2019.00017
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Ji ZJ, 2015, J VIS COMMUN IMAGE R, V28, P44, DOI 10.1016/j.jvcir.2015.01.008
   Kim HU, 2015, IEEE I CONF COMP VIS, P3011, DOI 10.1109/ICCV.2015.345
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Li CL, 2019, IEEE INT CONF COMP V, P2262, DOI 10.1109/ICCVW.2019.00279
   Li CL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1856, DOI 10.1145/3123266.3123289
   Li CL, 2018, SIGNAL PROCESS-IMAGE, V68, P207, DOI 10.1016/j.image.2018.08.004
   Li CL, 2016, IEEE T IMAGE PROCESS, V25, P5743, DOI 10.1109/TIP.2016.2614135
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li X, 2019, KNOWL-BASED SYST, V166, P71, DOI 10.1016/j.knosys.2018.12.011
   Liu HP, 2012, SCI CHINA INFORM SCI, V55, P590, DOI 10.1007/s11432-011-4536-9
   Liu Q., 2019, ARXIV190603568
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Liu YX, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P398, DOI 10.1109/ICInfA.2017.8078941
   Luo CW, 2019, INFRARED PHYS TECHN, V99, P265, DOI 10.1016/j.infrared.2019.04.017
   Pan GZ, 2019, NEUROCOMPUTING, V358, P33, DOI 10.1016/j.neucom.2019.05.033
   Petersen K. B., 2008, THE MATRIX COOKBOOK, V7, P510
   Qian XY, 2018, SIGNAL PROCESS-IMAGE, V60, P183, DOI 10.1016/j.image.2017.09.001
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Xu X, 2011, 2011 INTERNATIONAL CONFERENCE ON FUTURE COMPUTER SCIENCE AND APPLICATION (FCSA 2011), VOL 3, P1
   Yan BC, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102603
   Yun X, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/2437521
   Zhai SL, 2019, NEUROCOMPUTING, V334, P172, DOI 10.1016/j.neucom.2019.01.022
   Zhang XC, 2019, IEEE ACCESS, V7, P122122, DOI 10.1109/ACCESS.2019.2936914
   Zhou TX, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/1605959
NR 39
TC 19
Z9 21
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102881
DI 10.1016/j.jvcir.2020.102881
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400009
DA 2024-07-18
ER

PT J
AU Yuan, D
   Shu, X
   He, ZY
AF Yuan, Di
   Shu, Xiu
   He, Zhenyu
TI TRBACF: Learning temporal regularized correlation filters for high
   performance online visual object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Correlation filters; BACF tracker; Temporal
   regularization; ADMM
ID NETWORKS; MODEL
AB Correlation filter-based trackers (CFTs) have recently shown remarkable performance in the field of visual object tracking. The advantage of these trackers originates from their ability to convert time-domain calculations into frequency domain calculations. However, a significant problem of these CFTs is that the model is insufficiently robust when the tracking scenarios are too complicated, meaning that the ideal tracking performance cannot be acquired. Recent work has attempted to resolve this problem by reducing the boundary effects from modeling the foreground and background of the object target effectively (e.g., CFLB, BACF, and CACF). Although these methods have demonstrated reasonable performance, they are often affected by occlusion, deformation, scale variation, and other challenging scenes. In this study, considering the relationship between the current frame and the previous frame of a moving object target in a time series, we propose a temporal regularization strategy to improve the BACF tracker (denoted as TRBACF), a typical representative of the aforementioned trackers. The TRBACF tracker can efficiently adjust the model to adapt the change of the tracking scenes, thereby enhancing its robustness and accuracy. Moreover, the objective function of our TRBACF tracker can be solved by an improved alternating direction method of multipliers, which can speed up the calculation in the Fourier domain. Extensive experimental results demonstrate that the proposed TRBACF tracker achieves competitive tracking performance compared with state-of-the-art trackers.
C1 [Yuan, Di; He, Zhenyu] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen 518055, Peoples R China.
   [Shu, Xiu] Harbin Inst Technol, Sch Sci, Shenzhen 518055, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP He, ZY (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen 518055, Peoples R China.
EM dyuanhit@gmail.com; shuxiuhit@gmail.com; zhenyuhe@hit.edu
RI Yuan, Di/Q-6521-2019; Shu, Xiu/HNP-8892-2023
OI Yuan, Di/0000-0001-9403-1112; 
FU National Natural Science Foundation of China [61672183]; Shenzhen
   Research Council [JCYJ20170413104556946, JCYJ20170815113552036]; China
   Scholarship Council (CSC)
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61672183), by the Shenzhen Research Council (Grant No.
   JCYJ20170413104556946, JCYJ20170815113552036). Di Yuan is supported by a
   scholarship from China Scholarship Council (CSC).
CR [Anonymous], 2014, BMVC, DOI DOI 10.5244/C.28.56
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cao Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102635
   Cehovin L, 2014, IEEE WINT CONF APPL, P540, DOI 10.1109/WACV.2014.6836055
   Chen K, 2019, IEEE T MULTIMEDIA, V21, P86, DOI 10.1109/TMM.2018.2846405
   Cheng X, 2017, IEEE T SYST MAN CY-S, V47, P628, DOI 10.1109/TSMC.2016.2618749
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dong W, 2010, ASIA-PACIFIC YOUTH CONFERENCE ON COMMUNICATION TECHNOLOGY 2010 (APYCCT 2010), P154
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Gan WH, 2018, J VIS COMMUN IMAGE R, V53, P180, DOI 10.1016/j.jvcir.2018.03.016
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu Q, 2020, IEEE T MULTIMEDIA, V22, P666, DOI 10.1109/TMM.2019.2932615
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lu Allen, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P323, DOI 10.1007/978-3-319-66185-8_37
   Lu A., 2017, SPIE MED IMAGING, DOI [10.13904., DOI 10.13904.]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   O'Shea TP, 2016, MED PHYS, V43, P455, DOI 10.1118/1.4938582
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Simonyan K., 2014, CORR
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Teng Z, 2017, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2017.130
   Tian CW, 2020, NEURAL NETWORKS, V124, P117, DOI 10.1016/j.neunet.2019.12.024
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wen LY, 2014, IEEE T IMAGE PROCESS, V23, P785, DOI 10.1109/TIP.2013.2293430
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu JH, 2019, J VIS COMMUN IMAGE R, V62, P182, DOI 10.1016/j.jvcir.2019.05.014
   Yan BC, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102603
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105554
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
   Yuan D, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105697
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P27271, DOI 10.1007/s11042-019-07828-2
   Yuan D, 2019, MULTIMED TOOLS APPL, V78, P14277, DOI 10.1007/s11042-018-6800-0
   Zhang HY, 2018, J VIS COMMUN IMAGE R, V56, P1, DOI 10.1016/j.jvcir.2018.08.018
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang MD, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P595, DOI 10.1109/ICCVW.2015.81
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
NR 64
TC 28
Z9 30
U1 1
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102882
DI 10.1016/j.jvcir.2020.102882
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400010
DA 2024-07-18
ER

PT J
AU Guo, BY
   Song, KC
   Dong, HW
   Yan, YH
   Tu, ZB
   Zhu, L
AF Guo, Bingyang
   Song, Kechen
   Dong, Hongwen
   Yan, Yunhui
   Tu, Zhibiao
   Zhu, Liu
TI NERNet: Noise estimation and removal network for image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Convolutional neural networks; Attention mechanism;
   Dilated convolution; Dilation rate selecting
AB While some denoising methods based on deep learning achieve superior results on synthetic noise, they are far from dealing with photographs corrupted by realistic noise. Denoising on real-world noisy images faces more significant challenges due to the source of it is more complicated than synthetic noise. To address this issue, we propose a novel network including noise estimation module and removal module (NERNet). The noise estimation module automatically estimates the noise level map corresponding to the information extracted by symmetric dilated block and pyramid feature fusion block. The removal module focuses on removing the noise from the noisy input with the help of the estimated noise level map. Dilation selective block with attention mechanism in the removal module adaptively not only fuses features from convolution layers with different dilation rates, but also aggregates the global and local information, which is benefit to preserving more details and textures. Experiments on two datasets of synthetic noise and three datasets of realistic noise show that NERNet achieves competitive results in comparison with other state-of-the-art methods. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Guo, Bingyang; Song, Kechen; Dong, Hongwen; Yan, Yunhui] Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
   [Guo, Bingyang; Song, Kechen; Dong, Hongwen; Yan, Yunhui] Energy Saving Met Equipment & Intelligent Detect, Shenyang, Liaoning, Peoples R China.
   [Tu, Zhibiao; Zhu, Liu] Taizhou Univ, Taizhou, Zhejiang, Peoples R China.
C3 Northeastern University - China; Taizhou University
RP Song, KC; Yan, YH (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
EM songkc@me.neu.edu.cn; yanyh@mail.neu.edu.cn
RI Yan, Yunhui/HDL-7343-2022; Song, Kechen/T-1896-2019; Guo,
   Bingyang/GRX-0895-2022; Guo, Bingyang/GWC-9196-2022
OI Yan, Yunhui/0000-0001-7121-2367; Song, Kechen/0000-0002-7636-3460; Guo,
   Bingyang/0000-0002-6630-0044
FU National Natural Science Foundation of China [51805078]; National Key
   Research and Development Program of China [2017YFB0304200]; Fundamental
   Research Funds for the Central Universities [N2003021]; Taizhou Science
   and Technology Planning Project [1902GY09]
FX This work is supported by the National Natural Science Foundation of
   China (51805078), the National Key Research and Development Program of
   China (2017YFB0304200), the Fundamental Research Funds for the Central
   Universities (N2003021), Taizhou Science and Technology Planning Project
   (1902GY09).
CR Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182
   Anaya J, 2018, J VIS COMMUN IMAGE R, V51, P144, DOI 10.1016/j.jvcir.2018.01.012
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2016, INT C LEARNING REPRE
   Ben Hamza A, 2001, IEEE T SIGNAL PROCES, V49, P3045, DOI 10.1109/78.969512
   Benesty J, 2010, INT CONF ACOUST SPEE, P205, DOI 10.1109/ICASSP.2010.5496033
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   Cui ZX, 2017, J VIS COMMUN IMAGE R, V43, P30, DOI 10.1016/j.jvcir.2016.12.009
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Drineas P, 2005, J MACH LEARN RES, V6, P2153
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang KQ, 2005, SIGNAL PROCESS-IMAGE, V20, P115, DOI 10.1016/j.image.2004.08.002
   Jia XX, 2019, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2019.00621
   Lebrun M, 2014, IEEE IMAGE PROC, P2674, DOI 10.1109/ICIP.2014.7025541
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Li WJ, 2019, J VIS COMMUN IMAGE R, V62, P226, DOI 10.1016/j.jvcir.2019.05.008
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu J, 2017, SIGNAL PROCESS-IMAGE, V57, P33, DOI 10.1016/j.image.2017.05.001
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Liu YX, 2014, J VIS COMMUN IMAGE R, V25, P1006, DOI 10.1016/j.jvcir.2014.02.018
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mao X., 2016, ADV NEUR IN, V29
   Nam S, 2016, PROC CVPR IEEE, P1683, DOI 10.1109/CVPR.2016.186
   Niu Y, 2012, J VIS COMMUN IMAGE R, V23, P1144, DOI 10.1016/j.jvcir.2012.07.001
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Shi WZ, 2019, SIGNAL PROCESS-IMAGE, V76, P243, DOI 10.1016/j.image.2019.05.007
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1211, DOI 10.1007/s11760-012-0389-y
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   YANG RK, 1995, IEEE T SIGNAL PROCES, V43, P591, DOI 10.1109/78.370615
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 42
TC 17
Z9 17
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102851
DI 10.1016/j.jvcir.2020.102851
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400003
DA 2024-07-18
ER

PT J
AU Liu, ZM
   Peng, YX
   Hu, WJ
AF Liu, Zhongmin
   Peng, Yuxi
   Hu, Wenjin
TI Driver fatigue detection based on deeply-learned facial expression
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fatigue detection; MB-LBP; PERCLOS; Fuzzy reasoning
AB Driver fatigue detection is a significant application in smart cars. In order to improve the accuracy and timeliness of driver fatigue detection, a fatigue detection algorithm based on deeply-learned facial expression analysis is proposed. Specifically, the face key point detection model is first trained by multi block local binary patterns (MB-LBP) and Adaboost classifier. Subsequently, the eyes and mouth state are detected by using the trained model to detect the 24 facial features. Afterwards, we calculate the number of two parameters that can describe the driver's fatigue state and the proportion of the closed eye time within the unit time (PERCLOS) and yawning frequency. Finally, the fuzzy inference system is utilized to deduce the driver's fatigue state (normal, slight fatigue, severe fatigue). Experimental results show that the proposed algorithm can detect driver fatigue degree quickly and accurately. (c) 2019 Published by Elsevier Inc.
C1 [Liu, Zhongmin; Peng, Yuxi] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
   [Liu, Zhongmin; Peng, Yuxi] Lanzhou Univ Technol, Key Lab Gansu Adv Control Ind Proc, Lanzhou 730050, Peoples R China.
   [Liu, Zhongmin; Peng, Yuxi] Lanzhou Univ Technol, Natl Elect & Control Engn Expt Teaching Ctr, Lanzhou 730050, Peoples R China.
   [Hu, Wenjin] Northwest Minzu Univ, Coll Math & Comp Sci, Lanzhou 730000, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology;
   Lanzhou University of Technology; Northwest Minzu University
RP Liu, ZM (corresponding author), Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
EM shisl05@lut.edu.cn
FU Nature Science Foundation of China [61561042]
FX This work was supported in part by The Nature Science Foundation of
   China under Grant No. 61561042.
CR [白中浩 Bai Zhonghao], 2015, [仪器仪表学报, Chinese Journal of Scientific Instrument], V36, P768
   Cai ZB, 2016, MULTIMED TOOLS APPL, V75, P2393, DOI 10.1007/s11042-014-2411-6
   Cao Ying, 2013, Acta Automatica Sinica, V39, P745
   Chang Zheng, 2016, Journal of China Universities of Posts and Telecommunications, V23, P91, DOI 10.1016/S1005-8885(16)60050-X
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Li Wei, 2010, Journal of Shanghai Jiaotong University, V44, P292
   Mohammad F., 2017, COMPUT BIOL MED, P89
   [牛清宁 Niu Qingning], 2015, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V36, P394
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Trutschel U., 2011, Proceedings of the Sixth International Driving Symposium on Human Factors in Driver Assessment, Training and Vehicle Design, P172, DOI [10.17077/drivingassessment.1394, DOI 10.17077/DRIVINGASSESSMENT.1394]
   Viola P., RAPID OBJECT DETECTI
   [王斐 Wang Fei], 2014, [仪器仪表学报, Chinese Journal of Scientific Instrument], V35, P398
   [王琳 Wang Lin], 2018, [汽车工程, Automotive Engineering], V40, P333
   [王庆伟 Wang Qingwei], 2015, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V28, P35
   Xu ML, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3200491
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   [张旭 Zhang Xu], 2012, [自动化学报, Acta Automatica Sinica], V38, P2014
   Zhou Yunpeng, 2014, J ELECT MEAS INSTRUM
   Zutao Zhang, 2010, Journal of Control Theory and Applications, V8, P181, DOI 10.1007/s11768-010-8043-0
NR 21
TC 43
Z9 44
U1 13
U2 132
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102723
DI 10.1016/j.jvcir.2019.102723
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900007
DA 2024-07-18
ER

PT J
AU Xiao, JH
   Cui, XH
   Li, F
AF Xiao, Jihai
   Cui, Xiaohong
   Li, Feng
TI Human action recognition based on convolutional neural network and
   spatial pyramid representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Spatial pyramid; Convolution neural networks;
   Cosine distance measure
ID TRACKING
AB Detecting and recognizing human action in natural scenarios, such as indoor and outdoor, is a significant technique in computer vision and intelligent systems, which is widely applied in video surveillance, pedestrian tracking and human-computer interaction. Conventional approaches have been proposed based on various features and achieved impressive performance. However, these methods failed to cope with partial occlusion and changes of posture. In order to address these limitations, we propose a novel human action recognition method. More specifically, in order to capture image spatial composition, we leverage a three-level spatial pyramid feature extraction scheme, where each pyramid is encoded by local features. Thereafter, regions generated by a proposal algorithm are fed into a dual-aggregation net for deep representation extraction. Afterwards, both local features and deep features are fused to describe each image. To describe human action category, we design a metric CXQDA based on Cosine measure and Cross-view Quadratic Discriminant Analysis (XQDA) to calculate the similarity among different action categories. Experimental results demonstrate that our proposed method can effectively cope with object scale variations, partial occlusion and achieve competitive performance. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Xiao, Jihai; Cui, Xiaohong] Tai Yuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Shanxi, Peoples R China.
   [Li, Feng] Tai Yuan Univ Technol, Natl Demonstrat Ctr Expt Designing Art Educ, Jinzhong 030600, Shanxi, Peoples R China.
RP Cui, XH (corresponding author), Tai Yuan Univ Technol, Coll Informat & Comp, Jinzhong 030600, Shanxi, Peoples R China.
EM xiaojihai@tyut.edu.cn; tycuixiaohong@126.com; lifeng0l@tyut.edu.cn
CR [Anonymous], 2008, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2012, COMP VIS PATT REC WO
   [Anonymous], 2010, ECCV
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 1999, ICCV
   [Anonymous], 2007 IEEE COMP SOC C
   [Anonymous], 2011, ICCV
   Boyle M., 2001, EFFECTS CAPTURE COND
   Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396
   Harada T., 2011, 24 IEEE C COMP VIS P
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Ikizler-Cinbis N., 2010, COMPUTER VISION ECCV
   Jiang YG, 2015, IEEE T IMAGE PROCESS, V24, P3781, DOI 10.1109/TIP.2015.2456412
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kovashka A., 2010, 23 IEEE C COMP VIS P
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Maletic N., 2018, 2018 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB), P1
   Park S, 2006, COMPUT VIS IMAGE UND, V102, P1, DOI 10.1016/j.cviu.2005.07.011
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Schmid C., 2012, 2012 IEEE C COMP VIS
   Song S., 2016, END TO END SPATIOTEM
   Wang HZ, 2007, PATTERN RECOGN, V40, P1091, DOI 10.1016/j.patcog.2006.05.024
   Wang Y., 2009, MAX MARGIN HIDDEN CO
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
NR 30
TC 6
Z9 7
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102722
DI 10.1016/j.jvcir.2019.102722
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900018
DA 2024-07-18
ER

PT J
AU Liu, YQ
   Yu, HH
   Gong, CY
   Chen, YY
AF Liu, Yeqi
   Yu, Huihui
   Gong, Chuanyang
   Chen, Yingyi
TI A real time expert system for anomaly detection of aerators based on
   computer vision and surveillance cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Surveillance camera; Anomaly detection; Optical flow;
   Object region detection; Application
ID MODEL
AB Aerators are essential and crucial auxiliary devices in intensive culture, especially in industrial culture in China. In this paper, we propose a real-time expert system for anomaly detection of aerators based on computer vision technology and existing surveillance cameras. The expert system includes two modules, i.e., object region detection and working state detection. First, we present a small object region detection method based on the region proposal idea. Moreover, we propose a novel algorithm called reference frame Kanade-Lucas-Tomasi (RF-KLT) algorithm for motion feature extraction in fixed regions. Then, we describe a dimension reduction method of time series for establishing a feature dataset with obvious boundaries between classes. Finally, we use machine learning algorithms to build the feature classifier. The proposed expert system can realize real-time, robust and cost-free anomaly detection of aerators in both the actual video dataset and the augmented video dataset. Demo is available at https://youtu.be/xThHRwu_cnl. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Liu, Yeqi; Gong, Chuanyang; Chen, Yingyi] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Yu, Huihui] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing 100091, Peoples R China.
   [Liu, Yeqi; Gong, Chuanyang; Chen, Yingyi] Minist Agr, Key Lab Agr Informat Acquisit Technol, Beijing 100083, Peoples R China.
   [Liu, Yeqi; Gong, Chuanyang; Chen, Yingyi] Beijing Engn & Technol Res Ctr Internet Things Ag, Beijing 100083, Peoples R China.
   [Chen, Yingyi] China Agr Univ, Natl Innovat Ctr Digital Fishery, Beijing 100083, Peoples R China.
C3 China Agricultural University; Beijing Forestry University; Ministry of
   Agriculture & Rural Affairs; China Agricultural University
RP Chen, YY (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
EM liuyeqi@cau.edu.cn; chenyingyi@cau.edu.cn
FU National Key R&D Program of China [2017YFE0122100]; Key R&D Program
   "Research and development of intelligent model and precise monitoring of
   shrimp processing" [2018YFD0700904-2]
FX This work is supported by the National Key R&D Program of China ``Next
   generation precision aquaculture: R&D on intelligent measurement,
   control and equipment technologies"(No. 2017YFE0122100), and the Key R&D
   Program "Research and development of intelligent model and precise
   monitoring of shrimp processing" (No. 2018YFD0700904-2).
CR Alalousi A., 2016, International Journal of Electrical and Computer Engineering, V6, P778
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 1994, P IEEE C COMP VIS PA
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], COMPUT SCI
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bardon-Albaret A, 2016, AQUACULTURE, V459, P148, DOI 10.1016/j.aquaculture.2016.03.042
   Bouguet J. Y., 1999, OPENCV DOCUMENTS, V22, P363
   CHEN Y, 2016, MATH PROBL ENG, V2016, P1, DOI DOI 10.1155/2016/6564202
   Chuang MC, 2017, IEEE T SYST MAN CY-S, V47, P2467, DOI 10.1109/TSMC.2016.2523943
   DiPietro Robert, 2017, ARXIV170207805
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He JZ, 2011, LECT NOTES COMPUT SC, V6897, P81, DOI 10.1007/978-3-642-23535-1_9
   Janai J, 2020, FOUND TRENDS COMPUT, V12, P1, DOI 10.1561/0600000079
   Jun G, 2008, IEEE WORK APP COMP, P165
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Khan MUK, 2019, IEEE T INF FOREN SEC, V14, P541, DOI 10.1109/TIFS.2018.2856189
   Kim HY, 2018, EXPERT SYST APPL, V103, P25, DOI 10.1016/j.eswa.2018.03.002
   Liang YX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3428
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu YQ, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113082
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Ma CongGuo Ma CongGuo, 2015, Transactions of the Chinese Society of Agricultural Engineering, V31, P193
   Murugan KHS, 2017, 2017 THIRD INTERNATIONAL CONFERENCE ON SCIENCE TECHNOLOGY ENGINEERING & MANAGEMENT (ICONSTEM), P863, DOI 10.1109/ICONSTEM.2017.8261326
   Qin Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2627
   Schmidt M., 2013, ARXIV13092388, V162, P1, DOI DOI 10.1007/978-1-4614-7320-6175-1
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Solstorm D, 2018, AQUACULTURE, V486, P122, DOI 10.1016/j.aquaculture.2017.12.008
   Székely GJ, 2005, J CLASSIF, V22, P151, DOI 10.1007/s00357-005-0012-9
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wadhai M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P544, DOI 10.1109/INFOP.2015.7489444
   Wäldchen J, 2018, ARCH COMPUT METHOD E, V25, P507, DOI 10.1007/s11831-016-9206-z
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Xu M, 2019, IEEE T CIRC SYST VID, V29, P3516, DOI [10.1109/TCSVT.2018.2886277, 10.1080/17445302.2018.1558727]
   Zhou TL, 2016, KNOWL-BASED SYST, V105, P214, DOI 10.1016/j.knosys.2016.05.031
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 48
TC 11
Z9 11
U1 1
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2020
VL 68
AR 102767
DI 10.1016/j.jvcir.2020.102767
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LO3GK
UT WOS:000533516900002
DA 2024-07-18
ER

PT J
AU Ma, W
   Zhang, XY
   Xin, Y
   Li, SZ
AF Ma, Wen
   Zhang, Xinyang
   Xin, Yong
   Li, Shenzhang
TI Study on short-term network forecasting based on SVM-MFA algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Support vector machine; Improved firefly algorithm; Load forecasting;
   Nonlinear regression; Evaluation criteria
ID SUPPORT VECTOR MACHINE; PARAMETERS; SELECTION
AB Accurate prediction of power supply load is vital in power industry, which provides economic operation decision for the power operation department. For the unpredictability and periodicity of power load, nonlinear intelligent forecasting method is adopted. A modified firefly algorithm (MFA) combined with support vector machine (SVM) is proposed to predict the load of power supply data in this paper. The nonlinear mapping function is used to deal with the nonlinear regression problem in SVM, in which the parameters affect the accuracy of load prediction, so the MFA method is adopted to optimized the parameters of SVM. In order to verify the accuracy of SVM-MFA, mean absolute percentage error (eMAPE) was used as the fitness function for simulation and comparison experiment. The results show that the SVM-MFA proposed in this paper has stronger global search ability and faster convergence rate than the traditional artificial neural network, and it is verified that the method proposed in this paper has higher accuracy and higher stability of network load prediction. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ma, Wen; Zhang, Xinyang; Li, Shenzhang] Yunnan Power Grid Co Ltd, Informat Ctr, Kunming 650217, Yunnan, Peoples R China.
   [Xin, Yong] State Grid Infotelecom Greate Power Sci & Technol, Fuzhou 350003, Fujian, Peoples R China.
C3 China Southern Power Grid
RP Ma, W (corresponding author), Yunnan Power Grid Co Ltd, Informat Ctr, Kunming 650217, Yunnan, Peoples R China.
CR Amari S, 1999, NEURAL NETWORKS, V12, P783, DOI 10.1016/S0893-6080(99)00032-5
   [Anonymous], INT J COMBINATORICS
   Cao LJ, 2003, IEEE T NEURAL NETWOR, V14, P1506, DOI 10.1109/TNN.2003.820556
   Cherkassky V, 2004, NEURAL NETWORKS, V17, P113, DOI 10.1016/S0893-6080(03)00169-2
   Drezga I, 1998, IEEE T POWER SYST, V13, P1238, DOI 10.1109/59.736244
   Guan C, 2013, IEEE T POWER SYST, V28, P3806, DOI 10.1109/TPWRS.2013.2264488
   Guo Ming-wei, 2014, Control and Decision, V29, P193
   Hong WC, 2007, WATER RESOUR MANAG, V21, P495, DOI 10.1007/s11269-006-9026-2
   Hong WC, 2009, INT J ELEC POWER, V31, P409, DOI 10.1016/j.ijepes.2009.03.020
   Li Wanhua, 2016, Computer Engineering and Applications, V52, P236, DOI 10.3778/j.issn.1002-8331.1606-0203
   MBAMALU GAN, 1993, IEEE T POWER SYST, V8, P343, DOI 10.1109/59.221222
   Niu D.X., 2010, J MULT-VALUED LOG S, P16
   Niu DX, 2010, EXPERT SYST APPL, V37, P2531, DOI 10.1016/j.eswa.2009.08.019
   Pai PF, 2005, OMEGA-INT J MANAGE S, V33, P497, DOI 10.1016/j.omega.2004.07.024
   SI WD, 2013, COMPUT ENG APPL, V4, DOI DOI 10.1038/NCOMMS2337
   [田梦楚 Tian Mengchu], 2016, [自动化学报, Acta Automatica Sinica], V42, P89
   Turkay B.E., 2011, EL EL ENG ELECO 2011
   Vapnik V., 1999, NATURE STAT LEARNING
   [王贺 Wang He], 2014, [电工技术学报, Transactions of China Electrotechnical Society], V29, P237
   Yalcinoz T, 2005, ENERG CONVERS MANAGE, V46, P1393, DOI 10.1016/j.enconman.2004.07.005
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Ying LC, 2008, ENERG CONVERS MANAGE, V49, P205, DOI 10.1016/j.enconman.2007.06.015
   Zhu Zhiyong, 2005, MICROCOMPUT APPL, V29, P60
NR 23
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102646
DI 10.1016/j.jvcir.2019.102646
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700008
DA 2024-07-18
ER

PT J
AU Song, XY
   Liu, B
   Huang, QJ
   Hu, RH
AF Song, Xiaoying
   Liu, Bing
   Huang, Qijun
   Hu, Ruihan
TI Design of high-resolution quantization scheme with exp-Golomb code
   applied to compression of special images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High-resolution quantization scheme; Adaptive quantizer; Exp-Golomb
   code; Medical image; Aerial image; Near-lossless compression
ID NEAR-LOSSLESS COMPRESSION; ALGORITHM
AB For the compression of special image, such as medical image and aerial image, the reconstructed image quality is of utmost importance in the performance analysis. In this paper, a high-resolution quantization scheme based on the exp-Golomb code is proposed, aiming at improving the reconstructed image quality and realizing high-resolution near-lossless compression. Rather than quantizing the whole image uniformly, which adopted by most popular quantization schemes, an adaptive quantizer with smaller distortion is designed. Both the quantization step size and the quantization proportion are determined adaptively. Compression algorithms based on our adaptive quantizer can provide better reconstructed image quality, and the high frequency information of the image, such as texture and edge, can be better preserved. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Song, Xiaoying; Liu, Bing] Wuhan Univ Sci & Technol, Engn Res Ctr Met Automat & Measurement Technol, Wuhan 430081, Hubei, Peoples R China.
   [Song, Xiaoying; Huang, Qijun; Hu, Ruihan] Wuhan Univ, Sch Phys & Technol, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University of Science & Technology; Wuhan University
RP Huang, QJ (corresponding author), Wuhan Univ, Sch Phys & Technol, Wuhan 430072, Hubei, Peoples R China.
EM xiaoying811@wust.edu.cn; liubing17@wust.edu.cn; huangqj@whu.edu.cn;
   2014202020060@whu.edu.cn
FU National Natural Science Foundation of China [61471275, 61625305,
   61801338]
FX This work was supported by the National Natural Science Foundation of
   China (grants 61471275, 61625305 and 61801338).
CR Aiazzi B, 2002, IEEE SIGNAL PROC LET, V9, P77, DOI 10.1109/97.995822
   Aràndiga F, 2013, J COMPUT APPL MATH, V242, P70, DOI 10.1016/j.cam.2012.10.028
   Caldelli R, 2006, SIGNAL PROCESS-IMAGE, V21, P890, DOI 10.1016/j.image.2006.08.006
   Carvajal G, 2008, IEEE GEOSCI REMOTE S, V5, P593, DOI 10.1109/LGRS.2008.2000651
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   CHEN KS, 1994, IEEE T MED IMAGING, V13, P538, DOI 10.1109/42.310885
   Dauwels J, 2013, IEEE J BIOMED HEALTH, V17, P708, DOI 10.1109/TITB.2012.2230012
   Ding JJ, 2013, IEEE T CIRC SYST VID, V23, P661, DOI 10.1109/TCSVT.2012.2211952
   Fujiyoshi M, 2015, LECT NOTES COMPUT SC, V9315, P225, DOI 10.1007/978-3-319-24078-7_22
   Louie H, 2012, IEEE T SUSTAIN ENERG, V3, P598, DOI 10.1109/TSTE.2012.2195039
   Nargundmath S, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED NANOMATERIALS AND EMERGING ENGINEERING TECHNOLOGIES (ICANMEET), P607, DOI 10.1109/ICANMEET.2013.6609386
   Rad RM, 2013, MULTIMEDIA SYST, V19, P103, DOI 10.1007/s00530-012-0282-0
   Ramírez I, 2015, LECT NOTES COMPUT SC, V9423, P400, DOI 10.1007/978-3-319-25751-8_48
   Savic MS, 2015, EXPERT SYST APPL, V42, P7285, DOI 10.1016/j.eswa.2015.05.037
   Sepehrband F, 2011, 2011 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING (PACRIM), P66, DOI 10.1109/PACRIM.2011.6032869
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Starosolski R., 2005, MED IMAGING INT SOC, V5959
   Starosolski R, 2007, SOFTWARE PRACT EXPER, V37, P65, DOI 10.1002/spe.746
   Taquet J, 2012, IEEE T IMAGE PROCESS, V21, P2641, DOI 10.1109/TIP.2012.2186147
   Ulacha G, 2011, J INF SCI ENG, V27, P621
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yea S, 2006, IEEE T IMAGE PROCESS, V15, P3488, DOI 10.1109/TIP.2006.877525
NR 23
TC 4
Z9 4
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102684
DI 10.1016/j.jvcir.2019.102684
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700028
DA 2024-07-18
ER

PT J
AU Hou, R
   Zhao, YH
   Tian, SM
   Yang, Y
   Yang, WH
AF Hou Rui
   Zhao Yunhao
   Tian Shiming
   Yang Yang
   Yang Wenhai
TI Fault point detection of IOT using multi-spectral image fusion based on
   deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolution neural network; IoT fault point detection; Deep learning;
   Multi-spectral image fusion
ID OBJECT DETECTION; IDENTIFICATION; SYSTEM
AB Internet of Things (IoT) is widely applied in modern power systems, which could establish the intelligent power grid systems and obtain considerable social and economic benefits. IoT plays an important role in power grid safety production, user interaction, and information collection. However, existing methods cannot address problems of IoT devices accurately and quickly, such as fault detection. Aiming at the shortcomings of current power IoT equipment fault detection methods, this paper proposes a multi-spectral image fusion based on deep learning to detect fault points of power IoT equipment. The deep convolutional neural network is trained by simulating the image of the power device. The results show that the multi-spectral image descriptor based on deep learning presented in this paper shows very high accuracy in block matching, and the effect of image fusion is remarkable. This indicates that the proposed method can accurately integrate multi-spectral images of power equipment, helping to locate fault points quickly and accurately. (C) 2019 Published by Elsevier Inc.
C1 [Hou Rui; Zhao Yunhao] North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
   [Hou Rui; Zhao Yunhao] North China Elect Power Univ, Res Ctr Energy Network, Beijing 102206, Peoples R China.
   [Tian Shiming] China Elect Power Res Inst, Beijing 100192, Peoples R China.
   [Yang Yang] State Grid Hebei Econ Res Inst, Shijiazhuang 050021, Hebei, Peoples R China.
   [Yang Wenhai] China Huaneng Grp CO LTD, Beijing 100031, Peoples R China.
C3 North China Electric Power University; North China Electric Power
   University
RP Zhao, YH (corresponding author), North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
EM yunhzhao@126.com; laotian@epri.sgcc.com.cn
FU National Key RD Plan [2018YFB0605504]; Fundamental Research Funds for
   the Central Universities
FX Supported by "National Key R&D Plan": 2018YFB0605504.; Supported by "the
   Fundamental Research Funds for the Central Universities".
CR An Ming, 2018, CHINA MARKET, V4, P136
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Chang J., 2018, J VISUAL COMMUN IMAG
   Chen Qingjiang, 2018, J APPL OPT, V39, P69
   Chen Ying, 2018, J JIANGSU NORMAL U N, V36, P56
   Chen Zhenxiao, 2018, AUTOM TECHNOL APPL, V37, P63
   Cui Weiyang, 2018, INTERNET THINGS TECH, V1, P42
   Fontes CH, 2016, ENG APPL ARTIF INTEL, V49, P10, DOI 10.1016/j.engappai.2015.11.005
   Gao Fan, 2018, AUTOM INSTRUMENT, V39, P8
   Guo YB, 2017, ENERG BUILDINGS, V142, P167, DOI 10.1016/j.enbuild.2017.03.026
   Han Jun, 2017, SHIP SCI TECHNOL, V18, P139
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han Lijing, 2018, J KUNMING U, V40, P76
   Han Ze, 2018, TEST TECHNOL, V32, P23
   He Tongdi, 2017, MEASURE CONTR TECHNO, V36, P19
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Li Chuanyu, 2017, EQUIP MANAGE MAINTEN, V4, P101
   Li G, 2015, ADV DIFFER EQU-NY, DOI 10.1186/s13662-014-0342-1
   [李红 Li Hong], 2016, [计算机学报, Chinese Journal of Computers], V39, P1583
   Li XY, 2015, J NONLINEAR SCI APPL, V8, P496, DOI 10.22436/jnsa.008.05.05
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Lin Suzhen, 2017, CHIN J COMP, V11, P76
   Liu F, 2015, J APPL ANAL COMPUT, V5, P527
   Liu Wei, 2017, CHINA PETROL PETROCH, V4, P151
   López D, 2019, ARTIF INTELL REV, V52, P169, DOI 10.1007/s10462-017-9600-4
   Lu Sun Chao, 2019, ACTA OPTICA SINICA, V37
   Pignati M, 2017, IEEE T POWER DELIVER, V32, P381, DOI 10.1109/TPWRD.2016.2545923
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Qi Can, 2018, POWER SYSTEM PROTECT, V46, P141
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Shen Xin, 2016, CHINA SO POWER GRID, V10, P48
   Sica FC, 2015, ELECTR POW SYST RES, V127, P109, DOI 10.1016/j.epsr.2015.05.014
   Wang Qin, 2018, ELECT APPAR ENERGY E, V7, P56
   Wang Xi, 2017, AGR TECHNOL EQUIPM, V336, P90
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   XU ML, 2016, ACM T GRAPHIC, V35, P6, DOI DOI 10.1145/2980179.2982425
   Xu XX, 2015, APPL MATH COMPUT, V251, P275, DOI 10.1016/j.amc.2014.11.063
   [杨红菊 Yang Hongju], 2018, [山西大学学报. 自然科学版, Journal of Shanxi University. Natural Science Edition], V41, P114
   Yuan Yuxin, 2017, J COMP APPL SOFTW, V34, P183
   Zhang M., 2018, J VIS COMMUN IMAGE R, P53
   Zhi Shanshan, 2018, INFORM SYST ENG, P169
   Zhou Jie, 2018, SENSORS MICROSYST, V37
NR 48
TC 8
Z9 8
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102600
DI 10.1016/j.jvcir.2019.102600
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600003
DA 2024-07-18
ER

PT J
AU Yan, BC
   Xiao, LM
   Zhang, H
   Xu, DL
   Ruan, L
   Wang, ZK
   Zhang, YY
AF Yan, Baicheng
   Xiao, Limin
   Zhang, Hang
   Xu, Daliang
   Ruan, Li
   Wang, Zhaokai
   Zhang, Yiyang
TI An adaptive template matching-based single object tracking algorithm
   with parallel acceleration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual object tracking; Adaptive template update; Parallel acceleration;
   Deep learning; Embedded platform
ID CAROTID-ARTERY WALL; MEAN-SHIFT; ROBUST ESTIMATION; FILTERS
AB Existing template matching based visual object tracking algorithms usually require to manually update the template and have high execution cost on general embedded systems. To address these issues, an adaptive template matching-based single object tracking algorithm with parallel acceleration is proposed in this paper. In this algorithm, we propose an adaptive single object tracking algorithm framework to achieve template update online. Based on the Faster-RCNN model, we design a single object capture method to update the template. Meanwhile, we present a parallel strategy to accelerate the process of template matching. To evaluate the proposed algorithm, we use OTB benchmark to compare the performance with several state-of-the-art trackers on TX2 embedded platform. Experimental results show that the proposed method achieves a 5.9 times execution speed and 71.9% accuracy improvement over the comparison methods. (C) 2019 Published by Elsevier Inc.
C1 [Yan, Baicheng; Xiao, Limin; Ruan, Li; Wang, Zhaokai; Zhang, Yiyang] Beihang Univ, Sch Comp Sci & Engn, XueYuan Rd 37, Beijing 100191, Peoples R China.
   [Zhang, Hang] Sci & Technol Complex Syst Control & Intelligent, Beijing, Peoples R China.
   [Xu, Daliang] Peking Univ, Sch Elect Engn & Comp Sci, 5 Yiheyuan Rd, Beijing 10087, Peoples R China.
C3 Beihang University; Peking University
RP Xiao, LM (corresponding author), Beihang Univ, Sch Comp Sci & Engn, XueYuan Rd 37, Beijing 100191, Peoples R China.; Zhang, H (corresponding author), Sci & Technol Complex Syst Control & Intelligent, Beijing, Peoples R China.
EM xiaolm@buaa.edu.cn; zhanghang90@mail.nwpu.edu.cn
RI Li, Fan/JRY-4017-2023; Li, Nan/IXD-8260-2023; wu, jun/ISB-8607-2023;
   Yan, Baicheng/V-8152-2019
FU National Key R&D Program of China [2017YFB0202004]; Science Challenge
   Project [TZ2016002]; National Natural Science Foundation of China
   [61772053]
FX This work described in this paper is supported by the National Key R&D
   Program of China under Grant No. 2017YFB0202004, Science Challenge
   Project, No. TZ2016002, the National Natural Science Foundation of China
   under Grant No. 61772053. The final version has benefited greatly form
   the many detailed comments and suggestions from the selfless reviewers.
CR Ahmed J, 2008, MACH VISION APPL, V19, P1, DOI 10.1007/s00138-007-0072-4
   Ali A, 2016, FRONT COMPUT SCI-CHI, V10, P167, DOI 10.1007/s11704-015-4246-3
   Amiri M, 2010, PATTERN RECOGN, V43, P2485, DOI 10.1016/j.patcog.2009.12.014
   [Anonymous], OPTICAL ENG
   [Anonymous], CIRC SYST LASCAS 201
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baggio D., 2017, MASTERING OPENCV 3
   Barrena N, 2018, MACH VISION APPL, V29, P573, DOI 10.1007/s00138-018-0914-2
   Beleznai C, 2005, INT C IM PROC SING, V1, P349
   Beleznai C., 2005, IEEE INT WORKSH VIS, P25
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boykov Y, 2000, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.2000.854942
   BROIDA TJ, 1986, IEEE T PATTERN ANAL, V8, P90, DOI 10.1109/TPAMI.1986.4767755
   Brookner E., 1998, Tracking and Kalman filtering made easy, DOI DOI 10.1002/0471224197
   Cabido R, 2012, J VIS COMMUN IMAGE R, V23, P271, DOI 10.1016/j.jvcir.2011.10.005
   Cabido R, 2009, 2009 10TH INTERNATIONAL SYMPOSIUM ON PERVASIVE SYSTEMS, ALGORITHMS, AND NETWORKS (ISPAN 2009), P757, DOI 10.1109/I-SPAN.2009.94
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Chien SI, 2000, PATTERN RECOGN, V33, P237, DOI 10.1016/S0031-3203(99)00056-4
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dailey D. J., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P98, DOI 10.1109/6979.880967
   Desoer C. A., 1975, Feedback Systems: Input-Output Properties
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gao ZF, 2018, IEEE T MED IMAGING, V37, P273, DOI 10.1109/TMI.2017.2746879
   Gao ZF, 2017, MED IMAGE ANAL, V37, P1, DOI 10.1016/j.media.2017.01.004
   GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Green M., 1995, LINEAR ROBUST CONTRO
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hero AO, 2002, IEEE SIGNAL PROC MAG, V19, P85, DOI 10.1109/MSP.2002.1028355
   Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908
   Hisham MB, 2015, IEEE ST CONF RES DEV, P100, DOI 10.1109/SCORED.2015.7449303
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Hu WM, 2015, IEEE T PATTERN ANAL, V37, P816, DOI 10.1109/TPAMI.2014.2353628
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163
   Li BX, 2001, IEEE T IMAGE PROCESS, V10, P897, DOI 10.1109/83.923286
   Li PH, 2012, J SIGNAL PROCESS SYS, V68, P317, DOI 10.1007/s11265-011-0620-z
   Li ZY, 2017, J VIS COMMUN IMAGE R, V44, P1, DOI [10.1016/j.jvcir.2017.01.012, 10.16339/j.cnki.hdxbzkb.2017.11.001]
   Lu XH, 2016, INT C CLOUD COMP BIG, P243, DOI [10.1109/CCBD.2016.18, 10.1109/CCBD.2016.055]
   Machhale K. S., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P194, DOI 10.1109/CSNT.2012.49
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rout L, 2018, IEEE WINT CONF APPL, P1047, DOI 10.1109/WACV.2018.00120
   Shan CF, 2007, PATTERN RECOGN, V40, P1958, DOI 10.1016/j.patcog.2006.12.012
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Steinbring J, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1038
   Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012
   Vladimir T, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P212, DOI 10.1109/IMIS.2013.43
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xing X., 2016, 2016 10 INT S COMM S, P1
   Yang C, 2005, PROC CVPR IEEE, P176
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Yu Q, 2008, LECT NOTES COMPUT SC, V5303, P678
   Zhang D., 2017, ABS170108936 CORR
   Zhang X, 2018, ISPRS J PHOTOGRAMM, V140, P77, DOI 10.1016/j.isprsjprs.2017.07.009
   Zhou HY, 2009, PATTERN RECOGN LETT, V30, P98, DOI 10.1016/j.patrec.2008.02.027
NR 74
TC 14
Z9 14
U1 1
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102603
DI 10.1016/j.jvcir.2019.102603
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600005
DA 2024-07-18
ER

PT J
AU Tian, S
   Zou, L
   Fan, CA
   Chen, LQ
AF Tian, Sheng
   Zou, Lian
   Fan, Cian
   Chen, Liqiong
TI Weighted correlation filters guidance with spatial-temporal attention
   for online multi-object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-object tracking; Weighted correlation filters; Tracking by
   detection; Spatial-temporal attention mechanism
ID MULTIPLE OBJECT TRACKING
AB In recent years, discriminative correlation filters based trackers have made remarkable achievements for single object tracking, while directly applying these trackers for multi-object tracking may encounter some problem in drifted results caused by occlusion and missing detection from the detector. Thus, we propose a weighted-correlation-filters framework with spatial-temporal attention mechanism for online multi-object tracking to solve the above problems. First, we use the weighted correlation filters with dynamic updating scheme to pre-track each object in the current frame, which helps to filter out the improper detection according to the position of pre-tack for each object and is capable of tracking objects of the false negative. Then, we introduce a spatial-temporal attention mechanism to produce a discriminative appearance model and calculate reliable similarity scores for data association. The proposed online algorithm achieves 48.4% in MOTA on challenging MOT17 benchmark dataset and better performance on MT and ML than some offline methods. (C) 2019 Published by Elsevier Inc.
C1 [Tian, Sheng; Zou, Lian; Fan, Cian; Chen, Liqiong] Wuhan Univ, Elect Informat Sch, Wuhan, Hubei, Peoples R China.
C3 Wuhan University
RP Zou, L (corresponding author), Wuhan Univ, Elect Informat Sch, Wuhan, Hubei, Peoples R China.
EM zoulian@whu.edu.cn
CR [Anonymous], 2017, 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], IEEE T PATTERN ANAL
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Choi WG, 2015, IEEE I CONF COMP VIS, P3029, DOI 10.1109/ICCV.2015.347
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Eiselein V, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P325, DOI 10.1109/AVSS.2012.59
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720
   Ess A, 2008, PROC CVPR IEEE, P1857
   Ess A, 2010, INT J ROBOT RES, V29, P1707, DOI 10.1177/0278364910365417
   Fu ZY, 2018, IEEE ACCESS, V6, P14764, DOI 10.1109/ACCESS.2018.2816805
   Gan WH, 2018, SIGNAL PROCESS-IMAGE, V66, P95, DOI 10.1016/j.image.2018.05.008
   He ZQ, 2017, IEEE INT CONF COMP V, P1992, DOI 10.1109/ICCVW.2017.233
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Henschel R, 2018, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2018.00192
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ji ZJ, 2018, J VIS COMMUN IMAGE R, V55, P354, DOI 10.1016/j.jvcir.2018.06.017
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kim C., 2018, EUR C COMP VIS ECCV
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Lee S, 2019, IEEE ACCESS, V7, P8181, DOI 10.1109/ACCESS.2018.2889442
   Li K, 2008, MED IMAGE ANAL, V12, P546, DOI 10.1016/j.media.2008.06.001
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242
   Luo WH, 2014, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2014.168
   Luo Wenhan., 2014, Multiple object tracking: A literature review
   Makino H, 2015, NAT NEUROSCI, V18, P1116, DOI 10.1038/nn.4061
   Manafifard M, 2017, SIGNAL PROCESS-IMAGE, V55, P157, DOI 10.1016/j.image.2017.04.001
   Meijering E, 2009, SEMIN CELL DEV BIOL, V20, P894, DOI 10.1016/j.semcdb.2009.07.004
   Milan A., 2016, MOT16 BENCHMARK MULT
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Petrovskaya A, 2009, AUTON ROBOT, V26, P123, DOI 10.1007/s10514-009-9115-1
   Rapuru MK, 2017, IEEE T IMAGE PROCESS, V26, P4832, DOI 10.1109/TIP.2017.2699791
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   Yang B, 2011, PROC CVPR IEEE, P1233, DOI 10.1109/CVPR.2011.5995587
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
   Zhu Z, 2017, IEEE INT CONF COMP V, P1973, DOI 10.1109/ICCVW.2017.231
NR 63
TC 5
Z9 5
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102576
DI 10.1016/j.jvcir.2019.102576
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200015
DA 2024-07-18
ER

PT J
AU Arige, A
   Mitrea, M
   Boujelbane, I
AF Arige, A.
   Mitrea, M.
   Boujelbane, I.
TI HEVC intra-frame drift cancellation matrix
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Additive modification; Intra-drift free; Theoretical computation;
   Masking matrix
ID DATA HIDING ALGORITHM; VIDEO; SCHEME
AB This paper investigates the possibility of avoiding the HEVC intra-frame drift effect induced by additive modifications of the luma DCT/DST coefficients. The main novelty consists in solving the intra-drift problem in its general form: starting from the equations defining the 35 intra-prediction modes and the DCT/DST computation, a mask multiplicative matrix cancelling the intra-frame drift effect is computed. The relevance of the advanced method with respect to the state of the art studies is illustrated, discussed and quantitatively assessed. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Arige, A.; Mitrea, M.; Boujelbane, I.] IMT Telecom SudParis, ARTEMIS Dept, Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis
RP Mitrea, M (corresponding author), IMT TSP, ARTEMIS Dept, 9 Rue Charles Fourier, F-91011 Evry, France.
EM mihai.mitrea@telecom-sudparis.eu
CR Budagavi M, 2013, IEEE J-STSP, V7, P1029, DOI 10.1109/JSTSP.2013.2270429
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chen W, 2014, MULTIMEDIA SYST, V20, P179, DOI 10.1007/s00530-013-0329-x
   Cox I. J., 2002, Digital Watermarking
   Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3
   Gaj S, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3009910
   Gong X, 2008, IEEE INT SYM MULTIM, P649, DOI 10.1109/ISM.2008.16
   Hasnaoui M., P SPIE, V9028
   Hasnaoui M, 2014, SIGNAL PROCESS-IMAGE, V29, P107, DOI 10.1016/j.image.2013.07.007
   He X., 2018, INT C IM PROC ICIP
   Huo WJ, 2011, IEEE SIGNAL PROC LET, V18, P535, DOI 10.1109/LSP.2011.2162061
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Ma X., 2009, P 1 INT S COMP NETW
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Shen LQ, 2018, IEEE T IMAGE PROCESS, V27, P4195, DOI 10.1109/TIP.2018.2837379
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Zhang LW, 2010, INT CONF ACOUST SPEE, P1758, DOI 10.1109/ICASSP.2010.5495443
NR 18
TC 2
Z9 2
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 56
EP 67
DI 10.1016/j.jvcir.2019.04.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600005
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Abdolali, M
   Rahmati, M
AF Abdolali, Maryam
   Rahmati, Mohammad
TI Robust subspace clustering for image data using clean dictionary
   estimation and group lasso based matrix completion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Subspace estimation; Sparse representation; Sparse subspace clustering;
   Group lasso; Multi-scale estimation; Matrix completion
ID DIMENSIONALITY REDUCTION; SEGMENTATION; DECOMPOSITION; SHAPE
AB In this paper, we consider the problem of subspace clustering for image data under occlusion and gross spatially contiguous noise. The state of the art subspace clustering methods assume that the noise either follows independent Laplacian or Gaussian distributions. However, the realistic noise is much more complicated and exhibits different structures in different scales. To address this issue, we propose a multi scale framework that extracts a clean self-expressive dictionary through an iterative approach and is capable of identifying probable corrupted elements in each sample. Using this information, not only we can estimate parameters of each subspace more accurately but also by optimizing a matrix completion problem based on group sparsity, we can recover corrupted regions more precisely and hence achieve higher clustering accuracy for corrupted samples. Numerical experiments on synthetic and real world data sets demonstrate the efficiency of our proposed framework in presence of occlusion and spatially contiguous noise. (C) 2019 Published by Elsevier Inc.
C1 [Abdolali, Maryam; Rahmati, Mohammad] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
C3 Amirkabir University of Technology
RP Rahmati, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
EM mabdolali@aut.ac.ir; rahmati@aut.ac.ir
OI Abdolali, Maryam/0000-0001-7032-4498
CR Abdolali F, 2017, INT J COMPUT ASS RAD, V12, P581, DOI 10.1007/s11548-016-1484-2
   Abdolali M, 2017, IEEE SIGNAL PROC LET, V24, P1015, DOI 10.1109/LSP.2017.2704024
   [Anonymous], 2004, P 2004 IEEE COMPUTER
   [Anonymous], ARXIV10010736
   [Anonymous], INT ENCY STAT SCI
   Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bellman R, 2013, DYNAMIC PROGRAMMING
   Bingham E., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P245, DOI 10.1145/502512.502546
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   BOYD S, 2011, NIPS WORKSH OPT MACH
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Gao GW, 2017, PATTERN RECOGN, V66, P129, DOI 10.1016/j.patcog.2016.12.021
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gu J, 2018, PATTERN RECOGN, V74, P544, DOI 10.1016/j.patcog.2017.09.016
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Hongyuan Zha, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P25
   Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu G., 2014, Low-Rank and Sparse Modeling for Visual Analysis, P23
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lu CY, 2019, IEEE T PATTERN ANAL, V41, P487, DOI 10.1109/TPAMI.2018.2794348
   Lu CY, 2013, IEEE I CONF COMP VIS, P1345, DOI 10.1109/ICCV.2013.170
   Luo L, 2016, IEEE T IMAGE PROCESS, V25, P5757, DOI 10.1109/TIP.2016.2612885
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Martinez A., 2007, COMPUTER VISION CTR, V3, P5
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ong F, 2016, IEEE J-STSP, V10, P672, DOI 10.1109/JSTSP.2016.2545518
   Park D., 2014, P ADV NEUR INF PROC, V27, P2753
   Qiu Q, 2015, J MACH LEARN RES, V16, P187
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sim K, 2013, DATA MIN KNOWL DISC, V26, P332, DOI 10.1007/s10618-012-0258-x
   Simoncelli E. P., 1991, TECH REP
   Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199
   Soltanolkotabi M, 2012, ANN STAT, V40, P2195, DOI 10.1214/12-AOS1034
   Sugaya Y, 2004, LECT NOTES COMPUT SC, V3247, P13
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tseng P, 2000, J OPTIMIZ THEORY APP, V105, P249, DOI 10.1023/A:1004678431677
   Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244
   Vidal R., 2016, GEN PRINCIPAL COMPON, P25, DOI [10.1007/978-0-387-87811-9_2, DOI 10.1007/978-0-387-87811-9_2]
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang Y.X., 2016, J. Mach. Learn. Res, V17, P320
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Zhang FL, 2015, IEEE T IMAGE PROCESS, V24, P1956, DOI 10.1109/TIP.2015.2400213
   Zhang L, 2009, PROCEEDINGS OF 2009 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS TECHNOLOGY AND APPLICATIONS, P212, DOI 10.1109/ICCOMTA.2009.5349209
   Zhao X, 2019, SUBST USE MISUSE, V54, P459, DOI 10.1080/10826084.2018.1508298
NR 57
TC 2
Z9 2
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 303
EP 314
DI 10.1016/j.jvcir.2019.04.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100031
DA 2024-07-18
ER

PT J
AU Li, ZJ
   Wang, WL
   Chen, Y
   Hao, YS
AF Li, Zhenjiang
   Wang, Weilan
   Chen, Yang
   Hao, Yusheng
TI A novel method of text line segmentation for historical document image
   of the uchen Tibetan
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tibetan historical document; Text line segmentation; Baseline; Upper
   edge; Connected region analysis; Dataset; Image processing
ID OBJECTS
AB Text line segmentation is a key step in Tibetan historical document recognition. A novel method for text line segmentation was proposed based on the baseline in uchen Tibetan, and a new dataset was released, which was used to evaluate the results of text line segmentation of uchen Tibetan historical documents. In this paper, there were two steps for the proposed method: baseline detection and text line segmentation using the baseline. In baseline detection, the upper edges of all characters in the document were obtained by a horizontal gradient operator, then an edge connectivity definition was proposed by which the upper edge set was divided into disjoint subsets. Eligible sets were selected from these subsets, and the edges in these sets were joined in turn to obtain the baseline. In text line segmentation, the document image was truncated at the baseline position, then the adhesion regions were segmented again. Each connected region in the image was assigned to its nearest baseline. All connected regions belonging to the same baseline formed a text line. Experiments on the proposed dataset showed that the method could effectively avoid document distortion, the accuracy of text line segmentation was high, and the text line adhesion could be handled. (C) 2019 Published by Elsevier Inc.
C1 [Li, Zhenjiang; Wang, Weilan; Hao, Yusheng] Northwest Minzu Univ, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou, Gansu, Peoples R China.
   [Chen, Yang; Hao, Yusheng] Northwest Minzu Univ, Sch Math & Comp Sci, Lanzhou, Gansu, Peoples R China.
C3 Northwest Minzu University; Northwest Minzu University
RP Wang, WL (corresponding author), Northwest Minzu Univ, Key Lab Chinas Ethn Languages & Informat Technol, Minist Educ, Lanzhou, Gansu, Peoples R China.
EM weilanwang123@sina.com
FU National Natural Science Foundation of China [61772430]; Gansu
   Provincial first-class discipline program of Northwest Minzu University;
   Program for Leading Talent of State Ethnic Affairs Commission
FX This work is supported by the National Natural Science Foundation of
   China (No. 61772430) and by the Gansu Provincial first-class discipline
   program of Northwest Minzu University. The Program for Leading Talent of
   State Ethnic Affairs Commission supports the work also.
CR Aldavert D, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P293, DOI 10.1109/DAS.2018.24
   Anusree M, 2014, INT J ENG RES APPL, V4, P332
   Ayesh M., 2017, Electron Imaging, V2017, P42
   Bogacz B, 2016, INT CONF FRONT HAND, P301, DOI [10.1109/ICFHR.2016.59, 10.1109/ICFHR.2016.0064]
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Fengming Z., 2018, INT J PATTERN RECOGN, V32, P51
   Granell E, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P269, DOI 10.1109/DAS.2016.45
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Javed M., 2014, COMPUTER VISION PATT, P1
   Jindal P., 2016, INT C REC ADV ENG CO, P1
   Kavitha AS, 2016, EGYPT INFORM J, V17, P189, DOI 10.1016/j.eij.2015.11.003
   Li YX, 2017, COMM COM INF SC, V771, P356, DOI 10.1007/978-981-10-7299-4_29
   Likforman-Sulem L, 2007, INT J DOC ANAL RECOG, V9, P123, DOI 10.1007/s10032-006-0023-z
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Setitra I., 2017, INT C PATT REC APPL, P222
   Valy D, 2016, INT CONF FRONT HAND, P108, DOI [10.1109/ICFHR.2016.29, 10.1109/ICFHR.2016.0032]
   Wu Y. C., 2018, INT C DOC AN REC, P79
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   2015, IEEE T CIRC SYST VID, V25, P1309, DOI DOI 10.1109/TCSVT.2014.2381471
   2018, IET IMAGE PROCESS, V12, P438, DOI DOI 10.1049/IET-IPR.2017.0083
   2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI DOI 10.1109/TGRS.2014.2374218
NR 29
TC 11
Z9 11
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 23
EP 32
DI 10.1016/j.jvcir.2019.01.021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100003
DA 2024-07-18
ER

PT J
AU Liu, Y
   Luo, TJ
AF Liu Yang
   Luo Tiejian
TI The optimization of sum-product network structure learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Machine learning; Deep learning; Sum-product network; Structure learning
ID OBJECT DETECTION; DEEP
AB Sum-Product Network (SPN) are recently introduced deep tractable Probabilistic Graphical Models providing exact and tractable inference. SPN have been successfully employed as density estimators in some artificial intelligence fields, however, most of the proposed structure learning algorithms focus on improving the performance of a certain aspect of model, at the cost of reducing other performance. This is due to the fact that there is no effective balance between network width and depth during learning process. In this paper, we propose two clustering analysis algorithms to replace the clustering part of LearnSPN. We improve the structure quality of the generated model by deepening the network while adjusting the network width adaptively, trying to find a balance between the expressive power, representation ability, inference accuracy and simplicity. Experimental results prove that LearnSPN equipped by our clustering method has different degrees of improvement in various performances. (C) 2019 Published by Elsevier Inc.
C1 [Liu Yang; Luo Tiejian] Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Liu, Y (corresponding author), Univ Chinese Acad Sci, Beijing 101408, Peoples R China.
EM yangliu1783@sohu.com
CR Adel T, 2015, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P32
   [Anonymous], P WORKSH LEARN TRACT
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng Wei-Chen., 2014, INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association, P2098
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Dennis A., 2012, ADV NEURAL INFORM PR, V25, P2033
   Di Mauro N, 2017, LECT NOTES ARTIF INT, V10640, P334, DOI 10.1007/978-3-319-70169-1_25
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gens R, 2013, 30 INT C MACH LEARN
   Haaren J. V., 2012, P 26 C ART INT
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Lowd D., 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P334, DOI 10.1109/ICDM.2010.128
   Martens J., 2014, COMPUT SCI, V1, P102
   Molina A., 2018, AAAI C ART INT
   Nath A, 2016, AAAI CONF ARTIF INTE, P1294
   Peharz Robert, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3699, DOI 10.1109/ICASSP.2014.6854292
   Peharz Robert, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference (ECML PKDD 2013). Proceedings: LNCS 8189, P612, DOI 10.1007/978-3-642-40991-2_39
   Peharz R., 2015, PhD thesis
   Peharz Robert, 2014, WORKSH LEARN TRACT P
   Poon H., 2011, P 12 C UNC ART INT, P2551
   Rooshenas A, 2014, PR MACH LEARN RES, V32
   Roth D, 1996, ARTIF INTELL, V82, P273, DOI 10.1016/0004-3702(94)00092-1
   Vergari A., 2018, MACH LEARN J, V8, P1
   Vergari A., 2018, P 32 AAAI C ART INT
   Vergari A, 2015, LECT NOTES ARTIF INT, V9285, P343, DOI 10.1007/978-3-319-23525-7_21
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 38
TC 2
Z9 3
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 391
EP 397
DI 10.1016/j.jvcir.2019.02.012
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000042
DA 2024-07-18
ER

PT J
AU Zhang, S
   Huang, FY
   Liu, BQ
   Yu, H
   Chen, YC
AF Zhang, Shuai
   Huang, Fuyu
   Liu, Bingqi
   Yu, Hao
   Chen, Yichao
TI Infrared dim target detection method based on the fuzzy accurate
   updating symmetric adaptive resonance theory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Infrared dim target detection; Human vision system; Fuzzy accurate
   updating symmetric; adaptive resonance theory; ROI model
ID ART
AB Motivated by the human visual system, we propose an infrared dim target detection method that is based on a fuzzy accurate updating symmetric adaptive resonance theory network. From the bottom-up perspective, the regions of interest (ROls) are extracted using a difference of Gaussians at multiple scales and our designed ROI model in a saliency map. From the top-down perspective, five feature categories are extracted using the ROI model, which are used to train the proposed Fuzzy AUSART network. The well-trained network realizes the true identification of all ROI candidates. The results of the receiver operating characteristic (ROC) curves verify that the proposed method can better adapt to different circumstances and targets in our experiment. The average detection accuracy of the Fuzzy AUSART is improved by 15.4%, and the average F1 index of the proposed method is higher than six typical comparison methods by more than a factor of 2.48. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Shuai; Huang, Fuyu; Liu, Bingqi; Yu, Hao; Chen, Yichao] Army Engn Univ, Dept Elect & Opt Engn, Shijiazhuang, Hebei, Peoples R China.
C3 Army Engineering University of PLA
RP Huang, FY (corresponding author), Army Engn Univ, Dept Elect & Opt Engn, Shijiazhuang, Hebei, Peoples R China.
EM hfyoptics@163.com
OI Zhang, Shuai/0000-0001-9153-5673
FU National Natural Science Foundation of China [61801507]
FX This work was supported by the National Natural Science Foundation of
   China (61801507).
CR CARPENTER GA, 1991, NEURAL NETWORKS, V4, P759, DOI 10.1016/0893-6080(91)90056-B
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cui Z, 2016, MEASUREMENT, V91, P405, DOI 10.1016/j.measurement.2016.05.071
   Cui Z, 2016, INFRARED PHYS TECHN, V76, P474, DOI 10.1016/j.infrared.2016.03.023
   Deng H, 2017, PATTERN RECOGN, V61, P66, DOI 10.1016/j.patcog.2016.07.036
   Drummond O.E., 2014, P SOC PHOTO-OPT INS
   Frintrop S, 2011, COMPUTER ANALYSIS OF HUMAN BEHAVIOR, P69, DOI 10.1007/978-0-85729-994-9_4
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   KASKI S, 1994, NEURAL NETWORKS, V7, P973, DOI 10.1016/S0893-6080(05)80154-6
   Kondadadi R, 2002, IEEE IJCNN, P2545, DOI 10.1109/IJCNN.2002.1007544
   Li CM, 2018, IEEE T SIGNAL PROCES, V66, P3784, DOI 10.1109/TSP.2018.2835398
   [黎万义 Li Wanyi], 2014, [自动化学报, Acta Automatica Sinica], V40, P561
   Li YS, 2016, INFORM SCIENCES, V369, P548, DOI 10.1016/j.ins.2016.07.042
   Li YS, 2016, IEEE GEOSCI REMOTE S, V13, P157, DOI 10.1109/LGRS.2015.2503142
   Li ZZ, 2014, SENSORS-BASEL, V14, P9451, DOI 10.3390/s140609451
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma WP, 2017, IEEE GEOSCI REMOTE S, V14, P3, DOI 10.1109/LGRS.2016.2600858
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mahler R., 2014, P SOC PHOTO-OPT INS
   Matthews KE, 1998, IEEE T IMAGE PROCESS, V7, P720, DOI 10.1109/83.668028
   Qin Han-lin, 2009, Infrared Laser Engineering, V38, P737
   Shouxin Ji, 2010, Proceedings 3rd International Congress on Image and Signal Processing (CISP 2010), P2579, DOI 10.1109/CISP.2010.5648161
   Straka O, 2009, FUSION: 2009 12TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION, VOLS 1-4, P270
   Wang Weihua, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P774, DOI 10.1109/ICSPCC.2012.6335598
   Wang WG, 2015, INFRARED PHYS TECHN, V73, P19, DOI 10.1016/j.infrared.2015.08.015
   Wang X, 2012, INFRARED PHYS TECHN, V55, P513, DOI 10.1016/j.infrared.2012.08.004
   Wei YT, 2016, PATTERN RECOGN, V58, P216, DOI 10.1016/j.patcog.2016.04.002
   Xiong TS, 2016, J VIS COMMUN IMAGE R, V40, P345, DOI 10.1016/j.jvcir.2016.07.004
   Yang X, 2015, INFRARED PHYS TECHN, V71, P402, DOI 10.1016/j.infrared.2015.04.014
   Yousuf A, 2010, LECT NOTES COMPUT SC, V6063, P430, DOI 10.1007/978-3-642-13278-0_55
NR 33
TC 8
Z9 9
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 180
EP 191
DI 10.1016/j.jvcir.2019.02.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000021
DA 2024-07-18
ER

PT J
AU Hu, WJ
   Ye, YQ
   Meng, JH
   Zeng, FL
AF Hu, Wenjin
   Ye, Yuqi
   Meng, Jiahao
   Zeng, Fuliang
TI No reference quality assessment for Thangka color image based on
   superpixel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality; No reference assessment; Superpixel; Information entropy;
   Thangka image
AB In view of the situation that a large number of Thangka images are missing part of color information because of time and environmental factors, the existing image evaluation methods are inconsistent with the result of subjective evaluation. This paper aims at evaluating the damaged Thangka color image, and proposes a new method of image quality evaluation based on superpixel and color entropy. In this algorithm, we use the uniformity of Thangka color image to extract color feature based on CIE 1976 L* a* b* (CIELAB) color space and superpixel. Therefore, the loss of color information in the complex area of Thangka images is well handled. The color entropy is used to quantify the color distribution and structure characteristics of each superpixel, and then we can get the preliminarily evaluation score. In the end, large amounts of data are obtained through some operations such as image deformation and rotating by the Generative Adversarial Nets (GANs), which makes the final evaluation score more reliable. Experimental results show that this method can obtain a good consistency with the subjective results, and Spearman rank order the correlation coefficient (SROCC) and Pearson linear correlation coefficient (PLCC) of the new method already exceed 0.9. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hu, Wenjin; Ye, Yuqi; Zeng, Fuliang] Northwest Minzu Univ, Sch Math & Comp Sci, Lanzhou 730000, Gansu, Peoples R China.
   [Hu, Wenjin; Ye, Yuqi; Meng, Jiahao; Zeng, Fuliang] Minist Educ, Key Lab Chinas Ethn Languages & Informat Technol, Lanzhou 730000, Gansu, Peoples R China.
   [Meng, Jiahao] Northwest Minzu Univ, Natl Languages Informat Technol, Lanzhou 730000, Gansu, Peoples R China.
C3 Northwest Minzu University; Northwest Minzu University
RP Hu, WJ (corresponding author), Northwest Minzu Univ, Sch Math & Comp Sci, Lanzhou 730000, Gansu, Peoples R China.
EM wenjin_zhm@126.com
RI ye, yuqi/IVV-6836-2023
OI hu, wenjin/0000-0002-3120-5231; Meng, Jiahao/0000-0003-4350-3479
FU Nature Science Foundation of China [61561042, 61862057]; Fundamental
   Research Funds for the Central Universities [31920180117, 31920170143];
   special fund for talent introduction of northwestern nationalities
   university
FX This work was supported in part by The Nature Science Foundation of
   China under Grant No. 61561042 and No. 61862057, Fundamental Research
   Funds for the Central Universities (No. 31920180117, 31920170143) and by
   the special fund for talent introduction of northwestern nationalities
   university.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [董宏平 Dong Hongping], 2014, [中国图象图形学报, Journal of Image and Graphics], V19, P484
   [李俊峰 Li Junfeng], 2015, [自动化学报, Acta Automatica Sinica], V41, P1601
   Li Junfeng, 2015, J INSTRUM METER, V36, P339
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ning Xiaoqing, 2016, ART TECHNOL, V15, P215
   Pan Zhangmin, 2016, CHIN MEDIA TECHNOL, V15, P57
   Saadma Bovikacb, 2012, IEEE T IMAGE PROCESS, V21, P3339
   Sony X. Y., 2015, J IMAGE GRAPH, V20
   Wen W, 2017, COMPUT SCI, V44, P151
   [徐琳 Xu Lin], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1583
   Yue  Jing, 2019, ADV LASER OPTOELECTR, V56
NR 14
TC 6
Z9 6
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 407
EP 414
DI 10.1016/j.jvcir.2019.01.039
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600043
DA 2024-07-18
ER

PT J
AU Huang, CT
   Lin, LC
   Yang, CH
   Wang, SJ
AF Huang, Cheng-Ta
   Lin, Li-Chiun
   Yang, Cheng-Hsing
   Wang, Shiuh-Jeng
TI Dynamic embedding strategy of VQ-based information hiding approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vector quantization; Dynamic embedding algorithm; Steganography
ID CRYPTANALYSIS; ALGORITHM
AB Information security is one of the most challenging issues. Cryptography and Steganography techniques are two popular methods for protecting data privacy. In this study, an information hiding method with dynamic embedding capacity based on vector quantization is proposed for protecting confidential data. To improve embedding capacity and image quality at the same time, dynamic-length secret bits are embedded into each pixel. Compared with previous approaches, the proposed method preforms better regarding the embedding capacity and image quality. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Huang, Cheng-Ta] Oriental Inst Technol, Dept Informat Management, New Taipei, Taiwan.
   [Lin, Li-Chiun] Cent Police Univ, Dept Informat Management, Informat Cryptol Construct Lab, Taoyuan, Taiwan.
   [Yang, Cheng-Hsing] Natl Pingtung Univ, Dept & Grad Sch Comp Sci, Pingtung, Taiwan.
   [Wang, Shiuh-Jeng] Cent Police Univ, Dept Informat Management, Taoyuan, Taiwan.
C3 Asia Eastern University of Science & Technology; National Pingtung
   University
RP Wang, SJ (corresponding author), Cent Police Univ, Dept Informat Management, Taoyuan, Taiwan.
EM sjwang@mail.cpu.edu.tw
RI Wang, Suhang/AAH-1378-2019; Srinivasulu, Dr. Asadi/B-9382-2018
OI Srinivasulu, Dr. Asadi/0000-0002-5252-3669
FU Ministry of Science and Technology of the Republic of China
   [RD107-7-11-003]
FX This research was partially supported by Ministry of Science and
   Technology of the Republic of China under the Grants
   107-2221-E-015-001-MY2-and Oriental Institute of Technology under the
   Grant RD107-7-11-003.
CR [Anonymous], JIH MSP
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Boehm B., 2014, STEGEXPOSE TOOL DETE
   Bogdanov A, 2014, DESIGN CODE CRYPTOGR, V70, P369, DOI 10.1007/s10623-012-9697-z
   Bogdanov A, 2011, LECT NOTES COMPUT SC, V7073, P344, DOI 10.1007/978-3-642-25385-0_19
   Cavagnino D, 2015, SIGNAL PROCESS, V117, P258, DOI 10.1016/j.sigpro.2015.05.020
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Gao GY, 2015, IEEE SIGNAL PROC LET, V22, P2078, DOI 10.1109/LSP.2015.2459055
   Gilbert H, 2010, LECT NOTES COMPUT SC, V6147, P365, DOI 10.1007/978-3-642-13858-4_21
   Huang C.-T., 2016, J COMB OPTIM, P1
   Keyvanpour MR, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.040
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Shaamala A., 2011, International Journal of Computer Science Issues, V8, P220
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang WJ, 2016, MULTIMED TOOLS APPL, V75, P14895, DOI 10.1007/s11042-015-2761-8
   Wang XY, 2014, DIGIT SIGNAL PROCESS, V25, P244, DOI 10.1016/j.dsp.2013.10.020
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
NR 22
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 14
EP 32
DI 10.1016/j.jvcir.2018.12.018
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600003
DA 2024-07-18
ER

PT J
AU Wang, M
   Wang, XA
   Fan, ZC
   Chen, F
   Zhang, SX
   Peng, C
AF Wang, Mo
   Wang, Xin'an
   Fan, Zhuochen
   Chen, Fei
   Zhang, Sixu
   Peng, Chen
TI Research on feature extraction algorithm for plantar pressure image and
   gait analysis in stroke patients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Plantar pressure; Feature extraction; Image denoising; Clustering
   analysis; Gait analysis
AB The plantar pressure image is an important tool for gait analysis. It has important applications in evaluating the recovery of stroke patients after operation and formulating the rehabilitation training program. It is one of the key technologies of gait analysis to extract foot feature parameters from static/dynamic plantar pressure images. This article deals with the noise in the original image through the piecewise linear grayscale transformation, the time domain mean filter and the maximum value filter, then determine the position of the feet in the image by the foot localization algorithm based on the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) and the K-means clustering method. Finally, the plantar pressure feature parameters were extracted according to the positioned images. Based on the above feature parameter extraction algorithm, the plantar pressure feature parameters of 20 healthy subjects and 20 S patients with relative recovery period (2-6 months after the onset) were compared, showing a statistically significant difference (P < 0.001). Based on the above data, gait characteristics of stroke patients were further analyzed. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Mo; Wang, Xin'an; Fan, Zhuochen; Zhang, Sixu; Peng, Chen] Peking Univ, Shenzhen Grad Sch, Key Lab Integrated Microsyst, Shenzhen 518055, Peoples R China.
   [Chen, Fei] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China.
C3 Peking University; Hong Kong Polytechnic University
RP Wang, XA (corresponding author), Peking Univ, Shenzhen Grad Sch, Key Lab Integrated Microsyst, Shenzhen 518055, Peoples R China.
EM mohaiyou@sz.pku.edu.cn; anxinwang@pku.edu.cn
FU Special Fund for the Development of Shenzhen (China) Strategic New
   Industry [JCYJ20170818085946418]; Shenzhen (China) Science and
   Technology Research and Development Fund [JCYJ20170306092000960]
FX The project has been supported by the Special Fund for the Development
   of Shenzhen (China) Strategic New Industry (JCYJ20170818085946418) and
   the Shenzhen (China) Science and Technology Research and Development
   Fund (JCYJ20170306092000960).
CR Abualhaj B, 2016, STRAHLENTHER ONKOL, V192, P141
   [Anonymous], ST DBSCAN ALGORITHM
   Armstrong D G., Preventing Foot Ulcers
   Azhari S., 2017, SENSORS ACTUAT A
   Chen G, 2005, GAIT POSTURE, V22, P51, DOI 10.1016/j.gaitpost.2004.06.009
   Dekuang Y. U., 2018, J COMPUT APPL
   Feger MA, 2016, CLIN BIOMECH, V37, P117, DOI 10.1016/j.clinbiomech.2016.07.002
   Foruzan AH, 2013, IEICE T INF SYST, VE96D, P798, DOI 10.1587/transinf.E96.D.798
   Lee W, 2017, I C INF COMM TECH CO, P1041, DOI 10.1109/ICTC.2017.8190848
   Li X., 2011, OPTOELECTRON TECHNOL
   Morita Y., 2011, LEICE TECHN REP WELF, V111, P67
   Park J, 2018, J MED IMAG HEALTH IN, V8, P452, DOI 10.1166/jmihi.2018.2373
   Petsarb K., 2012, BIOM ENG INT C BMEIC, V2012, P1
   Piskorowski J, 2013, BIOCYBERN BIOMED ENG, V33, P171, DOI 10.1016/j.bbe.2013.07.006
   Tran TN, 2013, CHEMOMETR INTELL LAB, V120, P92, DOI 10.1016/j.chemolab.2012.11.006
   Vimal A, 2017, INT C COMP COMM NETW, P1, DOI [10.1109/ICCCNT.2017.8204005, DOI 10.1109/ICCCNT.2017.8204005]
   Ziegler S, 2009, IEEE SENS J, V9, P354, DOI 10.1109/JSEN.2009.2013914
NR 17
TC 8
Z9 9
U1 8
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 525
EP 531
DI 10.1016/j.jvcir.2018.12.017
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100051
DA 2024-07-18
ER

PT J
AU Yan, XH
   Lu, YL
AF Yan, Xuehu
   Lu, Yuliang
TI Generalized general access structure in secret image sharing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; General access structure; Chinese remainder
   theorem; Lossless recovery; Generalized general access structure
ID VISUAL CRYPTOGRAPHY; RECOVERY
AB Generally speaking, the probability of every qualified set is the same and fixed in conventional secret image sharing (SIS) for general access structure (GAS). In this paper, first we introduce generalized GAS (GGAS), which allows the user to assign probability to every qualified set. Then we design a SIS scheme for GGAS by Chinese remainder theorem (CRT). On one hand, for any qualified set, we can decode the secret image at pre-assigned probability. When we collect all the shares, we can losslessly decode the secret image. On the other hand, for any forbidden set, we will decode nothing of the secret image. We only employ modular operation to decode the secret image, which may be suitable for real-time and green computing scenarios. Experimental results and analyses are realized to examine the effectiveness of our scheme. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yan, Xuehu; Lu, Yuliang] Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
C3 National University of Defense Technology - China
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
EM publictiger@126.com
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61602491]; Key Program of
   the National University of Defense Technology [ZK-17-02-07]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work is supported by the National Natural
   Science Foundation of China (Grant No.: 61602491) and the Key Program of
   the National University of Defense Technology (Grant No.: ZK-17-02-07).
CR [Anonymous], INT J WAVELETS MULTI
   [Anonymous], 2009, 2009 INT C APPL INF
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Chuang TW, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P817, DOI 10.1109/IS3C.2016.208
   Goldreich O, 2000, IEEE T INFORM THEORY, V46, P1330, DOI 10.1109/18.850672
   KRISHNA H, 1992, IEEE T CIRCUITS-II, V39, P8, DOI 10.1109/82.204106
   Kumar S., 2013, INT J COMPUTER APPL, V83, P1
   Li P, 2018, SIGNAL PROCESS-IMAGE, V65, P210, DOI 10.1016/j.image.2018.04.002
   Lintao Liu, 2016, 2016 12th International Conference on Mobile Ad-Hoc and Sensor Networks (MSN). Proceedings, P380, DOI 10.1109/MSN.2016.069
   Liu X, 2018, J REAL-TIME IMAGE PR, V14, P51, DOI 10.1007/s11554-016-0644-5
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shen G., 2017, MULTIMED TOOLS APPL, P1
   Shyu SJ, 2008, 2008 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE, VOLS 1-3, PROCEEDINGS, P1332, DOI 10.1109/APSCC.2008.223
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang GY, 2016, INT J DIGIT CRIME FO, V8, P85, DOI 10.4018/IJDCF.2016070106
   Wang W., 2017, INFORM SECURITY DISP, P198
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu X, 2012, IET INFORM SECUR, V6, P299, DOI 10.1049/iet-ifs.2012.0046
   Xiao L, 2018, SIGNAL PROCESS, V150, P248, DOI 10.1016/j.sigpro.2018.04.022
   Xiao L, 2014, IEEE T SIGNAL PROCES, V62, P4772, DOI 10.1109/TSP.2014.2339798
   Yan XH, 2018, DIGIT SIGNAL PROCESS, V82, P80, DOI 10.1016/j.dsp.2018.07.015
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2018, J VIS COMMUN IMAGE R, V50, P135, DOI 10.1016/j.jvcir.2017.11.012
   Yan XH, 2018, MULTIMED TOOLS APPL, V77, P2653, DOI 10.1007/s11042-017-4421-7
   Yan XH, 2017, LECT NOTES COMPUT SC, V10603, P433, DOI 10.1007/978-3-319-68542-7_36
   Yan XH, 2017, INT J DIGIT CRIME FO, V9, P45, DOI 10.4018/IJDCF.2017040105
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 31
TC 14
Z9 14
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 89
EP 101
DI 10.1016/j.jvcir.2018.11.031
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100010
DA 2024-07-18
ER

PT J
AU Dong, F
   Nie, XS
   Liu, XB
   Geng, LL
   Wang, Q
AF Dong, Fei
   Nie, Xiushan
   Liu, Xingbo
   Geng, Leilei
   Wang, Qian
TI Cross-modal hashing based on category structure preserving
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-modal retrieval; Supervised hashing; Category-specific structure
   preserving
AB Cross-modal hashing has made a great development in cross-modal retrieval since its vital reduction in computational cost and storage. Generally, projections for each modality that map heterogeneous data into a common space are used to bridge the gap between different modalities. However, category specific distributions are usually be ignored during the projection. To address this issue, we propose a novel cross-modal hashing, termed as Category Structure Preserving Hashing (CSPH), for cross-modal retrieval. In CSPH, category-specific distribution is preserved by a structure-preserving regularization term during the hash learning. Compared with existing methods, CSPH not only preserves the local structure of each category, but also generates more stable hash codes with less time for training. Extensive experiments conducted on three benchmark datasets, and the experimental results demonstrate the superiority of CSPH under various cross-modal scenarios. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Dong, Fei] Shandong Normal Univ, Sch Journalism & Commun, Jinan, Shandong, Peoples R China.
   [Nie, Xiushan; Geng, Leilei; Wang, Qian] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Liu, Xingbo] Shandong Univ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong University of Finance & Economics;
   Shandong University
RP Nie, XS (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
RI Nie, Xiushan/AAZ-6410-2020
FU National Natural Science Foundation of China [61671274]; China
   Postdoctoral Science Foundation [2016M592190, 2016M602141]; Shangdong
   Provincial Key Research and Development Plan [2017CXGC1504]; Shandong
   Natural Science Foundation [ZR2017MF053]; Higher Educational Science and
   Technology Program of Shandong Province [017KB161]; Fostering Project of
   Dominant Discipline and Talent Team of Shandong Province Higher
   Education Institutions
FX This work is supported by the National Natural Science Foundation of
   China (61671274), China Postdoctoral Science Foundation (2016M592190 and
   2016M602141), Shangdong Provincial Key Research and Development Plan
   (2017CXGC1504), Shandong Natural Science Foundation (ZR2017MF053),
   Higher Educational Science and Technology Program of Shandong Province
   017KB161), and the Fostering Project of Dominant Discipline and Talent
   Team of Shandong Province Higher Education Institutions.
CR [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 2014, P 25 INT JOINT C ART
   [Anonymous], CVPR
   [Anonymous], NEURAL COMPATIBILITY
   [Anonymous], 2016, DEEP CROSS MODAL HAS
   [Anonymous], ASPECT AWARE LATENT
   [Anonymous], IEEE T CIRCUITS SYST
   Bronstein MM, 2010, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2010.5539928
   Cao Y, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P197, DOI 10.1145/2911996.2912000
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Cheng Z., 2014, Proceedings of international conference on multimedia retrieval p, P185, DOI [DOI 10.1145/2578726.2578751, 10.1145/2578726.2578751]
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Gui J., 2017, IEEE T PATTERN ANAL, VPP, P1
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Irie G, 2015, IEEE I CONF COMP VIS, P1886, DOI 10.1109/ICCV.2015.219
   Kong WH, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P45, DOI 10.1145/2348283.2348293
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225
   Moran S., 2013, Book Variable Bit Quantisation for LSH, P753
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Tang J, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2564638
   Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105
   Wang Z, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2298
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P2212, DOI 10.1109/TIP.2015.2419074
   Zhen Y., 2012, P INT C NEUR INF PRO, P1376
   Zhou JL, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P415
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 41
TC 5
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 28
EP 33
DI 10.1016/j.jvcir.2018.10.006
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400004
DA 2024-07-18
ER

PT J
AU Wang, YK
   Liu, QG
   Zhou, HL
   Wang, YH
AF Wang, Yankun
   Liu, Qiegen
   Zhou, Huilin
   Wang, Yuhao
TI Learning multi-denoising autoencoding priors for image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single image super-resolution; Denoising autoencoder; Multi-denoising
   autoencoding priors; Alternative iteration
ID RESOLUTION
AB Inspired by the application of denoising autoencoding priors (DAEP) to image restoration tasks, we propose a single image super-resolution (SISR) method via introducing multi-denoising autoencoding priors (MDAEP). On the basis of the naive DAEP, the proposed MDAEP integrates multi-DAEPs from different noisy inputs into the iterative restoration process. The combined strategy avails to alleviate the instability of the denoising autoencoders, and thus to avoid falling into local solutions. Furthermore, compared with the existing SISR methods based on end-to-end mapping, MDAEP is only trained once and applied to different magnification factors, but also can effectively preserve high-frequency information and reduce ringing effects of the reconstructed images. Both quantitative and qualitative assessments of the bench-mark datasets show that the ability and the stability of the network are improved effectively. The proposed method performs better than the state-of-the-art algorithms including the basic DAEP, in terms of PSNRs and visual comparisons. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Yankun; Liu, Qiegen; Zhou, Huilin; Wang, Yuhao] Nanchang Univ, Sch Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, QG; Wang, YH (corresponding author), Nanchang Univ, Sch Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM wangyuhao@ncu.edu.cn; liuqiegen@ncu.edu.cn
RI Li, Yuanyuan/J-3539-2014; WANG, Yuhao/O-9322-2019; Huilin,
   Zhou/GON-9860-2022
OI Li, Yuanyuan/0000-0001-6151-9306; WANG, Yuhao/0000-0002-8445-0361; 
FU National Natural Science Foundation of China [61503176, 61661031,
   61463035]; Young Scientist Training Plan of Jiangxi Province, China
   [20162BCB23019]; Key Scientist Plan of Jiangxi Province, China
   [20171BBH80023]
FX The authors sincerely thank the anonymous reviewers for their valuable
   comments and constructive suggestions that are very helpful in the
   improvement of this paper. This work was supported in part by the
   National Natural Science Foundation of China under 61503176, 61661031,
   61463035, the Young Scientist Training Plan of Jiangxi Province, China
   (20162BCB23019), and the Key Scientist Plan of Jiangxi Province, China
   (20171BBH80023).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Alain G, 2014, J MACH LEARN RES, V15, P3563
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bigdeli SA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P33, DOI 10.5220/0006532100330044
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Chan T, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P17, DOI 10.1007/0-387-28831-7_2
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cui Z, 2014, LECT NOTES COMPUT SC, V8693, P49, DOI 10.1007/978-3-319-10602-1_4
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai S., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383028
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Favaro P., 2017, INT C NEURAL INF PRO, P763
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Goodman J. W., 1968, INTRO FOURIER OPTICS
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   HARRIS JL, 1964, J OPT SOC AM, V54, P931, DOI 10.1364/JOSA.54.000931
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Levin A, 2012, LECT NOTES COMPUT SC, V7576, P73, DOI 10.1007/978-3-642-33715-4_6
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu D., 2016, Asian Conference on Computer Vision, P145
   Liu D, 2016, IEEE T IMAGE PROCESS, V25, P3194, DOI 10.1109/TIP.2016.2564643
   Mao X.-J., 2016, ARXIV160608921
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Russell M. F. T. B. C., 2003, P 3 INT WORKSHOP STA, P1
   Schmidt U, 2016, IEEE T PATTERN ANAL, V38, P677, DOI 10.1109/TPAMI.2015.2441053
   Shen HF, 2007, IEEE T IMAGE PROCESS, V16, P479, DOI 10.1109/TIP.2006.888334
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Sun J, 2010, INT J COMPUT MATH, V87, P552, DOI 10.1080/00207160802140031
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   Tekalp A. M., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P169, DOI 10.1109/ICASSP.1992.226249
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 51
TC 8
Z9 9
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 152
EP 162
DI 10.1016/j.jvcir.2018.10.028
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400018
DA 2024-07-18
ER

PT J
AU Hu, YC
   Lu, XB
AF Hu, Yaocong
   Lu, Xiaobo
TI Learning spatial-temporal features for video copy detection by the
   combination of CNN and RNN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video copyright; CNN; Sequence matching; SiamesLSTM
ID CLASSIFICATION; WATERMARKING
AB Following the rapid developments of network multimedia, video copyright protection online has become a hot topic in recent researches. However, video copy detection is still a challenging task in the domain of video analysis and computer vision, due to the large variations in scale and illumination of the copied contents. In this paper, we propose a novel deep learning based approach, in which we jointly use the Convolution Neural Network (CNN) and Recurrent Neural Network (RNN) to solve the specific problem of detecting copied segments in videos. We first utilize a Residual Convolutional Neural Network(ResNet) to extract content features of frame-levels, and then employ a SiameseLSTM architecture for spatial-temporal fusion and sequence matching. Finally, the copied segments are detected by a graph based temporal network. We evaluate the performance of the proposed CNN-RNN based approach on a public large scale video copy dataset called VCDB, and the experiment results demonstrate the effectiveness and high robustness of our method which achieves the significant performance improvements compared to the state of the art.
C1 [Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Coll Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Yaocong; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Southeast
   University - China
RP Lu, XB (corresponding author), Southeast Univ, Coll Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM ychu@seu.edu.cn
FU National Natural Science Foundation of China [61374194]; National Key
   Science & Technology Pillar Program of China [2014BAG01DB03]; Key
   Research & Development Program of Jiangsu Province [BE2016739]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX The authors would like to thank the editor and the anonymous reviewers
   for their valuable comments and constructive suggestions. This work was
   supported by the National Natural Science Foundation of China (No.
   61374194), National Key Science & Technology Pillar Program of China
   (No. 2014BAG01DB03), Key Research & Development Program of Jiangsu
   Province (No. BE2016739), and a Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], NEURAL INF PROCESSIN
   [Anonymous], ECCV
   [Anonymous], CORRABS14092329
   [Anonymous], PROC CVPR IEEE
   [Anonymous], CORRABS160405358
   [Anonymous], P INT WORKSH MULT IN
   [Anonymous], CORRABS161009975
   [Anonymous], SPRINGER SERIES STAT
   [Anonymous], 2009, P ACM INT C MULT, DOI DOI 10.1145/1631272.1631295
   [Anonymous], 2014, CAFFE
   [Anonymous], TRECVID 2008 GOALS T
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Cao Liangliang., 2012, Proceedings of the 20th ACM International Conference on Multimedia, P299
   Douze M, 2010, LECT NOTES COMPUT SC, V6311, P522, DOI 10.1007/978-3-642-15549-9_38
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Himeur Y, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATIONS (SIGMAP), P40
   Jiang YG, 2014, LECT NOTES COMPUT SC, V8692, P357, DOI 10.1007/978-3-319-10593-2_24
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li T, 2016, MULTIMEDIA SYST, V22, P29, DOI 10.1007/s00530-014-0387-8
   Liu CJ, 2016, INT CONF ACOUST SPEE, P5020, DOI 10.1109/ICASSP.2016.7472633
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Y., 2010, Proc. ACM International Conference on Image and Video Re- trieval, P89, DOI DOI 10.1145/1816041.1816057
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Maes M, 2000, IEEE SIGNAL PROC MAG, V17, P47, DOI 10.1109/79.879338
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mueller J, 2016, AAAI CONF ARTIF INTE, P2786
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qi XJ, 2007, SIGNAL PROCESS, V87, P1264, DOI 10.1016/j.sigpro.2006.11.002
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saadi K. Ait, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1799
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang L, 2017, LECT NOTES COMPUT SC, V10132, P576, DOI 10.1007/978-3-319-51811-4_47
   Wu A. G., 2007, P ACM MM, P218
   Yu-Gang Jiang, 2016, IEEE Transactions on Big Data, V2, P32, DOI 10.1109/TBDATA.2016.2530714
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
NR 39
TC 27
Z9 30
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 21
EP 29
DI 10.1016/j.jvcir.2018.05.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100003
DA 2024-07-18
ER

PT J
AU Anaya, J
   Barbu, A
AF Anaya, Josue
   Barbu, Adrian
TI RENOIR - A dataset for real low-light image noise reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Denoising dataset; Low light noise; Poisson-Gaussian
   noise model
AB Image denoising algorithms are evaluated using images corrupted by artificial noise, which may lead to incorrect conclusions about their performances on real noise. In this paper we introduce a dataset of color images corrupted by natural noise due to low-light conditions, together with spatially and intensity-aligned low noise images of the same scenes. We also introduce a method for estimating the true noise level in our images, since even the low noise images contain small amounts of noise. We evaluate the accuracy of our noise estimation method on real and artificial noise, and investigate the Poisson-Gaussian noise model. Finally, we use our dataset to evaluate six denoising algorithms: Active Random Field, BM3D, Bilevel-MRF, Multi-Layer Perceptron, and two versions of NL-means. We show that while the Multi-Layer Perceptron, Bilevel-MRF, and NL-means with soft threshold outperform BM3D on gray images with synthetic noise, they lag behind on our dataset.
C1 [Anaya, Josue; Barbu, Adrian] Florida State Univ, Dept Stat, 117 N Woodward Ave, Tallahassee, FL 32306 USA.
C3 State University System of Florida; Florida State University
RP Barbu, A (corresponding author), Florida State Univ, Dept Stat, 117 N Woodward Ave, Tallahassee, FL 32306 USA.
EM abarbu@stat.fsu.edu
RI Barbu, Adrian/C-6865-2009
OI Barbu, Adrian/0000-0002-9548-7872
FU DARPA MSEE [FA 8650-11-1-7149]
FX This work was supported in part by DARPA MSEE grant FA 8650-11-1-7149.
CR Alter F, 2006, LECT NOTES COMPUT SC, V3954, P267
   [Anonymous], 2014, CVPR
   [Anonymous], 2007, Numerical recipes 3rd edition: The art of scientific computing
   Barbu A, 2009, IEEE T IMAGE PROCESS, V18, P2451, DOI 10.1109/TIP.2009.2028254
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen YC, 2013, LECT NOTES COMPUT SC, V8142, P271, DOI 10.1007/978-3-642-40602-7_30
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Estrada F., 2010, IMAGE DENOISING BENC
   Estrada F., 2009, STOCHASTIC IMAGE DEN
   Foi A, 2008, IEEE T IMAGE PROCESS, V17, P1737, DOI 10.1109/TIP.2008.2001399
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Jancsary J, 2012, LECT NOTES COMPUT SC, V7578, P112, DOI 10.1007/978-3-642-33786-4_9
   Labs D., 2009, DXOMARK SENSOR SCORE
   Liu C, 2008, IEEE T PATTERN ANAL, V30, P299, DOI 10.1109/TPAMI.20071176
   Lu L, 2015, IEEE SIGNAL PROC LET, V22, P833, DOI 10.1109/LSP.2014.2371332
   Luisier F, 2011, IEEE T IMAGE PROCESS, V20, P696, DOI 10.1109/TIP.2010.2073477
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mäkitalo M, 2014, IEEE T IMAGE PROCESS, V23, P5348, DOI 10.1109/TIP.2014.2363735
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Schmidt U, 2010, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2010.5539844
   TEO PC, 1994, P SOC PHOTO-OPT INS, V2179, P127, DOI 10.1117/12.172664
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P411, DOI 10.1109/LSP.2013.2247755
NR 26
TC 91
Z9 98
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 144
EP 154
DI 10.1016/j.jvcir.2018.01.012
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fang, L
   Ye, L
   Tie, Y
   Zhong, W
   Zhang, Q
AF Fang, Li
   Ye, Long
   Tie, Yun
   Zhong, Wei
   Zhang, Qin
TI Design of linear-phase nonsubsampled nonuniform directional filter bank
   with arbitrary directional partitioning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Nonsubsampled nonuniform directional filter banks; Arbitrary directional
   partitioning; Multiresolution decomposition
ID CONTOURLET TRANSFORM
AB In this paper, we propose a design method for linear phase (LP) nonsubsampled nonuniform directional filter bank (NUDFB) with arbitrary number of subbands and arbitrary directional partitioning. The proposed NUDFB is simply designed by windowing the analytical expressions of wedge-shaped filters in space domain. The direction and angular bandwidth of the filters are determined by only two angular parameters. It can extract directional information according to the directional distribution of images, making it efficient in the directional representation of images. In addition, the perfect reconstruction conditions are derived. Numerical experiments on image directional information extraction and image denoising are given to illustrate the performance of our NUDFB. The results show that our NUDFB outperforms various directional decomposition methods while possesses LP property and more flexibility.
C1 [Fang, Li; Ye, Long; Zhong, Wei; Zhang, Qin] Commun Univ China, Key Lab Media Audio & Video, Minist Educ, Beijing 100024, Peoples R China.
   [Tie, Yun] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Henan, Peoples R China.
C3 Communication University of China; Zhengzhou University
RP Ye, L (corresponding author), Commun Univ China, Key Lab Media Audio & Video, Minist Educ, Beijing 100024, Peoples R China.
EM lifang8902@cuc.edu.cn; yelong@cuc.edu.cn; ieytie@zzu.edu.cn;
   wzhong@cuc.edu.cn; zhangqin@cuc.edu.cn
FU NSFC [61371191, 61631016]; Research Project of China SARFT [2015-53]
FX This work is supported by the Projects of NSFC (61371191, 61631016), and
   Research Project of China SARFT (2015-53).
CR Averbuch A, 2006, APPL COMPUT HARMON A, V21, P145, DOI 10.1016/j.acha.2005.11.003
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Eslami R, 2007, IEEE T IMAGE PROCESS, V16, P1152, DOI 10.1109/TIP.2007.891791
   Fang L, 2016, IET SIGNAL PROCESS, V10, P106, DOI 10.1049/iet-spr.2015.0075
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Liang LL, 2011, IEEE T IMAGE PROCESS, V20, P283, DOI 10.1109/TIP.2010.2052267
   Ma N, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P513
   Nguyen TT, 2007, IEEE T SIGNAL PROCES, V55, P949, DOI 10.1109/TSP.2006.887140
   Nguyen TT, 2005, IEEE T SIGNAL PROCES, V53, P3895, DOI 10.1109/TSP.2005.855410
   Park SI, 2004, IEEE T IMAGE PROCESS, V13, P1424, DOI 10.1109/TIP.2004.836186
   PARK SI, 1999, ACOUST SPEECH SIG PR, P1417
   Shi GM, 2009, IEEE T SIGNAL PROCES, V57, P4936, DOI 10.1109/TSP.2009.2027737
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tanaka Y, 2009, IEEE T IMAGE PROCESS, V18, P269, DOI 10.1109/TIP.2008.2008078
NR 17
TC 2
Z9 2
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 23
EP 28
DI 10.1016/j.jvcir.2017.12.013
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500003
DA 2024-07-18
ER

PT J
AU Han, TY
   Kim, DH
   Lee, SH
   Song, BC
AF Han, Tae Young
   Kim, Dae Ha
   Lee, Seung Hyun
   Song, Byung Cheol
TI Infrared image super-resolution using auxiliary convolutional neural
   network and visible image under low-light conditions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Near-infrared and visible images; Super-resolution; Convolutional neural
   networks; Low-light images
ID FUSION
AB Convolutional neural networks (CNN) have been successfully applied to visible image super-resolution (SR) methods. In this study, we propose a CNN-based SR algorithm for up-scaling near-infrared (NIR) images under low-light conditions, using corresponding visible images. Our algorithm first extracts high-frequency (HF) components from the up-scaled low-resolution (LR) NIR image and its corresponding high-resolution (HR) visible image, and then takes them as multiple inputs of the CNN. Next, the CNN outputs the HR HF component of the input NIR image. Finally, an HR NIR image is synthesized by adding the HR HF component to the up scaled LR NIR image. The simulation results show that the proposed algorithm outperforms the state-of-the-art methods, in terms of both qualitative and quantitative aspects.
C1 [Han, Tae Young; Kim, Dae Ha; Lee, Seung Hyun; Song, Byung Cheol] Inha Univ, Dept Elect Engn, 100 Inha Ro, Incheon 22212, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, 100 Inha Ro, Incheon 22212, South Korea.
EM bcsong@inha.ac.kr
RI Song, Byungcheol/AAH-9770-2019; Lee, Seunghyun/AAR-3231-2020; Kim,
   Daeha/HJH-1957-2023
OI Lee, Seunghyun/0000-0001-7139-1764; Song, Byung
   Cheol/0000-0001-8742-3433
FU National Research Foundation of Korea - Korean Government
   [2016R1A2B4007353]; Industrial Strategic Technology Development Program
   - Ministry of Trade, industry & Energy (MI, Korea) [10073154]
FX This research was supported by National Research Foundation of Korea
   Grant funded by the Korean Government (2016R1A2B4007353), and was also
   supported by the Industrial Strategic Technology Development Program
   (10073154, Development of human-friendly human-robot interaction
   technologies using human internal emotional states recognition) funded
   by the Ministry of Trade, industry & Energy (MI, Korea).
CR [Anonymous], 2015, ARXIV150502496
   [Anonymous], 2017, 2017 IEEE C COMP VIS
   [Anonymous], INT C MACH LEARN
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   Brown M, 2011, PROC CVPR IEEE, P177, DOI 10.1109/CVPR.2011.5995637
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chollet F., KERAS DEEP LEARNING
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Ghazali KH, 2014, UKSIM INT CONF COMP, P307, DOI 10.1109/UKSim.2014.111
   Gyaourova A, 2004, LECT NOTES COMPUT SC, V2034, P456
   Han T. Y., 2016, IEEE INT C CONSUMER, P1
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim Yong Jun, 2016, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V53, P73
   Krishnan D, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531402
   Li X, 2011, IET IMAGE PROCESS, V5, P141, DOI 10.1049/iet-ipr.2010.0084
   Lo KH, 2018, IEEE T CYBERNETICS, V48, P371, DOI 10.1109/TCYB.2016.2637661
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Shen XY, 2014, LECT NOTES COMPUT SC, V8692, P309, DOI 10.1007/978-3-319-10593-2_21
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Yan Q, 2013, IEEE I CONF COMP VIS, P1537, DOI 10.1109/ICCV.2013.194
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao Y, 2015, INFRARED PHYS TECHN, V71, P506, DOI 10.1016/j.infrared.2015.06.017
NR 25
TC 22
Z9 24
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 191
EP 200
DI 10.1016/j.jvcir.2018.01.018
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500018
DA 2024-07-18
ER

PT J
AU Xie, N
   Yang, Y
   Shen, HT
   Zhao, TT
AF Xie, Ning
   Yang, Yang
   Shen, Heng Tao
   Zhao, Ting Ting
TI Stroke-based stylization by learning sequential drawing examples
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stroke-based stylization; Reinforcement learning; Inverse reinforcement
   learning
ID IMAGE
AB Among various traditional art forms, brush stroke drawing is one of the widely used styles in modem computer graphic tools such as GIMP, Photoshop and Painter. In this paper, we develop an AI-aided art authoring (A4) system of non-photorealistic rendering that allows users to automatically generate brush stroke paintings in a specific artist's style. Within the reinforcement learning framework of brush stroke generation proposed by Xie et al. (2012), the first contribution in this paper is the application of regularized policy gradient method, which is more suitable for the stroke generation task; the other contribution is to learn artists' drawing styles from video-captured stroke data by inverse reinforcement learning. Through experiments, we demonstrate that our system can successfully learn artists' styles and render pictures with consistent and smooth brush strokes.
C1 [Xie, Ning; Yang, Yang; Shen, Heng Tao] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Ctr Future Media, Chengdu 611731, Sichuan, Peoples R China.
   [Zhao, Ting Ting] Tianjin Univ Sci & Technol, Sch Comp Sci & Informat Engn, Tianjin 300457, Peoples R China.
C3 University of Electronic Science & Technology of China; Tianjin
   University Science & Technology
RP Zhao, TT (corresponding author), Tianjin Univ Sci & Technol, Sch Comp Sci & Informat Engn, Tianjin 300457, Peoples R China.
EM seanxiening@gmail.com; dlyyang@gmail.com; shenhengtao@hotmail.com;
   tingting@tust.edu.cn
RI yang, yang/HGT-7999-2022; Lang, Ming/HIK-0758-2022; Shen, Heng
   Tao/ABD-5331-2021; yang, yang/GVT-5210-2022
FU National Natural Science Foundation of China [61602088, 61572108,
   61632007, 61502339, 61502081]; National Thousand-Young-Talents Program
   of China; Fundamental Research Funds for the Central Universities
   [ZYGX2014Z007, ZYGX2015J055, ZYGX2016J212]
FX This work was supported in part by the National Natural Science
   Foundation of China under Project 61602088, Project 61572108, Project
   61632007, Project 61502339 and Project 61502081, the National
   Thousand-Young-Talents Program of China, and the Fundamental Research
   Funds for the Central Universities under Project ZYGX2014Z007, Project
   ZYGX2015J055 and Project ZYGX2016J212.
CR Abbeel P., 2004, INT C MACH LEARN ICM
   Bar Y, 2015, LECT NOTES COMPUT SC, V8925, P71, DOI 10.1007/978-3-319-16178-5_5
   Baran I, 2010, COMPUT GRAPH FORUM, V29, P655, DOI 10.1111/j.1467-8659.2009.01635.x
   Bousseau A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276507
   Chu Nelson., 2010, P 8 INT S NONPHOTORE, P27, DOI 10.1145/1809939.1809943
   Chu NSH, 2005, ACM T GRAPHIC, V24, P504, DOI 10.1145/1073204.1073221
   Chu NSH, 2004, IEEE COMPUT GRAPH, V24, P76, DOI 10.1109/MCG.2004.37
   Davies E.R., 2005, MACHINE VISION THEOR, V3rd
   Deisenroth M. P., 2011, FOUND TRENDS ROBOT, V2, P1, DOI DOI 10.1561/2300000021
   Fu H., 2011, P ACM SIGGRAPH ASIA, V30
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Greensmith E, 2004, J MACH LEARN RES, V5, P1471
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Igarashi T., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P105, DOI 10.1145/263407.263525
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kakade S, 2002, ADV NEUR IN, V14, P1531
   Kalogerakis E, 2012, ACM T GRAPHIC, V31, DOI [10.1145/2077341.2077342, 10.1145/2185520.2185551]
   Kang H, 2008, COMPUT GRAPH FORUM, V27, P1773, DOI 10.1111/j.1467-8659.2008.01322.x
   Kyprianidis JE, 2009, COMPUT GRAPH FORUM, V28, P1955, DOI 10.1111/j.1467-8659.2009.01574.x
   Lu JW, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185542
   Miyamae A., 2010, ADV NEURAL INFORM PR, V2, P437
   Ning X, 2011, COMPUT GRAPH-UK, V35, P122, DOI 10.1016/j.cag.2010.11.017
   Orbay G, 2011, IEEE T VIS COMPUT GR, V17, P694, DOI 10.1109/TVCG.2010.105
   Peters J, 2008, NEUROCOMPUTING, V71, P1180, DOI 10.1016/j.neucom.2007.11.026
   Peters J, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2219, DOI 10.1109/IROS.2006.282564
   Pham TQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P454, DOI 10.1109/ICME.2005.1521458
   Sehnke F, 2010, NEURAL NETWORKS, V23, P551, DOI 10.1016/j.neunet.2009.12.004
   Sugimoto N, 2014, IEEE-RAS INT C HUMAN, P554, DOI 10.1109/HUMANOIDS.2014.7041417
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   Theodosios P., 1985, AUTOMATIC BEAUTIFIER, P225
   Weaver Lex., 2001, UAI, P538, DOI 10.5555/2074022.2074088
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xie N., 2012, ICML
   Xu SH, 2006, ACM T GRAPHIC, V25, P239, DOI 10.1145/1138450.1138454
   Xu SH, 2008, COMPUT GRAPH FORUM, V27, P1879, DOI 10.1111/j.1467-8659.2008.01335.x
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhao T., 2011, NEURIPS, P262
   Zhao TT, 2013, NEURAL COMPUT, V25, P1512, DOI 10.1162/NECO_a_00452
   Zhao TT, 2012, NEURAL NETWORKS, V26, P118, DOI 10.1016/j.neunet.2011.09.005
   Zitnick CL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461985
NR 40
TC 5
Z9 6
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 29
EP 39
DI 10.1016/j.jvcir.2017.12.012
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500004
DA 2024-07-18
ER

PT J
AU Boudechiche, DE
   Benierbah, S
   Khamadja, M
AF Boudechiche, Djamel Eddine
   Benierbah, Said
   Khamadja, Mohammed
TI Distributed video coding based on vector quantization: Application to
   capsule endoscopy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding; Wireless capsule endoscopy; Vector
   quantization; Side information; Image compression
ID DESIGN; COMPRESSION; QUALITY
AB We present in this paper a new distributed video coding (DVC) architecture for wireless capsule endoscopy. It is based on the state of the art DVC systems, but without using key frames. Instead, it uses an adapted vector quantization (VQ) with a searching complexity that is shifted to the decoder. VQ. allows creating a good side information (SI) by exploiting the similarities in human anatomy. Thus, SI is created from a codebook (CB) rather than by motion compensated prediction. This approach decreases largely the complexity of the encoder, which codes only Wyner-Ziv frames, and allows a progressive decoding. The encoder of the proposed DVC generates only a simple hash that is used by the decoder to select the corresponding VQ codeword. The obtained experimental results show that rate-distortion results are better than those of JPEG, and show the possibility of using scalable coding to control the used rate and energy. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Boudechiche, Djamel Eddine; Benierbah, Said] Mentouri Univ Constantine, Elect Dept, SP Lab, Constantine, Algeria.
   [Khamadja, Mohammed] Larbi Ben Mhidi Univ Oum el Bouaghi, SP Lab, Oum El Bouaghi, Algeria.
   [Khamadja, Mohammed] Larbi Ben Mhidi Univ Oum el Bouaghi, Elect Engn Dept, Oum El Bouaghi, Algeria.
C3 Universite Constantine; Universite d'Oum El Bouaghi; Universite d'Oum El
   Bouaghi
RP Boudechiche, DE (corresponding author), Mentouri Univ Constantine, Elect Dept, SP Lab, Constantine, Algeria.
EM boudechiche.djamel@gmail.com
RI Benierbah, Said/P-3578-2016
OI , Djamel Eddine/0000-0001-7325-4798
CR Al A, 2004, IEEE IMAGE PROC, P525, DOI 10.1109/ICIP.2004.1418806
   [Anonymous], 2014, VIDEO CAPSULE ENDOSC
   [Anonymous], P NETW ADV SYST ANN
   [Anonymous], IEEE INT C IM PROC B
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], AS C SIGN SYST COMP
   [Anonymous], THESIS
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], T INFORM THEORY
   [Anonymous], IEEE J SOLID STATE C
   [Anonymous], 2007, PICT COD S
   [Anonymous], INDEPENDENT JPEG GRO
   [Anonymous], 2008, IEEE BIOM CIRC SYST
   [Anonymous], IEEE INT SYST CHIP C
   [Anonymous], IEEE T SIGNAL PROCES
   [Anonymous], P IEEE INT C IM PROC
   Berens J, 2005, PROC SPIE, V5747, P283, DOI 10.1117/12.594799
   Bjontegaard G., 2001, Document VCEG-M33
   Boudechiche DE, 2014, 2014 6TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING (ISCCSP), P124, DOI 10.1109/ISCCSP.2014.6877831
   Brack T, 2007, DES AUT TEST EUROPE, P331
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Brites C, 2015, SIGNAL PROCESS-IMAGE, V32, P81, DOI 10.1016/j.image.2015.01.003
   Cao Y, 2016, CHINESE J ELECTRON, V25, P121, DOI 10.1049/cje.2016.01.019
   Chen CY, 2006, IEEE T CIRCUITS-I, V53, P578, DOI 10.1109/TCSI.2005.858488
   Chen XK, 2009, IEEE T BIOMED CIRC S, V3, P11, DOI 10.1109/TBCAS.2008.2006493
   Cohen R, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P21, DOI 10.1109/SITIS.2012.14
   COSMAN PC, 1994, P IEEE, V82, P919, DOI 10.1109/5.286196
   Deligiannis N, 2014, IEEE COMMUN LETT, V18, P1675, DOI 10.1109/LCOMM.2014.2349986
   Deligiannis N, 2012, EURASIP J WIREL COMM, P1, DOI 10.1186/1687-1499-2012-106
   Faigel DO, 2008, Capsule endoscopy
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hanca J, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.041008
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P645, DOI 10.1109/TCSVT.2005.846433
   Iddan G, 2000, NATURE, V405, P417, DOI 10.1038/35013140
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Khan TH, 2011, IEEE T CIRC SYST VID, V21, P1534, DOI 10.1109/TCSVT.2011.2163985
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P183, DOI 10.1109/MMSP.2007.4412848
   Li X, 2011, IEEE T CIRC SYST VID, V21, P957, DOI 10.1109/TCSVT.2011.2133750
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Martins R, 2009, IET IMAGE PROCESS, V3, P315, DOI 10.1049/iet-ipr.2008.0201
   Pai YS, 2012, J VIS COMMUN IMAGE R, V23, P63, DOI 10.1016/j.jvcir.2011.08.004
   Shen YC, 2017, IEEE SENS J, V17, P1872, DOI 10.1109/JSEN.2017.2653100
   Sitti M, 2015, P IEEE, V103, P205, DOI 10.1109/JPROC.2014.2385105
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sun TJ, 2012, IEEE T BIO-MED ENG, V59, P3247, DOI 10.1109/TBME.2012.2206809
   Taieb MH, 2013, ENG LET, V21, P1
   Toennies JL, 2010, P I MECH ENG C-J MEC, V224, P1397, DOI 10.1243/09544062JMES1879
   Turcza P, 2007, I W IMAG SYST TECHNI, P180
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wahid K, 2008, IEEE IJCNN, P2761, DOI 10.1109/IJCNN.2008.4634186
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiaoying Liu, 2012, 2012 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI), P737, DOI 10.1109/BHI.2012.6211688
   Xie X, 2006, IEEE J SOLID-ST CIRC, V41, P2390, DOI 10.1109/JSSC.2006.882884
   Xuelin Fang, 2011, Proceedings of the 2011 IEEE International Conference on Mechatronics and Automation (ICMA 2011), P232, DOI 10.1109/ICMA.2011.5985662
   Yu Marcia, 2002, Gastroenterol Nurs, V25, P24, DOI 10.1097/00001610-200201000-00007
NR 58
TC 7
Z9 7
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 14
EP 26
DI 10.1016/j.jvcir.2017.07.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800002
DA 2024-07-18
ER

PT J
AU Tang, LJ
   Li, LD
   Sun, KZ
   Xia, ZF
   Gu, K
   Qian, JS
AF Tang, Lijuan
   Li, Leida
   Sun, Kezheng
   Xia, Zhifang
   Gu, Ke
   Qian, Jiansheng
TI An efficient and effective blind camera image quality metric via
   modeling quaternion wavelet coefficients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image quality evaluation; Camera image quality; Quaternion wavelet
   transform; Random forest
ID BLUR ASSESSMENT; INDEX
AB As an extension of Discrete and Complex Wavelet Transform, Quaternion Wavelet Transform (QWT) has attracted extensive attention in the past few years, because it can provide better analytic representation for 2D images. The QWT of an image consists of four parts, i.e., one magnitude part and three phase parts. The magnitude is nearly shift-invariant, which characterizes features at any spatial location, and the three phases represent the structure of these features. This indicates that QWT is more powerful in representing image structures, and thus is suitable for image quality evaluation. In this paper, an efficient and effective Camera Image Quality Metric (CIQM) is proposed based on QWT, which is utilized to describe the intrinsic structures of an image. For an image, it is first decomposed by QWT with three scales. Then, for each scale, the magnitude and entropy of the subband coefficients, and natural scene statistics of the third phase are calculated. The magnitude is utilized to describe the generalized spectral behavior, and the entropy is used to encode die generalized information of distortions. Since the third phase of QWT is considered to be texture feature, the natural scene statistics of the third phase of QWT is used to measure structure degradations in the proposed method. All these features reflect the self-similarity and independency of image content, which can effectively reflect image distortions. Finally, random forest is utilized to build the quality model. Experiments conducted on three camera image databases and two multiply distorted image databases have proved that CIQM outperforms the relevant state-of-the-art models for both authentically distorted images and multiply distorted images.
C1 [Tang, Lijuan; Li, Leida; Qian, Jiansheng] China Univ Min & Technol, Sch Info & Cont Engn, Xuzhou, Peoples R China.
   [Tang, Lijuan; Sun, Kezheng] Jiangsu Vocat Coll Business, Sch Info & Elec Engn, Nantong, Peoples R China.
   [Xia, Zhifang] State Info Ctr PR China, Beijing, Peoples R China.
   [Gu, Ke] Beijing Univ Technol, BJUT Fac Info Tech, Beijing, Peoples R China.
C3 China University of Mining & Technology; Beijing University of
   Technology
RP Qian, JS (corresponding author), China Univ Min & Technol, Sch Info & Cont Engn, Xuzhou, Peoples R China.
EM qianzhangiqa@163.com
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022; Gu, Ke/AAJ-9684-2021
FU Fundamental Research Funds for the Central Universities [2017XKQY084]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities under Grant 2017XKQY084.
CR Abdelnour AF, 2001, INT CONF ACOUST SPEE, P3693, DOI 10.1109/ICASSP.2001.940644
   [Anonymous], 2010, Categorical image quality (CSIQ) database
   [Anonymous], 2017, IEEE T IMAGE PROCESS
   Bayro-Corrochano E, 2006, J MATH IMAGING VIS, V24, P19, DOI 10.1007/s10851-005-3605-3
   BULOW T, 1999, PROC INT CONF COMP, V1689, P25
   Chan WL, 2008, IEEE T IMAGE PROCESS, V17, P1069, DOI 10.1109/TIP.2008.924282
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Q., 2013, P IEEE C MULT EXP WO, V1, P1, DOI DOI 10.1007/978-3-7091-1419-3_
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Criminisi A., MSRTR201114
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K., 2017, IEEE T NEURAL NETW L
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kadiri M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-41
   Kingsbury N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2000.899397
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2016, NEUROCOMPUTING, V177, P572, DOI 10.1016/j.neucom.2015.11.063
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P122, DOI 10.1109/LSP.2013.2294333
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mallat S., 1998, WAVELET TOUR SIGNAL
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   PERONA P, 1992, IMAGE VISION COMPUT, V10, P663, DOI 10.1016/0262-8856(92)90011-Q
   Qian JS, 2014, DIGIT SIGNAL PROCESS, V33, P125, DOI 10.1016/j.dsp.2014.06.009
   Saad MA, 2015, IEEE SIGNAL PROC LET, V22, P1516, DOI 10.1109/LSP.2015.2406861
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Tang LJ, 2016, J VIS COMMUN IMAGE R, V40, P335, DOI 10.1016/j.jvcir.2016.07.007
   Traore A., 2014, P IEEE INT C IM PROC, V36, P127
   Traoré A, 2015, SIGNAL PROCESS-IMAGE, V36, P127, DOI 10.1016/j.image.2015.06.003
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhu YC, 2016, INT CONF ACOUST SPEE, P1085, DOI 10.1109/ICASSP.2016.7471843
NR 46
TC 15
Z9 15
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 204
EP 212
DI 10.1016/j.jvcir.2017.09.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800017
DA 2024-07-18
ER

PT J
AU Wang, XL
   Zhang, H
   Peng, GH
AF Wang, Xiaolong
   Zhang, Hong
   Peng, Guohua
TI A chordiogram image descriptor using local edgels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual place recognition; Loop closure detection; Chordiogram; Edge
   pixel; Dissimilarity measurement; Order statistics
ID FAB-MAP; BINARY; COLOR; SHAPE
AB Illumination variations result distant image representations of the same places, posing difficulty in image-based place recognition. We propose a shape-based global image descriptor and a matching method to address the problem. To describe a local image patch, a set of robust edge pixels is selected by thresholding a small proportion of pixels with large edge responses and represented by a shape descriptor which captures the local geometric features instead of image intensities. To alleviate the unbalanced distribution of edge pixels, the whole image is partitioned into regular patches and represented by a collection of local descriptors from individual patches. Instead of including the dissimilarity measurements of all patches in comparing two images, we propose to sum up a fraction of small measurements as a way to reject noisy patches. Experiments show that our global image descriptor supported by the proposed matching method achieves the state-of-the-art performance for visual place recognition. (c) 2017 Published by Elsevier Inc.
C1 [Wang, Xiaolong; Peng, Guohua] Northwestern Polytech Univ, Sch Nat & Appl Sci, Dept Appl Math, Xian 710072, Shaanxi, Peoples R China.
   [Zhang, Hong] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
C3 Northwestern Polytechnical University; University of Alberta
RP Wang, XL (corresponding author), Northwestern Polytech Univ, Sch Nat & Appl Sci, Dept Appl Math, Xian 710072, Shaanxi, Peoples R China.
EM wangxiaolongnwpu@163.com; zhang@cs.ualberta.ca; penggh@nwpu.edu.cn
OI Wang, Xiaolong/0000-0003-1201-3530
CR [Anonymous], 2001, P 7 ACM SIGKDD INT C
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S., 2000, Conference on Neural Information Processing Systems, V2, P3
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Cummins M, 2011, INT J ROBOT RES, V30, P1100, DOI 10.1177/0278364910385483
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277
   Glover A., 2014, GARDENS POINT WALKIN
   Hauagge DC, 2012, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2012.6247677
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2013, IEEE SYS MAN CYBERN, P2103, DOI 10.1109/SMC.2013.360
   Hou Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P2238, DOI 10.1109/ICInfA.2015.7279659
   Johns E, 2013, IEEE INT CONF ROBOT, P3212, DOI 10.1109/ICRA.2013.6631024
   Kim J, 2011, PROC CVPR IEEE, P1553, DOI 10.1109/CVPR.2011.5995526
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kovalev V, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P32, DOI 10.1109/MULMM.1998.722972
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li Q, 2016, NEUROCOMPUTING, V199, P114, DOI 10.1016/j.neucom.2016.03.029
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Milford MJ, 2012, IEEE INT CONF ROBOT, P1643, DOI 10.1109/ICRA.2012.6224623
   Neubert P, 2013, 2013 EUROPEAN CONFERENCE ON MOBILE ROBOTS (ECMR 2013), P198, DOI 10.1109/ECMR.2013.6698842
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Shahbazi H, 2011, IEEE INT C INT ROBOT, P1228, DOI 10.1109/IROS.2011.6048862
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Stylianou A, 2015, IEEE WINT CONF APPL, P892, DOI 10.1109/WACV.2015.123
   Sünderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986
   Sünderhauf N, 2011, IEEE INT C INT ROBOT, P1234, DOI 10.1109/IROS.2011.6048590
   Tekin N, 2015, SIG PROCESS COMMUN, P1615, DOI 10.1109/SIU.2015.7130159
   Torii A, 2015, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2015.7298790
   Toshev A, 2012, INT J COMPUT VISION, V99, P123, DOI 10.1007/s11263-012-0521-z
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010
   Wang Z, 2016, J VIS COMMUN IMAGE R, V40, P739, DOI 10.1016/j.jvcir.2016.08.022
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M., 2008, PATTERN RECOGN, P43, DOI DOI 10.5772/6237
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zitnick CL, 2010, LECT NOTES COMPUT SC, V6312, P170, DOI 10.1007/978-3-642-15552-9_13
NR 52
TC 3
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 129
EP 140
DI 10.1016/j.jvcir.2017.09.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800011
DA 2024-07-18
ER

PT J
AU Yue, GH
   Hou, CP
   Gu, K
   Lin, N
AF Yue, Guanghui
   Hou, Chunping
   Gu, Ke
   Lin, Nam
TI No reference image blurriness assessment with local binary patterns
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blurriness/sharpness; Image quality assessment (IQA); No reference (NR);
   Local binary pattern (LBP)
ID QUALITY ASSESSMENT; CLASSIFICATION
AB In this paper, we put forward an effective and efficient no reference image blurriness assessment metric on the basis of local binary pattern (LBP) features. In this proposal, we reveal that part of the LBP histogram bins present monotonously with the degree of blurriness. The proposed method contains the following steps. Firstly, the LBP maps of an input image are extracted with multiple radiuses. And then, the frequency of pattern histogram is analyzed before part of bins are chosen as the features. In addition, we also take the entropy of these bins as another feature. Finally, we learn the extracted features to predict the image blurriness score. Validation of the proposed method is conducted on the blurred images of LIVE-II, CSIQ, TID2008, TID2013, LIVE3D IQA Phase I and LIVE3D IQA Phase II. Experimental results demonstrate that compared with the state-of-the-art image quality assessment (IQA) methods, the proposed algorithm has notable advantage in correlation with subjective perception and computational complexity.
C1 [Yue, Guanghui; Hou, Chunping] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Gu, Ke] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Lin, Nam] Santa Clara Univ, Santa Clara, CA 95053 USA.
C3 Tianjin University; Beijing University of Technology; Santa Clara
   University
RP Yue, GH (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM yueguanghui_2014@tju.edu.cn
RI Gu, Ke/AAJ-9684-2021
FU National Natural Science Foundation of China [61471262, 61731003];
   International (Regional) Cooperation and Exchange [61520106002];
   Doctoral Fund of Ministry of Education of China [20130032110010]
FX Support for this program is provided by the National Natural Science
   Foundation of China under Grants 61471262 and 61731003, the
   International (Regional) Cooperation and Exchange under Grant
   61520106002, and the Doctoral Fund of Ministry of Education of China
   under Grant 20130032110010.
CR [Anonymous], 2010, J ELECT IMAG
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Feichtenhofer C, 2013, IEEE SIGNAL PROC LET, V20, P379, DOI 10.1109/LSP.2013.2248711
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Freitas PG, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON QUALITY OF MULTIMEDIA EXPERIENCE (QOMEX)
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Jun B, 2013, IEEE T PATTERN ANAL, V35, P1423, DOI 10.1109/TPAMI.2012.219
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Md SK, 2015, IEEE SIGNAL PROC LET, V22, P1985, DOI 10.1109/LSP.2015.2449878
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Shao F, 2016, IEEE T MULTIMEDIA, V18, P2104, DOI 10.1109/TMM.2016.2594142
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wee CY, 2010, PATTERN RECOGN, V43, P4055, DOI 10.1016/j.patcog.2010.05.026
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang M, 2013, INT J ENDOCRINOL, V2013, DOI 10.1155/2013/501015
NR 35
TC 22
Z9 26
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 382
EP 391
DI 10.1016/j.jvcir.2017.09.011
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800032
DA 2024-07-18
ER

PT J
AU Li, PY
   Lo, KT
AF Li, Peiya
   Lo, Kwok-Tung
TI Joint image compression and encryption based on order-8 alternating
   transforms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image encryption; Orthogonal transforms; Security analysis; JPEG
   standard
ID SCHEME; DESIGN
AB In this paper, we propose a novel joint image compression and encryption scheme based on JPEG standard. We realize image encryption at JPEG's transformation stage. Instead of only using 8 x 8 discrete cosine transform (DCT) for transformation, we generate new orthogonal transforms by embedding an extra rotation angle of it to different stages' butterflies in 8 x 8 DCT's flow-graph, and then apply them alternatively for transformation according to a predefined secret key. By carefully controlling the number of rotation angles embedded, the quality control of encrypted images can also be achieved. The encryption algorithm is further enhanced by performing block permutation before the entropy encoding stage. Extensive experiments have been conducted to show the good protection and compression performance of our encryption schemes. Finally, a detailed security analysis is provided to show the encryption schemes' resistance to various cryptanalysis methods, such as brute-force attack, key sensitivity analysis, replacement attack and statistical attack.(C) 2017 Elsevier Inc. All rights reserved.
C1 [Li, Peiya; Lo, Kwok-Tung] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Li, PY (corresponding author), Hong Kong Polytech Univ, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
EM yolanda.peiya@connect.polyu.hk; kwok.tung.lo@polyu.edu.hk
RI Lo, Kwok Tung KT/O-2143-2013
CR Agaian S. S., 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P1953, DOI 10.1109/ICSMC.2010.5642260
   [Anonymous], ADV CONCEPTS INTELLI
   Au Yeung SK, 2011, INT CONF ACOUST SPEE, P2436
   Bahrami S, 2013, OPTIK, V124, P3693, DOI 10.1016/j.ijleo.2012.11.028
   Bruen A.A., APPL CRYPTOGRAPHY PR
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   Fisher RonaldR., 1938, Statistical tables for biological, agricultural aad medical research
   Kaukonen K., 1999, STREAM CIPHER ENCRYP
   Li WH, 2009, IEEE INT CON MULTI, P1034, DOI 10.1109/ICME.2009.5202674
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Nag Amitava, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P309, DOI 10.1109/ICSCCN.2011.6024565
   Qiao LT, 1997, ISCE '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CONSUMER ELECTRONICS, P226, DOI 10.1109/ISCE.1997.658393
   Sesha Pallavi Indrakanti P.S. A., 2011, INT J COMPUT APPL, V28, P45
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Tang L., 1997, P 4 ACM INT C MULT, P219
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Wu CP, 2001, PROC SPIE, V4314, P128, DOI 10.1117/12.435392
   Wu CP, 2001, PROC SPIE, V4209, P284, DOI 10.1117/12.420829
   Yeung SKA, 2011, IEEE T CIRC SYST VID, V21, P1341, DOI 10.1109/TCSVT.2011.2125630
   Yeung SKA, 2009, IEEE SIGNAL PROC LET, V16, P893, DOI 10.1109/LSP.2009.2026109
   Younes M.A. Bani, IMAGE ENCRYTION USIN
   Zeng B, 2014, IEEE T INF FOREN SEC, V9, P309, DOI 10.1109/TIFS.2013.2293955
NR 26
TC 21
Z9 21
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 61
EP 71
DI 10.1016/j.jvcir.2017.01.021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lee, JW
   Lee, OY
   Kim, JO
AF Lee, Jae-Won
   Lee, Oh-Young
   Kim, Jong-Ok
TI Dual learning based compression noise reduction in the texture domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compression noise; Learning-based denoising; Dual learning; Texture
   domain
ID DEBLOCKING; ARTIFACTS; REMOVAL; DCT
AB Compression noise reduction is similar to the super-resolution problem in terms of the restoration of lost high-frequency information. Because learning-based approaches have proven successful in the past in terms of addressing the super-resolution problem, we focus on a learning-based technique for compressed image denoising. In this process, it is important to search for the exact prior in a training set. The proposed method utilizes two different databases (i.e., a noisy and a denoised database), which work together in a complementary way. The denoised images from the dual databases are combined into a final denoised one. Additionally, the input noisy image is decomposed into structure and texture components, and only the latter is denoised because most noise tends to exist within the texture component. Experimental results show that the proposed method can reduce compression noise while reconstructing the original information that was lost in the compression process, especially for texture regions. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lee, Jae-Won; Lee, Oh-Young; Kim, Jong-Ok] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Kim, JO (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM jokim@korea.ac.kr
RI KIM, MINJI/IXD-7702-2023
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) [IITP-2016-H8501-16-1017];
   IITP (Institute for Information & communications Technology Promotion);
   Brain Korea 21 Plus Project
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2016-H8501-16-1017) supervised by the IITP
   (Institute for Information & communications Technology Promotion).; This
   work was supported by the Brain Korea 21 Plus Project in 2016.
CR Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Goto T, 2011, IEEE T CONSUM ELECTR, V57, P253, DOI 10.1109/TCE.2011.5735510
   Hu W, 2009, IEEE T CONSUM ELECTR, V55, P2057, DOI 10.1109/TCE.2009.5373769
   Kim J, 2011, IEEE T CONSUM ELECTR, V57, P1944, DOI 10.1109/TCE.2011.6131175
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Ma L, 2012, SIGNAL PROCESS-IMAGE, V27, P54, DOI 10.1016/j.image.2011.05.004
   Ma L, 2008, LECT NOTES COMPUT SC, V5353, P279
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   MINAMI S, 1995, IEEE T CIRC SYST VID, V5, P74, DOI 10.1109/76.388056
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Rossholm A., 2005, P INT C IM PROC ICIP, VII, P1042
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   Shi RJ, 2005, COMPUTER GRAPHICS, IMAGING AND VISION: NEW TRENDS, P147
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Taniguchi K, 2012, 2011 6TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY (ICCIT), P861
   Wu S., 2008, IEEE T CIRCUITS SYST, V11, P1193
   Yang S, 2001, IEEE T CIRC SYST VID, V11, P963, DOI 10.1109/76.937440
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zhai G., 2008, IEEE T MULTIMEDIA, V10
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
NR 27
TC 3
Z9 3
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 98
EP 107
DI 10.1016/j.jvcir.2016.12.014
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400010
DA 2024-07-18
ER

PT J
AU Iuliani, M
   Fanfani, M
   Colombo, C
   Piva, A
AF Iuliani, Massimo
   Fanfani, Marco
   Colombo, Carlo
   Piva, Alessandro
TI Reliability assessment of principal point estimates for forensic
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image Forensics; Scene level analysis; Geometric constraints; Minimum
   Vanishing Angle; Cropping detection; Splicing detection
ID VANISHING POINTS; IMAGE
AB Although quite recent as a forensic research domain, computer vision analysis of scenes is likely to become more and more important in the near future, thanks to its robustness to image alterations at the signal level, such as image compression and filtering. However, the experimental assessment of vision-based forensic algorithms is a particularly critical task, since they cannot be tested on massive amounts of data, and their performance can heavily depend on user skill. In this paper we investigate on the accuracy and reliability of a vision-based, user-supervised method for the estimation of the camera principal point, to be used in cropping and splicing detection. Results of an extensive experimental evaluation show how the estimation accuracy depends on perspective conditions as well as on the selected image features. Such evidence led us to define a novel visual feature, referred to as Minimum Vanishing Angle, which can be used to assess the reliability of the method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Iuliani, Massimo] Univ Florence, Dept Math & Comp Sci, Florence, Italy.
   [Fanfani, Marco; Colombo, Carlo; Piva, Alessandro] Univ Florence, Dept Informat Engn, Florence, Italy.
   [Iuliani, Massimo; Piva, Alessandro] Univ Florence, FORLAB Multimedia Forens Lab, Prato, Italy.
C3 University of Florence; University of Florence; University of Florence
RP Piva, A (corresponding author), Univ Florence, Dept Informat Engn, Florence, Italy.; Piva, A (corresponding author), Univ Florence, FORLAB Multimedia Forens Lab, Prato, Italy.
EM alessandro.piva@unifi.it
RI Colombo, Carlo/AAC-6675-2019; Piva, Alessandro/B-8948-2008; Fanfani,
   Marco/V-9052-2018
OI Fanfani, Marco/0000-0003-3741-1842; COLOMBO, CARLO/0000-0001-9234-537X
FU GNSAGA of INdAM; Air Force Research Laboratory; Defense Advanced
   Research Projects Agency [FA8750-16-2-0188]
FX The first author is partially supported by GNSAGA of INdAM. This
   material is based on research partially sponsored by the Air Force
   Research Laboratory and the Defense Advanced Research Projects Agency
   under agreement number FA8750-16-2-0188. The U.S. Government is
   authorized to reproduce and distribute reprints for Governmental
   purposes notwithstanding any copyright notation thereon. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of the Air Force Research
   Laboratory and the Defense Advanced Research Projects Agency or the U.S.
   Government.
CR [Anonymous], IEEE INT WORKSH P IN
   [Anonymous], 2013, IEEE ACCESS, DOI DOI 10.1109/ACCESS.2013.2260814
   [Anonymous], 2013, ISRN SIGNAL PROCESS
   [Anonymous], CHIN J ELECT
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P SPIE
   [Anonymous], 2011, TEXTS COMPUT SCI
   Bazin JC, 2012, IEEE INT C INT ROBOT, P4282, DOI 10.1109/IROS.2012.6385802
   Bazin JC, 2012, PROC CVPR IEEE, P638, DOI 10.1109/CVPR.2012.6247731
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Colombo C, 2006, LECT NOTES COMPUT SC, V3951, P265
   Coughlan J. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P941, DOI 10.1109/ICCV.1999.790349
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Deutscher J, 2002, LECT NOTES COMPUT SC, V2353, P175
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Guillou E, 2000, VISUAL COMPUT, V16, P396, DOI 10.1007/PL00013394
   Jing Hu, 2011, 2011 International Conference on Computer Science and Service System (CSSS), P404
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson MK, 2008, LECT NOTES COMPUT SC, V5041, P19
   Kee E, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487236
   Kosecká J, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P223, DOI 10.1109/ROBOT.2002.1013365
   Li B, 2015, IEEE T INF FOREN SEC, V10, P558, DOI 10.1109/TIFS.2015.2389148
   Li Yan, 2014, [The Journal of China Universities of Posts and Telecommunications, 中国邮电高校学报], V21, P83
   Medioni G., 2004, EMERGING TOPICS COMP
   Pflugfelder R., 2005, Proc. IEEE DICTA, P75
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Rother C., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P382
   Tardif Jean-Philippe, 2009, 2009 IEEE 12th International Conference on Computer Vision (ICCV), P1250, DOI 10.1109/ICCV.2009.5459328
   Toldo R, 2015, COMPUT VIS IMAGE UND, V140, P127, DOI 10.1016/j.cviu.2015.05.011
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Tuytelaars T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P67, DOI 10.1109/ICCV.1998.710702
   Yao H, 2012, IEEE SIGNAL PROC LET, V19, P123, DOI 10.1109/LSP.2011.2182191
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 39
TC 5
Z9 5
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 65
EP 77
DI 10.1016/j.jvcir.2016.11.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200006
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Riaz, I
   Yu, T
   Rehman, Y
   Shin, H
AF Riaz, Irfan
   Yu, Teng
   Rehman, Yawar
   Shin, Hyunchul
TI Single image dehazing via reliability guided fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dehaze; Defog; Image restoration; Dark channel; Reliability guided
   fusion; Transmission estimation
ID ENHANCEMENT
AB This work addresses the shortcomings of the dark channel prior (DCP) and proposes a new and efficient method for transmission estimation. First, the accuracy of block-level and pixel-level dark channels is improved and a reliability map is generated. Then, through reliability guided fusion of block-level and pixel-level dark channels, a high-quality refined transmission map is obtained. The proposed method reduces the DCP failure probability and haloes by increasing the patch-size in an edge-preserving manner. DCP failure in the sky (bright) regions is handled by limiting the contrast boost of sky-like surfaces. This produces a more natural recovery of the sky regions. A downscaling method for fast transmission computation has also been proposed. Quantitative and qualitative comparisons show that the proposed method outperforms existing methods in terms of quality and speed. The proposed reliability guided fusion scheme is about 60 times faster than other well-known DCP based approaches. (C) 2016 Published by Elsevier Inc.
C1 [Riaz, Irfan; Yu, Teng; Rehman, Yawar; Shin, Hyunchul] Hanyang Univ, Dept Elect & Commun Engn, Ansan, South Korea.
C3 Hanyang University
RP Shin, H (corresponding author), Hanyang Univ, Dept Elect & Commun Engn, Ansan, South Korea.
EM irfancra@hanyang.ac.kr; yuteng@qdu.edu.cn; yawar@hanyang.ac.kr;
   shin@hanyang.ac.kr
RI Rehman, Yawar/ACL-3068-2022
OI Rehman, Yawar/0000-0001-9743-729X
FU National Research Foundation of Korea (NRF) Grant - Korean Government
   (MOE) [NRF-2013R1A1A2004421]; Higher Education Commission (HEC) of the
   Government of Pakistan
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant funded by the Korean Government (MOE)
   (NRF-2013R1A1A2004421). Moreover, the authors Irfan Riaz and Yawar
   Rehman are sponsored by Higher Education Commission (HEC) of the
   Government of Pakistan.
CR [Anonymous], 2010, P CVPR
   Badino H, 2009, LECT NOTES COMPUT SC, V5748, P51, DOI 10.1007/978-3-642-03798-6_6
   Carr P, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P103, DOI 10.1109/DICTA.2009.25
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-37
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hinds W.C., 1982, AEROSOL TECHNOLOGY, P1
   Huang Jinggang., 2000, C COMPUTER VISION PA, P1324
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Lemire D., 2006, Nordic Journal of Computing, V13, P328
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P5432, DOI 10.1109/TIP.2015.2482903
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Porter T., 1984, Computers & Graphics, V18, P253
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schaul L., 2009, ICIP
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Tan KK, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P788, DOI 10.1109/ICIP.2000.899827
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang YK, 2014, IEEE T IMAGE PROCESS, V23, P4826, DOI 10.1109/TIP.2014.2358076
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu T, 2015, IET IMAGE PROCESS, V9, P725, DOI 10.1049/iet-ipr.2015.0087
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 33
TC 32
Z9 33
U1 1
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 85
EP 97
DI 10.1016/j.jvcir.2016.06.011
PN A
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500010
DA 2024-07-18
ER

PT J
AU Ou, B
   Li, XL
   Wang, JW
AF Ou, Bo
   Li, Xiaolong
   Wang, Jinwei
TI High-fidelity reversible data hiding based on pixel-value-ordering and
   pairwise prediction-error expansion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Pixel-value-ordering; Pairwise prediction-error
   expansion; Reversible 2D mapping
ID DIFFERENCE EXPANSION; IMAGE WATERMARKING; STEGANALYSIS; FRAMEWORK
AB Pixel-value-ordering (PVO) technique refers to the process of first ranking the pixels in a block and then modifying the maximum/minimum for reversible data hiding (RDH). This paper discusses the PVO embedding in two-dimensional (2D) space and utilizes the prediction-error pair within a block for data embedding. We focus on not only the exploitation of conventional PVO embedding but also its effective implementation in 2D form. The PVO embedding is extended into a 2D form by integrating the pairwise prediction-error expansion, and a reversible 2D mapping adapted to the special distribution of prediction-error pairs is proposed. Moreover, an adaptive mapping selection mechanism is proposed to treat separately rough and smooth prediction-error pairs to further optimize the embedding performance. Experimental results show that the proposed method outperforms the previous PVO-based methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ou, Bo] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Xiaolong] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Peking University; Nanjing University of Information
   Science & Technology
RP Ou, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM oubo@hnu.edu.cn; lixiaolong@pku.edu.cn; wjwei_2004@163.com
RI li, xiao/GSN-6181-2022; Li, xiaolong/GRS-9148-2022; OU, BO/L-2212-2013
OI Ou, Bo/0000-0001-6936-9955
FU National Science Foundation of China [61502160, 61572052, 61272421];
   PAPD fund; CICAEET fund
FX This work is supported by the National Science Foundation of China (Nos.
   61502160, 61572052 and 61272421), the PAPD fund and the CICAEET fund.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Caldelli R, 2010, EURASIP J INFORM SEC, V2010, P2
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J., 2009, INFORM HIDING
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin YC, 2011, SIGNAL PROCESS-IMAGE, V26, P628, DOI 10.1016/j.image.2011.07.001
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sencar HusrevTaha., 2012, Digital Image Forensics - There is More to a Picture than Meets the Eye, DOI DOI 10.1007/978-1-4614-0757-7
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xia Z., 2015, IEEE T PARALL DISTR, V10, P2016
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
NR 50
TC 91
Z9 101
U1 4
U2 49
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 12
EP 23
DI 10.1016/j.jvcir.2016.05.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900002
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, G
   Zhang, JS
   Li, DF
AF Chen, Gao
   Zhang, Jiashu
   Li, Defang
TI Fractional-order total variation combined with sparsifying transforms
   for compressive sensing sparse image reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Two-dimensional compressive sensing; Reconstruction; Fractional-order
   total variation; Gradient projection
ID REGULARIZATION; ALGORITHM
AB The total variation (TV) model has been considered to be one of the most successful and representative model for compressive sensing (CS) sparse image reconstruction due to its advantage of preserving image edges. However, TV regularized term often favors piecewise constant solution and therefore it fails to preserve the details and textures. To overcome this defect and reconstruct the fine details, this paper proposes a two-dimensional CS sparse image reconstruction model by introducing the fractional-order TV (FrTV) regularization constraint into CS optimization problem. Furthermore, in order to achieve sparser representation flexibly, a combination of discrete wavelet transform and curvelet transform l(1)-norm regularization is also incorporated into the cost function and a method for estimating the regularization parameter that trades off the two terms in the cost function is proposed. By using a smooth approximation of the l(1)-norm, a gradient projection algorithm is derived to solve the combined FrTV and sparsifying transforms constrained minimization problem effectively. Compared with several state-of-the-art reconstruction algorithms, the proposed algorithm is more efficient and robust, not only yielding higher peak-signal-to-noise ratio, but also reconstructing the fine details and textures more efficiently. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Gao; Zhang, Jiashu; Li, Defang] Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
C3 Southwest Jiaotong University
RP Zhang, JS (corresponding author), Southwest Jiaotong Univ, Sichuan Prov Key Lab Signal & Informat Proc, Chengdu 610031, Peoples R China.
EM gchen984@gmail.com; jszhang@home.swjtu.edu.cn; Idf125@home.swjtu.edu.cn
OI Chen, Gao/0000-0003-3865-0896
FU National Science Foundation of PR China [61271341]; Sichuan Science
   Technology Foundation [2013JY0136]
FX This work was supported by National Science Foundation of PR China
   (Grant: 61271341) and the Sichuan Science Technology Foundation (Grant:
   2013JY0136).
CR [Anonymous], P INT C AC SPEECH SI
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Chen G, 2014, SIGNAL PROCESS, V104, P15, DOI 10.1016/j.sigpro.2014.03.039
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Eftekhari A, 2011, SIGNAL PROCESS, V91, P1589, DOI 10.1016/j.sigpro.2011.01.002
   James AP, 2012, COMPUT J, V55, P1072, DOI 10.1093/comjnl/bxs001
   Jun Z, 2011, APPL MATH MODEL, V35, P2516, DOI 10.1016/j.apm.2010.11.049
   Li Chengbo., 2009, Tval3: Tv minimization by augmented lagrangian and alternating direction algorithm
   Liao L., 2011, P INT C MULTIMEDIA T, P1
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Marjanovic G, 2010, INT CONF ACOUST SPEE, P3766, DOI 10.1109/ICASSP.2010.5495861
   Qu X, 2010, ELECTRON LETT, V46, P121, DOI 10.1049/el.2010.1845
   Ren ZM, 2013, SIGNAL PROCESS, V93, P2408, DOI 10.1016/j.sigpro.2013.02.015
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tian D, 2015, INFORM SCIENCES, V296, P147, DOI 10.1016/j.ins.2014.10.050
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang AH, 2014, SIGNAL PROCESS-IMAGE, V29, P599, DOI 10.1016/j.image.2014.03.002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 27
TC 22
Z9 26
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 407
EP 422
DI 10.1016/j.jvcir.2016.03.018
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100035
OA Bronze
DA 2024-07-18
ER

PT J
AU Li, D
   Wang, Q
   Shen, Y
AF Li, Dan
   Wang, Qiang
   Shen, Yi
TI Predicted multi-variable intelligent matching pursuit algorithm for
   image sequences reconstruction based on <i>l</i><sub>0</sub>
   minimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image sequences reconstruction; Prior information; Multi-variable
   sampling; l(0) minimization; Intelligent optimization algorithm;
   Matching strategies
ID PARALLEL FRAMEWORK; SIGNAL RECOVERY; SPARSE; SUPERRESOLUTION
AB In this paper, we study the problem of reconstructing image sequences which satisfy the conditions that (a) the sparsity level is high in the wavelet domain and (b) the sparsity pattern of adjacent images changes very slowly. The idea of the proposed method predicted multi-variable intelligent matching pursuit (PMIMP) algorithm is to use the estimated support collection of the previous image as prior information and then utilize the prior information to guide the current image reconstruction by solving 10 minimization. Multi-variable scheme is used to sample image sequences to enhance the guidance of prior information and improve the reconstruction accuracy with fewer measurements. to minimization is an NP-hard problem that requires exhaustively listing all possibilities of the original signal and is difficult to be achieved by traditional algorithms. To solve it, we take advantage of the intelligent optimization algorithm which is famous for its global searching ability and superior performance in solving combinatorial optimization problems. To improve the reconstruction speed, matching strategies of greedy algorithm, which performs quite well in reconstruction speed, are utilized to design the updating mechanism of PMIMP. As the sparsity level is hard to be estimated in image sequences reconstruction, we propose a novel optimization function which does not need the sparsity level known as a prior. We illustrate the reconstruction performance of our proposed method PMIMP on several image sequences and compare it with the state-of-the-art algorithms. The experimental results demonstrate that PMIMP achieves the best reconstruction performance in both PSNR, SSIM and visual quality with fewer measurements. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Li, Dan; Wang, Qiang; Shen, Yi] Harbin Inst Technol, Control Sci & Engn, 92 West Da Zhi St, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Li, D (corresponding author), Harbin Inst Technol, Control Sci & Engn, 92 West Da Zhi St, Harbin 150001, Peoples R China.
EM lidanhit@163.com; wangqiang@hit.edu.cn; shen@hit.edu.cn
RI Wang, Qiang/B-1053-2012; Shen, Yi/GRS-3602-2022
OI Wang, Qiang/0000-0002-9654-0268; 
FU National Science Foundations of China [61174016, 61171197]
FX This work is financially supported by National Science Foundations of
   China (No. 61174016) and (No. 61171197).
CR Bai Qinghai, 2010, COMPUTER INFORM SCI, V3, P180, DOI DOI 10.5539/CIS.V3N1P180
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Chen TG, 2009, INTERNATIONAL JOINT CONFERENCE ON COMPUTATIONAL SCIENCES AND OPTIMIZATION, VOL 2, PROCEEDINGS, P864, DOI 10.1109/CSO.2009.183
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du XP, 2014, SIGNAL PROCESS, V100, P1, DOI 10.1016/j.sigpro.2014.01.002
   Du XP, 2014, NEUROCOMPUTING, V131, P98, DOI 10.1016/j.neucom.2013.10.036
   Gamper U, 2008, MAGN RESON MED, V59, P365, DOI 10.1002/mrm.21477
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Huang HL, 2011, IEEE SIGNAL PROC LET, V18, P391, DOI 10.1109/LSP.2011.2147313
   Jung H, 2009, MAGN RESON MED, V61, P103, DOI 10.1002/mrm.21757
   Karaboga D, 2007, LECT NOTES COMPUT SC, V4529, P789, DOI 10.1007/978-3-540-72950-1_77
   Li D, 2014, IEEE IMTC P, P76, DOI 10.1109/I2MTC.2014.6860526
   Li D, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1023, DOI 10.1109/ICInfA.2013.6720445
   Liu ET, 2012, IEEE T INFORM THEORY, V58, P2040, DOI 10.1109/TIT.2011.2177632
   Lu W, 2012, IEEE T SIGNAL PROCES, V60, P2634, DOI 10.1109/TSP.2012.2186445
   Lu W, 2012, IEEE T SIGNAL PROCES, V60, P182, DOI 10.1109/TSP.2011.2170981
   Lu W, 2009, IEEE IMAGE PROC, P3045, DOI 10.1109/ICIP.2009.5414208
   LUNDY M, 1986, MATH PROGRAM, V34, P111, DOI 10.1007/BF01582166
   Mehmood I, 2015, INFORM FUSION, V24, P16, DOI 10.1016/j.inffus.2014.07.002
   Mosleh A, 2015, SIGNAL PROCESS-IMAGE, V30, P137, DOI 10.1016/j.image.2014.10.010
   MUHLENBEIN H, 1991, PARALLEL COMPUT, V17, P619, DOI 10.1016/S0167-8191(05)80052-3
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D., TOPICS COMPRESSED SE
   Plumbley MD, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P14
   Sajjad M, 2016, SIGNAL IMAGE VIDEO P, V10, P181, DOI 10.1007/s11760-014-0724-6
   Sajjad M, 2015, J VIS COMMUN IMAGE R, V26, P50, DOI 10.1016/j.jvcir.2014.10.012
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4595, DOI 10.1109/TSP.2010.2051150
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4108, DOI 10.1109/TSP.2010.2048105
   Vaswani N, 2008, IEEE IMAGE PROC, P893, DOI 10.1109/ICIP.2008.4711899
   Wakin M., 2006, PICT COD S APR, V1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Lu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2689, DOI 10.1109/ICIP.2011.6116222
   Wipf DP, 2004, IEEE T SIGNAL PROCES, V52, P2153, DOI 10.1109/TSP.2004.831016
   Wu J, 2013, SIGNAL PROCESS, V93, P1662, DOI 10.1016/j.sigpro.2012.09.010
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P3483, DOI 10.1109/TIP.2011.2150231
   Xu FM, 2013, SIGNAL PROCESS, V93, P1577, DOI 10.1016/j.sigpro.2012.10.019
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zonoobi D, 2013, J VIS COMMUN IMAGE R, V24, P196, DOI 10.1016/j.jvcir.2012.05.002
NR 47
TC 3
Z9 3
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 316
EP 327
DI 10.1016/j.jvcir.2016.03.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100027
OA Bronze
DA 2024-07-18
ER

PT J
AU Moeini, A
   Faez, K
   Sadeghi, H
   Moeini, H
AF Moeini, Ali
   Faez, Karim
   Sadeghi, Hamid
   Moeini, Hossein
TI 2D facial expression recognition via 3D reconstruction and feature
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Facial expression generic elastic model;
   3D local binary pattern; Local normal binary pattern;
   Expression-invariant 3D face reconstruction; Local binary pattern;
   Feature fusion; 2D and 3D features
ID FACE RECOGNITION; CLASSIFICATION
AB In this paper, a novel feature extraction method is proposed for facial expression recognition by extracting the feature from facial depth and 3D mesh alongside texture. Accordingly, the 3D Facial Expression Generic Elastic Model (3D FE-GEM) method is used to reconstruct an expression-invariant 3D model from the human face. Then, the texture, depth and mesh are extracted from the reconstructed face model. Afterwards, the Local Binary Pattern (LBP), proposed 3D High-Low Local Binary Pattern (3DH-LLBP) and Local Normal Binary Patterns (LNBPs) are applied to texture, depth and mesh of the face, respectively, to extract the feature from 2D images. Finally, the final feature vectors are generated through feature fusion and are classified by the Support Vector Machine (SVM). Convincing results are acquired for facial expression recognition on the CK+, CK, JAFFE and Bosphorus image databases compared to several stateof-the-art methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Moeini, Ali; Faez, Karim; Sadeghi, Hamid] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Moeini, Hossein] Semnan Univ, Dept Elect Engn, Semnan, Iran.
C3 Amirkabir University of Technology; Semnan University
RP Moeini, A (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
EM ali.moeini1989@gmail.com
RI faez, karim/K-5117-2019
OI faez, karim/0000-0002-1159-4866
CR [Anonymous], IJCAI 2013
   [Anonymous], FG
   [Anonymous], CVPR
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], BMVC
   [Anonymous], 2013, CVPR
   [Anonymous], INT C PATT REC ICPR
   Azazi A, 2015, EXPERT SYST APPL, V42, P3056, DOI 10.1016/j.eswa.2014.10.042
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Heo J, 2012, IEEE T INF FOREN SEC, V7, P563, DOI 10.1109/TIFS.2012.2184755
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang Y, 2006, BMVC
   Huang YH, 2012, IMAGE VISION COMPUT, V30, P750, DOI 10.1016/j.imavis.2011.12.008
   Jiang B., 2011, IEEE C AUT FAC GEST
   Kanade T., 2000, 4 IEEE INT C AUT FAC
   Liao S, 2009, IEEE IMAGE PROC, P3317, DOI 10.1109/ICIP.2009.5413904
   Liu S, 2012, IMAGE VISION COMPUT, V30, P535, DOI 10.1016/j.imavis.2012.05.004
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Moeini A., 2014, P INT C PATT REC ICP
   Moeini A, 2015, PATTERN RECOGN LETT, V68, P83, DOI 10.1016/j.patrec.2015.08.012
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Moeini A, 2015, IMAGE VISION COMPUT, V36, P9, DOI 10.1016/j.imavis.2015.01.007
   Moeini A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053013
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123
   Ptucha R, 2013, IMAGE VISION COMPUT, V31, P365, DOI 10.1016/j.imavis.2013.03.003
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rudovic Ognjen., 2012, CVPR
   Sandbach G., 2012, ICIP
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Taheri S, 2014, IEEE T IMAGE PROCESS, V23, P3590, DOI 10.1109/TIP.2014.2331141
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Xie S., 2008, P 19 INT C PATT REC, P1, DOI DOI 10.1109/WICOM.2008.1011008
   Yang SF, 2012, IEEE T SYST MAN CY B, V42, P980, DOI 10.1109/TSMCB.2012.2192269
   Zhang W., 2005, ICCV
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
NR 54
TC 15
Z9 16
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 1
EP 14
DI 10.1016/j.jvcir.2015.11.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600001
DA 2024-07-18
ER

PT J
AU Chen, W
   Cai, ZC
AF Chen, Wei
   Cai, Zhanchuan
TI Orthogonal Polar V Transforms and application to shape retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE V-system; Moments; Orthogonal piecewise polynomial; Rotation-invariant;
   Multi-scale features; Low computational complexity; Shape; Perspective
   distortion
ID IMAGE-ANALYSIS; WAVELET DESCRIPTOR; ZERNIKE; RECOGNITION; MOMENTS
AB The traditional orthogonal moments (e.g., Zernike moments) are formulated with polynomials as their basis that often face the problem of computation difficulty especially with the high-order moments. In this paper, we present a novel set of transforms namely the Polar V Transforms (PVTs). We can use the PVTs not only to generate the rotation-invariant features but also to capture global and local information of images. Since the PVTs basis functions can keep a low order of polynomials, we can significantly speed-up the runtime for computing the kernels. The experimental results have demonstrated that our proposed method outperforms the previous methods in runtimes and achieves very good results in shape retrieval compared to the previous methods especially when the images with high degree of perspective distortions. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Wei] Jiangnan Univ, Sch Digital Media, Wuxi 214122, Peoples R China.
   [Cai, Zhanchuan] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Peoples R China.
C3 Jiangnan University; Macau University of Science & Technology
RP Chen, W (corresponding author), Jiangnan Univ, Sch Digital Media, Wuxi 214122, Peoples R China.
EM chenwei.must@gmail.com
RI Li, Yan/JUU-5189-2023; long, wang/KGM-0871-2024
FU National Basic Research Program of China [2011CB302400]; National
   Natural Science Foundation of China [61170320, 61272026]; Science and
   Technology Development Fund of Macau [110/2014/A3, 084/2012/A3]; Open
   Project Program of the State Key Lab of CAD&CG of Zhejiang University
   [A1513]; Fundamental Research Funds for the Central Universities of
   China [JUSRP11416]
FX This work was supported by the National Basic Research Program of China
   (Grant No. 2011CB302400), the National Natural Science Foundation of
   China (Grant No. 61170320 and 61272026) the Science and Technology
   Development Fund of Macau (Grant No. 110/2014/A3 and 084/2012/A3), the
   Open Project Program of the State Key Lab of CAD&CG of Zhejiang
   University (Grant No. A1513) and Fundamental Research Funds for the
   Central Universities of China (Grant No. JUSRP11416).
CR Al-Rawi M, 2008, J REAL-TIME IMAGE PR, V3, P89, DOI 10.1007/s11554-007-0069-2
   Chen GY, 1999, PATTERN RECOGN, V32, P1083, DOI 10.1016/S0031-3203(98)00148-4
   Chen Z, 2010, IEEE T IMAGE PROCESS, V19, P205, DOI 10.1109/TIP.2009.2032890
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   Gope C, 2004, P ANN INT IEEE EMBS, V26, P1455
   Huang C, 2012, ACTA MATH SIN, V28, P105, DOI 10.1007/s10114-012-9424-8
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim HK, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P307, DOI 10.1109/ICME.2000.869602
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Lin HB, 2008, IEEE T IMAGE PROCESS, V17, P272, DOI 10.1109/TIP.2007.916157
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Novotni M., 2003, P 8 ACM S SOL MOD AP, P216, DOI DOI 10.1145/781606.781639
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   SHENG Y, 1986, J OPT SOC AM A, V3, P885, DOI 10.1364/JOSAA.3.000885
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Song RX, 2007, COMMUN PUR APPL ANAL, V6, P853
   Song RX, 2012, J ADV MECH DES SYST, V6, P340, DOI 10.1299/jamdsm.6.340
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
NR 24
TC 1
Z9 2
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 146
EP 152
DI 10.1016/j.jvcir.2015.11.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400013
DA 2024-07-18
ER

PT J
AU Grecova, S
   Morillas, S
AF Grecova, Svetlana
   Morillas, Samuel
TI Perceptual similarity between color images using fuzzy metrics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color imaging; Fuzzy logic; Fuzzy metrics; Perceptual image similarity;
   Color similarity; Perceptual observations; Low level image processing;
   Color image quality
ID STRUCTURAL SIMILARITY; IMPULSE NOISE; QUALITY
AB In many applications of the computer vision field measuring the similarity between (color) images is of paramount importance. However, the commonly used pixelwise similarity measures such as Mean Absolute Error, Peak Signal to Noise Ratio, Mean Squared Error or Normalized Color Difference do not match well with perceptual similarity. Recently, it has been proposed a method for gray-scale image similarity that correlates quite well with the perceptual similarity and it has been extended to color images. In this paper we use the basic ideas in this recent work to propose an alternative method based on fuzzy metrics for perceptual color image similarity. Experimental results employing a survey of observations show that the global performance of our proposal is competitive with best state of the art methods and that it shows some advantages in performance for images with low correlation among some image channels. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Grecova, Svetlana] Univ Latvia, Dept Math, Riga, Latvia.
   [Morillas, Samuel] Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, E-46022 Valencia, Spain.
C3 University of Latvia; Universitat Politecnica de Valencia
RP Grecova, S (corresponding author), Univ Latvia, Dept Math, Riga, Latvia.
EM grecova.svetlana@gmail.com; smorillas@mat.upv.es
RI Morillas, Samuel/H-2610-2015
OI Morillas, Samuel/0000-0001-9262-6139
CR [Anonymous], 2013, Int. J. Sci. Res.
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Camarena JG, 2010, PATTERN RECOGN LETT, V31, P1842, DOI 10.1016/j.patrec.2010.01.008
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Charrier C., 2004, EUR SIGN PROC C
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Hassan M., 2012, International Journal of Computer Applications, V43, P7
   Hore ES, 2005, OPT ENG, V44, DOI 10.1117/1.1883696
   Le Callet P, 2003, IEEE IMAGE PROC, P437
   Lee SM, 2005, COLOR RES APPL, V30, P265, DOI 10.1002/col.20122
   Li CF, 2010, SIGNAL PROCESS-IMAGE, V25, P517, DOI 10.1016/j.image.2010.03.004
   Mitsa T., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P301, DOI 10.1109/ICASSP.1993.319807
   Morillas S, 2005, LECT NOTES COMPUT SC, V3656, P81, DOI 10.1007/11559573_11
   Morillas S, 2005, REAL-TIME IMAGING, V11, P417, DOI 10.1016/j.rti.2005.06.007
   Morillas S, 2006, LECT NOTES COMPUT SC, V4141, P138
   Morillas S, 2009, IEEE T IMAGE PROCESS, V18, P1452, DOI 10.1109/TIP.2009.2019305
   Ninassi A., 2006, P SPIE C HUM VIS EL, VXI, P6057
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Süsstrunk S, 2004, PROC SPIE, V5304, P118, DOI 10.1117/12.537804
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 26
TC 15
Z9 15
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 230
EP 235
DI 10.1016/j.jvcir.2015.04.003
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400020
OA Green Published
DA 2024-07-18
ER

PT J
AU Lee, CP
   Tan, AWC
   Tan, SC
AF Lee, Chin Poo
   Tan, Alan W. C.
   Tan, Shing Chiang
TI Gait recognition with Transient Binary Patterns
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; Gait; Human walking; Transient Binary Patterns; Binary
   Patterns; Texture; Texture descriptor; Histograms
ID IMAGE; ANGLE
AB In this work, we present a combination of spatiotemporal approach and texture descriptors to extract the temporal patterns in gait cycles. Unlike most conventional methods that focus on spatial information while limiting temporal information captured, spatiotemporal methods preserve both spatial and temporal information. Inspired by the success of texture descriptors in face recognition, the proposed method likewise constructs texture descriptors of gait motion over time. For each gait cycle, the pixel-wise binary patterns along the temporal axis, referred to as the Transient Binary Patterns (TBP), is analyzed. These pixel-wise TBPs are then grouped into regional blocks from which we construct regional TBP histograms. These regional TBP histograms collectively form the global TBP histogram that represents both the distribution of temporal patterns and spatial location. Experimental results clearly show the superiority of the proposed approach over other considered methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lee, Chin Poo; Tan, Shing Chiang] Multimedia Univ, Fac Informat Sci & Technol, Melaka 75450, Malaysia.
   [Tan, Alan W. C.] Multimedia Univ, Fac Engn & Technol, Melaka 75450, Malaysia.
C3 Multimedia University; Multimedia University
RP Lee, CP (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
EM cplee@mmu.edu.my; wctan@mmu.edu.my; sctan@mmu.edu.my
RI Tan, SC/E-6463-2010; /AGV-9105-2022
OI Tan, SC/0000-0002-1267-1894; Lee, Chin Poo/0000-0003-3679-8977
FU Fundamental Research Grant Scheme [MMUE/140073]
FX Research reported in this paper was supported by Fundamental Research
   Grant Scheme, Grant No. MMUE/140073. Portions of the research in this
   paper use the CASIA Gait Database collected by Institute of Automation,
   Chinese Academy of Sciences.
CR [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], 2001, Cmu Ri Tr 01-18
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   CEDRAS C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P214, DOI 10.1109/CVPR.1994.323832
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Kale A., 2004, Handbook on Pattern Recognition and Computer Vision
   Kellokumpu V, 2009, LECT NOTES COMPUT SC, V5558, P1000, DOI 10.1007/978-3-642-01793-3_101
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P1489, DOI 10.1016/j.jvcir.2014.05.006
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liu YX, 2002, LECT NOTES COMPUT SC, V2351, P657
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Mowbray SD, 2003, LECT NOTES COMPUT SC, V2688, P566
   Mu Y, 2010, NEUROCOMPUTING, V73, P895, DOI 10.1016/j.neucom.2009.09.017
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Ohara Y., 2004, Proceedings of 5th Workshop on Omnidirectional Vision, Camera Networks and Non-classical Cameras, P79
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Wang M, 2011, LECT NOTES COMPUT SC, V6838, P257, DOI 10.1007/978-3-642-24728-6_34
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 34
TC 15
Z9 17
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 69
EP 77
DI 10.1016/j.jvcir.2015.09.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700007
DA 2024-07-18
ER

PT J
AU Alzu'bi, A
   Amira, A
   Ramzan, N
AF Alzu'bi, Ahmad
   Amira, Abbes
   Ramzan, Naeem
TI Semantic content-based image retrieval: A comprehensive study
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CBIR; Image features; Dimensionality reduction; Deep learning; Relevance
   feedback; Image annotation; Visualization; Semantic gap
ID DIMENSIONALITY REDUCTION; PERFORMANCE EVALUATION; MEDICAL APPLICATIONS;
   OBJECT RECOGNITION; RELEVANCE FEEDBACK; INTEGRATING COLOR; NORMALIZED
   CUTS; SPANNING TREE; SHAPE MODELS; SEGMENTATION
AB The complexity of multimedia contents is significantly increasing in the current digital world. This yields an exigent demand for developing highly effective retrieval systems to satisfy human needs. Recently, extensive research efforts have been presented and conducted in the field of content-based image retrieval (CBIR). The majority of these efforts have been concentrated on reducing the semantic gap that exists between low-level image features represented by digital machines and the profusion of high-level human perception used to perceive images. Based on the growing research in the recent years, this paper provides a comprehensive review on the state-of-the-art in the field of CBIR. Additionally, this study presents a detailed overview of the CBIR framework and improvements achieved; including image preprocessing, feature extraction and indexing, system learning, benchmarking datasets, similarity matching, relevance feedback, performance evaluation, and visualization. Finally, promising research trends, challenges, and our insights are provided to inspire further research efforts. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Alzu'bi, Ahmad; Amira, Abbes; Ramzan, Naeem] Univ West Scotland, Sch Engn & Comp, Paisley PA1 2BE, Renfrew, Scotland.
   [Amira, Abbes] Qatar Univ, Coll Engn, Doha, Qatar.
C3 University of West Scotland; Qatar University
RP Alzu'bi, A (corresponding author), Univ West Scotland, Sch Engn & Comp, Paisley PA1 2BE, Renfrew, Scotland.
EM ahmad.alzubi@uws.ac.uk; abbes.amira@uws.ac.uk; naeem.ramzan@uws.ac.uk
RI Alzu'bi, Ahmad/Y-4113-2019
OI Alzu'bi, Ahmad/0000-0001-5466-0379; Ramzan, Naeem/0000-0002-5088-1462
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Ai LF, 2013, J ZHEJIANG U-SCI C, V14, P505, DOI 10.1631/jzus.CIDE1304
   Alajlan N, 2008, IEEE T PATTERN ANAL, V30, P1003, DOI 10.1109/TPAMI.2008.37
   Ali S, 2012, IEEE T MED IMAGING, V31, P1448, DOI 10.1109/TMI.2012.2190089
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2006, Michigan State Univ.
   [Anonymous], 2013, Handbook on neural information processing
   [Anonymous], P 1 ACM INT WORKSH H
   [Anonymous], GENERIC SPECIFIC DEE
   [Anonymous], 2011, Synth Lect Inf Concepts Retr Serv, DOI [DOI 10.2200/S00371ED1V01Y201111ICR020, 10.2200/S00371ED1V01Y201111ICR020, DOI 10.2200/S00371ED1V0]
   [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2393427
   [Anonymous], 1993, Wavelets: Algorithms and Applications
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   Babenko A., 2014, Neural codes for image retrieval
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Basheer IA, 2000, J MICROBIOL METH, V43, P3, DOI 10.1016/S0167-7012(00)00201-3
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Beichel R, 2005, IEEE T MED IMAGING, V24, P1151, DOI 10.1109/TMI.2005.853237
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Biggio B, 2010, INT J MACH LEARN CYB, V1, P27, DOI 10.1007/s13042-010-0007-7
   Bilenko M., 2004, P INT C MACH LEARN, P11
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Bordogna G, 2011, WIRES DATA MIN KNOWL, V1, P138, DOI 10.1002/widm.3
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Brunelli R, 2000, IEEE T MULTIMEDIA, V2, P164, DOI 10.1109/6046.865481
   Bulò SR, 2011, PATTERN RECOGN, V44, P2109, DOI 10.1016/j.patcog.2011.03.016
   Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7
   Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3
   Bunke H, 2011, PATTERN RECOGN, V44, P1928, DOI 10.1016/j.patcog.2010.05.016
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Carvalho BM, 2005, DISCRETE APPL MATH, V151, P55, DOI 10.1016/j.dam.2005.02.031
   Carvalho BM, 1999, PATTERN ANAL APPL, V2, P73, DOI 10.1007/s100440050016
   Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P269, DOI 10.1109/TIP.1998.661176
   Chan YK, 2008, IMAGE VISION COMPUT, V26, P1540, DOI 10.1016/j.imavis.2008.04.019
   Chandrasekhar Vijay, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2504, DOI 10.1109/CVPRW.2009.5206733
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2014, MULTIMED TOOLS APPL, V70, P1767, DOI 10.1007/s11042-012-1192-z
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chen LP, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P273
   Chen X., 2005, 7 IEEE INT S MULT, V8, P12
   Chen YW, 2009, PATTERN RECOGN LETT, V30, P799, DOI 10.1016/j.patrec.2008.04.015
   Christiane Fellbaum., 1998, WORDNET ELECT LEXICA
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Çigla C, 2008, IEEE IMAGE PROC, P2272, DOI 10.1109/ICIP.2008.4712244
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2005, P 7 ACM SIGMM INT WO, P153, DOI [DOI 10.1145/1101826.1101866, 10.1145/1101826.1101866]
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Deserno TM, 2009, J DIGIT IMAGING, V22, P202, DOI 10.1007/s10278-007-9092-x
   Donahue J., 2013, Decaf: A deep convolutional activation feature for generic visual recognition
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Estrada FJ, 2009, INT J COMPUT VISION, V85, P167, DOI 10.1007/s11263-009-0251-z
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fabijanska A., 2012, IET C IMAGE PROCESSI
   Falcao AX, 2000, IEEE T MED IMAGING, V19, P55, DOI 10.1109/42.832960
   Fan B, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995385
   Fang W., 2007, IEEE CONFERENCE ON C, V40, P2163
   Faria F.F., 2010, Proceedings of the International Conference on Multimedia information retrieval, P285, DOI DOI 10.1145/1743384.1743434
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594
   Fernández ML, 2001, PATTERN RECOGN LETT, V22, P753, DOI 10.1016/S0167-8655(01)00017-4
   Ferreira CD, 2011, PATTERN RECOGN LETT, V32, P27, DOI 10.1016/j.patrec.2010.05.015
   Freedman D, 2005, PROC CVPR IEEE, P755
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   GABOW HN, 1986, COMBINATORICA, V6, P109, DOI 10.1007/BF02579168
   GALLAGER RG, 1983, ACM T PROGR LANG SYS, V5, P66, DOI 10.1145/357195.357200
   Gashler Michael., 2007, NIPS, V8, P513
   Ghanem B, 2010, INT J COMPUT VISION, V89, P40, DOI 10.1007/s11263-010-0321-2
   Ghiassi M, 2010, EXPERT SYST APPL, V37, P3118, DOI 10.1016/j.eswa.2009.09.017
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Grady L, 2005, PROC CVPR IEEE, P763
   Grady L, 2004, LECT NOTES COMPUT SC, V3117, P230
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Griffin G., 2007, CALTECH 256 OBJECT C
   Pedronette DCG, 2014, INFORM SCIENCES, V265, P91, DOI 10.1016/j.ins.2013.12.030
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   [郭杰 Guo Jie], 2014, [高分子通报, Polymer Bulletin], P1
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   He XF, 2004, ADV NEUR IN, V16, P153
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Herman GT, 2001, IEEE T PATTERN ANAL, V23, P460, DOI 10.1109/34.922705
   Hiroike A., VISUAL INFORM INFORM, P155
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hoàng NV, 2010, PATTERN RECOGN, V43, P3013, DOI 10.1016/j.patcog.2010.03.024
   Hochbaum DS, 2010, IEEE T PATTERN ANAL, V32, P889, DOI 10.1109/TPAMI.2009.80
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752
   Hong Shao, 2008, 2008 9th International Conference for Young Computer Scientists, P753, DOI 10.1109/ICYCS.2008.89
   Hsiao MJ, 2010, LIFE SCI J, V7, P99
   Hsiao YT, 2005, IEEE SYS MAN CYBERN, P2962
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Ingwersen P., 2006, TURN INTEGRATION INF, V18
   Jaakkola T., 1999, Advances in Neural Information Processing Systems, V11
   Jacob IJ, 2014, PATTERN RECOGN LETT, V42, P72, DOI 10.1016/j.patrec.2014.01.017
   Jaworska Tatiana, 2010, Computational Intelligence for Knowledge-Based Systems Design. Proceedings 13th International Conference on Information Processing and Management of Uncertainty, IPMU 2010, P149, DOI 10.1007/978-3-642-14049-5_16
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   Jing H, 1997, P C COMP VIS PATT RE, V97, P762
   Jorgensen C., 2003, IMAGE RETRIVAL THEOR
   Joulin Armand, 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539868
   JULESZ B, 1984, TRENDS NEUROSCI, V7, P41, DOI 10.1016/S0166-2236(84)80275-1
   Jung CK, 2014, DIGIT SIGNAL PROCESS, V24, P106, DOI 10.1016/j.dsp.2013.09.006
   Kaganami Hassana Grema, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1217, DOI 10.1109/IIH-MSP.2009.13
   Kalpathy-Cramer J, 2015, COMPUT MED IMAG GRAP, V39, P55, DOI 10.1016/j.compmedimag.2014.03.004
   Karoui I., 2007, 2007 IEEE INT S INTE, P1
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Ke Y, 2004, PROC CVPR IEEE, P506
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kelly Diane, 2009, Foundations and Trends in Information Retrieval, V3, P1, DOI 10.1561/1500000012
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kohli P, 2005, IEEE I CONF COMP VIS, P922
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Kotsiantis S, 2011, ARTIF INTELL REV, V35, P223, DOI 10.1007/s10462-010-9192-8
   Kovalev V, 1996, GRAPH MODEL IM PROC, V58, P187, DOI 10.1006/gmip.1996.0016
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A., 2014, IEEE J BIOMED HEALTH, V99, P2168
   Kumar A, 2014, MED IMAGE ANAL, V18, P330, DOI 10.1016/j.media.2013.11.003
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Kumar A, 2013, INT J COMPUT ASS RAD, V8, P1003, DOI 10.1007/s11548-013-0896-5
   Kwitt R, 2010, IEEE T IMAGE PROCESS, V19, P241, DOI 10.1109/TIP.2009.2032313
   Kwok SH, 1997, IEEE T IMAGE PROCESS, V6, P328, DOI 10.1109/83.551705
   Lai C, 2009, INTELL DATA ANAL, V13, P575, DOI 10.3233/IDA-2009-0382
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lee J, 2011, ADV ELECTR COMPUT EN, V11, P85, DOI 10.4316/AECE.2011.03014
   Lempitsky V, 2009, IEEE I CONF COMP VIS, P277, DOI 10.1109/ICCV.2009.5459262
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li HQ, 2004, IEEE T BIO-MED ENG, V51, P246, DOI 10.1109/TBME.2003.820400
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liang YY, 2014, LECT NOTES COMPUT SC, V8886, P847, DOI 10.1007/978-3-319-13563-2_71
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu JY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531375
   Liu W., 2009, 4 IEEE C IND EL APPL, V2667, P25
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   March W.B., 2010, P 16 ACM SIGKDD INT
   Mathews J, 2014, ADV INTELL SYST COMP, V264, P347, DOI 10.1007/978-3-319-04960-1_31
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Min R, 2009, PATTERN RECOGN, V42, P147, DOI 10.1016/j.patcog.2008.07.001
   Moghaddam B, 2001, MULTIMED TOOLS APPL, V14, P201, DOI 10.1023/A:1011355417880
   Moro M., 2009, ENCY DATABASE SYSTEM, P1289
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nanongkai D, 2014, LECT NOTES COMPUT SC, V8784, P439, DOI 10.1007/978-3-662-45174-8_30
   Niblack W., 1994, P SPIE STORAGE RETRI
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ovsjanikov M., 2009, P WORKSH NONR SHAP A
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Papakostas G.A., 2012, HUM CENT MACH VIS
   Park SB, 2004, PATTERN RECOGN LETT, V25, P287, DOI 10.1016/j.patrec.2003.10.015
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Pauleve L, 2010, PATTERN RECOGN LETT, V31, P1348, DOI 10.1016/j.patrec.2010.04.004
   Pavan M., 2003, P 2003 IEEE COMP SOC, V1, P1
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   PAVLIDIS T, 1980, STRUCTURAL PATTERN R
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Petrakis EGM, 2002, IMAGE VISION COMPUT, V20, P59, DOI 10.1016/S0262-8856(01)00077-4
   Prasad BG, 2004, COMPUT VIS IMAGE UND, V94, P193, DOI 10.1016/j.cviu.2003.10.016
   Priyatharshini R., 2013, Mobile Communication and Power Engineering, P17
   Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Ralescu A., 2003, GEN HAMMING DISTANCE
   Rashedi E, 2014, ENG APPL ARTIF INTEL, V35, P26, DOI 10.1016/j.engappai.2014.06.009
   Raymond JW, 2002, COMPUT J, V45, P631, DOI 10.1093/comjnl/45.6.631
   Rodrigues J.F., 2010, 14 INT C INF VIS, V61, P26
   Rodríguez JJ, 2006, IEEE T PATTERN ANAL, V28, P1619, DOI 10.1109/TPAMI.2006.211
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Ruthven I, 2008, ANNU REV INFORM SCI, V42, P43
   Sáez A, 2014, MACH VISION APPL, V25, P1813, DOI 10.1007/s00138-014-0631-4
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   SAMET H, 1984, COMPUT SURV, V16, P187, DOI 10.1145/356924.356930
   Sapiro G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P817, DOI 10.1109/ICIP.1996.559624
   SARKAR S, 1996, P IEEE C COMP VIS PA
   Schmid J, 2011, MED IMAGE ANAL, V15, P155, DOI 10.1016/j.media.2010.09.001
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765
   Senthilkumaran N., 2009, INT J REC TRENDS ENG, V1
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shao J, 2012, PATTERN RECOGN LETT, V33, P271, DOI 10.1016/j.patrec.2011.10.018
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Shenghua Gao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2809, DOI 10.1109/CVPR.2011.5995454
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Silpa-Anan C, 2008, PROC CVPR IEEE, P2308
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Skopal T, 2009, J DISCRET ALGORITHMS, V7, P62, DOI 10.1016/j.jda.2008.09.013
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J.R., 1996, P 4 ACM INT C MULT 9
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   Stoer M, 1997, J ACM, V44, P585, DOI 10.1145/263867.263872
   Su JH, 2011, IEEE T KNOWL DATA EN, V23, P360, DOI 10.1109/TKDE.2010.124
   Rallabandi VPS, 2007, DATA KNOWL ENG, V61, P524, DOI 10.1016/j.datak.2006.06.016
   Sun SH, 2012, IEEE T MED IMAGING, V31, P449, DOI 10.1109/TMI.2011.2171357
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thomas JJ, 2006, IEEE COMPUT GRAPH, V26, P10, DOI 10.1109/MCG.2006.5
   Tian Q, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P746, DOI 10.1109/ICIP.2000.899562
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Torralba A., 2008, PROC CVPR 08, P1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tory M, 2004, IEEE T VIS COMPUT GR, V10, P72, DOI 10.1109/TVCG.2004.1260759
   Trémeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950
   Udupa JK, 2002, IEEE T PATTERN ANAL, V24, P1485, DOI 10.1109/TPAMI.2002.1046162
   vander Maaten L., 2009, J MACH LEARN RES, V10, P13, DOI [10.1080/13506280444000102, DOI 10.1080/13506280444000102]
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Veltkamp Remco C., 2000, UUCS200034
   Verma B., 2006, SEMANTIC BASED VISUA, P252
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang F, 2014, PROC CVPR IEEE, P3142, DOI 10.1109/CVPR.2014.402
   Wang HF, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2483669.2483670
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang S., 2012, J COMPUT INF SYST, V8, P8727
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XC, 2009, IEEE T KNOWL DATA EN, V21, P945, DOI 10.1109/TKDE.2009.37
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wu GD, 2013, IEEE T FUZZY SYST, V21, P1, DOI 10.1109/TFUZZ.2012.2197754
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Wu L, 2011, IEEE MULTIMEDIA, V18, P24, DOI 10.1109/MMUL.2011.7
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiaoyin Duanmu, 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P200, DOI 10.1109/ITNG.2010.231
   Xu B, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P525
   Yang Y, 2011, PROC CVPR IEEE, P881, DOI 10.1109/CVPR.2011.5995499
   Yoon H, 2013, EXPERT SYST APPL, V40, P231, DOI 10.1016/j.eswa.2012.07.018
   Yu X., 1991, 1991 IEEE International Symposium on Circuits and Systems (Cat. No.91CH3006-4), P516, DOI 10.1109/ISCAS.1991.176386
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng JX, 2014, SCI WORLD J, DOI 10.1155/2014/615973
   Zeng Z., 2009, Proc. VLDB Endow., V2, P25, DOI [10.14778/1687627.1687631, DOI 10.14778/1687627.1687631]
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang H, 2010, INT CONF ACOUST SPEE, P930, DOI 10.1109/ICASSP.2010.5495286
   Zhang LN, 2012, IEEE T IMAGE PROCESS, V21, P2294, DOI 10.1109/TIP.2011.2177846
   Zhang LN, 2012, IEEE T SYST MAN CY B, V42, P282, DOI 10.1109/TSMCB.2011.2165335
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhang X, 2009, IEEE I CONF COMP VIS, P1103, DOI 10.1109/ICCV.2009.5459354
   Zhang Y., 2010, P 16 ACM SIGKDD INT, P1199, DOI DOI 10.1145/1835804.1835954
   Zhong C., 2014, INF SCI, V295, P1
   Zhong C., 2014, INF SCI
   Zhou XS, 2001, PROC CVPR IEEE, P11
   Zhou XS, 2000, PROC SPIE, V3974, P426, DOI 10.1117/12.382975
   Zhou YM, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P366, DOI 10.1109/FSKD.2008.363
   Zhuo L, 2014, NEUROCOMPUTING, V141, P202, DOI 10.1016/j.neucom.2014.03.014
NR 297
TC 130
Z9 143
U1 2
U2 95
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 20
EP 54
DI 10.1016/j.jvcir.2015.07.012
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300003
DA 2024-07-18
ER

PT J
AU Kim, S
   Lee, SH
   Ro, YM
AF Kim, Semin
   Lee, Seung Ho
   Ro, Yong Man
TI Image-based coin recognition using rotation-invariant region binary
   patterns based on gradient magnitudes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Region binary pattern; Rotation-invariant; Image-based coin recognition;
   Coin recognition; Local binary pattern; Feature extraction; MUSCLE CIS;
   Feature matching; Coin classification
ID MULTIRESOLUTION GRAY-SCALE; CLASSIFICATION
AB Most features of image-based coin recognition have been based on histogram information to achieve rotation-invariant property. However, discrimination of the features based on histogram information can be reduced by ignoring local spatial structure. In this paper, we propose a novel feature of image-based coin recognition that exploits a spatial structure. In order to consider the structure of a coin, rotation-and-flipping-robust region binary patterns (RFR) is adopted. The proposed method computes gradient magnitudes in a coin image, and extracts RFR using local difference magnitude transform to increase the accuracy of coin recognition. Comparative experiments with a number of state-of-the-art methods have been performed on the MUSCLE CIS-Benchmark Preview data set. The experimental results showed that the proposed method outperformed the state of the art methods in terms of recognition accuracy, smaller feature dimension, and shorter feature extraction time. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kim, Semin; Lee, Seung Ho; Ro, Yong Man] Korea Adv Inst Sci & Technol KAIST, Dept Elect Engn, Image & Video Syst Lab, Daejeon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol KAIST, Dept Elect Engn, Image & Video Syst Lab, Daejeon 305701, South Korea.
EM ymro@ee.kaist.ac.kr
RI Ro, Yong Man/ABF-6817-2020; Ro, Yong Man/C-1731-2011; Kim,
   Semin/HPD-7404-2023
OI Ro, Yong Man/0000-0001-5306-6853; Kim, Semin/0000-0003-3746-0863
FU ICT R&D program of MSIP/IITP [B0101-15-0525]
FX This work was supported by ICT R&D program of MSIP/IITP [B0101-15-0525,
   Development of global multi-target tracking and event prediction
   techniques based on real-time large-scale video analysis].
CR Arandjelovic O, 2012, LECT NOTES COMPUT SC, V7575, P317, DOI 10.1007/978-3-642-33765-9_23
   Bremananth R, 2005, INDICON 2005 Proceedings, P366
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Christian Kotz, COIN SEGMENTATION
   FUKUMI M, 1992, IEEE T NEURAL NETWOR, V3, P272, DOI 10.1109/72.125868
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hassoubah RS, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P62, DOI 10.1109/ICIIP.2013.6707556
   Huber R, 2005, PATTERN RECOGN LETT, V26, P61, DOI 10.1016/j.patrec.2004.09.006
   Hussein R., 2010, IEEE INT C ELECTRONI, P1
   Kim S, 2014, J VIS COMMUN IMAGE R, V25, P373, DOI 10.1016/j.jvcir.2013.12.003
   Maaten LJP, 2006, EVA, P19
   Mehta D., 2013, INT J COMPUT APPL, V73, P18
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Reisert M., 2006, P MUSCL CIS COIN COM, P19
   Rothwell C. A., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P395, DOI 10.1109/ISCV.1995.477034
   Saipullah KM, 2011, IEEE INT C MULTIMEDI, P1
   Saranya Y.M., 2013, INT J ADV RES COMPUT, V2, P1689
   Shen L, 2011, IET IMAGE PROCESS, V5, P394, DOI 10.1049/iet-ipr.2009.0251
   Vadivelan A., 2014, INT C EL ENG COMP SC, P135
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhu CR, 2012, INFORM SCIENCES, V187, P93, DOI 10.1016/j.ins.2011.10.014
NR 23
TC 8
Z9 9
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 217
EP 223
DI 10.1016/j.jvcir.2015.08.011
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300018
DA 2024-07-18
ER

PT J
AU Guo, JT
   Zheng, PJ
   Huang, JW
AF Guo, Jianting
   Zheng, Peijia
   Huang, Jiwu
TI Secure watermarking scheme against watermark attacks in the encrypted
   domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind watermarking scheme; Secure signal processing; Signal processing
   in the encrypted domain; Watermark attack; DWT; DCT; Encrypted domain;
   Homomorphic encryption
ID FULLY HOMOMORPHIC ENCRYPTION; TRANSFORM; PROTOCOL; ROBUST; DWT
AB The homomorphic cryptosystems create a great opportunity for secure signal processing (SSP). Watermarking in the encrypted domain provides a promising solution to the security of watermarking. However, the robust performance of the watermarking scheme in the encrypted domain should be carefully considered. In this paper, we propose a robust watermarking scheme in the encrypted domain, which protects the original images from the third party embedders. The hybrid discrete wavelet transform (DWT) and discrete cosine transform (DCT) based method improves the robust performance of the encrypted domain watermarking scheme. The watermark extraction can be performed on both the plaintext and the encrypted domains. We also give an estimation of the expanding factor after watermark embedding in the encrypted domain. At last, we discuss the watermark attacks that are available in the encrypted domain. Taking Haar wavelet transform for example, we conduct the experiments on the visual quality and the robustness of our watermarking scheme, which demonstrate that the entire performance is satisfactory. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Guo, Jianting] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Zheng, Peijia] Sun Yat Sen Univ, Sch Informat Management, Guangzhou 510006, Guangdong, Peoples R China.
   [Huang, Jiwu] Shenzhen Univ, Coll Informat Engn, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Shenzhen University
RP Zheng, PJ (corresponding author), Sun Yat Sen Univ, Sch Informat Management, Guangzhou 510006, Guangdong, Peoples R China.
EM zhpj@mail.sysu.edu.cn
RI huang, jw/KVY-9917-2024
FU 973 Program [2011CB302204]; National Science & Technology Pillar Program
   [2012BAK16B06]; NSFC [U1135001, 61332012]; Shenzhen RD Program
   [GJHZ20140418191518323]; NSF of Guangdong Province [2014A030310112]
FX This work was supported in part by the 973 Program (2011CB302204),
   National Science & Technology Pillar Program (2012BAK16B06), NSFC
   (U1135001, 61332012), Shenzhen R&D Program (GJHZ20140418191518323), NSF
   of Guangdong Province(2014A030310112).
CR Aguilar-Melchor C, 2013, IEEE SIGNAL PROC MAG, V30, P108, DOI 10.1109/MSP.2012.2230219
   [Anonymous], 2009, P 12 INT C INF SEC C, DOI [10.1007/978-3-642-14423-3_16, DOI 10.1007/978-3-642-14423-3_16]
   [Anonymous], 1978, FDN SEC COMPUT
   Barni M., 2010, Information Forensics and Security (WIFS), 2010 IEEE International Workshop on, P1, DOI DOI 10.1109/WIFS.2010.5711460
   Barni M, 2011, IEEE T INF FOREN SEC, V6, P452, DOI 10.1109/TIFS.2011.2108650
   BERNSTEIN R, 1976, IBM J RES DEV, V20, P40, DOI 10.1147/rd.201.0040
   Bianchi T, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/716357
   Bianchi T, 2010, IEEE T INF FOREN SEC, V5, P180, DOI 10.1109/TIFS.2009.2036230
   Bianchi T, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P85, DOI 10.1145/1411328.1411344
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Cancellaro M, 2011, SIGNAL PROCESS-IMAGE, V26, P1, DOI 10.1016/j.image.2010.11.001
   Damgård I, 2001, LECT NOTES COMPUT SC, V1992, P119
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Deng MN, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P9
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Failla P, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P241
   Fontaine C, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/13801
   Gamal T.E., 1984, P WORKSH THEOR APPL, V196, P10, DOI DOI 10.1007/3-540-39568-7_2
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Kuribayashi M, 2005, IEEE T IMAGE PROCESS, V14, P2129, DOI 10.1109/TIP.2005.859383
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Lian SG, 2006, OPT ENG, V45, DOI 10.1117/1.2333510
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Peijia Zheng, 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P240, DOI 10.1007/978-3-642-36373-3_16
   Rial A, 2011, IEEE T INF FOREN SEC, V6, P202, DOI 10.1109/TIFS.2010.2095844
   Schmitz Roland, 2012, Communications and Multimedia Security. 13th IFIP TC 6/TC 11 International Conference, CMS 2012. Proceedings, P117, DOI 10.1007/978-3-642-32805-3_10
   Shieh Jyh-Ren., 2011, Proceedings of the 20th ACM international Conference on Information and Knowledge Management - CIKM '11, P915
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wang XY, 2007, IEEE T AUDIO SPEECH, V15, P2270, DOI 10.1109/TASL.2007.906192
   Zheng PJ, 2013, IEEE T IMAGE PROCESS, V22, P2455, DOI 10.1109/TIP.2013.2253474
NR 40
TC 70
Z9 73
U1 1
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 125
EP 135
DI 10.1016/j.jvcir.2015.03.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900012
DA 2024-07-18
ER

PT J
AU Guan, JW
   Zhang, W
   Gu, JS
   Ren, HL
AF Guan, Jingwei
   Zhang, Wei
   Gu, Jason
   Ren, Hongliang
TI No-reference blur assessment based on edge modeling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; No-reference; HVS; Perception; Blur metric;
   Just noticeable blur; Edge model; Edge width
ID IMAGE QUALITY ASSESSMENT; NATURAL SCENE STATISTICS
AB This paper presents a no-reference objective blur metric based on edge model (EMBM) to address the image blur assessment problem. A parametric edge model is incorporated to describe and detect edges, which can offer simultaneous width and contrast estimation for each edge pixel. With the pixel-adaptive width and contrast estimations, the probability of detecting blur at edge pixels can be determined. Also, unlike previous work, we advocate using only the salient edge pixels to simulate the blur assessment in Human Visual System (HVS). Finally, the blur metric is obtained by cumulating the probability of blur detection. Various images with different blur distortions are tested to demonstrate the effectiveness of the proposed metric. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Guan, Jingwei; Zhang, Wei] Shandong Univ, Sch Control Sci & Engn, Jinan 250100, Peoples R China.
   [Gu, Jason] Dalhousie Univ, Dept Elect & Comp Engn, Halifax, NS, Canada.
   [Ren, Hongliang] Natl Univ Singapore, Dept Biomed Engn, Singapore 117548, Singapore.
C3 Shandong University; Dalhousie University; National University of
   Singapore
RP Zhang, W (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250100, Peoples R China.
EM davidzhangsdu@gmail.com
RI Lu, Wang/JVO-0416-2024; Ren, Hongliang/N-9194-2017
OI Ren, Hongliang/0000-0002-6488-1551; Gu, Jason
   Jianjun/0000-0002-7626-1077
FU National Natural Science Foundation of China (NSFC) [61203253,
   61233014]; Research Found of Outstanding Young Scientist Award of
   Shandong Province [BS2013DX023]; Independent Innovation Foundation of
   Shandong University (IIFSDU) [2013TB004]; Program of Key Lab of ICSP
   MOE; Singapore Academic Research Fund [R397000139133, R397000177133]
FX We thank the editor and all anonymous reviewers for their constructive
   comments. This work was supported by the National Natural Science
   Foundation of China (NSFC) Grant Nos. 61203253 and 61233014, Research
   Found of Outstanding Young Scientist Award of Shandong Province
   (BS2013DX023), Independent Innovation Foundation of Shandong University
   (IIFSDU) 2013TB004, and Program of Key Lab of ICSP MOE. This work was
   also in part supported by the Singapore Academic Research Fund under
   Grant R397000139133 and Grant R397000177133 awarded to Dr. Hongliang
   Ren.
CR [Anonymous], 2005, P IEEE INT C IM PROC
   Blanchet G., 2012, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2012), P1065, DOI 10.1109/ICASSP.2012.6288070
   Blanchet G., 2008, P INT C IM PROC, P1176
   Charrier C, 2012, SIGNAL PROCESS-IMAGE, V27, P209, DOI 10.1016/j.image.2012.01.002
   Fei X, 2012, SIGNAL PROCESS-IMAGE, V27, P772, DOI 10.1016/j.image.2012.04.005
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gao XB, 2013, IEEE T NEUR NET LEAR, V24, P2013, DOI 10.1109/TNNLS.2013.2271356
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   He LH, 2012, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2012.6247795
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   LeCallet P., 2005, 1 INT WORKSH VID PRO
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Ma L, 2013, SIGNAL PROCESS-IMAGE, V28, P884, DOI 10.1016/j.image.2012.08.001
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A., 2013, P SOC PHOTO-OPT INS, VXVIII
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Seshadrinathan K, 2008, IEEE IMAGE PROC, P1200, DOI 10.1109/ICIP.2008.4711976
   Sheikh H. R., 2003, Live image quality assessment database
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Soundararajan R., 2011, P INT C AC SPEECH SI
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   van Beek P. J. L, 1995, THESIS DELFT U TECHN
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Yang S, 2011, ELECTRON LETT, V47, P382, DOI 10.1049/el.2010.3620
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P873, DOI 10.1109/TIP.2011.2162739
   Zhou WJ, 2014, SIGNAL PROCESS-IMAGE, V29, P167, DOI 10.1016/j.image.2013.10.005
NR 34
TC 47
Z9 51
U1 2
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 1
EP 7
DI 10.1016/j.jvcir.2015.01.007
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100001
DA 2024-07-18
ER

PT J
AU Zand, M
   Doraisamy, S
   Halin, AA
   Mustaffa, MR
AF Zand, Mohsen
   Doraisamy, Shyamala
   Halin, Alfian Abdul
   Mustaffa, Mas Rina
TI Texture classification and discrimination for region-based image
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Region-based image retrieval; Texture feature extraction; Texture
   classification; Gabor wavelet; Curvelet filters; Polynomials; ImageCLEF;
   Outex
ID ROTATION-INVARIANT; CURVELET TRANSFORM; FEATURES; SEGMENTATION; SCALE
AB In RBIR, texture features are crucial in determining the class a region belongs to since they can overcome the limitations of color and shape features. Two robust approaches to model texture features are Gabor and curvelet features. Although both features are close to human visual perception, sufficient information needs to be extracted from their sub-bands for effective texture classification. Moreover, shape irregularity can be a problem since Gabor and curvelet transforms can only be applied on the regular shapes. In this paper, we propose an approach that uses both the Gabor wavelet and the curvelet transforms on the transferred regular shapes of the image regions. We also apply a fitting method to encode the sub-bands' information in the polynomial coefficients to create a texture feature vector with the maximum power of discrimination. Experiments on texture classification task with ImageCLEF and Outex databases demonstrate the effectiveness of the proposed approach. (C) 2014 The Authors. Published by Elsevier Inc.
C1 [Zand, Mohsen; Doraisamy, Shyamala; Halin, Alfian Abdul; Mustaffa, Mas Rina] Univ Putra Malaysia, Fac Comp Sci & Informat Technol, Dept Multimedia, Serdang 43400, Selangor, Malaysia.
C3 Universiti Putra Malaysia
RP Zand, M (corresponding author), Univ Putra Malaysia, Fac Comp Sci & Informat Technol, Dept Multimedia, Serdang 43400, Selangor, Malaysia.
EM zand.mohsen@gmail.com; shyamala@upm.edu.my; alfian@upm.edu.my;
   masrina@upm.edu.my
RI Zand, Mohsen/ABB-9707-2020; Abdul Halin, Alfian/D-1502-2017; MUSTAFFA,
   MAS RINA/B-1763-2017
OI Zand, Mohsen/0000-0001-8177-6000; Doraisamy,
   Shyamala/0000-0001-5502-8754; Abdul Halin, Alfian/0000-0002-0318-4496;
   MUSTAFFA, MAS RINA/0000-0001-5088-2871
CR Al-Absi HRH, 2013, IEEE ENG MED BIO, P3674, DOI 10.1109/EMBC.2013.6610340
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 1995, Pattern classification and scene analysis
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Fakheri M., 2011, 7 IR C MACH VIS IM P, P1
   Farsi H, 2013, IET IMAGE PROCESS, V7, P212, DOI 10.1049/iet-ipr.2012.0203
   Gómez F, 2011, PATTERN RECOGN LETT, V32, P2178, DOI 10.1016/j.patrec.2011.09.029
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   Herve N., 2007, 6 ACM INT C IM VID R, P4931
   Huiskes MJ, 2010, P INT C MULT INF RET
   Jing Y. T., 2008, INFORM TECHNOLOGY, V4, P4
   Kekre H.B., 2010, CSC INT J IMAGE PROC, V4, P1, DOI 10.5120/866-1216
   Keren D, 1999, IEEE T PATTERN ANAL, V21, P31, DOI 10.1109/34.745731
   Li Y, 2010, LECT NOTES ARTIF INT, V6216, P317
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu Y, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1891, DOI 10.1109/ICME.2004.1394628
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Materka A., 1998, TEXTURE ANAL METHODS
   Mei Y, 2008, IEEE IMAGE PROC, P165, DOI 10.1109/ICIP.2008.4711717
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Nikolopoulos S, 2013, SIGNAL PROCESS, V93, P2212, DOI 10.1016/j.sigpro.2012.08.004
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pang W.-M., 2013, J REAL TIME IMAGE PR
   Porter R., 1997, VISION IMAGE SIGNAL, VI
   Preety D S., 2012, INT J INF ENG, V2, P32
   Saevarsson BB, 2006, 2006 7TH NORDIC SIGNAL PROCESSING SYMPOSIUM, P318
   Saipullah KM, 2012, MULTIMED TOOLS APPL, V59, P717, DOI 10.1007/s11042-011-0766-5
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Sumana I. J., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P290, DOI 10.1109/ICME.2012.90
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Thomee B., 2012, CLEF, V53
   TUCERYAN M, 1990, IEEE T PATTERN ANAL, V12, P211, DOI 10.1109/34.44407
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Wu YQ., 2009, ELECT DEVICES M IEDM, P1
   Yin Q, 2007, LECT NOTES COMPUT SC, V4489, P10
   Yuanfei Xu, 2011, 2011 International Conference on Multimedia Technology, P145
   Zhang DS, 2013, J VIS COMMUN IMAGE R, V24, P1087, DOI 10.1016/j.jvcir.2013.07.004
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhou LP, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P596, DOI 10.1109/ICMLA.2009.131
NR 45
TC 26
Z9 28
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 305
EP 316
DI 10.1016/j.jvcir.2014.10.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000028
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Tang, CW
   Yang, XK
   Zhai, GT
AF Tang, Chongwu
   Yang, Xiaokang
   Zhai, Guangtao
TI Image quality/distortion metric based on α-stable model similarity in
   wavelet domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality metric; Distortion detection; Natural image assessment;
   Multi-scale decomposition; Wavelet coefficients; alpha-Stable
   distribution; Parameter analysis; Kullback-Leibler distance
ID QUALITY ASSESSMENT; STRUCTURAL SIMILARITY; BLUR
AB Quality assessment is of central importance in numerous image processing tasks. State-of-the-art objective image quality assessment (IQA) algorithms are generally devised for specific distortion types or based on training procedure of large databases. In this work, we propose a general-purpose full-reference/no-reference (FR/NR) IQA framework for image distortions, nominated by Image Quality/Distortion Metric (IQDM). The leptokurtic and heavy-tailed behaviors of image wavelet coefficients are characterized by symmetric alpha-stable (S alpha S) density, and the statistical studies indicate that the model parameters may be altered because of the presence of distortion. This important priori knowledge of original image's distribution is then used to gauge the distortion between degraded and reference S alpha S models in multi-scale wavelet sub-bands. We investigate the relationship between original and degraded parameters over scales, accordingly infer the original parameters from the degraded ones. A characteristic probability density function for S alpha S and its closed-form Kullback-Leibler distance are derived for FR/NR-IQDM using the model parameters. Extensive experiments and comparisons demonstrate that the proposed FR/NR-IQDM scheme is efficacious to most common types of distortion, and leads to a highly comparable performance to the benchmarks and prevalent competitors in consistency with subjective judgements. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Tang, Chongwu; Yang, Xiaokang; Zhai, Guangtao] Shanghai Jiao Tong Univ, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Tang, CW (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
EM tangcw@sjtu.edu.cn; xkyang@sjtu.edu.cn; zhaiguangtao@sjtu.edu.cn
RI Zhai, Guangtao/X-5949-2019; Yang, Xiaokang/C-6137-2009
OI Zhai, Guangtao/0000-0001-8165-9322; Yang, Xiaokang/0000-0003-4029-3322
FU National Nature Science Foundation of China (NSFC) [61025005, 60932006,
   61001145, 61102098, 61371146]; Science and Technology Commission of
   Shanghai Municipality (STCSM) [12DZ2272600]
FX This work was supported by National Nature Science Foundation of China
   (NSFC) (61025005, 60932006, 61001145, 61102098, 61371146), Science and
   Technology Commission of Shanghai Municipality (STCSM) (12DZ2272600).
CR Achim A, 2005, IEEE SIGNAL PROC LET, V12, P17, DOI 10.1109/LSP.2004.839692
   [Anonymous], Categorical image quality (CSIQ) database
   [Anonymous], 2002, MODEL SELECTION MULT
   [Anonymous], A57 DATABASE
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], SUBJECTIVE QUALITY A
   [Anonymous], MICT image quality evaluation database
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   KOUTROUVELIS IA, 1981, COMMUN STAT B-SIMUL, V10, P17, DOI 10.1080/03610918108812189
   KULLBACK S, 1987, AM STAT, V41, P340
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Nolan J. P., 2009, STABLE DISTRIBUTIONS, V22, P79
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sampat MP, 2009, IEEE T IMAGE PROCESS, V18, P2385, DOI 10.1109/TIP.2009.2025923
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Suthaharan S, 2009, SIGNAL PROCESS, V89, P1647, DOI 10.1016/j.sigpro.2009.02.007
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   Tong, 2004, P IEEE INT C IM PROC, P24
   Veillette M., 2012, STBL: Alpha stable distributions for MATLAB
   Wan T., 2007, P IEEE INT C IM PROC, V4, P357
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Zhang Y., 2013, P SPIE IS T ELECT IM, V8653
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
   Zhu X, 2009, INT WORK QUAL MULTIM, P64, DOI 10.1109/QOMEX.2009.5246976
NR 42
TC 4
Z9 5
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1746
EP 1757
DI 10.1016/j.jvcir.2014.06.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100023
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Lin, WS
   Shi, GM
   Xiao, JM
AF Wu, Jinjian
   Lin, Weisi
   Shi, Guangming
   Xiao, Jimin
TI Correlation based universal image/video coding loss recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Artifact reduction; Coding loss recovery; Correlation; Structural
   self-similarity; Global optimization; Pixel-adaptive; Image/Video
   coding; Reconstruction
ID ARTIFACT REDUCTION; COMPRESSED IMAGES; BLOCKING ARTIFACTS; PARALLEL
   FRAMEWORK; DEBLOCKING; REGULARIZATION; ALGORITHM
AB Coding artifacts are annoying in highly compressed signals. Most of the existing artifact reduction methods are designed for one specific type of artifacts, codecs, and bitrates, which are complex and exclusive for one type of artifact reduction. Since both the compressed image/video and the coding error contain information of the original signal, they are highly correlated. Therefore, we try to recover some lost data based on the correlation between the compressed signal and the coding error, and introduce a novel and universal artifact reduction method. Firstly, according to the spatial correlation among pixels, a pixel-adaptive anisotropic filter is designed to reconstruct the distorted signal. Next, a globally optimal filter is designed to further recover the coding loss. Experimental results demonstrate that within an extensive range of bitrates, the proposed method achieves about 0.8 dB, 0.45 dB, 0.3 dB, and 0.2 dB on average of PSNR improvement for JPEG, MPEG4, H.264/AVC, and HEVC compressed signals, respectively. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wu, Jinjian; Shi, Guangming] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Xiao, Jimin] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
C3 Xidian University; Nanyang Technological University; Tampere University
RP Lin, WS (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM jinjian.wu@mail.xidian.edu.cn; wslin@ntu.edu.sgs; gmshi@xidian.edu.cn;
   xiaojimin1981@gmail.com
RI Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012; Wu,
   Jinjian/GQH-0222-2022
OI Lin, Weisi/0000-0001-9866-1947; 
FU Major State Basic Research Development Program of China (973 Program)
   [2013CB329402]; Research Fund for the Doctoral Program of Higher
   Education [20130203130001, 20130203120009]; NSF of China [61227004,
   61033004]; Fundamental Research Funds for The Central Universities
   [JB140227]
FX This work is supported by the Major State Basic Research Development
   Program of China (973 Program, No.2013CB329402), the Research Fund for
   the Doctoral Program of Higher Education (No. 20130203130001 and
   20130203120009), the NSF of China (Nos. 61227004 and 61033004), and the
   Fundamental Research Funds for The Central Universities (No. JB140227).
CR Averbuch AZ, 2005, IEEE T IMAGE PROCESS, V14, P200, DOI 10.1109/TIP.2004.840688
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Choi H, 2000, IEEE T CIRC SYST VID, V10, P801, DOI 10.1109/76.856457
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Do QB, 2009, IEEE INT SYMP SIGNAL, P101, DOI 10.1109/ISSPIT.2009.5407480
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Frajka T, 2003, OPT ENG, V42, P182, DOI 10.1117/1.1526492
   Lee YL, 1998, IEEE T IMAGE PROCESS, V7, P229, DOI 10.1109/83.661000
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   Lin WS, 2008, IEEE INT SYMP CIRC S, P3562, DOI 10.1109/ISCAS.2008.4542229
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Liu SZ, 2002, IEEE T CIRC SYST VID, V12, P1139, DOI 10.1109/TCSVT.2002.806819
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mateos J, 2000, IEEE T IMAGE PROCESS, V9, P1200, DOI 10.1109/83.847833
   Mitchell J.L., 1996, MPEG VIDEO COMPRESSI
   O'Rourke T. P., 1995, IEEE T CIRCUITS SYST, V5, P90
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paek H, 2000, IEEE T CIRC SYST VID, V10, P36, DOI 10.1109/76.825856
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Shao L, 2008, SIGNAL PROCESS-IMAGE, V23, P463, DOI 10.1016/j.image.2008.04.011
   Shao L, 2007, IEEE T CONSUM ELECTR, V53, P691, DOI 10.1109/TCE.2007.381747
   Shen MM, 2011, IEEE T CIRC SYST VID, V21, P755, DOI 10.1109/TCSVT.2011.2130390
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tai SC, 2005, IEEE T CIRC SYST VID, V15, P733, DOI 10.1109/TCSVT.2005.848314
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P1158, DOI 10.1016/j.jvcir.2012.07.010
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P845, DOI 10.1016/j.jvcir.2012.04.010
   Xiong ZX, 1997, IEEE T CIRC SYST VID, V7, P433, DOI 10.1109/76.564123
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P735, DOI 10.1109/TMM.2008.922849
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
NR 37
TC 0
Z9 0
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1507
EP 1515
DI 10.1016/j.jvcir.2014.06.012
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100002
DA 2024-07-18
ER

PT J
AU Chen, J
   Yi, Z
AF Chen, Jie
   Yi, Zhang
TI Sparse representation for face recognition by discriminative low-rank
   matrix recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Low-rank representation; Matrix recovery;
   Dictionary learning; Face recognition; A low-rank projection matrix;
   Subspace; Eigenface
ID EIGENFACES; ALGORITHM; EQUATIONS; SYSTEMS
AB This paper proposes a discriminative low-rank representation (DLRR) method for face recognition in which both the training and test samples are corrupted owing to variations in occlusion and disguise. The proposed method extends the sparse representation-based classification algorithm by incorporating the low-rank structure of data representation. The DLRR algorithm recovers a clean dictionary with enhanced discrimination ability from the corrupted training samples for sparse representation. Simultaneously, it learns a low-rank projection matrix to correct corrupted test samples by projecting them onto their corresponding underlying subspaces. The dictionary elements from different classes are encouraged to be as independent as possible by regularizing the structural incoherence of the original training samples. This leads to a compact representation of a corrected test sample by a linear combination of more dictionary elements from the corrected class. The experimental results on benchmark databases show the effectiveness and robustness of our face recognition technique. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chen, Jie; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Yi, Z (corresponding author), Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
EM zyiscu@gmail.com
FU National Basic Research Program of China (973 Program) [2011CB302201]
FX The authors thank the anonymous reviewers for their thorough and
   valuable comments and suggestions. This work was supported by National
   Basic Research Program of China (973 Program) under Grant 2011CB302201.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], CVPR
   [Anonymous], 2009, ARXIV09123599
   [Anonymous], 2012, CVPR
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], ARXIV10102955
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   C L, IEEE T IMAGE PROCESS, V11
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elhamifar E., 2013, ARXIV12031005V3
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Kulkarni N, 2012, IEEE T CIRC SYST VID, V22, P778, DOI 10.1109/TCSVT.2011.2180773
   Lang CY, 2013, J VIS COMMUN IMAGE R, V24, P103, DOI 10.1016/j.jvcir.2012.06.002
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lin Z., 2012, ARXIV11090367
   Lin Z., 2011, ARXIV10095055
   Liu G., 2010, P INT C MACH LEARN, P663
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Min R., 2011, P 2011 IEEE INT C MU, DOI [10.1109/ICME.2011.6011971, DOI 10.1109/ICME.2011.6011971]
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Soni A., 2012, ICASSP
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wankou Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P527, DOI 10.1109/ICPR.2010.134
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Yang WK, 2009, PATTERN RECOGN, V42, P2327, DOI 10.1016/j.patcog.2009.03.017
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang Q., 2012, KDD, P1469
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang YMZ, 2013, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2013.93
NR 56
TC 45
Z9 62
U1 0
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 763
EP 773
DI 10.1016/j.jvcir.2014.01.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200005
DA 2024-07-18
ER

PT J
AU Sharma, M
   Chaudhury, S
   Lall, B
   Venkatesh, MS
AF Sharma, Mansi
   Chaudhury, Santanu
   Lall, Brejesh
   Venkatesh, M. S.
TI A flexible architecture for multi-view 3DTV based on uncalibrated
   cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth image based rendering; Multi-view 3DTV; Content based view
   specification; Free-viewpoint video; View synthesis; Hole-filling;
   Arbitrary virtual view rendering; Uncalibrated cameras; Selective
   warping
ID SELF-CALIBRATION; IMAGE; VIDEO; RECONSTRUCTION; ALGORITHM; STEREO
AB This paper presents a novel flexible architecture for 3DTV based on multiple uncalibrated cameras. The proposed signal representation improves the interactivity of dense point-based methods, making them appropriate for modeling the scene semantics and free-viewpoint 3DTV applications. The main concern is to address the shortcomings of depth image-based 3D video systems for free-viewpoint visualization, and to provide an efficient implementation of the rendering part which is computationally intensive as well potentially determine the view quality. Novel rendering algorithms are added that specifically aim at solving the rendering artifacts, and sampling issues encountered in wide baseline extensions and arbitrary camera movements. To optimize the process, a "selective" warping technique is proposed that takes the advantage of temporal coherence to reduce the computational overhead. Performance is illustrated on challenging videos to prove the suitability and flexibility of the architecture for advanced 3DTV systems. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Sharma, Mansi; Chaudhury, Santanu; Lall, Brejesh; Venkatesh, M. S.] Indian Inst Technol, Dept Elect Engn, Delhi 110016, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Sharma, M (corresponding author), Indian Inst Technol, Dept Elect Engn, Hauz Khas, Delhi 110016, India.
EM mansisharmaiitd@gmail.com; santanuc@ee.iit-d.ac.in;
   brejesh@ee.iitd.ac.in; msvenka@gmail.com
RI Zorzi, Michele/GQQ-2252-2022; Sharma, Mansi/S-1187-2017
OI Sharma, Mansi/0000-0003-3243-3321
FU Department of Science and Technology, Government of India
FX This work was supported in part by the Department of Science and
   Technology, Government of India.
CR Alatan AA, 2007, IEEE T CIRC SYST VID, V17, P1587, DOI 10.1109/TCSVT.2007.909974
   [Anonymous], P 3DTV C TRUE VIS CA
   Bajramovic Ferid, 2010, SELF CALIBRATION MUL
   Bertalmio M., 2001, PROC CVPR IEEE, V1, P1, DOI DOI 10.1109/CVPR.2001.990497
   Bhavsar AV, 2012, COMPUT VIS IMAGE UND, V116, P572, DOI 10.1016/j.cviu.2011.12.005
   Bhavsar Arnav V., 2009, BRIT MACH VIS C, P1
   Bourges-Sevenier Mikael, 2004, T CIRCUITS SYSTEMS V, V14
   Cao X, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/351452
   Cheng CM, 2011, IEEE T BROADCAST, V57, P523, DOI 10.1109/TBC.2011.2139090
   Christoph Fehn A, 2003, P 3 IASTED C VIS IM, P482
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fujii T, 2012, PROC SPIE, V8384, DOI 10.1117/12.922994
   Furukawa Y., 2014, 3D photography dataset
   Gallup David, 2007, CVPR
   Gulshan V., 2010, P C VIS PATT REC CVP
   Hartley R.I., 2004, MULTIPLE VIEW GEOMET, V2nd, P238
   Hasinoff SW, 2006, COMPUT VIS IMAGE UND, V103, P22, DOI 10.1016/j.cviu.2006.02.005
   Hirschmuller H., 2007, IEEE COMP SOC C COMP
   Hoeim D., 2005, IEEE INT C COMP VIS, V1, P654
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Huynh DQ, 2005, IMAGE VISION COMPUT, V23, P747, DOI 10.1016/j.imavis.2005.05.003
   Jantet V, 2011, 3D RES, V2, DOI 10.1007/3DRes.04(2011)4
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kim JH, 2009, PROC CVPR IEEE, P2144, DOI 10.1109/CVPRW.2009.5206593
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kovacs P.T., 2012, P ACM SIGGRAPH 12 EM
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Lee P. J., 2011, IEEE T MULTIMEDIA, V13
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233
   Liu YB, 2010, IEEE T VIS COMPUT GR, V16, P407, DOI 10.1109/TVCG.2009.88
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo K, 2009, J ZHEJIANG UNIV-SC A, V10, P1738, DOI 10.1631/jzus.A0820806
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Micusík B, 2010, INT J COMPUT VISION, V89, P106, DOI 10.1007/s11263-010-0327-9
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Park YK, 2009, SIGNAL PROCESS-IMAGE, V24, P122, DOI 10.1016/j.image.2008.10.008
   Pinson M., 2004, IEEE T BROADCASTING, V50
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schmeing M, 2010, 2010 3DTV C TRUE VIS, P1, DOI DOI 10.1109/3DTV.2010.5506596
   Shoemaker K., 1985, Computer Graphics, V19, P245, DOI 10.1145/325165.325242
   Sinha SN, 2009, IEEE I CONF COMP VIS, P1881, DOI 10.1109/ICCV.2009.5459417
   Stankiewicz Olgierd, 2008, JTC1SC29WG11MPEGM155
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Yu Lu, 2013, MASAYUKI TANIMOTO 3D
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zinger S, 2010, J VIS COMMUN IMAGE R, V21, P533, DOI 10.1016/j.jvcir.2010.01.004
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 56
TC 18
Z9 20
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 599
EP 621
DI 10.1016/j.jvcir.2013.07.012
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500002
DA 2024-07-18
ER

PT J
AU Zhang, XP
   Qian, ZX
   Feng, GR
   Ren, YL
AF Zhang, Xinpeng
   Qian, Zhenxing
   Feng, Guorui
   Ren, Yanli
TI Efficient reversible data hiding in encrypted images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; Embedding payload; LDPC code;
   Side information; Data compression; Least significant bits (LSB); Most
   significant bits (MSB)
ID PARITY-CHECK CODES; DIFFERENCE EXPANSION; COMPRESSION; DESIGN
AB This paper proposes a novel scheme of reversible data hiding in encrypted images based on lossless compression of encrypted data. In encryption phase, a stream cipher is used to mask the original content. Then, a data hider compresses a part of encrypted data in the cipher-text image using LDPC code, and inserts the compressed data as well as the additional data into the part of encrypted data itself using efficient embedding method. Since the majority of encrypted data are kept unchanged, the quality of directly decrypted image is satisfactory. A receiver with the data-hiding key can successfully extract the additional data and the compressed data. By exploiting the compressed data and the side information provided by the unchanged data, the receiver can further recover the original plaintext image without any error. Experimental result shows that the proposed scheme significantly outperforms the previous approaches. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Xinpeng; Qian, Zhenxing; Feng, Guorui; Ren, Yanli] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Zhang, XP (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, 149 Yanchang Rd, Shanghai 200072, Peoples R China.
EM xzhang@shu.edu.cn
RI Qian, Zhenxing/AHC-9176-2022
FU National Natural Science Foundation of China [61073190, 61103181];
   Research Fund for the Doctoral Program of Higher Education of China
   [20113108110010]; Program for Professor of Special Appointment (Eastern
   Scholar) at Shanghai Institutions of Higher Learning; Shanghai Pujiang
   Program [13PJ1403200]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61073190 and 61103181, the Research Fund for the
   Doctoral Program of Higher Education of China under Grant
   20113108110010, the Program for Professor of Special Appointment
   (Eastern Scholar) at Shanghai Institutions of Higher Learning, and
   Shanghai Pujiang Program under Grant 13PJ1403200.
CR [Anonymous], IEEE TRANS INF FOREN
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chung SY, 2001, IEEE COMMUN LETT, V5, P58, DOI 10.1109/4234.905935
   Fridrich J., 2007, P SOC PHOTO-OPT INS, V6050
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Gallager R., 1963, Ph.D. dissertation
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Luby MG, 2001, IEEE T INFORM THEORY, V47, P585, DOI 10.1109/18.910576
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   NORTON RM, 1984, AM STAT, V38, P135, DOI 10.2307/2683252
   Puech W., 2008, P SPIE, V6819
   Richardson TJ, 2001, IEEE T INFORM THEORY, V47, P619, DOI 10.1109/18.910578
   Schonberg D, 2008, IEEE T INF FOREN SEC, V3, P749, DOI 10.1109/TIFS.2008.2007244
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Zhang WM, 2010, IEEE T INFORM THEORY, V56, P1262, DOI 10.1109/TIT.2009.2039087
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
NR 22
TC 118
Z9 136
U1 1
U2 55
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 322
EP 328
DI 10.1016/j.jvcir.2013.11.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300009
DA 2024-07-18
ER

PT J
AU Hofmann, M
   Geiger, J
   Bachmann, S
   Schuller, B
   Rigoll, G
AF Hofmann, Martin
   Geiger, Juergen
   Bachmann, Sebastian
   Schuller, Bjoern
   Rigoll, Gerhard
TI The TUM Gait from Audio, Image and Depth (GAID) database: Multimodal
   recognition of subjects and traits
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; Soft biometrics; Multimodal fusion; Acoustic gait
   recognition; Gait energy image; Depth gradient histogram energy image
ID FEATURE FUSION; FACE
AB Recognizing people by the way they walk-also known as gait recognition-has been studied extensively in the recent past. Recent gait recognition methods solely focus on data extracted from an RGB video stream. With this work, we provide a means for multimodal gait recognition, by introducing the freely available TUM Gait from Audio, Image and Depth (GAID) database. This database simultaneously contains RGB video, depth and audio. With 305 people in three variations, it is one of the largest to-date. To further investigate challenges of time variation, a subset of 32 people is recorded a second time. We define standardized experimental setups for both person identification and for the assessment of the soft biometrics age, gender, height, and shoe type. For all defined experiments, we present several baseline results on all available modalities. These effectively demonstrate multimodal fusion being beneficial to gait recognition. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hofmann, Martin; Geiger, Juergen; Bachmann, Sebastian; Schuller, Bjoern; Rigoll, Gerhard] Tech Univ Munich, Inst Human Machine Commun, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Hofmann, M (corresponding author), Tech Univ Munich, Inst Human Machine Commun, Arcisstr 21, D-80333 Munich, Germany.
EM martin.hofmann@tum.de; geiger@tum.de; sebastian.bachmann@mytum.de;
   schuller@tum.de; rigoll@tum.de
RI Schuller, Björn Wolfgang/D-3241-2011
OI Schuller, Björn Wolfgang/0000-0002-6478-8699
FU ALIAS project [AAL-2009-2-049]; EC; French ANR; German BMBF
FX This research was supported by the ALIAS project (AAL-2009-2-049)
   co-funded by the EC, the French ANR and the German BMBF. The authors
   thank Adriana Anguera for her valuable input.
CR [Anonymous], EXPT PLAN AUTOMATIC
   [Anonymous], 2003, P INT C CONTR AUT SY
   [Anonymous], 2008, 2008 IEEE 2 INT C BI
   [Anonymous], 2001, CMU MOTION BODY MOBO
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Camplani M., 2012, IS T SPIE INT C 3D I, V8290
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Cuntoor N., 2003, P ICASSP, P6
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Carvalho RL, 2010, PROC IEEE INT SYMP, P1639, DOI 10.1109/ISIE.2010.5637551
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Hofmann M., 2012, Proceedings of the International Conference on Biometrics, P1
   Hofmann M., 2012, P IEEE INT C BIOM TH
   Hofmann M, 2012, IEEE IMAGE PROC, P1389, DOI 10.1109/ICIP.2012.6467128
   Hofmann M, 2011, WSCG 2011: COMMUNICATION PAPERS PROCEEDINGS, P99
   Huang Y, 2010, IEEE T CIRC SYST VID, V20, P431, DOI 10.1109/TCSVT.2009.2035852
   Itai A, 2008, IEEE INT SYMP CIRC S, P3234, DOI 10.1109/ISCAS.2008.4542147
   Itai A, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P992
   Johnson AY, 2001, LECT NOTES COMPUT SC, V2091, P301
   Kale A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P901
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kale A., 2002, P IEEE INT C AC SPEE
   Kalgaonkar K, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P27
   Lee TKM, 2006, INT C PATT RECOG, P541
   Little J. J., 1998, Videre, V1
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Makela K., 2003, P 2003 INT C AUD DIS, P144
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Makihara Y., 2011, 2011 INT JOINT C BIO, P1, DOI 10.1109/IJCB.2011.6117531
   Matovski DS, 2012, IEEE T INF FOREN SEC, V7, P543, DOI 10.1109/TIFS.2011.2176118
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Shakhnarovich G, 2001, PROC CVPR IEEE, P439
   She B., 2004, P INT C AC, P715
   Shoji Y., 2004, Proceedings of 2004 International Symposium on Intelligent Signal Processing And Communication Systems ISPACS 2004 (IEEE Cat. No.04EX910), P43, DOI 10.1109/ISPACS.2004.1439012
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sundaresan A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P93
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang TH, 2008, PATTERN RECOGN, V41, P805, DOI 10.1016/j.patcog.2007.06.035
   Zhou X, 2008, PATTERN RECOGN, V41, P778, DOI 10.1016/j.patcog.2007.06.019
   Zhou XL, 2006, INT C PATT RECOG, P529
NR 48
TC 135
Z9 144
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 195
EP 206
DI 10.1016/j.jvcir.2013.02.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900017
DA 2024-07-18
ER

PT J
AU Gao, ZR
   Xiong, CY
   Ding, LX
   Zhou, C
AF Gao, Zhirong
   Xiong, Chengyi
   Ding, Lixin
   Zhou, Cheng
TI Image representation using block compressive sensing for compression
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; Image compression; Encrypted image; Robust coding;
   Discrete cosine transform; Block compressive sensing; Coefficient random
   permutation; Adaptive sampling
ID SIGNAL RECOVERY
AB The emerging compressive sensing (CS) theory has pointed us a promising way of developing novel efficient data compression techniques, although it is proposed with original intention to achieve dimension-reduced sampling for saving data sampling cost. However, the non-adaptive projection representation for the natural images by conventional CS (CCS) framework may lead to an inefficient compression performance when comparing to the classical image compression standards such as JPEG and JPEG 2000. In this paper, two simple methods are investigated for the block CS (BCS) with discrete cosine transform (DCT) based image representation for compression applications. One is called coefficient random permutation (CRP), and the other is termed adaptive sampling (AS). The CRP method can be effective in balancing the sparsity of sampled vectors in DCT domain of image, and then in improving the CS sampling efficiency. The AS is achieved by designing an adaptive measurement matrix used in CS based on the energy distribution characteristics of image in DCT domain, which has a good effect in enhancing the CS performance. Experimental results demonstrate that our proposed methods are efficacious in reducing the dimension of the BCS-based image representation and/or improving the recovered image quality. The proposed BCS based image representation scheme could be an efficient alternative for applications of encrypted image compression and/or robust image compression. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Gao, Zhirong] South Cent Univ Nationalities, Coll Comp Sci, Wuhan 430074, Peoples R China.
   [Xiong, Chengyi; Zhou, Cheng] South Cent Univ Nationalities, Coll Elect & Informat Engn, Hubei Key Lab Intelligent Wireless Commun, Wuhan 430074, Peoples R China.
   [Gao, Zhirong; Ding, Lixin] Wuhan Univ, Comp Sch, Wuhan 430074, Peoples R China.
C3 South Central Minzu University; South Central Minzu University; Wuhan
   University
RP Xiong, CY (corresponding author), South Cent Univ Nationalities, Coll Elect & Informat Engn, Hubei Key Lab Intelligent Wireless Commun, Wuhan 430074, Peoples R China.
EM gaozhirong@mail.scuec.edu.cn; xiongcy@mail.scuec.edu.cn;
   lxding@whu.edu.cn
FU Fundamental Research Funds for the Central Universities [CZY12006];
   Natural Science Foundations of China [60972081]; Hubei Natural Science
   Foundations of China [2009CDA139]
FX The authors would like to thank Editor and the reviewers for their
   helpful comments that lead to an essential improvement of the
   manuscript. This work was supported by the Fundamental Research Funds
   for the Central Universities (granted No. CZY12006), Natural Science
   Foundations of China (granted No. 60972081) and Hubei Natural Science
   Foundations of China (granted No. 2009CDA139).
CR Bajwa WU, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P294, DOI 10.1109/SSP.2007.4301266
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Baraniuk RG, 2010, P IEEE, V98, P906, DOI 10.1109/JPROC.2010.2047424
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   Deng CW, 2010, IEEE INT CON MULTI, P462, DOI 10.1109/ICME.2010.5583387
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Goyal VK, 2008, IEEE SIGNAL PROC MAG, V25, P48, DOI 10.1109/MSP.2007.915001
   Han B, 2010, J VIS COMMUN IMAGE R, V21, P325, DOI 10.1016/j.jvcir.2010.02.007
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Huang HL, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P1287, DOI 10.1109/ICARCV.2008.4795707
   Kumar A.A., 2009, TENCON 2009 2009 IEE, P1
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Petrisor T, 2007, INT CONF ACOUST SPEE, P709
   Prades-Nebot J., 2009, 2009 Picture Coding Symposium, PCS 2009, P1, DOI DOI 10.1109/PCS.2009.5167431
   Sanei S., 2009, 16 INT C DIG SIGN PR, P1
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   Venkatraman D, 2009, INT CONF ACOUST SPEE, P3513, DOI 10.1109/ICASSP.2009.4960383
   Wen JT, 2010, INT CONF ACOUST SPEE, P1294, DOI 10.1109/ICASSP.2010.5495423
   Yang Y, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P373, DOI 10.1109/PCS.2009.5167354
   Yang Y, 2009, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2009.5202443
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Zhang YF, 2008, INT CONF ACOUST SPEE, P1361
   Zhirong Gao, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P321, DOI 10.1109/CMSP.2011.71
NR 32
TC 47
Z9 49
U1 0
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 885
EP 894
DI 10.1016/j.jvcir.2013.06.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700014
DA 2024-07-18
ER

PT J
AU Hou, J
   Liu, WX
   Xu, E
   Xia, Q
   Qi, NM
AF Hou, Jian
   Liu, Wei-Xue
   Xu, E.
   Xia, Qi
   Qi, Nai-Ming
TI An experimental study on the universality of visual vocabularies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bag-of-visual-words; Visual vocabulary; Universal; Bag-of-words;
   Classification; Experimental study; Image representation; Visual
   features
ID SCENE
AB Bag-of-visual-words has been shown to be a powerful image representation and attained success in many computer vision and pattern recognition applications. Usually for a given classification task, researchers choose to build a specific visual vocabulary, and the problem of building a universal visual vocabulary is rarely addressed. In this paper we conduct extensive classification experiments with three features on four image datasets and show that the visual vocabularies built from different datasets can be exchanged without apparent performance loss. Furthermore, we investigate the correlation between the visual vocabularies built from different datasets and find that they are nearly identical, which explains why they are universal across classification tasks. We believe that this work reveals what is behind the universality of visual vocabularies and narrows the gap between bag-of-visual-words and bag-of-words in text domain. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hou, Jian; Liu, Wei-Xue; Xu, E.] Bohai Univ, Sch Informat Sci & Technol, Jinzhou 121013, Peoples R China.
   [Xia, Qi; Qi, Nai-Ming] Harbin Inst Technol, Sch Astronaut, Harbin 150001, Peoples R China.
C3 Bohai University; Harbin Institute of Technology
RP Hou, J (corresponding author), Bohai Univ, Sch Informat Sci & Technol, Jinzhou 121013, Peoples R China.
EM dr.houjian@gmail.com
RI xia, qi/JBR-8998-2023
FU Scientific Research Fund of Liaoning Provincial Education Department
   [L2012400, L2012396, L2012397]; China Postdoctoral Science Foundation
   [2012M520158]; National Natural Science Foundation of China [61171189]
FX This work is supported by Scientific Research Fund of Liaoning
   Provincial Education Department under Grant Nos. L2012400, L2012396 and
   L2012397, and by China Postdoctoral Science Foundation under Grant No.
   2012M520158. Also this work is supported in part by National Natural
   Science Foundation of China under Grant No. 61171189.
CR [Anonymous], 2007, MIR
   [Anonymous], IEEE C COMP VIS PAT, DOI DOI 10.1109/CVPR.2006.68
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Cai HP, 2010, PROC CVPR IEEE, P2320, DOI 10.1109/CVPR.2010.5539918
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fei-Fei L., 2004, CVPR WORKSH GEN MOD, V106, P178, DOI DOI 10.1109/CVPR.2004.383
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hou J., 2011, P INT S VIS COMP, P414
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Li TQ, 2008, INT OFFSHORE POLAR E, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallapragada PK, 2010, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2010.5540062
   Marszalek M., 2006, PROC IEEE INT C COMP, V2, P2118
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Ries CX, 2010, IEEE INT CON MULTI, P1067, DOI 10.1109/ICME.2010.5583878
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Viitaniemi V., 2009, ACM INT C IM VID RET
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
NR 24
TC 10
Z9 10
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1204
EP 1211
DI 10.1016/j.jvcir.2013.08.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700043
DA 2024-07-18
ER

PT J
AU Yousef, M
   Hussain, KF
AF Yousef, Mohamed
   Hussain, Khaled F.
TI Fast exhaustive-search equivalent pattern matching through norm ordering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pattern matching; Template matching; Fast algorithms; Full search
   equivalent algorithm; NOM; Evaluation order; Nearest Neighbor; Image
   processing
ID ALGORITHM
AB Pattern matching is a fundamental problem in computer vision, and image and video processing. Exhaustive-search equivalent algorithms yield the same results as exhaustively searching all patterns in the image but significantly faster. In this paper, we propose a novel exhaustive-search equivalent algorithm that is combined with a number of state-of-art algorithms to provide a significantly faster alternative in the problem of finding nearest pattern according to a predefined distance measure. Our technique also shows high resilience to both blurring and JPEG compression types of noise. This is demonstrated in the paper with results from over 15 million runs for each compared algorithm. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yousef, Mohamed; Hussain, Khaled F.] Assiut Univ, Fac Comp & Informat, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Assiut University
RP Yousef, M (corresponding author), Assiut Univ, Fac Comp & Informat, Assiut, Egypt.
EM mohamed.mandi@compit.au.edu.eg; khussai-n@aun.edu.eg
RI Hussain, Khaled/ABB-7320-2020; Hussain, Khaled/Q-6599-2018
OI Hussain, Khaled/0000-0002-9387-1803
CR [Anonymous], 2008, 2008 IEEE C COMPUTER
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Ben-Artzi G, 2007, IEEE T PATTERN ANAL, V29, P382, DOI 10.1109/TPAMI.2007.62
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Dufour RM, 2002, IEEE T IMAGE PROCESS, V11, P1385, DOI 10.1109/TIP.2002.806245
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fitzgibbon A, 2005, INT J COMPUT VISION, V63, P141, DOI 10.1007/s11263-005-6643-9
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gharavi-Alkhansari M, 2001, IEEE T IMAGE PROCESS, V10, P526, DOI 10.1109/83.913587
   Hel-Or Y, 2005, IEEE T PATTERN ANAL, V27, P1430, DOI 10.1109/TPAMI.2005.184
   Kumar N, 2008, LECT NOTES COMPUT SC, V5303, P364, DOI 10.1007/978-3-540-88688-4_27
   Lewis JP, 1994, PROC CANAD IMAG PROC, P120
   Liu LJ, 2004, J AM SOC INF SCI TEC, V55, P81, DOI 10.1002/asi.10343
   Luczak T, 1997, IEEE T INFORM THEORY, V43, P1439, DOI 10.1109/18.623143
   MCDONNELL MJ, 1981, COMPUT VISION GRAPH, V17, P65, DOI 10.1016/S0146-664X(81)80009-3
   Ouyang WL, 2012, IEEE T PATTERN ANAL, V34, P127, DOI 10.1109/TPAMI.2011.106
   Ouyang WL, 2010, IEEE T PATTERN ANAL, V32, P165, DOI 10.1109/TPAMI.2009.104
   PRUGOVECKI E, 1981, QUANTUM MECH HILBERT
   Shakhnarovich G., 2006, NEAREST NEIGHBOR MET
   Tombari F, 2009, IEEE T PATTERN ANAL, V31, P129, DOI 10.1109/TPAMI.2008.46
   Wolf L, 2006, LECT NOTES COMPUT SC, V3952, P481
   Xiao CX, 2011, IEEE T VIS COMPUT GR, V17, P1122, DOI 10.1109/TVCG.2010.226
NR 24
TC 5
Z9 5
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 592
EP 601
DI 10.1016/j.jvcir.2013.03.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900008
DA 2024-07-18
ER

PT J
AU Talib, A
   Mahmuddin, M
   Husni, H
   George, LE
AF Talib, Ahmed
   Mahmuddin, Massudi
   Husni, Husniza
   George, Loay E.
TI A weighted dominant color descriptor for content-based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dominant color descriptor; MPEG-7; Object- and content-based image
   retrieval; Semantic feature; Similarity measures; Salient object
   detection; Background dominance problem; Linear Block Algorithm
ID SIMILARITY MEASURE; EXTRACTION
AB Color has been extensively used in the process of image retrieval. The dominant color descriptor (DCD) that was proposed by MPEG-7 is a famous case in point. It is based on compactly describing the prominent colors of an image or a region. However, this technique suffers from some shortcomings; especially with respect to object-based image retrieval. In this paper, a new semantic feature extracted from dominant colors (weight for each DC) is proposed. The newly proposed technique helps reduce the effect of image background on image matching decision where an object's colors receive much more focus. In addition, a modification to DC-based similarity measure is also proposed. Experimental results demonstrate that the proposed descriptor with the similarity measure modification performs better than the existing descriptor in content-based image retrieval application. The proposed descriptor considers as step forward to the object-based image retrieval. Crown Copyright (c) 2013 Published by Elsevier Inc. All rights reserved.
C1 [Talib, Ahmed; Mahmuddin, Massudi; Husni, Husniza] Univ Utara Malaysia, Sch Comp, Dept Comp Sci, Sintok 06010, Kedah, Malaysia.
   [Talib, Ahmed] Fdn Tech Educ, IT Dept, Tech Coll Management, Baghdad 10047, Iraq.
   [George, Loay E.] Univ Baghdad, Dept Comp Sci, Coll Sci, Baghdad 10071, Iraq.
C3 Universiti Utara Malaysia; University of Baghdad
RP Talib, A (corresponding author), Univ Utara Malaysia, Sch Comp, Dept Comp Sci, Sintok 06010, Kedah, Malaysia.
EM s91707@student.uum.edu.my
RI George, Loay Edwar/S-6596-2019; Talib, Ahmed/KBB-6403-2024; Husni,
   Husniza/AAG-6698-2021; Mahmuddin, Massudi/F-8366-2012
OI Husni, Husniza/0000-0002-5940-4566; George, Loay/0000-0001-9028-0816;
   Talib, Ahmed/0000-0003-3600-2369; Mahmuddin, Massudi/0000-0002-0357-4136
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587658
   [Anonymous], 2001, JTC1SC29WG11N391 ISO
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 1988, Proceedings of International Conference ofComputer Vision (ICCV'88), DOI [10.1109/CCV.1988.590008, DOI 10.1109/CCV.1988.590008]
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P361, DOI 10.1109/ICPR.1996.546971
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das M, 1997, PROC CVPR IEEE, P756, DOI 10.1109/CVPR.1997.609411
   Deng YN, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P21, DOI 10.1109/ISCAS.1999.779933
   FAUQUEUR J, 2002, P IEEE INT C IM PROC
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1007/BF00672252
   Grubinger M., 2007, THESIS VICTORIA U ME
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Kim S, 2003, LECT NOTES COMPUT SC, V2728, P39
   Kiranyaz S., 2012, PERCEPTUAL DIGITAL I
   Kiranyaz S, 2010, IMAGE VISION COMPUT, V28, P1309, DOI 10.1016/j.imavis.2010.01.012
   Krishnan N., 2007, COMP INT MULT APPL I, V3, P190
   Kunttu I, 2003, Digital Media: Processing Multimedia Interactive Services, P88, DOI 10.1142/9789812704337_0016
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma WY, 1997, P SOC PHOTO-OPT INS, V3016, P496, DOI 10.1117/12.274547
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Matas J, 2000, LECT NOTES COMPUT SC, V1842, P48
   Milanese R., 1993, THESIS U GENEVA
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Mojsilovic A, 2002, IEEE T IMAGE PROCESS, V11, P1238, DOI 10.1109/TIP.2002.804260
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Penatti O. A. B., 2012, J VIS COMMUN IMAGE R
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Phanendra Babu G., 1995, Multimedia Tools and Applications, V1, P327, DOI 10.1007/BF01215882
   Po LM, 2004, IEEE IMAGE PROC, P1533
   Rodhetbhai W., 2009, PREPROCESSING CONTEN
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Sclaroff S, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P2
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Stehling R. O., 2003, Knowledge and Information Systems, V5, P315, DOI 10.1007/s10115-003-0084-y
   Stehling RO, 2001, 2001 INTERNATIONAL DATABASE ENGINEERING & APPLICATIONS SYMPOSIUM, PROCEEDINGS, P356, DOI 10.1109/IDEAS.2001.938104
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Sykora D., 2005, Proceedings of Eurographics Workshop on Sketch-Based Interfaces and Modeling, P27
   Sykora D., 2003, C COMP GRAPH, P223, DOI [10.1145/984952.984989, DOI 10.1145/984952.984989]
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Wong KM, 2007, IEEE IMAGE PROC, P3161
   Wong KM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P611
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yu J, 2012, SIGNAL PROCESS, V92, P2147, DOI 10.1016/j.sigpro.2012.01.028
   Yu J, 2011, J COMPUT SCI TECH-CH, V26, P203, DOI 10.1007/s11390-011-9427-4
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang J., 2011, ROBUST CONTENT BASED
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
NR 58
TC 56
Z9 61
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 345
EP 360
DI 10.1016/j.jvcir.2013.01.007
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200012
DA 2024-07-18
ER

PT J
AU Tian, L
   Zhou, YM
   Sun, Y
AF Tian, Ling
   Zhou, Yimin
   Sun, Yu
TI Novel rate control scheme for intra frame video coding with exponential
   rate-distortion model on H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rate control; H.264/AVC; Video coding; Rate-distortion model;
   Intra-only; Mean absolute difference; Bit rate; Virtual buffer;
   Low-delay video; Video quality
AB Rate control regulates the output bit rate of a video encoder in order to obtain optimum visual quality within the available network bandwidth and to maintain buffer fullness within a specified tolerance range. Due to the benefits of intra-only encoding, such as less computational cost and less latency, it has been more and more widely used. In this paper, we propose an accurate intra-only rate control scheme for H.264/AVC, which includes a novel complexity measurement and a new rate-distortion (R-D) model. We also propose a linear rate-complexity model which takes the intercept into consideration to reduce the estimation error. The proposed R-D model is integrated by the linear rate-complexity model and an exponential rate-quantization model. Based on theoretical analysis and experimental validation, the proposed scheme has high bits prediction precision, and it can also accurately handle buffer fullness. Compared with JVT-W042, our algorithm achieves higher average PSNR and improves the coding quality up to 0.35 dB. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Tian, Ling; Zhou, Yimin] Univ Elect Sci & Technol China, Coll Comp Sci & Engn, Chengdu 610054, Peoples R China.
   [Sun, Yu] Univ Cent Arkansas, Dept Comp Sci, Conway, AR 72035 USA.
C3 University of Electronic Science & Technology of China; University of
   Central Arkansas
RP Zhou, YM (corresponding author), Univ Elect Sci & Technol China, Coll Comp Sci & Engn, Chengdu 610054, Peoples R China.
EM lingtian@uestc.edu.cn; yiminzhou@uestc.edu.cn; yusun@uca.edu
OI Zhou, Yimin/0000-0001-8692-9635
FU National Natural Science Foundation of China [61103111]; Foundation of
   Science and Technology Department of Sichuan Province, China
   [2011HH0037, 2011JY0083]
FX This work supported by the National Natural Science Foundation of China
   (Grant No. 61103111) and the Foundation of Science and Technology
   Department of Sichuan Province, China (No. 2011HH0037 and No.
   2011JY0083).
CR [Anonymous], 2007, AVC INTRA H 264 INTR
   [Anonymous], INTRO MATH STAT ITS
   [Anonymous], WHITE PAPER TRANSF 4
   Chen ZZ, 2007, SIGNAL PROCESS-IMAGE, V22, P19, DOI 10.1016/j.image.2006.11.002
   Jing X., 2006, P IEEE INT S CIRC SY
   *JOINT VID TEAM, REF SOFTW JM13 2
   Kirkup L., 2002, Data analysis with Excel: An introduction for physical scientists
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Leontaris A., 2007, JOINT VID TEAM ISO I
   LI ZG, 2003, JOINT VID TEAM ISO I, P7
   LIM KP, 2004, JOINT VID TEAM ISO I
   Ma S.W., 2002, J QUANTITATIVE TECHN, P5
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Rezaei M, 2005, IEEE WRK SIG PRO SYS, P550, DOI 10.1109/SIPS.2005.1579928
   Storey D, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P803, DOI 10.1109/ISSPIT.2006.270908
   Sullivan G., 2003, JOINT VID TEAM ISO I
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Tian L, 2010, IEEE IMAGE PROC, P2853, DOI 10.1109/ICIP.2010.5651988
   Wang J, 2007, IEEE PACIF, P565
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yu HY, 2005, IEEE INT SYMP CIRC S, P312
   Zhou YM, 2011, IEEE T CIRCUITS-II, V58, P184, DOI 10.1109/TCSII.2011.2106350
   Zhou YM, 2009, SIGNAL PROCESS-IMAGE, V24, P345, DOI 10.1016/j.image.2009.02.014
NR 24
TC 5
Z9 6
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 873
EP 882
DI 10.1016/j.jvcir.2012.05.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900005
DA 2024-07-18
ER

PT J
AU Yang, WJ
   Chung, KL
   Liao, HYM
AF Yang, Wei-Jen
   Chung, Kuo-Liang
   Liao, Hong-Yuan Mark
TI Quality-efficient demosaicing for digital time delay and integration
   images using edge-sensing scheme in color difference domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Demosaicing algorithm; Digital time delay and integration (DTDI); Edge
   information; Industrial print inspection; Line-scan camera; Mosaic
   images; Color filter array (CFA); Sobel edge detector
ID FILTER ARRAYS; INTERPOLATION; ALGORITHM; CAMERAS; DESIGN
AB In this paper, we present a novel edge sensing-based demosaicing algorithm for digital time delay and integration (DTDI) mosaic images, which are captured by DTDI line-scan cameras and suitable for industrial print inspection. We propose to use Sobel- and interpolation-based masks to extract more accurate gradient information in the color difference domain. The extracted gradient information is utilized to assist the design of the proposed demosaicing algorithm. By experimenting on more than one thousand and three hundred test DTDI mosaic images, the results demonstrate the efficiency of the proposed demosaicing algorithm in terms of demosaiced image quality. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Yang, Wei-Jen; Chung, Kuo-Liang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Liao, Hong-Yuan Mark] Acad Sinica, Inst Informat Sci, Taipei 11529, Taiwan.
C3 National Taiwan University of Science & Technology; Academia Sinica -
   Taiwan
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM k.l.chung@mail.ntust.edu.tw
RI Liao, Hong-Yuan Mark/AAQ-5514-2021
FU National Science Council of ROC [NSC99-2221-E-011-078-MY3]
FX Supported by National Science Council of ROC under the contract
   NSC99-2221-E-011-078-MY3.
CR [Anonymous], 1997, P SIGGRAPH
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bodenstorfer E., 2007, P EL IM C REAL TIM I
   Chung KH, 2010, IEEE INT CON MULTI, P388, DOI 10.1109/ICME.2010.5583902
   Chung KL, 2008, IEEE T IMAGE PROCESS, V17, P2356, DOI 10.1109/TIP.2008.2005561
   Chung KL, 2010, IEEE T CONSUM ELECTR, V56, P783, DOI 10.1109/TCE.2010.5506002
   Chung KL, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3302126
   Chung KL, 2009, IEEE T CONSUM ELECTR, V55, P1477, DOI 10.1109/TCE.2009.5278016
   Furtler J., 2007, P EL IM C MACH VIS A
   Gonzalez R., 1992, DIGITAL IMAGE PROCES
   Hamilton Jr J. F., 1997, US Patent, Patent No. [5,629,734, 5629734]
   Heiss-Czedik D, 2009, J VIS COMMUN IMAGE R, V20, P389, DOI 10.1016/j.jvcir.2009.04.003
   Hunt R.W.G., 1995, MEASURING COLOUR
   Laroche C., 1994, United States Patent, Patent No. 5373322
   Lu WM, 2003, IEEE T IMAGE PROCESS, V12, P1194, DOI 10.1109/TIP.2003.816004
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Nagahara H., 2008, P IEEE RSJ INT C INT, P4072
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Pekkucuksen I, 2012, IEEE T IMAGE PROCESS, V21, P393, DOI 10.1109/TIP.2011.2155073
   Sakamoto T, 1998, IEEE T CONSUM ELECTR, V44, P1342, DOI 10.1109/30.735836
   WONG HS, 1992, IBM J RES DEV, V36, P83, DOI 10.1147/rd.361.0083
   Zheng JY, 2008, INT J COMPUT VISION, V78, P169, DOI 10.1007/s11263-007-0080-x
NR 22
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 729
EP 741
DI 10.1016/j.jvcir.2012.04.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400005
DA 2024-07-18
ER

PT J
AU García, JA
   Rodriguez-Sánchez, R
   Fdez-Valdivia, J
AF Garcia, J. A.
   Rodriguez-Sanchez, Rosa
   Fdez-Valdivia, J.
TI Sustainable image transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Transmission cost; Axiomatic approach; Progressive transmission;
   Sustainable transmission path; Pontryagin's maximum principle; SPIHT;
   REWIC; SAVING
AB Under the assumption of oscillatory behaviour of the difference between coding gain and transmission cost over time, heavy losses may be incurred in the form of foregone transmission opportunities in the future or in the present. It calls for a sustainable transmission path which would then modify the optimal transmission condition accordingly to render it dynamically efficient over time.
   But what is the most sustainable transmission path? Sustainable transmission satisfies the needs for transmission at present time without compromising the needs of bits for future transmission.
   This paper presents a set of axioms that capture this idea of sustainable transmission and characterizes the criterion of sustainable transmission. The Pontryagin's maximum principle is then used to find out the transmission path that maximizes such a criterion. It will be the most sustainable transmission path.
   Here we analyze to which point three coding methods lead to sustainable transmission. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Garcia, J. A.; Rodriguez-Sanchez, Rosa; Fdez-Valdivia, J.] Univ Granada, Dept Ciencias Computac & IA, CITIC UGR, E-18071 Granada, Spain.
C3 University of Granada
RP García, JA (corresponding author), Univ Granada, Dept Ciencias Computac & IA, CITIC UGR, E-18071 Granada, Spain.
EM jags@decsai.ugr.es; rosa@decsai.ugr.es; jfv@decsai.ugr.es
RI Fdez-Valdivia, J/B-1844-2012; Garcia, Jose A./C-1703-2010; Rodriguez
   Sanchez, Rosa Maria/B-1847-2012
OI Fdez-Valdivia, J/0000-0001-7181-1554; Garcia, Jose
   A./0000-0001-7742-7270; Rodriguez Sanchez, Rosa
   Maria/0000-0001-7886-9329
FU Spanish Board for Science and Technology (MICINN) [TIN2010-15157];
   European FEDER funds
FX This research was sponsored by the Spanish Board for Science and
   Technology (MICINN) under grant TIN2010-15157 co-financed with European
   FEDER funds. The authors thank to the reviewers for suggesting several
   good ways to improve the original manuscript.
CR Chichilnisky G, 1997, LAND ECON, V73, P467, DOI 10.2307/3147240
   García JA, 2010, PATTERN RECOGN, V43, P1618, DOI 10.1016/j.patcog.2009.09.027
   Garcia JA, 2007, OPT ENG, V46, DOI 10.1117/1.2717132
   García JA, 2002, OPT ENG, V41, P2216, DOI 10.1117/1.1496789
   García JA, 2001, IEEE T PATTERN ANAL, V23, P362, DOI 10.1109/34.917572
   Garcia JA, 2008, OPT ENG, V47, DOI 10.1117/1.2904824
   Pontryagin L., 1962, MATH THEORY OPTIMAL
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, P IEEE DAT COMPR C, P214
NR 9
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 134
EP 142
DI 10.1016/j.jvcir.2011.09.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100013
DA 2024-07-18
ER

PT J
AU Bici, MO
   Akar, GB
AF Bici, M. Oguz
   Akar, Gozde B.
TI Improved prediction methods for scalable predictive animated mesh
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compression; Animated meshes; 3D dynamic meshes; Time consistent mesh
   sequence; Predictive coding; Weighted prediction; Animated mesh coding;
   Angle based prediction
AB Animated meshes represented as sequences of static meshes sharing the same connectivity require efficient compression. Among the compression techniques, layered predictive coding methods efficiently encode the animated meshes in a structured way such that the successive reconstruction with an adaptable quality can be performed. The decoding quality heavily depends on how well the prediction is performed in the encoder. Due to this fact, in this paper, three novel prediction structures are proposed and integrated into a state of the art layered predictive coder. The proposed structures are based on weighted spatial prediction with its weighted refinement and angular relations of triangles between current and previous frames. The experimental results show that compared to the state of the art scalable predictive coder, up to 30% bitrate reductions can be achieved with the combination of proposed prediction schemes depending on the content and quantization level. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Bici, M. Oguz; Akar, Gozde B.] Middle E Tech Univ, TR-06531 Ankara, Turkey.
C3 Middle East Technical University
RP Bici, MO (corresponding author), Middle E Tech Univ, TR-06531 Ankara, Turkey.
EM mobici@eee.metu.edu.tr
RI Akar, Gozde B./AAZ-8753-2020
OI B. Akar, Gozde/0000-0002-4227-5606
FU EC [216503]; Scientific and Technological Research Council of Turkey
   (TUBITAK)
FX This work is supported by EC within FP7 under Grant 216503 with the
   acronym Mobile3DTV. It is also partially supported by The Scientific and
   Technological Research Council of Turkey (TUBITAK). The chicken
   character was created by Andrew Glassner, Tom McClure, Scott Benza, and
   Mark Van Langeveld. This short sequence of connectivity and vertex
   position data is distributed solely for the purpose of comparison of
   geometry compression techniques. We would like to thank Nikolce
   Stefanoski for providing the source codes of layered predictive dynamic
   3D mesh codec [36].
CR Ahn JH, 2001, ELECTRON LETT, V37, P1445, DOI 10.1049/el:20010993
   Alexa M, 2000, COMPUT GRAPH FORUM, V19, pC411, DOI 10.1111/1467-8659.00433
   ALLIEZ P, 2003, P S MULT GEOM MOD
   AMJOUN R, 2008, J VIRTUAL REALITY BR, V5
   AMJOUN R, 2007, J WSCG, V15, P32
   Amjoun R, 2006, LECT NOTES COMPUT SC, V4035, P606
   Amjoun R, 2009, COMPUT AIDED DESIGN, V41, P711, DOI 10.1016/j.cad.2009.02.013
   BOULFANICUISINA.Y, 2007, IEEE INT C IM PROC
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   Cho JW, 2006, IEEE IMAGE PROC, P529, DOI 10.1109/ICIP.2006.312393
   GU X, 2002, SIGGRAPH 02, P355, DOI DOI 10.1145/566570.566589
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   Heu JH, 2009, J VIS COMMUN IMAGE R, V20, P439, DOI 10.1016/j.jvcir.2009.05.003
   IBARRIA L, 2003, P 2003 ACM SIGGRAPH, P126
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Kirchhoffer H, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P341, DOI 10.1109/ICME.2008.4607441
   Lengyel J. E., 1999, Proceedings 1999 Symposium on Interactive 3D Graphics, P89, DOI 10.1145/300523.300533
   Mamou K, 2008, IEEE IMAGE PROC, P2676, DOI 10.1109/ICIP.2008.4712345
   Mamou K, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P711
   Mamou K, 2006, COMPUT ANIMAT VIRT W, V17, P337, DOI 10.1002/cav.137
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Müller K, 2006, SIGNAL PROCESS-IMAGE, V21, P812, DOI 10.1016/j.image.2006.07.002
   MULLER K, 2005, 2005 IEEE INT C IM P
   PAYAN F, P IEEE ACIDCA ICMI 2
   Payan F, 2007, COMPUT GRAPH-UK, V31, P77, DOI 10.1016/j.cag.2006.09.009
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Sattler M., 2005, P 2005 ACM SIGGRAPH, P209
   STEFANOSKI N, 2007, 3DTV C 2007, P1, DOI DOI 10.1109/3DTV.2007.4379461
   Stefanoski N, 2006, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2006.312961
   Stefanoski N, 2010, COMPUT GRAPH FORUM, V29, P101, DOI 10.1111/j.1467-8659.2009.01547.x
   Stefanoski N, 2008, IEEE IMAGE PROC, P2696, DOI 10.1109/ICIP.2008.4712350
   Vása L, 2009, COMPUT GRAPH FORUM, V28, P1529, DOI 10.1111/j.1467-8659.2008.01304.x
   Vasa L, 2007, 3DTV CONF, P49, DOI 10.1109/3DTV.2007.4379408
   Vása L, 2010, COMPUT GRAPH FORUM, V29, P1921, DOI 10.1111/j.1467-8659.2010.01659.x
   Vása L, 2009, COMPUT ANIMAT VIRT W, V20, P447, DOI 10.1002/cav.227
   Yang JH, 2002, IEEE T CIRC SYST VID, V12, P1178, DOI 10.1109/TCSVT.2002.806814
   Zhang JH, 2004, IEEE DATA COMPR CONF, P508
   Zhang JH, 2007, COMPUT GRAPH-UK, V31, P463, DOI 10.1016/j.cag.2006.12.002
NR 39
TC 13
Z9 13
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 577
EP 589
DI 10.1016/j.jvcir.2011.07.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800001
DA 2024-07-18
ER

PT J
AU Lee, SW
   Kuo, CCJ
AF Lee, Szu-Wei
   Kuo, C. -C. Jay
TI Novel H.264/AVC entropy coding mode decision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; CABAC; CAVLC/UVLC; Decoding complexity profiling; Decoding
   complexity model; Entropy coding mode decision; Rate-distortion (RD)
   optimization; Rate-distortion and decoding complexity (RDC) optimization
AB In this work, we propose a novel entropy coding mode decision algorithm to balance the tradeoff between the rate-distortion (R-D) performance and the entropy decoding complexity for the H.264/AVC video coding standard. Context-based adaptive binary arithmetic coding (CABAC), context-based adaptive variable length coding (CAVLC), and universal variable length coding (UVLC) are three entropy coding tools adopted by H.264/AVC. CABAC can be used to encode the texture and the header data while CAVLC and UVLC are employed to encode the texture and the header data, respectively. Although CABAC can provide better R-D performance than CAVLC/UVLC, its decoding complexity is higher. Thus, by taking the entropy decoding complexity into account, CABAC may not be the best tool, which motivates us to examine the entropy coding mode decision problem in depth. It will be shown experimentally that the proposed mode decision algorithm can help the encoder generate the bit streams that can be decoded at much lower complexity with little R-D performance loss. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Lee, Szu-Wei] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   Univ So Calif, Inst Signal & Image Proc, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Lee, SW (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM szuweile@usc.edu; swli0311@yahoo.com
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR [Anonymous], AMD CODEANALYST PERF
   [Anonymous], IEEE INT C AC SPEECH
   Chen JW, 2009, IEEE T CONSUM ELECTR, V55, P1614, DOI 10.1109/TCE.2009.5278034
   intel, Intel VTune performance analyzer
   Joint Video Team, H 264 JM94 REF COD
   Lee SW, 2008, IEEE INT SYMP CIRC S, P1616
   Lee SW, 2007, PROC SPIE, V6696, DOI 10.1117/12.730962
   Ma Z., 2008, IEEE INT C IM PROC I
   Marpe Detlev., Context-based adaptive binary arithmetic coding (cabac)
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Wang Y., LOW COMPLEXITY H 264
   WANG YF, THESIS COLUMBIA U
   Yang Y. C., HIGH THROUGHPUT H 26
   Zhang P, 2008, ELECTRON LETT, V44, P1394, DOI 10.1049/el:20082126
   Zhang P, 2009, IEEE T VLSI SYST, V17, P417, DOI 10.1109/TVLSI.2008.2005286
NR 15
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 557
EP 562
DI 10.1016/j.jvcir.2011.03.004
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000010
DA 2024-07-18
ER

PT J
AU Tehrani, MP
   Ishikawa, A
   Sakazawa, S
   Koike, A
AF Tehrani, Mehrdad Panahpour
   Ishikawa, Akio
   Sakazawa, Shigeyuki
   Koike, Atsushi
TI Iterative colour correction of multicamera systems using corresponding
   feature points
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Colour correction; Average colour intensities; SIFT; Suppressing
   outliers; Corresponding intensities; Nonlinear weighting; Gaussian
   kernel density function; Dynamic programming
AB Multiview images captured by multicamera systems are generally not uniform in colour domain. In this paper, we propose a novel colour correction method of multicamera systems that can (i) be applied to not only dense multicamera system, but also sparse multicamera configuration and (ii) obtain an average colour pattern among all cameras. Our proposed colour correction method starts from any camera on the array sequentially, following a certain path, for pairs of cameras, until it reaches the starting point and triggers several iterations. The iteration stops when the correction applied to the images becomes small enough. We propose to calculate the colour correction transformation based on energy minimisation using a dynamic programming of a nonlinearly weighted Gaussian-based kernel density function of geometrically corresponding feature points, obtained by the modified scale invariant feature transformation (SIFT) method, from several time instances and their Gaussian-filtered images. This approach guarantees the convergence of the iteration procedure without any visible colour distortion. The colour correction is done for each colour channel independently. The process is entirely automatic, after estimation of the parameters through the algorithm. Experimental results show that the proposed iteration-based algorithm can colour-correct the dense/sparse multicamera system. The correction is always converged with average colour intensity among viewpoint, and out-performs the conventional method. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Tehrani, Mehrdad Panahpour] Nagoya Univ, Grad Sch Engn, Dept Elect Engn & Comp Sci, Chikusa Ku, Nagoya, Aichi 4648603, Japan.
   [Tehrani, Mehrdad Panahpour; Ishikawa, Akio; Sakazawa, Shigeyuki; Koike, Atsushi] Ultra Realist Commun KDDI R&D Labs Inc, Fujimino, Saitama 3568502, Japan.
   [Koike, Atsushi] Seikei Univ, Fac Sci & Technol, Dept Comp & Informat Sci, Musashino, Tokyo 1808633, Japan.
C3 Nagoya University; Seikei University
RP Tehrani, MP (corresponding author), Nagoya Univ, Grad Sch Engn, Dept Elect Engn & Comp Sci, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648603, Japan.
EM mehrdad.panahpour@ieee.org
OI Teratani, Mehrdad/0000-0001-9332-1409
CR [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], CS20050821 UCSD CSE
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   CHEN Y, 2006, P PCS2006
   Droese M., 2004, Proceedings of 11th International Workshop on Systems, Signals and Image Processing. Ambient Multimedia, P247
   DROESE M, 2004, P 3 D IM C 2004 TOK
   EVANS RM, 1953, PRINCIPLES COLOUR PH
   FECKER U, 2006, P PCS2006
   HIE A, 2005, ICCV05 2, P1268
   Ishikawa Akio, 2009, IEICE Transactions on Information and Systems, VJ92-D, P854
   *ISO JEC, 2004, JTCLSC29WGII ISOJEC
   Jahne B., 2002, DIGITAL IMAGE PROCES
   Kim SJ, 2008, IEEE T PATTERN ANAL, V30, P562, DOI 10.1109/TPAMI.2007.70732
   KIM SJ, 2004, P CVPR 2004
   LEE YL, 2006, JTCSC29WG11M12871 IS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matusik W, 2004, ACM T GRAPHIC, V23, P814, DOI 10.1145/1015706.1015805
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   NA BCP, 2005, J I IMAGE INFORM TEL, V59, P63
   Schapira AHV, 2002, EUR J NEUROL, V9, P7, DOI 10.1046/j.1468-1331.9.s3.9.x
   Scott D.W., 2015, Multivariate Density Estimation: Theory, Practice and Visualization, DOI 10.1002/9780470316849
   SHAO F, 2007, P ICASSP 2007 HAW US
   SOHN K, 2006, JTC1SC29WG11M12874 I
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Tehrani M. P., 2007, P FIT 2007 SEPT, P371
   Tehrani MP, 2004, IEICE T FUND ELECTR, VE87A, P1863
   YAMAMOTO K, 2007, J I IMAGE INFORM TEL, V61
   YAMAMOTO K, 2007, P WORKSH MULT MULT I
   YAMAMOTO K, 2006, MECSE42006 DECSE
   YAMAMOTO K, 2006, P SIGGRAPH2006 US
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
   Yamamoto K, 2008, INT J AUTOM COMPUT, V5, P234, DOI 10.1007/s11633-008-0234-5
NR 33
TC 23
Z9 28
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 377
EP 391
DI 10.1016/j.jvcir.2010.03.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600002
DA 2024-07-18
ER

PT J
AU Krommweh, J
AF Krommweh, Jens
TI Tetrolet transform: A new adaptive Haar wavelet algorithm for sparse
   image representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive wavelet transform; Directional wavelets; Haar-type wavelets;
   Locally orthonormal wavelet basis; Tetromino tiling; Image
   approximation; Data compression; Sparse representation
AB In order to get an efficient image representation we introduce a new adaptive Haar wavelet transform, called Tetrolet Transform. Tetrolets are Haar-type wavelets whose supports are tetrominoes which are shapes made by connecting four equal-sized squares. The corresponding fast filter bank algorithm is simple but very effective. In every level of the filter bank algorithm we divide the low-pass image into 4 x 4 blocks. Then in each block we determine a local tetrolet basis which is adapted to the image geometry in this block. An analysis of the adaptivity costs leads to modified versions of our method. Numerical results show the strong efficiency of the tetrolet transform for image approximation. (C) 2010 Elsevier Inc. All rights reserved.
C1 Univ Duisburg Essen, Dept Math, D-47048 Duisburg, Germany.
C3 University of Duisburg Essen
RP Krommweh, J (corresponding author), Univ Duisburg Essen, Dept Math, Campus Duisburg, D-47048 Duisburg, Germany.
EM jens.krommweh@uni-due.de
FU Deutsche Forschungsgemeinschaft (DFG) [PL 170/11-2]
FX The author thank the referees for their suggestions which substantially
   improved this paper. The research in this paper is funded by the project
   PL 170/11-2 of the Deutsche Forschungsgemeinschaft (DFG). This is
   gratefully acknowledged. Furthermore, the author thank his advisor
   Gerlind Plonka for her helpful instructions and permanent support as
   well as Stefanie Tenorth and Michael Wozniczka for valuable comments.
CR Breukelaar R, 2004, INT J COMPUT GEOM AP, V14, P41, DOI 10.1142/S0218195904001354
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Chang CL, 2007, IEEE T IMAGE PROCESS, V16, P1289, DOI 10.1109/TIP.2007.894242
   Ding WP, 2007, IEEE T IMAGE PROCESS, V16, P416, DOI 10.1109/TIP.2006.888341
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Friedrich F, 2007, SIAM J SCI COMPUT, V29, P842, DOI 10.1137/050646597
   FUHR H, 2006, DOCUMENT IMAGE COMPR
   Golomb S.W., 1994, Polyominoes, DOI DOI 10.1515/9780691215051
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Korn M., 2004, THESIS MIT
   Krommweh J, 2010, SIGNAL PROCESS, V90, P2529, DOI 10.1016/j.sigpro.2010.02.022
   Larsson B., 1937, FAIRY CHESS REV, V3, P51
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Mallat S, 2009, APPL COMPUT HARMON A, V26, P161, DOI 10.1016/j.acha.2008.03.004
   Plonka G, 2009, MULTISCALE MODEL SIM, V7, P1474, DOI 10.1137/080719248
   Velisavljevic V, 2006, IEEE T IMAGE PROCESS, V15, P1916, DOI 10.1109/TIP.2006.877076
NR 17
TC 99
Z9 123
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 364
EP 374
DI 10.1016/j.jvcir.2010.02.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zheng, WL
   Bhandarkar, SM
AF Zheng, Wenlong
   Bhandarkar, Suchendra M.
TI Face detection and tracking using a Boosted Adaptive Particle Filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive Particle Filter; Particle filter; Face detection; Video
   tracking; Image analysis; Boosted learning; Boosted Adaptive Particle
   Filter; Adaptive Learning Constraint
AB A novel algorithm, termed a Boosted Adaptive Particle Filter (BAPF), for integrated face detection and face tracking is proposed. The proposed algorithm is based on the synthesis of an adaptive particle filtering algorithm and the AdaBoost face detection algorithm. An Adaptive Particle Filter (APF), based on a new sampling technique, is proposed. The APF is shown to yield more accurate estimates of the proposal distribution and the posterior distribution than the standard Particle Filter thus enabling more accurate tracking in video sequences. In the proposed BAPF algorithm, the AclaBoost algorithm is used to detect faces in input image frames, whereas the APF algorithm is designed to track faces in video sequences. The proposed BAPF algorithm is employed for face detection, face verification, and face tracking in video sequences. Experimental results show that the proposed BAPF algorithm provides a means for robust face detection and accurate face tracking under various tracking scenarios. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Zheng, Wenlong] NW Missouri State Univ, Dept Informat Syst, Maryville, MO 64468 USA.
   [Bhandarkar, Suchendra M.] Univ Georgia, Dept Comp Sci, Athens, GA 30602 USA.
C3 University System of Georgia; University of Georgia
RP Zheng, WL (corresponding author), NW Missouri State Univ, Dept Informat Syst, 800 Univ Dr, Maryville, MO 64468 USA.
EM zheng@nwmissouri.edu; suchi@cs.uga.edu
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], THESIS CARNEGIE MELL
   [Anonymous], 2001, IEEE COMP SOC C COMP
   BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   Blake A., 1998, ACTIVE CONTOURS
   BORG M, 2005, IEEE INT C ADV VID S, P17
   Chang C., 2005, P IEEE C COMP VIS PA
   Curran K, 2005, IMAGING SCI J, V53, P105, DOI 10.1179/136821905X43954
   Davison A.J., 1998, P 5 EUR C COMP VIS F
   Doucet A, 2001, IEEE T SIGNAL PROCES, V49, P613, DOI 10.1109/78.905890
   HANSEN DW, 2005, IEEE C ADV VID SIGN, P111
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Isard M. A., 1998, THESIS U OXFORD OXFO
   Jebara T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P128, DOI 10.1109/ICCV.1998.710710
   Jiang J. L., 2003, P IEEE C COMP VIS PA
   KOLLER D, 1994, EUR C COMP VIS, P189
   Lepetit V, 2004, PROC CVPR IEEE, P244
   Li PH, 2003, IMAGE VISION COMPUT, V21, P111, DOI 10.1016/S0262-8856(02)00133-6
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   LUO X, 2005, IEEE INT C ADV VID S, P123
   LUOKEPOHI H, 1993, INTRO MULTIPLE TIME
   MacCormick J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390, DOI 10.1109/ICCV.1998.710748
   MACCORMICK J, 2000, THESIS U OXFORD OXFO
   MALIK S, 2002, P VIS INT CALG ALB C, P399
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Papoulis A., 1990, Probability Statistics
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   RATHI Y, 2005, P IEEE C COMP VIS PA
   Rehg J.M., 1994, Proceeding 3rd European Conf on Computer Vision, P35
   Reynard D., 1996, Proceedings of the 4th European Conference on Computer Vision, London, UK, P357
   Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075
   RUCKLIDGE WJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P457, DOI 10.1109/ICCV.1995.466904
   Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586
   Shih P., 2004, P 17 INT C PATT REC
   Terzopoulos D., 1993, ACTIVE VISION, V1, P3
   Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824
   VIOLA P, 2001, P IEEE ICCV WORKSH S
   WANG HL, 2005, P IEEE C COMP VIS PA
NR 45
TC 22
Z9 23
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 9
EP 27
DI 10.1016/j.jvcir.2008.09.001
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700002
DA 2024-07-18
ER

PT J
AU Macedonas, A
   Besiris, D
   Economou, G
   Fotopoulos, S
AF Macedonas, A.
   Besiris, D.
   Economou, G.
   Fotopoulos, S.
TI Dictionary based color image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image retrieval; Data compression; Sequence analysis; Dictionary;
   Similarity metric; Kolmogorov complexity; Information theory; Histogram
   Intersection; Earth Movers Distance; Wald-Wolfowitz Test
AB In this work the normalized dictionary distance (NDD) is presented and investigated. NDD is a similarity metric based on the dictionary of a sequence acquired from a data compressor. A dictionary gives significant information about the structure of the sequence it has been extracted from. We examine the performance of this new distance measure for color image retrieval tasks, by focusing on three parameters: the transformation of the 2D image to a 1D string, the color to character correspondence, and the image size. We demonstrate that NDD can outperform standard (dis)similarity measures based on color histograms or color distributions. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Macedonas, A.; Besiris, D.; Economou, G.; Fotopoulos, S.] Univ Patras, Dept Phys, Elect Lab, Rion 26500, Greece.
C3 University of Patras
RP Fotopoulos, S (corresponding author), Univ Patras, Dept Phys, Elect Lab, Rion 26500, Greece.
EM spiros@physics.upatras.gr
OI Economou, George/0000-0001-9938-0768
FU General Secretary of Research and Technology of the Greek Ministry
   [PENED 2003]
FX This work was financially supported by the General Secretary of Research
   and Technology of the Greek Ministry under project PENED 2003.
CR [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], CLUSTERING IMAGES US
   Benedetto D, 2002, PHYS REV LETT, V88, DOI 10.1103/PhysRevLett.88.048702
   Bennett CH, 1998, IEEE T INFORM THEORY, V44, P1407, DOI 10.1109/18.681318
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Cebrian M, 2005, COMMUN INF SYST, V5, P367
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   *COR CORP, COR STOCK PHOT LIB
   FRANK E, 2000, IEEE DAT COMPR C, P200
   GASIENIEC L, 1999, DAT COMPR C P
   Keogh E. J., 2004, KDD, P206, DOI [DOI 10.1145/1014052.1014077, 10.1145/1014052.1014077]
   Li M, 2004, IEEE T INFORM THEORY, V50, P3250, DOI 10.1109/TIT.2004.838101
   LI M, 2006, LECT NOTES COMPUT SC, P704
   PASS G, 1996, P ACM INT MULT C EXH
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   Rubner Y., 2001, Perceptual metrics for image database navigation
   SCULLEY D, 2006, IEEE P DAT COMPR C
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Theoharatos C, 2005, IEEE T KNOWL DATA EN, V17, P808, DOI 10.1109/TKDE.2005.85
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   [No title captured]
   [No title captured]
NR 22
TC 23
Z9 24
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2008
VL 19
IS 7
BP 464
EP 470
DI 10.1016/j.jvcir.2008.06.006
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 363NU
UT WOS:000260274800005
DA 2024-07-18
ER

PT J
AU Money, AG
   Agius, H
AF Money, Arthur G.
   Agius, Harry
TI Video summarisation: A conceptual framework and survey of the state of
   the art
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video summaries; video summarisation; video content; survey; conceptual
   framework; user based information; contextual information
ID SCENE DETECTION; EXTRACTION; HIGHLIGHTS; CONTEXT; MPEG-7; AUDIO; MODEL
AB Video summaries provide condensed and succinct representations of the content of a video stream through a combination of still images, video segments, graphical representations and textual descriptors. This paper presents a conceptual framework for video summarisation derived from the research literature and used as a means for surveying the research literature. The framework distinguishes between video summarisation techniques (the methods used to process content from a source video stream to achieve a summarisation of that stream) and video summaries (outputs of video summarisation techniques). Video summarisation techniques are considered within three broad categories: internal (analyse information sourced directly from the video stream), external (analyse information not sourced directly from the video stream) and hybrid (analyse a combination of internal and external information). Video summaries are considered as a function of the type of content they are derived from (object, event, perception or feature based) and the functionality offered to the user for their consumption (interactive or static, personalised or generic). It is argued that video summarisation would benefit from greater incorporation of external information, particularly user based information that is unobtrusively sourced, in order to overcome longstanding challenges such as the semantic gap and providing video summaries that have greater relevance to individual users. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Money, Arthur G.; Agius, Harry] Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
C3 Brunel University
RP Agius, H (corresponding author), Brunel Univ, Sch Informat Syst Comp & Math, Uxbridge UB8 3PH, Middx, England.
EM harryagius@acni.org
OI Money, Arthur/0000-0003-1063-3680
CR AGNIHOTRI L, 2004, P IEEE INT C MULT EX, V3, P1943
   AGNIHOTRI L, 2005, P 7 ACM INT WORKSH M
   Aizawa K, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P398, DOI 10.1109/ICIP.2001.958135
   Aizawa Kiyoharu., 2004, CARPE 04 P THE 1 ACM, P22, DOI DOI 10.1145/1026653.1026656
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   BABAGUCHI N, 2001, P IEEE INT C MULT EX, P800
   Barbieri M, 2003, PROC SPIE, V5242, P1, DOI 10.1117/12.515733
   BENJAMAS N, 2005, P IEEE INT S COMM IN, V1, P441
   Bezerra F., 2006, PROC 8 ACM INT WORKS, P71
   Boyatzis R.E., 1998, TRANSFORMING QUALITA
   Cai R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P37
   Cerneková Z, 2006, IEEE T CIRC SYST VID, V16, P82, DOI 10.1109/TCSVT.2005.856896
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Chang SF, 2002, IEEE MULTIMEDIA, V9, P6, DOI 10.1109/93.998041
   CHEATLE P, 2004, P IEEE 17 INT C PATT, V4, P979
   CHENG W, 2003, P 2 IEEE INT C MACH, V5, P2896
   CIOCCA G, 2006, P 8 ACM SIGMM INT WO
   Coldefy F, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P163
   Crockford C, 2006, INT J HUM-COMPUT ST, V64, P340, DOI 10.1016/j.ijhcs.2005.08.012
   Davis Marc., 2004, P 12 ANN ACM INT C M, P188, DOI DOI 10.1145/1027527.1027572
   de Silva G. C., 2005, 13th Annual ACM International Conference on Multimedia, P820, DOI 10.1145/1101149.1101329
   Dey I., 2003, Qualitative data analysis: A user-friendly guide for social scientists, DOI DOI 10.4324/9780203412497
   Dimitrova N, 2004, IEEE MULTIMEDIA, V11, P7, DOI 10.1109/MMUL.2004.6
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Fayzullin M, 2005, MULTIMED TOOLS APPL, V26, P153, DOI 10.1007/s11042-005-0451-7
   FAYZULLIN M, 2004, P 2 ACM INT WORKSH M, P28, DOI DOI 10.1145/1032604.1032611
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Girgensohn A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P77
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   Hanjalic A, 2003, IEEE IMAGE PROC, P1
   HAUBOLD A, 2005, P 13 ANN ACM INT C M, P51, DOI DOI 10.1145/1101149.1101158
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Jaimes A, 2002, IEEE IMAGE PROC, P133
   Joffe H., 2004, RES METHODS CLIN HLT, P56, DOI [DOI 10.4135/9781849209793, 10.4135/9781849209793]
   JUNG B, 2004, P 12 ANN ACM INT C M
   Kang H.-B., 2003, Proceedings of the 11th ACM International Conference on Multimedia, P259
   KIM J, 2004, J IMAGING SYSTEMS TE, V13, P267
   Kopf S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2067, DOI 10.1109/ICME.2004.1394672
   Lee JH, 2003, IEEE T CONSUM ELECTR, V49, P742, DOI 10.1109/TCE.2003.1233813
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Liang CH, 2004, 2004 47TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL I, CONFERENCE PROCEEDINGS, P297
   Lienhart R, 2000, PROC SPIE, V3972, P378
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Lienhart R., 1999, ACM MULTIMEDIA, P37, DOI DOI 10.1145/319878.319888
   Lin CY, 2005, IEEE INT SYMP CIRC S, P1250
   Lu S, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P197
   Luo B, 2003, IEEE IMAGE PROC, P297
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   MEI T, 2005, P 13 ANN ACM INT C M
   MORIYAMA T, 2002, SYSTEMS COMPUTERS JA, V33, P1122
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   *NIST, DRAFT GUID TRECVID 2
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   PINZON J, 2005, P IASTED INT C HUM C
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   Rui Y, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P735, DOI 10.1109/MMCS.1999.778576
   SHAO X, 2003, P IEEE INT C IM PROC, V3, P547
   Shih HC, 2005, IEEE T BROADCAST, V51, P449, DOI 10.1109/TBC.2005.854169
   SHIPMAN F, 2003, P IEEE INT C MULT EX, V3, P753
   Silverman D., 2013, DOING QUALITATIVE RE, DOI DOI 10.3917/DS.293.0349
   Smith MA, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P61, DOI 10.1109/CAIVD.1998.646034
   Sugano M, 2002, IEEE IMAGE PROC, P956
   Sundaram Hari., 2002, COMUNICA O APRESENTA, DOI [DOI 10.1145/641007.641042, 10.1145/641007.641042]
   Syeda-Mahmood T., 2001, PROC ACM MULITMEDIA, V9, P119, DOI DOI 10.1145/500141.500161
   Takahashi Y, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1171
   Taylor SJ., 1984, INTRO QUALITATIVE RE
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   TJONDRONEGORO DW, 2003, P IEEE INT C MULT EX, V1, P579
   Tseng BL, 2003, P SOC PHOTO-OPT INS, V5242, P14, DOI 10.1117/12.512987
   Tseng BL, 2004, IEEE MULTIMEDIA, V11, P42, DOI 10.1109/MMUL.2004.1261105
   Tseng BL, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P5
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   WU Y, 2004, P 6 IEEE INT S MULT, P302
   XU C, 2006, P 14 ANN ACM INT C M
   Xu M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P281
   Yang Hui, 2003, P 11 ACM INT C MULT, P632, DOI DOI 10.1145/957013.957146
   YU B, 2003, P 11 ACM INT C MULT, P382
   Yu JCS, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P329
   Zhang D., 2002, ACM Multimedia, P315
   ZHU X, 2003, P IEEE INT C MULT EX, V3, P333
   Zhu XQ, 2004, MULTIMEDIA SYST, V10, P98, DOI 10.1007/s00530-004-0142-7
   ZIMMERMAN J, 2003, P INTERACT IFIP INT
NR 87
TC 289
Z9 308
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2008
VL 19
IS 2
BP 121
EP 143
DI 10.1016/j.jvcir.2007.04.002
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 264MD
UT WOS:000253290600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chan, TF
   Esedoglu, S
   Park, FE
AF Chan, Tony F.
   Esedoglu, Selim
   Park, Frederick E.
TI Image decomposition combining staircase reduction and texture extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image decomposition; denoising; texture; staircase reduction; dual
   methods; oscillating pattern
ID TOTAL VARIATION MINIMIZATION; NOISE REMOVAL
AB This paper proposes a natural and efficient way to achieve staircase reduction in texture extraction models of image processing. Moreover, we propose a precise framework for this amalgamation. In a sense, we utilize the best of both worlds: (I) the use of higher order derivatives through a variant of the Chambolle-Lions inf convolution energy (an image decomposition model in itself) along with (II) approximations to Meyer's G and E norms including the H-1 negative norm for ameliorating staircasing in image decomposition and restoration problems. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Chan, Tony F.; Esedoglu, Selim; Park, Frederick E.] Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA.
C3 University of California System; University of California Los Angeles
RP Park, FE (corresponding author), Univ Calif Los Angeles, Dept Math, 405 Hilgard Ave, Los Angeles, CA 90095 USA.
EM chan@math.ucla.edu; esedoglu@math.ucla.edu; fpark@math.ucla.edu
RI Chan, Tony/IQW-1869-2023; Chan, Tony F/A-4166-2013
OI Chan, Tony F/0000-0001-6196-2068
CR Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   AUJOL JF, 2003, 4704 RR INRIA
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   BLOMGREN P, 1997, P IEEE INT C IM PROC, V3, P384
   CARTER JL, 2001, THESIS UCLA
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   Chan TF, 1998, SIAM J SCI COMPUT, V20, P568, DOI 10.1137/S1064827596311554
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   CHAN TF, 2004, 0415 UCLA CAM
   Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045
   LEVINE S, 2005, 0501 DUQ U DEP MATH
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Meyer Y., 2001, Memoirs of the American Mathematical Society
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Starck JL, 2003, PROC SPIE, V5207, P571, DOI 10.1117/12.507447
   Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448
   Vese LA, 2004, J MATH IMAGING VIS, V20, P7, DOI 10.1023/B:JMIV.0000011316.54027.6a
NR 21
TC 89
Z9 95
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2007
VL 18
IS 6
BP 464
EP 486
DI 10.1016/j.jvcir.2006.12.004
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 243NA
UT WOS:000251803400002
DA 2024-07-18
ER

PT J
AU Trentacoste, M
   Heidrich, W
   Whitehead, L
   Seetzen, H
   Ward, G
AF Trentacoste, Matthew
   Heidrich, Wolfgang
   Whitehead, Lorne
   Seetzen, Helge
   Ward, Greg
TI Photometric image processing for high dynamic range displays
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE high dynamic range; displays; image processing; photometry
AB Many real-world scenes contain brightness levels exceeding the capabilities of conventional display technology by several orders of magnitude. Through the combination of several existing technologies, new high dynamic range displays have been constructed recently. These displays are capable of reproducing a range of intensities much closer to that of real environments. We present several methods of reproducing photometrically accurate images on this new class of devices, and evaluate these methods in a perceptual framework. (C) 2007 Elsevier Inc. All rights reserved.
C1 Univ British Columbia, Vancouver, BC V6T 1Z4, Canada.
   Dolby Canada, Vancouver, BC V5K 4R1, Canada.
C3 University of British Columbia; Dolby Laboratories, Inc.
RP Trentacoste, M (corresponding author), Univ British Columbia, 2329 W Mall, Vancouver, BC V6T 1Z4, Canada.
EM mmt@cs.ube.ca; heidrich@cs.ubc.ca; whitehead@physics.ubc.ca;
   helge.seetzen@dolby.com; gward@lmi.net
OI Whitehead, Lorne/0000-0002-4170-0033
CR ACOSTASERAFINI PM, 2005, Patent No. 6977685
   [Anonymous], 1975, P SID
   [Anonymous], 1997, SIGGRAPH, DOI DOI 10.1145/258734.258884
   Chiu K., 1993, Proceedings Graphics Interface '93, P245
   *LUM, 2005, IQCAM IM PHOT
   Mantiuk R, 2004, IEEE SYS MAN CYBERN, P2763
   Mantiuk R, 2004, ACM T GRAPHIC, V23, P733, DOI 10.1145/1015706.1015794
   Mantiuk R, 2006, ACM T GRAPHIC, V25, P713, DOI 10.1145/1141911.1141946
   MOON P, 1945, J OPT SOC AM, V35, P233, DOI 10.1364/JOSA.35.000233
   MOON P, 1944, J OPTICAL SOC AM, V34
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Robertson M.A., 1999, PROCEEDING ICIP, P159
   Seetzen H, 2004, ACM T GRAPHIC, V23, P760, DOI 10.1145/1015706.1015797
   SEETZEN H, 2003, SID03, P1450
   TRENTACOSTE M, 2006, THESIS U BRIT COLUMB
   WARD G, 2004, APGV 04, P83
   WARD G, 2002, P PICS
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
NR 18
TC 16
Z9 24
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 439
EP 451
DI 10.1016/j.jvcir.2007.06.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mayster, Y
   Lopez, MA
AF Mayster, Yan
   Lopez, Mario A.
TI Approximating a set of points by a step function
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE combinatorial optimization; visual data reduction; curve fitting;
   approximation algorithms
ID POLYGONAL CURVES
AB Let S be a set of n points in the plane. We derive algorithms for approximating S by a step function of size k < n, i.e., by an x-monotone rectilinear polyline R with k < it horizontal segments. We use the vertical distance to measure the quality of the approximation, i.e., the maximum distance from a point in S to the horizontal segment directly above or below it. We consider two types of problems: min-epsilon, where the goal is to minimize the error for a given number of horizontal segments k and min-#, where the goal is to minimize the number of segments for a given allowed error epsilon. After O(n) preprocessing time, we solve instances of the latter in O(min{k log n,n}) time per instance. We can then solve the former problem in O(min{n(2), nklogn}) time. Both algorithms require O(n) space. Our second contribution is an approximation algorithm for the min-epsilon problem that computes a solution within a factor of 3 of the optimal error for k segments, or with at most the same error as the k-optimal but using 2k - 1 segments. Furthermore, experiments on real data show even better results than what is guaranteed by the theoretical bounds. Both approximations run in O(n log n) time and O(n) space. (C) 2006 Elsevier Inc. All rights reserved.
C1 Univ Denver, Dept Comp Sci, Denver, CO 80208 USA.
C3 University of Denver
RP Lopez, MA (corresponding author), Univ Denver, Dept Comp Sci, 2360 S Gaylord St, Denver, CO 80208 USA.
EM ymayster@cs.du.edu; mlopez@cs.du.edu
CR Barequet G, 2002, ALGORITHMICA, V33, P150, DOI 10.1007/s00453-001-0096-5
   Chan WS, 1996, INT J COMPUT GEOM AP, V6, P59, DOI 10.1142/S0218195996000058
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Díaz-Báñez JM, 2000, INFORMS J COMPUT, V12, P317, DOI 10.1287/ijoc.12.4.317.11880
   Díaz-Báñez JM, 2001, EUR J OPER RES, V130, P214, DOI 10.1016/S0377-2217(00)00023-0
   EU D, 1994, CVGIP-GRAPH MODEL IM, V56, P231, DOI 10.1006/cgip.1994.1021
   GOODRICH MT, 1994, SCG 94 P 10 ANN S CO, P322
   HAKIMI SL, 1991, CVGIP-GRAPH MODEL IM, V53, P132, DOI 10.1016/1049-9652(91)90056-P
   Imai H., 1986, Journal of Information Processing, V9, P159
   IMAI H, 1986, COMPUT VISION GRAPH, V36, P31, DOI 10.1016/S0734-189X(86)80027-5
   Melkman A., 1988, COMPUTATIONAL MORPHO, P87, DOI [10.1016/B978-0-444-70467-2.50012-6, DOI 10.1016/B978-0-444-70467-2.50012-6]
   Toussaint G.T, 1988, MACHINE INTELLIGENCE, V6, P71
   VARADARAJAN KR, 1996, SGC 94 P 12 ANN S CO, P311
   Wang DP, 2002, PATTERN RECOGN LETT, V23, P329, DOI 10.1016/S0167-8655(01)00130-1
   WANG DP, 1993, INT S ALGORITHMS COM, P515
NR 15
TC 9
Z9 10
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1178
EP 1189
DI 10.1016/j.jvcir.2006.04.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200004
DA 2024-07-18
ER

PT J
AU Terol-Villalobos, IR
   Mendiola-Santibáñez, JD
   Canchola-Magdaleno, SL
AF Terol-Villalobos, Ivan R.
   Mendiola-Santibanez, Jorge D.
   Canchola-Magdaleno, Sandra L.
TI Image segmentation and filtering based on transformations with
   reconstruction criteria
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE reconstruction filters; transformations with reconstruction criteria;
   markers; image segmentation; image filtering
AB In this paper, a class of transformations with reconstruction criteria, derived from the reconstruction transformations, is investigated. The idea to build these transformations consists in stopping the reconstruction process according to a size criterion. This class of transformations was initially proposed for obtaining intermediate results between the morphological opening and the opening by reconstruction. Here, the transformations are presented in the general case, as in the reconstruction transformations case, by imposing some conditions on the marker. We show that the set of markers for the transformations with reconstruction criteria is given by the set of dilated images. The interest of these transformations in image segmentation is shown, and in particular, the form of selecting the markers for segmenting images is described for binary images. Also, the use of the opening and closing with reconstruction criteria to build other morphological tools is illustrated to show the performance of these transformations. In particular, the notion of granulometry and the alternating sequential filters using openings and closings with reconstruction criteria are investigated. (c) 2005 Elsevier Inc. All rights reserved.
C1 CIDETEQ SC, Escobedo 76700, Queretaro, Mexico.
C3 CIDETEQ - Centro de Investigacion & Desarrollo Tecnologico en
   Electroquimica S.C.
RP Terol-Villalobos, IR (corresponding author), CIDETEQ SC, Parque Tecnol Queretaro SN, Escobedo 76700, Queretaro, Mexico.
EM famter@ciateq.net.mx
RI Canchola Magdaleno, Sandra Luz/M-9230-2018; cai, bo/G-1491-2010;
   Mendiola, Jorge/AAB-6054-2020
OI Canchola Magdaleno, Sandra Luz/0000-0002-7497-281X; Mendiola,
   Jorge/0000-0002-9173-0732
CR [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 1994, Morphological Image Operators
   Beucher S, 1998, COMP IMAG VIS, V12, P307
   Beucher S, 1994, COMP IMAG VIS, V2, P69
   CANCHOLAMAGDELE.S, 2002, AVANCES CIENCIAS COM, P389
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Matheron G., 1975, Random sets and integral geometry
   Meyer F, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P69
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Salembier P, 1996, COMP IMAG VIS, P97
   SALEMBIER P, 1992, SPIE VISUAL COMMUNIC, P620
   Serra J, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P79
   Serra J, 1998, COMP IMAG VIS, V12, P107
   Serra J., 1988, IMAGE ANAL MATH MORP
   SVALBE I, 1995, IEEE WORKSH NON SIGN, P464
   Terol-Villalobos IR, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P413
   Terol-Villalobos IR, 2003, LECT NOTES COMPUT SC, V2756, P361
   Tzafestas CS, 2002, J MATH IMAGING VIS, V17, P109, DOI 10.1023/A:1020629402912
   VARGASVAZQUZ D, 2003, INT C IM PROC, P620
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
NR 22
TC 10
Z9 11
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 107
EP 130
DI 10.1016/j.jvcir.2005.01.001
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900007
DA 2024-07-18
ER

PT J
AU Gao, K
   Gao, W
   He, SM
   Zhang, YA
AF Gao, K
   Gao, W
   He, SM
   Zhang, YA
TI Real-time smoothing for network adaptive video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE real-time scheduling; scalable streaming; fine granularity scalable;
   smoothing; network adaptive
AB Real-time streaming delivery over the Internet with bandwidth variation is a very challenging task. It is important to smooth the quality variability and improve the utilization of the available network bandwidth. In this paper, we propose a real-time optimal smoothing scheduling algorithm for network adaptive video streaming with the variable network bandwidth and packet loss. The algorithm adopts a rate-distortion optimized framework and real-time scheduling scheme to select and schedule the packets according to the network status. It attempts to minimize the quality variability at the client end while at the same time maximizing the utilization of the variable network bandwidth. Experiments show that, compared with frame-based scheduling algorithm, our proposed real-time smoothing algorithm improves and smoothes the quality in decoded video frames. (c) 2005 Elsevier Inc. All rights reserved.
C1 Chinese Acad Sci, Comp Technol Inst, Beijing 100080, Peoples R China.
   Chinese Acad Sci, Grad Sch, Beijing 100039, Peoples R China.
   Beijing Braodcasting Inst, Beijing 100024, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Communication University of China
RP Gao, K (corresponding author), Chinese Acad Sci, Comp Technol Inst, Beijing 100080, Peoples R China.
EM kgao@jdl.ac.cn; wgao@jdl.ac.cn; smhe@jdl.ac.cn; yzhang@jdl.ac.cn
CR Buttazzo G., 1997, HARD REAL TIME COMPU
   CAI H, 2002, P IEEE INT S CIRC SY
   CHOU PA, UNPUB IEEE T MULTIME
   DAI M, 2003, P IEEE INT C IM PROC
   Floyd S., 2000, P ACM SIGCOMM
   Gao K, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P824
   GAO K, 2003, P SPIE VIS COMM IM P
   GRINGERI S, 1999, ACM MULT 199 EL P
   Grossglauser M, 1997, IEEE ACM T NETWORK, V5, P741, DOI 10.1109/90.650136
   KIM T., 2003, P IEEE INFOCOM
   KIM T, 2001, P NETW OP SYST SUPP
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Li WP, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL I, P299, DOI 10.1109/ISCAS.2000.857089
   LI X, 1998, P INFOCOM
   LIU CL, 1973, J ACM, V20, P46, DOI 10.1145/321738.321743
   Miao Z., 2002, P INT PACK VID WORKS
   *MPEG4, 2000, 144962FPDAM4 ISOIEC
   *MPEG4 ISO IEC, 2002, 1449652001FDAM1 MPEG
   NELAKUDITI S, 2000, P NETW OP SYST SUPP
   Podolsky MG, 2001, J VLSI SIG PROC SYST, V27, P81, DOI 10.1023/A:1008123631453
   Radha HM, 2001, IEEE T MULTIMEDIA, V3, P53, DOI 10.1109/6046.966110
   Salehi JD, 1998, IEEE ACM T NETWORK, V6, P397, DOI [10.1109/90.720873, 10.1142/S0218213097000219]
   SAPARILLA D, 2000, P IEEE INFOCOM
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   YEE JR, 1995, IEEE T COMMUN, V43, P2316, DOI 10.1109/26.403764
NR 26
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 512
EP 526
DI 10.1016/j.jvcir.2004.12.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600008
DA 2024-07-18
ER

PT J
AU Ramachandran, G
   Krishnan, V
   Wu, DP
   He, ZH
AF Ramachandran, G
   Krishnan, V
   Wu, DP
   He, ZH
TI A model-based adaptive motion estimation scheme using Renyi's entropy
   for wireless video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE adaptive motion estimation; Renyi's entropy; wireless video; model-based
   motion estimation; very low complexity
AB Efficient motion estimation is an important problem because it determines the compression efficiency and complexity of a video encoder. Motion estimation can be formulated as an optimization problem; most motion estimation algorithms use mean squared error, sum of absolute differences or maximum a posteriori probability as the optimization criterion and apply search-based techniques (e.g., exhaustive search or three-step search) to find the optimum motion vector. However, most of these algorithms do not effectively utilize the knowledge gained in the search process for future search efforts and hence are computationally inefficient. This paper addresses this inefficiency problem by introducing an adaptive motion estimation scheme that substantially reduces computational complexity while yet providing comparable compression efficiency, as compared to existing fast-search methods. Our approach is motivated by the recent developments in using Renyi's entropy as the optimization criterion for system modeling [D. Erdogmus, J. Principe.. Comparison of entropy and mean square error criteria in adaptive system training using higher order, in: Proceedings of the International Workshop on Independent Component Analysis and Signal Separation, Helsinki, Finland, 2000, pp. 75-80]. This scheme is particularly suited for wireless video sensor networks, video conferencing systems and live streaming videos which have stringent computational requirements. Our results show that our scheme reduces the computational complexity by a factor of 9-21, compared to the existing fast algorithms. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
   Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65203 USA.
C3 State University System of Florida; University of Florida; University of
   Missouri System; University of Missouri Columbia
RP Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
EM rgancsan@ufl.edu; vigneshk@ufl.edu; wu@ece.ufl.edu; HeZhi@missouri.edu
RI He, Zhihai/A-5885-2019
OI Wu, Dapeng/0000-0003-1755-0183
CR Al-Mualla M.E., 2002, VIDEO CODING MOBILE
   [Anonymous], 2007, Probability theory
   [Anonymous], 109181 ISOIEC IS
   [Anonymous], P SPIE C VIS COMM IM
   Chen YS, 2001, IEEE T IMAGE PROCESS, V10, P1212, DOI 10.1109/83.935037
   Erdogmus D, 2002, IEEE T NEURAL NETWOR, V13, P1035, DOI 10.1109/TNN.2002.1031936
   ERDOGMUS D, 2001, P ICA CA, P7
   ERDOGMUS D, 2000, P 2 INT WORKSH IND C, P75
   Haykin S. O., 2001, ADAPTIVE FILTER THEO
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   KOGA T, 1981, P NTC NEW ORL LA
   LAI MP, 1996, IEEE T CIRCUITS SYST, V6, P313
   LI R, 1994, NEW 3 STEP SEARCH AL, V4, P438
   LI W, 1995, SUCCESSIVE ELIMINATI, V4, P105
   Liu B, 1993, IEEE T CIRC SYST VID, V3, P148, DOI 10.1109/76.212720
   LURNGKUO L, 1996, BLOCK BASED GRADIENT, V6, P419
   NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087
   Parzen E., 1967, TIME SERIES ANAL PAP
   SONG BC, 1998, SPIE VISUAL COMMUNIC, P88
   Stiller C, 1999, IEEE SIGNAL PROC MAG, V16, P70, DOI 10.1109/79.774934
   Wang Y., 2001, VIDEO PROCESSING COM
   Yeh J., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P574, DOI 10.1109/ICIP.1995.531431
NR 22
TC 1
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 432
EP 449
DI 10.1016/j.jvcir.2004.11.007
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600004
DA 2024-07-18
ER

PT J
AU Li, BX
   Errico, JH
   Pan, H
   Sezan, I
AF Li, BX
   Errico, JH
   Pan, H
   Sezan, I
TI Bridging the semantic gap in sports video retrieval and summarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE semantic video analysis; video summarization; event detection
AB One of the major challenges facing current media management systems and related applications is the so-called "semantic gap" between the rich meaning that a user desires and the shallowness of the content descriptions that are automatically extracted from the media. In this paper, we address the problem of bridging this gap in the sports domain. We propose a general framework for indexing and summarizing sports broadcast programs, with a high-level model of sports broadcast video using the concept of an event, defined according to domain-specific knowledge for different types of sports. Within this general framework, we develop automatic event detection algorithms that are based on automatic analysis of the visual and aural signals in the media. We have successfully applied the event detection algorithms to different types of sports including American football, baseball, Japanese sumo wrestling, and soccer. Event modeling and detection contribute to the reduction of the semantic gap by providing rudimentary semantic information obtained through media analysis. We further propose a novel approach, which makes use of independently generated rich textual metadata, to fill the gap completely through synchronization of the information-laden textual data with the basic event segments. We implemented an MPEG-7 compliant browsing system for semantic retrieval and summarization of sports video using the proposed algorithms. (C) 2004 Elsevier Inc. All rights reserved.
C1 Sharp Labs Amer, Camas, WA 98607 USA.
C3 Hisense
RP Sharp Labs Amer, 5750 NW Pacific Rim Blvd, Camas, WA 98607 USA.
EM Baoxin.Li@ieee.org
CR [Anonymous], P IEEE ICASSP 2002
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   BABAGUCHI N, 2000, P ACM MULT 2000 WORK, P205
   BORECZKY S, 1998, P IEEE INT C AC SPEE
   CHOI S, 1997, INT C IM AN PROC FLO, P197
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   EICKELER S, 1999, P IEEE INT C AC SPEE
   EKIN A, 2003, INT C IMAGE PROCESSI
   EKIN A, 2002, VISUAL COM IMAGE PRO
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   GOLIN SJ, 1999, P IS T SPIE C VIS CO
   GONG Y, 1995, IEEE INT C MULT COMP, P167
   KAWASHIMA T, 1998, P IEEE INT C IM PROC
   Leonardi R, 2002, IEEE MULTIMEDIA, V9, P44, DOI 10.1109/93.998057
   LI B, 2001, IEEE C COMP VIS PATT
   LI B, 2001, P IEEE WORKSH CON BA
   Li BX, 2002, P SOC PHOTO-OPT INS, V4676, P202
   LIENHART R, 1999, P IS T SPIE C VISU C
   LU HB, 1999, P IEEE INT C IM PROC
   NAPHADE MR, 1998, P IEEE INT C IM PROC
   PAN H, 2001, P IEEE INT C AC SPEE
   RUI Y, 2000, P ACM MULT 2000
   Saur DD, 1997, P SOC PHOTO-OPT INS, V3022, P176, DOI 10.1117/12.263406
   VANBEEK P, 2002, INTRO MPEG7
   WOLF M, 1907, P IEEE P IEEE INT C
   YOW D, 1995, P 2 AS C COMP VIS SI
   ZHAND D, 2002, P ACM MULT C
   ZHANG D, 2002, INT C IMAGE PROCESSI
   Zhong D., 2001, P IEEE INT C MULT EX P IEEE INT C MULT EX
NR 29
TC 27
Z9 31
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 393
EP 424
DI 10.1016/S1047-3203(04)00034-3
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100008
DA 2024-07-18
ER

PT J
AU Ahmad, I
   Grosky, WI
AF Ahmad, I
   Grosky, WI
TI Indexing and retrieval of images by spatial constraints
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE content-based retrieval; spatial similarity-based retrieval; symbolic
   image; image indexing; image database
ID KNOWLEDGE REPRESENTATION; DATABASE-SYSTEMS; DISTANCE; STRINGS; FILES
AB Many multimedia applications require retrieval of spatially similar images against a given query image. Existing work on image retrieval and indexing either requires extensive low-level computations or elaborate human interaction. In this paper, we introduce a new symbolic image representation technique to eliminate repetitive tasks of image understanding and object processing. Our symbolic image representation scheme is based on the concept of hierarchical decomposition of image space into spatial arrangements of features while preserving the spatial relationships among the image objects. Quadtrees are used to manage the decomposition hierarchy and play an important role in defining the similarity measure. This scheme is incremental in nature, can be adopted to accommodate varying levels of details in a wide range of application domains, and provides geometric variance independence. While ensuring that there are no false negatives, our approach also discriminates against non-matching entities by eliminating them as soon as possible, during the coarser matching phases. A hierarchical indexing scheme based on the concept of image signatures and efficient quadtree matching has been devised. Each level of the hierarchy tends to reduce the search space, allowing more involved comparisons only for potentially matching candidate database images. For a given query image, a facility is provided to rank-order the retrieved spatially similar images from the image database for subsequent browsing and selection by the user. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
   Univ Michigan, Dept Comp & Informat Sci, Dearborn, MI 48128 USA.
C3 University of Windsor; University of Michigan System; University of
   Michigan
RP Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
EM imran@cs.uwindsor.ca; wgrosky@umich.edu
CR Ahmad I, 1997, IDEAS '97 - INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P269, DOI 10.1109/IDEAS.1997.625690
   AHMAD I, 1997, THESIS WAYNE STATE U
   [Anonymous], IEEE COMPUT
   ASLANDOGAN YA, 1995, PROC INT CONF DATA, P280, DOI 10.1109/ICDE.1995.380383
   BIMBO AD, 1994, P IEEE S VIS LANG OC, P216
   CHANG CC, 1995, PATTERN RECOGN LETT, V16, P465, DOI 10.1016/0167-8655(95)00002-X
   Chang S. K., 1986, 1986 IEEE Computer Society Workshop on Visual Languages (Cat. No.86CH2343-2), P12
   CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923
   CHAUDHURI S, 1996, P 1996 ACM SIGMOD C, V25, P91
   FALOUTSOS C, 1984, ACM T OFF INF SYST, V2, P267, DOI 10.1145/2275.357411
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   GROSKY W, 1992, ADV COMPUT, P237
   GROSKY WI, 1995, P MULT INF SYST HYP, P7
   GUDIVADA V, 1994, TR19944 OH U DEP COM
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   GUDIVADA VN, 1995, ACM T INFORMATION SY
   Hoaglin D. C., 1983, Understanding Robust and Exploratory Data Analysis
   Hsu FJ, 1999, J VISUAL LANG COMPUT, V10, P147, DOI 10.1006/jvlc.1998.0107
   HU WC, 1997, P IEEE INT C MULT CO, P434
   HUANG PW, 1994, PATTERN RECOGN, V27, P1249, DOI 10.1016/0031-3203(94)90008-6
   JUNGERT E, 1989, VISUAL DATABASE SYST, P301
   LEE JP, 1990, EYE, V4, P1
   LEE SY, 1990, PATTERN RECOGN, V23, P1077, DOI 10.1016/0031-3203(90)90004-5
   LEE SY, 1992, J VISUAL LANG COMPUT, V3, P373
   LU SY, 1979, IEEE T PATTERN ANAL, V1, P219, DOI 10.1109/TPAMI.1979.6786615
   LU Y, 2000, P ACM MULT, P31
   MEHROTRA R, 1995, COMPUTER, V28, P57, DOI 10.1109/2.410154
   PFALTZ JL, 1980, COMMUN ACM, V23, P522, DOI 10.1145/359007.359013
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SACKSDAVIS R, 1987, ACM T DATABASE SYST, V12, P655, DOI 10.1145/32204.32222
   SAMET H, 1982, IEEE T PATTERN ANAL, V4, P298, DOI 10.1109/TPAMI.1982.4767246
   SAMET H, 1993, APPL SPATIAL DATA ST
   SMITH JR, 1996, P ACM C MULT, P211
   SMITH SM, 1995, 95SMS1C DEP CLIN NEU
   TANIMOTO SL, 1976, ICONIC SYMBOLIC DATA, P452
   Vinod VV, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, P229, DOI 10.1109/MMCS.1996.534980
   YANG MC, 1990, 2D B STRING REPRESEN
   Zhou XS, 2002, IEEE MULTIMEDIA, V9, P23, DOI 10.1109/93.998050
NR 38
TC 12
Z9 15
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 291
EP 320
DI 10.1016/S1047-3203(03)00039-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200005
DA 2024-07-18
ER

PT J
AU Wang, JQ
   Ou, B
AF Wang, Jiaqi
   Ou, Bo
TI Video reversible data hiding: A systematic review
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Reversible data hiding; Video protection; Systematic review; Embedding
   position determination; Drift distortion minimization; Security
   extension
ID FRAME ERROR CONCEALMENT; DIFFERENCE EXPANSION; WATERMARKING; HEVC;
   ALGORITHM; SCHEME; IMAGES; H.264
AB Reversible data hiding (RDH), also known as lossless data hiding, ensures the losslessly recovery of both the cover medium and the secret message at the decoder. For the video medium, RDH can also provide the effective protection and has attracted a lot of attention due to its unique reversibility. This paper aims to present a systematic review about the existing video RDH methods and the corresponding practical applications. We summarize the basic frameworks and the current optimization aspects in video RDH methods, including (1) the determination for the suitable embedding position, (2) the drift distortion minimization, (3) the extension for security improvement. Then, the fundamental trade-off for the evaluation metrics is quantified, and the performance comparison of the classical methods is given. Finally, the future research directions are discussed to exploit the further idea for this area.
C1 [Wang, Jiaqi; Ou, Bo] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
C3 Hunan University
RP Ou, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM oubo@hnu.edu.cn
FU National Science Foundation of China [61972031]; Aid program for Science
   and Technology Innovative Research Team in Higher Educational
   Institutions of Hunan Province, China
FX <B>Acknowledgments</B> This work was supported by the National Science
   Foundation of China (61972031) , and the Aid program for Science and
   Technology Innovative Research Team in Higher Educational Institutions
   of Hunan Province, China.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Bossen F., 2013, JCTVCL1100
   Cao XC, 2020, IEEE T CIRC SYST VID, V30, P2297, DOI 10.1109/TCSVT.2020.3002109
   Chang J, 2022, IEEE T CIRC SYST VID, V32, P5055, DOI 10.1109/TCSVT.2022.3146517
   Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Chang Q, 2022, IEEE T CIRC SYST VID, V32, P5725, DOI 10.1109/TCSVT.2022.3153796
   Chen YL, 2018, IEEE ACCESS, V6, P77004, DOI 10.1109/ACCESS.2018.2879338
   Chen YL, 2022, IEEE ACCESS, V10, P699, DOI 10.1109/ACCESS.2021.3137398
   Chen YL, 2021, IEEE T DEPEND SECURE, V18, P1320, DOI 10.1109/TDSC.2019.2932983
   Chen Y, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720911001
   Chen Y, 2019, MULTIMED TOOLS APPL, V78, P23097, DOI 10.1007/s11042-019-7635-z
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Dutta T, 2016, J VIS COMMUN IMAGE R, V38, P29, DOI 10.1016/j.jvcir.2015.12.007
   Elrowayati AA, 2020, IEEE ACCESS, V8, P114172, DOI 10.1109/ACCESS.2020.3004049
   Gao XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107579
   Gujjunoori S, 2013, J INF SECUR APPL, V18, P157, DOI 10.1016/j.istr.2013.01.002
   He WG, 2021, IEEE T INF FOREN SEC, V16, P3000, DOI 10.1109/TIFS.2021.3069173
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Konyar MZ, 2020, SIGNAL IMAGE VIDEO P, V14, P897, DOI 10.1007/s11760-019-01621-2
   Li D, 2019, MULTIMED TOOLS APPL, V78, P8167, DOI 10.1007/s11042-018-6729-3
   Li Dong, 2018, Journal of Wuhan University (Natural Science Edition), V64, P127, DOI 10.14188/j.1671-8836.2018.02.005
   Li LC, 2023, SIGNAL PROCESS, V208, DOI 10.1016/j.sigpro.2023.108970
   [李淑芝 Li Shuzhi], 2015, [中国图象图形学报, Journal of Image and Graphics], V20, P1285
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liu YX, 2016, NEUROCOMPUTING, V188, P63, DOI 10.1016/j.neucom.2014.10.109
   Liu YX, 2015, NEUROCOMPUTING, V151, P1053, DOI 10.1016/j.neucom.2014.03.088
   Long M, 2018, J REAL-TIME IMAGE PR, V14, P171, DOI 10.1007/s11554-017-0727-y
   Ma XJ, 2017, IEEE T CLOUD COMPUT, V5, P510, DOI 10.1109/TCC.2015.2469651
   Ma XJ, 2016, IEEE T EMERG TOP COM, V4, P349, DOI 10.1109/TETC.2015.2460462
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Marchetti F, 2022, SIAM J IMAGING SCI, V15, P1977, DOI 10.1137/22M147637X
   Muhit AA, 2012, J VIS COMMUN IMAGE R, V23, P31, DOI 10.1016/j.jvcir.2011.07.003
   Muhit AA, 2010, IEEE T CIRC SYST VID, V20, P661, DOI 10.1109/TCSVT.2010.2045804
   Nguyen TS, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14091768
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Niu K, 2017, TSINGHUA SCI TECHNOL, V22, P489
   Noorkami M, 2008, IEEE T INF FOREN SEC, V3, P441, DOI 10.1109/TIFS.2008.923825
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Peng F, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115715
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Shang XW, 2019, IEEE T CIRC SYST VID, V29, P1239, DOI 10.1109/TCSVT.2018.2836974
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Sohn H, 2011, IEEE T CIRC SYST VID, V21, P170, DOI 10.1109/TCSVT.2011.2106250
   Tang XX, 2020, MULTIMED TOOLS APPL, V79, P28661, DOI 10.1007/s11042-020-09315-5
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang W., 2012, P ACM MULTIMEDIA INT, P27
   Wang YM, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118600
   Xiao M., 2022, ACM Trans. Multimed. Comput. Commun. Appl., V19, P1
   Xiao MY, 2021, IEEE T CIRC SYST VID, V31, P2535, DOI 10.1109/TCSVT.2020.3027391
   Xu DW, 2022, MULTIMED TOOLS APPL, V81, P29305, DOI 10.1007/s11042-022-12740-3
   Xu DW, 2016, SIGNAL PROCESS-IMAGE, V47, P369, DOI 10.1016/j.image.2016.08.003
   Xu DW, 2014, J VIS COMMUN IMAGE R, V25, P410, DOI 10.1016/j.jvcir.2013.12.008
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Xu YZ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103375
   Yamato K, 2014, IEEE IMAGE PROC, P4216, DOI 10.1109/ICIP.2014.7025856
   Yao Y., 2016, INT WORKSHOP DIGITAL, P421
   Yao YZ, 2019, SIGNAL PROCESS, V164, P386, DOI 10.1016/j.sigpro.2019.06.034
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yeh HL, 2014, IET SIGNAL PROCESS, V8, P579, DOI 10.1049/iet-spr.2012.0233
   [张明辉 Zhang Minghui], 2016, [信号处理, Journal of Signal Processing], V32, P220
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 68
TC 0
Z9 0
U1 8
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104029
DI 10.1016/j.jvcir.2023.104029
EA DEC 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FR4F6
UT WOS:001147561500001
DA 2024-07-18
ER

PT J
AU Ren, TF
   Lian, QS
   Zhang, D
AF Ren, Tengfei
   Lian, Qiusheng
   Zhang, Dan
TI Constructing comprehensive and discriminative representations with
   diverse attention for occluded person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Representation learning; Diverse attention;
   Transformer
AB Occluded person re-identification (Re-ID) is a challenging task that aims to match occluded person images to holistic ones across different camera views. Feature diversity is crucial for achieving high-performance Re-ID. Previous methods rely on additional annotations or hand-crafted rules to achieve feature diversity, which are inefficient or infeasible for occluded Re-ID. To address this, we propose the Diverse Attention Net (DANet) which utilizes attention mechanism to achieve diverse feature mining. Specifically, DANet incorporates a pair of complementary Diverse Parallel Attention Modules (DPAM), which, under the attention decorrelation constraint (ADC), help the model automatically capture diverse discriminative features in a global scope. Additionally, we propose an Efficient Transformer layer that can seamlessly integrate with the proposed DPAM and synergistically enhance the capability to handle occlusions. The resulting DANet construct a set of comprehensive representations that encode diverse discriminative features. Extensive experiments demonstrate DANet achieves state-of-the-art performance on both occluded and holistic ReID benchmarks.
C1 [Lian, Qiusheng] Yanshan Univ, Sch Informat Sci & Engn, QinhuangDao 066004, Hebei, Peoples R China.
   Yanshan Univ, Hebei Key Lab Informat Transmiss & Signal Proc, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Yanshan University
RP Lian, QS (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, QinhuangDao 066004, Hebei, Peoples R China.
EM rentengfei92@gmail.com; lianqs@ysu.edu.cn; danzh267@gmail.com
FU Hebei Natural Science Foundation, China [F2022203030]
FX The authors would like to thank the anonymous reviewers for valuable
   comments. This work was supported by Hebei Natural Science Foundation,
   China F2022203030.
CR [Anonymous], 2019, P 33 AAAI C ART INT
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen H, 2020, IEEE WINT CONF APPL, P2472, DOI [10.1109/WACV45572.2020.9093541, 10.1109/wacv45572.2020.9093541]
   Chen PX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11813, DOI 10.1109/ICCV48922.2021.01162
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen Y, 2022, PATTERN RECOGN LETT, V157, P90, DOI 10.1016/j.patrec.2022.03.020
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan Huijie, 2023, IEEE Trans. Ind. Inform.
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, Arxiv, DOI arXiv:1810.07399
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou RB, 2022, IEEE T PATTERN ANAL, V44, P4894, DOI 10.1109/TPAMI.2021.3079910
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Jia MX, 2023, IEEE T MULTIMEDIA, V25, P1294, DOI 10.1109/TMM.2022.3141267
   Jia MX, 2021, AAAI CONF ARTIF INTE, V35, P1673
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma ZX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1487, DOI 10.1145/3474085.3475283
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Park H, 2020, AAAI CONF ARTIF INTE, V34, P11839
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Shizhen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P647, DOI 10.1007/978-3-030-58539-6_39
   Shu XJ, 2021, PATTERN RECOGN LETT, V149, P17, DOI 10.1016/j.patrec.2021.05.020
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan HC, 2023, IEEE T NEUR NET LEAR, V34, P8210, DOI 10.1109/TNNLS.2022.3144163
   Tan HC, 2022, IEEE T CIRC SYST VID, V32, P160, DOI 10.1109/TCSVT.2021.3061412
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2021, IEEE SIGNAL PROC LET, V28, P1155, DOI 10.1109/LSP.2021.3087079
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang T, 2022, AAAI CONF ARTIF INTE, P2540
   Wang ZK, 2022, IEEE T CIRC SYST VID, V32, P8179, DOI 10.1109/TCSVT.2021.3076097
   Xie Ben, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12307), P16, DOI 10.1007/978-3-030-60636-7_2
   Xu BQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P673, DOI 10.1145/3394171.3414056
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Zang XH, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104330
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu K, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3301856
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 58
TC 0
Z9 0
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103993
DI 10.1016/j.jvcir.2023.103993
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW6P6
UT WOS:001128313800001
DA 2024-07-18
ER

PT J
AU Fan, ZY
   Song, ZH
   Wu, D
   Zhu, YX
AF Fan, Zheyi
   Song, Zihao
   Wu, Di
   Zhu, Yixuan
TI Multi-branch Segmentation-guided Attention Network for crowd counting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Multi-task learning; Attention mechanism
ID SCALE
AB Crowd counting has gained increasing attention recently owing to its importance in public safety. However, it remains a challenging task due to background complexities and high annotation costs. To address these challenges, we propose the Multi-branch Segmentation-guided Attention Network (MSGANet). To deal with the complex background, we incorporate segmentation-guided attention branches into both shallow and deep layers of the baseline model, allowing simultaneous consideration of spatial and semantic information. Multi-level attention maps enable the network to minimize the influence of complex backgrounds while focusing on the regions containing crowds. To tackle the issue of costly annotations, MSGANet utilizes only point annotations to generate ground truth density and segmentation maps, eliminating additional expenses. Our results demonstrate that our approach achieves highly competitive performance compared to state-of-the-art crowd counting methods.
C1 [Fan, Zheyi; Song, Zihao; Wu, Di; Zhu, Yixuan] Beijing Inst Technol, Sch Integrated Circuits & Elect, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Fan, ZY (corresponding author), Beijing Inst Technol, Sch Integrated Circuits & Elect, Beijing 100081, Peoples R China.
EM funye@bit.edu.cn
RI wu, di/IYS-9217-2023
CR Abousamra S, 2021, AAAI CONF ARTIF INTE, V35, P872
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chen JW, 2021, IET IMAGE PROCESS, V15, P1221, DOI 10.1049/ipr2.12099
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Cheng J, 2021, IEEE T IMAGE PROCESS, V30, P2862, DOI 10.1109/TIP.2021.3055631
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan ZD, 2020, IEEE ACCESS, V8, P36376, DOI 10.1109/ACCESS.2020.2975268
   Gong Shenjian, 2022, arXiv
   Hossain MA, 2019, IEEE WINT CONF APPL, P1280, DOI 10.1109/WACV.2019.00141
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P1049, DOI 10.1109/TIP.2017.2740160
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ilyas N, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-09685-w
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Kang D, 2019, IEEE T CIRC SYST VID, V29, P1408, DOI 10.1109/TCSVT.2018.2837153
   Li J, 2020, IEEE T IND INFORM, V16, P566, DOI 10.1109/TII.2019.2935244
   Li PF, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.902
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Lin H, 2022, ARXIV
   Lin H, 2021, Arxiv, DOI arXiv:2107.01558
   Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu N, 2019, PROC CVPR IEEE, P3220, DOI 10.1109/CVPR.2019.00334
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu YB, 2021, APPL INTELL, V51, P427, DOI 10.1007/s10489-020-01842-w
   Ma ZH, 2021, AAAI CONF ARTIF INTE, V35, P2319
   Marsden M, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Miao YQ, 2020, AAAI CONF ARTIF INTE, V34, P11765
   Oh MH, 2020, AAAI CONF ARTIF INTE, V34, P11799
   Paszke A, 2019, ADV NEUR IN, V32
   Regazzoni CS, 1996, SIGNAL PROCESS, V53, P47, DOI 10.1016/0165-1684(96)00075-8
   Rong LZ, 2021, IEEE WINT CONF APPL, P3674, DOI 10.1109/WACV48630.2021.00372
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Tian Y, 2021, Arxiv, DOI [arXiv:2109.14483, DOI 10.48550/ARXIV.2109.14483]
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan J, 2021, PROC CVPR IEEE, P1974, DOI 10.1109/CVPR46437.2021.00201
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang Q, 2022, IEEE T INTELL TRANSP, V23, P15233, DOI 10.1109/TITS.2021.3138896
   Wang YB, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3465455
   Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041
   Xu CF, 2022, INT J COMPUT VISION, V130, P405, DOI 10.1007/s11263-021-01542-z
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan ZY, 2022, IEEE T MULTIMEDIA, V24, P2633, DOI 10.1109/TMM.2021.3086709
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao MM, 2019, PROC CVPR IEEE, P12728, DOI 10.1109/CVPR.2019.01302
   Zhao Muming, 2019, Comput. Vis. Patt. Recogn.
NR 56
TC 0
Z9 0
U1 3
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103964
DI 10.1016/j.jvcir.2023.103964
EA OCT 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y5SY1
UT WOS:001105866100001
DA 2024-07-18
ER

PT J
AU Chen, Y
   Wang, L
   Hu, DK
   Cheng, H
AF Chen, Yang
   Wang, Ling
   Hu, Dekun
   Cheng, Hong
TI Multi-view graph convolution network for the recognition of human action
   with spatial and temporal occlusion problems*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Spatial-temporal occlusion; Multi-view; Graph
   network
AB Human action recognition holds great significance in the field of social security. However, the challenges posed by occlusion and changes in viewpoint create specific obstacles in achieving accurate recognition. In this study, we propose a multi-view graph convolution fusion method to effectively address this issue. Specifically, considering the limited availability of public human action datasets that include occlusion, we introduce an adaptive multi-view spatial-temporal occlusion generation method. It allows us to generate occlusion skeleton data from multiple viewpoints, ensuring a close resemblance to real-life scenarios with minimal modifications to existing public datasets. Additionally, we present a plug-and-play multi-view information fusion module, briefed as MGL, which aims to solve the occlusion problem. The MGL combines the capabilities of Graph Convolutional network (GCN) and Long Short-Term Memory network (LSTM), in which GCN is employed to reconstruct human skeleton information using multi-view spatial occlusion data, and LSTM captures the long-term dependencies within the temporal sequences of the multi-view data. Moreover, an attention mask mechanism is introduced to highlight key joint features. Experiment results illustrate the excellent performance of our method on the NTU RGB+D 60 and NTU RGB+D 120 datasets.
C1 [Chen, Yang; Wang, Ling] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, 2006 Xiyuan Ave,West Hitech Zone, Chengdu 611731, Sichuan, Peoples R China.
   [Hu, Dekun] Buffalo Robot Tech Co Ltd, 2039 Tianfu Ave, Chengdu 610213, Peoples R China.
   [Cheng, Hong] Univ Elect Sci & Technol China, Sch Automat Engn, 2006 Xiyuan Ave,West Hitech Zone, Chengdu 611731, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China
RP Wang, L (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, 2006 Xiyuan Ave,West Hitech Zone, Chengdu 611731, Sichuan, Peoples R China.
EM eewangling@uestc.edu.cn
RI Chen, Yang/HTN-0471-2023
OI Wang, Ling/0000-0002-1235-1241; Chen, Yang/0009-0008-5752-1639
FU National Natural Science Foundation of China (NSFC) [61971106]; Key
   Research and Development Project of Sichuan Province [2021YFS0016];
   Chengdu key research and development support plan [2021-YF05-02388-SN]
FX The authors would like to thank the support of "National Natural Science
   Foundation of China (NSFC)" (No. 61971106), "Key Research and
   Development Project of Sichuan Province" (No. 2021YFS0016), "Chengdu key
   research and development support plan" (No. 2021-YF05-02388-SN).
CR Bai Y, 2021, AAAI CONF ARTIF INTE, V35, P6714
   BanTeng ML, 2021, INT C PATT RECOG, P3799, DOI 10.1109/ICPR48806.2021.9412329
   Becker S, 1996, NETWORK-COMP NEURAL, V7, P7, DOI 10.1080/0954898X.1996.11978653
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Chenarlogh VA, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066079
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   Efthymiou N, 2018, IEEE IMAGE PROC, P455, DOI 10.1109/ICIP.2018.8451146
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   Hao T, 2017, J VIS COMMUN IMAGE R, V48, P453, DOI 10.1016/j.jvcir.2017.01.019
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hu ZX, 2020, INFORM FUSION, V55, P251, DOI 10.1016/j.inffus.2019.09.005
   Huang ZY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2563
   Hussein, 2013, INT JOINT C ART INT
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Ke Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P536, DOI 10.1007/978-3-030-58586-0_32
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Kong Y, 2017, IEEE T IMAGE PROCESS, V26, P3028, DOI 10.1109/TIP.2017.2696786
   Liang Q, 2020, IEEE ACCESS, V8, P139792, DOI 10.1109/ACCESS.2020.3012692
   Liang ZX, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104357
   Liu J., 2013, P 2013 SIAM INT C DA, P252, DOI DOI 10.1137/1.9781611972832.28
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Ma C, 2019, IEEE T MULTIMEDIA, V21, P1169, DOI 10.1109/TMM.2018.2875512
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939
   Obinata Y, 2021, INT C PATT RECOG, P534, DOI 10.1109/ICPR48806.2021.9412113
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Song YF, 2023, IEEE T PATTERN ANAL, V45, P1474, DOI 10.1109/TPAMI.2022.3157033
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun ZK, 2020, AAAI CONF ARTIF INTE, V34, P8992
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vyas Shruti, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P427, DOI 10.1007/978-3-030-58583-9_26
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang MS, 2023, IEEE T PATTERN ANAL, V45, P6940, DOI 10.1109/TPAMI.2020.3032738
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wu Y, 2020, IEEE INT CONF BIG DA, P3355, DOI 10.1109/BigData50022.2020.9378458
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yan XQ, 2021, NEUROCOMPUTING, V448, P106, DOI 10.1016/j.neucom.2021.03.090
   Yang D, 2021, IEEE INT CONF AUTOMA
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 62
TC 0
Z9 0
U1 7
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103957
DI 10.1016/j.jvcir.2023.103957
EA OCT 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y9ME7
UT WOS:001108421100001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Wan, ZL
   Yin, XH
   Yue, GH
   Tan, AP
   Zheng, Z
AF Liu, Yun
   Wan, Zuliang
   Yin, Xiaohua
   Yue, Guanghui
   Tan, Aiping
   Zheng, Zhi
TI Detection of GAN generated image using color gradient representation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image generative model; Generative adversarial networks; Fake image
   identification
ID FACE
AB With the development of generative adversarial network (GANs) technology, the technology of GAN generates images has evolved dramatically. Distinguishing these GAN generated images is challenging for the human eye. Moreover, the GAN generated fake images may cause some behaviors that endanger society and bring great security problems to society. Research on GAN generated image detection is still in the exploratory stage and many challenges remain. Motivated by the above problem, we propose a novel GAN image detection method based on color gradient analysis. We consider the difference in color information between real images and GAN generated images in multiple color spaces, and combined the gradient information and the directional texture information of the generated images to extract the gradient texture features for GAN generated images detection. Experimental results on PGGAN and StyleGAN2 datasets demonstrate that the proposed method achieves good performance, and is robust to other various perturbation attacks.
C1 [Liu, Yun; Wan, Zuliang; Yin, Xiaohua; Tan, Aiping] Liaoning Univ, Coll Informat, Shenyang 110036, Peoples R China.
   [Yue, Guanghui] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518000, Peoples R China.
   [Zheng, Zhi] Beijing Jiaotong Univ, Dept Elect & Informat Engn, Beijing 100000, Peoples R China.
C3 Liaoning University; Shenzhen University; Beijing Jiaotong University
RP Liu, Y; Tan, AP (corresponding author), Liaoning Univ, Coll Informat, Shenyang 110036, Peoples R China.
EM yunliu@tju.edu.cn; aipingtan@lnu.edu.cn
OI Liu, Yun/0000-0003-4115-1617
FU National Natural Science Foundation of China [61901205]; Liaoning
   Province Natural Science Foundation, China [2023-MS-139]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61901205, and Liaoning Province Natural Science
   Foundation, China under Grant 2023-MS-139.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Barni M, 2020, IEEE INT WORKS INFOR, DOI 10.1109/WIFS49906.2020.9360905
   Berthelot D, 2017, Arxiv, DOI arXiv:1703.10717
   Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]
   Chandrasegaran K., 2021, P IEEE CVF C COMP VI, P7200
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen BJ, 2022, IEEE T CIRC SYST VID, V32, P3527, DOI 10.1109/TCSVT.2021.3116679
   Chen BJ, 2021, INFORM SCIENCES, V572, P16, DOI 10.1016/j.ins.2021.05.006
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J., 2021, IMAGE COMMUN, V96
   Fu T, 2022, MULTIMED TOOLS APPL, V81, P26345, DOI 10.1007/s11042-022-12661-1
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Gangan MP, 2022, J INF SECUR APPL, V68, DOI 10.1016/j.jisa.2022.103261
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   He PS, 2019, IEEE IMAGE PROC, P2299, DOI [10.1109/icip.2019.8803740, 10.1109/ICIP.2019.8803740]
   Hsu CC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10010370
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kiruthika S, 2023, MULTIMED TOOLS APPL, V82, P8691, DOI 10.1007/s11042-021-11493-9
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li H., 2018, DETECTION DEEP NETWO, V1808, P1
   Li HD, 2020, SIGNAL PROCESS, V174, DOI 10.1016/j.sigpro.2020.107616
   Liu MY, 2017, ADV NEUR IN, V30
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Marra F, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P506, DOI 10.1109/MIPR.2019.00103
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   McCloskey S, 2019, IEEE IMAGE PROC, P4584, DOI [10.1109/icip.2019.8803661, 10.1109/ICIP.2019.8803661]
   Mi ZJ, 2020, IEEE J-STSP, V14, P969, DOI 10.1109/JSTSP.2020.2994523
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nataraj L., 2019, Electron. Imaging, V5, P1, DOI 10.2352/
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Peng C., 2022, SECUR COMMUN NETW, V2022
   Quan WZ, 2018, IEEE T INF FOREN SEC, V13, P2772, DOI 10.1109/TIFS.2018.2834147
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Tang G., 2021, SECUR COMMUN NETW, V2021
   Tariq S, 2018, MPS'18: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY, P81, DOI 10.1145/3267357.3267367
   Wang O., 2020, PROC IEEECVF C COMPU, V7, P8695
   Wang R, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3444
   Wang YW, 2021, PATTERN RECOGN LETT, V146, P15, DOI 10.1016/j.patrec.2021.03.009
   Wang ZJ, 2019, SIGNAL PROCESS, V156, P92, DOI 10.1016/j.sigpro.2018.10.004
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Xia ZM, 2022, INFORM SCIENCES, V607, P654, DOI 10.1016/j.ins.2022.06.003
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yu Y, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3499026
   Zhang X, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035107
   Zhao JB, 2017, Arxiv, DOI arXiv:1609.03126
   Zhao L, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23121692
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 60
TC 1
Z9 1
U1 11
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103876
DI 10.1016/j.jvcir.2023.103876
EA JUN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M7GQ2
UT WOS:001031867400001
DA 2024-07-18
ER

PT J
AU Tong, K
   Wu, YQ
AF Tong, Kang
   Wu, Yiquan
TI Rethinking PASCAL-VOC and MS-COCO dataset for small object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data annotation; Small object detection; SDOD; Mini6K; Mini2022;
   Mini6KClean
AB The data and the algorithm are critical to deep learning-based small object detectors. In this paper, we rethink the PASCAL-VOC and MS-COCO dataset for small object detection. By visual analysis of the original annotations, we find that there are different labeling errors in these two datasets. To solve these problems, we build specific datasets, including SDOD, Mini6K, Mini2022 and Mini6KClean. The experimental results of several typical al-gorithms (e.g. SSD, YOLOv5, Faster RCNN and Deformable DETR) on the datasets show that data labeling errors (such as missing labels, category label errors, inappropriate labels) are another factor that affects the detection performance of small objects.
C1 [Tong, Kang; Wu, Yiquan] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 211106, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wu, YQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 211106, Peoples R China.
EM nuaavision@163.com
CR Aziz L, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104287
   Chen G, 2022, IEEE T SYST MAN CY-S, V52, P936, DOI 10.1109/TSMC.2020.3005231
   Chen SJ, 2020, IEEE SIGNAL PROC LET, V27, P1680, DOI 10.1109/LSP.2020.3025128
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Lee G, 2021, IEEE SIGNAL PROC LET, V28, P1026, DOI 10.1109/LSP.2021.3081041
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Nguyen ND, 2020, J ELECTR COMPUT ENG, V2020, DOI 10.1155/2020/3189691
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samet Nermin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P406, DOI 10.1007/978-3-030-58595-2_25
   Savvides M., 2019, 30 BRIT MACHINE VISI
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tong K, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104471
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Xi Y, 2020, PATTERN RECOGN LETT, V137, P53, DOI 10.1016/j.patrec.2019.03.009
   Xingyi Yang, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P15, DOI 10.1007/978-3-030-64559-5_2
   Xu DL, 2020, IEEE SIGNAL PROC LET, V27, P1435, DOI 10.1109/LSP.2020.3013160
   Yang X., 2022, ANN C NEURAL INFORM
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Yuzhe, 2020, NEURIPS, V33, P19290
   Yuan Y, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3122190
   Zhang XP, 2020, IET IMAGE PROCESS, V14, P1662, DOI 10.1049/iet-ipr.2019.0833
   Zhu Xizhou, 2021, 9 INT C LEARNING REP
NR 30
TC 10
Z9 11
U1 16
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103830
DI 10.1016/j.jvcir.2023.103830
EA MAY 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J3OX3
UT WOS:001008749500001
DA 2024-07-18
ER

PT J
AU He, ZY
   He, LQ
   Xu, HY
   Chai, TY
   Luo, T
AF He, Zhouyan
   He, Lingqiang
   Xu, Haiyong
   Chai, Tong-Yuen
   Luo, Ting
TI A bilateral attention based generative adversarial network for DIBR 3D
   image watermarking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Watermarking; Depth-image-based rendering (DIBR) 3D image; Bilateral
   attention; Cross-modal feature fusion; Redundancy elimination
ID QUALITY ASSESSMENT; SYNTHESIZED VIEWS; DEPTH
AB This paper presents a bilateral attention based generative adversarial network (BAGAN) for depth-image-based rendering (DIBR) 3D image watermarking to protect the image copyright. Convolutional block operations are employed to extract main image features for robust watermarking, but embedding watermark into some features will degrade image quality much. To relieve this kind of image distortion, the bilateral attention module (BAM) is utilized by mining correlations of the center view and the depth map to compute attention of the 3D image for guiding watermark to distribute over different image regions. Since a modality gap exists between the center view and the depth map, a cross-modal feature fusion module (CMFFM) is designed for BAM to bridge the cross-view gap. Because the depth map has lots of flat background information including many redundant features, to prune them, the depth redundancy elimination module (DREM) is used for cross-view feature fusion. In the decoder, two extractors with the same structure are built to recover watermark from the center view and the synthesized view, respectively. In addition, the discriminator is supposed to build a competitive relationship with the encoder to increase the image quality. The noise sub-network is used to train different image attacks for robustness. Extensive experimental results have demonstrated that the proposed BAGAN can obtain higher watermarking invisibility and robustness compared with existing DIBR 3D watermarking methods. Ablation experiments have also proven the effectiveness of DREM, CMFFM and BAM on BAGAN.
C1 [He, Zhouyan; He, Lingqiang; Luo, Ting] Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Peoples R China.
   [He, Zhouyan; He, Lingqiang; Xu, Haiyong; Luo, Ting] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315000, Peoples R China.
   [Chai, Tong-Yuen] Quest Int Univ, Ipoh 30250, Perak, Malaysia.
C3 Ningbo University; Ningbo University; Quest International University
   Perak
RP Luo, T (corresponding author), Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Peoples R China.; Luo, T (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315000, Peoples R China.
EM luoting@nbu.edu.cn
RI zhouyan, he/GXM-4974-2022
OI Luo, Ting/0000-0003-1762-148X
FU Natural Science Foundation of China [61971247]; Natural Science
   Foundation of Zhejiang Province [LY22F020020, LQ23F010011]; Natural
   Science Foundation of Ningbo [2021J134, 2022J136]; Foundation of
   Zhejiang Province Education Department [Y202248989]
FX Acknowledgement This work was supported by Natural Science Foundation of
   China under Grant No. 61971247, Natural Science Foundation of Zhejiang
   Province under Grant Nos. LY22F020020 and LQ23F010011, Natural Science
   Foundation of Ningbo under Grant Nos. 2021J134 and 2022J136, and
   Foundation of Zhejiang Province Education Department, No. Y202248989.
CR Ahmad Z, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4150
   Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Al-Haj A, 2017, MEASUREMENT, V95, P405, DOI 10.1016/j.measurement.2016.10.016
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Bai X, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108102
   Borghi G, 2020, IEEE T PATTERN ANAL, V42, P596, DOI 10.1109/TPAMI.2018.2885472
   Chen C., 2021, IEEE Transactions on Instrumentation and Measurement, V70, P1
   Chen WY, 2022, DIGIT SIGNAL PROCESS, V130, DOI 10.1016/j.dsp.2022.103697
   Cui C, 2017, MULTIMED TOOLS APPL, V76, P649, DOI 10.1007/s11042-015-3028-0
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Fu Y, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2021.108010
   Halici E, 2009, IEEE IMAGE PROC, P4217, DOI 10.1109/ICIP.2009.5413525
   Hao KL, 2020, CHINA COMMUN, V17, P131, DOI 10.23919/JCC.2020.11.012
   Haribabu K., 2015, PROC IEEE WORKSHOP C, P1
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Itu-R R., 2000, REC 500 10 METH SUBJ, P500
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Li Y, 2021, NEUROCOMPUTING, V461, P171, DOI 10.1016/j.neucom.2021.07.051
   Liao X, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103244
   Lin YH, 2011, IEEE T BROADCAST, V57, P602, DOI 10.1109/TBC.2011.2131470
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Liu Q., 2022, IEEE Trans.Geosci. Remote Sens., V60, P1
   Liu XY, 2022, INFORM SCIENCES, V604, P97, DOI 10.1016/j.ins.2022.05.010
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Luo T, 2016, DIGIT SIGNAL PROCESS, V48, P116, DOI 10.1016/j.dsp.2015.09.007
   Luo YF, 2021, MULTIMED TOOLS APPL, V80, P14915, DOI 10.1007/s11042-020-10375-w
   Min-Jeong Lee, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P81, DOI 10.1109/IIHMSP.2011.83
   Mun SM, 2017, Arxiv, DOI arXiv:1704.03248
   Nam SH, 2020, IEEE ACCESS, V8, P93760, DOI 10.1109/ACCESS.2020.2994966
   Nam SH, 2018, MULTIMED TOOLS APPL, V77, P7811, DOI 10.1007/s11042-017-4678-x
   Pan ZQ, 2022, IEEE T CIRC SYST VID, V32, P6347, DOI 10.1109/TCSVT.2022.3161103
   Pavlovic K, 2022, DIGIT SIGNAL PROCESS, V122, DOI 10.1016/j.dsp.2021.103381
   Sandic-Stankovic DD, 2022, IEEE T IMAGE PROCESS, V31, P1161, DOI 10.1109/TIP.2021.3139238
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Su QT, 2022, INFORM SCIENCES, V606, P194, DOI 10.1016/j.ins.2022.05.046
   Su QT, 2022, INT J INTELL SYST, V37, P4747, DOI 10.1002/int.22738
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Tian SS, 2021, NEUROCOMPUTING, V423, P158, DOI 10.1016/j.neucom.2020.09.062
   Vosco N., 2021, P IEEE CVF INT C COM, P345
   Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083
   Wang FY, 2022, IEEE T IMAGE PROCESS, V31, P1285, DOI 10.1109/TIP.2022.3140606
   Wu HZ, 2021, IEEE T CIRC SYST VID, V31, P2591, DOI 10.1109/TCSVT.2020.3030671
   Xia ZQ, 2021, DIGIT SIGNAL PROCESS, V116, DOI 10.1016/j.dsp.2021.103130
   Xiyang Luo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13545, DOI 10.1109/CVPR42600.2020.01356
   Zhang C., 2021, arXiv
   Zhang H., 2022, IEEE T CIRC SYST VID, V32, P1
   Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zhu XY, 2022, IEEE T MULTIMEDIA, V24, P3074, DOI 10.1109/TMM.2021.3092571
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 52
TC 1
Z9 1
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103794
DI 10.1016/j.jvcir.2023.103794
EA MAR 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H0TA7
UT WOS:000993161100001
DA 2024-07-18
ER

PT J
AU da Silveira, TLT
   Pinto, PGL
   Lermen, TS
   Jung, CR
AF da Silveira, Thiago L. T.
   Pinto, Paulo G. L.
   Lermen, Thiago S.
   Jung, Claudio R.
TI Omnidirectional 2.5D representation for COVID-19 diagnosis using chest
   CTs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 2; 5D representation; COVID-19 diagnosis; Ground-glass opacity;
   Omnidirectional imaging
ID PNEUMONIA; FRAMEWORK
AB The Coronavirus Disease 2019 (COVID-19) has drastically overwhelmed most countries in the last two years, and image-based approaches using computerized tomography (CT) have been used to identify pulmonary infections. Recent methods based on deep learning either require time-consuming per-slice annotations (2D) or are highly data-and hardware-demanding (3D). This work proposes a novel omnidirectional 2.5D representation of volumetric chest CTs that allows exploring efficient 2D deep learning architectures while requiring volume-level annotations only. Our learning approach uses a siamese feature extraction backbone applied to each lung. It combines these features into a classification head that explores a novel combination of Squeeze-and-Excite strategies with Class Activation Maps. We experimented with public and in-house datasets and compared our results with state-of-the-art techniques. Our analyses show that our method provides better or comparable prediction quality and accurately distinguishes COVID-19 infections from other kinds of pneumonia and healthy lungs.
C1 [da Silveira, Thiago L. T.; Pinto, Paulo G. L.; Lermen, Thiago S.; Jung, Claudio R.] Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, Brazil.
C3 Universidade Federal do Rio Grande do Sul
RP da Silveira, TLT (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, Brazil.
EM tltsilveira@inf.ufrgs.br
RI ; da Silveira, Thiago/C-7925-2018
OI Lermen, Thiago/0000-0003-1327-5356; da Silveira,
   Thiago/0000-0001-6788-2667
FU Fundacao de Amparo a Pesquisa do Estado do Rio Grande do Sul (FAPERGS),
   Brazil; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico
   (CNPq), Brazil; Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior (CAPES), Brazil [001]
FX We thank the financial support from Fundacao de Amparo a Pesquisa do
   Estado do Rio Grande do Sul (FAPERGS), Brazil, Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico (CNPq), Brazil, and Coordenacao
   de Aperfeicoamento de Pessoal de Nivel Superior (CAPES) Finance Code
   001, Brazil.
CR Abdel-Basset M, 2021, PATTERN RECOGN LETT, V152, P311, DOI 10.1016/j.patrec.2021.10.027
   Afshar P, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00900-3
   Benseddik HE, 2016, J VIS COMMUN IMAGE R, V40, P708, DOI 10.1016/j.jvcir.2016.08.010
   Bougourzi F, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8568, DOI 10.1109/ICASSP39728.2021.9414185
   Bougourzi F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175878
   Callaway E, 2022, NATURE, V607, P18, DOI 10.1038/d41586-022-01771-3
   Chate RC, 2020, J BRAS PNEUMOL, V46, DOI 10.36416/1806-3756/e20200121
   Chaudhary S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8583, DOI 10.1109/ICASSP39728.2021.9414007
   Chen JQ, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000021240
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   da Silveira TLT, 2022, ACM COMPUT SURV, V55, DOI DOI 10.1145/3519021
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeVries T, 2017, Arxiv, DOI [arXiv:1708.04552, DOI 10.48550/ARXIV.1708.04552]
   Di DL, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101910
   Eder M, 2019, INT CONF 3D VISION, P76, DOI 10.1109/3DV.2019.00018
   Elsken T, 2019, J MACH LEARN RES, V20
   Ewen N., 2021, 2021 IEEE INT C AUTO, P1
   Fernandez-Labrador C, 2020, IEEE ROBOT AUTOM LET, V5, P1255, DOI 10.1109/LRA.2020.2967274
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Garg P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8558, DOI 10.1109/ICASSP39728.2021.9414426
   Grando RD, 2020, BRAZ J INFECT DIS, V24, P524, DOI 10.1016/j.bjid.2020.10.002
   Hassan H, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heidarian S., 2020, COVID FACT FULLY AUT, V10
   Heidarian S., 2021, CT CAPS FEATURE EXTR
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Hofmanninger J, 2020, EUR RADIOL EXP, V4, DOI 10.1186/s41747-020-00173-2
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Reddi SJ, 2019, Arxiv, DOI arXiv:1904.09237
   Jabeen N., 2019, CUREUS
   Jin C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18685-1
   K Jalal Deen, 2017, Asian Pac J Cancer Prev, V18, P1869
   Khademi S, 2022, Arxiv, DOI arXiv:2109.09241
   Kupferschmidt K., 2021, SCIENCE
   Kwee TC, 2020, RADIOGRAPHICS, V40, P1848, DOI 10.1148/rg.2020200159
   Laghi A, 2020, LANCET DIGIT HEALTH, V2, pE225, DOI 10.1016/S2589-7500(20)30079-0
   Li BY, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8563, DOI 10.1109/ICASSP39728.2021.9413707
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Li Y., 2017, arXiv, DOI 10.48550/arXiv.1704.00109
   Liu ZS, 2022, IEEE T IMAGE PROCESS, V31, P1857, DOI 10.1109/TIP.2022.3148819
   Meirelles Gustavo de Souza Portes, 2020, Radiol Bras, V53, P320, DOI 10.1590/0100-3984.2020.0074
   Melo F., 2013, Area Under the ROC Curve, P38, DOI [DOI 10.1007/978-1-4419-9863-7209, 10.1007/978-1-4419-9863-7_209, DOI 10.1007/978-1-4419-9863-7_209, 10.1007/978-1-4419-9863-7209]
   Mohammadi A., 2021, IEEE ICASSP 2021 SIG
   Rahman MF, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103521
   Ren QY, 2022, IEEE J BIOMED HEALTH, V26, P194, DOI 10.1109/JBHI.2021.3132157
   Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simpson S, 2020, RADIOL-CARDIOTHORAC, V2, DOI [10.1148/ryct.2020200152, 10.1097/RTI.0000000000000524]
   Sohn K., 2020, ADV NEURAL INFORM PR
   Sousa AM, 2019, MED PHYS, V46, P4970, DOI 10.1002/mp.13773
   Stommel M, 2014, IEEE SENS J, V14, P1107, DOI 10.1109/JSEN.2013.2291315
   Sun C, 2021, PROC CVPR IEEE, P2573, DOI 10.1109/CVPR46437.2021.00260
   Tan MX, 2019, PR MACH LEARN RES, V97
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang XG, 2020, IEEE T MED IMAGING, V39, P2615, DOI 10.1109/TMI.2020.2995965
   Wang Y, 2018, Arxiv, DOI arXiv:1807.06288
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887
   Wu X, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101913
   Xue SH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8573, DOI 10.1109/ICASSP39728.2021.9414947
   Yang S., 2022, IEEE J BIOMED HEALTH, P1
   Yang ST, 2019, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2019.00348
   Yang ZF, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8578, DOI 10.1109/ICASSP39728.2021.9414745
   Yu Q, 2020, THERANOSTICS, V10, P5641, DOI 10.7150/thno.46465
   Zhang J., 2020, Ethiop. J. Health Dev, V34, P235
   Zhang YC, 2021, IEEE J BIOMED HEALTH, V25, P4152, DOI 10.1109/JBHI.2021.3106341
   Zhao FQ, 2019, Arxiv, DOI [arXiv:1904.00906, DOI 10.48550/ARXIV.1904.00906, 10.48550/arXiv.1904.00906]
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
NR 73
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103775
DI 10.1016/j.jvcir.2023.103775
EA JAN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D3TW9
UT WOS:000967995500001
PM 36741546
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Othman, E
   Werner, P
   Saxen, F
   Al-Hamadi, A
   Gruss, S
   Walter, S
AF Othman, Ehsan
   Werner, Philipp
   Saxen, Frerk
   Al-Hamadi, Ayoub
   Gruss, Sascha
   Walter, Steffen
TI Classification networks for continuous automatic pain intensity
   monitoring in video using facial expression on the X-ITE Pain Database
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Continuous pain intensity recognition; Random Forest classifier; Facial
   expression; Long-Short Term Memory; Sample weighting
AB So far, the current methods in the clinical application do not facilitate continuous monitoring for pain and are unreliable, especially for vulnerable patients. In contrast, several automated methods have been proposed for this task by using facial features that were extracted independently from every frame of a given sequence. However, the obtained results were poor due to the failure to represent movement dynamics. To solve this problem, this work introduces three distinct methods regarding classification to monitor continuous pain intensity: (1) A Random Forest classifier (RFc) baseline method, (2) Long-Short Term Memory (LSTM) method, and (3) LSTM using sample weighting method (LSTM-SW). In this study, we conducted experiments with 11 datasets regarding classification, then compared results to regression results in Othman et al. (2021). Experimental results showed that the LSTM & LSTM-SW methods for continuous automatic pain intensity recognition performed better than guessing and RFc except with small datasets such as the reduced tonic datasets.
C1 [Othman, Ehsan; Werner, Philipp; Saxen, Frerk; Al-Hamadi, Ayoub] Otto von Guericke Univ, Inst Informat Technol & Commun, Dept Neuroinformat Technol, D-39106 Magdeburg, Germany.
   [Gruss, Sascha; Walter, Steffen] Univ Hosp Ulm, Dept Med Psychol, D-89081 Ulm, Germany.
C3 Otto von Guericke University; Ulm University
RP Othman, E (corresponding author), Otto von Guericke Univ, Inst Informat Technol & Commun, Dept Neuroinformat Technol, D-39106 Magdeburg, Germany.
EM Ehsan.Othman@ovgu.de; Philipp.Werner@ovgu.de; Frerk.Saxen@ovgu.de;
   Steffen.Walter@uni-ulm.de; Sascha.Gruss@uni-ulm.de;
   Steffen.Walter@uni-ulm.de
RI Werner, Philipp/C-7247-2009
OI Werner, Philipp/0000-0002-2136-6568; Othman, Ehsan/0000-0002-4738-1897;
   Walter, Steffen/0000-0002-8112-515X
FU German Academic Exchange Ser-vice (DAAD); Federal Ministry of Education
   and Research of Germany (BMBF) [03ZZ04X02B]; German Research Foundation
   (DFG) [AI 638/13-1, AI 638/15-1]
FX Acknowledgements This research was supported by German Academic Exchange
   Ser-vice (DAAD) and the Federal Ministry of Education and Research of
   Germany (BMBF) ; projects Robo-Lab no. 03ZZ04X02B and German Research
   Foundation (DFG) under grants AI 638/13-1 and AI 638/15-1.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alharbi S, 2017, IEEE IPCCC, DOI 10.1109/TCYB.2017.2662199
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2016, SLPAT 2016 WORKSHOP, DOI DOI 10.21437/SLPAT.2016-7
   Arashloo SR, 2014, IEEE T MULTIMEDIA, V16, P2099, DOI 10.1109/TMM.2014.2362855
   Aung MSH, 2016, IEEE T AFFECT COMPUT, V7, P435, DOI 10.1109/TAFFC.2015.2462830
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bargshady G, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P52, DOI [10.1109/CCOMS.2019.8821779, 10.1109/ccoms.2019.8821779]
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Brahnam S., 2005, Fuzzy Logic and Applications. 6th International Workshop, WILF 2005. Revised Selected Papers (Lecture Notes in Artificial Intelligence Vol. 3849), P121
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen JK, 2017, COMPUT VIS IMAGE UND, V155, P113, DOI 10.1016/j.cviu.2016.11.003
   Chu YQ, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00279
   Craig K.D., 1992, APS J, V1, P153
   Craig KD, 2009, CAN PSYCHOL, V50, P22, DOI 10.1037/a0014772
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gruss S, 2019, JOVE-J VIS EXP, DOI 10.3791/59057
   Haque MA, 2018, IEEE INT CONF AUTOMA, P250, DOI 10.1109/FG.2018.00044
   Harrison D, 2014, BMC PEDIATR, V14, DOI 10.1186/1471-2431-14-134
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Herr K, 2011, PAIN MANAG NURS, V12, P230, DOI 10.1016/j.pmn.2011.10.002
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kachele M., 2015, ENG APPL NEURAL NETW, P275, DOI DOI 10.1007/978-3-319-23983-5_26.1
   Kalischek N, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P317, DOI [10.1109/ACIIW.2019.8925055, 10.1109/aciiw.2019.8925055]
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kubat M., 1997, ICML, P179
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lopez-Martinez D, 2018, IEEE ENG MED BIO, P5624, DOI 10.1109/EMBC.2018.8513575
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Othman E., 2021, 25 INT C IMAGE PROCE, P13
   Othman E, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093273
   Othman E, 2019, INT SYMP IMAGE SIG, P181, DOI 10.1109/ISPA.2019.8868562
   Othman E, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122786
   Pasqualetti G, 2010, EUR J CLIN PHARMACOL, V66, P647, DOI 10.1007/s00228-010-0827-0
   Salekin MS, 2021, DATA BRIEF, V35, DOI 10.1016/j.dib.2021.106796
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Soar Jeffrey, 2018, Smart Homes and Health Telematics. Designing a Better Future: Urban Assisted Living. 16th International Conference, ICOST 2018. Proceedings: LNCS 10898, P249, DOI 10.1007/978-3-319-94523-1_22
   Thiam P., 2018, MULTIMODAL PATTERN R, P49
   Thiam P., 2017, IMAGE PROCESSING THE, P1, DOI DOI 10.1109/IPTA.2017.8310115
   Thiam P., 2017, 25 EUR S ART NEUR NE, P465
   Thiam P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030839
   Thiam P, 2021, IEEE T AFFECT COMPUT, V12, P743, DOI 10.1109/TAFFC.2019.2892090
   Thiam P, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204503
   Tsai FS, 2016, INTERSPEECH, P92, DOI 10.21437/Interspeech.2016-408
   Velana M, 2017, LECT NOTES ARTIF INT, V10183, P127, DOI 10.1007/978-3-319-59259-6_11
   Walter Steffen, 2013, 2013 IEEE International Conference on Cybernetics (CYBCO), P128, DOI 10.1109/CYBConf.2013.6617456
   Walter Steffen, 2014, Psychol. Neurosci., V7, P363
   Wang F, 2017, IEEE IMAGE PROC, P1087, DOI 10.1109/ICIP.2017.8296449
   Werner P, 2022, IEEE T AFFECT COMPUT, V13, P530, DOI 10.1109/TAFFC.2019.2946774
   Werner P, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P290, DOI 10.1109/ACIIW.2019.8925061
   Werner P, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.119
   Werner P, 2017, INT CONF AFFECT, P176, DOI 10.1109/ACIIW.2017.8272610
   Werner P, 2017, IEEE T AFFECT COMPUT, V8, P286, DOI 10.1109/TAFFC.2016.2537327
   Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080
   Yang R., 2016, 6 INT C IMAGE PROCES, DOI [10.1109/IPTA.2016.7820930, DOI 10.1109/IPTA.2016.7820930]
   Yen SJ, 2009, EXPERT SYST APPL, V36, P5718, DOI 10.1016/j.eswa.2008.06.108
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
NR 60
TC 4
Z9 4
U1 3
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103743
DI 10.1016/j.jvcir.2022.103743
EA JAN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8G5WB
UT WOS:000920414200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yang, Z
   Huang, ZY
   He, DY
   Zhang, T
   Yang, F
AF Yang, Zhen
   Huang, Zhiyi
   He, Dunyun
   Zhang, Tao
   Yang, Fan
TI Dynamic representation-based tracker for long-term pedestrian tracking
   with occlusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pedestrian tracking with occlusion; Dynamic representation-based tracker
   (DRT); Adaptive representation network (ARN); Pose supervised module
   (PSM)
ID VISUAL TRACKING; OBJECT TRACKING
AB This paper presents a dynamic representation-based tracker (DRT) to handle occlusions in the long-term pedestrian tracking of a single target. In our DRT, an adaptive representation network (ARN) is first constructed to extract multiple features, including classical features such as appearance and pose as well as some vector -format deep features. These features are then stacked to form a dynamic representation so as to convert the target tracking into a matching problem between the target features and candidate features, where the Euclidean distance (ED) and locality-constrained linear coding (LLC) are used as measurements in the decision -making. Next, the target state is determined through a voting procedure according to the feature matching error. Finally, a pose supervised module (PSM) and an IOU filtering module (IFM) are applied, respectively, to refine the target state and to filter out some invalid candidate targets that have been detected. Experimental results on public benchmark datasets show that our DRT is quite robust to complex environments with long-term pedestrian occlusions, and outperforms several existing state-of-the-arts trackers as it produces the best performance on both the pedestrian tracking dataset with occlusion (PTDO) and the pedestrian tracking dataset with occlusion plus (PTDO Plus).
C1 [Yang, Zhen; Huang, Zhiyi; He, Dunyun; Yang, Fan] Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, Nanchang, Peoples R China.
   [Yang, Zhen] Guangdong Atv Acad Performing Arts, Dongguan, Peoples R China.
   [Zhang, Tao] Shanghai Jiao Tong Univ, Shanghai Key Lab Intelligent Sensing & Recognit, Shanghai, Peoples R China.
C3 Jiangxi Science & Technology Normal University; Shanghai Jiao Tong
   University
RP Zhang, T (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Intelligent Sensing & Recognit, Shanghai, Peoples R China.
EM sjtu-zt@sjtu.edu.cn
RI He, Dunyun/HZI-0212-2023
OI He, Dunyun/0000-0001-9553-263X
FU National Natural Science Foundation of China [61866016, 62261026,
   62201343]; Jiangxi Provincial Natural Science Foundation
   [20202BABL202014, 20212BAB202013]; Key Project of Jiangxi Education
   Department [GJJ201107, GJJ190587]; Key Laboratory of System Control and
   Information Processing, Ministry of Education, China [Scip202106]
FX This work was supported by the National Natural Science Foundation of
   China (61866016, 62261026, 62201343), Jiangxi Provincial Natural Science
   Foundation (20202BABL202014, 20212BAB202013), the Key Project of Jiangxi
   Education Department (GJJ201107, GJJ190587), and the Key Laboratory of
   System Control and Information Processing, Ministry of Education, China
   (Scip202106).
CR Bao Q, 2021, INT ARCH ALLERGY IMM, V182, P350, DOI 10.1159/000510966
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bian C, 2016, INT CONF SIGN PROCES, P1067, DOI 10.1109/ICSP.2016.7877993
   Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919
   Chen K, 2019, IEEE ACCESS, V7, P26060, DOI 10.1109/ACCESS.2019.2900296
   Dai P, 2021, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR46437.2021.00247
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Du F, 2020, IEEE T CIRC SYST VID, V30, P1625, DOI 10.1109/TCSVT.2019.2909654
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu Z., 2021, 2021 IEEECVF C COMPU, P10
   Fu ZY, 2019, IEEE T MULTIMEDIA, V21, P2277, DOI 10.1109/TMM.2019.2902480
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He M, 2019, IEEE ACCESS, V7, P89475, DOI 10.1109/ACCESS.2019.2926416
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jing Y., 2021, 2021 IEEECVF C COMPU, P2
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Jing Yongcheng, 2021, P IEEE CVF INT C COM, P5301
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y., 2019, INT C NEUR INF PROC
   Li Y., 2019, AAAI C ARTIFICIAL IN
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Liu QS, 2018, IEEE T CIRC SYST VID, V28, P2826, DOI 10.1109/TCSVT.2017.2708726
   Neubeck A., 2006, 18 INT C PATTERN REC, P375
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Niu XG, 2017, LECT NOTES COMPUT SC, V10636, P44, DOI 10.1007/978-3-319-70090-8_5
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Shen GJ, 2019, IEEE ACCESS, V7, P42718, DOI 10.1109/ACCESS.2019.2892469
   Shuai B, 2021, PROC CVPR IEEE, P12367, DOI 10.1109/CVPR46437.2021.01219
   Simonyan K., 2014, CORR
   Song K, 2020, IEEE T CIRC SYST VID, V30, P4182, DOI 10.1109/TCSVT.2019.2948600
   Sun C, 2017, IEEE T CIRC SYST VID, V27, P2567, DOI 10.1109/TCSVT.2016.2595265
   Valmadre J, 2018, LECT NOTES COMPUT SC, V11207, P692, DOI 10.1007/978-3-030-01219-9_41
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P930, DOI 10.1109/TMM.2018.2869277
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu YP, 2020, IEEE T MULTIMEDIA, V22, P2177, DOI 10.1109/TMM.2019.2953380
   Xingyi Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P474, DOI 10.1007/978-3-030-58548-8_28
   Xiu Y., 2018, Pose Flow: Efficient Online Pose Tracking
   Xu Y., 2020, AAAI C ARTIFICIAL IN
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yin JL, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102832
   Zhai YY, 2018, IEEE ACCESS, V6, P50752, DOI 10.1109/ACCESS.2018.2869766
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang T, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3216532
   Zhang W, 2018, J ENG-JOE, P375, DOI 10.1049/joe.2017.0795
   Zhao SY, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3159179
   Zhou QQ, 2019, IEEE T MULTIMEDIA, V21, P1183, DOI 10.1109/TMM.2018.2875360
NR 60
TC 2
Z9 2
U1 3
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103710
DI 10.1016/j.jvcir.2022.103710
EA DEC 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7K4WU
UT WOS:000905285600001
DA 2024-07-18
ER

PT J
AU Zhu, YJ
   Yang, WZ
   Wang, LJ
   Chen, DY
   Wang, M
   Wei, FY
   KeZiErBieKe, H
   Liao, YY
AF Zhu, Yingjie
   Yang, Wenzhong
   Wang, Liejun
   Chen, Danny
   Wang, Min
   Wei, Fuyuan
   KeZiErBieKe, HaiLaTi
   Liao, Yuanyuan
TI Multiscale Global-Aware Channel Attention for Person Re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Multi-scale; Global-aware; Channel attention
AB Most person re-identification methods are researched under various assumptions. However, viewpoint variations or occlusions are often encountered in practical scenarios. These are prone to intra-class variance. In this paper, we propose a multiscale global-aware channel attention (MGCA) model to solve this problem. It imitates the process of human visual perception, which tends to observe things from coarse to fine. The core of our approach is a multiscale structure containing two key elements: the global-aware channel attention (GCA) module for capturing the global structural information and the adaptive selection feature fusion (ASFF) module for high-lighting discriminative features. Moreover, we introduce a bidirectional guided pairwise metric triplet (BPM) loss to reduce the effect of outliers. Extensive experiments on Market-1501, DukeMTMC-reID, and MSMT17, and achieve the state-of-the-art results on mAP. Especially, our approach exceeds the current best method by 2.0% on the most challenging MSMT17 dataset.
C1 [Zhu, Yingjie; Yang, Wenzhong; Wang, Liejun; Chen, Danny; Wang, Min; Wei, Fuyuan; KeZiErBieKe, HaiLaTi; Liao, Yuanyuan] Xinjiang Univ, Sch Software, Urumqi, Xinjiang, Peoples R China.
   [Zhu, Yingjie; Yang, Wenzhong; Chen, Danny; Wang, Min; Wei, Fuyuan] Xinjiang Univ, Xinjiang Key Lab Multilingual Informat Technol, Urumqi, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Yang, WZ (corresponding author), Xinjiang Univ, Sch Software, Urumqi, Xinjiang, Peoples R China.; Yang, WZ (corresponding author), Xinjiang Univ, Xinjiang Key Lab Multilingual Informat Technol, Urumqi, Xinjiang, Peoples R China.
EM zhuyj_0824@163.com; wljxju@xju.edu.cn; kabuoxygen@163.com;
   wangmin@stu.xju.edu.cn; 641868693@qq.com; hayrat805@163.com;
   liaoyuan@xju.edu.cn
CR Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen GY, 2019, IEEE T IMAGE PROCESS, V28, P4192, DOI 10.1109/TIP.2019.2908062
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Fang PF, 2019, IEEE I CONF COMP VIS, P8029, DOI 10.1109/ICCV.2019.00812
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   GuanshuoWang Yufeng Yuan, 2021, ACM MM
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S., 2021, P IEEECVF INT C COMP, P15013, DOI DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Lai SQ, 2021, IEEE INT CONF COMP V, P4133, DOI 10.1109/ICCVW54120.2021.00461
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Martinel N, 2020, IEEE T IMAGE PROCESS, V29, P7306, DOI 10.1109/TIP.2020.3000904
   Park H, 2020, AAAI CONF ARTIF INTE, V34, P11839
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Ren S., 2015, ADV NEURAL INFORM PR, V28, P91
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shizhen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P647, DOI 10.1007/978-3-030-58539-6_39
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Zeng W., 2022, IEEE INTERNET THINGS
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhao CR, 2020, IEEE T MULTIMEDIA, V22, P3180, DOI 10.1109/TMM.2020.2972125
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2017, Arxiv, DOI arXiv:1701.07732
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zijie Zhuang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P140, DOI 10.1007/978-3-030-58610-2_9
NR 56
TC 3
Z9 3
U1 3
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103714
DI 10.1016/j.jvcir.2022.103714
EA DEC 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7K2MH
UT WOS:000905118700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Rasmussen, T
   Feuchtner, T
   Huang, WD
   Gronbaek, K
AF Rasmussen, Troels
   Feuchtner, Tiare
   Huang, Weidong
   Gronbaek, Kaj
TI Supporting workspace awareness in remote assistance through a flexible
   multi-camera system and Augmented Reality awareness cues
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Remote assistance; Augmented reality; Workspace awareness; Awareness
   cues; Calibration
ID VIEW INDEPENDENCE; COLLABORATION
AB Workspace awareness is critical for remote assistance with physical tasks, yet it remains difficult to facilitate. For example, if the remote helper is limited to the single viewpoint provided by the worker's hand-held or head-mounted camera, she lacks the ability to gain an overview of the workspace. This may be addressed by granting the helper view-independence, e.g., through a multi-camera system. However, it can be cumbersome to set up and calibrate multiple cameras, and it can be challenging for the local worker to identify the current viewpoint of the remote helper. We present CueCam , a multi-camera remote assistance system that supports mutual workspace awareness through a flexible ad-hoc camera calibration and various Augmented Reality cues that communicate the helper's viewpoint and focus. In particular, we propose visual cues presented through a head-mounted Augmented Reality display (Virtual Hand, Color Cue), and sound cues emitted from the cameras' physical locations (Spatial Sound). Findings from a lab study indicate that all proposed cues effectively support the worker's awareness of helper's location and focus, while the Color Cue demonstrated superiority in task performance and preference ratings during a search task.
C1 [Rasmussen, Troels; Feuchtner, Tiare; Gronbaek, Kaj] Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.
   [Huang, Weidong] Univ Technol Sydney, Sydney, Australia.
C3 Aarhus University; University of Technology Sydney
RP Rasmussen, T (corresponding author), Aarhus Univ, Dept Comp Sci, Aarhus, Denmark.
EM troels.rasmussen@cs.au.dk
RI Huang, Weidong/B-7504-2011
OI Huang, Weidong/0000-0002-5190-7839; Feuchtner, Tiare/0000-0002-9922-5538
FU MADE Digital [6151-00006B]
FX This paper has been recommended for acceptance by Dr. Zicheng Liu. The
   work reported here is funded by MADE Digital (Project 6151-00006B).
CR Adcock Matt, 2013, P 12 ACM SIGGRAPH IN, P235
   [Anonymous], 2003, P SIGCHI C HUM FACT
   [Anonymous], 2007, P 19 AUSTRALASIAN C, DOI DOI 10.1145/1324892.1324911
   Aschenbrenner D, 2016, IFAC PAPERSONLINE, V49, P18, DOI 10.1016/j.ifacol.2016.11.116
   Avery B, 2009, IEEE VIRTUAL REALITY 2009, PROCEEDINGS, P79
   ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543
   Fakourfar O, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1548, DOI 10.1145/2858036.2858171
   Fussell SR, 2004, HUM-COMPUT INTERACT, V19, P273, DOI 10.1207/s15327051hci1903_3
   Gao L, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139204
   Gauglitz S., 2014, P 27 ANN ACM S USER, P449
   GAVER W, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P335
   Günther S, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P339, DOI 10.1145/3197768.3201568
   Gutwin C., 2002, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V11, P411, DOI 10.1023/A:1021271517844
   Huang W, 2013, P 2013 C COMP SUPP C, P153, DOI DOI 10.1145/2441955.2441994
   Huang WD, 2019, J VIS COMMUN IMAGE R, V58, P428, DOI 10.1016/j.jvcir.2018.12.010
   Huang WD, 2018, J MULTIMODAL USER IN, V12, P77, DOI 10.1007/s12193-017-0250-2
   Joachimczak M, 2017, P 19 ACM INT C MULT, P514, DOI [10.1145/3136755.3143031, DOI 10.1145/3136755.3143031]
   Kangas J, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188598
   Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300403
   Kim S, 2018, COMPUT SUPP COOP W J, V27, P569, DOI 10.1007/s10606-018-9324-2
   Klemen Lilija H.P., 2020, CHI ACM C HUMAN FACT
   Lanir J., 2013, P SIGCHI C HUM FACT, P2243
   Lee GA, 2018, INT SYM MIX AUGMENT, P153, DOI 10.1109/ISMAR.2018.00051
   Lee GA, 2017, SA'17: SIGGRAPH ASIA 2017 EMERGING TECHNOLOGIES, DOI 10.1145/3132818.3132827
   Mohr P, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376289
   Norris James, 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P627, DOI 10.1145/2207676.2207765
   Norris James, 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1329, DOI DOI 10.1145/2470654.2466174
   Nuernberger B, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P149, DOI 10.1109/3DUI.2016.7460046
   Olin Patrick Aggergaard, 2020, OzCHI '20: Proceedings of the 32nd Australian Conference on Human-Computer Interaction, P112, DOI 10.1145/3441000.3441070
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Piumsomboon T, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00005
   Piumsomboon T, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139200
   Piumsomboon T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300458
   Ranjan A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1177
   Rasmussen TA, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P28, DOI 10.1109/ISMAR-Adjunct.2019.00023
   Rasmussen TA, 2019, LECT NOTES COMPUT SC, V11677, P80, DOI 10.1007/978-3-030-28011-6_6
   Seinfeld S, 2021, HUM-COMPUT INTERACT, V36, P400, DOI 10.1080/07370024.2020.1724790
   Sodhi R. S., 2013, P SIGCHI C HUMAN FAC, P179
   Speicher Maximilian, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3229091
   Tait M, 2015, COMPUT SUPP COOP W J, V24, P563, DOI 10.1007/s10606-015-9231-8
   Teo T, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364238
   Teo T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300431
   Teo T, 2018, PROCEEDINGS OF THE 30TH AUSTRALIAN COMPUTER-HUMAN INTERACTION CONFERENCE (OZCHI 2018), P406, DOI 10.1145/3292147.3292200
   Trepkowski C, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P575, DOI [10.1109/vr.2019.8798312, 10.1109/VR.2019.8798312]
   Wickens C. D., 2002, Theor Issues Ergon Sci, V3, P159, DOI [10.1080/14639220210123806, DOI 10.1080/14639220210123806]
   Yamanashi K., 1996, Human Factors in Computing Systems. Common Ground. CHI 96 Conference Proceedings, P50, DOI 10.1145/238386.238402
   Yang J, 2020, J MULTIMODAL USER IN, V14, P337, DOI 10.1007/s12193-020-00331-1
NR 47
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103655
DI 10.1016/j.jvcir.2022.103655
EA NOV 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600005
OA hybrid
DA 2024-07-18
ER

PT J
AU Jiang, K
   Peng, P
   Lian, YZ
   Xu, WS
AF Jiang, Kai
   Peng, Peng
   Lian, Youzao
   Xu, Weisheng
TI The encoding method of position embeddings in vision transformer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vision transformer; Position embeddings; Gabor filters
AB In contrast to Convolutional Neural Networks (CNNs), Vision Transformers (ViT) cannot capture sequence ordering of input tokens and require position embeddings. As a learnable fixed-dimension vector, the position embedding improves accuracy while limiting the migration of the model between different input sizes. Hence, this paper conducts an empirical study on position embeddings of pre-trained models, which mainly focuses on two questions: (1) What do the position embeddings learn from training? (2) How do the position embeddings affect the self-attention modules?This paper analyzes the pattern of position embedding in pre-trained models and finds that the linear combination of Gabor filters and edge markers can fit the learned position embeddings well. The Gabor filters and edge markers can occupy some channels to append the position information, and the edge markers have flowed to values in self-attention modules. The experimental results can guide future work to choose suitable position embeddings.
C1 [Jiang, Kai; Peng, Peng; Lian, Youzao; Xu, Weisheng] Tongji Univ, Coll Elect & Informat Engn, Dept Control Sci & Engn, Caoan Highway 4800, Shanghai 201804, Peoples R China.
C3 Tongji University
RP Xu, WS (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Dept Control Sci & Engn, Caoan Highway 4800, Shanghai 201804, Peoples R China.
EM jkjiang@tongji.edu.cn; peng.peng@tongji.edu.cn;
   youzaolian@tongji.edu.cn; xuweisheng@tongji.edu.cn
FU Innovation Program of Science and Technology Commission of Shanghai
   Municipality;  [19DZ1209200]
FX Acknowledgments The authors would like to thank the Innovation Program
   of Science and Technology Commission of Shanghai Municipality under
   Grant No. 19DZ1209200. The authors would like to express their gratitude
   to EditSprings (https:// www.editsprings.cn/) for the expert linguistic
   services provided.
CR Bai J, 2019, IEEE IJCNN
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chu X., 2021, arXiv, DOI 10.48550/arXiv.2104.13840
   Chu XX, 2021, Arxiv, DOI [arXiv:2102.10882, DOI 10.48550/ARXIV.2102.10882]
   Cubuk E.D., 2020, ADV NEURAL INFORM PR
   Deng J., 2009, IEEE C COMP VIS PATT
   Devlin J., 2018, BERT PRE TRAINING DE
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Dufter P, 2021, Arxiv, DOI [arXiv:2102.11090, 10.48550/arXiv.2102.11090]
   Fei LK, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500206
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gehring J, 2017, PR MACH LEARN RES, V70
   Hu XD, 2020, DEF TECHNOL, V16, P1116, DOI 10.1016/j.dt.2019.12.002
   Hu Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P386, DOI 10.1109/ICISCE.2016.91
   Huang Zhiheng, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, P3327, DOI [10.18653/v1/2020.findings-emnlp.298, DOI 10.18653/V1/2020.FINDINGS-EMNLP.298, DOI 10.18653/V1/2020.FINDINGSEMNLP.298]
   Islam M., 2021, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li C, 2017, J SUPERCOMPUT, V73, P1532, DOI 10.1007/s11227-016-1840-6
   Li YW, 2021, Arxiv, DOI arXiv:2104.05707
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Liu Z, 2021, Arxiv, DOI [arXiv:2103.14030, DOI 10.48550/ARXIV.2103.14030]
   Loshchilov I., 2018, INT C LEARN REPR ICL, P1
   Luan SZ, 2018, IEEE T IMAGE PROCESS, V27, P4357, DOI 10.1109/TIP.2018.2835143
   Meng F, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010105
   Paszke A, 2019, ADV NEUR IN, V32
   Peng ZL, 2021, Arxiv, DOI arXiv:2105.03889
   Perez Juan C., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P450, DOI 10.1007/978-3-030-58545-7_26
   Shaw P., 2018, P 2018 NAACL, V2, P464, DOI [DOI 10.18653/V1/N18-2074, 10.18653/v1/N18-2074]
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Touvron H, 2021, Arxiv, DOI arXiv:2103.17239
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WH, 2023, Arxiv, DOI arXiv:2106.13797
   Wang WH, 2021, Arxiv, DOI arXiv:2102.12122
   Wang YA, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6840
   Wightman Ross, 2023, Zenodo
   Wu HP, 2021, Arxiv, DOI [arXiv:2103.15808, DOI 10.48550/ARXIV.2103.15808]
   Wu K., 2021, arXiv
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhu MJ, 2021, Arxiv, DOI arXiv:2104.08500
NR 43
TC 4
Z9 4
U1 4
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103664
DI 10.1016/j.jvcir.2022.103664
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500002
DA 2024-07-18
ER

PT J
AU Niu, C
   Shang, JY
   Huang, JC
   Yang, JM
   Song, YT
   Zhou, ZH
   Zhou, GX
AF Niu, Chang
   Shang, Junyuan
   Huang, Junchu
   Yang, Junmei
   Song, Yuting
   Zhou, Zhiheng
   Zhou, Guoxu
TI Unbiased feature generating for generalized zero-shot learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Generalized zero-shot learning; Generative adversarial network; Image
   classification
ID CLASSIFICATION
AB Generalized zero-shot learning (GZSL) aims at training a model on seen data to recognize objects from both seen and unseen classes. Existing generated-based methods show encouraging performance by directly generating unseen samples. However, due to insufficient exploration of unseen label space and limited class-wise semantic descriptions, existing methods still face the bias problem. In this paper, we divide the bias problem into seen-biased and neighbor-biased problems and propose a GZSL method named Unbiased Feature Generating. For the seen-biased problem, we train a classifier in complete label space by introducing the discriminative information contained in fake unseen samples. For the neighbor-biased problem, we generate untypical samples and refine the classification boundaries among neighbor classes. The classifier in complete label space and generator are trained in an iterative process to complement each other. The experimental results on four widely used datasets verify our method achieves encouraging performance compared with the state-of-the-art methods.
C1 [Niu, Chang; Shang, Junyuan; Huang, Junchu; Yang, Junmei; Song, Yuting; Zhou, Zhiheng] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Niu, Chang; Shang, Junyuan; Huang, Junchu; Song, Yuting; Zhou, Zhiheng] South China Univ Technol, Key Lab Big Data & Intelligent Robot, Minist Educ, Guangzhou, Peoples R China.
   [Zhou, Guoxu] Guangdong Univ Technol, Sch Automat, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; Guangdong University of Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM zhouzh@scut.edu.cn
RI Xi, Yang/KEH-5204-2024; xu, lingzhi/JVZ-8748-2024; Zhou,
   zhiheng/HNC-4591-2023; zhou, chen/KBC-4023-2024; Zhou,
   Guoxu/D-2040-2014; Lin, Kuan-Yu/JXM-6653-2024; ying, liu/KEI-0478-2024
OI Niu, Chang/0000-0002-7426-1479; Shang, Junyuan/0000-0003-4301-750X
FU National Key R&D Program of China; Guangdong Provincial Key Laboratory
   of Human Digital Twin; National Natural Science Founda-tion of China; 
   [2022YFF0607000];  [2022B1212010004];  [61871188]
FX Acknowledgments The work is supported by National Key R&D Program of
   China (2022YFF0607000) , Guangdong Provincial Key Laboratory of Human
   Digital Twin (2022B1212010004) , National Natural Science Founda-tion of
   China (61871188) .
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Ba JL, 2015, IEEE I CONF COMP VIS, P4247, DOI 10.1109/ICCV.2015.483
   Bo L, 2021, PROC CVPR IEEE, P16494, DOI 10.1109/CVPR46437.2021.01623
   Bucher M, 2017, IEEE INT CONF COMP V, P2666, DOI 10.1109/ICCVW.2017.308
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Deng J., 2009, IEEE C COMP VIS PATT
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Ding ZM, 2017, PROC CVPR IEEE, P6005, DOI 10.1109/CVPR.2017.636
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354
   Fu ZY, 2015, PROC CVPR IEEE, P2635, DOI 10.1109/CVPR.2015.7298879
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1774
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Gulrajani I, 2017, ADV NEUR IN, V30
   Ji Z, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105847
   Ji Z, 2019, NEUROCOMPUTING, V329, P339, DOI 10.1016/j.neucom.2018.10.069
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li AX, 2020, INT J COMPUT VISION, V128, P2810, DOI 10.1007/s11263-020-01342-x
   Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758
   Li X., 2020, J VIS COMMUN IMAGE R
   Li X., 2020, IMAGE COMMUN, V87
   Li X, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104077
   Li X, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106378
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Liu J., 2020, IMAGE COMMUN, V89
   Liu SC, 2018, ADV NEUR IN, V31
   Norouzi M, 2014, Arxiv, DOI arXiv:1312.5650
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Sun L, 2020, IEEE ACCESS, V8, P119287, DOI 10.1109/ACCESS.2020.3000347
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wah Catherine, 2011, Technical report
   Wan ZY, 2019, ADV NEUR IN, V32
   Wang DH, 2016, AAAI CONF ARTIF INTE, P2145
   Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Zhang HF, 2019, NEUROCOMPUTING, V329, P12, DOI 10.1016/j.neucom.2018.10.043
   Zhang ZM, 2016, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2016.649
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
NR 51
TC 3
Z9 3
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103657
DI 10.1016/j.jvcir.2022.103657
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500006
DA 2024-07-18
ER

PT J
AU Zhu, QX
   Kuang, WL
   Li, ZX
AF Zhu, Qiangxi
   Kuang, Wenlan
   Li, Zhixin
TI Dual attention interactive fine-grained classification network based on
   data augmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data augmentation; Hierarchical training; Denoising autoencoder; Dual
   attention mechanism; Interactive attention
AB The key to fine-grained image classification is to find discriminative regions. Most existing methods only use simple baseline networks or low-recognition attention modules to discover object differences, which will limit the model to finding discriminative regions hidden in images. This article proposes an effective method to solve this problem. The first is a novel layered training method, which uses a new training method to enhance the feature extraction ability of the baseline model. The second step focuses on key regions of the image based on improved long short-term memory (LSTM) and multi-head attention. In the third step, based on the feature map obtained by the dual attention network, spatial mapping is performed by a multi-layer perceptron (MLP). Then the element-by-element mutual multiplication calculation of the channel is performed to obtain a feature map with finer granularity. Finally, the CUB-200-2011, FGVC Aircraft, Stanford Cars, and MedMNIST v2 datasets achieved good performance.
C1 [Zhu, Qiangxi; Kuang, Wenlan; Li, Zhixin] Guangxi Normal Univ, Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Li, Zhixin/ABI-9264-2022
OI Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [62276073, 61966004,
   61866004]; Guangxi Natural Science Foundation [2019GXNSFDA245018];
   Innovation Project of Guangxi Graduate Education [YCBZ2022060]; Guangxi
   "Bagui Scholar'' Teams for Innovation and Research Project; Guangxi
   Talent Highland Project of Big Data Intelligence and Application;
   Guangxi Collaborative Innovation Center of Multi-source Information
   Integration and Intelligent Processing
FX This work is supported by National Natural Science Foundation of China
   (Nos. 62276073, 61966004, 61866004), Guangxi Natural Science Foundation
   (No. 2019GXNSFDA245018), the Innovation Project of Guangxi Graduate
   Education (No. YCBZ2022060), Guangxi "Bagui Scholar'' Teams for
   Innovation and Research Project, Guangxi Talent Highland Project of Big
   Data Intelligence and Application, and Guangxi Collaborative Innovation
   Center of Multi-source Information Integration and Intelligent
   Processing.
CR Branson S, 2014, Arxiv, DOI arXiv:1406.2952
   Chang DL, 2020, IEEE T IMAGE PROCESS, V29, P4683, DOI 10.1109/TIP.2020.2973812
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Fan Zhang, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12572), P136, DOI 10.1007/978-3-030-67832-6_12
   Feurer M, 2015, ADV NEUR IN, V28
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu T, 2019, Arxiv, DOI [arXiv:1901.09891, DOI 10.48550/ARXIV.1901.09891]
   Huang S., 2020, arXiv
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jin HF, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1946, DOI 10.1145/3292500.3330648
   Ju M, 2020, IEEE IMAGE PROC, P703, DOI 10.1109/icip40778.2020.9190875
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XJ, 2021, INT C PATT RECOG, P3660, DOI 10.1109/ICPR48806.2021.9412252
   Li XL, 2020, Arxiv, DOI arXiv:2004.01817
   Li ZC, 2017, IEEE INT CONF COMP V, P1199, DOI 10.1109/ICCVW.2017.145
   Li ZX, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3426974
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu C, 2021, APPL INTELL, V51, P7903, DOI 10.1007/s10489-021-02280-y
   Liu ML, 2016, LECT NOTES COMPUT SC, V10040, P337, DOI 10.1007/978-3-319-48674-1_30
   Liu X, 2017, Arxiv, DOI arXiv:1603.06765
   Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833
   Maji S, 2013, Arxiv, DOI arXiv:1306.5151
   Min SB, 2020, IEEE T IMAGE PROCESS, V29, P4996, DOI 10.1109/TIP.2020.2977457
   Shi XJ, 2015, ADV NEUR IN, V28
   Shroff P, 2020, IEEE COMPUT SOC CONF, P3782, DOI 10.1109/CVPRW50498.2020.00442
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song KY, 2019, IEEE T CIRC SYST VID, V29, P2972, DOI 10.1109/TCSVT.2018.2875449
   Sun M, 2018, LECT NOTES COMPUT SC, V11220, P834, DOI 10.1007/978-3-030-01270-0_49
   Vaswani A, 2017, ADV NEUR IN, V30
   Wah C., 2011, 2010001 CALTECH
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wei HY, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103068
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Xu S., 2021, 2021 IEEE 31 INT WOR, P1
   Yang JC, 2022, Arxiv, DOI arXiv:2110.14795
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yang Z, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103245
   Ye ZH, 2020, IEEE IMAGE PROC, P1851, DOI [10.1109/icip40778.2020.9191018, 10.1109/ICIP40778.2020.9191018]
   Yu C., 2018, P EUROPEAN C COMPUTE, P574
   Zhang F, 2020, Arxiv, DOI [arXiv:2003.09150, 10.48550/arXiv.2003.09150]
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang LB, 2021, IEEE WINT CONF APPL, P3208, DOI 10.1109/WACV48630.2021.00325
   Zhang LB, 2019, IEEE I CONF COMP VIS, P8330, DOI 10.1109/ICCV.2019.00842
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zheng HL, 2019, PROC CVPR IEEE, P5007, DOI 10.1109/CVPR.2019.00515
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zheng YF, 2020, PROTEIN CELL, V11, P740, DOI 10.1007/s13238-020-00762-2
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou T, 2020, MULTIMED TOOLS APPL, V79, P6871, DOI 10.1007/s11042-019-08568-z
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 58
TC 6
Z9 6
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103632
DI 10.1016/j.jvcir.2022.103632
EA SEP 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800005
DA 2024-07-18
ER

PT J
AU Wang, FF
   Chen, J
   Zeng, HQ
   Cai, CH
AF Wang, Feifeng
   Chen, Jing
   Zeng, Huanqiang
   Cai, Canhui
TI Spatial-frequency HEVC multiple description video coding with adaptive
   perceptual redundancy allocation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple description coding; High efficiency video coding (HEVC); Human
   visual system; Error resilience
ID H.264/AVC
AB Multiple description coding (MDC) approaches improve the error-resilient performance of video transmission by introducing redundancy. The existing multiple description video coding (MDVC) schemes are rarely designed for particular coding structure of HEVC, and the characteristics of the human visual system (HVS) are seldom considered. In this paper, a spatial-frequency multiple description video coding with adaptive perceptual redundancy allocation framework, named SF-PMDVC, is proposed for HEVC. For descriptions generation, after polyphase down-sampling in spatial domain, a transformation based on integer discrete cosine transform (DCT) is expended to adapt to the flexible coding unit partitioning process in HEVC, and the frequency coefficients are segmented and mapped to reduce the bitrate of each description. To further improve the performance of MDVC, an adaptive perceptual redundancy allocation strategy based on visual saliency is proposed, which improves the coding efficiency adapting to the visual perception. Experimental results show that the proposed scheme im-proves the error resiliency of HEVC by achieving superior objective and subjective reconstructed video quality as compared to the state-of-the-art MDVC methods for HEVC.
C1 [Wang, Feifeng; Chen, Jing; Zeng, Huanqiang] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
   [Zeng, Huanqiang; Cai, Canhui] Huaqiao Univ, Sch Engn, Quanzhou, Peoples R China.
   [Wang, Feifeng; Chen, Jing; Zeng, Huanqiang; Cai, Canhui] Xiamen Key Lab Mobile Multimedia Commun, Xiamen, Peoples R China.
C3 Huaqiao University; Huaqiao University
RP Chen, J (corresponding author), Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
EM chenjing8005@hqu.edu.cn
RI Zeng, Huanqiang/U-2017-2018
FU National Key R & D Program of China [2021YFE0205400]; National Natural
   Science Foundation of China [61871434, 61976098]; Natural Science
   Foundation for Outstanding Young Scholars of Fujian Province
   [2022J06023]; Natural Science Foundation of Fujian Province
   [2022J01294]; Collaborative Innovation Platform Project of
   Fuzhou-Xiamen-Quanzhou National Independent Innovation Demonstration
   Zone [2021FX03]
FX This work was supported in part by the National Key R & D Program of
   China under the grant 2021YFE0205400, in part by the National Natural
   Science Foundation of China under grants 61871434 and 61976098, in part
   by the Natural Science Foundation for Outstanding Young Scholars of
   Fujian Province under the grant 2022J06023, in part by Natural Science
   Foundation of Fujian Province under the grant 2022J01294, and in part by
   Collaborative Innovation Platform Project of Fuzhou-Xiamen-Quanzhou
   National Independent Innovation Demonstration Zone under the grant
   2021FX03.
CR Adedoyin S, 2008, IEEE T CONSUM ELECTR, V54, P2045, DOI 10.1109/TCE.2008.4711271
   Bai HH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1331
   Bai HH, 2014, IEEE T CIRC SYST VID, V24, P1390, DOI 10.1109/TCSVT.2014.2315770
   Bernardini R, 2004, IEEE IMAGE PROC, P3213
   Carnpana O, 2008, IEEE T CIRC SYST VID, V18, P268, DOI 10.1109/TCSVT.2008.918113
   Crave O, 2010, IEEE T CIRC SYST VID, V20, P769, DOI 10.1109/TCSVT.2010.2045805
   Ding Q, 2021, IEEE T IMAGE PROCESS, V30, P6459, DOI 10.1109/TIP.2021.3092949
   Gallant M, 2001, IEEE IMAGE PROC, P946, DOI 10.1109/ICIP.2001.959203
   Goyal VK, 2001, IEEE T INFORM THEORY, V47, P2199, DOI 10.1109/18.945243
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Guan ZY, 2021, IEEE T PATTERN ANAL, V43, P949, DOI 10.1109/TPAMI.2019.2944806
   Horn R. A., 2013, Topics in Matrix Analysis, V2nd
   Hsiao CW, 2010, IEEE T CIRC SYST VID, V20, P76, DOI 10.1109/TCSVT.2009.2026973
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Karim HA, 2008, IEEE T CONSUM ELECTR, V54, P745, DOI 10.1109/TCE.2008.4560156
   Kazemi M, 2017, IEEE T MULTIMEDIA, V19, P54, DOI 10.1109/TMM.2016.2607342
   Kazemi M, 2012, IEEE T CIRC SYST VID, V22, P202, DOI 10.1109/TCSVT.2011.2159431
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Majid M, 2018, MULTIMED TOOLS APPL, V77, P20955, DOI 10.1007/s11042-017-5499-7
   Radulovic I, 2010, IEEE T CIRC SYST VID, V20, P144, DOI 10.1109/TCSVT.2009.2026815
   Reibman AR, 2002, IEEE T CIRC SYST VID, V12, P193, DOI 10.1109/76.993440
   Seber GAF, 2007, A matrix handbook for statisticians
   Stephan W., 1999, SG16 ITUT RED BANK, P2004
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tsai WJ, 2010, IEEE T CIRC SYST VID, V20, P1822, DOI 10.1109/TCSVT.2010.2087816
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Wang MH, 2021, IEEE SIGNAL PROC LET, V28, P1440, DOI 10.1109/LSP.2021.3092234
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang Y, 2002, IEEE T SIGNAL PROCES, V50, P2843, DOI 10.1109/TSP.2002.804062
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   Xu YY, 2013, IEEE T CIRC SYST VID, V23, P1523, DOI 10.1109/TCSVT.2013.2249018
   Zeeshan M, 2021, TELECOMMUN SYST, V76, P63, DOI 10.1007/s11235-020-00702-9
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhang N, 2008, IEEE T CIRC SYST VID, V18, P646, DOI 10.1109/TCSVT.2008.918848
   Zhu SY, 2020, IEEE T IMAGE PROCESS, V29, P5596, DOI 10.1109/TIP.2020.2984876
NR 36
TC 2
Z9 2
U1 4
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103614
DI 10.1016/j.jvcir.2022.103614
EA AUG 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4H2GN
UT WOS:000849699300003
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Chen, ZZ
   Liu, S
AF Zhang, Yuhang
   Chen, Zhenzhong
   Liu, Shan
TI A multi-stage spatio-temporal adaptive network for video
   super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video super-resolution; Conv LSTM; Inter-frame correlation; Residual
   stacked bidirectional architecture
AB Video super-resolution aims at restoring the spatial resolution of the reference frame based on consecutive input low-resolution (LR) frames. Existing implicit alignment-based video super-resolution methods commonly utilize convolutional LSTM (ConvLSTM) to handle sequential input frames. However, vanilla ConvLSTM processes input features and hidden states independently in operations and has limited ability to handle the inter-frame temporal redundancy in low-resolution fields. In this paper, we propose a multi-stage spatio-temporal adaptive network (MS-STAN). A spatio-temporal adaptive ConvLSTM (STAC) module is proposed to handle input features in low-resolution fields. The proposed STAC module utilizes the correlation between input features and hidden states in the ConvLSTM unit and modulates the hidden states adaptively conditioned on fused spatio-temporal features. A residual stacked bidirectional (RSB) architecture is further proposed to fully exploit the processing ability of the STAC unit. The proposed STAC and RSB architecture promote the vanilla ConvLSTM's ability to exploit the inter-frame correlations, thus improving the reconstruction quality. Furthermore, different from existing methods that only aggregate features from the temporal branch once at a specified stage of the network, the proposed network is organized in a multi-stage manner. The corresponding temporal correlation in features at different stages can be fully exploited. Experimental results on Vimeo-90K-T and o10 datasets show that the proposed method has comparable performance with current video super-resolution methods. The code is available at https://github.com/yhjoker/MS-STAN.
C1 [Zhang, Yuhang; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
   [Liu, Shan] Tencent Media Lab, Palo Alto, CA USA.
C3 Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
EM zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015
OI zhang, yuhang/0000-0002-7726-6726
CR [Anonymous], 2008, P IEEE C COMP VIS PA
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Cao, ARXIV PREPRINT ARXIV
   Chan KCK, 2021, PROC CVPR IEEE, P4945, DOI 10.1109/CVPR46437.2021.00491
   de Vries H, 2017, ADV NEUR IN, V30
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo J, 2017, AAAI CONF ARTIF INTE, P4053
   Haris M, 2019, PROC CVPR IEEE, P3892, DOI 10.1109/CVPR.2019.00402
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Y., 2015, ADV NEURAL INFPROCES, V28, P235
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Isaac JS, 2015, 2015 INT C TECHN SUS, P1, DOI [10.1109/ictsd.2015.7095900, DOI 10.1109/ICTSD.2015.7095900, 10.1109/ICTSD.2015.7095900]
   Isobe Takashi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P645, DOI 10.1007/978-3-030-58610-2_38
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jing Y., 2021, P IEEECVF C COMPUTER, P7772
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li Wenbo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P335, DOI 10.1007/978-3-030-58607-2_20
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   Mao XJ, 2016, ADV NEUR IN, V29
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Rasti P, 2016, LECT NOTES COMPUT SC, V9756, P175, DOI 10.1007/978-3-319-41778-3_18
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi XJ, 2015, ADV NEUR IN, V28
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Wang LD, 2018, IEEE ENG MED BIO, P514, DOI 10.1109/EMBC.2018.8512300
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yi P, 2019, IEEE I CONF COMP VIS, P3106, DOI 10.1109/ICCV.2019.00320
   Yu JS, 2018, IEEE ACCESS, V6, P58096, DOI 10.1109/ACCESS.2018.2873385
   Zhang K., 2020, P IEEE CVF C COMP VI, P492
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YH, 2020, IEEE I C VI COM I PR, P298, DOI 10.1109/vcip49819.2020.9301823
NR 44
TC 1
Z9 1
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103555
DI 10.1016/j.jvcir.2022.103555
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100009
DA 2024-07-18
ER

PT J
AU Belbel, A
   Bekhouch, A
   Doghmane, N
   Harize, S
   Kouadria, N
AF Belbel, Amel
   Bekhouch, Amara
   Doghmane, Noureddine
   Harize, Saliha
   Kouadria, Nasreddine
TI Improved inter-view correlations for low complexity MV-HEVC*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inter-view offset; Disparity estimation; Coding unit; Inter-view
   correlations; Prediction unit
ID MULTIVIEW VIDEO
AB The more advanced multi-view extension, MV-HEVC, effectively exploits visual similarities between multi view videos and enables high compression efficiency. Each view in the multi-view sequence depends on the captured scene, the distance between cameras and recording angles. Increasing the distance between dependent viewpoints generates an inter-view disparity. This impacts the inter-view similarities, affects the disparity estimation and further increases the computational complexity of the MV-HEVC encoder. In this paper, an efficient earlier disparity estimation is proposed for low complexity MV-HEVC. This algorithm is based on reducing the complexity of disparity estimation by eliminating the inter-view offset. Moreover, the inter-view similarities are controlled by considering the reliability of each coding unit size in the search range. This reliability is estimated by reducing the number of searching points within a new limited window. For reliable motion estimation, we further proposed an earlier decision of coding units splitting in the dependent views according to those in the reference views. Experimental results show that the proposed algorithm can achieve an average encoding time saving of 20.37%-40,61% with marginal performance degradation.
C1 [Belbel, Amel; Doghmane, Noureddine; Harize, Saliha; Kouadria, Nasreddine] Univ Badji Mokhtar Annaba, Dept Elect, Annaba 23000, Algeria.
   [Bekhouch, Amara] Univ Souk Ahras, Dept Comp Sci, Souk Ahras 41000, Algeria.
C3 Universite Badji Mokhtar - Annaba; Universite de Souk Ahras Mohammed
   Cherif Messaadia
RP Belbel, A (corresponding author), Univ Badji Mokhtar Annaba, Dept Elect, Annaba 23000, Algeria.
EM amel.belbel@univ-annaba.org; ndoghmane@univ-annaba.org
RI Bekhouch, Amara/KCK-6721-2024
OI Kouadria, Nasreddine/0000-0002-1940-9100
CR Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Bakkouri S, 2020, MULTIMED TOOLS APPL, V79, P6987, DOI 10.1007/s11042-019-08461-9
   Bekhouch A, 2016, IEEE T CONSUM ELECTR, V62, P437, DOI 10.1109/TCE.2016.7838097
   Bekhouch A, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043010
   Belbel A, 2020, INT SYMP WIREL, DOI 10.1109/wpmc50192.2020.9309453
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Hannuksela MM, 2015, IEEE IMAGE PROC, P2154
   Jiang GY, 2019, SIGNAL PROCESS-IMAGE, V70, P199, DOI 10.1016/j.image.2018.10.002
   Khan SN, 2021, IEEE ACCESS, V9, P150234, DOI 10.1109/ACCESS.2021.3125962
   Lee CC, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.18
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Muller K, 2014, ITU-T SG 16 WP 3 and ISO/IEC JTC 1/SC 29/WG 11, JCT3v, VG1100, P1
   Onural L., 2004, EWIMT
   Pan ZQ, 2020, MULTIMED TOOLS APPL, V79, P4297, DOI 10.1007/s11042-018-6830-7
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Smolic A., 2007, ISOIEC JTC1SC29WG11, P6
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tanimoto Masayuki, 2017, IEIE Transactions on Smart Processing & Computing, V6, P415, DOI 10.5573/IEIESPC.2017.6.6.415
   Vetro A, 2012, PROC SPIE, V8499, DOI 10.1117/12.945926
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang PC, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P217, DOI 10.1109/SmartCity.2015.74
   Wang Y, 2012, IEEE T CIRC SYST VID, V22, P989, DOI 10.1109/TCSVT.2012.2186745
   Zhang QW, 2019, J REAL-TIME IMAGE PR, V16, P1909, DOI 10.1007/s11554-017-0692-5
NR 24
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103525
DI 10.1016/j.jvcir.2022.103525
EA MAY 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1V1LX
UT WOS:000805861200005
DA 2024-07-18
ER

PT J
AU Xing, FY
   Yan, XH
   Yu, L
   Sun, YY
AF Xing, Fengyue
   Yan, Xuehu
   Yu, Long
   Sun, Yuyuan
TI Information hiding in the sharing domain*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Random element utilization model; Information
   hiding
ID EFFICIENT
AB Secret image sharing (SIS) can divide a secret image into several shadow images for protection. Information hiding in the sharing domain (IHSD) fuses SIS and information hiding (IH) to simultaneously share any secret image and hide any information, and this technique can be applied in cloud computing, law enforcement and medical diagnoses. IHSD not only marks shadow images with information to prevent malicious tampering and for convenient management, search and identification but also enhances the robustness of IH. In this paper, we first introduce a formal definition of IHSD. Then, we describe a general IHSD model and algorithms with a concrete example in detail. In IHSD, we design the random element utilization model to control the random pixels generated from SIS. Then, we obtain shadow images with hidden information to realize SIS and IH simultaneously. The inputs of SIS with secret images, steganography and extra information in algorithms are without any limitations. Theoretical analyses, experiments and comparisons are presented to prove the effectiveness and feasibility of IHSD.
C1 [Yan, Xuehu] Natl Univ Def Technol, Hefei 230037, Peoples R China.
   Anhui Prov Key Lab Cyberspace Secur Situat Awarene, Hefei 230037, Peoples R China.
C3 National University of Defense Technology - China
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Peoples R China.
EM yanxh17@nudt.edu.cn
RI Yu, Long/GRR-6500-2022
OI Yu, Long/0000-0001-7385-7644
FU Programs of the National University of Defense Technology; National
   Natural Science Foundation of China [61602491]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. We are grateful to Prof. Ching-Nung Yang for his
   discussions and suggestions. This work is supported by the Programs of
   the National University of Defense Technology and the National Natural
   Science Foundation of China (Grant Number: 61602491) .
CR Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chih-Ching Thien, 2002, Computers & Graphics, V26, P765, DOI 10.1016/S0097-8493(02)00131-0
   Gong QH, 2019, IEEE ACCESS, V7, P113216, DOI 10.1109/ACCESS.2019.2934999
   He XY, 2019, MULTIMED TOOLS APPL, V78, P29137, DOI 10.1007/s11042-018-6589-x
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Lee C-F, 2020, ICFET 2020 2020 6 IN
   Li XY, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/6989452
   Li ZH, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8847559
   Liu YH, 2020, MULTIMED TOOLS APPL, V79, P17281, DOI 10.1007/s11042-019-08526-9
   Luo GF, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-019-2413-4
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Maniriho P, 2019, J KING SAUD UNIV-COM, V31, P335, DOI 10.1016/j.jksuci.2018.01.011
   Ren S, 2020, IEEE ACCESS, V8, P214992, DOI 10.1109/ACCESS.2020.3040005
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Su CF, 2020, QUANTUM INF PROCESS, V19, DOI 10.1007/s11128-019-2523-z
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Wu XT, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107768
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Yan X., 2019, IET IMAGE PROCESS, V14
   Yan XH, 2020, IEEE T INF FOREN SEC, V15, P3848, DOI 10.1109/TIFS.2020.3001735
   Yan XH, 2018, IEEE ACCESS, V6, P45246, DOI 10.1109/ACCESS.2018.2865421
   Yan XH, 2018, INT J DIGIT CRIME FO, V10, P66, DOI 10.4018/IJDCF.2018070106
   Yu YQ, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/6627178
   Zhang X, 2012, REVERSIBLE DATA HIDI
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 30
TC 5
Z9 5
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103520
DI 10.1016/j.jvcir.2022.103520
EA MAY 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1V1LX
UT WOS:000805861200001
OA hybrid
DA 2024-07-18
ER

PT J
AU He, ZY
   Jiang, GY
   Yu, M
   Jiang, ZD
   Peng, ZJ
   Chen, F
AF He, Zhouyan
   Jiang, Gangyi
   Yu, Mei
   Jiang, Zhidi
   Peng, Zongju
   Chen, Fen
TI TGP-PCQA: Texture and geometry projection based quality assessment for
   colored point clouds
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Colored point cloud; Visual quality assessment; Texture and geometry
   projection; Objective quality assessment
ID SIMILARITY; ERROR
AB Colored point cloud (PC) will inevitably encounter distortion during its acquisition, processing, coding and transmission, which may affect the visual quality of the colored PC. Therefore, it is necessary to design an effective tool for colored PC quality assessment (PCQA). In this paper, considering the mapping relationship of perception between the colored PC and its corresponding projection images, we propose a novel PCQA method based on texture and geometry projection (denoted as TGP-PCQA). The main idea of the proposed TGP-PCQA method is to obtain texture and geometry projection maps from different perspectives for evaluating the colored PC. Specifically, 4D tensor decomposition is used to obtain the combination and difference information between the reference and distorted texture projection maps for mainly characterizing texture distortion of colored PC. Meanwhile, the edge features of the geometry projection map are calculated to measure the global or local geometry distortion. All of the extracted features are combined to predict an overall quality of colored PC. In addition, this paper establishes a multi-distorted colored PC database named CPCD2.0 with compression distortions and Gaussian noise, which orients to the influence of both geometry and texture components in distortion. Experimental results on two open subjective evaluation databases (IRPC and SJTU-PCQA) and the self-built CPCD2.0 database show that the proposed TGP-PCQA method outperforms the state-of-the-art PCQA methods. We are also providing the self-built CPCD2.0 database free of charge at https://github.com/cherry041 5/CPCD2.0.
C1 [He, Zhouyan; Jiang, Gangyi; Yu, Mei; Jiang, Zhidi] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [Peng, Zongju; Chen, Fen] Chongqing Univ Technol, Sch Elect & Elect Engn, Chongqing 400054, Peoples R China.
C3 Ningbo University; Chongqing University of Technology
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM jianggangyi@nbu.edu.cn
RI jiang, gang/KII-8233-2024; zhouyan, he/GXM-4974-2022
FU National Natural Science Foundation of China [61871247, 61931022,
   62071266]; Nat-ural Science Foundation of Ningbo [202003 N4088]; K.C.
   Wong Magna Fund of Ningbo University
FX Acknowledgements The authors thank the relevant scholars for providing
   the point cloud data, which has been used to construct the colored point
   cloud subjec-tive evaluation database. The authors also thank the
   relevant scholars with their subjective evaluation databases to test the
   proposed method. This work was supported by the National Natural Science
   Foundation of China under Grant Nos. 61871247, 61931022 and 62071266,
   the Nat-ural Science Foundation of Ningbo (202003 N4088) . It was also
   spon-sored by the K.C. Wong Magna Fund of Ningbo University.
CR 3DG Group, 2019, JTC1SC29WG11 ISOIEC
   3DG Group, 2019, N18665 ISOIEC JTC 1S
   Alexiou E., 2018, IEEE INT CONF MULTI
   Alexiou E., 2019, INT WORK QUAL MULTIM, P1, DOI [DOI 10.1109/qomex.2019.8743277, 10.1109/QoMEX.2019.8743277]
   Alexiou E., 2017, P 9 INT C QUAL MULT, P1
   Alexiou E, 2018, INT WORK QUAL MULTIM, P132
   Alexiou E, 2018, IEEE INT CON MULTI
   Alexiou E, 2017, IEEE INT WORKSH MULT
   [Anonymous], 2012, ITU-R BT.500-13
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Charles L, JPEG PLENO DATABASE
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Corsini M, 2013, COMPUT GRAPH FORUM, V32, P101, DOI 10.1111/cgf.12001
   de Queiroz R. L., 2018, M78030 ISOIEC JTC1SC
   Dong L, 2015, IEEE T MULTIMEDIA, V17, P2174, DOI 10.1109/TMM.2015.2484221
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gu S, 2020, IEEE SIGNAL PROC LET, V27, P176, DOI 10.1109/LSP.2019.2963793
   Gu S, 2020, IEEE T IMAGE PROCESS, V29, P796, DOI 10.1109/TIP.2019.2936738
   He Z., 2020, COLOR POINT CLOUD DA
   Hua L., 2020, PROC SPIE, P11550
   Javaheri Alireza, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P1, DOI 10.1109/ICMEW.2017.8026263
   Javaheri A., 2019, 1 RENDERING POINT CL
   Kovesi P., 1999, Videre, V1
   Lavoué G, 2006, PROC SPIE, V6312, DOI 10.1117/12.686964
   Li L, 2021, IEEE T MULTIMEDIA, V23, P2806, DOI 10.1109/TMM.2020.3016894
   Li L, 2021, IEEE T CIRC SYST VID, V31, P326, DOI 10.1109/TCSVT.2020.2966118
   Lin Y., 2019, P IEEE INT C MULT EX
   Lin YY, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22020190
   Mekuria R., 2016, Standard ISO/IEC JTC1/SC29/WG11 MPEG N16332
   Meynet G, 2020, INT WORK QUAL MULTIM, DOI 10.1109/qomex48832.2020.9123147
   Meynet G, 2019, INT WORK QUAL MULTIM
   MPEG 3DG, 2017, N16716 MPEG 3DG ISOI
   Schwarz S, 2019, IEEE J EM SEL TOP C, V9, P133, DOI 10.1109/JETCAS.2018.2885981
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Su HL, 2019, IEEE IMAGE PROC, P3182, DOI [10.1109/ICIP.2019.8803298, 10.1109/icip.2019.8803298]
   Tian D, 2017, IEEE IMAGE PROC, P3460, DOI 10.1109/ICIP.2017.8296925
   Torlig E. M., 2018, P INT C APPL DIG IM
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu YQ, 2021, IEEE T CIRC SYST VID, V31, P1968, DOI 10.1109/TCSVT.2020.3015901
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang Q., SHANGHAI JIAO TONG U
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang J, 2014, 2014 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), VOLS 1-2, P827, DOI 10.1109/ICALIP.2014.7009910
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 48
TC 7
Z9 8
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103449
DI 10.1016/j.jvcir.2022.103449
EA FEB 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800003
DA 2024-07-18
ER

PT J
AU Dai, Y
   Yang, L
AF Dai, Yuan
   Yang, Long
TI Detecting moving object from dynamic background video sequences via
   simulating heat conduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving object detection; Dynamic background; Heat conduction; Entropy;
   K-means clustering
ID SUBTRACTION; SEGMENTATION; ENHANCEMENT; IMAGE; PIXEL
AB Moving object detection is one of the essential tasks for surveillance video analysis. The dynamic background often composed by waving trees, rippling water or fountains, etc. in nature scene greatly interferes with the detection of moving objects in the form of noise. In this paper, a method simulating heat conduction is proposed to extract moving objects from dynamic background video sequences. Based on the visual background extractor (ViBe) with an adaptable distance threshold, we design a temperature field relying on the generated mask image to distinguish between the moving objects and the noise caused by dynamic background. In temperature field, a brighter pixel is associated with more energy. It will transfer a certain amount of energy to its neighboring darker pixels. Through multiple steps of energy transfer the noise regions loss more energy so that they become darker than the detected moving objects. After heat conduction, K-Means algorithm with the customized initial clustering centers is utilized to separate the moving objects from background. We test our method on many videos with dynamic background from public datasets. The results show that the proposed method is feasible and effective for moving object detection from dynamic background sequences.
C1 [Dai, Yuan; Yang, Long] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
C3 Northwest A&F University - China
RP Yang, L (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Shaanxi, Peoples R China.
EM yl@nwafu.edu.cn
FU NSFC, China [61702422]; Chinese Universities Scientific Fund
   [2452018146]
FX Acknowledgments The authors would like to thank all the anonymous
   reviewers for their comments. This work was partly supported by NSFC,
   China (No. 61702422) and the Chinese Universities Scientific Fund (No.
   2452018146) .
CR Akilan T, 2018, INFORM SCIENCES, V430, P414, DOI 10.1016/j.ins.2017.11.062
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Chen XYL, 2021, IEEE ROBOT AUTOM LET, V6, P6529, DOI 10.1109/LRA.2021.3093567
   Chen YY, 2019, IEEE T CIRC SYST VID, V29, P2567, DOI 10.1109/TCSVT.2017.2770319
   De Gregorio M, 2014, IEEE COMPUT SOC CONF, P409, DOI 10.1109/CVPRW.2014.66
   Dey B, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2445631
   Ge WF, 2016, PATTERN RECOGN, V59, P112, DOI 10.1016/j.patcog.2016.01.031
   Haines TSF, 2012, LECT NOTES COMPUT SC, V7575, P99, DOI 10.1007/978-3-642-33765-9_8
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Incropera F., 2011, Introduction to heat transfer
   Isik S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023002
   Jiang SQ, 2018, IEEE T CIRC SYST VID, V28, P2105, DOI 10.1109/TCSVT.2017.2711659
   Jiao SM, 2019, OPT EXPRESS, V27, P12841, DOI 10.1364/OE.27.012841
   Kaewtrakulpong P., 2002, VIDEO BASED SURVEILL, V11, P125
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lee SH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050621
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Liu RR, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030703
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mittal A, 2004, PROC CVPR IEEE, P302
   Mondejar-Guerra V., 2019, British Machine Vision Conference, P266
   Sanches SRR, 2019, APPL INTELL, V49, P1771, DOI 10.1007/s10489-018-1346-4
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI [10.1109/WACV45572.2020.9093464, 10.1109/wacv45572.2020.9093464]
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Vosters L. P. J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P384, DOI 10.1109/AVSS.2010.72
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wu MJ, 2010, AEU-INT J ELECTRON C, V64, P739, DOI 10.1016/j.aeue.2009.05.004
   Yang SY, 2018, MEMET COMPUT, V10, P53, DOI 10.1007/s12293-017-0225-6
   [姚杰 Yao Jie], 2007, [作物杂志, Crops], P1
   Yao S., 2017, INT J GEO INF, V6, P1
   Zeng Z, 2016, COMPUT VIS IMAGE UND, V152, P58, DOI 10.1016/j.cviu.2016.08.009
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 44
TC 2
Z9 2
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103439
DI 10.1016/j.jvcir.2022.103439
EA JAN 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800007
DA 2024-07-18
ER

PT J
AU Yang, JL
   Li, YH
   Yang, L
AF Yang, Jinglun
   Li, Youhua
   Yang, Lu
TI Shape transformer nets: Generating viewpoint-invariant 3D shapes from a
   single image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D shape generation; Invariant viewpoint; Disentanglement; B-spline
   surfaces
ID RECONSTRUCTION
AB Single-view 3D shapes generation has achieved great success in recent years. However, current methods always blind the learning of shapes and viewpoints. The generated shape only fit the observed viewpoints and would not be optimal from unknown viewpoints. In this paper, we propose a novel encoder-decoder based network which contains a disentangled transformer to generate the viewpoint-invariant 3D shapes. The differentiable and parametric Non-uniform B-spline (NURBS) surface generation and 3D-to-3D viewpoint transformation are incorporated to learn the viewpoint-invariant shape and the camera viewpoint, respectively. Our new framework allows us to learn the latent geometric parameters of shapes and viewpoints without knowing the ground truth viewpoint. That can simultaneously generate camera-viewpoint and viewpoint-invariant 3D shapes of the object. We analyze the effects of disentanglement and show both quantitative and qualitative results of shapes generated at various unknown viewpoints.
C1 [Yang, Jinglun; Li, Youhua; Yang, Lu] Univ Elect Sci & Technol China, Sch Automat Engn, 2006 Xiyuan Ave, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Yang, L (corresponding author), Univ Elect Sci & Technol China, Sch Automat Engn, 2006 Xiyuan Ave, Chengdu 611731, Peoples R China.
EM yanglu@uestc.edu.cn
RI Jin, Ling/G-3285-2013
OI Jin, Ling/0000-0003-1267-7396
CR Aszodi B., 2004, NURBS FAIRING KNOT V
   Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Chang A. X., 2015, ARXIV
   Chen X, 2016, ADV NEUR IN, V29
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dimitrov A, 2016, COMPUT-AIDED CIV INF, V31, P483, DOI 10.1111/mice.12192
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Farin G., 2001, Curves and Surfaces for CAGD: A Practical Guide, Vfifth
   Feng LB, 2016, J VIS COMMUN IMAGE R, V40, P831, DOI 10.1016/j.jvcir.2016.08.012
   FREEMAN WT, 1994, NATURE, V368, P542, DOI 10.1038/368542a0
   Galassi F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190650
   Gao J., 2019, ARXIV190702724
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Grant E, 2016, LECT NOTES COMPUT SC, V9915, P266, DOI 10.1007/978-3-319-49409-8_22
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Han B, 2011, J VIS COMMUN IMAGE R, V22, P421, DOI 10.1016/j.jvcir.2011.03.006
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kanazawa Angjoo, 2018, P EUR C COMP VIS
   Kar A, 2015, PROC CVPR IEEE, P1966, DOI 10.1109/CVPR.2015.7298807
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kratochvil BE, 2010, J MICROSC-OXFORD, V237, P122, DOI 10.1111/j.1365-2818.2009.03313.x
   Kulkarni TD, 2015, ADV NEUR IN, V28
   Liao Y.-L., 2018, ARXIV PREPRINT ARXIV
   Lin CH, 2018, AAAI CONF ARTIF INTE, P7114
   Liu ZJ, 2019, ADV NEUR IN, V32
   Makhzani A., 2015, ARXIV
   Mandikal P, 2019, IEEE WINT CONF APPL, P1052, DOI 10.1109/WACV.2019.00117
   Moriconi S, 2015, IEEE ENG MED BIO, P4222, DOI 10.1109/EMBC.2015.7319326
   Ong EJ, 2006, COMPUT VIS IMAGE UND, V104, P178, DOI 10.1016/j.cviu.2006.08.004
   Peng WL, 2016, NEUROCOMPUTING, V179, P228, DOI 10.1016/j.neucom.2015.11.090
   Perra C, 2016, INT CONF IMAG PROC, DOI 10.1109/ICMEW.2016.7574671
   Pontes JK, 2019, LECT NOTES COMPUT SC, V11361, P365, DOI 10.1007/978-3-030-20887-5_23
   Reed S, 2014, PR MACH LEARN RES, V32, P1431
   Rezende D.J., 2016, ADV NEURAL INFORM PR, P4996
   Riegler G, 2017, INT CONF 3D VISION, P57, DOI 10.1109/3DV.2017.00017
   Rock J, 2015, PROC CVPR IEEE, P2484, DOI 10.1109/CVPR.2015.7298863
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szeliski R, 2010, COMPUTER VISION ALGO, P31
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Tatarchenko M, 2016, LECT NOTES COMPUT SC, V9911, P322, DOI 10.1007/978-3-319-46478-7_20
   Tehrani M.P., 2012, 3DTV C TRUE VIS CAPT, P1
   Toponogov V.A., 2006, DIFFERENTIAL GEOMETR
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wolff K, 2016, INT CONF 3D VISION, P118, DOI 10.1109/3DV.2016.20
   WU C., 2008, P CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587501
   Xing X., 2018, ARXIV PREPRINT ARXIV
   Yan RJ, 2016, COMPUT AIDED DESIGN, V81, P14, DOI 10.1016/j.cad.2016.08.007
   Yan XC, 2016, ADV NEUR IN, V29
   Yang J., 2015, Advances in Neural Information Processing Systems, P1099
   Yang L, 2016, IEEE T CIRC SYST VID, V26, P903, DOI 10.1109/TCSVT.2015.2424052
   Yang L, 2010, IEEE IMAGE PROC, P1785, DOI 10.1109/ICIP.2010.5650222
   Yang L, 2010, J VIS COMMUN IMAGE R, V21, P542, DOI 10.1016/j.jvcir.2009.09.009
   Yanpeng C., 2009, IEEE Workshop on Applications of Computer Vision (WACV), P1
NR 53
TC 1
Z9 1
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103345
DI 10.1016/j.jvcir.2021.103345
EA OCT 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WP1JM
UT WOS:000712896500004
DA 2024-07-18
ER

PT J
AU Shi, ZF
   Sun, C
   Cao, QJ
   Wang, Z
   Fan, QQ
AF Shi, Zaifeng
   Sun, Cheng
   Cao, Qingjie
   Wang, Zhe
   Fan, Qiangqiang
TI Residual attention-based tracking-by-detection network with
   attention-driven data augmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Data augmentation; Attention mechanism; Deep learning
ID VISUAL TRACKING; ROBUST TRACKING; OBJECT TRACKING
AB Tracking-by-detection (TBD) is a significant framework for visual object tracking. However, current trackers are usually updated online based on random sampling with a probability distribution. The performance of the learning-based TBD trackers is limited by the lack of discriminative features, especially when the background is full of semantic distractors. We propose an attention-driven data augmentation method, in which a residual attention mechanism is integrated into the TBD tracking network as supplementary references to identify discriminative image features. A mask generating network is used to simulate changes in target appearances to obtain positive samples, where attention information and image features are combined to identify discriminative features. In addition, we propose a method for mining hard negative samples, which searches for semantic distractors with the response of the attention module. The experiments on the OTB2015, UAV123, and LaSOT benchmarks show that this method achieves competitive performance in terms of accuracy and robustness.
C1 [Shi, Zaifeng; Sun, Cheng; Wang, Zhe; Fan, Qiangqiang] Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
   [Cao, Qingjie] Tianjin Normal Univ, Sch Math Sci, Tianjin 300387, Peoples R China.
C3 Tianjin University; Tianjin Normal University
RP Shi, ZF (corresponding author), Tianjin Univ, Sch Microelect, Tianjin 300072, Peoples R China.
EM shizaifeng@tju.edu.cn; suncheng@tju.edu.cn; qingjiecao@tjnu.edu.cn;
   wang_zhe@tju.edu.cn; qiangqiangfan@tju.edu.cn
OI Cao, Qingjie/0000-0002-7087-2651; Shi, Zaifeng/0000-0002-3851-5697
FU National Natural Science Foundation of China [62071326, 61674115]
FX This paper was supported by the National Natural Science Foundation of
   China (No. 62071326 and No. 61674115).
CR Ba J., 2015, P ICLR, P1, DOI DOI 10.1016/J.JCYT.2014.02.008
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Du YH, 2020, NEUROCOMPUTING, V384, P67, DOI 10.1016/j.neucom.2019.12.022
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kim HI, 2018, IEEE SIGNAL PROC LET, V25, P1029, DOI 10.1109/LSP.2018.2835768
   Koschan A, 2003, PATTERN RECOGN LETT, V24, P1751, DOI 10.1016/S0167-8655(02)00330-6
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu XM, 2007, IEEE I CONF COMP VIS, P660
   Lu XK, 2019, NEUROCOMPUTING, V349, P133, DOI 10.1016/j.neucom.2019.02.021
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Pu S., 2018, ADV NEURAL INFORM PR, V31, P1931, DOI DOI 10.1016/J.PATCOG.2018.10.005
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tang F, 2019, NEUROCOMPUTING, V358, P369, DOI 10.1016/j.neucom.2019.05.063
   Tian M, 2007, LECT NOTES COMPUT SC, V4843, P355
   Tian S, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102576
   Vincze M, 2001, PATTERN RECOGN, V34, P487, DOI 10.1016/S0031-3203(99)00230-7
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang X, 2018, PROC CVPR IEEE, P4864, DOI 10.1109/CVPR.2018.00511
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang YD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091939
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 44
TC 2
Z9 2
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103312
DI 10.1016/j.jvcir.2021.103312
EA SEP 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA3DL
UT WOS:000702769700001
DA 2024-07-18
ER

PT J
AU Peng, JJ
   Jiang, GQ
   Wang, HB
AF Peng, Jinjia
   Jiang, Guangqi
   Wang, Huibing
TI Generalized multiple sparse information fusion for vehicle
   re-identification*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vehicle re-identification; Hierarchical attention network; Multi-views
AB Vehicle re-identification (reID) aims to search the target vehicle in a non-overlapping multi-camera network, which is important for the intelligent analysis in large scale of surveillance videos. Many existing methods have employed various techniques to achieve discriminative information. However, those methods always focus on the description of one view for the same vehicle images. Hence, a generated multiple sparse information fusion method is proposed for exploiting latent features from multi-views, which employs three different deep networks to extract multiple features from coarse to fine. And these features are regarded as multi-view features. Besides, to fuse these features reasonably, the paper transfers various features into a common space for better seeking distinctive features. Especially, besides ResNet, two feature learning networks are proposed to learn different features, respectively. One is designed to learn robust feature by dropping some features randomly when training the reID model. Another is to combine various salient features from different layers, which forms strong features for the reID task. Moreover, comprehensive experimental results have demonstrated that our proposed method can achieve competitive performances on benchmark datasets VehicleID and VeRi-776.
C1 [Peng, Jinjia] Hebei Univ, Sch Cyber Secur & Comp, Baoding, Hebei, Peoples R China.
   [Jiang, Guangqi; Wang, Huibing] Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian, Liaoning, Peoples R China.
C3 Hebei University; Dalian Maritime University
RP Peng, JJ (corresponding author), Hebei Univ, Sch Cyber Secur & Comp, Baoding, Hebei, Peoples R China.; Wang, HB (corresponding author), Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian, Liaoning, Peoples R China.
EM jinjiapeng@dlmu.edu.cn; guangqi-j@dlmu.edu.cn; huibing.wang@dlmu.edu.cn
FU National Natural Science Foundation of China [62002041]; Fundamental
   Research Funds for the Central Universities Grant [3132021238]; Liaoning
   Revitalization Talents Program [XLYC1908007]; Dalian Science and
   Technology Innovation Fund [2019J11CY001]
FX Jinjia Peng and Guangqi Jiang contribute equally. This work was
   supported by National Natural Science Foundation of China (No.62002041)
   , Fundamental Research Funds for the Central Univer-sities Grant
   (No.3132021238) , by the Liaoning Revitalization Talents Program
   (No.XLYC1908007) and by the Dalian Science and Technology Innovation
   Fund (No.2019J11CY001) .
CR [Anonymous], 2018, 32 AAAI C ART INT
   Bai Y, 2018, IEEE T MULTIMEDIA, V20, P2385, DOI 10.1109/TMM.2018.2796240
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo H., IEEE T IMAGE PROCESS
   He B, 2019, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2019.00412
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Khorramshahi Pirazh, ARXIV PREPRINT ARXIV
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XB, 2018, IEEE INT CON MULTI
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Lou YH, 2019, IEEE T IMAGE PROCESS, V28, P3794, DOI 10.1109/TIP.2019.2902112
   Peng JJ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P913
   Serra A, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0680-3
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Wang H., IEEE T MULTIMEDIA
   Wang HB, 2021, NEUROCOMPUTING, V438, P55, DOI 10.1016/j.neucom.2020.06.148
   Wang HB, 2020, IEEE MULTIMEDIA, V27, P112, DOI 10.1109/MMUL.2020.2999464
   Wang HB, 2020, IEEE T VEH TECHNOL, V69, P10484, DOI 10.1109/TVT.2020.3009162
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Wei W, 2019, NEUROCOMPUTING, V368, P11, DOI 10.1016/j.neucom.2019.08.047
   Wei XS, 2019, LECT NOTES COMPUT SC, V11362, P575, DOI 10.1007/978-3-030-20890-5_37
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu L, 2019, IEEE T NEUR NET LEAR, V30, P3347, DOI 10.1109/TNNLS.2019.2891244
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu MJ, 2020, LECT NOTES COMPUT SC, V11962, P88, DOI 10.1007/978-3-030-37734-2_8
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Zapletal D, 2016, IEEE COMPUT SOC CONF, P1568, DOI 10.1109/CVPRW.2016.195
   Zhang YH, 2017, IEEE INT CON MULTI, P1386, DOI 10.1109/ICME.2017.8019491
   Zhou Y., 2017, 1 AS AUSTR C PREC PA, P1, DOI DOI 10.5244/C.31.186
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhou Yi, 2018, IEEE Trans Image Process, V27, P3275, DOI 10.1109/TIP.2018.2819820
   Zhu JQ, 2020, IEEE T INTELL TRANSP, V21, P410, DOI 10.1109/TITS.2019.2901312
NR 44
TC 6
Z9 6
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103207
DI 10.1016/j.jvcir.2021.103207
EA JUL 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900011
DA 2024-07-18
ER

PT J
AU Zhang, DH
   Zhu, HB
   Liu, SL
   Wei, X
AF Zhang, Denghui
   Zhu, Hongbin
   Liu, Shenglong
   Wei, Xu
TI HP-VCS: A high-quality and printer-friendly visual cryptography scheme*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography scheme; Image security; Halftoning; Color VCS
AB Visual Cryptography Scheme (VCS) is a secret-sharing scheme which aims to encrypt a secret message into multiple shares and transmit them to participants over an untrusted communication channel. Although human vision can easily reveal the secret message by stacking a sufficient number of shares, this scheme reduces the visual quality of recovered images. This paper presents a novel high-quality and printer-friendly VCS. When providing high-quality recovery, this scheme keeps the size of the shares the same as the secret image. Experimental results show that, compared with previous work, the proposed scheme significantly improves the performance of recovered images.
C1 [Zhang, Denghui] Guangzhou Univ, Cyberspace Inst Adv Technol, Guangzhou 510006, Peoples R China.
   [Wei, Xu] Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China.
   [Zhang, Denghui] Huakong TsingJiao Informat Sci Beijing Ltd TsingJ, Beijing 100084, Peoples R China.
   [Zhu, Hongbin; Liu, Shenglong] Big Data Ctr State Grid Corp China, Beijing 100031, Peoples R China.
C3 Guangzhou University; Tsinghua University
RP Wei, X (corresponding author), Tsinghua Univ, Inst Interdisciplinary Informat Sci, Beijing 100084, Peoples R China.
EM zhang.dh@outlook.com; hbzhu@sgcc.com.cn; shenglong-liu@sgcc.com.cn;
   weixu@tsinghua.edu.cn
OI Zhang, Denghui/0000-0002-8452-5925
FU National Natural Science fundation of China (NSFC) [61532001]; Tsinghua
   Initiative Research Program Grant [20151080475]; Huawei; Ant Financial;
   Nanjing Turing AI Institute
FX This work was supported in part by the National Natural Science
   fundation of China (NSFC) Grant 61532001, Tsinghua Initiative Research
   Program Grant. 20151080475, and gift funds from Huawei, Ant Financial
   and Nanjing Turing AI Institute.
CR Andrabi S.J., 2015, 11 S USABLE PRIVACY, P89
   [Anonymous], 2013, 2013 26 IEEE CAN C E, DOI [DOI 10.1109/CCECE.2013.6567726, 10.1109/CCECE.2013.6567726]
   Chaum D, 2004, IEEE SECUR PRIV, V2, P38, DOI 10.1109/MSECP.2004.1264852
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   Cheng YQ, 2018, IEEE T INF FOREN SEC, V13, P2393, DOI 10.1109/TIFS.2018.2819125
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   Forte Andrea G., 2014, Security and Cryptography for Networks. 9th International Conference (SCN 2014). Proceedings: LNCS 8642, P255, DOI 10.1007/978-3-319-10879-7_15
   Hou Y.C., 2004, J INFORM TECHNOLOGY, V4, P95
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Li Y, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1299, DOI 10.1145/3292500.3330920
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu WJ, 2019, IEEE ACCESS, V7, P114374, DOI 10.1109/ACCESS.2019.2931073
   Naor M., 1997, Security Protocols. International Workshop Proceedings, P197
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Prakash NK, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P174, DOI 10.1109/ICCIMA.2007.217
   Ross A, 2011, IEEE T INF FOREN SEC, V6, P70, DOI 10.1109/TIFS.2010.2097252
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Tuyls P, 2004, LECT NOTES COMPUT SC, V2802, P271
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XY, 2009, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY (ISCSCT 2009), P310
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 25
TC 10
Z9 10
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103186
DI 10.1016/j.jvcir.2021.103186
EA JUN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500006
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Gong, X
   Yang, P
AF Zhou, Yang
   Gong, Xun
   Yang, Peng
TI A directional margin paradigm for noise suppression in face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Margin paradigm; Loss function; Noisy labels; Two-step
   learning
AB Convolutional neural networks (CNN) have achieved outstanding face recognition (FR) performance with increasing large-scale face datasets. With face dataset size grown, noisy data will inevitably increase, undoubtedly bringing difficulties to data cleaning. In this paper, the probability that the sample belongs to noise can be determined based on the cosine distance (cos theta) of normalized angle center and face feature vector in the margin-based loss functions. According to this finding, we propose a two-step learning method integrated into the loss function. The new proposed directional margin loss function combines the noise probability with the label as the supervision information. Experiments show that our method can tolerate noisy data and get high FR accuracy when the training datasets mix with more than 30% noise. Our approach can also achieve a great result of 79.33% in MegaFace challenge one using a noisy training dataset.
C1 [Zhou, Yang; Gong, Xun] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611730, Sichuan, Peoples R China.
   [Yang, Peng] Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Jiangsu, Peoples R China.
C3 Southwest Jiaotong University; Nanjing Audit University
RP Gong, X (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611730, Sichuan, Peoples R China.
EM yzhou_01@my.swjtu.edu.cn; xgong@swjtu.edu.cn; llylab@21cn.com
RI Yang, Jacky/HKE-6819-2023
OI Gong, Xun/0000-0002-1494-0955; zhou, yang/0000-0002-9148-4316; Yang,
   Peng/0000-0002-1505-7857
FU National Natural Science Foundation of China [61876158, 61662048];
   Fundamental Research Funds for the Central Universities, China
   [2682021ZTPY030]
FX This work is supported by National Natural Science Foundation of China
   (61876158, 61662048) , Fundamental Research Funds for the Central
   Universities, China (2682021ZTPY030) .
CR [Anonymous], 2008, LABELED FACES WILD D
   [Anonymous], 2014, LEARNING FACE REPRES
   Arazo E, 2019, PR MACH LEARN RES, V97
   Chen Q, 2013, PHYSICA A, V392, P529, DOI 10.1016/j.physa.2012.09.012
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Friedman J., 2001, ELEMENTS STAT LEARNI, V1, DOI DOI 10.1007/978-0-387-84858-7
   Goldberger J., 2017, INT C LEARN REPR ICL
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Han B., 2018, ABS180508193 CORR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu MY, 2019, LECT NOTES COMPUT SC, V11365, P404, DOI 10.1007/978-3-030-20873-8_26
   Hu W, 2019, PROC CVPR IEEE, P11879, DOI 10.1109/CVPR.2019.01216
   Jiang L., 2017, ABS171205055 CORR
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Li YC, 2017, IEEE I CONF COMP VIS, P1928, DOI 10.1109/ICCV.2017.211
   Liao B.B., 2019, P MACHINE LEARNING R, V97, P1062
   Liu H, 2019, PROC CVPR IEEE, P11939, DOI 10.1109/CVPR.2019.01222
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Liu WY, 2016, PR MACH LEARN RES, V48
   Liu Yu, 2017, ABS171000870 CORR
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Pawan Kumar M., 2010, NIPS
   Ranjan R., 2017, ABS170309507 CORR
   Ranjan Rajeev, 2017, L2-constrained softmax loss for discriminative face verification
   Ren M., 2018, ABS180309050 CORR
   Rothe S., 2017, ARXIVARXIV171111383
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shen YY, 2019, PR MACH LEARN RES, V97
   Sukhbaatar S., 2015, ARXIV14062080
   Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vahdat A., 2017, ABS170600038 CORR
   Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696
   Wang F., 2018, COMPUTER VISION ECCV, P765
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Yu Z., 2017, ARXIV161202295
NR 47
TC 3
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103182
DI 10.1016/j.jvcir.2021.103182
EA JUN 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500001
DA 2024-07-18
ER

PT J
AU Tambe, RG
   Talbar, SN
   Chavan, SS
AF Tambe, Rishikesh G.
   Talbar, Sanjay N.
   Chavan, Satishkumar S.
TI Deep multi-feature learning architecture for water body segmentation
   from satellite images*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; Deep learning; Refinement modules;
   Satellite image analysis; Water body extraction
ID NEURAL-NETWORKS; INDEX NDWI; EXTRACTION
AB Automatic water body extraction from satellite images of various scenes is a classical and challenging task in remote sensing and image interpretation. Convolutional neural network (CNN) has become prominent option for performing image segmentation task in remote sensing applications. However, CNN-based networks have non-trivial issues for segmenting such as: (1) blurring boundary pixels; (2) large number of trainable parameters; and (3) huge number of training samples. In this paper, we propose an end-to-end multifeature based CNN architecture, called as W-Net, to perform water body segmentation. W-Net consists of contracting/expanding networks and inception layers. W-Net takes advantage of contracting network to capture context information while localization is achieved with expanding network. With these networks, W-Net is able to train on less number of images and extract water pixels accurately. Use of inception layers reduces computational burden within the network by decreasing total number of trainable parameters. W-Net incorporated two refinement modules to enhance predicted results which mitigate blurring effect and to inspect continuity of boundary pixels. Dataset consisting 2671 images with manually annotated ground truths are built to validate performance and effectiveness of our proposed method. In addition, we evaluated our method on crack detection dataset where W-Net achieved competitive performance with Deepcrack. W-Net accomplished excellent performance on the water body dataset (I/U = 0.9434 and F - score = 0.9509).
C1 [Tambe, Rishikesh G.; Talbar, Sanjay N.] SGGS Inst Engn & Technol, Nanded 431606, Maharashtra, India.
   [Chavan, Satishkumar S.] Don Bosco Inst Technol, Mumbai 400070, Maharashtra, India.
C3 Shri Guru Gobind Singhji Institute of Engineering & Technology
RP Tambe, RG (corresponding author), SGGS Inst Engn & Technol, Nanded 431606, Maharashtra, India.
EM rishitambe@gmail.com
RI Talbar, Sanjay/AAB-3610-2019; Chavan, Satishkumar/AAH-1453-2019
OI Chavan, Satishkumar/0000-0003-2137-8849; Talbar,
   Sanjay/0000-0002-0111-4910; Tambe, Rishikesh Gitaram/0000-0002-9035-3111
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Buslaev A, 2018, IEEE COMPUT SOC CONF, P197, DOI 10.1109/CVPRW.2018.00035
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng DC, 2017, IEEE GEOSCI REMOTE S, V14, P247, DOI 10.1109/LGRS.2016.2637439
   Essa A, 2017, IEEE GEOSCI REMOTE S, V14, P1056, DOI 10.1109/LGRS.2017.2695559
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Feng WQ, 2019, IEEE GEOSCI REMOTE S, V16, P618, DOI 10.1109/LGRS.2018.2879492
   Feyisa GL, 2014, REMOTE SENS ENVIRON, V140, P23, DOI 10.1016/j.rse.2013.08.029
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Ghassemi S, 2019, IEEE T GEOSCI REMOTE, V57, P6517, DOI 10.1109/TGRS.2019.2906689
   Gonzalez J.A., 2019, ARXIV PREPRINT ARXIV
   Guo QD, 2017, INT J REMOTE SENS, V38, P5430, DOI 10.1080/01431161.2017.1341667
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang X, 2015, IEEE J-STARS, V8, P2097, DOI 10.1109/JSTARS.2015.2420713
   Iglovikov V., 2018, TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation
   Iglovikov V, 2018, IEEE COMPUT SOC CONF, P228, DOI 10.1109/CVPRW.2018.00042
   Isikdogan F, 2017, IEEE J-STARS, V10, P4909, DOI 10.1109/JSTARS.2017.2735443
   Isikdogan L.F., 2019, IEEE GEOSCI REMOTE S
   Khryashchev V., 2019, 2019 IEEE E W DESIGN, P1
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li LW, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101162
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   Li Y., 2020, IEEE T CIRC SYST VID
   Lin HN, 2017, IEEE GEOSCI REMOTE S, V14, P1665, DOI 10.1109/LGRS.2017.2727515
   Lin HN, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050480
   Liu YH, 2019, IEEE T GEOSCI REMOTE, V57, P2043, DOI 10.1109/TGRS.2018.2870871
   Liu YH, 2019, NEUROCOMPUTING, V338, P139, DOI 10.1016/j.neucom.2019.01.036
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma GX, 2020, IEEE T VIS COMPUT GR, V26, P3535, DOI 10.1109/TVCG.2020.3023636
   Ma GX, 2020, IEEE T MULTIMEDIA, V22, P324, DOI 10.1109/TMM.2019.2929943
   Maggiori E, 2017, IEEE T GEOSCI REMOTE, V55, P4962, DOI 10.1109/TGRS.2017.2697453
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Miao ZM, 2018, IEEE GEOSCI REMOTE S, V15, P602, DOI 10.1109/LGRS.2018.2794545
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pouliot D, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030394
   Qin RJ, 2015, IEEE J-STARS, V8, P1974, DOI 10.1109/JSTARS.2014.2357832
   Rakhlin A, 2018, IEEE COMPUT SOC CONF, P257, DOI 10.1109/CVPRW.2018.00048
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Segal-Rozenhaimer M, 2020, REMOTE SENS ENVIRON, V237, DOI 10.1016/j.rse.2019.111446
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith P, 2013, J APPL ECOL, V50, P812, DOI 10.1111/1365-2664.12016
   Song HH, 2018, IEEE J-STARS, V11, P821, DOI 10.1109/JSTARS.2018.2797894
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vakalopoulou M, 2019, INT GEOSCI REMOTE SE, P4939, DOI [10.1109/IGARSS.2019.8898220, 10.1109/igarss.2019.8898220]
   Wang X., 2020, IEEE T IMAGE PROCESS, V30, P458
   Wu W, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111704
   Wu Z., 2020, IEEE T MULTIMED
   Xu HQ, 2006, INT J REMOTE SENS, V27, P3025, DOI 10.1080/01431160600589179
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yao FF, 2015, REMOTE SENS-BASEL, V7, P12336, DOI 10.3390/rs70912336
   Zhang P, 2017, IEEE GEOSCI REMOTE S, V14, P1183, DOI 10.1109/LGRS.2017.2673118
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhu XX, 2017, IEEE GEOSC REM SEN M, V5, P8, DOI 10.1109/MGRS.2017.2762307
NR 64
TC 21
Z9 21
U1 6
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103141
DI 10.1016/j.jvcir.2021.103141
EA MAY 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200006
DA 2024-07-18
ER

PT J
AU Liu, LT
   Lu, YL
   Yan, XH
AF Liu, Lintao
   Lu, Yuliang
   Yan, Xuehu
TI A novel (<i>k</i><sub>1</sub>, <i>k</i><sub>2</sub>, <i>n</i>)-threshold
   two-in-one secret image sharing scheme for multiple secrets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Ideal secret sharing; RGVCS; Polynomial-based SISS; TiOSISS; Multiple
   secrets; (k(1), k(2), n)-threshold
ID VISUAL CRYPTOGRAPHY
AB A two-in-one secret image sharing scheme (TiOSISS) is the combination of two different secret image sharing schemes (SISSs), which has advantages of both schemes, such as the simple stacking-to-see property and precise recovery with computing devices available. Since most of current TiOSISSs depend on steganography techniques, it results in several drawbacks, such as large pixel expansion and poor visual quality with shares stacking. Besides, researchers ignore the independence between two different SISSs, that is, both SISSs should deal with irrelevant secret images with different thresholds. By controlling the randomness of the sharing phase according to constraints from both SISSs, we combine polynomial-based SISS (PSISS) and random-grid-based visual cryptography scheme (RGVCS) together, and propose an ideal (k(1),k(2), n)-threshold TiOSISS for multiple secrets. The proposed TiOSISS not only overcomes drawbacks above, but also has high scalability to improve its performances by utilizing different RGVCSs. Sufficient analyses and experiments are provided to verify its security and effectiveness.
C1 [Liu, Lintao; Lu, Yuliang; Yan, Xuehu] Natl Univ Def Technol, Hefei, Anhui, Peoples R China.
C3 National University of Defense Technology - China
RP Liu, LT; Yan, XH (corresponding author), Natl Univ Def Technol, Hefei, Anhui, Peoples R China.
EM liuta1989@163.com; publictiger@126.com
RI Yan, Xuehu/AAG-1718-2022; Yan, Xuehu/AFK-3139-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61602491]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Number: 61602491). Thanks for the anonymous reviewers'
   constructive comments and suggestions.
CR [Anonymous], 2016, PLOS BIOL
   Chao KY, 2009, INT J PATTERN RECOGN, V23, P263, DOI 10.1142/S0218001409007090
   Chen J, 2014, CHIN CONTR CONF, P3303
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Fu Z., 2013, P 12 INT WORKSH DIG, P109
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Li P, 2018, J REAL-TIME IMAGE PR, V14, P41, DOI 10.1007/s11554-016-0621-z
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1380, DOI 10.1016/j.jvcir.2013.09.010
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   LIU XR, 2016, ADV MATER SCI ENG, V2016
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Stinson D. R., 1992, Designs, Codes and Cryptography, V2, P357, DOI 10.1007/BF00125203
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Xuehu Yan, 2018, Journal of Real-Time Image Processing, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2016, 2016 8TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY IN MEDICINE AND EDUCATION (ITME), P668, DOI [10.1109/ITME.2016.64, 10.1109/ITME.2016.0156]
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
NR 26
TC 6
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102971
DI 10.1016/j.jvcir.2020.102971
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OJ
UT WOS:000613150700005
DA 2024-07-18
ER

PT J
AU Wang, XY
   Lin, TP
   Jiang, XS
   Xiang, K
   Pan, F
AF Wang, Xuanyin
   Lin, Tianpei
   Jiang, Xuesong
   Xiang, Ke
   Pan, Feng
TI Reliable fusion of ToF and stereo data based on joint depth filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE ToF; Stereo vision; Data fusion; 3D block matching; Seed-growing
ID TIME-OF-FLIGHT; COLOR; RANGE
AB To obtain reliable depth images with high resolution, a novel method is proposed in this study that fuses data acquired from time-of-flight (ToF) and stereo cameras, through which the advantages of both active and passive sensing are utilised. Based on the classic error model of the ToF, gradient information is introduced to establish the likelihood distribution for all disparity candidates. The stereo likelihood is estimated in parallel based on a 3D adaptive support-weight approach. The two independent likelihoods are unified using a maximum likelihood estimation, a process also referred to as a joint depth filter herein. Conventional post-processing methods such as a mutual consistency check are also used after applying a joint depth filter. We also propose a novel hole-filling method based on the seed-growing algorithm to retrieve missing disparities. Experiment results show that the proposed fusion method can produce reliable high-resolution depth maps and outperforms other compared methods.
C1 [Wang, Xuanyin; Lin, Tianpei; Jiang, Xuesong; Xiang, Ke] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Pan, Feng] Zhejiang Sunny Opt Intelligence Technol Co Ltd, 525 Xixi Rd, Hangzhou 310007, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Lin, TP (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM lintp@zju.edu.cn
RI wang, xuan/GXF-3679-2022; wang, xuan/JBJ-6948-2023
CR Agresti G, 2019, PROC CVPR IEEE, P5569, DOI 10.1109/CVPR.2019.00573
   Agresti G, 2019, INFORM FUSION, V49, P161, DOI 10.1016/j.inffus.2018.11.006
   Agresti G, 2017, IEEE INT CONF COMP V, P697, DOI 10.1109/ICCVW.2017.88
   [Anonymous], 2008, PROC ISPRS
   [Anonymous], 2012, TIME FLIGHT CAMERAS
   Chen BL, 2018, IEEE T MULTIMEDIA, V20, P2882, DOI 10.1109/TMM.2018.2825883
   DAK P, 2013, TIME OF FLIGHT DEPTH, P105
   Dal Mutto C., 2010, P 3DPVT MAY, V2, P69
   Dal Mutto C, 2015, IEEE T PATTERN ANAL, V37, P2260, DOI 10.1109/TPAMI.2015.2408361
   Dal Mutto C, 2012, LECT NOTES COMPUT SC, V7583, P598, DOI 10.1007/978-3-642-33863-2_62
   Eichhardt I, 2017, MACH VISION APPL, V28, P267, DOI 10.1007/s00138-017-0831-9
   Evangelidis GD, 2015, IEEE T PATTERN ANAL, V37, P2178, DOI 10.1109/TPAMI.2015.2400465
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Gandhi V, 2012, IEEE INT CONF ROBOT, P4742, DOI 10.1109/ICRA.2012.6224771
   Guomundsson SA, 2010, COMPUT VIS IMAGE UND, V114, P1376, DOI 10.1016/j.cviu.2010.07.011
   Hahne Uwe, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P325, DOI 10.1504/IJISTA.2008.021295
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Horaud R, 2016, MACH VISION APPL, V27, P1005, DOI 10.1007/s00138-016-0784-4
   Lee JE, 2015, IET IMAGE PROCESS, V9, P62, DOI 10.1049/iet-ipr.2014.0044
   Marin G, 2016, INNOVATION MANAGEMENT AND EDUCATION EXCELLENCE VISION 2020: FROM REGIONAL DEVELOPMENT SUSTAINABILITY TO GLOBAL ECONOMIC GROWTH, VOLS I - VI, P38
   Mattoccia Stefano, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1763, DOI 10.1109/ICCVW.2009.5457496
   Nair R, 2012, LECT NOTES COMPUT SC, V7584, P1, DOI 10.1007/978-3-642-33868-7_1
   Penne R, 2015, IMAGE VISION COMPUT, V43, P50, DOI 10.1016/j.imavis.2015.09.001
   Pu C., 2019, ARXIV190410044
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2005, PROC CVPR IEEE, P924
   Zhang YG, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/529480
   Zhu J, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COGNITIVE RADIO ORIENTED WIRELESS NETWORKS AND COMMUNICATIONS, P22
   Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172
   Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68
NR 33
TC 2
Z9 3
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103006
DI 10.1016/j.jvcir.2020.103006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I2ON
UT WOS:000779264200006
DA 2024-07-18
ER

PT J
AU Shen, GR
AF Shen, Guorong
TI Image understanding via learning weakly-supervised cross-modal semantic
   translation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image understanding; Cross-modal semantic translation; Weakly-supervised
   learning
ID CLASSIFICATION
AB Fusing cross-modal features is significant for image understanding, which aims at describing objects inside an image by optimally combining multiple visual channels. In the literature, low-level based multimodal feature fusion have achieved impressive performance. However, the semantic gap is a big limitation, i.e., these methods cannot reflect the how humans perceive image semantic objects. Supervised learning-based methods require intolerably expensive manual labeling, which is not a good choice in practice. To alleviate these limitations, we present an image understanding method by learning weakly-supervised based cross-modal semantic translation. More specifically, we design a manifold embedding algorithm to automatically translate image-level text semantic labels into several pixel level image regions. Subsequently, we leverage a three-level spatial pyramid model to extract both local and global features of objects from training images. Afterwards, these cross-modal features are seamlessly concatenated to form a multiple feature matrix. Afterwards, these cross-modal features are seamlessly concatenated to form a multiple feature matrix. The feature matrix can be employed to learn a kernel SVM and ranking SVM for image classification and retrieval respectively. Comprehensive experiments on image recognition, classification and retrieval have demonstrated the effectiveness of our method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Shen, Guorong] Henan Univ Technol, Sch Foreign Languages, Zhengzhou, Henan, Peoples R China.
C3 Henan University of Technology
RP Shen, GR (corresponding author), Henan Univ Technol, Sch Foreign Languages, Zhengzhou, Henan, Peoples R China.
EM Shenguorong2006@163.com
FU Henan Social Science Planning Project [2018BYY005]; Science Foundation
   Of Henan University of Technology for High-level Talents [2016SBS008];
   National University Foreign Language Teaching and Research Project
   [2018IN0002A]; Higher Education Teaching Reform Project of Henan
   University of Technology [2017SJGLX299]
FX The work is supported by Henan Social Science Planning Project (No.
   2018BYY005), Science Foundation Of Henan University of Technology for
   High-level Talents (No. 2016SBS008), National University Foreign
   Language Teaching and Research Project (2018IN0002A) and Higher
   Education Teaching Reform Project of Henan University of Technology (No.
   2017SJGLX299).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2018, RECURRENT CONVOLUTIO
   [Anonymous], 2016, DEEPLY FUSED NETS
   [Anonymous], 2014, COMPUTER SCI
   Aslan MS, 2017, PATTERN RECOGN LETT, V85, P79, DOI 10.1016/j.patrec.2016.11.021
   Bach F., 2007, P CVPR
   Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631
   Durand T, 2016, PROC CVPR IEEE, P4743, DOI 10.1109/CVPR.2016.513
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Feng J., 2014, P CVPR
   Guo K, 2020, NEURAL COMPUT APPL, V32, P1679, DOI 10.1007/s00521-019-04257-y
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Harada T., 2011, 24 IEEE C COMP VIS P
   Hou Y, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141850043X
   Huang Y, 2003, PATTERN RECOGN LETT, V24, P393, DOI 10.1016/S0167-8655(02)00263-5
   Jäger M, 2008, IEEE T IMAGE PROCESS, V17, P1700, DOI 10.1109/TIP.2008.2001043
   Li L.J., 2010, P ECCV
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu XP, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418500337
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Quadrianto N., 2013, P UAI
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Song Jingkuan, 2018, T PAMI
   Vezhnevets A., 2010, COMPUTER VISION PATT
   Xu Xing, 2019, IEEE T CYB
   Yang HM, 2018, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2018.00366
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623
   Zhao J., 2016, FLIC FAST LINEAR ITE
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 30
TC 0
Z9 0
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102789
DI 10.1016/j.jvcir.2020.102789
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400019
DA 2024-07-18
ER

PT J
AU Wang, YP
AF Wang, Yupeng
TI Analysis of financial business model towards big data and its
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Financial business; Big data; Neural network
AB Finance service based on big data faces many issues, such as fraud, credit. In this paper, we study the development of financial business model under the big data. We first analyze the impact mechanism of big data finance on customer information protection of commercial banks. Customer information has the characteristics of large amount of information, high value of data and strong destructive data leakage. Then, we propose two solutions towards issues of finance service including face anti-spoofing algorithm and financial risk evaluation. Experiments show the effectiveness of our proposed method in improving the reliability and security of modern big data finance. (c) 2019 Published by Elsevier Inc.
C1 [Wang, Yupeng] ZhengZhou ShengDa Univ Econ Business & Management, Sch Finance & Trade, Zhengzhou 451191, Peoples R China.
RP Wang, YP (corresponding author), ZhengZhou ShengDa Univ Econ Business & Management, Sch Finance & Trade, Zhengzhou 451191, Peoples R China.
EM YupengWang_edu@hotmail.com
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   [Anonymous], 2018, ARXIV181200408
   [Anonymous], AS PAC SIGN INF PROC
   [Anonymous], 2018, LEARNING DEEP MODELS
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Breymann W, 2003, QUANT FINANC, V3, P1, DOI 10.1088/1469-7688/3/1/301
   Buko B., 2022, ABS151203385 CORR, V22, P8878
   Cai D., 2007, IJCAI 2007 P 20 INT
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Costagliola A, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/8016186
   Erdogmus N., 2014, IEEE 6 INT C BIOM TH
   Galbally J., 2014, INT C PATT REC
   Goswami G, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Kazemi V., 2014, 2014 IEEE C COMP VIS
   Kim K., 2000, 21 INT C INF SYST
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Liao Z, 2012, J DECIS SYST, V21, P161, DOI 10.1080/12460125.2012.680355
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Sun L., 2007, ADV BIOM INT C ICB 2
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Yue GD, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416500208
NR 22
TC 1
Z9 2
U1 13
U2 82
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102729
DI 10.1016/j.jvcir.2019.102729
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900010
DA 2024-07-18
ER

PT J
AU Hu, ZQ
   Li, B
   Liu, Y
   Niu, XW
AF Hu, Zhengquan
   Li, Bin
   Liu, Yu
   Niu, Xiaowei
TI Research on quality improvement method of deformation monitoring data
   based on InSAR
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE INSAR; Surface deformation; Monitoring; GPU acceleration
ID RECONSTRUCTION; SUBSIDENCE; GPS
AB In recent years, geological disasters caused by surface deformation frequently occur, which seriously threatens the safety of people's lives and property. Therefore, it is of great significance to strengthen the monitoring of surface deformation. With the continuous advancement of science and technology, traditional monitoring technology is difficult to meet the development requirements of modern society. As a new type of space-to-earth observation technology, INSAR technology has the advantages of high precision and real-time dynamic monitoring, and has been obtained in surface deformation monitoring widely used. This paper briefly analyzes the basic working principle of INSAR technology and its specific application in surface deformation monitoring. The algorithm parallelism of the ground-based SAR deformation monitoring process is analyzed, and the CPU + GPU heterogeneous platform is used to accelerate the implementation to improve the timeliness of deformation monitoring. BP imaging algorithm, interferogram generation, interferogram filtering and phase unwrapping algorithm are designed in parallel, and appropriate parallel granularity planning for multiple loops, adaptive division of optimal thread block size and use of shared memory to reduce duplicate data are adopted. Optimization strategies such as read time enable GPU acceleration processing. Compared with the implementation of CPU platform and CPU + GPU heterogeneous platform, the acceleration effect from tens to hundreds of times is accelerated, and the feasibility of GPU to improve the timeliness of deformation monitoring is verified. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hu, Zhengquan; Liu, Yu; Niu, Xiaowei] ChongQing Three Gorges Univ, Sch Elect & Informat Engn, Chongqing, Peoples R China.
   [Li, Bin] CCCC First Harbor Engn Co Ltd, Tianjin Port Engn Inst Co Ltd, Tianjin, Peoples R China.
   [Li, Bin] PRC, Key Lab Port Geotech Engn, Minist Commun, Tianjin, Peoples R China.
   [Li, Bin] CCCC First Harbor Engn Co Ltd, Tianjin, Peoples R China.
C3 Chongqing Three Gorges University
RP Li, B (corresponding author), CCCC First Harbor Engn Co Ltd, Tianjin Port Engn Inst Co Ltd, Tianjin, Peoples R China.
EM hzq250314@sanxiau.edu.cn; lee_bin8409@126.com
FU youth project of science and technology research program of Chongqing
   Education Commission of China [KJQN201801227]; National natural science
   foundation of china [11201510]; National Key Research and Development
   Program of China [2017YFC0805308]
FX This work was support by youth project of science and technology
   research program of Chongqing Education Commission of China. (Grant No.
   KJQN201801227); National natural science foundation of china (11201510)
   and The National Key Research and Development Program of China"(No.
   2017YFC0805308).
CR Amelung F, 1999, GEOLOGY, V27, P483, DOI 10.1130/0091-7613(1999)027<0483:STUADO>2.3.CO;2
   Bechor NBD, 2006, GEOPHYS RES LETT, V33, DOI 10.1029/2006GL026883
   Bertr Delouis, 2011, TRANSLATED WORLD SEI, V37
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Chlieh M., 2010, GEOPHYS J ROY ASTRON, V158, P695
   Deledalle CA, 2011, IEEE T GEOSCI REMOTE, V49, P1441, DOI 10.1109/TGRS.2010.2076376
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Ferraiuolo G, 2004, IEEE GEOSCI REMOTE S, V1, P66, DOI 10.1109/LGRS.2003.822882
   Ferretti A, 1999, IEEE T GEOSCI REMOTE, V37, P705, DOI 10.1109/36.752187
   Ferretti A., 2007, J FINANC STABIL, V19, P156, DOI 10.1287/ited.1100.0047
   Hajnsek I, 2009, IEEE T GEOSCI REMOTE, V47, P481, DOI 10.1109/TGRS.2008.2009437
   Hooper A, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2004GL021737
   Karimi N, 2018, J VIS COMMUN IMAGE R, V55, P853, DOI 10.1016/j.jvcir.2018.04.001
   Li ZF, 2006, IEEE T GEOSCI REMOTE, V44, P288, DOI 10.1109/TGRS.2005.860984
   Osmanoglu B, 2011, INT J APPL EARTH OBS, V13, P1, DOI 10.1016/j.jag.2010.05.009
   Parizzi A, 2011, IEEE GEOSCI REMOTE S, V8, P441, DOI 10.1109/LGRS.2010.2083631
   Pascazio V, 2002, IEEE T IMAGE PROCESS, V11, P1478, DOI 10.1109/TIP.2002.804274
   Ping W., 2010, AS PAC C SYNTH AP RA
   Ryder I., 2010, GEOPHYS J ROY ASTRON, V169, P1009
   Simons M, 2002, B SEISMOL SOC AM, V92, P1390, DOI 10.1785/0120000933
   Sriman B, 2019, J VIS COMMUN IMAGE R, V62, P23, DOI 10.1016/j.jvcir.2019.04.007
   Stilla U, 2003, ISPRS J PHOTOGRAMM, V58, P113, DOI 10.1016/S0924-2716(03)00021-2
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   Wadge G, 2002, GEOPHYS RES LETT, V29, DOI 10.1029/2002GL015159
   Wright TJ, 2004, GEOPHYS RES LETT, V31, DOI 10.1029/2003GL018827
   Wright TJ, 2003, GEOPHYS RES LETT, V30, DOI 10.1029/2003GL018014
   Wright TJ, 2004, SCIENCE, V305, P236, DOI 10.1126/science.1096388
   Xu W, 1999, IEEE T GEOSCI REMOTE, V37, P124, DOI 10.1109/36.739143
NR 28
TC 2
Z9 2
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102652
DI 10.1016/j.jvcir.2019.102652
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600033
DA 2024-07-18
ER

PT J
AU Li, CL
   Li, ZH
   Ge, ZY
   Li, MJ
AF Li, Changlin
   Li, Zhihui
   Ge, Zongyuan
   Li, Mingjie
TI Knowledge driven temporal activity localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Temporal activity detection; Knowledge constraints; Reasoning module
AB In this paper, we focus on the problem of temporal activity detection, which aims to directly predict the temporal bounds of actions. Most existing temporal activity detection algorithms treat the classification of each action proposal separately and neglect vital semantic correlations between actions in one video. This will deteriorate the classification performance in the scenario of long-tail problems, where only a handful of examples are available for uncommon actions. To solve this problem, we propose to incorporate knowledge to reason over large scale action classes and maintain semantic coherency within one video. Specifically, we employ an implicit knowledge reasoning module and an explicit knowledge reasoning module to incorporate the knowledge constraints to facilitate temporal activity localization. To demonstrate the superiority of the proposed model, we test the proposed method on large-scale action detection datasets, namely ActivityNet and THUMOS'14 datasets. The experimental results have demonstrated the superiority of the proposed model. Codes and models will be released once this paper is accepted. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Changlin; Ge, Zongyuan; Li, Mingjie] Monash Univ, Fac Informat Technol, Clayton, Vic, Australia.
   [Li, Zhihui] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
C3 Monash University; University of New South Wales Sydney
RP Li, CL (corresponding author), Monash Univ, Fac Informat Technol, Clayton, Vic, Australia.
EM changlin.li@monash.edu
RI Li, Zhihui/AAB-7394-2020; Li, Changlin/GRX-7207-2022
OI Li, Zhihui/0000-0001-9642-8009; Li, Changlin/0000-0002-8486-7482; Ge,
   Zongyuan/0000-0002-5880-8673
FU 973 Program [201203316400]; ARC DECRA project; U.S. Department of
   Defense, U.S. Army Research Office [W911NF-13-1-0277]; National Science
   Foundation [IIS-1251187]
FX This paper was partially supported by the 973 Program (201203316400),
   partially supported by the ARC DECRA project, partially supported by the
   U.S. Department of Defense, U.S. Army Research Office (W911NF-13-1-0277)
   and partially supported by the National Science Foundation under Grant
   No. IIS-1251187. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purposes notwithstanding any
   copyright annotation thereon. Disclaimer: The views and conclusions
   contained herein are those of the authors and should not be interpreted
   as necessarily representing the official policies or endorsements,
   either expressed or implied, of ARO, the National Science Foundation or
   the U.S. Government.
CR [Anonymous], 2017, BMVC
   [Anonymous], 2017, BMVC
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, CVPR
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], 2015, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2009, Computer Vision and Pattern Recognition
   [Anonymous], 2016, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, ICCV
   [Anonymous], 2016, CVPR
   [Anonymous], 2018, CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], ICIP
   [Anonymous], 2010, ECCV
   [Anonymous], 2017, ABS170506950 CORR
   [Anonymous], 2018, CVPR
   [Anonymous], 2003, ICCV
   [Anonymous], 2018, ECCV
   [Anonymous], 2017, CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], 2017, ICCV
   [Anonymous], 2016, CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], 2011, CVPR
   [Anonymous], 2016, CVPR
   Atmosukarto I, 2012, INT C PATT RECOG, P3333
   Buch S., 2017, CVPR
   Caba Heilbron F., 2016, CVPR
   Dai X., 2017, ICCV
   Escorcia V., 2016, ECCV
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Galleguillos Carolina., 2008, CVPR
   Gao J., 2017, ARXIV170704818
   Gorban A., 2015, THUMOS challenge: Action recognition with a large number of classes
   Hanina A., 2018, US Patent App, Patent No. [10/116,903, 10116903]
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Karaman S., 2014, THUMOS 2014 CHALLENG
   Laptev I., 2007, ICCV
   Li Y., 2016, ICLR
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Merler M., 2018, CVPR WORKSH
   Montes Alberto, 2016, CORR, V1608. 08128, P1
   Niepert Mathias, 2016, ICML
   Oneata D., 2014, The lear submission at thumos
   Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768
   Richard A., 2016, CVPR
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh Gurkirt., 2016, CoRR
   Stoian A, 2016, IEEE T CIRC SYST VID, V26, P1917, DOI 10.1109/TCSVT.2015.2475835
   Sun C., 2013, ACM
   Wang L, 2014, ECCV THUMOS WORKSH
   Wang L., 2015, CVPR
   Wang L, 2014, LARGE SCALE ACTIVITY
   Wang R., 2016, Uts at activitynet 2016. AcitivityNet Large Scale Activity Recognition Challenge
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y
   Yuan J., 2016, CVPR
   Yuan Z.-H., 2017, CVPR
   ZHENG C, 2019, IEEE T KNOWL DATA EN
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
NR 67
TC 5
Z9 6
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102628
DI 10.1016/j.jvcir.2019.102628
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600035
OA Bronze
DA 2024-07-18
ER

PT J
AU Chin, SH
   Chen, C
   Ko, PC
   Lin, SY
AF Chin, Shih-Hsien
   Chen, Cheng
   Ko, Po-Chang
   Lin, Shih-Yang
TI Design of museum advertisement picture management system based on web
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE The museum; Advertising pictures; C/S mode; The system design
AB With the rapid development of information technology and the popularity of computer and information technology, intelligent, digital has become a hot topic of discussion, industries in the daily work of the museum, there is a large amount of collection and collection information to process and maintenance staff to, so museum in various fields is also an urgent need to informationization, the digital revolution, allowing staff to liberate from the tedious work. One of the emphases of the daily work of museums is the management of the collections. Museum collection of computer management information system's purpose is to put as the basic object of information collection, through to the existing various CARDS, books and pictures, sounds, video, etc of traditional data processing and digital, set up a computer information management system, system including hardware and software of two parts. This paper starts from the background, elaborated the picture management system present situation, the existence superiority; Secondly, it is the system demand analysis, mainly introduced the system environment demand, performance demand and system role demand; Then is another part of the system outline design, including the overall system architecture design, use case design, database design; Finally is the system detailed design and the realization part, this part mainly is carries on the design to the system function module, and has carried on the programming realization. (C) 2019 Published by Elsevier Inc.
C1 [Chin, Shih-Hsien] Yango Univ, Fuzhou 350015, Fujian, Peoples R China.
   [Chen, Cheng] Yango Univ, Art Dept, Fuzhou 350015, Fujian, Peoples R China.
   [Ko, Po-Chang] Natl Kaohsiung Univ Sci & Technol, Dept Informat Management, Kaohsiung 807, Taiwan.
   [Lin, Shih-Yang] Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 807, Taiwan.
C3 National Kaohsiung University of Science & Technology; National
   Kaohsiung University of Science & Technology
RP Lin, SY (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 807, Taiwan.
EM cobol@nkust.edu.tw; Lsy.msn@hotmail.com
CR Ahn S. J., 1999, IJNM, V9, P309
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2016, CHIN J BIOMED ENG, P11
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   Ayala I, 2014, SENSORS-BASEL, V14, P21213, DOI 10.3390/s141121213
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Chang J., 2018, J VISUAL COMMUN IMAG
   Deng F., 2014, ADV MAT RES, V4, P1006
   Dourte DR, 2014, AGR SYST, V125, P33, DOI 10.1016/j.agsy.2013.11.006
   [方恩权 Fang Enquan], 2017, [现代隧道技术, Modern Tunnelling Technology], V54, P40
   Gavrielides M, 2014, SOURCE CODE BIOL MED, V9, DOI 10.1186/s13029-014-0025-z
   Grimes SM, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-290
   Hung JC, 2016, EVOL SYST-GER, V7, P145, DOI 10.1007/s12530-016-9154-8
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Jin G., 2014, ADV MAT RES, V4, P926
   Li RYC, 2015, MUS MANAG CURATORSHI, V30, P208, DOI 10.1080/09647775.2015.1042509
   Miyazaki Y, 2014, BIODIVERS CONSERV, V23, P2383, DOI 10.1007/s10531-014-0724-4
   Moreira L, 2015, IFIP ADV INF COMM TE, V450, P337, DOI 10.1007/978-3-319-16766-4_36
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Qi LX, 2017, CLUSTER COMPUT, V20, P941, DOI 10.1007/s10586-017-0786-7
   Safie S, 2014, ADV SCI LETT, V20, P2018, DOI 10.1166/asl.2014.5646
   Sanger E, 2015, J MUS EDUC, V40, P147, DOI 10.1179/1059865015Z.00000000091
   Solima L, 2016, BUSINESS PROCESS MAN, V22
   Sulaiman S, 2017, ADV SCI LETT, V23, P11444, DOI 10.1166/asl.2017.10302
   Wei QW, 2016, CONSERV MANAGE ARCHA, V18, P464, DOI 10.1080/13505033.2016.1290471
   Weng Y. C., 2017, J INTELL INF SYST, V51, P60
   Xiang Xin, 2014, Applied Mechanics and Materials, V539, P438, DOI 10.4028/www.scientific.net/AMM.539.438
   Xiao CL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010060
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Yang C, 2015, GEOGR RES-AUST, V53, P321, DOI 10.1111/1745-5871.12117
   Yang Xiufang, 2014, Applied Mechanics and Materials, V541-542, P3207, DOI 10.4028/www.scientific.net/AMM.543-547.3207
   Zhang C. Y., 2014, APPL MECH MAT, V4, P608
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
NR 33
TC 1
Z9 1
U1 6
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102595
DI 10.1016/j.jvcir.2019.102595
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200021
DA 2024-07-18
ER

PT J
AU Afifi, M
   Abdelhamed, A
AF Afifi, Mahmoud
   Abdelhamed, Abdelrahman
TI AFIF<SUP>4</SUP>: Deep gender classification based on AdaBoost-based
   fusion of isolated facial features and foggy faces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gender classification; Deep convolutional neural networks; Face image
   dataset
ID TEXTURE CLASSIFICATION
AB Gender classification aims at recognizing a person's gender. Despite the high accuracy achieved by state-of-the-art methods for this task, there is still room for improvement in generalized and unrestricted data sets. In this paper, we advocate a new strategy inspired by the behavior of humans in gender recognition. Instead of dealing with the face image as a sole feature, we rely on the combination of isolated facial components and a contextual feature which we call the foggy face. Then, we use these features to train deep convolutional neural networks followed by an AdaBoost-based score fusion to infer the final gender class. We evaluate our method on four challenging datasets to demonstrate its efficacy in achieving better or on-par accuracy with state-of-the-art methods. In addition, we present a new face dataset that intensifies the challenges of occluded faces and illumination changes, which we believe to be a much-needed resource for gender classification research. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Afifi, Mahmoud] York Univ, Lassonde Sch Engn, Dept Elect Engn & Comp Sci, 4700 Keele St, N York, ON M3J 1P3, Canada.
   Assiut Univ, Fac Comp & Informat, Assiut, Egypt.
C3 York University - Canada; Egyptian Knowledge Bank (EKB); Assiut
   University
RP Afifi, M (corresponding author), York Univ, Lassonde Sch Engn, Dept Elect Engn & Comp Sci, 4700 Keele St, N York, ON M3J 1P3, Canada.
EM mafifi@eecs.yorku.ca; kamel@eecs.yorku.ca
RI Abdelhamed, Abdelrahman/AGM-9019-2022; afifi, mahmoud/AAH-3095-2019
OI Abdelhamed, Abdelrahman/0000-0002-4836-794X; afifi,
   mahmoud/0000-0003-0125-4945
CR Afifi M., 2018, ARXIV180201009
   Amayeh G., 2008, 2008 IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. Work. CVPR Work, DOI [10.1109/CVPRW.2008.4563122, DOI 10.1109/CVPRW.2008.4563122]
   [Anonymous], 2016, COMPUT VIS IMAGE UND
   [Anonymous], 2013, INT C BIOM ICB
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   BURTON AM, 1993, PERCEPTION, V22, P153, DOI 10.1068/p220153
   Castrillon-Santana M., 2016, MULTIMED TOOLS APPL, V2016, P1
   Chen CJ, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P182
   Choi SI, 2012, PATTERN RECOGN LETT, V33, P1083, DOI 10.1016/j.patrec.2012.01.005
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Hadid A, 2015, PATTERN RECOGN LETT, V68, P231, DOI 10.1016/j.patrec.2015.04.017
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   Jain A. K., 2011, HDB FACE RECOGNITION
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Juefei-Xu F., 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P68
   Kawulok M, 2011, PATTERN RECOGN, V44, P929, DOI 10.1016/j.patcog.2010.10.010
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li B, 2012, NEUROCOMPUTING, V76, P18, DOI 10.1016/j.neucom.2011.01.028
   Lian X.-C., 2008, International Conference on Neural Information Processing, Part II, P647
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Mery D, 2015, PATTERN RECOGN LETT, V68, P260, DOI 10.1016/j.patrec.2015.05.005
   Moeini A, 2015, IET IMAGE PROCESS, V9, P690, DOI 10.1049/iet-ipr.2014.0733
   Moeini H, 2017, J VIS COMMUN IMAGE R, V42, P1, DOI 10.1016/j.jvcir.2016.11.002
   Mozaffari Saeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1192, DOI 10.1109/ICPR.2010.297
   Ng CB, 2015, PATTERN ANAL APPL, V18, P739, DOI 10.1007/s10044-015-0499-6
   Ngan M., 2015, Face Recognition Vendor Test (FRVT) Performance of Automated Gender Classification Algorithms, DOI [10.6028/NIST.IR.8052, DOI 10.6028/NIST.IR.8052]
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rai P, 2014, J VIS COMMUN IMAGE R, V25, P1118, DOI 10.1016/j.jvcir.2014.03.009
   Riccio D., 2012, 2012 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications (BIOMS 2012), DOI 10.1109/BIOMS.2012.6345776
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   van de Wolfshaar J, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P188, DOI 10.1109/SSCI.2015.37
   Wu J, 2009, IEEE IMAGE PROC, P2449, DOI 10.1109/ICIP.2009.5414129
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zhang N., 2007, Tech. Rep. 07-49, P7
NR 48
TC 42
Z9 46
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 77
EP 86
DI 10.1016/j.jvcir.2019.05.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Duan, P
   Wang, TW
   Cui, MW
   Sang, HY
   Sun, Q
AF Duan, Peng
   Wang, Tingwei
   Cui, Maowei
   Sang, Hongyan
   Sun, Qun
TI Multi-person pose estimation based on a deep convolutional neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-person pose estimation; Improved faster R-CNN; Top-down structure;
   ResNet-152 model; Conditional random field
ID ACTION RECOGNITION; MOTION
AB Human motion recognition based on computer vision plays an important role in many fields, such as video surveillance, virtual reality, and medical care. To solve the inaccurate multi-person pose estimation problem and improve the generalizability of the extracted features, this paper proposes a multi-person pose estimation method based on a deep convolutional neural network. This method mainly relies on a top-down structure which includes two stages. In the first stage, the bounding boxes that are likely to contain people are first detected by an improved faster R-CNN. Individuals in the complex scenario are then tailored by box cropping. In the second stage, we combine heatmap detection with coordinate regression to address the single person pose estimation problem. Specially, a deep convolutional ResNet is employed to produce heatmaps of human body. The precise location of each joint is achieved by the fully connected conditional random field. Experimental results demonstrate our method achieves comparable performance with the state-of-the-art ones. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Duan, Peng; Cui, Maowei; Sang, Hongyan] Liaocheng Univ, Sch Comp Sci, Liaocheng 252059, Shandong, Peoples R China.
   [Sun, Qun] Liaocheng Univ, Sch Mech & Automot Engn, Liaocheng 252059, Shandong, Peoples R China.
   [Wang, Tingwei] Univ Jinan, Sch Informat Sci & Engn, Jinan 250013, Shandong, Peoples R China.
C3 Liaocheng University; Liaocheng University; University of Jinan
RP Wang, TW (corresponding author), Univ Jinan, Sch Informat Sci & Engn, Jinan 250013, Shandong, Peoples R China.
EM tingweiwang@ujn.edu.cn
RI Duan, Peng/ITV-2620-2023; Wang, Ting-Wei/ABB-6079-2021
OI Wang, Ting-Wei/0000-0003-3463-643X; Sang, Hongyan/0000-0001-7476-5039;
   Duan, Peng/0000-0002-7396-7592
FU Natural Science Foundation of Shandong Province [ZR2016FL13,
   ZR2017BF039, ZR2018BD008]; Special fund plan for local science and
   technology development [61773192, 61503170, 61603169, 61773246];
   Shandong Province Higher Educational Science and Technology Program
   [J17KZ005, J14LN28]; Key Laboratory of Computer Network and Information
   Integration (Southeast University), Ministry of Education
   [K93-9-2017-02]; State Key Laboratory of Synthetical Automation for
   Process Industries [PAL-N201602]
FX This research is partially supported by Natural Science Foundation of
   Shandong Province (ZR2016FL13, ZR2017BF039, ZR2018BD008), Special fund
   plan for local science and technology development lead by central
   authority, National Science Foundation of China (61773192, 61503170,
   61603169, and 61773246), Shandong Province Higher Educational Science
   and Technology Program (J17KZ005, J14LN28), Key Laboratory of Computer
   Network and Information Integration (Southeast University), Ministry of
   Education (K93-9-2017-02), and State Key Laboratory of Synthetical
   Automation for Process Industries (PAL-N201602).
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2013, P IEEE C COMP VIS PA
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], ACM MULT C
   Belagiannis V., 2017, P IEEE INT C AUT FAC
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen Q, 2009, SCI CHINA SER F, V52, P244, DOI 10.1007/s11432-009-0031-y
   Chen XJ, 2015, PROC CVPR IEEE, P3945, DOI 10.1109/CVPR.2015.7299020
   Chen YF, 2018, IEEE CONF COMPUT
   Cui CR, 2019, IEEE T MULTIMEDIA, V21, P1209, DOI 10.1109/TMM.2018.2875357
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740
   Gkioxari G, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.458
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Iqbal U, 2016, LECT NOTES COMPUT SC, V9914, P627, DOI 10.1007/978-3-319-48881-3_44
   Jain A., 2014, COMPUT SCI
   Kato N., 2018, P IEEE C COMP VIS PA
   Levinkov E, 2017, PROC CVPR IEEE, P1904, DOI 10.1109/CVPR.2017.206
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Newell A., 2017, P C NEUR INF PROC SY
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Ouyang W., 2014, P IEEE C COMP VIS PA
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052
   Qiao LS, 2018, NEUROCOMPUTING, V312, P336, DOI 10.1016/j.neucom.2018.05.084
   Qiao LS, 2017, NEUROCOMPUTING, V259, P112, DOI 10.1016/j.neucom.2016.08.122
   Ramanan D., 2007, Advances in Neural Information Processing Systems, V19, P1129
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Q, 2016, NEURAL PROCESS LETT, V43, P505, DOI 10.1007/s11063-015-9423-8
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Tompson Jonathan, 2014, ARXIV14062984, DOI DOI 10.5555/2968826.2969027
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Varadarajan S, 2018, IEEE WINT CONF APPL, P418, DOI 10.1109/WACV.2018.00052
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang LM, 2016, PROC CVPR IEEE, P2708, DOI 10.1109/CVPR.2016.296
   Wang TW, 2019, J VIS COMMUN IMAGE R, V61, P315, DOI 10.1016/j.jvcir.2019.04.001
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yi Y., 2011, P IEEE C COMP VIS PA
   Zhang CY, 2013, IEEE COMPUT SOC CONF, P500, DOI 10.1109/CVPRW.2013.80
   Zhang N., 2015, COMPUTER SCI, V69, P207
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
NR 51
TC 7
Z9 8
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 245
EP 252
DI 10.1016/j.jvcir.2019.05.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600023
DA 2024-07-18
ER

PT J
AU Han, SD
   Yang, ZQ
   Li, QQ
   Chen, Y
AF Han, Shoudong
   Yang, Ziqing
   Li, Qianqian
   Chen, Yang
TI Deformed landmark fitting for sequential faces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Landmark fitting; Active shape model; Large displacement optical flow
   model; Global shape model
ID ALIGNMENT
AB Fitting facial landmarks on unconstrained videos is a challenging task with broad applications. At present, many methods of one-shot landmark fitting have been proposed with varying degrees of success. However, most of them are heavily sensitive to initializations and usually rely on offline-trained static models, which limit their performance on sequential images with extensive variations. Therefore, they usually can't align the deformed face very well. To address these limitations, we propose a method of deformed landmark fitting (DLF) for sequential faces, which is designed based on active shape model (ASM) and deformation tracking/correction. This method overcomes the loss of consecutive information between frames, and makes full use of the motion variation information of video sequences in time and space dimensions. Firstly, the optical flow values of several possible deformation points on the face are calculated by the large displacement optical flow (LDOF) model, and the tracking of these points in the current frame are performed through the optical flow motion vector. Secondly, the initial shape of face in each frame is established by the locations of these deformation points and the global shape model in ASM algorithm. Finally, on the basis of initial shape, according to the guidance of local texture model in ASM algorithm, different correction strategies are applied to different landmarks for local search, and then each landmark is reasonably suppressed to obtain the ultimate results. Our DLF observably improves the fitting accuracy for deformed faces, and takes full advantage of the continuity among video sequences. Compared with some state-of-the-art landmarkers, extensive experiments on landmark fitting for sequential faces show that our DLF performs outstandingly in terms of accuracy and robustness. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Han, Shoudong; Yang, Ziqing; Li, Qianqian; Chen, Yang] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Key Lab Image Proc & Intelligent Control, Minist Educ, Wuhan 430074, Hubei, Peoples R China.
   [Han, Shoudong] Huazhong Univ Sci & Technol Shenzhen, Res Inst, Shenzhen 518057, Peoples R China.
C3 Huazhong University of Science & Technology
RP Han, SD (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Key Lab Image Proc & Intelligent Control, Minist Educ, Wuhan 430074, Hubei, Peoples R China.; Han, SD (corresponding author), Huazhong Univ Sci & Technol Shenzhen, Res Inst, Shenzhen 518057, Peoples R China.
EM shoudonghan@hust.edu.cn
OI Han, Shoudong/0000-0003-0572-4748
FU National Natural Science Foundation of China [61105006]; Shenzhen
   Strategic Emerging Industry Development Special Fund
   [JCYJ20170307172130906]; Aerospace Science and Technology Foundation
   [2018-HT-HZ]; Open Fund of Key Laboratory of Image Processing and
   Intelligent Control (Huazhong University of Science and Technology),
   Ministry of Education [IPIC2019-01]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61105006; the Shenzhen Strategic Emerging Industry
   Development Special Fund under Grant No. JCYJ20170307172130906; the
   Aerospace Science and Technology Foundation under Grant No. 2018-HT-HZ;
   and the Open Fund of Key Laboratory of Image Processing and Intelligent
   Control (Huazhong University of Science and Technology), Ministry of
   Education under Grant No. IPIC2019-01.
CR Alabort-i-Medina J, 2017, INT J COMPUT VISION, V121, P26, DOI 10.1007/s11263-016-0916-3
   [Anonymous], 2014, IEEE INT C COMP VIS
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], COMPUT VIS PATT RECO
   [Anonymous], COMPUT VIS PATT RECO
   [Anonymous], AAAI C ART INT AAAI
   [Anonymous], 2019, 2019 IEEE C COMP VIS
   [Anonymous], APPL COMPUT VISION
   [Anonymous], INT C COMP VIS THEOR
   [Anonymous], 2018, ECCV
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Çeliktutan O, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-13
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Deng JK, 2019, IEEE T IMAGE PROCESS, V28, P3636, DOI 10.1109/TIP.2019.2899267
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Fanelli G, 2013, IEEE INT CONF AUTOMA
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Jeni LA, 2017, IMAGE VISION COMPUT, V58, P13, DOI 10.1016/j.imavis.2016.05.009
   Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z
   Khan MH, 2017, IEEE I CONF COMP VIS, P3811, DOI 10.1109/ICCV.2017.409
   Li Dang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P944, DOI 10.1109/CISP.2010.5646914
   Liu H, 2018, IEEE T PATTERN ANAL, V40, P2546, DOI 10.1109/TPAMI.2017.2734779
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P1666, DOI 10.1109/TIP.2017.2657118
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Milborrow S., 2010, Pattern Recognition Association of South Africa, V201, P1
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Peng X, 2018, INT J COMPUT VISION, V126, P184, DOI 10.1007/s11263-017-0996-8
   Pengfei Xiong, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3971, DOI 10.1109/ICPR.2010.966
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sangineto E, 2013, IEEE T PATTERN ANAL, V35, P624, DOI 10.1109/TPAMI.2012.87
   Shen XH, 2013, PROC CVPR IEEE, P3460, DOI 10.1109/CVPR.2013.444
   Singh G, 2018, J INF TECHNOL RES, V11, P91, DOI 10.4018/JITR.2018010106
   Smith BM, 2014, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2014.225
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Tulyakov S, 2015, IEEE I CONF COMP VIS, P3748, DOI 10.1109/ICCV.2015.427
   Wang NN, 2018, NEUROCOMPUTING, V275, P50, DOI 10.1016/j.neucom.2017.05.013
   Wu LF, 2015, SIAM J SCI COMPUT, V37, pS365, DOI 10.1137/140979381
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
NR 41
TC 5
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 381
EP 393
DI 10.1016/j.jvcir.2019.06.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600035
DA 2024-07-18
ER

PT J
AU Zhu, JH
   Wang, JX
   Pang, SM
   Guan, WL
   Li, ZY
   Li, YC
   Qian, XM
AF Zhu, Jihua
   Wang, Jiaxing
   Pang, Shanmin
   Guan, Weili
   Li, Zhongyu
   Li, Yaochen
   Qian, Xueming
TI Co-weighting semantic convolutional features for object retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object retrieval; Deep convolutional features; Aggregation
AB Deep feature aggregation, which refers to aggregating a set of local convolutional features into a global image-level vector, has attracted increasing attention in object instance retrieval. In this manuscript, we propose an unsupervised framework that aggregates feature maps by an adaptive selection and two weighting strategies. Particularly, the selection process finds the foreground contour by explaining the semantic structure implicated in the feature maps, while two weighting process including an adaptive Gaussian filter that highlights semantic features and an element-value sensitive channel vector that activates feature channels corresponding to sparse yet distinctive image patterns. Experimental results on benchmark image retrieval datasets validate that the selection and two weighting schemes are complementary in improving the discriminative power of image vectors. With the same experimental settings, the proposed approach outperforms state-of-the-art aggregation approaches by a considerable margin. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhu, Jihua; Wang, Jiaxing; Pang, Shanmin; Li, Zhongyu; Li, Yaochen] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Shaanxi, Peoples R China.
   [Pang, Shanmin] State Key Lab Rail Transit Engn Informatizat FSDI, Xian 710043, Shaanxi, Peoples R China.
   [Guan, Weili] Hewlett Packard Enterprise, Singapore, Singapore.
   [Qian, Xueming] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Pang, SM (corresponding author), State Key Lab Rail Transit Engn Informatizat FSDI, Xian 710043, Shaanxi, Peoples R China.
EM zhujh@xjtu.edu.cn; csuwjx@stu.xjtu.edu.cn; pangsm@xjtu.edu.cn;
   yaochenli@xjtu.edu.cn; qianxm@xjtu.edu.cn
RI li, zy/HZM-1892-2023; Pang, Shanmin/KBQ-6978-2024
OI Zhu, Jihua/0000-0002-3081-8781
FU National Natural Science Foundation of China (NSFC) [61603289,
   61573273]; State Key Laboratory of Rail Transit Engineering
   Informatization [SKLK19-07]; Postdoctoral Science Foundation of Shaanxi
   [2017BSHEDZZ89]
FX This work was supported in part by National Natural Science Foundation
   of China (NSFC) (Grant Nos. 61603289 and 61573273); in part by State Key
   Laboratory of Rail Transit Engineering Informatization (Grant No.
   SKLK19-07); and in part by Postdoctoral Science Foundation of Shaanxi
   (Grant No. 2017BSHEDZZ89).
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ARXIV171110795
   [Anonymous], NEUROCOMPUTING
   [Anonymous], ARXIV170702581
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Li ZY, 2018, MED IMAGE ANAL, V43, P66, DOI 10.1016/j.media.2017.09.007
   Liu M, 2018, ACM/SIGIR PROCEEDINGS 2018, P15, DOI 10.1145/3209978.3210003
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pang SM, 2019, IEEE T IMAGE PROCESS, V28, P841, DOI 10.1109/TIP.2018.2874286
   Pang SM, 2018, PATTERN RECOGN, V83, P150, DOI 10.1016/j.patcog.2018.05.010
   Philbin J., 2008, P CVPR, P1
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Tolias G., 2016, Conference Track Proceedings,
   Hoang T, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1600, DOI 10.1145/3123266.3123417
   Nguyen VH, 2017, INT CONF SYST SCI EN, P753, DOI 10.1109/ICSSE.2017.8030977
   Wang J, 2018, INT J SPEECH-LANG PA, V20, P669, DOI 10.1080/17549507.2018.1508499
   Xu J, 2019, IEEE T IMAGE PROCESS, V28, P601, DOI 10.1109/TIP.2018.2867104
   Yang JY, 2016, NEUROCOMPUTING, V190, P70, DOI 10.1016/j.neucom.2016.01.032
   Zhang GX, 2017, NEUROCOMPUTING, V238, P399, DOI 10.1016/j.neucom.2017.01.081
   Zhong ZL, 2017, INT GEOSCI REMOTE SE, P1824
NR 37
TC 11
Z9 12
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 368
EP 380
DI 10.1016/j.jvcir.2019.06.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600034
DA 2024-07-18
ER

PT J
AU Wu, XT
   Yang, CN
AF Wu, Xiaotian
   Yang, Ching-Nung
TI A combination of color-black-and-white visual cryptography and
   polynomial based secret image sharing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Secret image sharing; Color; Embedding; Polynomial;
   Black and white
ID SCHEMES; STEGANOGRAPHY
AB A new (k, n) threshold secret image sharing scheme with two decoding options is introduced in this paper. The proposed scheme combines color-black-and-white visual cryptography scheme (CBW-VCS) and polynomial based secret image sharing (PSIS) together, to offer stacking-to-see decryption and lossless image reconstruction. To construct the color shares, a general (k, n) threshold CBW-VCS is firstly given. A grayscale secret image is converted to a p-radix image and a binary image. The p-radix image is encrypted by the (k, n) PSIS under mod p operation, and n p-radix shadows are obtained. Then, a color share generation algorithm with data embedding is proposed to construct n color shares. Theoretical analysis and sufficient experiments are provided to show the effectiveness and advantages of the proposed scheme. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wu, Xiaotian] Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Wu, Xiaotian] Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Wu, Xiaotian] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 Jinan University; Nanjing University of Information Science &
   Technology; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS; National Dong Hwa University
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.; Wu, XT (corresponding author), Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.; Wu, XT (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing, Peoples R China.; Yang, CN (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
EM wxt.sysu@gmail.com; cnyang@gms.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
OI Wu, Xiaotian/0000-0002-1484-2247
FU National Natural Science Foundation of China [61602211]; Science and
   Technology Program of Guangzhou, China [201707010259]; Fundamental
   Research Funds for the Central Universities; Ministry of Science and
   Technology [107-2221-E-259-007]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant No. 61602211), Science and Technology Program of
   Guangzhou, China (Grant No. 201707010259), Fundamental Research Funds
   for the Central Universities and Ministry of Science and Technology,
   under Grant 107-2221-E-259-007.
CR Blaldey G. R., 1979, P NAT COMP C, V88, P317
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   De Prisco R, 2013, THEOR COMPUT SCI, V510, P62, DOI 10.1016/j.tcs.2013.09.005
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Geetha P, 2018, COMPUT SECUR, V78, P301, DOI 10.1016/j.cose.2018.07.009
   Jia XX, 2019, MULTIMED TOOLS APPL, V78, P8207, DOI 10.1007/s11042-018-6779-6
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1380, DOI 10.1016/j.jvcir.2013.09.010
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
   Yang CN, 2008, COMPUT J, V51, P710, DOI 10.1093/comjnl/bxm118
   Yang CN, 2018, J VIS COMMUN IMAGE R, V55, P660, DOI 10.1016/j.jvcir.2018.07.012
   Yang CN, 2017, J VIS COMMUN IMAGE R, V42, P121, DOI 10.1016/j.jvcir.2016.10.014
   Yang CN, 2016, THEOR COMPUT SCI, V609, P143, DOI 10.1016/j.tcs.2015.09.016
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   2011, J SYST SOFTW, V84, P1197, DOI DOI 10.1016/J.JSS.2011.02.023
   1979, COMMUN ACM, V22, P612
   2010, IMAGE VISION COMPUT, V28, P1600, DOI DOI 10.1016/J.IMAVIS.2010.04.003
   2009, PATTERN RECOGN, V42, P2203, DOI DOI 10.1016/J.PATCOG.2008.11.015
   2007, J SYST SOFTW, V80, P1070, DOI DOI 10.1016/J.JSS.2006.11.022
NR 30
TC 30
Z9 31
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 74
EP 84
DI 10.1016/j.jvcir.2019.03.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100008
DA 2024-07-18
ER

PT J
AU Zhang, B
   Liu, YL
   Zhuang, J
   Wang, K
   Cao, YQ
AF Zhang, Bo
   Liu, Yulin
   Zhuang, Jie
   Wang, Kai
   Cao, Yuqiang
TI Matrix permutation meets block compressed sensing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Matrix permutation; Image compression; Image coding; Block compressed
   sensing
ID RESTRICTED ISOMETRY PROPERTY; SIGNAL RECOVERY; RECONSTRUCTION
AB Traditional block compressed sensing (CS) schemes encode nature images via a fixed sampling rate without taking the sparsity level differences among the blocks into consideration. In order to improve sampling efficiency, permutation-based block CS (BCS) schemes are proposed. In these schemes, the crux is to find a good permutation strategy which can make the nonzero entries evenly distributed among the blocks. In order to make the nonzero entries distributed among the blocks as evenly as possible, a novel matrix permutation strategy is proposed in this paper. Then, a BCS scheme with matrix permutation (BCS-MP) is proposed, which can be utilized to encode nature images effectively. Simulation results show that the proposed approach gets a significant gain of peak signal-to-noise ratio (PSNR) of the reconstructed-images compared with the state-of-the-art permutation-based ones and the traditional non-permutation one at the cost of slightly increasing the encoding time. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Bo; Wang, Kai; Cao, Yuqiang] Army Engn Univ, Commun NCO Acad, Chongqing 400035, Peoples R China.
   [Liu, Yulin] China Elect Syst Engn Corp, Shenyang 110005, Liaoning, Peoples R China.
   [Zhuang, Jie] Univ Elect Sci & Technol China, Sch Commun & Informat Engn, Chengdu 611731, Sichuan, Peoples R China.
C3 Army Engineering University of PLA; University of Electronic Science &
   Technology of China
RP Zhang, B (corresponding author), Army Engn Univ, Commun NCO Acad, Chongqing 400035, Peoples R China.
EM zhangboswjtu@163.com
RI Wang, Fei/KEH-6292-2024; Zhang, Bo/GLN-6323-2022
OI Zhang, Bo/0000-0001-6035-0887
FU National Natural Science Foundation of China [61633005, 61572089,
   61471366]; Chongqing Research Program of Basic Research and Frontier
   Technology [cstc2017jcyjBX0008]; Fundamental Research Funds for the
   Central Universities [106112017CDJQJ188830]
FX This research is funded by the National Natural Science Foundation of
   China (Grant No. 61633005, 61572089, 61471366), the Chongqing Research
   Program of Basic Research and Frontier Technology (Grant No.
   cstc2017jcyjBX0008) and the Fundamental Research Funds for the Central
   Universities (Grant Nos. 106112017CDJQJ188830). The authors would like
   to thank Prof. Di Xiao from the Chongqing University for helpful
   conversations during the development of this work. The authors also
   thank the anonymous Associate Editor and three anonymous reviewers for
   their helpful comments.
CR Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Cao YQ, 2018, AUTOM CONTROL COMPUT, V52, P118, DOI 10.3103/S0146411618020025
   Cao YQ, 2018, IEICE T FUND ELECTR, VE101A, P526, DOI 10.1587/transfun.E101.A.526
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Gan L., 2008, 2008 16th European Signal Processing Conference, P1
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Goyal VK, 2008, IEEE SIGNAL PROC MAG, V25, P48, DOI 10.1109/MSP.2007.915001
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Stankovic V, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P7, DOI 10.1109/CISP.2008.476
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Unde AS, 2017, J VIS COMMUN IMAGE R, V44, P187, DOI 10.1016/j.jvcir.2017.01.028
   Yang Y, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P373, DOI 10.1109/PCS.2009.5167354
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   Zhang B., 2017, VISUAL COMMUNICATION, DOI [10.1109/VCIP.2016.7805531, DOI 10.1109/VCIP.2016.7805531]
   Zhang B, 2018, INT CONF SIGN PROCES, P312, DOI 10.1109/ICSP.2018.8652451
   Zhang P, 2015, IEEE T SIGNAL PROCES, V63, P3974, DOI 10.1109/TSP.2015.2425809
NR 29
TC 9
Z9 9
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 69
EP 78
DI 10.1016/j.jvcir.2019.02.023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000010
DA 2024-07-18
ER

PT J
AU Hu, M
   Wang, HW
   Wang, XH
   Yang, J
   Wang, RG
AF Hu, Min
   Wang, Haowen
   Wang, Xiaohua
   Yang, Juan
   Wang, Ronggui
TI Video facial emotion recognition based on local enhanced motion history
   image and CNN-CTSLSTM networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video emotion recognition; Motion history image; LSTM; Facial landmarks
AB This paper focuses on the issue of recognition of facial emotion expressions in video sequences and proposes an integrated framework of two networks: a local network, and a global network, which are based on local enhanced motion history image (LEMHI) and CNN-LSTM cascaded networks respectively. In the local network, frames from unrecognized video are aggregated into a single frame by a novel method, LEMHI. This approach improves MHI by using detected human facial landmarks as attention areas to boost local value in difference image calculation, so that the action of crucial facial unit can be captured effectively. Then this single frame will be fed into a CNN network for prediction. On the other hand, an improved CNN-LSTM model is used as a global feature extractor and classifier for video facial emotion recognition in the global network. Finally, a random search weighted summation strategy is conducted as late-fusion fashion to final predication. Our work also offers an insight into networks and visible feature maps from each layer of CNN to decipher which portions of the face influence the networks' predictions. Experiments on the AFEW, CK+ and MMI datasets using subject-independent validation scheme demonstrate that the integrated framework of two networks achieves a better performance than using individual network separately. Compared with state-of-the-arts methods, the proposed framework demonstrates a superior performance. (C) 2018 Published by Elsevier Inc.
C1 [Hu, Min; Wang, Haowen; Wang, Xiaohua; Yang, Juan; Wang, Ronggui] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Hu, Min; Wang, Haowen; Wang, Xiaohua] Anhui Prov Key Lab Affect Comp & Adv Intelligent, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Hu, M (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.; Hu, M (corresponding author), Anhui Prov Key Lab Affect Comp & Adv Intelligent, Hefei 230009, Anhui, Peoples R China.
EM jsjxhumin@hfut.edu.cn; 2016170718@mail.hfut.edu.cn; xh_wang@hfut.edu.cn
RI wang, hw/HZH-3227-2023; Lin, Kuan-Yu/JXM-6653-2024; Wang,
   Huiwen/JED-3206-2023
FU National Natural Science Foundation of China [61672202, 61502141]; State
   Key Program of NSFC-Shenzhen Joint Foundation [01613217]; State Key
   Program of National Natural Science of China [61432004]
FX This research has been partially supported by National Natural Science
   Foundation of China (Grant No. 61672202, 61502141), State Key Program of
   NSFC-Shenzhen Joint Foundation (Grant No. 01613217) and State Key
   Program of National Natural Science of China (61432004).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2017, ARXIV170408063
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2018, ARXIV180206664
   [Anonymous], 2018, ARXIV180107848
   [Anonymous], APPEARANCE BASED MOT
   [Anonymous], ARXIV1804066552
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dhall A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2106, DOI 10.1109/ICCVW.2011.6130508
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Fan XJ, 2017, PATTERN RECOGN, V64, P399, DOI 10.1016/j.patcog.2016.12.002
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Huynh XP, 2017, IEEE INT CONF COMP V, P3065, DOI 10.1109/ICCVW.2017.362
   Kim BK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2818346.2830590
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Lee SH, 2014, IEEE T AFFECT COMPUT, V5, P340, DOI 10.1109/TAFFC.2014.2346515
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ma Chih-Yao., 2017, Ts-lstm and temporal-inception: Exploiting spatiotemporal dynamics for activity recognition
   Mayer C., 2014, Pattern Recognition and Image Analysis, V24, P124, DOI 10.1134/S1054661814010106
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Pantic M., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Ranjan R, 2018, IEEE SIGNAL PROC MAG, V35, P66, DOI 10.1109/MSP.2017.2764116
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Taheri S, 2014, IEEE T IMAGE PROCESS, V23, P3590, DOI 10.1109/TIP.2014.2331141
   Yann LeCun, 2004, COMP VIS PATT REC 20, V2
   Yao AB, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P451, DOI 10.1145/2818346.2830585
NR 39
TC 72
Z9 76
U1 2
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 176
EP 185
DI 10.1016/j.jvcir.2018.12.039
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600018
DA 2024-07-18
ER

PT J
AU Kong, J
   Liu, TS
   Jiang, M
AF Kong, Jun
   Liu, Tianshan
   Jiang, Min
TI Collaborative multimodal feature learning for RGB-D action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D action recognition; Multimodal data; Max-margin learning
   framework; Supervised matrix factorization
ID FUSION; DEPTH
AB The emergence of cost-effective depth sensors opens up a new dimension for RGB-D based human action recognition. In this paper, we propose a collaborative multimodal feature learning (CMFL) model for human action recognition from RGB-D sequences. Specifically, we propose a robust spatio-temporal pyramid feature (RSTPF) to capture dynamic local patterns around each human joint. The proposed CMFL model fuses multimodal data (skeleton, depth and RGB), and learns action classifiers using the fused features. The original low-level feature matrices are factorized to learn shared features and modality-specific features under a supervised fashion. The shared features describe the common structures among the three modalities while the modality-specific features capture intrinsic information of each modality. We formulate shared-specific features mining and action classifiers learning in a unified max-margin framework, and solve the formulation using an iterative optimization algorithm. Experimental results on four action datasets demonstrate the efficacy of the proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kong, Jun; Liu, Tianshan; Jiang, Min] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Jiang, M (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Peoples R China.
EM minjiang@jiangnan.edu.cn
RI Jiang, Min/AAJ-9579-2020; ARSLAN, Okan/AAA-3232-2020
OI Jiang, Min/0000-0003-3826-6405; Liu, Tianshan/0000-0003-3831-8893
FU National Natural Science Foundation of China [61362030, 61201429]; China
   Postdoctoral Science Foundation [2015M581720, 2016M600360]; Jiangsu
   Postdoctoral Science Foundation [1601216C]; Scientific and Technological
   Aid Program of Xinjiang [2017E0279]; Postgraduate Research and Practice
   Innovation Program of Jiangsu Province [KYCX18_1863]
FX This work was partially supported by the National Natural Science
   Foundation of China(61362030, 61201429), China Postdoctoral Science
   Foundation (2015M581720, 2016M600360), Jiangsu Postdoctoral Science
   Foundation (1601216C), Scientific and Technological Aid Program of
   Xinjiang (2017E0279), Postgraduate Research and Practice Innovation
   Program of Jiangsu Province (KYCX18_1863). The authors thank Professor
   Zicheng Liu for providing the MSR Daily Activity Dataset which helps to
   evaluate their research work proposed in this paper.
CR [Anonymous], 2013, INT JOINT C ART INT
   [Anonymous], INT J ARTIFICIAL INT
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bulbul MF, 2015, INT J MULTIMED DATA, V6, P23, DOI 10.4018/IJMDEM.2015100102
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Chen C., 2016, P 25 INT JOINT C ART, P3331
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Garcia  N., 2018, ARXIV180607110
   Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436
   Hoffman J, 2016, PROC CVPR IEEE, P826, DOI 10.1109/CVPR.2016.96
   Hu JF, 2017, IEEE T PATTERN ANAL, V39, P2186, DOI 10.1109/TPAMI.2016.2640292
   Imran J, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P144, DOI 10.1109/ICACCI.2016.7732038
   Ji XP, 2017, KNOWL-BASED SYST, V122, P64, DOI 10.1016/j.knosys.2017.01.035
   Ji XJ, 2017, SYNLETT, V28, P143, DOI 10.1055/s-0036-1588677
   Jia CC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P87, DOI 10.1145/2647868.2654928
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P2856, DOI 10.1109/TIP.2016.2556940
   Kong Y, 2015, PROC CVPR IEEE, P1054, DOI 10.1109/CVPR.2015.7298708
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Liang B, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P76
   Lin YY, 2014, PROC CVPR IEEE, P2617, DOI 10.1109/CVPR.2014.335
   Liu L., 2013, 23 INT JOINT C ART I
   Mahjoub A. B., 2017, DES TEST S, P83
   Ni BB, 2012, LECT NOTES COMPUT SC, V7573, P173, DOI 10.1007/978-3-642-33709-3_13
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Raman N, 2016, NEUROCOMPUTING, V199, P163, DOI 10.1016/j.neucom.2016.03.024
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shahzad A, 2015, INT J THERMOPHYS, V36, P2565, DOI 10.1007/s10765-014-1671-8
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Si  C., 2018, ARXIV180502335
   Singh A. P., 2008, P 14 ACM SIGKDD INT, P650
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang  J., 2014, LEARNING ACTIONLET E
   Wang PC, 2018, AAAI CONF ARTIF INTE, P7404
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925
   Yu S, 2017, J VIS COMMUN IMAGE R, V49, P192, DOI 10.1016/j.jvcir.2017.09.007
   Zhang H., 2018, ARXIV181109908
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
   Zhu  Y., 2014, EVALUATING SPATIOTEM
NR 52
TC 6
Z9 6
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 537
EP 549
DI 10.1016/j.jvcir.2019.02.013
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600056
DA 2024-07-18
ER

PT J
AU Liu, L
   Xi, ZH
   Sun, Q
AF Liu, Long
   Xi, Zhaohui
   Sun, Qiang
TI Multi-vision tracking and collaboration based on spatial particle filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Particle filter; Collaboration; Epipolar line;
   Homography
ID PEOPLE
AB In existing multi-vision tracking methods, a distributed collaborative tracking mode based on homography constraints is often adopted, yet there are significant shortcomings to this approach. For example, visual information complementation is not used to improve the robustness of tracking, and collaborative tracking is limited by homography constraints. In this study, a three-dimensional spatial particle filter tracking method was proposed, and multi-vision joint tracking and collaboration were effectively achieved. This method was based on the existing particle filter framework. A two-dimensional plane particle was taken as the projection of a three-dimensional spatial particle on the imaging plane, and the formula for calculating a spatial particle's weight was derived based on Bayesian posterior probability recursion. In addition, an approximation method to determine spatial particle weight was given. The resampling of spatial particles was performed by using an epipolar line resampling method, and a collaborative tracking mechanism was established based on the concept of resolution. The results showed that the proposed method had higher tracking precision and anti-occlusion performance than other existing methods. In this method, the robustness of tracking was effectively improved, and unlimited optimization cooperation between visual sensing was achieved. (C) 2018 Published by Elsevier Inc.
C1 [Liu, Long; Xi, Zhaohui; Sun, Qiang] Xian Univ Technol, Automat & Informat Sch, Xian 710048, Shaanxi, Peoples R China.
C3 Xi'an University of Technology
RP Liu, L (corresponding author), Xian Univ Technol, Automat & Informat Sch, Xian 710048, Shaanxi, Peoples R China.
EM liulong@xaut.edu.cn; qsun@xaut.edu.cn
FU National Natural Science Foundation of China [61673318]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016JM6020]
FX Thanks to the funding of the National Natural Science Foundation of
   China (61673318) and Natural Science Basic Research Plan in Shaanxi
   Province of China (2016JM6020).
CR [Anonymous], P 6 INT C DISTR SMAR
   Hu Weiming, 2006, PATTERN ANAL MACHINE, p[663, 671]
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Huang Shuyi, 2016, IEEE 12 INT C SIGN P, P38
   Jahanshahi P., 2015, IEEE INT C AI ROB IR, P1
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Kwolek Bogdan, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P294, DOI 10.1109/AVSS.2010.20
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P1298, DOI 10.1109/TIP.2011.2169970
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Niño-Castañeda J, 2016, IEEE T IMAGE PROCESS, V25, P2259, DOI 10.1109/TIP.2016.2542021
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Seo S, 2013, KOR-JPN JT WORKS FR, P209, DOI 10.1109/FCV.2013.6485489
   Sternig S., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1689, DOI 10.1109/ICCVW.2011.6130453
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yun YX, 2013, IEEE J EM SEL TOP C, V3, P185, DOI 10.1109/JETCAS.2013.2256814
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
NR 25
TC 7
Z9 7
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 316
EP 326
DI 10.1016/j.jvcir.2018.12.050
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600033
DA 2024-07-18
ER

PT J
AU Xiao, HM
   Lu, W
   Li, RP
   Zhong, N
   Yeung, Y
   Chen, JJ
   Xue, F
   Sun, W
AF Xiao, Huimei
   Lu, Wei
   Li, Ruipeng
   Zhong, Nan
   Yeung, Yuileong
   Chen, Junjia
   Xue, Fei
   Sun, Wei
TI Defocus blur detection based on multiscale SVD fusion in gradient domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Defocus blur detection; Multiscale singular value decomposition;
   Sub-bands; Meanshift
ID MEAN SHIFT; IMAGE
AB Recently, defocus blur detection has been an extensive study, but it is still full of challenges in the blur estimation without having any prior knowledge of test image such as blur kernel, degree, or camera parameters. Inspired by the observation that the degree of defocus blur depth could be distinguished by different frequencies, a novel blur metric based on Multiscale SVD fusion (M-SVD) is proposed. The blur metric fuses different sub-bands of the selected singular values (SVs) in multiscale image windows, which could drastically reduce the chances of false positives for blur detection and overcome the difficulty that the sharp region is misjudged for a blur region because of its smooth texture. Finally, a blur map is applied on the test image combined with post-processing operation meanshift cluster to segment the blur region. Experimental results demonstrate that the proposed method can detect the defocus blur regions of test images with a satisfactory performance and outperforms the state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xiao, Huimei; Lu, Wei; Li, Ruipeng; Yeung, Yuileong; Chen, Junjia; Xue, Fei; Sun, Wei] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Zhong, Nan] South China Agr Univ, Coll Engn, Natl Ctr Int Collaborat Res Precis Agr Aviat Pest, Guangzhou 510642, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; South China Agricultural University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Sch Data & Comp Sci,Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.; Zhong, N (corresponding author), South China Agr Univ, Coll Engn, Natl Ctr Int Collaborat Res Precis Agr Aviat Pest, Guangzhou 510642, Guangdong, Peoples R China.
EM xiaohm8@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   lirp5@mail2.sysu.edu.cn; zhongnan@scau.edu.cn;
   yeungyl@mail2.sysu.edu.cn; chenjj233@mail2.sysu.edu.cn; xuefeicn@qq.com;
   sunwei@mail.sysu.edu.cn
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; National Key
   RAMP;D Program of China [2017YFB0802500]; Natural Science Foundation of
   Guangdong [2016A030313350]; Special Funds for Science and Technology
   Development of Guangdong [2016KZ010103]; Key Project of Scientific
   Research Plan of Guangzhou [201804020068]; Fundamental Research Funds
   for the Central Universities [16lgjc83, 17lgjc45]; Alibaba Group through
   Alibaba Innovative Research Program
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the National Key R&D Program of China (No.
   2017YFB0802500), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45), the Alibaba Group through Alibaba Innovative Research
   Program.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2016, J ELECT COMPUTER ENG
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, ENG APPL ARTIF INTEL, DOI DOI 10.1016/j.engappai.2016.12.022
   [Anonymous], IEEE T CYBERNET
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2015, ACM Trans. Graph.
   [Anonymous], 1 BREAK
   [Anonymous], PARTIAL BLUR MODEL D
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Darrell T., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P504, DOI 10.1109/CVPR.1988.196282
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71
   Huang R, 2018, NEUROCOMPUTING, V285, P154, DOI 10.1016/j.neucom.2018.01.041
   Javaran TA, 2017, VISUAL COMPUT, V33, P151, DOI 10.1007/s00371-015-1166-z
   Lee H, 2014, IEEE IMAGE PROC, P4427, DOI 10.1109/ICIP.2014.7025898
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Liu R., 2008, IEEE C COMPUTER VISI, P1
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu XW, 2018, MOLECULES, V23, DOI 10.3390/molecules23061464
   Lu WN, 2018, IEEE T INSTRUM MEAS, V67, P1679, DOI 10.1109/TIM.2018.2800978
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478
   Park J, 2017, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2017.295
   Pendyala S, 2015, ANNU IEEE IND CONF
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Sanz I, 2001, J VIS COMMUN IMAGE R, V12, P240, DOI 10.1006/jvci.2001.0473
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   Tang LJ, 2016, J VIS COMMUN IMAGE R, V40, P335, DOI 10.1016/j.jvcir.2016.07.007
   Wang R, 2011, OPT ENG, V50, DOI 10.1117/1.3579459
   Wang YF, 2012, PROCEEDINGS OF THE 3RD IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT (IEEE IC-NIDC 2012), P487, DOI 10.1109/ICNIDC.2012.6418801
   Xu GD, 2017, IEEE I CONF COMP VIS, P5381, DOI 10.1109/ICCV.2017.574
   Yang D, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P2414, DOI 10.1109/ICMA.2015.7237865
   Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhu X, 2013, IEEE T IMAGE PROCESS, V22, P4879, DOI 10.1109/TIP.2013.2279316
NR 52
TC 22
Z9 25
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 52
EP 61
DI 10.1016/j.jvcir.2018.12.048
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600006
DA 2024-07-18
ER

PT J
AU Zhang, LG
   Yang, QL
   Sun, Q
   Feng, DY
   Zhao, Y
AF Zhang, Laigang
   Yang, Qili
   Sun, Qun
   Feng, Deying
   Zhao, Ying
TI Research on the size of mechanical parts based on image recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image recognition; Machine vision; Size measurement; Mechanical parts
ID OBJECT DETECTION; MACHINE; SYSTEM; CAMERA; DEEP
AB Because the image measurement technology based on machine vision has the advantages of high accuracy, high efficiency and non-contact measurement, this kind of measurement technology has gradually become the focus of attention in industrial production measurement and detection. Based on the analysis of image measurement technology, this paper studies the measurement method of mechanical parts size based on image recognition and improves related algorithms. Specific research work is as follows: Design a measurement method of machine parts size based on image recognition, study and analyze the formation of noise, types and corresponding denoising technology, select a fast median filtering algorithm to achieve filtering. Polynomial interpolation is applied to the sub-pixel edge location method to extract the edges accurately. Some classical operators are studied and analyzed with the specific part image to be tested as the experimental object. Several classical operators are compared and analyzed through many experiments. Experiments show that the improved morphological gradient operator can effectively refine the image edge. The experimental scheme proposed in this paper can better realize the measurement of mechanical parts size, and the improved algorithm has significantly improved the accuracy than before. (C) 2019 Published by Elsevier Inc.
C1 [Zhang, Laigang; Sun, Qun; Feng, Deying; Zhao, Ying] Liaocheng Univ, Sch Mech & Automot Engn, Liaocheng 252059, Shandong, Peoples R China.
   [Yang, Qili] ZaoZhuang Univ, Sch Optoelect Engn, Zaozhuang 277160, Peoples R China.
C3 Liaocheng University; Zaozhuang University
RP Yang, QL (corresponding author), ZaoZhuang Univ, Sch Optoelect Engn, Zaozhuang 277160, Peoples R China.
EM zhanglaigang@lcu.edu.cn; Yglzsb@163.com; sunqun@lcu.edu.cn;
   fengdeying@lcu.edu.cn; zhaoying@lcu.edu.cn
FU Natural Science Foundation of Shandong Province [ZR2015FL007]; National
   Natural Science Foundation of China [61603171, 61703192]
FX This work was supported by the Natural Science Foundation of Shandong
   Province (No. ZR2015FL007), National Natural Science Foundation of China
   (No. 61603171 and No. 61703192).
CR Chen X., 2014, MACHINE TOOL HYDRAUL
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dou Y, 2015, INT CONF MEAS, P991, DOI 10.1109/ICMTMA.2015.242
   Dowlati M, 2012, TRAC-TREND ANAL CHEM, V40, P168, DOI 10.1016/j.trac.2012.07.011
   Flesia AG, 2014, IEEE IMTC P, P402, DOI 10.1109/I2MTC.2014.6860776
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Han L, 2012, APPL MECH MATER, V220-223, P1377, DOI 10.4028/www.scientific.net/AMM.220-223.1377
   Han Yong, 2014, Advanced Materials Research, V912-914, P1172, DOI 10.4028/www.scientific.net/AMR.912-914.1172
   Jiao L., 2016, COMPUT MEAS CONTROL
   Li CH, 2013, ADV MATER RES-SWITZ, V694-697, P1945, DOI 10.4028/www.scientific.net/AMR.694-697.1945
   Li P., 2010, INT C COMP APPL SYST
   Li Y. F., 2016, INT C IM SIGN PROC I, P974
   Liu Y., 2014, APPL MECH MAT, V20-23, P58
   Matej J, 2014, COMPUT ELECTRON AGR, V109, P134, DOI 10.1016/j.compag.2014.09.011
   Patel KK, 2012, J FOOD SCI TECH MYS, V49, P123, DOI 10.1007/s13197-011-0321-4
   Qin ZF, 2014, APPL MECH MATER, V513-517, P3249, DOI 10.4028/www.scientific.net/AMM.513-517.3249
   Razmjooy N, 2012, COMPUT MATH APPL, V63, P268, DOI 10.1016/j.camwa.2011.11.019
   Shang XY, 2012, ADV MATER RES-SWITZ, V466-467, P602, DOI 10.4028/www.scientific.net/AMR.466-467.602
   Shen H, 2012, MEASUREMENT, V45, P719, DOI 10.1016/j.measurement.2011.12.018
   Sonka Milan, 2014, J ELECTRON IMAGING, Vxix, P685
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wang Y., 2016, J HECHI U
   Wang Y, 2014, ADV MATER RES-SWITZ, V835-836, P1186, DOI 10.4028/www.scientific.net/AMR.834-836.1186
   Wen -Yong Y. U., 2015, MODULAR MACH TOOL AU
   Xiao F., 2012, RES CONSTRUCTION CRA
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang H. P., 2015, GEAR PARTS MEASUREME
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T., 2011, INT C DIG MAN AUT, P904
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
NR 37
TC 8
Z9 9
U1 8
U2 53
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 425
EP 432
DI 10.1016/j.jvcir.2019.01.035
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600045
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Hu, CH
   Lu, XB
AF Zhang, Yang
   Hu, Changhui
   Lu, Xiaobo
TI IL-GAN: Illumination-invariant representation learning for single sample
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single sample per person; Singular value decomposition; Generative
   adversarial network; Representation learning; Illumination-invariant
   face recognition
ID IMAGE; MODELS
AB Single sample per person face recognition influenced by varying illumination is a tricky issue. Conventional techniques for illumination-invariant face recognition either realize illumination normalization on the whole face, or learn the illumination-invariant representation from the face image. This paper holds the opinion that deep learning method, which is more similar to the behavior of primate brain, can leverage the advantages of both the conventional techniques. Motivated by the success of generative adversarial network in image representation, this paper proposes IL-GAN model based on the basic structures of variational auto-encoder and generative adversarial network, generating the Controlled Illumination-level Face Image while preserves identity character as well performing a powerful latent representation from the face image, which encodes illumination-invariant signatures. Moreover, this model can be adopted in single sample per person face recognition. Meanwhile, this research proposes an novel illumination level estimation method based on singular value decomposition to generate the Controlled Illumination-level Face Image optionally. Finally, the performances of the proposed method and other state-of-the-art techniques are verified on the Extended Yale B, CMU PIE, IJB-A and our Self-built Driver Face databases. The experimental results indicate that the IL-GAN model outperforms previous approaches for single sample per person face recognition under varying illumination. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Yang; Hu, Changhui; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Zhang, Yang; Hu, Changhui; Lu, Xiaobo] Southeast Univ, Key Lab Measurement & Control Complex Syst Engn, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Changhui] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Nanjing
   University of Posts & Telecommunications
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
RI Hu, Chang-Hui/AAD-8822-2020
FU National Natural Science Foundation of China [61871123, 61802203]; Key
   Research and Development Program in Jiangsu Province [BE2016739];
   Natural Science Foundation of Jiangsu Province [BK20180311]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No. 61871123 & No. 61802203), Key Research and Development
   Program in Jiangsu Province (No. BE2016739), Natural Science Foundation
   of Jiangsu Province (No. BK20180311) and a Project Funded by the
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], 2016, DO WE REALLY NEED CO
   [Anonymous], ULTRARESOLVING FACE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ICLR
   [Anonymous], 2015, DEEP CONVOLUTIONAL I
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], UNCONSTRAINED FACE V
   [Anonymous], 2014, Computer Science
   [Anonymous], 2016, NIPS
   [Anonymous], 2012, P 29 INT C MACH LEAR
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2015, NEURIPS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ADVERSARIAL SYMMETRI
   [Anonymous], 2012, P 29 INT COFERENCE I
   [Anonymous], 2015, PUSHING FRONTIERS UN
   [Anonymous], ROTATING YOUR FACE U
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, CONDITIONAL IMAGE SY
   [Anonymous], FRONTAL PROFILE FACE
   [Anonymous], UNSUPERVISED LEARNIN
   [Anonymous], 2016, GENERATIVE ADVERSARI
   [Anonymous], 2014, LEARNING FACE REPRES
   [Anonymous], 2018, FSRNET END TO END LE
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Chiang HH, 2014, IEEE SYST J, V8, P681, DOI 10.1109/JSYST.2012.2212636
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gonzales R.C., 2002, Digital image processing
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu CH, 2015, NEUROCOMPUTING, V160, P287, DOI 10.1016/j.neucom.2015.02.032
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Kim W, 2014, IEEE SIGNAL PROC LET, V21, P1336, DOI 10.1109/LSP.2014.2334656
   Kingma D. P., 2013, STAT-US
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu HD, 2014, IMAGE VISION COMPUT, V32, P335, DOI 10.1016/j.imavis.2014.02.010
   Liu J, 2008, PATTERN RECOGN, V41, P378, DOI 10.1016/j.patcog.2007.03.027
   Long J., 2015, COMPUTER SCI, V2, P3
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Marta-Lazo C, 2019, INTERACT LEARN ENVIR, V27, P33, DOI 10.1080/10494820.2018.1451346
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Radford A., 2016, ICLR
   Salimans T., 2016, P 30 INT C NEURAL IN
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Vega PJS, 2016, SIBGRAPI, P96, DOI [10.1109/SIBGRAPI.2016.21, 10.1109/SIBGRAPI.2016.022]
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang B, 2013, NEUROCOMPUTING, V115, P186, DOI 10.1016/j.neucom.2013.02.004
   Wang JW, 2011, IEEE SIGNAL PROC LET, V18, P567, DOI 10.1109/LSP.2011.2163798
   Wei CP, 2015, IEEE T IMAGE PROCESS, V24, P1722, DOI 10.1109/TIP.2015.2409738
   Yan HB, 2014, NEUROCOMPUTING, V143, P134, DOI 10.1016/j.neucom.2014.06.012
   Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017
   Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247
   Zhu Z., 2014, MULTIVIEW PERCEPTRON
NR 68
TC 21
Z9 22
U1 0
U2 51
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 501
EP 513
DI 10.1016/j.jvcir.2019.02.007
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600053
DA 2024-07-18
ER

PT J
AU Fang, YM
   Yan, JB
   Liu, XL
   Wang, JH
AF Fang, Yuming
   Yan, Jiebin
   Liu, Xuelin
   Wang, Jiheng
TI Stereoscopic image quality assessment by deep convolutional neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Stereoscopic images; No reference;
   Convolutional neural network
AB In this paper, we propose a no-reference (NR) quality assessment method for stereoscopic images by deep convolutional neural network (DCNN). Inspired by the internal generative mechanism (IGM) in the human brain, which shows that the brain first analyzes the perceptual information and then extract effective visual information. Meanwhile, in order to simulate the inner interaction process in the human visual system (HVS) when perceiving the visual quality of stereoscopic images, we construct a two-channel DCNN to evaluate the visual quality of stereoscopic images. First, we design a Siamese Network to extract high-level semantic features of left- and right-view images for simulating the process of information extraction in the brain. Second, to imitate the information interaction process in the HVS, we combine the high-level features of left- and right-view images by convolutional operations. Finally, the information after interactive processing is used to estimate the visual quality of stereoscopic image. Experimental results show that the proposed method can estimate the visual quality of stereoscopic images accurately, which also demonstrate the effectiveness of the proposed two-channel convolutional neural network in simulating the perception mechanism in the HVS. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Fang, Yuming; Yan, Jiebin; Liu, Xuelin] Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang, Jiangxi, Peoples R China.
   [Wang, Jiheng] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada.
C3 Jiangxi University of Finance & Economics; University of Waterloo
RP Fang, YM (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Management, Nanchang, Jiangxi, Peoples R China.
EM fa0001ng@e.ntu.edu.sg
RI Liu, Xuelin/ISS-3375-2023
FU Natural Science Foundation of China [61822109, 61571212]; Fok Ying Tung
   Education Foundation [161061]; Natural Science Foundation of Jiangxi
   [20181BBH80002]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61822109 and 61571212, Fok Ying Tung Education
   Foundation under Grant 161061 and by the Natural Science Foundation of
   Jiangxi under Grant 20181BBH80002.
CR [Anonymous], P IEEE INT C QUAL MU
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], AM J PSYCHOL
   [Anonymous], 2015, 3 INT C LEARN REPR I
   [Anonymous], P CVPR
   Bare B, 2017, IEEE INT CON MULTI, P1356, DOI 10.1109/ICME.2017.8019508
   BLAKE R, 1980, PERCEPTION, V9, P223, DOI 10.1068/p090223
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   LEVELT WJM, 1966, BRIT J PSYCHOL, V57, P225, DOI 10.1111/j.2044-8295.1966.tb01023.x
   Li Q., IEEE J SEL TOP SIGNA, V3
   Lv YQ, 2016, SIGNAL PROCESS-IMAGE, V47, P346, DOI 10.1016/j.image.2016.07.003
   Meegan DV, 2001, J EXP PSYCHOL-APPL, V7, P143, DOI 10.1037//1076-898X.7.2.143
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Oh H, 2017, IEEE T IMAGE PROCESS, V26, P4923, DOI 10.1109/TIP.2017.2725584
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao F, 2016, IEEE T CYBERNETICS, V46, P730, DOI 10.1109/TCYB.2015.2414479
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Jiheng, 2014, MICROCHIM ACTA, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2016, SIGNAL PROCESS-IMAGE, V47, P16, DOI 10.1016/j.image.2016.05.008
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Wu Q., IEEE T IMAGE PROCESS, V27
   Wu QB, 2018, IEEE T CIRC SYST VID, V28, P2078, DOI 10.1109/TCSVT.2017.2710419
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Xue W., IEEE T IMAGE PROCESS, V23
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Zagoruyko N., 2015, CVPR, P1
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhou WJ, 2017, IEEE T BROADCAST, V63, P404, DOI 10.1109/TBC.2016.2638620
   Zhou WJ, 2016, IEEE T MULTIMEDIA, V18, P1077, DOI 10.1109/TMM.2016.2542580
NR 46
TC 30
Z9 34
U1 3
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 400
EP 406
DI 10.1016/j.jvcir.2018.12.006
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HK1MD
UT WOS:000457668100039
DA 2024-07-18
ER

PT J
AU Bezzine, I
   Kaaniche, M
   Boudjit, S
   Beghdadi, A
AF Bezzine, I
   Kaaniche, M.
   Boudjit, S.
   Beghdadi, A.
TI Sparse optimization of non separable vector lifting scheme for stereo
   image coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo images; Adaptive coding; Vector lifting scheme; Non separable
   transform; Optimization
ID TRANSFORM
AB One of the potential 3D imaging techniques relies on the use of stereoscopic systems. The great interest in these systems has resulted in huge amount of data which needs to be compressed for storage and transmission purposes. In this context, vector lifting scheme has been found to be an efficient approach for stereo image coding. For instance, the coding performance depends on the design of the involved lifting operators referred to as prediction and update filters. For this reason, while a non separable vector lifting structure is retained, we investigate different techniques for optimizing sparse criteria to design the filters used with both views. More precisely, an independent full optimization algorithm as well as a joint algorithm will be developed and studied. Simulations performed on different stereo images demonstrate the effectiveness of the proposed sparse optimization algorithms in terms of quality of reconstruction and bitrate saving. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Bezzine, I; Kaaniche, M.; Boudjit, S.; Beghdadi, A.] Univ Paris 13, Sorbonne Paris Cite, Inst Galilee, L2TI, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
C3 Universite Paris 13
RP Bezzine, I (corresponding author), Univ Paris 13, Sorbonne Paris Cite, Inst Galilee, L2TI, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
EM ismail.bezzine@univ-paris13.fr; mounir.kaaniche@univ-paris13.fr;
   boudjit@univ-paris13.fr; beghdadi@univ-paris13.fr
RI Beghdadi, Azeddine/ABF-9801-2022
OI Beghdadi, Azeddine/0000-0002-5595-0615
FU NPRP Grant from the Qatar National Research Fund (Qatar Foundation)
   [NPRP8-140-2-065]
FX This work was made possible by NPRP Grant No. NPRP8-140-2-065 from the
   Qatar National Research Fund (a member of Qatar Foundation). The
   statements made herein are solely the responsibility of the authors.
CR [Anonymous], VCEGM33 ITU SG16
   Boulgouris NV, 2002, IEEE T CIRC SYST VID, V12, P898, DOI 10.1109/TCSVT.2002.804895
   Chappelier V, 2006, IEEE T IMAGE PROCESS, V15, P2892, DOI 10.1109/TIP.2006.877526
   Chaux C, 2007, INVERSE PROBL, V23, P1495, DOI 10.1088/0266-5611/23/4/008
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Combettes PL, 2005, MULTISCALE MODEL SIM, V4, P1168, DOI 10.1137/050626090
   Darazi R, 2009, INT CONF ACOUST SPEE, P917, DOI 10.1109/ICASSP.2009.4959734
   Dauphin G, 2015, IEEE IMAGE PROC, P4868, DOI 10.1109/ICIP.2015.7351732
   Dhifallah O, 2014, EUR SIGNAL PR CONF, P536
   Feldmann I., 2010, Proc. of 3DTV-Conference (3DTV-CON), P1, DOI DOI 10.1109/3DTV.2010.5506312
   Gerek ÖN, 2000, IEEE T IMAGE PROCESS, V9, P1649, DOI 10.1109/83.869176
   GISH H, 1968, IEEE T INFORM THEORY, V14, P676, DOI 10.1109/TIT.1968.1054193
   Gouze A, 2004, IEEE T IMAGE PROCESS, V13, P1589, DOI 10.1109/TIP.2004.837556
   Hachicha Walid, 2013, 21st European Signal Processing Conference (EUSIPCO 2013)
   Hachicha W., 2014, EUR WORKSH VIS INF P, P1
   Hirschmuller H, 2007, CVPR, P8
   Kaaniche M, 2012, EUR SIGNAL PR CONF, P769
   Kaaniche M, 2011, SIGNAL PROCESS, V91, P2767, DOI 10.1016/j.sigpro.2011.01.003
   Kaaniche M., 2012, NON TRADITIONAL REF
   Kaaniche M, 2009, IEEE T IMAGE PROCESS, V18, P2463, DOI 10.1109/TIP.2009.2026672
   Kadaikar A, 2015, SIGNAL PROCESS-IMAGE, V39, P159, DOI 10.1016/j.image.2015.09.007
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Lucas LFR, 2017, MULTIDIM SYST SIGN P, V28, P1393, DOI 10.1007/s11045-016-0417-0
   Maalouf A, 2010, INT CONF ACOUST SPEE, P698, DOI 10.1109/ICASSP.2010.5495084
   Moellenhoff MS, 1998, SIGNAL PROCESS-IMAGE, V14, P55, DOI 10.1016/S0923-5965(98)00028-9
   Moellenhoff MS, 1998, IEEE T IMAGE PROCESS, V7, P804, DOI 10.1109/83.679421
   Moreau Jean-Jacques, 1965, B SOC MATH FRANCE, V93, P273, DOI DOI 10.24033/BSMF.1625
   Palaz D, 2011, IEEE IMAGE PROC, P133, DOI 10.1109/ICIP.2011.6115684
   Parrilli S., 2008, INT WORKSH MULT SIGN, P6
   Scharstein D., 2014, GERM C PATT REC MUNS, P12
   Sdiri B., 2018, IEEE T MED IMAG
   SWELDENS W, 1995, P SOC PHOTO-OPT INS, V2569, P68, DOI 10.1117/12.217619
   Tabus I, 2014, IEEE SIGNAL PROC LET, V21, P1220, DOI 10.1109/LSP.2014.2331107
   Taubman D., 2001, STANDARDS PRACTICE
   Usevitch B, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P387, DOI 10.1109/DCC.1996.488344
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo W, 1997, P SOC PHOTO-OPT INS, V3024, P391, DOI 10.1117/12.263251
   Xing Y., 2015, 2015 International Conference on 3D Imaging (IC3D), DOI 10.1109/IC3D.2015.7391830
NR 38
TC 11
Z9 11
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 283
EP 293
DI 10.1016/j.jvcir.2018.10.025
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400033
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chang, J
   Gu, NJ
   Zhang, XC
   Yang, L
   Lin, CW
   Huang, ZS
   Su, JJ
AF Chang, Jie
   Gu, Naijie
   Zhang, Xiaoci
   Yang, Li
   Lin, Chuanwen
   Huang, Zengshi
   Su, Junjie
TI An uniformizing method of MR image intensity transformation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MR images; Intensity value; Distribution uniformization
ID BRAIN-TUMOR SEGMENTATION
AB The scanner-dependent variations effect fluctuation of intensities of MR images, even under the fixed condition of key parameters: the scanner, the patient, the body region and the type of MRI protocol. The inherent variation causes the lack of a standard and quantifiable interpretation of image intensities. Moreover, the unbalanced distribution of intensity values lowers accuracy and sensitivity of automatic analysis and segmentation based on MR images. As such, we proposed a uniformizing method to make the distribution even while ensuring that similar intensities of MR images reflect the same tissue after processed. Our experiments based on the 3D brain tumor MR images proved that this method can significantly improve labeling and segmentation accuracy as compared to conventional preprocessed methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chang, Jie; Gu, Naijie; Zhang, Xiaoci; Huang, Zengshi; Su, Junjie] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230000, Anhui, Peoples R China.
   [Chang, Jie] Wannan Med Coll, Sch Med Informat, Wuhu 241002, Anhui, Peoples R China.
   [Chang, Jie] Wannan Med Coll, Res Ctr Hlth Big Data Min & Applicat, Wuhu 241002, Anhui, Peoples R China.
   [Yang, Li] Wannan Med Coll, Sch Med Informat, Wuhu 241000, Peoples R China.
   [Lin, Chuanwen] Hefei Univ, Dept Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Wannan Medical College; Wannan Medical College; Wannan
   Medical College; Hefei University
RP Gu, NJ (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230000, Anhui, Peoples R China.
EM cjfuture@mail.ustc.edu.cn; gunj@ustc.edu.cn; zxiaoci@mail.ustc.edu.cn;
   huang88@mail.ustc.edu.cn; jjsu@mail.ustc.edu.cn
FU National Natural Science Foundation of China [61672386]; Anhui
   Provincial Natural Science Foundation of China [1708085MF142]; Major
   Research Project Breeding Foundation of Wannan Medical College
   [WK2017Z01]; Anhui Provincial Humanities and Social Science Foundation
   of China [SK2018A0201]; ANHUI Province Key Laboratory of Affective
   Computing & Advanced Intelligent Machine [ACAIM180202]
FX This work was supported by the National Natural Science Foundation of
   China [Grant numbers 61672386]; the Anhui Provincial Natural Science
   Foundation of China [Grant numbers 1708085MF142]; the Major Research
   Project Breeding Foundation of Wannan Medical College [Grant numbers
   WK2017Z01]; the Anhui Provincial Humanities and Social Science
   Foundation of China [Grant numbers SK2018A0201]; ANHUI Province Key
   Laboratory of Affective Computing & Advanced Intelligent Machine [Grant
   numbers ACAIM180202].
CR [Anonymous], P CVPR
   [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   [Anonymous], P CVPR
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Nyul L.G., STANDARDIZING MR IMA, V1081
   Nyúl LG, 2000, IEEE T MED IMAGING, V19, P143, DOI 10.1109/42.836373
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Rao WW, 2017, IEEE ICC
   Upadhyay N., 2011, BRIT J RADIOL
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wendt R E 3rd, 1994, J Digit Imaging, V7, P95
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang Luming, 2015, FINE GRAINED IMAGE C
   Zhang Luming, 2014, PERCEPTION GUIDED MU
   Zhang Luming, 2009, FEATURE SELECTION FA
   Zhang Luming, 2015, BIOL INSPIRED MEDIA
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   Zikic D., 2014, Proc. MICCAI-BRATS, V36, P36
   Zou KH, 2004, ACAD RADIOL, V11, P178, DOI 10.1016/S1076-6332(03)00671-8
NR 35
TC 0
Z9 0
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 138
EP 151
DI 10.1016/j.jvcir.2018.10.021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400017
DA 2024-07-18
ER

PT J
AU Pan, H
   He, JR
   Ling, Y
   Ju, L
   He, GL
AF Pan, Heng
   He, Jinrong
   Ling, Yu
   Ju, Lie
   He, Guoliang
TI Graph regularized multiview marginal discriminant projection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Marginal discriminant projection; Graph Laplacian; Manifold
   regularization; Multiview learning; Dimensionality reduction;
   Hyperspectral images classification
ID FRAMEWORK
AB Multi-view data has become commonplace in today's computer vision applications, for the same object can be sampled through various viewpoints or by different instruments. The large discrepancy between distinct even heterogenous views bring the challenge of handling multi-view data. To obtain intrinsic common representation shared by all views, this paper proposes a novel multi-view algorithm called Multiview Marginal Discriminant Projection (MMDP), which is a supervised dimensionality reduction method for searching latent common subspace across multiple views. MMDP takes both inter-view and intra-view discriminant information into account and can preserve the global geometric structure and local discriminant structure of data manifold. Furthermore, the performance of MMDP is improved via imposing graph embedding as a regularization term to give a penalization of the local data geometric structure violation, which is called Graph regularized Multiview Marginal Discriminant Projection (GMMDP). The extensive experimental results on face recognition tasks demonstrate the effectiveness and robustness of MMDP and GMMDP. Finally, this paper excavates a new application scenario of multi-view learning and introduce it including the proposed GMMDP into solving hyperspectral image classification (HIC) problem, which leads to a satisfactory result. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Pan, Heng; He, Jinrong; Ling, Yu; Ju, Lie] Northwest A&F Univ, Coll Informaiton Engn, Yangling 712100, Shaanxi, Peoples R China.
   [Pan, Heng; He, Jinrong; Ling, Yu; Ju, Lie] Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
   [He, Guoliang] Wuhan Univ, Sch Comp, Wuhan 430070, Hubei, Peoples R China.
C3 Northwest A&F University - China; Ministry of Agriculture & Rural
   Affairs; Wuhan University
RP He, JR (corresponding author), Northwest A&F Univ, Coll Informaiton Engn, Yangling 712100, Shaanxi, Peoples R China.; He, JR (corresponding author), Minist Agr & Rural Affairs, Key Lab Agr Internet Things, Yangling 712100, Shaanxi, Peoples R China.
RI Ju, Lie/JHU-9528-2023; He, Jinrong/R-9293-2019
OI He, Jinrong/0000-0003-4040-4766
FU China Postdoctoral Science Foundation [2018 M633585]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2018JQ6060]; Doctoral
   Starting up Foundation of Northwest AF University [2452015302]; Students
   Innovation Training Project of China [201710712064]
FX This work was partially supported by China Postdoctoral Science
   Foundation (No. 2018 M633585), Natural Science Basic Research Plan in
   Shaanxi Province of China (No. 2018JQ6060), the Doctoral Starting up
   Foundation of Northwest A&F University (No. 2452015302), and Students
   Innovation Training Project of China (No. 201710712064).
CR [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], QUADRATICALLY CONSTR
   [Anonymous], CARTR914
   [Anonymous], IEEE T CYBERN
   [Anonymous], P INT M PSYCH SOC IM
   [Anonymous], 2016, IEEE T VEH TECHNOL
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], ADV INTELLIGENT INFO
   [Anonymous], IEEE GEOSCI REMOTE S
   [Anonymous], 2000, DTEW RES REP
   [Anonymous], J IMAGE GRAPH
   [Anonymous], REMOTE SENS TECHNOL
   [Anonymous], 2016, ACTA OPT SIN
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Fan R. K, 1997, SPECTRAL GRAPH THEOR
   He Jin-Rong, 2014, Journal of Software, V25, P826
   He JR, 2016, J SUPERCOMPUT, V72, P2095, DOI 10.1007/s11227-015-1453-5
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu W, 2015, J SENSORS, V2015, DOI 10.1155/2015/258619
   Huang S, 2015, PATTERN ANAL APPL, V18, P639, DOI 10.1007/s10044-014-0434-2
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   John S.-T, 2010, P 13 MULT INF SOC, P201
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kan MN, 2012, LECT NOTES COMPUT SC, V7572, P808, DOI 10.1007/978-3-642-33718-5_58
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Mei SH, 2017, IEEE T GEOSCI REMOTE, V55, P4520, DOI 10.1109/TGRS.2017.2693346
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   MOORE BC, 1981, IEEE T AUTOMAT CONTR, V26, P17, DOI 10.1109/TAC.1981.1102568
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Wang Hong-Qiao, 2010, Acta Automatica Sinica, V36, P1037, DOI 10.3724/SP.J.1004.2010.01037
   Yang PP, 2013, NEURAL COMPUT APPL, V22, P1337, DOI 10.1007/s00521-012-0956-8
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
NR 40
TC 7
Z9 7
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 12
EP 22
DI 10.1016/j.jvcir.2018.10.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400002
DA 2024-07-18
ER

PT J
AU Shi, D
   Zhu, L
   Cheng, ZY
   Li, ZH
   Zhang, HX
AF Shi, Dan
   Zhu, Lei
   Cheng, Zhiyong
   Li, Zhihui
   Zhang, Huaxiang
TI Unsupervised multi-view feature extraction with dynamic graph learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view feature extraction; Intrinsic sample relations; Dynamic graph
   learning
ID LOW-RANK; CLASSIFICATION; FRAMEWORK
AB Graph-based multi-view feature extraction has attracted much attention in literature. However, conventional solutions generally rely on a manually defined affinity graph matrix, which is hard to capture the intrinsic sample relations in multiple views. In addition, the graph construction and feature extraction are separated into two independent processes which may result in sub-optimal results. Furthermore, the raw data may contain adverse noises that reduces the reliability of the affinity matrix. In this paper, we propose a novel Unsupervised Multi-view Feature Extraction with Dynamic Graph Learning (UMFE-DGL) to solve these limitations. We devise a unified learning framework which simultaneously performs dynamic graph learning and the feature extraction. Dynamic graph learning adaptively captures the intrinsic multiple view-specific relations of samples. Feature extraction learns the projection matrix that could accordingly preserve the dynamically adjusted sample relations modelled by graph into the low-dimensional features. Experimental results on several public datasets demonstrate the superior performance of the proposed approach, compared with state-of-the-art techniques. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Shi, Dan; Zhu, Lei; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Li, Zhihui] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
   [Cheng, Zhiyong] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Shandong Normal University; University of New South Wales Sydney;
   National University of Singapore
RP Zhu, L (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
EM leizhu0608@gmail.com
RI Zhu, Lei/AAC-6810-2019; Li, Zhihui/AAB-7394-2020; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-2993-7142; Li, Zhihui/0000-0001-9642-8009; Zhu,
   Lei/0000-0002-5348-7532
FU National Natural Science Foundation of China [61802236]
FX The authors would like to thank the anonymous reviewers for their
   constructive and helpful suggestions. This work is supported by the
   National Natural Science Foundation of China (No. 61802236).
CR [Anonymous], COMPUTING RES REPOSI
   [Anonymous], 2002, Adv. Neural Inf. Process. Syst.
   [Anonymous], 2019, IEEE T CYBERNETICS, DOI DOI 10.1109/TCYB.2018.2831447
   [Anonymous], IEEE POTENTIALS
   Boyd S., 2004, CONVEX OPTIMIZATION
   CARROLL JD, 1980, ANNU REV PSYCHOL, V31, P607, DOI 10.1146/annurev.ps.31.020180.003135
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dong X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2064
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Grauman K., 2006, CVPR 1, P19
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Liu JG, 2009, PROC CVPR IEEE, P461, DOI 10.1109/CVPRW.2009.5206845
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Nie FP, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1181
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082299
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   van Breukelen M, 1998, KYBERNETIKA, V34, P381
   Wang W, 2018, IEEE T IMAGE PROCESS, V27, P2664, DOI 10.1109/TIP.2018.2810515
   Winn J, 2005, IEEE I CONF COMP VIS, P756
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Zhang J, 2018, IEEE SIGNAL PROC LET, V25, P333, DOI 10.1109/LSP.2017.2748604
   Zhao NW, 2017, IEEE T KNOWL DATA EN, V29, P2498, DOI 10.1109/TKDE.2017.2732986
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2015, IEEE T CYBERNETICS, V45, P2756, DOI 10.1109/TCYB.2014.2383389
   Zhu L, 2015, IEEE T MULTIMEDIA, V17, P981, DOI 10.1109/TMM.2015.2431496
   Zhuge WZ, 2017, IEEE T KNOWL DATA EN, V29, P2347, DOI 10.1109/TKDE.2017.2725263
NR 48
TC 26
Z9 26
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 256
EP 264
DI 10.1016/j.jvcir.2018.09.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500025
DA 2024-07-18
ER

PT J
AU Sun, YC
   Yu, J
AF Sun, Yuechuan
   Yu, Jun
TI General-to-specific learning for facial attribute classification in the
   wild
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial attribute; Deep convolutional network; Joint learning; Task-aware
   learning
ID FACE; REPRESENTATION
AB Recent studies have shown that facial attributes provide useful cues for a number of applications such as face verification. However, accurate facial attribute interpretation is still a formidable challenge in real life due to large head poses, occlusion and illumination variations. In this work, we propose a general to-specific deep convolutional network architecture for predicting multiple attributes from a single image in the wild. First, we model the interdependencies among all attributes by joint learning them all. Second, task-aware learning is adopted to explore the disparity regarding each attribute. Finally, an attribute-aware face cropping scheme is proposed to extract more discriminative features from where a certain attribute naturally shows up. The proposed learning strategy ensures both robustness and performance of our model. Extensive experiments on two challenging publicly available datasets demonstrate the effectiveness of our architecture and the superiority to state-of-the-art alternatives. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Sun, Yuechuan; Yu, Jun] Univ Sci & Technol China, Dept Automat, Room 301,Expt Bldg,West Campus,Huangshan Rd, Hefei, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Yu, J (corresponding author), Univ Sci & Technol China, Dept Automat, Room 301,Expt Bldg,West Campus,Huangshan Rd, Hefei, Anhui, Peoples R China.
EM ycsun@mail.ustc.edu.cn; harryjun@ustc.edu.cn
FU National Natural Science Foundation of China [U1736123, 61572450]; Anhui
   Provincial Natural Science Foundation [1708085QF138]; Fundamental
   Research Funds for the Central Universities [WK2350000002]
FX This work is supported by the National Natural Science Foundation of
   China (U1736123, 61572450), Anhui Provincial Natural Science Foundation
   (1708085QF138), the Fundamental Research Funds for the Central
   Universities (WK2350000002).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2011, Comput Math Methods Med, DOI DOI 10.1097/PRS
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299058
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Argyriou A., 2007, Advances in neural information processing systems, P41
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Duan Y., 2018, IEEE T PATTERN ANAL, P1
   Fairchild G, 2010, BIOL PSYCHIAT, V68, P272, DOI 10.1016/j.biopsych.2010.02.019
   Hand EM, 2017, AAAI CONF ARTIF INTE, P4068
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Kalayeh M. M., 2017, ARXIV170408740
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kong S, 2015, IEEE IMAGE PROC, P4922, DOI 10.1109/ICIP.2015.7351743
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lei Y.-H., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P651
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4042, DOI 10.1109/TIP.2017.2713940
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Luo P, 2013, IEEE I CONF COMP VIS, P2864, DOI 10.1109/ICCV.2013.356
   Mery D, 2015, PATTERN RECOGN LETT, V68, P260, DOI 10.1016/j.patrec.2015.05.005
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Radford A., 2015, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh KK, 2016, LECT NOTES COMPUT SC, V9910, P753, DOI 10.1007/978-3-319-46466-4_45
   Wang J, 2016, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2016.252
   Weng RL, 2016, IEEE T IMAGE PROCESS, V25, P1163, DOI 10.1109/TIP.2016.2515987
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang C, 2014, IEEE WINT CONF APPL, P1036, DOI 10.1109/WACV.2014.6835990
   Zhang Kaipeng., 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops CVPR Workshops, P34
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 50
TC 3
Z9 5
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 83
EP 91
DI 10.1016/j.jvcir.2018.09.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500007
DA 2024-07-18
ER

PT J
AU Kuai, YL
   Wen, GJ
   Li, DD
AF Kuai, Yangliu
   Wen, Gongjian
   Li, Dongdong
TI Learning adaptively windowed correlation filters for robust tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Correlation filter; Target likelihood; Window adaptation
ID OBJECT TRACKING
AB Visual tracking is a fundamental component for high-level video understanding problems such as motion analysis, event detection and action recognition. Recently, Discriminative Correlation Filters (DCF) have achieved enormous popularity in the tracking community due to high computational efficiency and fair robustness. However, the underlying boundary effect of DCF leads to a very restricted target search region at the detection step. Generally, a larger search area is adopted to overcome this disadvantage. Such an expansion of search area usually includes substantial amount of background information which will contaminate the tracking model in realist tracking scenarios. To alleviate this major drawback, we propose a generic DCF tracking framework which suppresses background information and highlights the foreground object with an object likelihood map computed from the color histograms. This object likelihood map is merged with the cosine window and then integrated into the DCF formulation. Therefore, DCF are less burdened in the training step by focusing more on pixels with higher object likelihood probability. Extensive experiments on the OTB50 and OTB100 benchmarks demonstrate that our adaptively windowed tracking framework can be combined with many DCF trackers and achieves significant performance improvement.
C1 [Kuai, Yangliu; Wen, Gongjian; Li, Dongdong] Natl Univ Def Technol, Coll Elect Sci, Changsha, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Kuai, YL (corresponding author), Natl Univ Def Technol, Coll Elect Sci, Changsha, Hunan, Peoples R China.
EM kuaiyangliunudt@163.com
CR Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Galoogahi H. K., ABS170304590 CORR
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Gundogdu E, 2016, IEEE IMAGE PROC, P1684, DOI 10.1109/ICIP.2016.7532645
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu JL, 2016, IEEE T CIRC SYST VID, V26, P2056, DOI 10.1109/TCSVT.2015.2477936
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ma L, 2015, IEEE I CONF COMP VIS, P3128, DOI 10.1109/ICCV.2015.358
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 24
TC 15
Z9 15
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 104
EP 111
DI 10.1016/j.jvcir.2018.01.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500010
DA 2024-07-18
ER

PT J
AU Li, Z
   Lang, CY
   Feng, SH
   Wang, T
AF Li, Zun
   Lang, Congyan
   Feng, Songhe
   Wang, Tao
TI Saliency ranker: A new salient object detection method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Label ranking; Matrix recovery
ID REGION DETECTION; DETECTION MODEL; IMAGE
AB Recently, saliency detection has become an active research topic in learning from labeled image, where various supervised methods were designed. Many existing methods usually cast saliency detection as a binary classification or regression problem, in which saliency detection performance relies heavily on the expensive pixel-wise annotations of salient objects. This paper addresses the issue by developing a novel learning-to-rank model with a limited number of training data, which combines the strength of cost-sensitive label ranking methods with the power of low-rank matrix recovery theories. Rather than using a binary decision for each saliency value, our approach ranks saliency values in a descending order with the estimated relevance to the given saliency. Additionally, we also aggregate the prediction models for different saliency labels into a matrix, and solve saliency ranking via a low-rank matrix recovery problem. Extensive experiments over challenging benchmarks clearly validate advantage of our method.
C1 [Li, Zun; Lang, Congyan; Feng, Songhe; Wang, Tao] Beijing Jiaotong Univ, Dept Comp Sci & Engn, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Lang, CY (corresponding author), Beijing Jiaotong Univ, Dept Comp Sci & Engn, Beijing Key Lab Traff Data Anal & Min, Beijing 100044, Peoples R China.
EM zunlee@bjtu.edu.cn; cylang@bjtu.edu.cn; shfeng@bjtu.edu.cn;
   twang@bjtu.edu.cn
FU National Natural Science Foundation of China [61472028, 61403423,
   61673048]; Beijing Natural Science Foundation [4162048, 4163075];
   Fundamental Research Funds for the Central universities [2017JBZ108,
   2017YJS049]; Jiangsu Key Laboratory of Big Data Analysis Technology,
   Nanjing University of Information Science and Technology, Nanjing, China
FX This work is supported in part by National Natural Science Foundation of
   China (61472028, 61403423, 61673048), Beijing Natural Science Foundation
   (4162048, 4163075), the Fundamental Research Funds for the Central
   universities (2017JBZ108, 2017YJS049), and Jiangsu Key Laboratory of Big
   Data Analysis Technology, Nanjing University of Information Science and
   Technology, Nanjing, China.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], EPFL
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], 1983, SOV MATH DOKL
   [Anonymous], INT C INT MULT COMP
   [Anonymous], 2002, P INT C COMP VIS
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Feng SH, 2017, IEEE T MULTIMEDIA, V19, P136, DOI 10.1109/TMM.2016.2608786
   Feng SH, 2015, IEEE T IMAGE PROCESS, V24, P1223, DOI 10.1109/TIP.2015.2395816
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji S., 2009, An accelerated gradient method for trace norm minimization, P457
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin WY, 2012, IEEE T BROADCAST, V58, P34, DOI 10.1109/TBC.2011.2170611
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Mai L, 2013, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2013.150
   Mehrani Paria., 2010, BMVC, P1
   Nesterov Y, 2013, MATH PROGRAM, V140, P125, DOI 10.1007/s10107-012-0629-5
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng H., 2013, PROC AAAI C ARTIF IN, P796
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ren JQ, 2015, IEEE COMPUT SOC CONF, DOI 10.1109/CVPRW.2015.7301391
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 58
TC 8
Z9 9
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 16
EP 26
DI 10.1016/j.jvcir.2017.11.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700003
DA 2024-07-18
ER

PT J
AU Ren, JR
   Liu, Z
   Zhou, XF
   Sun, GL
   Bai, C
AF Ren, Jingru
   Liu, Zhi
   Zhou, Xiaofei
   Sun, Guangling
   Bai, Cong
TI Saliency integration driven by similar images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency integration; Saliency propagation; Similar image; Saliency
   model
ID OBJECT DETECTION; DETECTION MODEL; VIDEO; SEGMENTATION; LOOKING; LEVEL
AB This paper proposes a saliency integration approach via the use of similar images to elevate saliency detection performance. Given the input image, a group of similar images are first retrieved, and meanwhile, the corresponding multiple saliency maps of the input image are generated by using existing saliency models. Then, the saliency fusion map is generated by using an adaptive fusion method to integrate such saliency maps, for which the fusion weights are measured by the corresponding similarity between each similar image and the input image. Next, an inter-image graph, for each pair of input image and similar image, is constructed to propagate the confident saliency values from the similar image to the input image, yielding the saliency propagation map. Finally, the saliency fusion map and the saliency propagation map are integrated to obtain the final saliency map. Experimental results on two public datasets demonstrate that the proposed approach achieves the better saliency detection performance compared to the existing saliency models and other saliency integration approaches.
C1 [Ren, Jingru; Liu, Zhi; Zhou, Xiaofei] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Ren, Jingru; Liu, Zhi; Zhou, Xiaofei; Sun, Guangling] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Bai, Cong] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Shanghai University; Shanghai University; Zhejiang University of
   Technology
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI Bai, Cong/T-9188-2019; Xiaofei, Zhou/AAE-8347-2020; LIU, Zhi/D-4518-2012
OI Bai, Cong/0000-0002-6177-3862; LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61771301, 61502424];
   Shanghai Municipal Natural Science Foundation [16ZR1411100]; Zhejiang
   Provincial Natural Science Foundation of China [LY15F020028,
   LY18F020032]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771301 and 61502424, Shanghai Municipal Natural
   Science Foundation under Grant No. 16ZR1411100, and Zhejiang Provincial
   Natural Science Foundation of China under Grants LY15F020028 and
   LY18F020032.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], P AS C COMP VIS
   [Anonymous], IEEE T CIRCUITS SYST
   Aytekin Ç, 2015, IEEE IMAGE PROC, P1692, DOI 10.1109/ICIP.2015.7351089
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lang CY, 2013, IEEE T CIRC SYST VID, V23, P1016, DOI 10.1109/TCSVT.2013.2248495
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   MAI L, 2013, PROC CVPR IEEE, P1131, DOI DOI 10.1109/CVPR.2013.150
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Nguyen TV, 2017, MULTIMED TOOLS APPL, V76, P10501, DOI 10.1007/s11042-016-3615-8
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Setlur V, 2007, IEEE COMPUT GRAPH, V27, P80, DOI 10.1109/MCG.2007.133
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Song HK, 2016, IEEE SIGNAL PROC LET, V23, P1722, DOI 10.1109/LSP.2016.2615293
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang YZ, 2010, LECT NOTES COMPUT SC, V6315, P631, DOI 10.1007/978-3-642-15555-0_46
   Ye LW, 2016, IEEE SIGNAL PROC LET, V23, P838, DOI 10.1109/LSP.2016.2558489
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou X., 2016, MULTIMED TOOLS APPL
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou WB, 2015, IEEE T IMAGE PROCESS, V24, P3858, DOI 10.1109/TIP.2015.2456497
NR 45
TC 19
Z9 19
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 227
EP 236
DI 10.1016/j.jvcir.2017.12.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700023
DA 2024-07-18
ER

PT J
AU Lee, OY
   Lee, JW
   Kim, JO
AF Lee, Oh-Young
   Lee, Jae-Won
   Kim, Jong-Ok
TI Combining self-learning based super-resolution with denoising for noisy
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Self-learning; Image super-resolution; PCA; Denoising; Noisy image
AB In this paper, we propose a new learning based joint Super-Resolution (SR) and denoising algorithm for noisy images. The individual processing of denoising and SR when super-resolving a noisy image has drawbacks such as noise amplification, blurring and SR performance reduction. In the proposed joint method, principal component analysis (PCA) based denoising is closely combined with a self-learning SR framework in order to minimize the SR visual quality degradation caused by noise. Experimental results show that the joint method achieves an SR image quality improvement in terms of noise and blurring, when compared with the state-of-the-art joint method and sequential combinations of individual denoising and SR. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Lee, Oh-Young; Lee, Jae-Won; Kim, Jong-Ok] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Kim, JO (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM triple0@korea.ac.kr; laden3647@korea.ac.kr; jokim@korea.ac.kr
RI KIM, MINJI/IXD-7702-2023
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Tech - nology Research Center) support program
   [IITP-2017-2014-0-00743]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Tech - nology
   Research Center) support program (IITP-2017-2014-0-00743) supervised by
   the IITP (Institute for Information & communications Technology
   Promotion).
CR [Anonymous], P 16 ACM INT C MULT
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai SY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1039
   Dong WS, 2009, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2009.5414423
   Freedman G., 2010, ACM T GRAPH
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Lee J., 2017, J VIS COMMUN IMAGE R, V43
   Lee O., 2016, IEEE INT C VIS COMM
   Park S. J., 2013, P APSIPA ASC 2013 OC
   Qiu F., 2011, 4 INT C IM SIGN PROC
   Sajjad M, 2015, J VIS COMMUN IMAGE R, V26, P50, DOI 10.1016/j.jvcir.2014.10.012
   Shen M., 2010, J VIS COMMUN IMAGE R, V21
   Singh A., 2014, IEEE INT C PATT REC
   Singh A., 2014, ACCV
   Singh A, 2014, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2014.364
   Suetake N, 2008, OPT REV, V15, P26, DOI 10.1007/s10043-008-0005-0
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xian Y, 2016, J VIS COMMUN IMAGE R, V35, P91, DOI 10.1016/j.jvcir.2015.11.015
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P2017, DOI 10.1109/TIP.2010.2045707
   Yang J., 2010, IEEE T IMAGE P
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 25
TC 5
Z9 5
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 66
EP 76
DI 10.1016/j.jvcir.2017.05.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700006
DA 2024-07-18
ER

PT J
AU Su, YT
   Jin, X
   Zhang, CQ
   Chen, YW
AF Su, Yuting
   Jin, Xiao
   Zhang, Chengqian
   Chen, Yawei
TI Hierarchical image resampling detection based on blind deconvolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Image resampling detection; Blind deconvolution
AB Resampling detection is a helpful tool in multimedia forensics; however, it is a challenge task in cases with compression and noisy. In this paper, by modeling the recovery of edited images using an inverse filtering process, we propose a novel resampling detection framework based on blind deconvolution. Different interpolation types in the resampling process can be distinguished by our algorithm, which is significant for practical forensics scenarios. Furthermore, in contrast to traditional resampling detection algorithms, our method can effectively avoid interference caused by JPEG block artifacts. As the experimental results show, our method is more robust than other state-of-the-art approaches in the case of strong JPEG compression and substantial Gaussian noise. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Su, Yuting; Jin, Xiao; Chen, Yawei] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Zhang, Chengqian] Southwest Petr Univ, Sch Elect Engn & Informat, Chengdu, Sichuan, Peoples R China.
C3 Tianjin University; Southwest Petroleum University
RP Chen, YW (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM ytsu@tju.edu.cn
FU National Natural Science Foundation of China [61572356, 61303208];
   Tianjin Research Program of Application Foundation and Advanced
   Technology [15JCQNJC41600]
FX This work was supported in part by the National Natural Science
   Foundation of China (61572356 and 61303208) and the Tianjin Research
   Program of Application Foundation and Advanced Technology
   (15JCQNJC41600).
CR [Anonymous], 2003, IS TSPIE ELECT IMAG
   [Anonymous], 31 AAAI C ART INT AA
   [Anonymous], P IEEE INT WORKSH IN
   [Anonymous], P IEEE CVPR
   [Anonymous], 2011, P INT WORKSH DIG WAT
   [Anonymous], P SPIE INT SOC OPTIC
   [Anonymous], P TRECVID 2008 WORKS
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Birajdar GK, 2014, AEU-INT J ELECTRON C, V68, P644, DOI 10.1016/j.aeue.2014.01.013
   Campisi P., 2007, Blindimagedeconvolution:theoryandapplications
   Cao HJ, 2012, INT CONF SIGN PROCES, P989, DOI 10.1109/ICoSP.2012.6491745
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   David V., 2011, Workshop on Information Forensics and Security, P1
   Feng XY, 2012, IEEE T MULTIMEDIA, V14, P536, DOI 10.1109/TMM.2012.2191946
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Gul G, 2010, IEEE IMAGE PROC, P1765, DOI 10.1109/ICIP.2010.5652854
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   Hou XD, 2014, MULTIMED TOOLS APPL, V72, P1681, DOI 10.1007/s11042-013-1466-0
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Liu A, 2016, IEEE T CYBER, P1
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Prasad S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1325, DOI 10.1109/ICME.2006.262783
   Ryu SJ, 2014, PATTERN RECOGN LETT, V36, P89, DOI 10.1016/j.patrec.2013.09.028
   Tang S, 2012, IEEE T MULTIMEDIA, V14, P43, DOI 10.1109/TMM.2011.2168198
   Vázquez-Padín D, 2015, EUR SIGNAL PR CONF, P2067, DOI 10.1109/EUSIPCO.2015.7362748
   Wang R, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P879, DOI 10.1109/ICIG.2009.46
   Zhang RR, 2017, MOL NEUROBIOL, V54, P6006, DOI 10.1007/s12035-016-0111-0
NR 33
TC 12
Z9 12
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 480
EP 490
DI 10.1016/j.jvcir.2017.01.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700042
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wu, CW
   Xiang, K
   Chen, W
AF Wang, Xuan-Yin
   Wu, Chang-Wei
   Xiang, Ke
   Chen, Wen
TI Efficient local and global contour detection based on superpixels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contour detection; Segmentation; Superpixels; Saliency object
   segmentation
ID IMAGE; SALIENCY
AB In this paper, two contour detection methods, inspired from gPb framework, are introduced and applied to saliency object segmentation. To improve the computational efficiency of gPb method, superpixels are introduced into the computational processes of both mPb and sPb. Specifically, for mPb, only the pixels within a given distance from the boundaries of superpixels are considered. For sPb, graph is constructed from superpixels and some selected pixels. Experiments on a public available BSDS500 image dataset show that higher efficiency could be achieved by the proposed local contour detection method, mPbSP, than mPb while with competitive results. Besides, compared with state-of-the-art methods, better results could be produced by the proposed global contour detection method, gPbSP, when a relatively small distance is considered. Moreover, experiments on PASCAL V0C2012 training segmentation dataset show that competitive results of saliency object segmentation could also be produced by the proposed methods with much less time. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Wang, Xuan-Yin; Wu, Chang-Wei; Xiang, Ke] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Mech Engn, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chen, Wen] Shanghai Inst Spaceflight Control Technol, Shanghai Key Lab Aerosp Intelligent Control Techn, Shanghai, Peoples R China.
C3 Zhejiang University
RP Wu, CW (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, Mech Engn, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM xywang@zju.edu.cn; chgw_88@163.com; kxiang@zju.edu.cn
RI wang, xuan/JBJ-6948-2023; wang, xuan/GXF-3679-2022
OI Wu, Chang-Wei/0000-0002-0889-3347
FU Science Fund for Creative Research Groups of National Natural Science
   Foundation of China [51521064]; innovation fund of Shanghai academy of
   spaceflight technology [SAST2015086]
FX This work was supported by the Science Fund for Creative Research Groups
   of National Natural Science Foundation of China [51521064]; and the
   innovation fund of Shanghai academy of spaceflight technology
   [SAST2015086].
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, PASCAL VISUAL OBJECT
   Arbelaez P., 2008, Proc. IEEE Conf. Computer Vision and Pattern Recognition CVPR 2008, P1
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Catanzaro B, 2009, IEEE I CONF COMP VIS, P2381, DOI 10.1109/ICCV.2009.5459410
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Hsiao YT, 2005, IEEE SYS MAN CYBERN, P2962
   Huang X., NEUROCOMPUTING
   Isola P, 2014, LECT NOTES COMPUT SC, V8691, P799, DOI 10.1007/978-3-319-10578-9_52
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jevnisek R. J., SEMIGLOBAL BOUNDARY
   Jiang HZ, 2013, IEEE IMAGE PROC, P3069, DOI 10.1109/ICIP.2013.6738632
   Kennedy R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2065, DOI 10.1109/CVPR.2011.5995739
   Kivinen N. H. Jyri, AISTATS
   Leordeanu M, 2012, LECT NOTES COMPUT SC, V7575, P516, DOI 10.1007/978-3-642-33765-9_37
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Mairal J., 2002, NSTAR 2002, P43
   Maire M, 2015, LECT NOTES COMPUT SC, V9006, P273, DOI 10.1007/978-3-319-16817-3_18
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Papari G, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/71828
   Pont-Tuset J, 2013, PROC CVPR IEEE, P2131, DOI 10.1109/CVPR.2013.277
   Prasad M., 2006, LEARNING CLASSSPECIF
   Ren X., 2008, MULTISCALE IMPROVES
   Sanderson C., J OPEN SOURCE SOFTWA
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun X, 2015, SENSORS-BASEL, V15, P26654, DOI 10.3390/s151026654
   Tang QL, 2016, PATTERN RECOGN, V60, P51, DOI 10.1016/j.patcog.2016.05.009
   Taylor CJ, 2013, PROC CVPR IEEE, P1916, DOI 10.1109/CVPR.2013.250
   Tsai YH, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.80
   Wu CW, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053009
   Xiaofeng Ren, 2012, NeurIPS, V25, DOI DOI 10.5555/2999134.2999200
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
NR 46
TC 2
Z9 2
U1 2
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 77
EP 87
DI 10.1016/j.jvcir.2017.06.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700007
DA 2024-07-18
ER

PT J
AU Wu, S
   Su, H
   Yang, H
   Zheng, SB
   Fan, YW
   Zhou, Q
AF Wu, Shuang
   Su, Hang
   Yang, Hua
   Zheng, Shibao
   Fan, Yawen
   Zhou, Qin
TI Bilinear dynamics for crowd video analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bilinear dynamics; Curl and divergence; Motion representation; Crowd
   scene classification; Video retrieval
AB In this paper, a novel crowd descriptor, termed as bilinear CD (Curl and Divergence) descriptor, is proposed based on the bilinear interaction of curl and divergence. Specifically, the curl and divergence activation maps are computed from the normalized average flow. A local curl patch and the corresponding divergence patch are cropped respectively from the activation maps. The outer product of the two local patches is defined as the bilinear CD vector. Through sliding a window on the activation maps, we can get hundreds to thousands local bilinear CD vectors. To encode them into a compact representation, fisher vector pooling and PCA algorithms are applied on the local descriptors. Experiments on the CUHK crowd dataset show that the proposed bilinear dynamics can improve the performance of video classification and retrieval by a noticeable margin when compared with the existing crowd features. (C) 2017 Published by Elsevier Inc.
C1 [Wu, Shuang; Yang, Hua; Zheng, Shibao; Zhou, Qin] Shanghai Jiao Tong Univ, Inst Image Proc & Network Engn, Shanghai, Peoples R China.
   [Su, Hang] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
   [Fan, Yawen] Nanjing Univ Posts & Telecommun, Key Lab Broadband Wireless Commun & Sensor Networ, Nanjing, Jiangsu, Peoples R China.
C3 Shanghai Jiao Tong University; Tsinghua University; Nanjing University
   of Posts & Telecommunications
RP Su, H (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
EM suhangss@gmail.com
RI Wu, Shuang/KIH-6794-2024
FU National Natural Science Foundation of China (NSFC) [61671289, 61171172,
   61102099, 61571261, 61521062]; Science and Technology Commission of
   Shanghai Municipality (STCSM) [15DZ1207403, 12DZ2272600]; open research
   fund of Key Lab of Broadband Wireless Communication and Sensor Network
   Technology (Nanjing University of Posts and Telecommunications, Ministry
   of Education)
FX This work was supported in part by National Natural Science Foundation
   of China (NSFC, Grant Nos. 61671289, 61171172, 61102099, 61571261 and
   61521062), Science and Technology Commission of Shanghai Municipality
   (STCSM, Grant Nos. 15DZ1207403 and 12DZ2272600) and the open research
   fund of Key Lab of Broadband Wireless Communication and Sensor Network
   Technology (Nanjing University of Posts and Telecommunications, Ministry
   of Education).
CR Ali S, 2013, IEEE I CONF COMP VIS, P1097, DOI 10.1109/ICCV.2013.140
   [Anonymous], 2016, IEEE INT S RAD FREQ
   [Anonymous], INT J COMPUT V UNPUB
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Mehran R, 2010, LECT NOTES COMPUT SC, V6313, P439
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nie WZ, 2016, IMAGE VISION COMPUT, V55, P109, DOI 10.1016/j.imavis.2016.04.011
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Jacques JCS, 2010, IEEE SIGNAL PROC MAG, V27, P66, DOI 10.1109/MSP.2010.937394
   Solmaz B, 2012, IEEE T PATTERN ANAL, V34, P2064, DOI 10.1109/TPAMI.2012.123
   Su H, 2013, IEEE T INF FOREN SEC, V8, P1575, DOI 10.1109/TIFS.2013.2277773
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Wu S, 2016, IEEE IMAGE PROC, P1205, DOI 10.1109/ICIP.2016.7532549
   Yi S., 2014, CVPR
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhou BL, 2013, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2013.392
NR 27
TC 11
Z9 11
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 461
EP 470
DI 10.1016/j.jvcir.2017.01.026
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700040
DA 2024-07-18
ER

PT J
AU Yang, RL
   Su, LF
   Zhao, XB
   Wan, H
   Sun, JG
AF Yang, Ronglu
   Su, Lifan
   Zhao, Xibin
   Wan, Hai
   Sun, Jiaguang
TI Representative band selection for hyperspectral image classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dimensional image; Band selection; Pattern recognition; Feature
   selection; Disjoint information
AB High dimensional curse for hyperspectral images is one major challenge in image classification. In this work, we introduce a novel spectral band selection method by representative band mining. In the proposed method, the distance between two spectral bands is measured by using disjoint information. For band selection, all spectral bands are first grouped into clusters, and representative bands are selected from these clusters. Different from existing clustering-based band selection methods which select bands from each cluster individually, the proposed method aims to select representative bands simultaneously by exploring the relationship among all band clusters. The optimal representative band selection is based on the criteria of minimizing the distance inside each cluster and maximizing the distance among different representative bands. These selected bands can be further applied in hyperspectral image classification. Experiments are conducted on the 92AV3C Indian Pine data set. Experimental results show that the disjoint information-based spectral band distance measure is effective and the proposed representative band selection approach outperforms state-of-the-art methods for high dimensional image classification. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yang, Ronglu; Su, Lifan; Zhao, Xibin; Wan, Hai; Sun, Jiaguang] Tsinghua Univ, Sch Software, Key Lab Informat Syst Secur, Minist Educ,Tsinghua Natl Lab Informat Sci & Tech, Beijing 100086, Peoples R China.
C3 Tsinghua University
RP Zhao, XB (corresponding author), Tsinghua Univ, Sch Software, Key Lab Informat Syst Secur, Minist Educ,Tsinghua Natl Lab Informat Sci & Tech, Beijing 100086, Peoples R China.
EM 2545812002@qq.com
RI wan, hai/GSM-9077-2022
FU NSFC [61671267, 91218302, 61527812]; National Science and Technology
   [2016ZX01038101]; National Key Technology RD Program [2015BAG14801-02];
   MILT IT funds (Research and application of TCN key technologies) of
   China
FX This research is sponsored in part by NSFC Program (Nos. 61671267,
   91218302, 61527812), National Science and Technology Major Project (No.
   2016ZX01038101), MILT IT funds (Research and application of TCN key
   technologies) of China, and The National Key Technology R&D Program (No.
   2015BAG14801-02).
CR An L, 2016, IEEE T IMAGE PROCESS, V25, P3303, DOI 10.1109/TIP.2016.2567072
   An L, 2016, IEEE T CIRC SYST VID, V26, P776, DOI 10.1109/TCSVT.2015.2416561
   [Anonymous], 2013, PROC INT C MULTIMEDI
   [Anonymous], P IEEE WORKSH ADV TE
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Bearman G. H., 2000, P SPIE, V3920
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389
   Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631, DOI 10.1109/36.803411
   Chang YL, 2011, IEEE J-STARS, V4, P579, DOI 10.1109/JSTARS.2011.2160048
   CONESE C, 1993, ISPRS J PHOTOGRAMM, V48, P2, DOI 10.1016/0924-2716(93)90059-V
   Corinna C., 1995, MACH LEARN, V20, P273, DOI [DOI 10.1007/BF00994018, 10.1007/BF00994018. S2CID 206787478]
   De Backer S, 2005, IEEE GEOSCI REMOTE S, V2, P319, DOI 10.1109/LGRS.2005.848511
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Du Q, 2008, IEEE GEOSCI REMOTE S, V5, P564, DOI 10.1109/LGRS.2008.2000619
   Du Z, 2007, IEEE T AUTOM SCI ENG, V4, P332, DOI 10.1109/TASE.2006.888048
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P2769, DOI 10.1109/TIP.2014.2319735
   Gu Y., 2016, IEEE T GEOSCI REMOTE
   Gu YF, 2016, IEEE T GEOSCI REMOTE, V54, P3235, DOI 10.1109/TGRS.2015.2514161
   Gu YF, 2015, IEEE T GEOSCI REMOTE, V53, P5312, DOI 10.1109/TGRS.2015.2421051
   Guo BF, 2006, IEEE GEOSCI REMOTE S, V3, P522, DOI 10.1109/LGRS.2006.878240
   Huang R, 2005, IEEE GEOSCI REMOTE S, V2, P156, DOI 10.1109/LGRS.2005.844658
   Ifarraguerri A, 2004, IEEE GEOSCI REMOTE S, V1, P101, DOI 10.1109/LGRS.2003.822879
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Keshava N, 2004, IEEE T GEOSCI REMOTE, V42, P1552, DOI 10.1109/TGRS.2004.830549
   Landgrebe D.A., 2003, SIGNAL THEORY METHOD, P237
   Lin JS, 2002, IEEE T SYST MAN CY C, V32, P499, DOI 10.1109/TSMCC.2002.807276
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951
   Ratle F, 2010, IEEE T GEOSCI REMOTE, V48, P2271, DOI 10.1109/TGRS.2009.2037898
   Richards J.A., 2006, Remote Sensing Digital Image Analysis: An Introduction, Vfourth
   Serpico SB, 2001, IEEE T GEOSCI REMOTE, V39, P1360, DOI 10.1109/36.934069
   Serpico SB, 2007, IEEE T GEOSCI REMOTE, V45, P484, DOI 10.1109/TGRS.2006.886177
   Shen SS, 2002, PROC SPIE, V4725, P18, DOI 10.1117/12.478755
   Sotoca J. M., IEEE T SYST MAN CYBE, V45
   Tarabalka Y, 2010, IEEE T SYST MAN CY B, V40, P1267, DOI 10.1109/TSMCB.2009.2037132
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Wang QW, 2016, IEEE T GEOSCI REMOTE, V54, P3912, DOI 10.1109/TGRS.2016.2530807
   Wang S, 2007, IEEE T GEOSCI REMOTE, V45, P2979, DOI 10.1109/TGRS.2007.901051
   Yang H, 2011, IEEE GEOSCI REMOTE S, V8, P138, DOI 10.1109/LGRS.2010.2053516
   Yuan Y, 2015, IEEE T GEOSCI REMOTE, V53, P631, DOI 10.1109/TGRS.2014.2326655
   Zare A, 2008, IEEE GEOSCI REMOTE S, V5, P256, DOI 10.1109/LGRS.2008.915934
   Zhang L, 2012, IEEE INT SYMP CIRC S
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhong YF, 2012, IEEE T SYST MAN CY B, V42, P1306, DOI 10.1109/TSMCB.2012.2189561
   Zhu GK, 2016, IEEE T GEOSCI REMOTE, V54, P227, DOI 10.1109/TGRS.2015.2453362
NR 49
TC 43
Z9 43
U1 2
U2 50
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 396
EP 403
DI 10.1016/j.jvcir.2017.02.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700033
DA 2024-07-18
ER

PT J
AU Zhang, LB
   Peng, F
   Long, M
AF Zhang, Le-Bing
   Peng, Fei
   Long, Min
TI Identifying source camera using guided image estimation and block
   weighted average
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Source camera identification; Guided image filtering; Block weighted
   average; Sensor pattern noise
ID IDENTIFICATION
AB Sensor pattern noise (SPN) has been widely used in source camera identification. However, the SPN extracted from natural image may be contaminated by its content and eventually introduce side effect to the identification accuracy. In this paper, an effective source camera identification scheme based on guided image estimation and block weighted average is proposed. Before the SPN extraction, an adaptive SPN estimator based on image content is implemented to reduce the influence of image scene and improve the quality of the SPN. Furthermore, a novel camera reference SPN construction method is put forward by using some ordinary images, instead of the blue sky images in the previous schemes, and a block weighted average approach is used to suppress the influence of the image scenes in the reference SPN. Experimental results and analysis indicate that the proposed method can effectively identify the source of the natural image, especially in actual forensics environment with a small number of images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Le-Bing; Peng, Fei] Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410112, Hunan, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Sch Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM zhanglebing@hnu.edu.cn; eepengf@gmail.com; caslongm@gmail.com
RI Zhang, Le-Bing/AHA-1060-2022; Long, Min/AGW-6059-2022; Peng,
   Fei/H-6951-2017
OI Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [61572182, 61370225]; Hunan
   Provincial Natural Science Foundation of China [15JJ2007]; Scientific
   Research Plan of Hunan Provincial Science and Technology Department of
   China [2014FJ4161]
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant Nos. 61572182, 61370225), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No. 15JJ2007), and supported by the Scientific Research Plan of Hunan
   Provincial Science and Technology Department of China (2014FJ4161).
CR Alles EJ, 2009, J FORENSIC SCI, V54, P628, DOI 10.1111/j.1556-4029.2009.01029.x
   [Anonymous], 2010, J DIGITAL FORENSIC P
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chierchia G., 2011, 2011 17 INT C DIGITA, P1
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Chierchia Giovanni., 2010, Proceedings of the 2nd ACM workshop on Multimedia in forensics, security, and intelligence, MiFor '10, P117, DOI DOI 10.1145/1877972.1878002
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fridrich J., 2013, Digital Image Forensics, P179
   Gloe T., 2012, Proceedings of the on Multimedia and security, P109
   Goljan M., 2016, Electronic Imaging, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.8.MWSF-086, DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-086]
   Goljan Miroslav, 2008, P 8 INT WORKSH DIG W, P454, DOI DOI 10.1007/978-3-642-04438-0_38
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Kang XG, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-19
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Lin XF, 2016, IEEE T INF FOREN SEC, V11, P126, DOI 10.1109/TIFS.2015.2478748
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Peng F, 2017, AEU-INT J ELECTRON C, V71, P72, DOI 10.1016/j.aeue.2016.11.009
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   San Choi K., 2006, ELECT IMAGING 2006
   SANKUR B, 2007, P SPIE ELECT IMAGING, V6505, pH1
   Satta R., 2015, INT JOINT C COMP VIS, V1, P222
   Sorell M. J., 2008, MULTIMEDIA FORENSICS, P291
   Sutcu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P24
   Sutthiwan P, 2009, LECT NOTES COMPUT SC, V5703, P323, DOI 10.1007/978-3-642-03688-0_28
   Valsesia D, 2015, IEEE T INF FOREN SEC, V10, P1472, DOI 10.1109/TIFS.2015.2415461
   Zeng H, 2016, J FORENSIC SCI, V61, P520, DOI 10.1111/1556-4029.13017
NR 34
TC 14
Z9 14
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 471
EP 479
DI 10.1016/j.jvcir.2016.12.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700041
DA 2024-07-18
ER

PT J
AU Abd Warif, NB
   Wahab, AWA
   Idris, MYI
   Salleh, R
   Othman, F
AF Abd Warif, Nor Bakiah
   Wahab, Ainuddin Wahid Abdul
   Idris, Mohd Yamani Idna
   Salleh, Rosli
   Othman, Fazidah
TI SIFT-Symmetry: A robust detection method for copy-move forgery with
   reflection attack
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind detection; Copy-move forgery; Image forensics; Reflection
   detection
AB Copy-move forgery (CMF) is a popular image manipulation technique that is simple and effective in creating forged illustrations. The bulk of CMF detection methods concentrate on common geometrical transformation attacks (e.g., rotation and scale) and post-processing attacks (e.g., Joint Photographic Experts Group (JPEG) compression and Gaussian noise addition). However, geometrical transformation that involves reflection attacks has not yet been highlighted in the literature. As the threats of reflection attack are inevitable, there is an urgent need to study CMF detection methods that are robust against this type of attack. In this study, we investigated common geometrical transformation attacks and reflection-based attacks. Also, we suggested a robust CMF detection method, called SIFT-Symmetry, that innovatively combines the Scale Invariant Feature Transform(SIFT)-based CMF detection method with symmetry based matching. We evaluated the SIFT-Symmetry with three established methods that are based on SIFT, multi-scale analysis, and patch matching using two new datasets that cover simple transformation and reflection -based attacks. The results show that the F-score of the SIFT-Symmetry method surpassed the average 80% value for all geometrical transformation cases, including simple transformation and reflection -based attacks, except for the reflection with rotation case which had an average F-score of 65.3%. The results therefore show that the SIFT-Symmetry method gives better performance compared to the other existing methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Abd Warif, Nor Bakiah; Wahab, Ainuddin Wahid Abdul; Idris, Mohd Yamani Idna; Salleh, Rosli; Othman, Fazidah] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya
RP Idris, MYI (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
EM nurbaqiyah@siswa.um.edu.my; ainuddin@um.edu.my; yamani@um.edu.my;
   rosli_salleh@um.edu.my; fazidah@um.edu.my
RI SALLEH, ROSLI/B-9611-2010; Idris, Mohd. Yamani Idna/B-5232-2010; WARIF,
   NOR BAKIAH ABD/X-5674-2019; Idris, Mohd. Yamani Idna/GPP-2401-2022;
   Wahid, Abdul/JAO-5831-2023; Abdul Wahab, Ainuddin Wahid/A-9293-2013;
   Othman, Fazidah/B-8518-2010
OI SALLEH, ROSLI/0000-0002-7379-8397; Idris, Mohd. Yamani
   Idna/0000-0003-4894-0838; WARIF, NOR BAKIAH ABD/0000-0002-6226-2271;
   Abdul Wahab, Ainuddin Wahid/0000-0003-1062-0329; Othman,
   Fazidah/0000-0002-9569-2382
FU Bright Sparks Unit; University of Malaya, Malaysia; Ministry of
   Education, Malaysia, under the University of Malaya High Impact
   [UM.C/625/1/HIR/MoE/FCSIT/17]
FX This work was fully funded by the Bright Sparks Unit, University of
   Malaya, Malaysia, and partially funded by the Ministry of Education,
   Malaysia, under the University of Malaya High Impact Research Grant
   UM.C/625/1/HIR/MoE/FCSIT/17.
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2011, CASIA TAMPERED IMAGE
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Ferreira A., 2016, IEEE T IMAGE PROCESS, V7149, P1
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Guo JM, 2013, EXPERT SYST APPL, V40, P707, DOI 10.1016/j.eswa.2012.08.002
   Hastie T., 2009, The Elements of Statistical Learning
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Kim S., 2002, IAPR WORKSH MACH VIS, P11
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Shao H, 2012, FORENSIC SCI INT, V222, P71, DOI 10.1016/j.forsciint.2012.05.002
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Wang T, 2012, COMM COM INF SC, V321, P438
   Yu L, 2014, MULTIMED TOOLS APPL
   Zandi M., 2016, IEEE T INF FOREN SEC, V11, P1
NR 30
TC 41
Z9 42
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 219
EP 232
DI 10.1016/j.jvcir.2017.04.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500020
DA 2024-07-18
ER

PT J
AU Sahu, N
   Sur, A
AF Sahu, Nilkanta
   Sur, Arijit
TI SIFT based video watermarking resistant to temporal scaling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Watermarking; Scale Invariant Feature Transform (SIFT); Feature points;
   Context coherency
AB In this paper, a blind video watermarking scheme is proposed which can resist temporal scaling such as frame dropping and frame rate adaptation due to scalable compression by exploiting the scale invariance property of the scale invariant feature transform (SIFT). A video scene can also be viewed from side plane where height is the number of rows in a video frame, width is the number of frames in the scene and depth is the number of columns in the frame. In this work, intensity values of selected embedding locations changed such that strong SIFT feature can be generated. SIFT features are extracted from side plane of the video. These newly generated SIFT features are used for watermark signal and are stored in the database for the authentication. A comprehensive set of experiments has been done to demonstrate the efficacy of the proposed scheme over the existing literature against temporal attacks. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Sahu, Nilkanta] IIIT Guwahati, Gauhati, India.
   [Sur, Arijit] IIT Guwahati, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Guwahati
RP Sahu, N (corresponding author), IIIT Guwahati, Gauhati, India.
EM sahu.nilkanta@gmail.com
RI Sur, Arijit/AAB-4216-2020
CR [Anonymous], 2002, RECBT50011
   Asikuzzaman M., 2013, VISUAL COMMUNICATION, P1
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Bollimpalli P., 2014, 2014 21 IEEE INT C I
   Fan X., 2002, JVTE070
   PIPER A, 2005, P 7 WORKSH MULT SEC, P79, DOI DOI 10.1145/1073170.1073186
   Reichel J., 2007, JOINT SCALABLE VIDEO, V11
   Sahu N., 2015, MULTIMED TOOLS APPL, P1
   Vatolin D., 2001, MSU VIDEO QUALITY ME
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
NR 10
TC 24
Z9 25
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 77
EP 86
DI 10.1016/j.jvcir.2017.02.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100007
DA 2024-07-18
ER

PT J
AU Akinlar, C
   Topal, C
AF Akinlar, Cuneyt
   Topal, Cihan
TI ColorED: Color edge and segment detection by Edge Drawing (ED)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color edge detection; Edge Drawing (ED); Vector gradient operators
   Compass; Edge segment validation; Helmholtz principle
AB We extend our recent edge and segment detector, Edge Drawing (GrayED), to detect edge segments in color images. Edge Drawing for color images, named ColorED, takes in a color image, and outputs a set of edge segments, each a contiguous, 1-pixel wide chain of pixels. Detected edge segments are then passed through an 'a contrario' validation step due to the Helmholtz principle to eliminate perceptually invalid detections. We quantitatively evaluate ColorED with different colorspaces and vector gradient operators within the precision-recall framework of the widely-used Berkeley Segmentation Dataset and Benchmark (BSDS300), and compare its results with those of GrayED and a color version of the Canny edge detector named ColorCanny. We conclude that color edge detection is in general superior to grayscale edge detection, and that ColorED with edge segment validation (ColorEDV) greatly outperforms GrayED, ColorED, and ColorCanny, producing an F-score of 0.6593 with DiZenzo and 0.6747 with the Compass operator while taking an average time of 31.5 ms for BSDS300. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Akinlar, Cuneyt; Topal, Cihan] Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
C3 Anadolu University
RP Akinlar, C (corresponding author), Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
EM cuneytakinlar@gmail.com; cihant@anadolu.edu.tr
RI Akinlar, Cuneyt/AAH-7483-2019; Akinlar, Cuneyt/U-5132-2019; TOPAL,
   CIHAN/ABC-9414-2021
OI TOPAL, CIHAN/0000-0002-6329-5251; AKINLAR, CUNEYT/0000-0002-0961-7790
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020
   Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], C COL GRAPH IM VIS C
   [Anonymous], ICCV
   [Anonymous], INT S MULT ISM
   [Anonymous], CS231AWINTER1314 STA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2001, CIE PUBLICATION
   [Anonymous], MACH INTELL
   [Anonymous], ICCV
   [Anonymous], GESTALT THEORY COMPU
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   Desolneux A, 2001, J MATH IMAGING VIS, V14, P271, DOI 10.1023/A:1011290230196
   Desolneux A., 2008, From gestalt theory to image analysis a probabilistic approach
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Gong XJ, 2011, IEEE IMAGE PROC, P1041, DOI 10.1109/ICIP.2011.6115602
   Koschan A, 2005, IEEE SIGNAL PROC MAG, V22, P64, DOI 10.1109/MSP.2005.1407716
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MCLAREN K, 1976, J SOC DYERS COLOUR, V92, P338
   Meinhardt-Llopis E, 2008, IEEE IMAGE PROC, P613, DOI 10.1109/ICIP.2008.4711829
   Moreno R, 2009, IEEE IMAGE PROC, P2153, DOI 10.1109/ICIP.2009.5414337
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   Pratt W., 2007, DIGITAL IMAGE PROCES, V4th
   Ren X., 2012, NIPS
   Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118
   Sáez A, 2013, IET IMAGE PROCESS, V7, P355, DOI 10.1049/iet-ipr.2012.0085
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Topal C, 2013, INT CONF ACOUST SPEE, P1444, DOI 10.1109/ICASSP.2013.6637890
   Topal C, 2012, J VIS COMMUN IMAGE R, V23, P862, DOI 10.1016/j.jvcir.2012.05.004
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P259, DOI 10.1109/83.217230
   TRAHANIAS PE, 1992, P SOC PHOTO-OPT INS, V1818, P1396, DOI 10.1117/12.131411
   Trahanias PE, 1996, IEEE T SYST MAN CY B, V26, P135, DOI 10.1109/3477.484445
   Zhu SY, 1999, OPT ENG, V38, P612, DOI 10.1117/1.602105
NR 38
TC 18
Z9 19
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 82
EP 94
DI 10.1016/j.jvcir.2017.01.024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600008
DA 2024-07-18
ER

PT J
AU Saini, MK
   Saini, S
AF Saini, Manish Kumar
   Saini, Sumit
TI Multiwavelet transform based license plate detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE License plate detection; Multiwavelet transform; Hilbert-Huang transform
ID WAVELET TRANSFORM; RECOGNITION; INFORMATION
AB The presented framework uses the localization concept of multiwavelet transform and empirical mode decomposition (EMD) to locate number plate from vehicle. Multiwavelet transform is similar to wavelet transform but unlike wavelet, it simultaneously provides orthogonality, symmetry, short -support and vanishing moment. Multiwavelet is used to decompose the image and EMD helps to find the actual wave crest from the projected information provided by multiwavelet transform. The effectiveness of the proposed algorithm is improvised using pre- and post-processing steps which include image enhancement and skew correction respectively. Proposed algorithm has also been tested on single and double line number plate. The performance of the proposed algorithm has been tested on various countries' number plates like Croatia, Austria, France, India and Greece, and in various conditions like shadow, dirt and blurry. Proposed algorithm has detected number plate with high accuracy and in relatively less time. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Saini, Manish Kumar; Saini, Sumit] DCR Univ Sci & Technol, Dept Elect Engn, Sonepat, India.
C3 Deenbandhu Chhotu Ram University of Science & Technology
RP Saini, MK (corresponding author), DCR Univ Sci & Technol, Dept Elect Engn, Sonepat, India.
EM manishkumar.ee@dcrustm.org
RI Saini, Manish Kumar/AAB-5704-2022; Saini, Manish/AAB-5704-2022
OI Saini, Manish Kumar/0000-0003-1564-5058; Saini,
   Manish/0000-0001-7121-5189
FU AOLP; Media Lab LPR database
FX This work is partly supported by AOLP and Media Lab LPR database.
CR Abo Samra GA, 2014, IEEE T EVOLUT COMPUT, V18, P244, DOI 10.1109/TEVC.2013.2255611
   [Anonymous], 2011, THESIS U IOWA LOWA C
   [Anonymous], DIGITAL IMAGE PROCES
   Ashtari A., 2014, IEEE T INTELL TRANSP, V15, P1
   Azam S, 2016, J VIS COMMUN IMAGE R, V36, P172, DOI 10.1016/j.jvcir.2016.01.015
   Deb Kaushik, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P3291
   Dimitri A.L., 2005, P 2005 IEEE COMP SOC
   Friedrich M., 2008, INT C SURV METH TRAN, V8, P1
   Ghahnavieh AE, 2014, IRAN CONF ELECTR ENG, P220, DOI 10.1109/IranianCEE.2014.6999536
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Hinds S.C., 1990, P 10 INT C PATT REC
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Kapoor R, 2004, PATTERN RECOGN LETT, V25, P1215, DOI 10.1016/j.patrec.2004.03.020
   Kapoor R., 2007, J I ENG INDIA ELECT, V88, P9
   Kapoor R., 2010, International Journal of Nonlinear Science, V10, P279
   Kapoor R, 2012, EUR T ELECTR POWER, V22, P518, DOI 10.1002/etep.581
   Lalimi MA, 2013, COMPUT ELECTR ENG, V39, P834, DOI 10.1016/j.compeleceng.2012.09.015
   Li Y, 2015, TRANSPORT RES C-EMER, V51, P19, DOI 10.1016/j.trc.2014.10.009
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   Massoud MA, 2013, ALEX ENG J, V52, P319, DOI 10.1016/j.aej.2013.02.005
   Namitha S., 2014, INT J EMERGING TECHN, V4, P85
   Pan MS, 2008, INT J AUTOM COMPUT, V5, P425, DOI 10.1007/s11633-008-0425-0
   Panahi R., 2016, IEEE T INTELL TRANSP, V18, P1
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Saini M., 2013, INT C SIGN PROC COMM
   Saini M., 2015, INT J ELECT ELECT CO, V4, P67
   Saini M., 2009, INT J NETWORK SECUR, V1, P118
   Saini M.K., 2013, P INT C ADV SIGN PRO, P118
   Tadic V, 2016, ENG APPL ARTIF INTEL, V48, P40, DOI 10.1016/j.engappai.2015.09.009
   Tian YM, 2016, NEUROCOMPUTING, V212, P22, DOI 10.1016/j.neucom.2016.02.081
   Tsai S. J. S, 2002, THESIS
   Verma VS, 2015, J VIS COMMUN IMAGE R, V31, P75, DOI 10.1016/j.jvcir.2015.06.001
   Wafy M, 2016, IET INTELL TRANSP SY, V10, P389, DOI 10.1049/iet-its.2015.0064
   Wang RM, 2014, OPTIK, V125, P2283, DOI 10.1016/j.ijleo.2013.10.126
   Wang RM, 2014, OPTIK, V125, P186, DOI 10.1016/j.ijleo.2013.06.008
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Yang X., 2011, INT J OPTIK, V123, P1486
   Yao ZJ, 2014, INFORM FUSION, V18, P78, DOI 10.1016/j.inffus.2013.05.008
   Yu SY, 2015, PATTERN RECOGN, V48, P114, DOI 10.1016/j.patcog.2014.07.027
NR 41
TC 9
Z9 9
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 128
EP 138
DI 10.1016/j.jvcir.2017.01.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600012
DA 2024-07-18
ER

PT J
AU Xu, YY
   Gong, JY
   Xiong, LZ
   Xu, ZQ
   Wang, JW
   Shi, YQ
AF Xu, Yanyan
   Gong, Jiaying
   Xiong, Lizhi
   Xu, Zhengquan
   Wang, Jinwei
   Shi, Yun-qing
TI A privacy-preserving content-based image retrieval method in cloud
   environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Privacy-preserving; Image retrieval; Secure search; Orthogonal
   decomposition
ID HOMOMORPHIC ENCRYPTION; EXTRACTION; DOMAIN
AB In order to protect data privacy, image with sensitive or private information needs to be encrypted before being outsourced to a cloud service provider. However, this causes difficulties in image retrieval and data management. A privacy-preserving content-based image retrieval method based on orthogonal decomposition is proposed in the paper. The image is divided into two different components, for which encryption and feature extraction are executed separately. As a result, cloud server can extract features from an encrypted image directly and compare them with the features of the queried images, so that users can thus obtain the image. Different from other methods, the proposed method has no special requirements to encryption algorithms, which makes it more universal and can be applied in different scenarios. Experimental results prove that the proposed method can achieve better security and better retrieval performance. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Xu, Yanyan; Gong, Jiaying; Xu, Zhengquan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
   [Xiong, Lizhi; Wang, Jinwei] Nanjing Univ Sci & Technol, Sch Comp & Software, Nanjing 210094, Jiangsu, Peoples R China.
   [Shi, Yun-qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Wuhan University; Nanjing University of Science & Technology; New Jersey
   Institute of Technology
RP Xu, YY (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
EM xuyy@whu.edu.cn
RI Shi, Yun/JWP-3360-2024; Xiong, Lizhi/KCK-1464-2024
FU National Natural Science Foundation of China [41571426, 4137140,
   261232016, U1405254]; PAPD; LIESMARS Special Research Funding
FX We thank the anonymous reviewers for their helpful suggestions. This
   work was supported by the National Natural Science Foundation of China
   under Grant 41571426, 41371402, 61232016, U1405254, PAPD, and LIESMARS
   Special Research Funding.
CR [Anonymous], 2016, IEEE T INF FORENSICS
   Cheng H, 2016, MULTIMED TOOLS APPL, V75, P13791, DOI 10.1007/s11042-015-2741-z
   Edmundson David, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P587, DOI 10.1109/ICSPCC.2012.6335725
   EOM M, 2005, INT C ENF SYST SCI E
   Erkin Z., 2007, EURASIP J INF SEC, V2008
   Ferreira B, 2015, SYM REL DIST SYST, P11, DOI 10.1109/SRDS.2015.27
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Karthik K, 2013, SIGNAL IMAGE VIDEO P, V7, P647, DOI 10.1007/s11760-013-0471-0
   Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653
   Lay JA, 1999, INT CONF ACOUST SPEE, P3009, DOI 10.1109/ICASSP.1999.757474
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lu WJ, 2014, IEEE ACCESS, V2, P125, DOI 10.1109/ACCESS.2014.2307057
   Lu ZM, 2006, INT J INNOV COMPUT I, V2, P831
   Schaefer Gerald, 2012, Active Media Technology. 8th International Conference, AMT 2012. Proceedings, P318, DOI 10.1007/978-3-642-35236-2_32
   Song TC, 2013, IEEE SIGNAL PROC LET, V20, P59, DOI 10.1109/LSP.2012.2229273
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Xu ZQ, 2014, SIGNAL PROCESS-IMAGE, V29, P607, DOI 10.1016/j.image.2013.10.007
   Zhang Y, 2014, INT CONF DIGIT SIG, P269, DOI 10.1109/ICDSP.2014.6900669
NR 21
TC 47
Z9 51
U1 5
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 164
EP 172
DI 10.1016/j.jvcir.2017.01.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400016
DA 2024-07-18
ER

PT J
AU Hagag, A
   Fan, XP
   Abd El-Samie, FE
AF Hagag, Ahmed
   Fan, Xiaopeng
   Abd El-Samie, Fathi E.
TI HyperCast: Hyperspectral satellite image broadcasting with band ordering
   optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral satellite images; Image broadcasting; Karhunen-Loeve
   Transform (KLT); Hyperspectral band ordering; SoftCast; LineCast;
   Wireless communications
ID COMPRESSION; TRANSMISSION; TRANSFORM; LOSSY
AB This paper presents a novel framework for hyperspectral satellite image broadcasting over wireless channels. We present a new hyperspectral band ordering algorithm that improves the compression performance. The proposed scheme employs the 1D low-complexity Karhunen-Loeve transform (KLT) that uses a clustering approach for spectral decorrelation. After that, the 2D DCT is applied to remove the redundant information from the spatial bands. The DCT components are quantized using a simple DC-quantization algorithm. After that, the transmission power is directly allocated to the quantized data according to their distributions and magnitudes without forward error correction (FEC). These data are transformed by Hadamard matrix and transmitted over a dense constellation. Experiments demonstrate that the proposed scheme improves the average image quality by 6.98 dB and 3.48 dB over LineCast and SoftCast, respectively, and it achieves up to 6.14 dB gain over JPEG2000 with FEC. (C) 2016 Published by Elsevier Inc.
C1 [Hagag, Ahmed; Fan, Xiaopeng] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Hagag, Ahmed] Egyptian E Learning Univ, Fac Informat Technol, Dept Informat Technol, Giza 12611, Egypt.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Harbin Institute of Technology; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Fan, XP (corresponding author), Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150001, Peoples R China.
EM ahagag88@gmail.com; fxp@hit.edu.cn; fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Hagag, Ahmed/0000-0003-2631-1846
FU National Science Foundation of China (NSFC) [61472101, 61631017,
   61390513]; Major State Basic Research Development Program of China (973
   Program) [2015CB351804]; National High Technology Research and
   Development Program of China (863 Program) [2015AA015903]
FX This work was supported in part by the National Science Foundation of
   China (NSFC) under grants 61472101, 61631017 and 61390513, the Major
   State Basic Research Development Program of China (973 Program
   2015CB351804), and the National High Technology Research and Development
   Program of China (863 Program 2015AA015903). The authors would like to
   thank Dr. Ibrahim Omara for his support in this work and also the
   anonymous reviewers for their valuable comments that greatly improved
   this paper.
CR Auli-Llinas F., 2014, BOI CODEC
   Blanes Ian, 2009, 2009 Data Compression Conference. DCC 2009, P233, DOI 10.1109/DCC.2009.7
   Blanes I, 2014, IEEE GEOSC REM SEN M, V2, P8, DOI 10.1109/MGRS.2014.2352465
   Blanes I, 2012, IEEE SIGNAL PROC MAG, V29, P71, DOI 10.1109/MSP.2011.2179416
   Blanes I, 2011, IEEE T GEOSCI REMOTE, V49, P961, DOI 10.1109/TGRS.2010.2071880
   Carvajal G, 2008, IEEE GEOSCI REMOTE S, V5, P593, DOI 10.1109/LGRS.2008.2000651
   CCSDS, 2005, 1220B1 CCSDS
   Crowley MD, 2006, INT GEOSCI REMOTE SE, P907, DOI 10.1109/IGARSS.2006.233
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   Du Q, 2009, IEEE GEOSCI REMOTE S, V6, P713, DOI 10.1109/LGRS.2009.2024175
   Fan X., IEEE T CIRC SYST VID, V23
   Ghandi MM, 2006, J VIS COMMUN IMAGE R, V17, P451, DOI 10.1016/j.jvcir.2005.05.005
   Hagag A, 2015, SIGNAL IMAGE VIDEO P, V9, P769, DOI 10.1007/s11760-013-0516-4
   Hagag A, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073511
   Jakubczak S., 2011, PROC MOBICOM, P289
   Johnson M, 2004, COMPUT NETW, V46, P423, DOI 10.1016/j.comnet.2004.06.015
   Kratochvil T., 2009, LECT NOTES ELECT ENG, P333
   Liveris AD, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P53
   Penna B., P INT REM SENS S, V7
   Penna B, 2007, IEEE T GEOSCI REMOTE, V45, P1408, DOI 10.1109/TGRS.2007.894565
   RAMCHANDRAN K, 1993, IEEE J SEL AREA COMM, V11, P6, DOI 10.1109/49.210540
   Reznic Z., 2011, U.S. Patent, Patent No. [8, 006, 168, 8006168]
   Saghri JA, 2010, OPT ENG, V49, DOI 10.1117/1.3425656
   Schwarz Heike., 2007, IEEE Transactions on Circuits and Systems for Video Technology, V17
   Shannon C. E., 1961, P 4 BERK S MATH STAT, V1, P611
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Taubman D., 2012, JPEG2000 IMAGE COMPR, V642
   Wu F, 2014, IEEE T IMAGE PROCESS, V23, P1015, DOI 10.1109/TIP.2014.2298972
   Xu Q, 2007, IEEE J SEL AREA COMM, V25, P851, DOI 10.1109/JSAC.2007.070520
NR 29
TC 8
Z9 8
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 14
EP 27
DI 10.1016/j.jvcir.2016.11.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200002
OA Bronze
DA 2024-07-18
ER

PT J
AU Lai, Y
   Lan, XG
   Liu, YH
   Zheng, NN
AF Lai, Yi
   Lan, Xuguang
   Liu, Yuehu
   Zheng, Nanning
TI An efficient depth image-based rendering with depth reliability maps for
   view synthesis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth image-based rendering; Depth reliability maps; Interpolation
   weight; View synthesis
ID INTERPOLATION; SYSTEM
AB In this paper, an efficient depth image-based rending (DIBR) with depth reliability maps (DRM) is proposed to improve the quality of synthesized images. First, a DRM-based occlusion-aware approach is developed to obtain a segmentation mask, which can explicitly indicate where the information in an intermediate image should be blended preferably. Next, an improved weight model for view creation is introduced to enhance the quality of synthesized images. Finally, a distance and depth-based sub pixel weighted (DDSPW) algorithm is presented to solve the visibility and resampling problems. Experimental results demonstrate that the treated DIBR schemes have better performance for view synthesis than the other three methods through the subjective visual perception and objective assessments in terms of peak signal to noise ratio and structural similarity index. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lai, Yi] Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
   [Lan, Xuguang; Liu, Yuehu; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an Jiaotong
   University
RP Lai, Y (corresponding author), Xian Univ Posts & Telecommun, Sch Telecommun & Informat Engn, Xian 710121, Peoples R China.
EM laiyi0614@163.com; xglan@aiar.xjtu.edu.cn; yhliu@aiar.xjtu.edu.cn;
   nnzheng@aiar.xjtu.edu.cn
RI Lan, Xuguang/N-8814-2019
OI Lan, Xuguang/0000-0002-3422-944X
FU Program 973 [2012CB316400]; NSFC [61175010, 60805044]
FX This work was supported in part by the Program 973 No. 2012CB316400, and
   NSFC No. 61175010 and 60805044.
CR [Anonymous], 3DTV C TRUE VIS CAPT
   [Anonymous], 3DTV C TRUE VIS CAPT
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chan SC, 2007, IEEE SIGNAL PROC MAG, V24, P22, DOI 10.1109/MSP.2007.905702
   Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Chen WY, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P1315
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   De Abreu A, 2015, J VIS COMMUN IMAGE R, V33, P255, DOI 10.1016/j.jvcir.2015.09.010
   Fan YC, 2014, J DISP TECHNOL, V10, DOI 10.1109/JDT.2014.2331064
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Greene N., 1993, Computer Graphics Proceedings, P231, DOI 10.1145/166117.166147
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Hirschmuller H., 2007, P IEEE COMP SOC C CO
   Lai Y, 2012, IEEE DATA COMPR CONF, P402, DOI 10.1109/DCC.2012.57
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Mark W. R., 1999, THESIS
   McMillan Leonard, 1997, THESIS
   Morvan Y, 2007, LECT NOTES COMPUT SC, V4678, P675
   Ohm JR, 1997, IEEE T CIRC SYST VID, V7, P801, DOI 10.1109/76.633502
   Park JH, 2006, IEEE T IMAGE PROCESS, V15, P1751, DOI 10.1109/TIP.2006.877070
   Purica AI, 2016, IEEE T CIRC SYST VID, V26, P360, DOI 10.1109/TCSVT.2015.2389511
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Sharma M, 2014, J VIS COMMUN IMAGE R, V25, P599, DOI 10.1016/j.jvcir.2013.07.012
   Shum H., 2007, IMAGE BASED RENDERIN
   Takahashi K, 2010, LECT NOTES COMPUT SC, V6314, P340, DOI 10.1007/978-3-642-15561-1_25
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolberg G., 1990, Digital image warping
   Xin Tong, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P490, DOI 10.1109/PCS.2010.5702544
   Xiu XY, 2011, IEEE T CIRC SYST VID, V21, P693, DOI 10.1109/TCSVT.2011.2129230
   Yuan H, 2012, IEEE T BROADCAST, V58, P558, DOI 10.1109/TBC.2012.2187612
   Zhang L., 2013, ITUTSG16WP3
NR 33
TC 5
Z9 6
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 176
EP 184
DI 10.1016/j.jvcir.2016.09.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000016
DA 2024-07-18
ER

PT J
AU Oszust, M
AF Oszust, Mariusz
TI BDSB: Binary descriptor with shared pixel blocks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Binary descriptor; Robust features; Image matching; Object recognition
ID PERFORMANCE EVALUATION; FEATURE-DETECTORS; SIFT
AB The recent growth of multimedia content used in daily-life communication requires the development of image description techniques able to unequivocally identify observed objects, despite image transformations, demanding lighting conditions, or noise. This paper focuses on binary feature descriptors which are often used for this purpose. They have smaller memory footprint, and are faster to compute and match than their floating-point counterparts. Hand-crafted binary descriptors use an image patch around the detected keypoint and divide it into disjoint regions, or select pixels according to a sampling scheme. In this paper, an approach to binary, rotation and scale invariant descriptor is proposed. In the descriptor, a small number of scale-dependent patches are divided into overlapping blocks of pixels, and then binary tests are performed on blocks' intensities and gradients. The extensive experimental evaluation of the approach on seven image benchmarks reveals that it outperforms compared state-of-the-art techniques. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Oszust, Mariusz] Rzeszow Univ Technol, Dept Comp & Control Engn, Wincentego Pola 2, PL-35959 Rzeszow, Poland.
C3 Rzeszow University of Technology
RP Oszust, M (corresponding author), Rzeszow Univ Technol, Dept Comp & Control Engn, Wincentego Pola 2, PL-35959 Rzeszow, Poland.
EM marosz@kia.prz.edu.pl
RI Oszust, Mariusz/AAC-3224-2022
OI Oszust, Mariusz/0000-0002-5482-6313
CR Abeles P, 2013, LECT NOTES COMPUT SC, V8034, P454, DOI 10.1007/978-3-642-41939-3_44
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   [Anonymous], ARXIV 1512 03385
   [Anonymous], 2012, 2012 IEEE INT S MIX
   [Anonymous], 2015, MULTIMEDIA TOOL APPL
   [Anonymous], 260 SWISS FED I TECH
   [Anonymous], ABS150405133 CORR
   [Anonymous], 2008, MIR 08
   [Anonymous], MULTIMED TOOLS APPL
   Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bianco S, 2015, DIGIT SIGNAL PROCESS, V44, P1, DOI 10.1016/j.dsp.2015.06.001
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Calonder M, 2009, IEEE I CONF COMP VIS, P357, DOI 10.1109/ICCV.2009.5459272
   Chen CC, 2015, J VIS COMMUN IMAGE R, V30, P86, DOI 10.1016/j.jvcir.2015.02.014
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Fan B, 2014, IEEE T IMAGE PROCESS, V23, P2583, DOI 10.1109/TIP.2014.2317981
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Garcia-Fidalgo E, 2015, ROBOT AUTON SYST, V64, P1, DOI 10.1016/j.robot.2014.11.009
   Gbèhounou S, 2016, J VIS COMMUN IMAGE R, V38, P276, DOI 10.1016/j.jvcir.2016.03.009
   Geng LC, 2016, NEUROCOMPUTING, V184, P43, DOI 10.1016/j.neucom.2015.07.120
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Hietanen A, 2016, NEUROCOMPUTING, V184, P3, DOI 10.1016/j.neucom.2015.08.106
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jin L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P311, DOI 10.1109/ISM.2014.56
   Kannala J, 2012, INT C PATT RECOG, P1363
   Khan N, 2015, MACH VISION APPL, V26, P819, DOI 10.1007/s00138-015-0689-7
   Kieu H, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/3/035401
   Kim J, 2011, INTEL SERV ROBOT, V4, P191, DOI 10.1007/s11370-011-0091-x
   Kim MU, 2015, MULTIMED TOOLS APPL, V74, P2499, DOI 10.1007/s11042-014-2152-6
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li XC, 2015, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR.2015.7299151
   Lindeberg T, 2015, J MATH IMAGING VIS, V52, P3, DOI 10.1007/s10851-014-0541-0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mandal B, 2016, NEUROCOMPUTING, V184, P107, DOI 10.1016/j.neucom.2015.07.121
   Matas Jiri, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1721
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mukherjee D, 2015, MACH VISION APPL, V26, P443, DOI 10.1007/s00138-015-0679-9
   Musialski P, 2013, COMPUT GRAPH FORUM, V32, P146, DOI 10.1111/cgf.12077
   Nister David, 2006, CVPR
   Oszust M, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/3/035402
   Pan YW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P233, DOI 10.1145/2647868.2656404
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370
   Turcot Panu, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2109, DOI 10.1109/ICCVW.2009.5457541
   Vonikakis V, 2013, MEAS SCI TECHNOL, V24, DOI 10.1088/0957-0233/24/7/074024
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Wei X, 2016, ARTIF INTELL REV, V45, P333, DOI 10.1007/s10462-015-9448-4
   Wu J, 2013, MEAS SCI REV, V13, P122, DOI 10.2478/msr-2013-0021
   Xu C, 2016, IEEE T IMAGE PROCESS, V25, P1495, DOI 10.1109/TIP.2016.2524207
   Xu XW, 2014, IEEE T IMAGE PROCESS, V23, P2983, DOI 10.1109/TIP.2014.2324824
   Yang X, 2014, IEEE T PATTERN ANAL, V36, P188, DOI 10.1109/TPAMI.2013.150
   Yong Luo, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P551, DOI 10.1109/ICIG.2013.116
NR 63
TC 3
Z9 3
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 154
EP 165
DI 10.1016/j.jvcir.2016.09.013
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000014
DA 2024-07-18
ER

PT J
AU Wang, XD
   Chen, RC
   Yan, F
   Zeng, ZQ
AF Wang, Xiao-dong
   Chen, Rung-Ching
   Yan, Fei
   Zeng, Zhi-qiang
TI Semi-supervised feature selection with exploiting shared information
   among multiple tasks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semi-supervised learning; Feature selection; Multi-task learning; Face
   recognition; 3D motion data analysis; Spoken letter recognition;
   Handwritten digits recognition
ID CLASSIFICATION; RECOGNITION
AB Given several related tasks, multi-task feature selection determines the importance of features by mining the correlations between them. There have already many efforts been made on the supervised multi-task feature selection. However, in real-world applications, it's noticeably time-consuming and unpractical to collect sufficient labeled training data for each task. In this paper, we propose a novel feature selection algorithm, which integrates the semi-supervised learning and multi-task learning into a joint framework. Both the labeled and unlabeled samples are sufficiently utilized for each task, and the shared information between different tasks is simultaneously explored to facilitate decision making. Since the proposed objective function is non-smooth and difficult to be solved, we also design an efficient iterative algorithm to optimize it. Experimental results on different applications demonstrate the effectiveness of our algorithm. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Xiao-dong; Yan, Fei; Zeng, Zhi-qiang] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Wang, Xiao-dong; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
C3 Xiamen University of Technology; Chaoyang University of Technology
RP Wang, XD; Chen, RC (corresponding author), Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
EM xdwangjsj@xmut.edu.cn; crching@cyut.edu.tw
RI zeng, zhiqiang/D-7708-2017; wang, xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61103100]; National
   Natural Science Foundation of Fujian Province, China [2016J01324];
   International Science and Technology Cooperation Program of Xiamen
   University of Technology [E201400400]; Xiamen Science and Technology
   Planning Project [3502Z20143030, 3502Z20103037, 3502Z20133043];
   Scientific Research Fund of Fujian Provincial Education Department
   [JA15385]; Scientific Research Fund of Zhejiang Provincial Education
   Department [Y201326609]
FX This paper is supported by National Natural Science Foundation of China
   (Grant No. 61103100), National Natural Science Foundation of Fujian
   Province, China (Grant No. 2016J01324), the International Science and
   Technology Cooperation Program of Xiamen University of Technology (No.
   E201400400), Xiamen Science and Technology Planning Project (Nos.
   3502Z20143030, 3502Z20103037, 3502Z20133043), Scientific Research Fund
   of Fujian Provincial Education Department (No. JA15385), and Scientific
   Research Fund of Zhejiang Provincial Education Department (No.
   Y201326609).
CR [Anonymous], 2011, IJCAI INT JOINT C AR
   [Anonymous], P 17 AAAI C LAT BREA
   Argyriou A, 2008, MACH LEARN, V73, P243, DOI 10.1007/s10994-007-5040-8
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Cheng Zheng-Dong, 2010, Acta Automatica Sinica, V36, P1361, DOI 10.3724/SP.J.1004.2010.01361
   Doquire G, 2013, NEUROCOMPUTING, V121, P5, DOI 10.1016/j.neucom.2012.10.028
   Fung G., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P64, DOI 10.1145/347090.347105
   Gu Q., 2011, 27 C UNC ART INT UAI, P266
   He X., 2005, P ADV NEURAL INFORM, V18, P507
   He X. F., 2007, P 10 IEEE INT C COMP, P823
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Z., 2012, P AAAI C ART INT, P1026
   Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Luo Y., 2011, P 19 ACM INT C MULT, P1165
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Nie F., 2010, NIPS
   Nie FP, 2011, IEEE I CONF COMP VIS, P2268
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Ren YZ, 2012, NEUROCOMPUTING, V89, P147, DOI 10.1016/j.neucom.2012.02.021
   Wang L., 2007, HYBRID HUBERIZED SUP
   Wang S, 2016, SIGNAL PROCESS, V120, P746, DOI 10.1016/j.sigpro.2014.12.012
   Xiaojun Chang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P74, DOI 10.1007/978-3-319-06605-9_7
   Xu ZL, 2010, IEEE T NEURAL NETWOR, V21, P1033, DOI 10.1109/TNN.2010.2047114
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, AAAI CONF ARTIF INTE, P3841
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yang SH, 2012, IEEE T KNOWL DATA EN, V24, P1422, DOI 10.1109/TKDE.2011.92
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Zeng ZQ, 2016, NEUROCOMPUTING, V173, P102, DOI 10.1016/j.neucom.2015.05.119
NR 45
TC 11
Z9 11
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 272
EP 280
DI 10.1016/j.jvcir.2016.10.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000024
DA 2024-07-18
ER

PT J
AU Liu, WH
   Gao, CQ
   Chang, XJ
   Wu, Q
AF Liu, Wenhe
   Gao, Chenqiang
   Chang, Xiaojun
   Wu, Qun
TI Unified discriminating feature analysis for visual category recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature selection; Supervised learning; Semi-supervised learning; Sparse
   learning
ID FEATURE-SELECTION
AB Visual category recognition (VCR) is one of the most important tasks in image and video indexing. To deal with high dimension image/video data, feature analysis algorithms have been widely used for visual category recognition. In this paper, to enhance the flexibility regarding the exploitation of labeled or unlabeled data, we propose a unified feature analysis framework that can be applied to both supervised and semi-supervised scenarios. Furthermore, by revealing intrinsic relationships of traditional feature analysis methods, our framework not only integrates traditional methods, but also introduces an l(2,1)-norm regularization term for sparse learning. Extensive experiments report that the proposed method obtains advantageous performance in comparison with other state-of-the-art supervised and semi-supervised feature selection algorithms. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Wenhe; Chang, Xiaojun] Univ Technol Sydney, Ctr Quantum Computat & Intelligent Syst, Sydney, NSW 2007, Australia.
   [Gao, Chenqiang] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing 400065, Peoples R China.
   [Wu, Qun] Zhejiang Sci Tech Univ, Hangzhou 310018, Zhejiang, Peoples R China.
C3 University of Technology Sydney; Chongqing University of Posts &
   Telecommunications; Zhejiang Sci-Tech University
RP Gao, CQ (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Signal & Informat Proc, Chongqing 400065, Peoples R China.
EM gaocq@cqupt.edu.cn
RI liu, wenhe/Y-4506-2019; Chang, Xiaojun/A-2055-2015
OI liu, wenhe/0000-0003-4679-2958; Chang, Xiaojun/0000-0002-7778-8807
FU Science and Technology Major Project of Zhejiang province
   [2013C03017-1]; Taizhou Science and Technology Plan [13ZJU007]
FX This work is supported by Science and Technology Major Project of
   Zhejiang province (2013C03017-1), Taizhou Science and Technology Plan
   (13ZJU007).
CR [Anonymous], AMSTER658
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], P AAAI C ART INT AAA
   [Anonymous], NEURAL NETWORKS
   [Anonymous], 2011, IJCAI INT JOINT C AR
   [Anonymous], P AAAI C ART INT AAA
   [Anonymous], PATTERN RECOGN
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2006, HUMANEVA SYNCHRONIZ
   [Anonymous], 2010, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], P AAAI C ART INT AAA
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Cai X., 2013, P INT JOINT C ART IN, P1240
   Cover Thomas M, 1999, Elements of information theory
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Giles DEA, 2004, OXFORD B ECON STAT, V66, P425, DOI 10.1111/j.1468-0084.2004.00086.x
   Gu Q., 2011, Proceedings of the Twenty-Second international joint conference on Artificial Intelligence, V2, P1294
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2014, INFORM SCIENCES, V281, P523, DOI 10.1016/j.ins.2014.03.093
   Han YH, 2012, PROC CVPR IEEE, P2981, DOI 10.1109/CVPR.2012.6248027
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   Joanl F. B., 1987, Statistical Science, V2, P45, DOI [10.1214/ss/1177013437, DOI 10.1214/SS/1177013437]
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sokeh HajarSadeghi., 2013, AAAI Conference on Artificial Intelligence (AAAI), P1076
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Wang W, 2016, PROC INT CONF RECON
   WEI LJ, 1981, J AM STAT ASSOC, V76, P1006, DOI 10.2307/2287603
   Wu F, 2012, INT J MULTIMED INF R, V1, P3, DOI 10.1007/s13735-012-0001-9
   Yan Y., 2013, ACM International Conference on Multimedia, P537
   Yan Y, 2014, INT C PATT RECOG, P3493, DOI 10.1109/ICPR.2014.601
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
NR 48
TC 5
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 772
EP 778
DI 10.1016/j.jvcir.2016.06.028
PN B
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600031
DA 2024-07-18
ER

PT J
AU Tang, LJ
   Li, LD
   Gu, K
   Sun, XM
   Zhang, JY
AF Tang, Lijuan
   Li, Leida
   Gu, Ke
   Sun, Xingming
   Zhang, Jianying
TI Blind quality index for camera images with natural scene statistics and
   patch-based sharpness assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment (IQA); Camera images; Blind/no-reference (NR);
   Natural scene statistics (NSS); Local sharpness; Free energy theory;
   Structural degradation model
ID PARALLEL FRAMEWORK; BLUR; MOTION
AB The current image quality metrics work on the assumption that an image contains single and simulated distortions which are not representative of real camera images. In this paper we address the problem of quality assessment of camera images from two respects, natural scene statistics (NSS) and local sharpness, and associated three types of features. The first type of four features measures the naturalness of an image, inspired by a recent finding that there exists high correlation between structural degradation information and free energy entropy on natural scene images and this regulation will be gradually devastated as more distortions are introduced. The second type of four features originates from an observation concerning the NSS that a broad spectrum of statistics of distorted images can be caught by the generalized Gaussian distribution (GGD). Both the two types of features above belong to the NSS-based models, but they come from the considerations of local auto-regression (AR) and global histogram, respectively. The third type of three features focuses on estimating the local sharpness, which works by computing log-energies in discrete wavelet transform domain. Finally our quality metric is achieved via a SVR-based machine learning tool, and its performance is proved to be statistically better than state-of-the-art competitors on the CID2013 database dedicated to the quality assessment of camera images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tang, Lijuan; Li, Leida; Zhang, Jianying] China Univ Min & Technol, Sch Info & Elec Eng, Xuzhou, Peoples R China.
   [Tang, Lijuan] Jiangsu Vocat Coll Business, Sch Info & Elec Eng, Nantong, Peoples R China.
   [Gu, Ke] Shanghai Jiao Tong Univ, Inst Image Commu & Infor Proce, Shanghai 200030, Peoples R China.
   [Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Compu & Soft, Nanjing, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; Shanghai Jiao Tong University;
   Nanjing University of Information Science & Technology
RP Zhang, JY (corresponding author), China Univ Min & Technol, Sch Info & Elec Eng, Xuzhou, Peoples R China.
EM zhangjianyingiqa@163.com
RI li, li/HII-4157-2022; Li, Li/AEM-3636-2022; Sun, Xingming/AAD-1866-2019;
   Gu, Ke/AAJ-9684-2021; zhang, jian/HPD-1712-2023
FU National Natural Science Foundation of China [61379143]; Fundamental
   Research Funds for the Central Universities [2015QNA66]; Science and
   Technology Planning Project of Nantong [BK2014022]; Qing Lan Project of
   Jiangsu Province
FX This work is kindly supported in part by National Natural Science
   Foundation of China (61379143), the Fundamental Research Funds for the
   Central Universities (2015QNA66), Science and Technology Planning
   Project of Nantong (BK2014022) and the Qing Lan Project of Jiangsu
   Province.
CR Attias H, 2000, ADV NEUR IN, V12, P209
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Cohen A., 1992, COMMUN PURE APPL MAT, V45
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gronqvist H, 2006, VISION RES, V46, P1754, DOI 10.1016/j.visres.2005.11.007
   Gu K., IEEE T IMAGE PROCESS, P24
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Gu K, 2013, IEEE INT CON MULTI
   Gu K, 2013, IEEE INT SYMP CIRC S, P1095, DOI 10.1109/ISCAS.2013.6572041
   Kee E, 2011, P NATL ACAD SCI USA, V108, P19907, DOI 10.1073/pnas.1110747108
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., IEEE T CYBERNET, P46
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Narvekar N.D., IEEE T IMAGE PROCESS, P20
   Nuutinen M, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.061111
   Nuutinen M, 2012, 2012 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P165, DOI 10.1109/ISM.2012.40
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Rottach KG, 1996, VISION RES, V36, P2189, DOI 10.1016/0042-6989(95)00302-9
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad M., 2015, 9 INT WORKSH VID PRO
   Saad MA, 2015, IEEE SIGNAL PROC LET, V22, P1516, DOI 10.1109/LSP.2015.2406861
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh H.R., Live Image Quality Assessment Database
   Sheikh H.R., IEEE T IMAGE PROCESS, P15
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang S., IEEE T MULTIMEDIA, V18
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HR, 2013, P IEEE, V101, P2025, DOI 10.1109/JPROC.2013.2262911
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 54
TC 14
Z9 14
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 335
EP 344
DI 10.1016/j.jvcir.2016.07.007
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500029
DA 2024-07-18
ER

PT J
AU Yang, K
   Dou, Y
   Lv, SH
   Zhang, F
   Lv, Q
AF Yang, Ke
   Dou, Yong
   Lv, Shaohe
   Zhang, Fei
   Lv, Qi
TI Relative distance features for gait recognition with Kinect
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Relative distance feature; Gait feature; Anthropometric features; Gait
   recognition; Biometrics
ID SEQUENCES
AB Gait and static body measurement are important biometric technologies for passive human recognition. Many previous works argue that recognition performance based completely on the gait feature is limited. The reason for this limited performance remains unclear. This study focuses on human recognition with gait feature obtained by Kinect and shows that gait feature can effectively distinguish from different human beings through a novel representation - relative distance-based gait features. Experimental results show that the recognition accuracy with relative distance features reaches up to 85%, which is comparable with that of anthropometric features. The combination of relative distance features and anthropometric features can provide an accuracy of more than 95%. Results indicate that the relative distance feature is quite effective and worthy of further study in more general scenarios (e.g., without Kinect). (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yang, Ke] Natl Univ Def Technol, Natl Lab Parallel & Distributed Proc, Changsha 410073, Hunan, Peoples R China.
   Natl Univ Def Technol, Coll Comp, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China
RP Yang, K (corresponding author), Natl Univ Def Technol, Natl Lab Parallel & Distributed Proc, Changsha 410073, Hunan, Peoples R China.
EM bityangke@163.com
RI zhang, fei/KHU-5230-2024
FU National Natural Science Foundation of China [61125201, U1435219,
   61572515]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61125201, U1435219, and 61572515.
CR Ahmed M., 2014, SPIE PHOTONICS EUROP
   Andersson V., 2014, PROC ACM S APPL COMP, DOI DOI 10.1145/2554850.2555147
   Andersson VO, 2015, AAAI CONF ARTIF INTE, P425
   Araujo R.M., 2013, Proceedings of the 28th Annual ACM Symposium on Applied Computing, P21
   Ball A, 2012, ACMIEEE INT CONF HUM, P225
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Chattopadhyay P, 2015, PATTERN RECOGN LETT, V63, P9, DOI 10.1016/j.patrec.2015.06.004
   Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114
   Cunado D, 1997, LECT NOTES COMPUT SC, V1206, P95
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Gianaria E, 2014, LECT NOTES COMPUT SC, V8897, P16, DOI 10.1007/978-3-319-13386-7_2
   Gianaria E, 2013, IEEE INT WORKSH MULT, P440, DOI 10.1109/MMSP.2013.6659329
   Guan Y, 2015, IEEE T PATTERN ANAL, V37, P1521, DOI 10.1109/TPAMI.2014.2366766
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hofmann M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P390, DOI 10.1109/ICB.2012.6199782
   Hofmann M, 2011, WSCG 2011: COMMUNICATION PAPERS PROCEEDINGS, P99
   Jain AK, 1997, P IEEE, V85, P1365, DOI 10.1109/5.628674
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Lombardi S, 2013, IEEE I CONF COMP VIS, P1041, DOI 10.1109/ICCV.2013.133
   Lu JW, 2010, PATTERN RECOGN LETT, V31, P382, DOI 10.1016/j.patrec.2009.11.006
   Makihara Y., 2015, IPSJ T COMPUTER VISI, V7, P74
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Matovski D., 2014, GAIT RECOGNITION, P309, DOI DOI 10.1007/978-0-387-31439-6
   Matovski DS, 2012, INT C PATT RECOG, P3272
   Muramatsu D, 2015, INT CONF BIOMETR, P169, DOI 10.1109/ICB.2015.7139048
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731
   Preis J., 2012, 1 INT WORKSH KIN PER
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Yoo J.-H., 2002, P BMVA S ADV BIOMETR, P596
   Yoo JH, 2011, ETRI J, V33, P259, DOI 10.4218/etrij.11.1510.0068
NR 34
TC 49
Z9 52
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 209
EP 217
DI 10.1016/j.jvcir.2016.05.020
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900020
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kaplan, NH
   Erer, I
   Ersoy, O
AF Kaplan, N. H.
   Erer, I.
   Ersoy, O.
TI Fusion of multifocus images by lattice structures
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Lifting wavelet transform; Multiscale products; Lattice
   filters; QMF filterbanks
ID PARALLEL FRAMEWORK; PERFORMANCE
AB Image fusion methods based on multiscale transform (MST) suffer from high computational load due to the use of fast Fourier transforms (ffts) in the lowpass and highpass filtering steps. Lifting wavelet scheme which is based on second generation wavelets has been proposed as a solution to this issue. Lifting Wavelet Transform (LWT) is composed of split, prediction and update operations all implemented in the spatial domain using multiplications and additions, thus computation time is highly reduced. Since image fusion performance benefits from undecimated transform, it has later been extended to Stationary Lifting Wavelet Transform (SLWT). In this paper, we propose to use the lattice filter for the MST analysis step. Lattice filter is composed of analysis and synthesis parts where simultaneous lowpass and highpass operations are performed in spatial domain with the help of additions/multiplications and delay operations, in a recursive structure which increases robustness to noise. Since the original filter is designed for the undecimated case, we have developed undecimated lattice structures, and applied them to the fusion of multifocus images. Fusion results and evaluation metrics show that the proposed method has better performance especially with noisy images while having similar computational load with LSWT based fusion method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kaplan, N. H.] Erzurum Tech Univ, Dept Elect & Elect Engn, TR-25700 Erzurum, Turkey.
   [Erer, I.] Istanbul Tech Univ, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey.
   [Ersoy, O.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
C3 Erzurum Technical University; Istanbul Technical University; Purdue
   University System; Purdue University
RP Erer, I (corresponding author), Istanbul Tech Univ, Dept Elect & Commun Engn, TR-34469 Istanbul, Turkey.
EM ierer@itu.edu.tr
RI Kaplan, Nur Hüseyin/H-1771-2016; Kaplan, Nur Hüseyin/JCO-4465-2023;
   Erer, Işın/ABI-5663-2020
OI Kaplan, Nur Hüseyin/0000-0002-4740-3259; Kaplan, Nur
   Hüseyin/0000-0002-4740-3259; Erer, Işın/0000-0002-2225-6379
CR [Anonymous], 2012, MATH PROB ENG
   Bao P, 2003, IEEE T MED IMAGING, V22, P1089, DOI 10.1109/TMI.2003.816958
   Chai Y, 2011, OPT COMMUN, V284, P1146, DOI 10.1016/j.optcom.2010.10.056
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   Lee CS, 2000, ELECTRON LETT, V36, P1894, DOI 10.1049/el:20001294
   LI H, 1994, IEEE IMAGE PROC, P51, DOI 10.1109/ICIP.1994.413273
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   Loza A, 2010, COMPUT VIS IMAGE UND, V114, P54, DOI 10.1016/j.cviu.2009.09.002
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Seales WB, 1996, P SOC PHOTO-OPT INS, V2905, P227, DOI 10.1117/12.256333
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   VAIDYANATHAN PP, 1988, IEEE T ACOUST SPEECH, V36, P81, DOI 10.1109/29.1491
   Wang M, 2007, INT C WAVEL ANAL PAT, P321
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   XU YS, 1994, IEEE T IMAGE PROCESS, V3, P747, DOI 10.1109/83.336245
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang L, 2008, NEUROCOMPUTING, V72, P203, DOI 10.1016/j.neucom.2008.02.025
   Zhang Qiang, 2008, Acta Automatica Sinica, V34, P135, DOI 10.3724/SP.J.1004.2008.00135
NR 25
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 848
EP 857
DI 10.1016/j.jvcir.2016.04.017
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100071
DA 2024-07-18
ER

PT J
AU Kwon, HJ
   Lee, SH
   Lee, GY
   Sohng, KI
AF Kwon, Hyuk-Ju
   Lee, Sung-Hak
   Lee, Geun-Young
   Sohng, Kyu-Ik
TI Radiance map construction based on spatial and intensity correlations
   between LE and SE images for HDR imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HDR; Radiance map; Camera response function; Least squares method; LE
   (long exposure); SE (short exposure)
ID PARALLEL FRAMEWORK
AB HDR image was developed for the reproduction of real scenes with an acquisition of large dynamic range. In general, HDR image consists of several different exposure images according to the exposure value of a digital camera. Before the construction of a single HDR image, each input image is calibrated using CRF to convert its image data to scene radiance. In order find CRF, conventional methods require special apparatus and reference targets, or several exposure images. This paper proposes a new HDR blending algorithm that uses only dual-exposure images. The proposed algorithm is based on the least squares method, and includes spatial and intensity weighting functions. Each weighting function is used to reduce error points and improve CRF computation accuracy. In addition, a constraint is added to correct white balance in the brightness level. The rendering results show that the proposed algorithm is superior to the conventional algorithm. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kwon, Hyuk-Ju; Lee, Sung-Hak; Lee, Geun-Young; Sohng, Kyu-Ik] Kyungpook Natl Univ, Sch Elect Engn, 80 Dahakro, Bukgu 702701, Daegu, South Korea.
C3 Kyungpook National University
RP Lee, SH (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, 80 Dahakro, Bukgu 702701, Daegu, South Korea.
EM shak2@ee.knu.ac.kr
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [NRF-2015R1D1A1A01059929]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2015R1D1A1A01059929).
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   ASADA N, 1996, IEEE INT C PATT REC, P186
   BERNS RS, 1995, J ELECTRON IMAGING, V4, P360, DOI 10.1117/12.218935
   Cvetkovic S, 2008, IEEE T CONSUM ELECTR, V54, P904, DOI 10.1109/TCE.2008.4560177
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Grossberg MD, 2003, PROC CVPR IEEE, P602
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Hong GW, 2001, COLOR RES APPL, V26, P76, DOI 10.1002/1520-6378(200102)26:1<76::AID-COL8>3.0.CO;2-3
   Johnson GM, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P36
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Kwon HJ, 2014, DIGIT SIGNAL PROCESS, V30, P74, DOI 10.1016/j.dsp.2014.03.008
   Kwon HJ, 2013, J VIS COMMUN IMAGE R, V24, P678, DOI 10.1016/j.jvcir.2012.03.001
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Monobe Y, 2005, IEEE T CONSUM ELECTR, V51, P1, DOI 10.1109/TCE.2005.1405691
   Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 21
TC 9
Z9 9
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 695
EP 703
DI 10.1016/j.jvcir.2016.04.022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100058
DA 2024-07-18
ER

PT J
AU Luo, Y
   Yuan, JS
   Lu, JW
AF Luo, Ye
   Yuan, Junsong
   Lu, Jianwei
TI Finding spatio-temporal salient paths for video objects discovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatio-temporal path; Salient object detection; Temporal coherence;
   Video saliency estimation; Saliency density; Dynamic programming;
   Salient path discovery; Computer vision
AB Many videos capture and follow salient objects in a scene. Detecting such salient objects is thus of great interests to video analytics and search. However, the discovery of salient objects in an unsupervised way is a challenging problem as there is no prior knowledge of the salient objects provided. Different from existing salient object detection methods, we propose to detect and track salient object by finding a spatio-temporal path which has the largest accumulated saliency density in the video. Inspired by the observation that salient video objects usually appear in consecutive frames, we leverage the motion coherence of videos into the path discovery and make the salient object detection more robust. Without any prior knowledge of the salient objects, our method can detect salient objects of various shapes and sizes, and is able to handle noisy saliency maps and moving cameras. Experimental results on two public datasets validate the effectiveness of the proposed method in both qualitative and quantitative terms. Comparisons with the state-of-the-art methods further demonstrate the superiority of our method on salient object detection in videos. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Luo, Ye; Lu, Jianwei] Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.
   [Yuan, Junsong] Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Tongji University; Nanyang Technological University
RP Luo, Y (corresponding author), Tongji Univ, Sch Software Engn, Shanghai 201804, Peoples R China.
EM Iuoy0009@e.ntu.edu.sg; jsyuan@ntu.edu.sg; jwlu33@tongji.edu.cn
RI Yuan, Junsong/R-4352-2019; luo, ye/KQU-4093-2024; Yuan,
   Junsong/A-5171-2011
OI Yuan, Junsong/0000-0002-7901-8793
FU China NSFC [61572362, 81571347]
FX This work is supported in part by the China NSFC grant 61572362 and the
   China NSFC grant 81571347.
CR [Anonymous], 2008, PROC INT CONF PATTER
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Du Tran, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3321, DOI 10.1109/CVPR.2011.5995416
   Fukuchi K, 2009, IEEE INT CON MULTI, P638, DOI 10.1109/ICME.2009.5202577
   Gang Hua, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P182
   Geng Zhang, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P193
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Lampert C. H., 2008, PROC IEEE C COMPUTER, P1
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Liu D, 2008, IEEE T MULTIMEDIA, V10, P200, DOI 10.1109/TMM.2007.911781
   Luo Y., 2013, P 21 ACM INT C MULTI, P509, DOI [10.1145/2502081.2502135, DOI 10.1145/2502081.2502135]
   Luo Y, 2011, IEEE T CIRC SYST VID, V21, P1822, DOI 10.1109/TCSVT.2011.2147230
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Shah M., 2008, PROC IEEE C COMPUTER, P1
   Tuytelaars T, 2010, INT J COMPUT VISION, V88, P284, DOI 10.1007/s11263-009-0271-8
   Yang JC, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2601069
NR 21
TC 8
Z9 9
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 45
EP 54
DI 10.1016/j.jvcir.2016.02.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100005
DA 2024-07-18
ER

PT J
AU Song, KC
   Wen, X
   Zhao, YJ
   Dong, ZP
   Yan, YH
AF Song, Kechen
   Wen, Xin
   Zhao, Yongjie
   Dong, Zhipeng
   Yan, Yunhui
TI Noise robust image matching using adjacent evaluation census transform
   and wavelet edge joint bilateral filter in stereo vision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Census transform; Random walk; Joint bilateral filter
ID PARALLEL FRAMEWORK; COST
AB Automation application systems based on stereo vision require robust image matching methods to achieve available depth image information. This paper presents a novel noise robust stereo matching using adjacent evaluation census transform and wavelet edge joint bilateral filter. The adjacent evaluation census is firstly proposed to improve the robustness against noise of the census transform. Meanwhile, two different and complementary types of metrics are extracted (the adjacent evaluation census mean and the adjacent evaluation census weighted difference). Moreover, the weighted template is composed of four different directions. Then, to improve the robustness of cost aggregation and disparity optimization, the random walk is integrated into the proposed stereo matching method. Additionally, a disparity map post-processing method named wavelet edge joint bilateral filter is employed to eliminate error regions. An obtained wavelet-based edge image is considered as an important weighted coefficient to guide the post-processing. Experimental results demonstrate that the proposed method presents the best performance of the robustness against noise on the Middlebury dataset. Even in the toughest situation with additive Gaussian noise, our method can still achieve the moderate disparity map. In addition, the wider applicability of the proposed method is demonstrated on the KITTI (i.e., Karlsruhe Institute of Technology (KIT) and Toyota Technological Institute at Chicago (TTI-C)) dataset and some typical real-world sequences. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Song, Kechen; Wen, Xin; Zhao, Yongjie; Dong, Zhipeng; Yan, Yunhui] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Song, KC (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Liaoning, Peoples R China.
EM unkechen@gmail.com; yanyh@mail.neu.edu.cn
RI Song, Kechen/T-1896-2019; Yan, Yunhui/HDL-7343-2022
OI Song, Kechen/0000-0002-7636-3460; Yan, Yunhui/0000-0001-7121-2367; Zhao,
   Yongjie/0000-0002-1865-258X
FU National Natural Science Foundation of China [51374063]; Fundamental
   Research Funds for the Central Universities [N140303008, N141008001,
   N150308001]
FX This work is supported by the National Natural Science Foundation of
   China (51374063) and the Fundamental Research Funds for the Central
   Universities (N140303008, N141008001, N150308001). In addition, the
   authors would like to sincerely thank for sharing the source codes of
   ERS and ARW.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], ACM T GRAPHIC
   [Anonymous], J COMPUT INFORM SYST
   Cigla C, 2013, SIGNAL PROCESS-IMAGE, V28, P1072, DOI 10.1016/j.image.2013.04.001
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Heo YS, 2013, IEEE T PATTERN ANAL, V35, P1094, DOI 10.1109/TPAMI.2012.167
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Jiao JB, 2014, IEEE MULTIMEDIA, V21, P16, DOI 10.1109/MMUL.2014.51
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kordelas GA, 2015, IMAGE VISION COMPUT, V35, P31, DOI 10.1016/j.imavis.2014.12.001
   Lee S, 2015, IMAGE VISION COMPUT, V37, P1, DOI 10.1016/j.imavis.2015.01.003
   Liu MY, 2014, IEEE T PATTERN ANAL, V36, P99, DOI 10.1109/TPAMI.2013.107
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mozerov MG, 2015, IEEE T IMAGE PROCESS, V24, P1153, DOI 10.1109/TIP.2015.2395820
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tombari F., 2008, Computer Vision and Pattern Recognition, P1
   Tombari F, 2007, LECT NOTES COMPUT SC, V4872, P427
   Wang ZF, 2008, PROC CVPR IEEE, P887
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang CB, 2015, AEU-INT J ELECTRON C, V69, P226, DOI 10.1016/j.aeue.2014.09.006
   Zhang K, 2015, J VIS COMMUN IMAGE R, V26, P275, DOI 10.1016/j.jvcir.2014.10.002
NR 33
TC 7
Z9 7
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 487
EP 503
DI 10.1016/j.jvcir.2016.03.026
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100042
DA 2024-07-18
ER

PT J
AU Tang, T
   Li, L
AF Tang, Tong
   Li, Ling
TI Adaptive deblocking method for low bitrate coded HEVC video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deblocking filter; HEVC; Blocking artifact; Post-processing; Perceptual
   quality
ID BLOCKING ARTIFACTS; COMPRESSED IMAGES; FILTER; ALGORITHM; STANDARD
AB HEVC in-loop deblocking filter significantly improves the subjective quality of coded video by removing blocking artifact. However, there are still visible blocking artifacts in the complex videos with fast and chaotic motions coded at a low bitrate. In this paper, we propose a three-step deblocking filter scheme, which pre-processes video to remove undesired noise, next removes the corner outliers, and then suppresses the normal blocking artifacts with adaptive deblocking filters. The whole deblocking filtering process is applied on both luma and chroma components. Experimental results show that the proposed method could effectively improve the subjective quality for various videos, and outperform other typical post-processing deblocking methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tang, Tong] Univ Sci & Technol China, Inst Informat Sci & Technol, Wuhan, Peoples R China.
   [Li, Ling] Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Li, L (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100864, Peoples R China.
EM ttly@mail.ustc.edu.cn; ling_li@ia.ac.cn
RI TANG, TONG/KRO-7674-2024
OI Li, Ling/0000-0001-8877-9052
FU Strategic Priority Research Program of Chinese Academy of Sciences
   [XDA06010402]; National Key Technology Support Program [Y4M1011GK1]; NSF
   of China [61303158]
FX This work is partially supported by the Strategic Priority Research
   Program of Chinese Academy of Sciences (under Grant XDA06010402), the
   National Key Technology Support Program (under Grant Y4M1011GK1), and
   the NSF of China (under Grant 61303158).
CR [Anonymous], 2012, JCT VC ITU T SG16 WP
   Chen T, 2001, IEEE T CIRC SYST VID, V11, P594, DOI 10.1109/76.920189
   Chou J, 1998, IEEE SIGNAL PROC LET, V5, P33, DOI 10.1109/97.659544
   Girod Bernd, 1993, P207
   Jicheng An, 2010, JCTVCC142 ITUT SG16
   Kim J, 2007, IEEE T CONSUM ELECTR, V53, P1694, DOI 10.1109/TCE.2007.4429272
   Kim Jongho, 2007, IEEE T CONSUMER ELEC, V53
   Kim SD, 1999, IEEE T CIRC SYST VID, V9, P156, DOI 10.1109/76.744282
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Norkin A., 2013, P IEEE INT C VIS COM
   Norkin A, 2014, IEEE IMAGE PROC, P3666, DOI 10.1109/ICIP.2014.7025744
   Norkin A, 2012, IEEE T CIRC SYST VID, V22, P1746, DOI 10.1109/TCSVT.2012.2223053
   ORourke TP, 1995, IEEE T CIRC SYST VID, V5, P490, DOI 10.1109/76.475891
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tai SC, 2006, IEE P-VIS IMAGE SIGN, V153, P46, DOI 10.1049/ip-vis:20045191
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Xiong ZX, 1997, IEEE T CIRC SYST VID, V7, P433, DOI 10.1109/76.564123
   Yang YY, 1993, IEEE T CIRC SYST VID, V3, P421, DOI 10.1109/76.260198
   Yeh CH, 2012, IET IMAGE PROCESS, V6, P534, DOI 10.1049/iet-ipr.2010.0545
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
NR 23
TC 8
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 721
EP 734
DI 10.1016/j.jvcir.2016.04.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100060
OA Bronze
DA 2024-07-18
ER

PT J
AU Yang, JY
   Yuan, JS
   Li, YF
AF Yang, Jianyu
   Yuan, Junsong
   Li, Youfu
TI Parsing 3D motion trajectory for gesture recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D trajectory representation; Motion recognition; Trajectory primitive
ID INTEGRAL INVARIANTS; CHAIN CODE; REPRESENTATION; RETRIEVAL; CAPTURE
AB Motion trajectories have been widely used for gesture recognition. An effective representation of 3D motion trajectory is important for capturing and recognizing complex motion patterns. In this paper, we propose a view invariant hierarchical parsing method for free form 3D motion trajectory representation. The raw motion trajectory is first parsed into four types of trajectory primitives based on their 3D shapes. These primitives are further segmented into sub-primitives by the proposed shape descriptors. Based on the clustered sub-primitives, trajectory recognition is achieved by using Hidden Markov Model. The proposed parsing approach is view-invariant in 3D space and is robust to variations of scale, temporary speed and partial occlusion. It well represents long motion trajectories can also support online gesture recognition. The proposed approach is evaluated on multiple benchmark datasets. The competitive experimental results and comparisons with the state-of-the-art methods verify the effectiveness of our approach. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yang, Jianyu] Soochow Univ, Sch Urban Rail Transportat, 8 Jixue Rd, Suzhou, Jiangsu, Peoples R China.
   [Yang, Jianyu; Yuan, Junsong] Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
   [Li, Youfu] City Univ Hong Kong, Dept Mech & Biomed Engn, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
C3 Soochow University - China; Nanyang Technological University; City
   University of Hong Kong
RP Yang, JY (corresponding author), Soochow Univ, Sch Urban Rail Transportat, 8 Jixue Rd, Suzhou, Jiangsu, Peoples R China.
EM jyyang@suda.edu.cn; JSYUAN@ntu.edu.sg; meyfli@cityu.edu.hk
RI Yuan, Junsong/A-5171-2011; Liu, Liu/JXM-8208-2024; yang,
   jian/HIK-0188-2022
OI Yuan, Junsong/0000-0002-7901-8793; LI, You Fu/0000-0002-5227-1326
FU National Natural Science Foundation of China [61305020]; Natural Science
   Foundation of Jiangsu province, China [BK20130316]; Singapore MoE Tier-2
   project [MOE2015-T2-2-114]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61305020), the Natural Science Foundation
   of Jiangsu province, China (Grant No. BK20130316), and the Singapore MoE
   Tier-2 project MOE2015-T2-2-114.
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   [Anonymous], 2013, P IEEE WORKSH APPL C
   Bashir F, 2004, INMIC 2004: 8th International Multitopic Conference, Proceedings, P20
   Bashir FI, 2006, MULTIMEDIA SYST, V12, P45, DOI 10.1007/s00530-006-0024-2
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   Bribiesca E, 2000, PATTERN RECOGN, V33, P755, DOI 10.1016/S0031-3203(99)00093-X
   Cattani C, 2010, MATH PROBL ENG, V2010, DOI 10.1155/2010/408418
   Chen SY, 2011, IEEE T BIO-MED ENG, V58, P480, DOI 10.1109/TBME.2010.2087331
   Chen WB, 2015, J VIS COMMUN IMAGE R, V26, P182, DOI 10.1016/j.jvcir.2014.11.008
   COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818
   Harding PRG, 2004, INT C PATT RECOG, P286, DOI 10.1109/ICPR.2004.1334523
   Hervieu A, 2008, IEEE T CIRC SYST VID, V18, P1533, DOI 10.1109/TCSVT.2008.2005609
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965
   Keogh E. J., 2000, P ACM SIGKDD
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Latecki L. J., 2005, P PRINC PRACT KNOWL
   Li YX, 2014, IEEE INT C INT ROBOT, P1046, DOI 10.1109/IROS.2014.6942687
   Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208
   Min J, 2004, INT C PATT RECOG, P199, DOI 10.1109/ICPR.2004.1333738
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Psarrou A, 2002, IMAGE VISION COMPUT, V20, P349, DOI 10.1016/S0262-8856(02)00007-0
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Ryoo M., 2006, 2006 IEEE COMP SOC C, V2, P1709, DOI DOI 10.1109/CVPR.2006.242
   Shao ZP, 2015, PATTERN RECOGN, V48, P2418, DOI 10.1016/j.patcog.2015.02.029
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Terejanu G., 2008, CRIB SHEET LINEAR KA
   Vlachos M, 2005, MACH LEARN, V58, P301, DOI 10.1007/s10994-005-5830-9
   Wang J., 2006, P IEEE INT C COMP VI, V2
   Wang XG, 2011, INT J COMPUT VISION, V95, P287, DOI 10.1007/s11263-011-0459-6
   Wu S, 2009, PATTERN RECOGN, V42, P194, DOI 10.1016/j.patcog.2008.06.023
   Yang J.Y., 2015, P IEEE WINT C APPL C
   Yang JY, 2016, NEUROCOMPUTING, V190, P70, DOI 10.1016/j.neucom.2016.01.032
   Yang JY, 2016, COMPUT VIS IMAGE UND, V145, P43, DOI 10.1016/j.cviu.2016.01.005
   Yang JY, 2011, IEEE INT C INT ROBOT, P3440, DOI 10.1109/IROS.2011.6048210
   Yang JY, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/613939
   Zalik B, 2015, J VIS COMMUN IMAGE R, V29, P8, DOI 10.1016/j.jvcir.2015.01.013
   Zhang Z, 2011, IEEE T PATTERN ANAL, V33, P240, DOI 10.1109/TPAMI.2010.60
NR 43
TC 16
Z9 16
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 627
EP 640
DI 10.1016/j.jvcir.2016.04.010
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100054
DA 2024-07-18
ER

PT J
AU Qi, XY
   Liu, BQ
   Xu, JW
AF Qi, Xianying
   Liu, Boqiang
   Xu, Jianwei
TI A neutrosophic filter for high-density Salt and Pepper noise based on
   pixel-wise adaptive smoothing parameter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Salt and Pepper noise; Adaptive neutrosophic weight
   function; Pixel-wise adaptive smoothing parameter; Indicator of image
   contents; Similarity measurement; Neutrosophic Set; Indeterminacy
ID IMPULSE NOISE; NONLOCAL MEANS; MEDIAN FILTER; REMOVAL; DETECTOR; SET
AB Image indeterminacy has been neglected in most traditional filtering algorithms. This paper proposes a pixel-wise adaptive neutrosophic filter based on neutrosophic indeterminacy feature to remove high-level Salt-and-Pepper noise. In the proposed algorithm, the indeterminacy of a pixel is quantified by a Neutrosophic Set and innovatively exploited as an efficient characteristic of measuring the similarity of pixels. In order to adjust the smoothing parameter of the weight function pixel-wise adaptively, the uncertainty of a pixel is utilized as an indicator of image contents. Extensive experiments on numerous images demonstrate that with a 3 x 3 window, our method outperforms many existing denoising methods in terms of noise suppression and detail preservation. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Qi, Xianying; Liu, Boqiang] Shandong Univ, Sch Control Sci & Engn, Jinan 250010, Shandong, Peoples R China.
   [Qi, Xianying] Taishan Med Univ, Dept Radiol, Tai An 271000, Shandong, Peoples R China.
   [Xu, Jianwei] Taian Tumor Prevent & Treatment Hosp, Dept Med Imaging, Tai An 271000, Shandong, Peoples R China.
C3 Shandong University; Shandong First Medical University & Shandong
   Academy of Medical Sciences
RP Liu, BQ (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250010, Shandong, Peoples R China.
EM xyqi@tsmc.edu.cn; qxy9228@163.com
FU National Natural Science Foundation of China [61203330]; Department of
   Science and Technology of Shandong Province [2015ZDXX0801A01];
   Fundamental Research Funds of Shandong University [2015QY001]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61203330), the Department of Science and Technology of
   Shandong Province (Grant No. 2015ZDXX0801A01) and the Fundamental
   Research Funds of Shandong University (Grant No. 2015QY001).
CR An SJ, 2015, IEEE SIGNAL PROC LET, V22, P202, DOI 10.1109/LSP.2014.2353694
   Ansari AQ, 2013, APPL SOFT COMPUT, V13, P563, DOI 10.1016/j.asoc.2012.08.002
   Brox T, 2007, LECT NOTES COMPUT SC, V4485, P13
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Gao GR, 2015, OPTIK, V126, P467, DOI 10.1016/j.ijleo.2014.11.004
   Guo YH, 2013, CIRC SYST SIGNAL PR, V32, P1699, DOI 10.1007/s00034-012-9531-x
   Guo YH, 2009, NEW MATH NAT COMPUT, V5, P653, DOI 10.1142/S1793005709001490
   Guo YH, 2009, PATTERN RECOGN, V42, P587, DOI 10.1016/j.patcog.2008.10.002
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P956, DOI 10.1016/j.jvcir.2013.06.012
   Ibrahim H, 2008, IEEE T CONSUM ELECTR, V54, P1920, DOI 10.1109/TCE.2008.4711254
   Loeb P. A., 2000, NONSTANDARD ANAL WOR
   Nair MS, 2012, SIGNAL IMAGE VIDEO P, V6, P579, DOI 10.1007/s11760-010-0186-4
   Nasri M, 2013, SCI IRAN, V20, P760, DOI 10.1016/j.scient.2013.01.001
   Nasri M, 2013, CIRC SYST SIGNAL PR, V32, P1839, DOI 10.1007/s00034-012-9546-3
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Sengur A, 2011, COMPUT VIS IMAGE UND, V115, P1134, DOI 10.1016/j.cviu.2011.04.001
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Tasdizen T, 2009, IEEE T IMAGE PROCESS, V18, P2649, DOI 10.1109/TIP.2009.2028259
   Tukey J., 1974, Conference Records of Electronics and Aerospace Systems Convention (EASCOM), P673
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Vijaykumar VR, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.3.033011
   Xu GY, 2014, CIRC SYST SIGNAL PR, V33, P421, DOI 10.1007/s00034-013-9640-1
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang M, 2010, SIGNAL PROCESS, V90, P1510, DOI 10.1016/j.sigpro.2009.10.021
   Zhang XQ, 2015, AEU-INT J ELECTRON C, V69, P307, DOI 10.1016/j.aeue.2014.09.018
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
NR 30
TC 13
Z9 14
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 1
EP 10
DI 10.1016/j.jvcir.2016.01.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200001
OA Green Published
DA 2024-07-18
ER

PT J
AU Simon-Liedtke, JT
   Farup, I
AF Simon-Liedtke, Joschua Thomas
   Farup, Ivar
TI Evaluating color vision deficiency daltonization methods using a
   behavioral visual-search method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Daltonization; Color vision deficiency; Behaviorism;
   Visual-search; Response time; Accuracy; CVD simulation
ID LAW
AB Daltonization methods are used to automatically improve color images for color-deficient people. A comparison of different daltonization methods, however, is still left undone. We propose a visual-search method to evaluate daltonization methods by assessing behavioral performances of the attentional mechanism through the analysis of accuracy and response time data. Firstly, we show that the visual-search methodology can indeed be used to evaluate daltonization methods. Secondly, we argue that a combination of natural images and Ishihara images is needed to highlight differences between the daltonization methods. Our results indicate that the investigated daltonization methods can be ranked from highest to lowest as following: Firstly, the method proposed by Kotera; secondly, the method proposed by Fidaner et al.; thirdly, the method proposed by Huang et al.; and lastly the method proposed by Kuhn et al. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Simon-Liedtke, Joschua Thomas; Farup, Ivar] Gjovik Univ Coll, Norwegian Colour & Visual Comp Lab, Pb 191, N-2802 Gjovik, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Simon-Liedtke, JT (corresponding author), Gjovik Univ Coll, Norwegian Colour & Visual Comp Lab, Pb 191, N-2802 Gjovik, Norway.
EM joschua.simonliedtke@hig.no
RI Farup, Ivar/HOC-8111-2023
OI Farup, Ivar/0000-0003-3473-1138; Simon-Liedtke, Joschua
   Thomas/0000-0003-4809-1688
FU Research Council of Norway [221073]
FX We thank Dr. Peter Nussbaum, Dr. Reiner Eschbach and Dr. Jonny Nersveen
   (all Gjovik University College) for constructive feedback on the
   article, and Prof. Bruno Laeng (University of Oslo) for his help during
   the behavioral experiment and the data analysis. Also, we thank Manuel
   Oliveira and Jia-Bin Huang for providing the implementation of the Kuhn
   and the Huang methods respectively. This research has been funded by the
   Research Council of Norway through Project No. 221073 "HyPerCept -
   Colour and quality in higher dimensions".
CR Anagnostopoulos C.-N., 2007, 5 INT C COMP VIS SYS
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   [Anonymous], PRINC UN DES
   Bramao I., 2012, ADV OBJECT RECOGNITI, P73, DOI [10.5772/34821, DOI 10.5772/34821]
   Bramao I, 2012, BRAIN COGNITION, V78, P28, DOI 10.1016/j.bandc.2011.10.004
   Bramao I, 2011, ACTA PSYCHOL, V138, P244, DOI 10.1016/j.actpsy.2011.06.010
   Brettel H, 1997, J OPT SOC AM A, V14, P2647, DOI 10.1364/JOSAA.14.002647
   Center for Universal Design, 2008, UN DES
   Cole BL, 2006, CLIN EXP OPTOM, V89, P73, DOI 10.1111/j.1444-0938.2006.00015.x
   Farnsworth D., 1947, FARNSWORTH DICHOTOMO
   Hansen E., 2010, FARGEBLINDHET
   Huang HB, 2007, IEEE SIGNAL PROC LET, V14, P711, DOI 10.1109/LSP.2007.898333
   Huang J.-B., 2015, COMMUNICATION
   Huang JB, 2009, INT CONF ACOUST SPEE, P1161, DOI 10.1109/ICASSP.2009.4959795
   Ishihara S., 1972, Tests for colour-blindness
   Kim HJ, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P602, DOI 10.1109/ICCE.2012.6162036
   Kotera H, 2012, COLOR IMAG CONF, P302
   Kuhn GR, 2008, IEEE T VIS COMPUT GR, V14, P1747, DOI 10.1109/TVCG.2008.112
   LANTHONY P, 1978, DOC OPHTHALMOL, V46, P185
   Lovas G. G., 2008, STAT U HOGSKOLER
   Machado GM, 2010, COMPUT GRAPH FORUM, V29, P933, DOI 10.1111/j.1467-8659.2009.01701.x
   Matplotlib Development Team, 2014, MAPL DOC
   Mazur J. E., 2005, LEARNING BEHAV
   MCGILL R, 1978, AM STAT, V32, P12, DOI 10.2307/2683468
   Mood A.M., 1950, Introduction to the Theory of Statistics
   Nagel W.A., 1907, Zeitschrift fur Augenheilkunde, V17, P201
   NumPy Developers, 2013, NUMPY DOC
   Pedersen M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3277145
   Peirce J., 2014, PSYCHOPY DOCUMENTATI
   PyData Development Team, 2012, PAND DOC
   Rigden C, 1999, BRIT TELECOMMUN ENG, V17, P291
   SciPy Developers, 2013, SCIPY DOC
   Simon-Liedtke J., 2015, MIDT M INT COL ASS A, P1329
   Simon-Liedtke J., 2015, P AIC2015 TOK COL IM, P391
   Simon-Liedtke J., 2013, 12 C INT COL ASS AIC, P108
   Simon-Liedtke J.T., 2015, COLOR IMAGING 20 DIS, V93
   Simon-Liedtke J.T., USING BEHAV MA UNPUB
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Valberg A., 1998, LYS SYN FARGE
   Viénot F, 1999, COLOR RES APPL, V24, P243, DOI 10.1002/(SICI)1520-6378(199908)24:4<243::AID-COL5>3.0.CO;2-3
   Wilson EB, 1927, J AM STAT ASSOC, V22, P209, DOI 10.2307/2276774
   Wyszecki G., 2000, COLOR SCI
NR 43
TC 14
Z9 14
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 236
EP 247
DI 10.1016/j.jvcir.2015.12.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA DD4GD
UT WOS:000369879600021
DA 2024-07-18
ER

PT J
AU Jin, C
   Jin, SW
AF Jin, Cong
   Jin, Shu-Wei
TI Image distance metric learning based on neighborhood sets for automatic
   image annotation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Automatic image annotation; Improve performance; Image distance metric
   learning; Neighborhood sets; Algorithm performance; Visual similarity;
   Semantic similarity; Probability density ratio
ID OBJECT RECOGNITION; RETRIEVAL; MODEL; SELECTION
AB Since there is semantic gap between low-level visual features and high-level image semantic, the performance of many existing content-based image annotation algorithms is not satisfactory. In order to bridge the gap and improve the image annotation performance, a novel automatic image annotation (AIA) approach using neighborhood set (NS) based on image distance metric learning (IDML) algorithm is proposed in this paper. According to IDML, we can easily obtain the neighborhood set of each image since obtained image distance can effectively measure the distance between images for AIA task. By introducing NS, the proposed AIA approach can predict all possible labels of the image without caption. The experimental results confirm that the introduction of NS based on IDML can improve the efficiency of AIA approaches and achieve better annotation performance than the existing AIA approaches. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jin, Cong] Cent China Normal Univ, Sch Comp, Wuhan 430079, Peoples R China.
   [Jin, Shu-Wei] Ecole Normale Super, Dept Phys, 24 Rue Lhomond, F-75231 Paris 5, France.
C3 Central China Normal University; Universite PSL; Ecole Normale
   Superieure (ENS)
RP Jin, C (corresponding author), Cent China Normal Univ, Sch Comp, Wuhan 430079, Peoples R China.
EM jincong@mail.ccnu.edu.cn
OI , Cong/0000-0002-3703-359X
FU Natural Social Science Foundation of China [13BTQ050]
FX This work was supported by Natural Social Science Foundation of China
   (Grant No. 13BTQ050).
CR Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], 1999, 1 INT WORKSH MULT IN
   [Anonymous], 2007, THESIS
   [Anonymous], 2006, P 2006 IEEE COMPUTER, DOI DOI 10.1109/CVPR.2006.167
   [Anonymous], 2001, P 24 ANN INT ACM SIG
   [Anonymous], 2011, THESIS
   Bar-Hillel A., 2003, ICML, P11
   Nguyen CT, 2013, ACM T WEB, V7, DOI 10.1145/2516633.2516634
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang JY, 2015, COMPUT VIS IMAGE UND, V132, P3, DOI 10.1016/j.cviu.2014.11.006
   Chen ZH, 2012, IEEE T SYST MAN CY C, V42, P1120, DOI 10.1109/TSMCC.2011.2178831
   Chiang CC, 2013, COMPUT STAND INTER, V35, P50, DOI 10.1016/j.csi.2012.05.002
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Cusano C, 2004, PROC SPIE, V5304, P330
   Davis J. V., 2007, ICML, P209
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   Fan Rong-En, 2007, A study on threshold selection for multi-label classification
   Feng S. L., 2004, COMPUTER VISION PATT, V2, pII
   Goldberger S., 2005, ADV NEURAL INFORM PR, V17, P103
   Gomes RB, 2013, COMPUT GRAPH-UK, V37, P496, DOI 10.1016/j.cag.2013.03.005
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hoo WL, 2015, EXPERT SYST APPL, V42, P3991, DOI 10.1016/j.eswa.2015.01.019
   Hu QH, 2010, IEEE T SYST MAN CY B, V40, P137, DOI 10.1109/TSMCB.2009.2024166
   Escalante HJ, 2012, EXPERT SYST APPL, V39, P11011, DOI 10.1016/j.eswa.2012.03.023
   Jin C, 2015, SIGNAL PROCESS, V109, P172, DOI 10.1016/j.sigpro.2014.10.031
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Li Xiao-xu, 2012, Journal of China Universities of Posts and Telecommunications, V19, P107, DOI 10.1016/S1005-8885(11)60254-9
   Li Zheng, 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P1187, DOI 10.1145/1873951.1874183
   Liu Y., 2007, OVERVIEW DISTANCE ME
   Lu JJ, 2010, KNOWL INF SYST, V24, P325, DOI 10.1007/s10115-009-0240-0
   Lughofer E, 2012, PATTERN RECOGN, V45, P884, DOI 10.1016/j.patcog.2011.08.009
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Samanta K, 2014, COMPUT IND ENG, V69, P1, DOI 10.1016/j.cie.2013.12.010
   Seeger Matthias, 2000, Technical Report
   Shrivastava N, 2014, INFORM SCIENCES, V259, P212, DOI 10.1016/j.ins.2013.08.043
   Si L, 2006, MULTIMEDIA SYST, V12, P34, DOI 10.1007/s00530-006-0033-1
   Srivastava P, 2014, MOBILE NETW APPL, V19, P618, DOI 10.1007/s11036-014-0526-7
   Sun L, 2014, PATTERN RECOGN, V47, P1361, DOI 10.1016/j.patcog.2013.10.015
   Taieb MAH, 2014, ENG APPL ARTIF INTEL, V36, P238, DOI 10.1016/j.engappai.2014.07.015
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thamar S., 2001, IASTED INT C ART INT
   Thomas J., 2003, SPRINGER MONOGRAPHS
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wang C., 2008, ACM SIGIR, P355, DOI DOI 10.1145/1390334.1390396
   Watcharapinchai N, 2011, LECT NOTES COMPUT SC, V6468, P359
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu Lei., 2009, Proceedings of the 17th ACM international conference on Multimedia. ACM, P135
   Yao YY, 1998, INFORM SCIENCES, V111, P239, DOI 10.1016/S0020-0255(98)10006-3
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhou N, 2011, IEEE T PATTERN ANAL, V33, P1281, DOI 10.1109/TPAMI.2010.204
   Zhuang Y., 1999, Proceedings of the SPIE: Storage and Retrieval For Media Databases, V1, P442, DOI [DOI 10.1117/12.373576, 10.1117/12.373576]
NR 58
TC 17
Z9 20
U1 1
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 167
EP 175
DI 10.1016/j.jvcir.2015.10.017
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400015
DA 2024-07-18
ER

PT J
AU Kim, TE
   Kim, MH
AF Kim, Tak-Eun
   Kim, Myoung Ho
TI Improving the search accuracy of the VLAD through weighted aggregation
   of local descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compact image descriptor; Weighting scheme; Weighted VLAD; Saliency
   analysis; Content-based image retrieval; Importance of local
   descriptors; Calibration of saliency values; Search accuracy
ID IMAGE CLASSIFICATION; SCALE; FEATURES; IDF
AB We present a novel compact image descriptor, called the Weighted VLAD (wVLAD), which extends the original vector of locally aggregated descriptors (VLAD). The main idea is that the relative importance of local descriptors can be quite different among the local descriptors of an image, depending on the positions from which the descriptors are extracted. Thus, we propose an approach where we assign a weight to each local descriptor of an image, and then compute weighted aggregations of local descriptors. The weights of local descriptors are measured by performing saliency analysis together with an appropriate calibration function. We show, through experiments on publicly available datasets, that our proposed method works better than other existing methods in most image datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kim, Tak-Eun; Kim, Myoung Ho] Korea Adv Inst Sci & Technol, Dept Comp Sci, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, MH (corresponding author), Korea Adv Inst Sci & Technol, Dept Comp Sci, 291 Daehak Ro, Taejon 305701, South Korea.
EM tekim@dbserver.kaist.ac.kr; mhkim@dbserver.kaist.ac.kr
RI Kim, Myoung Ho/C-1997-2011
FU Bio-Synergy Research Project of the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, through the National Research Foundation
   [NRF-2013M3A9C4078137]; MSIP, Korea under the ITRC (Information
   Technology Research Center) support program [NIPA-2013-H0301-13-4009]
FX This work was supported by the Bio-Synergy Research Project
   (NRF-2013M3A9C4078137) of the MSIP (Ministry of Science, ICT and Future
   Planning), Korea, through the National Research Foundation, and by the
   MSIP, Korea under the ITRC (Information Technology Research Center)
   support program (NIPA-2013-H0301-13-4009) supervised by the NIPA
   (National IT Industry Promotion Agency).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2011, P 2 ANN ACM C MULTIM
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chandrasekhar V, 2012, INT J COMPUT VISION, V96, P384, DOI 10.1007/s11263-011-0453-z
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2009, IEEE I CONF COMP VIS, P2357, DOI 10.1109/ICCV.2009.5459419
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Marszalek M., 2006, PROC IEEE INT C COMP, V2, P2118
   Marszalek M, 2012, INT J COMPUT VISION, V97, P191, DOI 10.1007/s11263-011-0479-2
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Murata M, 2014, IEEE T MULTIMEDIA, V16, P1690, DOI 10.1109/TMM.2014.2323945
   Perronnin F., 2007, P IEEE CVPR, P1
   Philbin J., 2008, PROC COMPUTER VISION, P1
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shi MJ, 2015, PROC CVPR IEEE, P605, DOI 10.1109/CVPR.2015.7298659
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Torralba A., 2008, PROC COMPUTER VISION, P1
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Z., 2014, PROC INT C MACHINE L, P1
   Xie LX, 2014, IEEE T IMAGE PROCESS, V23, P1994, DOI 10.1109/TIP.2014.2310117
   Xu LF, 2013, J VIS COMMUN IMAGE R, V24, P465, DOI 10.1016/j.jvcir.2013.02.007
   Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 40
TC 11
Z9 15
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 237
EP 252
DI 10.1016/j.jvcir.2015.07.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600022
DA 2024-07-18
ER

PT J
AU Leborgne, A
   Mille, J
   Tougne, L
AF Leborgne, Aurelie
   Mille, Julien
   Tougne, Laure
TI Noise-resistant Digital Euclidean Connected Skeleton for graph-based
   shape matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skeletonization; Squared Euclidean distance map; Maximal ball; Medial
   axis; Ridge point detection; Digital shape representation; Pruning;
   Linear complexity; Shape reconstruction
ID SHOCK GRAPHS; ALGORITHM; PARALLEL
AB The skeleton is an essential shape descriptor providing a compact representation of a shape that can be used in the context of real object recognition. However, due to the discretization, the required properties to use it for graph matching (homotopy to the shape, consequently connectivity, thinness, robustness to noise) may be difficult to obtain simultaneously. In this paper, we propose a new skeletonization algorithm having all these properties, based on the Euclidean distance map. More precisely, the algorithm cleverly combines the centers of maximal balls included in the shape and the ridges of the distance map. Post-processing is then applied to thin and prune the resulting skeleton. We compare the proposed method to three fairly recent methods and demonstrate its good properties. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Leborgne, Aurelie; Mille, Julien; Tougne, Laure] Univ Lyon, CNRS, Lyon, France.
   [Leborgne, Aurelie] INSA Lyon, LIRIS, UMR5205, F-69621 Villeurbanne, France.
   [Mille, Julien] Univ Lyon 1, LIRIS, F-69622 Villeurbanne, France.
   [Tougne, Laure] Univ Lyon 2, LIRIS, UMR5205, F-69676 Bron, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut National
   des Sciences Appliquees de Lyon - INSA Lyon; Universite Claude Bernard
   Lyon 1; Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Lyon 2
RP Leborgne, A (corresponding author), Univ Lyon 2, LIRIS, 5 Ave Pierre Mendes France, F-69676 Bron, France.
EM aurelie.leborgne@liris.cnrs.fr; julien.mille@liris.cnrs.fr;
   laure.tougne@liris.cnrs.fr
OI Tougne, Laure/0000-0001-9208-6275
CR Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Bernard T.M., 1999, 10 INT C IM AN PROC, P215
   Bertrand G, 2014, J MATH IMAGING VIS, V48, P134, DOI 10.1007/s10851-012-0402-7
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   BORGEFORS G, 1988, P 9 INT C PATT REC R, V1, P504
   Choi WP, 2003, PATTERN RECOGN, V36, P721, DOI 10.1016/S0031-3203(02)00098-5
   Coeurjolly D, 2007, IEEE T PATTERN ANAL, V29, P437, DOI 10.1109/TPAMI.2007.54
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   diBaja GS, 1996, IMAGE VISION COMPUT, V14, P47, DOI 10.1016/0262-8856(95)01039-4
   Dimitrov P, 2000, C COMP VIS PATT REC, V1, P1417
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Latecki L.J., 2000, C COMP VIS PATT REC, P1424
   LATECKI LJ, 2007, IM PROC 2007 ICIP 20, V5, P349
   Layton M., 1987, COMPUT VISION GRAPH, V38, P327
   Liu HZ, 2013, PATTERN RECOGN LETT, V34, P1138, DOI 10.1016/j.patrec.2013.03.013
   Liu L, 2010, COMPUT GRAPH FORUM, V29, P2253, DOI 10.1111/j.1467-8659.2010.01814.x
   Macrini D, 2011, COMPUT VIS IMAGE UND, V115, P1187, DOI 10.1016/j.cviu.2011.03.002
   Manzanera A, 1999, LECT NOTES COMPUT SC, V1568, P313
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Palágyi K, 2014, LECT NOTES COMPUT SC, V8466, P91, DOI 10.1007/978-3-319-07148-0_9
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   Saeed K, 2010, INT J AP MAT COM-POL, V20, P317, DOI 10.2478/v10006-010-0024-4
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shen W, 2013, PATTERN RECOGN, V46, P539, DOI 10.1016/j.patcog.2012.07.023
   Shen W, 2011, PATTERN RECOGN, V44, P196, DOI 10.1016/j.patcog.2010.08.021
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Siddiqi K, 2002, INT J COMPUT VISION, V48, P215, DOI 10.1023/A:1016376116653
   YE QZ, 1988, P 9 INT C PATT REC R, V1, P495
NR 28
TC 12
Z9 12
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 165
EP 176
DI 10.1016/j.jvcir.2015.06.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600015
DA 2024-07-18
ER

PT J
AU Aguilera-Aguilera, EJ
   Carmona-Poyato, A
   Madrid-Cuevas, FJ
   Muñoz-Salinas, R
AF Aguilera-Aguilera, E. J.
   Carmona-Poyato, A.
   Madrid-Cuevas, F. J.
   Munoz-Salinas, R.
TI Novel method to obtain the optimal polygonal approximation of digital
   planar curves based on Mixed Integer Programming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Polygonal approximation; Digital planar curve; Mixed Integer
   Programming; Discrete optimization; Dominant points; Breakpoints;
   Integral square error; Optimization
ID DOMINANT POINT DETECTION; ALGORITHM; UNIT
AB Polygonal approximations of digital planar curves are very useful for a considerable number of applications in computer vision. A great interest in this area has generated a huge number of methods for obtaining polygonal approximations. A good measure to compare these methods is known as Rosin's merit. This measure uses the optimal polygonal approximation, but the state-of-the-art methods require a tremendous computation time for obtaining this optimal solution.
   We focus on the problem of obtaining the optimal polygonal approximation of a digital planar curve. Given N ordered points on a Euclidean plane, an efficient method to obtain M points that defines a polygonal approximation with the minimum distortion is proposed.
   The new solution relies on Mixed Integer Programming techniques in order to obtain the minimum value of distortion. Results, show that computation time for the new method dramatically decreases in comparison with state-of-the-art methods for obtaining the optimal polygonal approximation. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Aguilera-Aguilera, E. J.; Carmona-Poyato, A.; Madrid-Cuevas, F. J.; Munoz-Salinas, R.] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Aguilera-Aguilera, EJ (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
EM i22agage@uco.es; ma1capoa@uco.es; ma1macuf@uco.es; in1musar@uco.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Cuevas, Francisco José
   Madrid/H-1396-2015; Carmona-Poyato, Angel/G-1593-2015
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Carmona-Poyato,
   Angel/0000-0002-8820-8396
FU Science and Technology Ministry of Spain [TIN2012-32952]; FEDER
FX This work has been developed with the support of the Research Projects
   called TIN2012-32952 and BROCA both financed by Science and Technology
   Ministry of Spain and FEDER.
CR Aguirre AM, 2012, COMPUT CHEM ENG, V47, P217, DOI 10.1016/j.compchemeng.2012.06.036
   Alemany J, 2014, INT J ELEC POWER, V54, P86, DOI 10.1016/j.ijepes.2013.06.034
   [Anonymous], 1965, LINEAR PROGRAMMING E
   Backes AR, 2013, INFORM SCIENCES, V222, P795, DOI 10.1016/j.ins.2012.07.062
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gomory R., 1958, B AM MATH SOC, V64, P275, DOI [DOI 10.1090/S0002-9904-1958-10224-4, https://doi.org/10.1090/S0002-9904-1958-10224-4]
   Grauman K, 2004, PROC CVPR IEEE, P220
   Horng JH, 2002, PATTERN RECOGN LETT, V23, P171, DOI 10.1016/S0167-8655(01)00098-8
   Inc. Gurobi Optimization, 2014, GUR OPT REF MAN
   LAND AH, 1960, ECONOMETRICA, V28, P497, DOI 10.2307/1910129
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Rueda-Medina AC, 2013, ELECTR POW SYST RES, V97, P133, DOI 10.1016/j.epsr.2012.12.009
   Salotti M, 2001, PATTERN RECOGN LETT, V22, P215, DOI 10.1016/S0167-8655(00)00088-X
   Toussaint G.T, 1988, MACHINE INTELLIGENCE, V6, P71
   Wang YM, 2012, COMPUT IND ENG, V62, P546, DOI 10.1016/j.cie.2011.11.003
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
NR 21
TC 8
Z9 8
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 106
EP 116
DI 10.1016/j.jvcir.2015.03.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900010
DA 2024-07-18
ER

PT J
AU Liang, ZS
   Yang, GB
   Ding, XL
   Li, LD
AF Liang, Zaoshan
   Yang, Gaobo
   Ding, Xiangling
   Li, Leida
TI An efficient forgery detection algorithm for object removal by
   exemplar-based image inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Blind detection; Object removal; Exemplar-based
   inpainting; Central pixel mapping; Greatest zero-connectivity component
   labeling; Fragment splicing detection; Load factor
AB As a popular image manipulation technique, object removal can be achieved by image-inpainting without any noticeable traces, which poses huge challenges to passive image forensics. The existing detection approach utilizes full search for block matching, resulting in high computational complexity. This paper presents an efficient forgery detection algorithm for object removal by exemplar-based inpainting, which integrates central pixel mapping (CPM), greatest zero-connectivity component labeling (GZCL) and fragment splicing detection (FSD). CPM speeds up suspicious block search by efficiently matching those blocks with similar hash values and then finding the suspicious pairs. To improve the detection precision, GZCL is used to mark the tampered pixels in suspected block pairs. FSD is adopted to distinguish and locate tampered regions from its best-match regions. Experimental results show that the proposed algorithm can reduce up to 90% of the processing time and maintain a detection precision above 85% under different kinds of object-removed images. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liang, Zaoshan; Yang, Gaobo; Ding, Xiangling] Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Leida] China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Peoples R China.
C3 Hunan University; China University of Mining & Technology
RP Yang, GB (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM yanggaobo@hnu.edu.cn
RI xiangling, Ding/T-7175-2019; Li, Li/AEM-3636-2022; li, li/HII-4157-2022
OI ding, xiangling/0000-0002-6581-4633
FU National Natural Science Foundation of China [61072122, 61379143];
   program for New Century Excellent Talents in University [NCET-11-0134];
   Specialized Research Fund for the Doctoral Program of Higher Education
   (SRFDP) [20120161110014]; S&T Program of Xuzhou City [XM13B119]
FX This work is supported in part by the National Natural Science
   Foundation of China (61072122, 61379143), the program for New Century
   Excellent Talents in University (NCET-11-0134), the Specialized Research
   Fund for the Doctoral Program of Higher Education (SRFDP) under Grant
   20120161110014 and the S&T Program of Xuzhou City (XM13B119). The
   authors appreciate the nice help from Dr. Wang Jing of Henan Polytechnic
   University for her providing the source codes of exemplar-based image
   inpainting.
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bacchuwar KS, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P723, DOI 10.1109/iMac4s.2013.6526502
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Chang TY, 2014, J VIS COMMUN IMAGE R, V25, P1289, DOI 10.1016/j.jvcir.2014.04.010
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Jung MY, 2011, IEEE T IMAGE PROCESS, V20, P1583, DOI 10.1109/TIP.2010.2092433
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Wang J, 2014, NEUROCOMPUTING, V123, P150, DOI 10.1016/j.neucom.2013.06.022
   Wu Q, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1222, DOI 10.1109/ICMLC.2008.4620591
NR 25
TC 60
Z9 69
U1 1
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 75
EP 85
DI 10.1016/j.jvcir.2015.03.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900007
DA 2024-07-18
ER

PT J
AU Nian, YJ
   He, M
   Wan, JW
AF Nian, Yongjian
   He, Mi
   Wan, Jianwei
TI Loss less and near-lossless compression of hyperspectral images based on
   distributed source coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral images; Lossless compression; Near-lossless compression;
   Distributed source coding; Error resilience; Low complexity; Peak error;
   Linear prediction
ID ALGORITHM
AB This paper addresses the problem of the lossless and near-lossless compression of hyperspectral images and presents two efficient algorithms based on distributed source coding, which perform the lossless compression by means of multilevel scalar codes. The proposed algorithms are implemented on the co-located blocks in the spectral orientation. A novel multiband spectral predictor is proposed to construct the side information of each block. The back-up side information is introduced for the second algorithm to recover the images when the original side information is corrupted by errors. The encoder only requires the transmission of the least significant bit (LSB) bit-planes to the decoder, and the number of bits is computed by the maximum error between the block and its side information. The proposed algorithms are also extended to near-lossless compression. The experimental results show that the proposed algorithms have a competitive compression performance with the existing distributed compression algorithms. Moreover, the proposed algorithms can provide low complexity and different degrees of error resilience, which is suitable for onboard compression. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Nian, Yongjian; He, Mi] Third Mil Med Univ, Sch Biomed Engn, Chongqing 400038, Peoples R China.
   [Wan, Jianwei] Natl Univ Def Technol, Coll Elect Sci & Engn, Changsha 410073, Hunan, Peoples R China.
C3 Army Medical University; National University of Defense Technology -
   China
RP He, M (corresponding author), Third Mil Med Univ, Sch Biomed Engn, Chongqing 400038, Peoples R China.
EM hmcherry@126.com
FU National Natural Science Foundation of China [41201363, 41301397]
FX This work has been sponsored by a grant from the National Natural
   Science Foundation of China (Nos. 41201363 and 41301397). Moreover, the
   authors would like to thank the anonymous reviewers for their insightful
   comments in improving the quality of this paper.
CR Abrardo A, 2010, IEEE T GEOSCI REMOTE, V48, P1892, DOI 10.1109/TGRS.2009.2033470
   Cheung NM, 2008, IEEE T IMAGE PROCESS, V17, P2122, DOI 10.1109/TIP.2008.2004619
   Magli E, 2004, IEEE GEOSCI REMOTE S, V1, P21, DOI 10.1109/LGRS.2003.822312
   Magli E, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/45493
   Mielikainen J, 2003, IEEE T GEOSCI REMOTE, V41, P2943, DOI 10.1109/TGRS.2003.820885
   Mielikainen J, 2012, IEEE GEOSCI REMOTE S, V9, P1118, DOI 10.1109/LGRS.2012.2191531
   Nian YJ, 2014, COMPUT ELECTR ENG, V40, P1006, DOI 10.1016/j.compeleceng.2013.12.009
   Pan XZ, 2012, IEEE GEOSCI REMOTE S, V9, P224, DOI 10.1109/LGRS.2011.2165271
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P1181, DOI 10.1109/TIT.2003.810622
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P626, DOI 10.1109/TIT.2002.808103
   Rizzo F, 2005, IEEE SIGNAL PROC LET, V12, P138, DOI 10.1109/LSP.2004.840907
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Valsesia D, 2014, IEEE T GEOSCI REMOTE, V52, P6341, DOI 10.1109/TGRS.2013.2296329
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P994, DOI 10.1109/83.846242
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
NR 17
TC 10
Z9 11
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 113
EP 119
DI 10.1016/j.jvcir.2014.06.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000013
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Hu, S
   Ma, XX
   Wang, LF
AF Pan, Zhibin
   Hu, Sen
   Ma, Xiaoxiao
   Wang, Lingfei
TI A new lossless data hiding method based on joint neighboring coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Joint neighboring coding; Embedding capacity;
   Bitwise exclusive-OR; Side-match distortion; Residual value; Embedding
   rules; Bit rate
ID HISTOGRAM-MODIFICATION; EMBEDDING TECHNIQUES; SCHEME; EXPANSION
AB In this paper, we present a new reversible data hiding method based on joint neighboring coding. The proposed method uses the side-match distortion (SMD) function to sort the codebook so as to make an index value become very close to its neighboring index values, then the residual value between the index and its neighboring index is obtained by bitwise exclusive-OR operation and the secret bits are embedded into the residual value according to our embedding rules based on joint neighboring coding. The experimental results show our proposed method outperforms the related existing data hiding methods in embedding performance. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Pan, Zhibin; Hu, Sen; Ma, Xiaoxiao; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of the State Key Lab of SKL, Nanjing
   University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30) and Open Project Program of the State Key Lab of
   SKL (Grant No. KFKT2013B05), Nanjing University.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2007, IEEE T INF FOREN SEC, V2, P341, DOI 10.1109/TIFS.2007.902683
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2012, INFORM SCIENCES, V201, P70, DOI 10.1016/j.ins.2011.12.025
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2010, INFORM SCIENCES, V180, P3045, DOI 10.1016/j.ins.2010.03.027
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chen CC, 2010, SIGNAL PROCESS, V90, P2141, DOI 10.1016/j.sigpro.2010.01.018
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Lee CF, 2011, IMAGING SCI J, V59, P278, DOI 10.1179/1743131X10Y.0000000018
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin CC, 2009, INFORM SCIENCES, V179, P140, DOI 10.1016/j.ins.2008.09.001
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang C, 2010, IEEE IMAGE PROC, P217, DOI 10.1109/ICIP.2010.5652066
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   ZHAO Z, 2011, INT J ELECT COMMUNIC, V65, P814
NR 25
TC 6
Z9 6
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 14
EP 23
DI 10.1016/j.jvcir.2014.09.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000003
DA 2024-07-18
ER

PT J
AU Yang, HY
   Li, YW
   Li, WY
   Wang, XY
   Yang, FY
AF Yang, Hong-Ying
   Li, Yong-Wei
   Li, Wei-Yi
   Wang, Xiang-Yang
   Yang, Fang-Yu
TI Content-based image retrieval using local visual attention feature
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Salient point; SURF; Visually significant image point;
   Weighted color histogram; Spatial distribution entropy; Color complexity
   measure; Similarity
ID SEGMENTATION
AB Content-based image retrieval (CBIR) has been an active research topic in the last decade. As one of the promising approaches, salient point based image retrieval has attracted many researchers. However, the related work is usually very time consuming, and some salient points always may not represent the most interesting subset of points for image indexing. Based on fast and performant salient point detector, and the salient point expansion, a novel content-based image retrieval using local visual attention feature is proposed in this paper. Firstly, the salient image points are extracted by using the fast and performant SURF (Speeded-Up Robust Features) detector. Then, the visually significant image points around salient points can be obtained according to the salient point expansion. Finally, the local visual attention feature of visually significant image points, including the weighted color histogram and spatial distribution entropy, are extracted, and the similarity between color images is computed by using the local visual attention feature. Experimental results, including comparisons with the state-of-the-art retrieval systems, demonstrate the effectiveness of our proposal. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yang, Hong-Ying; Li, Yong-Wei; Li, Wei-Yi; Wang, Xiang-Yang; Yang, Fang-Yu] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Wang, Xiang-Yang] Nanjing Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Socia, Nanjing 210094, Jiangsu, Peoples R China.
C3 Liaoning Normal University; Nanjing University of Science & Technology
RP Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM yhy_65@126.com; wxy37@126.com
RI liu, xinyi/KFB-4466-2024; Yang, Jing/JFK-4046-2023; wu,
   jun/ISB-8607-2023
OI Yang, Jing/0009-0004-8274-9863; Li, Yongwei/0000-0003-3847-6744
FU National Natural Science Foundation of China [61272416, 60873222,
   60773031]; Open Project Program of Jiangsu Key Laboratory of Image and
   Video Understanding for Social Safety (Nanjing University of Science and
   Technology) [30920130122006]; Open Foundation of Zhejiang Key Laboratory
   for Signal Processing [ZJKL_4_SP-OP2013-01]; Open Foundation of
   Provincial Key Laboratory for Computer Information Processing Technology
   (Soochow University) [KJS1325]; Open Project Program of the State Key
   Lab of CAD&CG, Zhejiang University [A1425]; Liaoning Research Project
   for Institutions of Higher Education of China [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61272416, 60873222, and 60773031, the Open
   Project Program of Jiangsu Key Laboratory of Image and Video
   Understanding for Social Safety (Nanjing University of Science and
   Technology) under Grant No. 30920130122006, the Open Foundation of
   Zhejiang Key Laboratory for Signal Processing under Grant No.
   ZJKL_4_SP-OP2013-01, the Open Foundation of Provincial Key Laboratory
   for Computer Information Processing Technology (Soochow University)
   under Grant No. KJS1325, the Open Project Program of the State Key Lab
   of CAD&CG (Grant No. A1425), Zhejiang University, and Liaoning Research
   Project for Institutions of Higher Education of China under Grant No.
   L2013407.
CR Abdullah A, 2010, PATTERN RECOGN, V43, P650, DOI 10.1016/j.patcog.2009.09.007
   Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Banerjee M, 2009, FUZZY SET SYST, V160, P3323, DOI 10.1016/j.fss.2009.02.024
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chary R., 2012, 2012 IEEE INT C COMP, P1
   Chiang CC, 2009, J VIS COMMUN IMAGE R, V20, P167, DOI 10.1016/j.jvcir.2009.01.001
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Chung CH, 2010, PATTERN RECOGN, V43, P3219, DOI 10.1016/j.patcog.2010.04.022
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   Hiremath, 2008, International Journal of Image Processing, V2, P10
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Huang W, 2010, J SIGNAL PROCESS SYS, V59, P143, DOI 10.1007/s11265-008-0294-3
   Pedrosa GV, 2011, IEEE INT SYMP CIRC S, P2797
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Pratikakis I, 2006, IEE P-VIS IMAGE SIGN, V153, P313, DOI 10.1049/ip-vis:20050061
   Stöttinger J, 2012, IEEE T IMAGE PROCESS, V21, P2681, DOI 10.1109/TIP.2012.2186143
   Stottinger J., 2007, Proceedings of the 12th Computer Vision Winter Workshop, P83
   Sun JD, 2006, PATTERN RECOGN LETT, V27, P1122, DOI 10.1016/j.patrec.2005.12.014
   Sylvie P.F., 2009, COMPUT VIS IMAGE UND, V113, P683
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Yoon KJ, 2001, PROC SPIE, V4572, P269, DOI 10.1117/12.444191
   Zhang DS, 2012, INT J COMPUT VISION, V98, P187, DOI 10.1007/s11263-011-0503-6
   Zheng X., 2007, MED IM INF MIMI 2007, P118
NR 27
TC 8
Z9 10
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1308
EP 1323
DI 10.1016/j.jvcir.2014.05.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100003
DA 2024-07-18
ER

PT J
AU He, B
   Wang, GJ
   Zhang, C
AF He, Bei
   Wang, Guijin
   Zhang, Cha
TI Iterative transductive learning for automatic image segmentation and
   matting with RGB-D data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image matting; Image segmentation; Transductive learning; Irregular
   neighboring patches; Adaptive laranger; Iterative optimization; RGB-D
   data; Kinect; Depth holes
ID ALPHA MATTE; DEPTH
AB In this paper, we propose a fully automatic image segmentation and matting approach with RGB-Depth (RGB-D) data based on iterative transductive learning. The algorithm consists of two key elements: robust hard segmentation for trimap generation, and iterative transductive learning based image matting. The hard segmentation step is formulated as a Maximum A Posterior (MAP) estimation problem, where we iteratively perform depth refinement and bi-layer classification to achieve optimal results. For image matting, we propose a transductive learning algorithm that iteratively adjusts the weights between the objective function and the constraints, overcoming common issues such as over-smoothness in existing methods. In addition, we present a new way to form the Laplacian matrix in transductive learning by ranking similarities of neighboring pixels, which is essential to efficient and accurate matting. Extensive experimental results are reported to demonstrate the state-of-the-art performance of our method both subjectively and quantitatively. (c) 2014 Elsevier Inc. All rights reserved.
C1 [He, Bei] Beijing Natl Railway Res & Design Inst Signal & C, Beijing, Peoples R China.
   [Wang, Guijin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Zhang, Cha] Microsoft Res, Redmond, WA USA.
C3 Tsinghua University; Microsoft
RP Wang, GJ (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM coo1hebei@163.com; wangguijin@tsinghua.edu.cn; chazhang@microsoft.com
FU NSFC [61271390, 61132007]
FX This work is partially sponsored by NSFC (No. 61271390) and NSFC (No.
   61132007).
CR [Anonymous], IEEE INT C COMP VIS
   Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760
   Cho JH, 2009, IEICE ELECTRON EXPR, V6, P1602, DOI 10.1587/elex.6.1602
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Duchenne O., 2008, IEEE COMPUTER VISION, P1, DOI DOI 10.1109/CVPR.2008.4587419
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   He B., 2012, IEICE T INF SYST, V96
   He B., 2013, 20 IEEE INT C IM PRO
   He B, 2012, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2012.6466851
   He KM, 2010, PROC CVPR IEEE, P2165, DOI 10.1109/CVPR.2010.5539896
   Jiangming Yu, 2012, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery, P1934, DOI 10.1109/FSKD.2012.6234121
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A., 2006, Proceedings of the International Conference on Computer Vision and Pattern Recognition, P61, DOI [10.1109/CVPR.2006.18, DOI 10.1109/TPAMI.2007.1177]
   Li S, 1995, P 3 EUR C COMP VIS, VII, P361
   Matyunin S., 2011, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, P1
   Rhemann C., 2008, P BRIT MACHINE VISIO, P1155
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shahrian E, 2012, PROC CVPR IEEE, P718, DOI 10.1109/CVPR.2012.6247741
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954
   Wang GJ, 2013, APPL OPTICS, V52, P516, DOI 10.1364/AO.52.000516
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Wang J, 2011, LECT NOTES COMPUT SC, V6930, P239
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Wang L, 2012, INT J COMPUT VISION, V97, P104, DOI 10.1007/s11263-011-0471-x
   Xiang SM, 2010, IEEE T PATTERN ANAL, V32, P2039, DOI 10.1109/TPAMI.2010.35
   Yin XW, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.1.013105
   Zhang C., 2009, Proc. IEEE International Workshop on Multimedia Signal Processing, P1
   Zhang ZP, 2012, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2012.6467308
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
   Zhu JJ, 2009, PROC CVPR IEEE, P453, DOI 10.1109/CVPRW.2009.5206520
NR 33
TC 10
Z9 13
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1031
EP 1043
DI 10.1016/j.jvcir.2014.03.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200030
DA 2024-07-18
ER

PT J
AU He, JR
   Ding, LX
   Jiang, L
   Li, ZK
   Hu, QH
AF He, Jinrong
   Ding, Lixin
   Jiang, Lei
   Li, Zhaokui
   Hu, Qinghui
TI Intrinsic dimensionality estimation based on manifold assumption
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intrinsic dimension estimation; Dimensionality reduction; Graph
   distance; Geodesic distance; Manifold assumption; Geometric relation;
   Local neighborhood; Data analysis
ID REDUCTION; EIGENMAPS
AB Dimensionality reduction is an important tool and has been widely used in many fields of data mining and machine learning. Intrinsic dimension of data sets is a key parameter for dimensionality reduction. In this paper, a new intrinsic dimension estimation method based on geometrical relationship between manifold intrinsic dimension and data neighborhood geodesic distances is presented. The estimator is derived by manifold sampling assumption. On a densely sampled manifold, the number of samples that fall into a ball is equal to the volume times the density of the ball. The radius of the ball is calculated by graph distance which is approximation of geodesic distance on manifold. Then the intrinsic dimension is estimated on each sample. Experiments conducted on synthetic and real world data set show that the performance of our new method is robust and comparable to other works. (C) 2014 Elsevier Inc. All rights reserved.
C1 [He, Jinrong; Ding, Lixin; Li, Zhaokui; Hu, Qinghui] Wuhan Univ, Sch Comp, State Key Lab Software Engn, Wuhan 430072, Hubei, Peoples R China.
   [Jiang, Lei] Hunan Univ Sci & Technol, Key Lab Knowledge Proc & Networked Manufacture, Xiangtan 411201, Peoples R China.
C3 Wuhan University; Hunan University of Science & Technology
RP He, JR (corresponding author), Wuhan Univ, Sch Comp, State Key Lab Software Engn, Wuhan 430072, Hubei, Peoples R China.
EM hejinrong@whu.edu.cn
RI Jiang, Lei/GSO-0813-2022; He, Jinrong/R-9293-2019
OI Jiang, Lei/0000-0002-5654-7748; He, Jinrong/0000-0003-4040-4766
FU Fundamental Research Funds for the Central Universities [2012211020209];
   Special Project on the Integration of Industry, Education and Research
   of Ministry of Education and Guangdong Province [2011B090400477];
   Special Project on the Integration of Industry, Education and Research
   of Zhuhai City [2011A050101005, 2012D0501990016]; Zhuhai Key Laboratory
   Program for Science and Technique [2012D0501990026]
FX The authors would like to thank the anonymous reviewers and associate
   editor for their constructive comments and suggestions. This work is
   partially supported by the Fundamental Research Funds for the Central
   Universities (No. 2012211020209), Special Project on the Integration of
   Industry, Education and Research of Ministry of Education and Guangdong
   Province (2011B090400477), Special Project on the Integration of
   Industry, Education and Research of Zhuhai City (2011A050101005,
   2012D0501990016), Zhuhai Key Laboratory Program for Science and
   Technique (2012D0501990026).
CR Aguirre LA, 1997, INT J BIFURCAT CHAOS, V7, P1411, DOI 10.1142/S0218127497001138
   [Anonymous], 2001, P 20 ACM SIGMOD SIGA
   [Anonymous], 1982, PATTERN RECOGN
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2001, MULTIDIMENSIONAL SCA
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212
   Camastra F, 2003, PATTERN RECOGN, V36, P2945, DOI 10.1016/S0031-3203(03)00176-6
   Camastra F, 2009, NEURAL COMPUT APPL, V18, P1021, DOI 10.1007/s00521-009-0266-y
   Coifman R.R., 2006, Applied and Comp. Harmonic Ana
   Costa J., 2003, CS0307038 ARXIV
   Costa J., 2004, IEEE T SIGN IN PRESS
   Dijkstra E., 1959, NUMER MATH, V1, P83
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Farahmand A. M., 2007, P 24 INT C MACH LEAR, P265, DOI [10.1145/1273496.1273530, DOI 10.1145/1273496.1273530]
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   GRASSBERGER P, 1983, PHYS REV LETT, V50, P346, DOI 10.1103/PhysRevLett.50.346
   Haro G, 2008, INT J COMPUT VISION, V80, P358, DOI 10.1007/s11263-008-0144-6
   Hein Matthias, 2005, P 22 INT C MACH LEAR, DOI DOI 10.1145/1102351.1102388
   Jolliffe I.T., 1989, PRINCIPAL COMPONENT
   Kegl Balazs, 2003, NEURAL INFORM PROCES
   Lee JA, 2007, INFORM SCI STAT, P1
   Levina E., 2005, ADV NEURAL INFORM PR, V17
   MATSUMOTO T, 1985, IEEE T CIRCUITS SYST, V32, P797, DOI 10.1109/TCS.1985.1085791
   Mordohai P, 2010, J MACH LEARN RES, V11, P411
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rozza A., 2012, MACH LEARN
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang J., 2012, Geometric structure of high-dimensional data and dimensionality reduction
   WEINBERGER KQ, 2005, P 10 INT WORKSH ART
   Yu M., 2009, PATTERN RECOGN, V42, P780
   Zhang Zhenyue, 2005, SIAM J SCI COMPUT, V26
NR 32
TC 16
Z9 20
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 740
EP 747
DI 10.1016/j.jvcir.2014.01.006
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200002
DA 2024-07-18
ER

PT J
AU Lee, TH
   Lee, YG
   Song, BC
AF Lee, Tae Hwan
   Lee, Yun-gu
   Song, Byung Cheol
TI Fast 3D video stabilization using ROI-based warping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video stabilization; Region-of-interest; Warping; 3D motion; Depth
   information; Content-preserving; De-shaking; Feature point
AB With the rapid development of portable digital video equipment, such as camcorders, digital cameras and smart phones, video stabilization techniques for camera de-shaking are strongly required. The cutting-edge video stabilization techniques provide outstanding visual quality by utilizing 3D motion, while early video stabilization is based on 20 motion only. Recently, a content-preserving warping algorithm has been acknowledged as state-of-the-art thanks to its superior stabilization performance. However, the huge computational cost of this technique is a serious burden in spite of its excellent performance. Thus, we propose a fast video stabilization algorithm that provides significantly reduced computational complexity over the state-of-the-art with the same stabilization performance. First, we estimate the 3D information of the feature points in each input frame and define the region of interest (ROI) based on the estimated 3D information. Next, if the number of feature points in the ROI is sufficient, we apply the proposed ROI-based pre-warping and content-preserving warping sequentially to the input frame. Otherwise, conventional full-frame warping is applied. From intensive simulation results, we find that the proposed algorithm reduces computational complexity to 14% of that of the state-of-the-art method, while keeping almost equivalent stabilization performance. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lee, Tae Hwan; Song, Byung Cheol] Inha Univ, Inchon 302751, South Korea.
   [Lee, Yun-gu] Kwangwoon Univ, Seoul 139701, South Korea.
C3 Inha University; Kwangwoon University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, 253 Yonghyun-4dong, Inchon 402751, South Korea.
EM yglee96@kw.ac.kr; bcsong@inha.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012R1A1B3000446]; Inha University
FX This work was supported by Basic Science Research Program through the
   National Research Foundation of Korea (NRF) funded by the Ministry of
   Education, Science and Technology (2012R1A1B3000446), and supported by
   Inha University Research Grant.
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Avidan S., 2007, ACM SIGGRAPH 2007 PA, P10, DOI [10.1145/1275808.1276390, DOI 10.1145/1275808.1276390]
   Battiato S, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P825, DOI 10.1109/ICIAP.2007.4362878
   Chang HC, 2006, J VIS COMMUN IMAGE R, V17, P659, DOI 10.1016/j.jvcir.2005.10.004
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Heckbert P.S., 1989, THESIS COMPUTER SCI
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Jebara T, 1999, IEEE SIGNAL PROC MAG, V16, P66, DOI 10.1109/79.768574
   Krishna Ratakonda, 1998, IEEE P ISCAS, V4, P69
   Lee J, 2002, IEEE T VIS COMPUT GR, V8, P119, DOI 10.1109/2945.998665
   Liu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899408
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   More, 1977, LEVENBERG MARQUARDT
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Wang JM, 2009, IEEE IMAGE PROC, P3477, DOI 10.1109/ICIP.2009.5413831
   Yeh YM, 2001, OPT ENG, V40, P2172, DOI 10.1117/1.1405415
   Zhang GF, 2009, VISUAL COMPUT, V25, P997, DOI 10.1007/s00371-009-0310-z
NR 20
TC 9
Z9 14
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 943
EP 950
DI 10.1016/j.jvcir.2014.02.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200022
DA 2024-07-18
ER

PT J
AU Lo, NW
   Chang, HT
   Chang, JY
AF Lo, Neng-Wen
   Chang, Hsuan T.
   Chang, Jiang-Yu
TI Caged mice mating behavior detection in surveillance videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mice mating; Animal behavior analysis; Video surveillance; Caged mice;
   Laboratory animals; Tracking techniques; Feature extraction; Object
   detection
ID SYSTEM
AB The purpose of this study is to develop a computer vision-based method to automatically detect the mating behavior of caged mice in surveillance videos. Previously we took advantage of our developed algorithm and analyzed the objects of mating mice in the consecutive frames, we unprecedentedly showed that, to the best of our knowledge, the mice mating behavior can be automatically detected based on video processing (Lo et al., 2009 [13]). In this paper, we proposed an improved method which monitors the distance between two mating objects and more effectively detects the mating behavior. In addition, a more detailed portrayal of the mating behavior can be further elaborated as a function of the distance patterns in the tails of two caged mice. Experimental results show that the current system can effectively detect the mice mating behavior with the highest precision rate of 96.1%, far better than that of our previously proposed method. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lo, Neng-Wen] Tunghai Univ, Dept Anim Sci & Biotechnol, Taichung 40704, Taiwan.
   [Chang, Hsuan T.; Chang, Jiang-Yu] Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Touliu 64002, Yunlin, Taiwan.
C3 Tunghai University; National Yunlin University Science & Technology
RP Chang, HT (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Elect Engn, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
EM htchang@yuntech.edu.tw
FU National Yunlin University of Science and Technology (YunTech), Yunlin
   Taiwan; National Science Council of the Republic of China, Taiwan
FX The authors would like to thank National Yunlin University of Science
   and Technology (YunTech), Yunlin Taiwan, and the National Science
   Council of the Republic of China, Taiwan, for financially supporting
   this research.
CR Burghardt T, 2006, IEE P-VIS IMAGE SIGN, V153, P305, DOI 10.1049/ip-vis:20050052
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Fu SC, 2009, J NEUROSCI METH, V179, P309, DOI 10.1016/j.jneumeth.2009.02.011
   Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852
   Gao DS, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P330, DOI 10.1109/ITSC.2001.948678
   Hsu CC, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P411
   Ishii Hiroyuki, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4152, DOI 10.1109/IROS.2007.4399587
   Ishii Idaku, 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P628
   Ishii I, 2008, IEEE T AUTOM SCI ENG, V5, P176, DOI 10.1109/TASE.2007.902868
   Jhuang H, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1064
   Kalafatic Z, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P175
   Kalafatic Z, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P334, DOI 10.1109/ICIAP.2001.957031
   Komuro T, 2010, IEEE T CIRC SYST VID, V20, P496, DOI 10.1109/TCSVT.2009.2035832
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Lo N.-W., 2009, P 2009 APSIPA ANN SU, P668
   Nie YM, 2009, J REAL-TIME IMAGE PR, V4, P181, DOI 10.1007/s11554-009-0111-7
   Nie Y, 2008, IEEE INT CON AUTO SC, P206, DOI 10.1109/COASE.2008.4626501
   Pan W, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P502, DOI 10.1109/ICIG.2007.14
   Shi Q, 2010, IEEE INT C INT ROBOT, P3073, DOI 10.1109/IROS.2010.5653253
   Xinwei Xue, 2006, 2006 IEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (IEEE Cat. No. 06TH8908), P335
NR 20
TC 2
Z9 2
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 755
EP 762
DI 10.1016/j.jvcir.2014.02.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200004
DA 2024-07-18
ER

PT J
AU Malekmohamadi, H
   Fernando, A
   Kondoz, A
AF Malekmohamadi, Hossein
   Fernando, Anil
   Kondoz, Ahmet
TI A new reduced reference metric for color plus depth 3D video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast measure; GLCM; RR metric; SAMVIQ; Subjective quality; Objective
   quality metric; H.264/AVC; Two-state Markov
ID QUALITY; COMPRESSION
AB A new reduced reference (RR) objective quality metric for 3D video is proposed that incorporates spatial neighboring information. The contrast measures from gray level co-occurrence matrices (GLCM) for both color and depth sections are main parts of spatial information. Side information is extracted from edge properties of reference 3D video and sent through an auxiliary channel. The other important factor in the proposed metric is the unequal weight of color and depth sections, which can maximize the performance of the proposed metric for some specific values. Performance of the proposed metric is validated through series of subjective tests. For validations, compression and transmission artifacts are considered. The average correlation of the proposed metric and subjective quality scores is 0.82 for compressed 3D videos when color to depth importance ratio is near 0.8. This measure for transmitted 3D videos is 0.857 for the same value of color to depth importance ratio. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Malekmohamadi, Hossein; Fernando, Anil; Kondoz, Ahmet] Univ Surrey, I LAB Multimedia Commun Syst Res, CVSSP, Guildford GU2 7XH, Surrey, England.
C3 University of Surrey
RP Malekmohamadi, H (corresponding author), Univ Surrey, I LAB Multimedia Commun Syst Res, CVSSP, Guildford GU2 7XH, Surrey, England.
EM h.malekmohamadi@surrey.ac.uk; w.fernando@surrey.ac.uk;
   a.kondoz@surrey.a-c.uk
RI Malekmohamadi, Hossein/I-4793-2017
OI Malekmohamadi, Hossein/0000-0003-1457-0162
CR [Anonymous], 2003, SAMVIQ SUBJ ASS METH
   [Anonymous], 2012, IEEE T CIRCUITS SYST
   [Anonymous], 2011, P 3DTV C TRUE VIS CA
   [Anonymous], 1993, DIGITAL IMAGES HUMAN
   Boev A, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218
   Bovik AC, 2001, INT CONF ACOUST SPEE, P1725, DOI 10.1109/ICASSP.2001.941272
   Farias M.C.Q., 2002, IEEE INT C IM PROC, V3
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Furht Borko, 2003, HDB VIDEO DATABASES, V8
   Gastaldo P, 2001, IEEE IJCNN, P1432, DOI 10.1109/IJCNN.2001.939572
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hewage CTER, 2012, IEEE J-STSP, V6, P471, DOI 10.1109/JSTSP.2012.2195155
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   International telecommunication union (ITU), 2000, P910 ITU, P910
   International Telecommunication Untion (ITU), 2002, BT5007 ITUR
   Ishihara S., 1917, TESTS COLOR BLINDNES
   Joveluro P., 2010, 3DTV C TRUE VIS CAPT, P1, DOI DOI 10.1109/3DTV.2010.5506331
   KNEE M, 2001, ROBUST EFFICIENT ACC
   Lambrecht CJV, 1996, INT CONF ACOUST SPEE, P2291, DOI 10.1109/ICASSP.1996.547739
   LAMBRECHT CJV, 1996, THESIS
   Lubin Jeffrey, 1993, P163
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Snellen H., 1862, PROBEBUCHSTABEN BEST
   Stefan W, 2005, DIGITAL VIDEO QUALIT
   Sugimoto O., 2000, Proceedings of the SPIE - The International Society for Optical Engineering, V4310, P932, DOI 10.1117/12.411876
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   WANG Z, 2000, INT C IM PROC, V3
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   Wegner S., 2003, IEEE T CIRCUIT SYST, V13
   Woods Richard E., 2007, DIGITAL IMAGE PROCES
NR 32
TC 10
Z9 11
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 534
EP 541
DI 10.1016/j.jvcir.2013.12.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100003
DA 2024-07-18
ER

PT J
AU Kim, S
   Lee, SH
   Ro, YM
AF Kim, Semin
   Lee, Seung Ho
   Ro, Yong Man
TI Rotation and flipping robust region binary patterns for video copy
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Region binary pattern; Rotation robust pattern; Flipping robust pattern;
   Video copy detection; Video fingerprint; Local binary pattern; Image
   Descriptor; Video Descriptor
ID MULTIRESOLUTION GRAY-SCALE; TEXTURE CLASSIFICATION; EFFICIENT
AB Many video fingerprints have been proposed to handle the video transformations problems when the original contents are copied and redistributed. However, most of them did not take into account flipping and rotation transformations. In this paper, we propose a novel video fingerprint based on region binary patterns, aiming to realize robust and fast video copy detection against video transformations including rotation and flipping. We extract two complementary region binary patterns from several rings in keyframes. These two kinds of binary patterns are converted into a new type of patterns for the proposed video fingerprint which is robust against rotation and flipping. The experimental results demonstrated that the proposed video fingerprint is effective for video copy detection particularly in the case of rotation and flipping. Furthermore, our experimental results proved that the proposed method allows for high storage efficiency and low computation complexity, which is suitable for practical video copy system. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Kim, Semin; Lee, Seung Ho; Ro, Yong Man] Korea Adv Inst Sci & Technol, Dept Elect Engn, Image & Video Syst Lab, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Image & Video Syst Lab, Taejon 305701, South Korea.
EM resemin@kaist.ac.kr; leesh09@kaist.ac.kr; ymro@ee.kaist.ac.kr
RI Kim, Semin/HPD-7404-2023; Ro, Yong Man/ABF-6817-2020; Ro, Yong
   Man/C-1731-2011
OI Ro, Yong Man/0000-0001-5306-6853; Kim, Semin/0000-0003-3746-0863
FU Basic Science Research Program of the National Research Foundation (NRF)
   of Korea; Ministry of Education, Science and Technology [2011-0011383]
FX This research was supported by the Basic Science Research Program of the
   National Research Foundation (NRF) of Korea, funded by the Ministry of
   Education, Science and Technology (research grant: 2011-0011383).
CR [Anonymous], TREC VID RETR EV ONL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P ACM INT C MULT NOV
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Chen DY, 2013, J VIS COMMUN IMAGE R, V24, P544, DOI 10.1016/j.jvcir.2013.04.005
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Kim C, 2005, IEEE T CIRC SYST VID, V15, P127
   Küçüktunç O, 2010, J VIS COMMUN IMAGE R, V21, P838, DOI 10.1016/j.jvcir.2010.07.001
   Lei YQ, 2012, IEEE T CIRC SYST VID, V22, P1332, DOI 10.1109/TCSVT.2012.2201670
   Leon G, 2009, IEEE INT CON MULTI, P1030, DOI 10.1109/ICME.2009.5202673
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath B.S., 2002, INTRO MPEG 7
   Barrios JM, 2011, IEEE INT CON MULTI
   Marcel Sebastien., 2007, INT J IMAGE VIDEO PR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Sarkar A, 2010, IEEE T CIRC SYST VID, V20, P870, DOI 10.1109/TCSVT.2010.2046056
   WANG L, 1990, PATTERN RECOGN, V23, P905, DOI 10.1016/0031-3203(90)90135-8
   Wang LZ, 2011, 2011 4TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK AND MULTIMEDIA TECHNOLOGY (4TH IEEE IC-BNMT2011), P286, DOI 10.1109/ICBNMT.2011.6155942
   Wei SK, 2011, IEEE T CIRC SYST VID, V21, P15, DOI 10.1109/TCSVT.2011.2105554
   Wu A. G., 2007, P ACM MM, P218
   Yonghong Tian, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3629, DOI 10.1109/ICIP.2011.6116504
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao WL, 2013, IEEE T IMAGE PROCESS, V22, P980, DOI 10.1109/TIP.2012.2226043
   Zhu CR, 2012, INFORM SCIENCES, V187, P93, DOI 10.1016/j.ins.2011.10.014
NR 31
TC 16
Z9 16
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 373
EP 383
DI 10.1016/j.jvcir.2013.12.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300014
DA 2024-07-18
ER

PT J
AU Vijayanagar, KR
   Kim, J
   Lee, Y
   Kim, JB
AF Vijayanagar, Krishna Rao
   Kim, Joohee
   Lee, Yunsik
   Kim, Jong-bok
TI Low complexity distributed video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding; Wyner-Ziv; GOP size control; Video
   surveillance; Encoder rate control; BCH code; Unidirectional;
   Low-complexity
ID INFORMATION
AB Context: Conventional video encoding is a computationally intensive process that requires a lot of computing resources, power and memory. Such codecs cannot be deployed in remote sensors that are constrained in terms of power, memory and computational capabilities. For such applications, distributed video coding might hold the answer.
   Objective: In this paper, we propose a distributed video coding (DVC) architecture that adheres to the principles of DVC by shifting the computational complexity from the encoder to the decoder and caters to low-motion scenarios like video conferencing and surveillance of hallways and buildings.
   Method: The architecture presented is block-based and introduces a simple yet effective classification scheme that aims at maximizing the use of skip blocks to exploit temporal correlation between consecutive frames. In addition to the skip blocks, a dynamic GOP size control algorithm is proposed that instantaneously alters the GOP size in response to the video statistics without causing any latency and without the need to buffer additional frames at the encoder. To facilitate real-time video delivery and consumption, iterative channel codes like low density parity check codes and turbo codes are not used and in their place a Bose-Chaudhuri-Hocquenghem (BCH) code with encoder rate control is used.
   Results: In spite of reducing the complexity and eliminating the feedback channel, the proposed architecture can match and even surpass the performance of current DVC systems making it a viable solution as a codec for low-motion scenarios.
   Conclusion: We conclude that the proposed architecture is a suitable solution for applications that require real-time, low bit rate video transmission but have constrained resources and cannot support the complex conventional video encoding solutions. Practical implications: The practical implications of the proposed DVC architecture include deployment in remote video sensors like hallway and building surveillance, video conferencing, video sensors that are deployed in remote regions (wildlife surveillance applications), and capsule endoscopy. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Vijayanagar, Krishna Rao; Kim, Joohee] Illinois Inst Technol, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
   [Lee, Yunsik] Korea Elect Technol Inst, Songnam, Gyungki Do, South Korea.
   [Kim, Jong-bok] Sane Syst, Anyang Si, Gyungki Do, South Korea.
C3 Illinois Institute of Technology; Korea Electronics Technology Institute
   (KETI)
RP Vijayanagar, KR (corresponding author), Illinois Inst Technol, Dept Elect & Comp Engn, 3301 South Dearborn St, Chicago, IL 60616 USA.
EM kvijayan@hawk.iit.edu
CR Abid H., 2010, P 44 ANN C INF SCI S, P1
   Agrafiotis D, 2006, IEEE T CIRC SYST VID, V16, P960, DOI 10.1109/TCSVT.2006.879988
   Anantrasirichai N, 2009, INT CONF ACOUST SPEE, P717, DOI 10.1109/ICASSP.2009.4959684
   [Anonymous], 2009, IEEE P PCS
   [Anonymous], P SUBOPTIC C CONV
   [Anonymous], P INT S MICR MICRO 0
   ARTIGAS X, 2007, P PICT COD S PCS 07
   Brites C., 2007, P IEEE INT C IM PROC, V2
   Chen Fu, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P333, DOI 10.1109/MMSP.2010.5662042
   Chen XM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P236
   Ciuti Gastone, 2011, IEEE Rev Biomed Eng, V4, P59, DOI 10.1109/RBME.2011.2171182
   Cui L., 2012, P SPIE, V84990M
   Deligiannis N., 2009, 16 INT C DIG SIGN PR, P1
   Deligiannis N, 2009, 2009 10TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES, P93, DOI 10.1109/WIAMIS.2009.5031440
   Du BG, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P9, DOI 10.1109/MUE.2009.12
   Eckford A.W., 2005, P 39 AS C SIGN SYST, P1203
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Hall R.D., 2010, FORENSIC ENTOMOLOGY, P1
   Hall R. D., 2010, PULP PAP IND TECHN C, P1, DOI DOI 10.1109/PAPCON.2010.5556522
   Huchet Gregory, 2009, 2009 Canadian Conference on Electrical and Computer Engineering (CCECE 2009), P674, DOI 10.1109/CCECE.2009.5090214
   Jiang J, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY PROCEEDINGS, VOLS 1-7, P1316, DOI 10.1109/ISIT.2007.4557405
   Ko B, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P785, DOI 10.1109/ICME.2008.4607552
   Kubasov D, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P251, DOI 10.1109/MMSP.2007.4412865
   Liu HW, 2009, PROCEEDINGS OF THE FIBER SOCIETY 2009 SPRING CONFERENCE, VOLS I AND II, P1
   Liu L., 2008, J IMAGE COMMUN, V23, P53
   Liu L., 2006, roc. Signal Proc. Symposium (NORSIG), P258
   Martinez JL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1125, DOI 10.1109/ICME.2008.4607637
   Martinez JL, 2008, IEEE IMAGE PROC, P1140, DOI 10.1109/ICIP.2008.4711961
   Martins R, 2010, IET IMAGE PROCESS, V4, P28, DOI 10.1049/iet-ipr.2008.0133
   Morbe M., 2007, P IEEE INT C AC SPEE, V1, pI
   Pereira F, 2007, LECT NOTES COMPUT SC, V4872, P801
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Rowitch D.N., IEEE T COMMUN, V28
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Sun Y.F., 2009, Proc.,71st EAGE Conference, Amsterdam, Netherlands, P1
   Varodayan D, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1203
   Vijayanagar K.R., 2010, P PICT COD S PCS 10
   Wang S, 2012, IEEE T CIRC SYST VID, V22, P649, DOI 10.1109/TCSVT.2011.2171263
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Yaacoub C, 2009, IEEE IMAGE PROC, P1397, DOI 10.1109/ICIP.2009.5413513
   Ye SM, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P633, DOI 10.1109/ICME.2008.4607514
NR 42
TC 6
Z9 8
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 361
EP 372
DI 10.1016/j.jvcir.2013.12.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300013
DA 2024-07-18
ER

PT J
AU Mikhelson, IV
   Lee, PG
   Sahakian, AV
   Wu, Y
   Katsaggelos, AK
AF Mikhelson, Ilya V.
   Lee, Philip G.
   Sahakian, Alan V.
   Wu, Ying
   Katsaggelos, Aggelos K.
TI Automatic, fast, online calibration between depth and color cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Calibration; Depth cameras; Color cameras; Automatic; Online; Fast;
   Point cloud; Point correspondence
AB Automatic camera calibration has remained a hard topic in computer vision since its inception due to its reliance on the image correspondence problem. This problem becomes even more pronounced when calibrating a depth image with a color image due to a lack of simple correspondences between the two modalities. In this work, we develop a completely automatic, very fast, online algorithm that demonstrates how a consumer-grade depth camera can be calibrated with a color camera with minimal user interaction. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Mikhelson, Ilya V.; Lee, Philip G.; Sahakian, Alan V.; Wu, Ying; Katsaggelos, Aggelos K.] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
   [Sahakian, Alan V.] Northwestern Univ, Dept Biomed Engn, Evanston, IL 60208 USA.
C3 Northwestern University; Northwestern University
RP Mikhelson, IV (corresponding author), Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
EM i-mikhelson@u.northwestern.edu
RI wu, yiping/JEF-4104-2023; Wu, Ying/B-7283-2009; Sahakian, Alan
   V/B-7268-2009; Katsaggelos, Aggelos K/B-7233-2009
OI Mikhelson, Ilya/0000-0001-5111-791X; Katsaggelos, Aggelos
   K/0000-0003-4554-0070; Sahakian, Alan/0000-0003-3090-0328; Koochak,
   Atousa/0000-0001-6547-2728
CR [Anonymous], MATLAB VERS 8 0 0 R2
   Bouguet J.-Y., 2004, CAMERA CALIBRATION T
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fuchs S., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587828
   Harris C., 1988, ALVEY VISION C, P147151
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Kassir A., 2010, P 2010 AUSTR C ROB A, P1
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   Mikhelson I., 2013, CALIBRT TOOLBOX MATL
   Mikhelson IV, 2012, IEEE T INF TECHNOL B, V16, P927, DOI 10.1109/TITB.2012.2204760
   Mikhelson IV, 2011, IEEE T BIO-MED ENG, V58, P1671, DOI 10.1109/TBME.2011.2111371
   More J. J., 1978, Proceedings of the Biennial Conference on numerical analysis, P105
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Shim H., 2011, VISUAL COMPUT, P1
   Silva M., 2012, WORKSH COL DEPTH CAM
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Wang ZS, 2007, APPL MATH COMPUT, V185, P894, DOI 10.1016/j.amc.2006.05.210
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Zhang XG, 2011, PROCEEDINGS OF THE 2011 INTERNATIONAL CONFERENCE ON ENGINEERING AND RISK MANAGEMENT, P1
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 23
TC 18
Z9 21
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 218
EP 226
DI 10.1016/j.jvcir.2013.03.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900019
DA 2024-07-18
ER

PT J
AU Horng, SJ
   Hsu, LY
   Li, TR
   Qiao, SJ
   Gong, X
   Chou, HH
   Khan, MK
AF Horng, Shi-Jinn
   Hsu, Ling-Yuan
   Li, Tianrui
   Qiao, Shaojie
   Gong, Xun
   Chou, Hsien-Hsin
   Khan, Muhammad Khurram
TI Using Sorted Switching Median Filter to remove high-density impulse
   noises
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Denoising; Digital image; Decision based media n filter; Impulse noise;
   SSMF; Noise model; Salt-and-pepper noise; PSNR
ID PEPPER NOISE; ALGORITHMS; SALT
AB We propose a novel Sorted Switching Median Filter (i.e. SSMF) for effectively denoising extremely corrupted images while preserving the image details. The center pixel is considered as "uncorrupted" or "corrupted" noise in the detecting stage. The corrupted pixels that possess more noise-free surroundings will have higher processing priority in the SSMF sorting and filtering stages to rescue the heavily noisy neighbors. Five noise models are considered to assess the performance of the proposed SSMF algorithm. Several extensive simulation results conducted on both grayscale and color images with a wide range (from 10% to 90%) of noise corruption clearly show that the proposed SSMF substantially outperforms all other existing median-based filters. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Horng, Shi-Jinn; Li, Tianrui; Qiao, Shaojie; Gong, Xun] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Peoples R China.
   [Horng, Shi-Jinn; Hsu, Ling-Yuan] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 106, Taiwan.
   [Hsu, Ling-Yuan] St Marys Med Nursing & Management Coll, Dept Informat Management, Yilan, Taiwan.
   [Chou, Hsien-Hsin] Natl Ilan Univ, Dept Elect Engn, Yilan, Taiwan.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh 11451, Saudi Arabia.
C3 Southwest Jiaotong University; National Taiwan University of Science &
   Technology; National Ilan University; King Saud University
RP Horng, SJ (corresponding author), 43,Sec 4,Kee Lung Rd, Taipei 106, Taiwan.
EM horngsj@yahoo.com.tw; HsuLingYuan@gmail.com; trli@home.swjtu.edu.cn;
   qiaoshaojie@gmail.com; gongxun@foxmail.com; hhchou@niu.edu.tw;
   mkhurram@ksu.edu.sa
RI Li, Tianrui/A-4889-2012; Li, Tianrui/F-4974-2019; Khan,
   Muhammad/IXN-8470-2023; KHAN, MUHAMMAD KHURRAM/E-4836-2014; Nusa,
   Nuhammad/JXY-5819-2024; Horng, Shi-Jinn/GVU-0488-2022
OI Li, Tianrui/0000-0001-7780-104X; KHAN, MUHAMMAD
   KHURRAM/0000-0001-6636-0533; Hsu, Ling-Yuan/0000-0002-9543-6872; Chou,
   Hsien-Hsin/0000-0001-7169-6752
FU National Science Council [NSC-99-2916-I-011-002-A1]; 111 Project
   [111-2-14]; One Hundred Talents Program, Sichuan Province
FX This work was supported in part by the National Science Council under
   contract number NSC-99-2916-I-011-002-A1, and it was also partially
   supported by the 111 Project under the Grant No. 111-2-14 and One
   Hundred Talents Program 2012, Sichuan Province.
CR Abadpour A, 2007, J VIS COMMUN IMAGE R, V18, P15, DOI 10.1016/j.jvcir.2006.08.001
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Cheng SC, 2003, J VIS COMMUN IMAGE R, V14, P184, DOI 10.1016/S1047-3203(03)00024-5
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Gao DH, 2012, J VIS COMMUN IMAGE R, V23, P1019, DOI 10.1016/j.jvcir.2012.06.009
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Pok G, 2003, IEEE T IMAGE PROCESS, V12, P85, DOI 10.1109/TIP.2002.804278
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Thirilogasundari V, 2012, PROCEDIA ENGINEER, V38, P2858, DOI 10.1016/j.proeng.2012.06.334
   Tkalcic M, 2003, IEEE REGION 8 EUROCON 2003, VOL A, PROCEEDINGS, P304
   Toh KKV, 2010, IEEE T CONSUM ELECTR, V56, P2560, DOI 10.1109/TCE.2010.5681141
   Tukey J. M., 1971, EXPLORATORY DATA ANA
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 1999, IEEE T CIRCUITS-II, V46, P78, DOI 10.1109/82.749102
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
NR 19
TC 26
Z9 27
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 956
EP 967
DI 10.1016/j.jvcir.2013.06.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700020
DA 2024-07-18
ER

PT J
AU Xiao, B
   Wang, GY
AF Xiao, Bin
   Wang, Guo-yin
TI Generic radial orthogonal moment invariants for invariant image
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Radial orthogonal moments; Jacobi-Fourier moments; Complex moments;
   Orthogonal Fourier-Mellin moments; Invariant image recognition;
   Invariant features; Normalized Jacobi-Fourier moments; Polar coordinate
ID PATTERN-RECOGNITION; ZERNIKE MOMENTS
AB As the variation of parameters in Jacobi polynomial, Jacobi-Fourier moments can form various types of orthogonal moments: Legendre-Fourier moments, Orthogonal Fourier-Mellin moments, Zernike moments, pseudo-Zernike moments, and so on. In this paper, we present a generic approach based on Jacobi-Fourier moments for scale and rotation invariant analysis of radial orthogonal moments, named Jacobi-Fourier moment invariants (JFMIs). It provides a fundamental mathematical tool for invariant analysis of the radial orthogonal moments since Jacobi-Fourier moments are the generic expressions of radial orthogonal moments. Theoretical and experimental results also show the superiority of the proposed method and its robustness to noise in comparison with some exist methods. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Xiao, Bin] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China.
   Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Xiao, B (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China.
EM xiaobin@cqupt.edu.cn
RI SUN, Ye/KBC-8159-2024; Xiao, Bin/E-2722-2012
OI Wang, Guoyin/0000-0002-8521-5232
FU National Natural Science Foundation of China [61201383, 61173089];
   Ningxia Natural Science Foundation [NZ12158]; Natural Science Foundation
   of Chongqing university of Posts and Telecommunications [2012-80]
FX This work was supported by the National Natural Science Foundation of
   China (61201383, 61173089), Ningxia Natural Science Foundation (NZ12158)
   and Natural Science Foundation of Chongqing university of Posts and
   Telecommunications (2012-80). The authors thank the anonymous referees
   for their valuable comments and suggestions.
CR ABRAMOWITZ M, 1964, HDB FUNCTIONS FORMUL, P733
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   Flusser J, 2002, PATTERN RECOGN, V35, P3015, DOI 10.1016/S0031-3203(02)00093-6
   Ghorbel F, 2006, PATTERN RECOGN LETT, V27, P1361, DOI 10.1016/j.patrec.2006.01.001
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Ping ZL, 2007, PATTERN RECOGN, V40, P1245, DOI 10.1016/j.patcog.2006.07.016
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Xiao B, 2012, J VIS COMMUN IMAGE R, V23, P381, DOI 10.1016/j.jvcir.2011.11.008
   Xiao B, 2012, PATTERN RECOGN, V45, P314, DOI 10.1016/j.patcog.2011.06.017
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
NR 18
TC 14
Z9 15
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1002
EP 1008
DI 10.1016/j.jvcir.2013.06.017
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700024
DA 2024-07-18
ER

PT J
AU Pyatykh, S
   Zheng, L
   Hesser, J
AF Pyatykh, Stanislav
   Zheng, Lei
   Hesser, Juergen
TI Efficient method of pixel neighborhood traversal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neighborhood traversal; Boundary condition; Image processing; Image
   filtering; Image traversal; Code optimization; Generic programming;
   Image processing library
ID IMAGE; ALGORITHMS
AB The processing of a pixel neighborhood is a common operation in image processing. Therefore, a flexible, computationally efficient and easy-to-use strategy for neighborhood traversal is required. In this paper, a new neighborhood traversal method and its implementation in C++ are presented. In the proposed method, the pixel neighbor access is organized without boundary checks and without image extension, which yields to significant improvements of computational efficiency. The method is based on a partition of the image domain, for which valid neighbor pixel offsets can be precomputed for each subset. The proposed C++ implementation is based on generic programming and can handle images of arbitrary dimensionality. It hides all implementation details from the user and can be extended in order to support additional boundary conditions. The evaluation demonstrates that the proposed method is considerably faster than neighborhood traversal implementations from other libraries. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Pyatykh, Stanislav; Zheng, Lei; Hesser, Juergen] Heidelberg Univ, Univ Med Ctr Mannheim, D-68167 Mannheim, Germany.
C3 Ruprecht Karls University Heidelberg
RP Pyatykh, S (corresponding author), Heidelberg Univ, Univ Med Ctr Mannheim, Theodor Kutzer Ufer 1-3, D-68167 Mannheim, Germany.
EM stanislav.pyatykh@medma.uni-heidelberg.de;
   lei.zheng@medma.uni-heidelberg.de;
   juergen.hesser@medma.uni-heidelberg.de
CR [Anonymous], INT 64 IA 32 ARCH OP
   [Anonymous], 2005, The ITK software guide
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bosc M, 2003, LECT NOTES COMPUT SC, V2879, P981
   Bradski G., 2008, LEARNING OPENCV
   Buades A., TECHNICAL NOTE CMLA
   DRONGOWSKI P, 2006, BASIC PERFORMANCE ME
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Janka R, 2001, INT CONF ACOUST SPEE, P949, DOI 10.1109/ICASSP.2001.941073
   Köthe U, 2000, C++ REP, V12, P24
   Kothe U., 1999, HDB COMPUTER VISION, V3, P149
   Levillain R, 2009, LECT NOTES COMPUT SC, V5720, P295, DOI 10.1007/978-3-642-03613-2_27
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Martin D., 2008, P 8 INT C COMP VIS, V2, P416
   Nvidia, 2011, COMP UN DEV ARCH PRO
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Sprunt B, 2002, IEEE MICRO, V22, P64, DOI 10.1109/MM.2002.1028477
   Stewart E., 2004, INTEL INTEGRATED PER
   Stroustrup B., 1997, The C++ Programming Language
   Zhao M., SPIE C SERIES, V5367, P39
NR 20
TC 0
Z9 0
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 719
EP 728
DI 10.1016/j.jvcir.2012.03.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400004
DA 2024-07-18
ER

PT J
AU Zhang, W
   Cham, WK
AF Zhang, Wei
   Cham, Wai-Kuen
TI Reference-guided exposure fusion in dynamic scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Exposure fusion; Deghosting; High dynamic range imaging; Tone mapping;
   Image gradient; Quality assessment; Weighting map; Flash and no-flash
   photography
ID PHOTOGRAPHY; FLASH
AB Unlike high dynamic range (HDR) imaging, exposure fusion is a process of generating a tonemapped-like HDR image directly by fusing a series of bracketed images. Since it frees users from the tedious radiometric calibration and tone mapping steps, this technique is getting more and more popular, and becomes a basic tool in many graphics software. The main drawback of exposure fusion is its limitation to static scenes and any object movement of the target scene will incur severe ghosting artifacts in the fused result. In this paper, we intend to overcome this limitation and make exposure fusion applicable in dynamic scenes. A new quality assessment system is developed, where both temporal consistency and spatial consistency are introduced to account for ghosting artifacts. Experimental results of various dynamic scenes are shown to prove the effectiveness of the proposed method. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zhang, Wei] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
   [Cham, Wai-Kuen] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 University of California System; University of California Berkeley;
   Chinese University of Hong Kong
RP Zhang, W (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
EM zhangwei@ee.cuhk.edu.hk
CR Agrawal A, 2005, ACM T GRAPHIC, V24, P828, DOI 10.1145/1073204.1073269
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], COMP VIS PATT REC IE
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Eisemann E, 2004, ACM T GRAPHIC, V23, P673, DOI 10.1145/1015706.1015778
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gallo O., 2009, P ICCP
   GROSCH T, 2006, VISION MODELING VISU, P277
   Grossberg MD, 2003, IEEE T PATTERN ANAL, V25, P1455, DOI 10.1109/TPAMI.2003.1240119
   Jacobs K, 2008, IEEE COMPUT GRAPH, V28, P84, DOI 10.1109/MCG.2008.23
   Kang SB, 2003, ACM T GRAPHIC, V22, P319, DOI 10.1145/882262.882270
   Khan E. A., 2006, P ICIP
   Li XG, 2007, J VIS COMMUN IMAGE R, V18, P397, DOI 10.1016/j.jvcir.2007.06.005
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   PARIS S, 2006, P ECCV
   Park SH, 2007, J VIS COMMUN IMAGE R, V18, P415, DOI 10.1016/j.jvcir.2007.06.008
   Pece F., 2010, P CVMP NOV
   Pedone M, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P36
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Shanmuganathan R., 2009, P EUR
   Sidibe D., 2009, P EUSIPCO
   Ward G., 2003, Journal of Graphics Tools, V8, P17, DOI 10.1080/10867651.2003.10487583
   Zhang W., 2010, P CVPR
NR 27
TC 44
Z9 47
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 467
EP 475
DI 10.1016/j.jvcir.2012.01.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800006
DA 2024-07-18
ER

PT J
AU Avci, A
   De Cock, J
   Lambert, P
   Beernaert, R
   De Smet, J
   Bogaert, L
   Meuret, Y
   Thienpont, H
   De Smet, H
AF Avci, Aykut
   De Cock, Jan
   Lambert, Peter
   Beernaert, Roe
   De Smet, Jelle
   Bogaert, Lawrence
   Meuret, Youri
   Thienpont, Hugo
   De Smet, Herbert
TI Efficient disparity vector prediction schemes with modified P frame for
   2D camera arrays
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view; Video coding; Camera array; Disparity; Vector coding;
   Estimation; Complexity; Scheme; Prediction; H.264
ID 3DTV; PERFORMANCE
AB An efficient disparity estimation algorithm for multi-view video sequences, recorded by a two-dimensional camera array in which the cameras are spaced equidistantly, is presented. Because of the strong geometrical relationship among views, the disparity vectors of a certain view can for most blocks be derived from the disparity vectors of other views. A frame constructed using that idea is called a D frame in this work. Three new prediction schemes which contain D frames are proposed for encoding 5 x 3 multi-view video sequences. The schemes are applied to several multi-view image sequences taken from a camera-array and they are compared in terms of quality, bit-rate and complexity. The experimental results show that the proposed prediction schemes significantly decrease the complexity of the encoder at a very low cost of quality and/or bit-rate. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Avci, Aykut; Beernaert, Roe; De Smet, Jelle; De Smet, Herbert] Univ Ghent, Ctr Microsyst Technol, Dept Elect & Informat Syst, B-9052 Ghent, Belgium.
   [De Cock, Jan; Lambert, Peter] Univ Ghent, IBBT, Dept Elect & Informat Syst, Multimedia Lab, B-9050 Ledeberg Ghent, Belgium.
   [Bogaert, Lawrence; Meuret, Youri; Thienpont, Hugo] Vrije Univ Brussel, Brussels Photon Team, B-1050 Brussels, Belgium.
   [De Smet, Herbert] IMEC, Ctr Microsyst Technol, B-9052 Ghent, Belgium.
C3 Ghent University; Ghent University; Vrije Universiteit Brussel; IMEC;
   Ghent University
RP Avci, A (corresponding author), Univ Ghent, Ctr Microsyst Technol, Dept Elect & Informat Syst, Technol Pk 914, B-9052 Ghent, Belgium.
EM Aykut.Avci@UGent.be
RI Meuret, Youri/C-5148-2016; Avci, Aykut/G-2598-2012; Thienpont,
   Hugo/AAH-4242-2020; De Smet, Herbert/D-1221-2010; Lambert,
   Peter/D-7776-2016
OI Thienpont, Hugo/0000-0003-0483-0960; De Smet,
   Herbert/0000-0001-9640-8454; Lambert, Peter/0000-0001-5313-4158; Meuret,
   Youri/0000-0002-2815-5915
FU Research Foundation-Flanders (FWO-Vlaanderen)
FX This work is supported by the Research Foundation-Flanders
   (FWO-Vlaanderen). The project is titled "Compact LCOS projection
   displays for high-quality 3D images with high spatial and angular
   resolution".
CR Alvarez M, 2005, I S WORKL CHAR PROC, P24, DOI 10.1109/IISWC.2005.1525998
   [Anonymous], 2006, 7 WORKSH DIG BROADC
   Avci A, 2010, PROC SPIE, V7526, DOI 10.1117/12.838296
   Benzie P, 2007, IEEE T CIRC SYST VID, V17, P1647, DOI 10.1109/TCSVT.2007.905377
   Bjotegaard G., 2001, VCEGM33
   Chen Y, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/786015
   Cooke E, 2006, SIGNAL PROCESS-IMAGE, V21, P476, DOI 10.1016/j.image.2006.03.004
   *ITU T, 2005, H264 ITUT
   Kim YT, 2004, SIGNAL PROCESS-IMAGE, V19, P539, DOI 10.1016/j.image.2004.04.004
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Lin JP, 2009, IEEE INT SYMP CIRC S, P2589, DOI 10.1109/ISCAS.2009.5118331
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Pang D, 2009, IEEE INT CON MULTI, P5, DOI 10.1109/ICME.2009.5202422
   Saponara S, 2004, EURASIP J APPL SIG P, V2004, P220, DOI 10.1155/S111086570431019X
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Ugur K, 2007, IEEE 3DTV C MAY, P1
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 19
TC 5
Z9 8
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 287
EP 292
DI 10.1016/j.jvcir.2011.10.006
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900006
OA Green Published
DA 2024-07-18
ER

PT J
AU Seeman, M
   Zemcík, P
   Juránek, R
   Herout, A
AF Seeman, Michal
   Zemcik, Pavel
   Juranek, Roman
   Herout, Adam
TI Fast bilateral filter for HDR imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bilateral filter; HDR; Dynamic range reduction; Tone mapping; Image
   processing; Approximation; Acceleration; Human visual system
AB Bilateral filtering is a method often used in image processing applications. It is specifically useful for HDR algorithms. A novel approach to a fast and close approximation of bilateral filtering is presented. The method is designed especially with a focus on HDR image conversion into a normal color space processing. This paper presents the methods itself, describes the sources of acceleration and discusses the results of the method. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Seeman, Michal; Zemcik, Pavel; Juranek, Roman; Herout, Adam] Brno Univ Technol, Fac Informat Technol, Brno 61266, Czech Republic.
C3 Brno University of Technology
RP Seeman, M (corresponding author), Brno Univ Technol, Fac Informat Technol, Bozetechova 2, Brno 61266, Czech Republic.
EM seeman@fit.vutbr.cz; zemcik@fit.vutbr.cz; ijuranek@fit.vutbr.cz;
   herout@fit.vutbr.cz
RI Zemcik, Pavel/G-6439-2010; Herout, Adam/B-5651-2014; Herout,
   Adam/ITV-1820-2023; Herout, Adam/ITT-4790-2023
OI Zemcik, Pavel/0000-0001-7969-5877; Juranek, Roman/0000-0003-0589-0172;
   Herout, Adam/0000-0003-2143-9314
FU Czech Ministry of Education [2B06052]
FX This paper was supported by Czech Ministry of Education project
   Biomarker (2B06052).
CR [Anonymous], P ACM AFRIGRAPH 04
   [Anonymous], 1995, P MUSTERERKENNUNG 19
   [Anonymous], P ACM SIGGRAPH BOST
   [Anonymous], 2002, PROC ACM T GRAPH SIG, DOI DOI 10.1145/566570.566574
   PARIS S, 2006, P EUR C COMP VIS MA, P24
   Porikli F., 2008, IEEE COMP SOC C COMP
   SEEMAN M, 2009, P GRAVISMA PLZEN CZE, P145
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yoshizawa S, 2010, COMPUT GRAPH FORUM, V29, P60, DOI 10.1111/j.1467-8659.2009.01544.x
NR 9
TC 4
Z9 5
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 12
EP 17
DI 10.1016/j.jvcir.2011.07.012
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100002
DA 2024-07-18
ER

PT J
AU Liu, HW
   Sun, MT
   Wu, RC
   Yu, SS
AF Liu, Haowei
   Sun, Ming-Ting
   Wu, Ruei-Cheng
   Yu, Shiaw-Shian
TI Automatic video activity detection using compressed domain motion
   trajectories for H.264 videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Activity detection; Vehicle tracking; Compressed domain processing;
   H.264 videos; Object classification; Trajectory classification; Motion
   vector tracking; Residual error tracking
AB Most automatic event detection methods for video surveillance detect target events based on features extracted in the pixel domain. However, in practice, surveillance videos are often compressed. It is desirable to perform automatic event detection in the compressed domain directly so that the video does not need to be decoded for analysis purpose. In this paper, we investigate the use of motion trajectories for video activity detection in the compressed domain. We show it is possible to extract reliable motion trajectories directly from compressed H.264 video streams. To overcome the problems caused by unreliable motion vectors, we propose to include the information from the compressed domain prediction residuals to make the tracking more robust. We use a real world application of detecting vacant or occupied parking spaces to demonstrate the effectiveness of our proposed approach. We also demonstrate the robustness of our approach to different encoder settings, and lighting conditions. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Liu, Haowei; Sun, Ming-Ting] Univ Washington, Seattle, WA 98195 USA.
   [Wu, Ruei-Cheng; Yu, Shiaw-Shian] Ind Technol Res Inst, Hsinchu, Taiwan.
C3 University of Washington; University of Washington Seattle; Industrial
   Technology Research Institute - Taiwan
RP Liu, HW (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM hwliu@u.washington.edu; mts@u.washington.edu; AllenRCWu@itri.org.tw;
   ssyu@itri.org.tw
CR Chen ZB, 2006, J VIS COMMUN IMAGE R, V17, P264, DOI 10.1016/j.jvcir.2004.12.002
   COIMBRA M, 2004, P IEEE INT C AC SPEE, V3
   Fonseca PM, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/59451
   HUANG CC, 2008, IEEE INT C AC SPEECH
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee CH, 2005, CAR C SECUR, P271, DOI 10.1109/CCST.2005.1594862
   Lie Wen-Nang., 2001, IEEE International Conference on Multimedia and Expo (ICME), P965
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   SULLIVAN G, 2005, 16 M POZN PL 24 29 J
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tourapis AM, 2002, PROC SPIE, V4671, P1069, DOI 10.1117/12.453031
   WANG WQ, 2005, IEEE INT WORKSH VID
   Wang XG, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P36, DOI 10.1109/ACV.1998.732855
   YAMASAKI A, 2008, INT C PATT REC ICPR
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 16
TC 11
Z9 12
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 432
EP 439
DI 10.1016/j.jvcir.2011.03.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800007
DA 2024-07-18
ER

PT J
AU Baseski, E
   Pugeault, N
   Kalkan, S
   Bodenhagen, L
   Piater, JH
   Krüger, N
AF Baseski, Emre
   Pugeault, Nicolas
   Kalkan, Sinan
   Bodenhagen, Leon
   Piater, Justus H.
   Kruger, Norbert
TI Using multi-modal 3D contours and their relations for vision and
   robotics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cognitive vision; Contour representation; 3D contours; Contour
   relations; Perceptual relations; 3D reasoning; Driver assistance;
   Grasping
ID SIMULTANEOUS LOCALIZATION; PERCEPTUAL ORGANIZATION; OBJECT; APPEARANCE;
   ALGORITHM; TRACKING; SYSTEM
AB In this work, we make use of 3D contours and relations between them (namely, coplanarity, cocolority, distance and angle) for four different applications in the area of computer vision and vision-based robotics. Our multi-modal contour representation covers both geometric and appearance information. We show the potential of reasoning with global entities in the context of visual scene analysis for driver assistance, depth prediction, robotic grasping and grasp learning. We argue that, such 3D global reasoning processes complement widely-used 2D local approaches such as bag-of-features since 3D relations are invariant under camera transformations and 3D information can be directly linked to actions. We therefore stress the necessity of including both global and local features with different spatial dimensions within a representation. We also discuss the importance of an efficient use of the uncertainty associated with the features, relations, and their applicability in a given context. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Baseski, Emre; Bodenhagen, Leon; Kruger, Norbert] Univ So Denmark, Maersk Mc Kinney Moller Inst, Odense, Denmark.
   [Pugeault, Nicolas] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 5XH, Surrey, England.
   [Kalkan, Sinan] Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey.
   [Piater, Justus H.] Univ Liege, Dept Elect Engn & Comp Sci, Liege, Belgium.
C3 University of Southern Denmark; University of Surrey; Middle East
   Technical University; University of Liege
RP Baseski, E (corresponding author), Univ So Denmark, Maersk Mc Kinney Moller Inst, Odense, Denmark.
EM emre@mmmi.sdu.dk; n.pugeault@surrey.ac.uk; skalkan@ceng.metu.edu.tr;
   lebo@mmmi.sdu.dk; Justus.Piater@ULg.ac.be; norbert@mmmi.sdu.dk
RI Kalkan, Sinan/A-4843-2016; Pugeault, Nicolas/AAF-9768-2019; Pugeault,
   Nicolas/JGC-8673-2023; Pugeault, Nicolas/I-1873-2015; KALKAN,
   Sinan/AAC-3625-2019; Bodenhagen, Leon/Q-9790-2018; Kruger,
   Norbert/P-6315-2015
OI Pugeault, Nicolas/0000-0002-3455-6280; Pugeault,
   Nicolas/0000-0002-3455-6280; Piater, Justus/0000-0002-1898-3362; Kalkan,
   Sinan/0000-0003-0915-5917; Bodenhagen, Leon/0000-0002-8083-0770; Kruger,
   Norbert/0000-0002-3931-116X
FU European Commission [IST-FP6-IP-027657]; European Regional Development
   Fund
FX This work was conducted within the EU Cognitive Systems project
   PACO-PLUS (IST-FP6-IP-027657) funded by the European Commission and the
   INTERREG 4 A-program Syddanmark-Schleswig-K.E.R.N. with funds by the
   European Regional Development Fund.
CR Altmann CF, 2003, CURR BIOL, V13, P342, DOI 10.1016/S0960-9822(03)00052-6
   [Anonymous], 2002, P AAAI IAAI
   [Anonymous], 2003, Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence (IJCAI)
   [Anonymous], 1988, Proceedings of International Conference ofComputer Vision (ICCV'88), DOI [10.1109/CCV.1988.590008, DOI 10.1109/CCV.1988.590008]
   Behrmann M, 2003, J EXP PSYCHOL HUMAN, V29, P19, DOI 10.1037/0096-1523.29.1.19
   BERGSTROM N, 2009, ICVS, P245
   Bertozzi M, 2000, ROBOT AUTON SYST, V32, P1, DOI 10.1016/S0921-8890(99)00125-6
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   BODENHAGEN L, 2009, THESIS U SO DENMARK
   BOESMAN B, 2009, VIS MOD VIS WORKSH V
   Camps OI, 1998, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.1998.698678
   CLARKE J, 1998, 216198 U OXF DEP ENG
   De Winter J, 2004, BEHAV RES METH INS C, V36, P604, DOI 10.3758/BF03206541
   Dickinson S. J., 1991, Workshop on Directions in Automated CAD-Based Vision. (Cat. No.91TH0377-2), P85, DOI 10.1109/CADVIS.1991.148761
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381
   FIDLER S, 2007, CVPR07
   FIDLER S, 2008, CVPR08, P182
   FIDLER S, 2006, CVPR, P182
   FIELD DJ, 1993, VISION RES, V33, P173, DOI 10.1016/0042-6989(93)90156-Q
   Guivant JE, 2001, IEEE T ROBOTIC AUTOM, V17, P242, DOI 10.1109/70.938382
   Henricsson O., 1995, Automatic Extraction of Man-Made Objects from Aerial and Space Images, P13
   Hoschek J., 1993, FUNDAMENTALS COMPUTE
   Huebner K, 2008, IEEE INT CONF ROBOT, P1628, DOI 10.1109/ROBOT.2008.4543434
   Hunt RW G., 1998, MEASURING COLOUR
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalkan S, 2007, NETWORK-COMP NEURAL, V18, P129, DOI 10.1080/09548980701580444
   KALKAN S, 2008, VISAPP 08
   Kamon I, 1996, IEEE INT CONF ROBOT, P2470, DOI 10.1109/ROBOT.1996.506534
   Karhunen J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P995, DOI 10.1109/ICNN.1995.487556
   KIKUCHI M, 2005, J VIS, V5, P76
   KRUGER N, 2004, INTERDISCIPLINARY J, V1, P417
   Lee IK, 2000, COMPUT AIDED GEOM D, V17, P161, DOI 10.1016/S0167-8396(99)00044-8
   Leibe B, 2003, PROC CVPR IEEE, P409
   Lemaire T, 2007, INT J COMPUT VISION, V74, P343, DOI 10.1007/s11263-007-0042-3
   Lerner Y, 2001, CEREB CORTEX, V11, P287, DOI 10.1093/cercor/11.4.287
   Lowe D. G., 1985, Perceptual Organization and Visual Recognition
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   McCall JC, 2006, IEEE T INTELL TRANSP, V7, P20, DOI 10.1109/TITS.2006.869595
   Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Montúfar-Chaveznava R, 2009, COMM COM INF SC, V33, P119
   Moreels P, 2005, IEEE I CONF COMP VIS, P800
   MURRAY D, 2005, WACV MOTION 05, V1, P192
   Murray D. W., 2004, THESIS
   MYKOLAJCZYK K, 2002, P EUR C COMP VIS ECC
   Nedevschi S, 2004, ITSC 2004: 7TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P161, DOI 10.1109/ITSC.2004.1398890
   Pearl J., 1988, PROBABILISTIC REASON
   Piegl L, 1995, NURBS BOOK
   Pilz F, 2009, LECT NOTES COMPUT SC, V5604, P280, DOI 10.1007/978-3-642-03061-1_14
   PONCE J, 1993, INT J ROBOT RES, V12, P263, DOI 10.1177/027836499301200305
   Popovic M, 2010, ROBOT AUTON SYST, V58, P551, DOI 10.1016/j.robot.2010.01.003
   PUGEAULT N, 2008, P INT C COMP VIS THE
   PUGEAULT N, 2003, P BRIT MACH VIS C BM
   PUGEAULT N, INT J HUMAN IN PRESS
   PUGEAULT N, 2006, P IEEE WORKSH PERC O
   Quack T, 2007, IEEE I CONF COMP VIS, P612
   RALLI J, MACHINE VIS IN PRESS
   SABATINI SP, 2007, INT C COMP VIS THEOR, V1, P213
   Saxena A, 2008, INT J ROBOT RES, V27, P157, DOI 10.1177/0278364907087172
   SHAPIRO LG, 1984, PATTERN RECOGN, V17, P385, DOI 10.1016/0031-3203(84)90068-2
   Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772
   Speth J, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2240, DOI 10.1109/IROS.2008.4650632
   Tanaka K, 1997, CURR OPIN NEUROBIOL, V7, P523, DOI 10.1016/S0959-4388(97)80032-3
   Thrun S, 2004, INT J ROBOT RES, V23, P693, DOI 10.1177/0278364904045479
   TKALCIC M, 2003, IEEE REGION, V8, P304
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Ullman S., 1996, High level vision
   VANDERMERWE R, 2000, ADV NEURAL INFORM PR, V13
   WANG X, 1997, FUZZ INF PROC SOC 19, P160
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
NR 71
TC 7
Z9 7
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 850
EP 864
DI 10.1016/j.jvcir.2010.06.006
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500009
DA 2024-07-18
ER

PT J
AU Kang, XZ
   Zhang, H
   Jiang, GF
   Chen, HF
   Meng, XQ
   Yoshihira, K
AF Kang, Xiaozhu
   Zhang, Hui
   Jiang, Guofei
   Chen, Haifeng
   Meng, Xiaoqiao
   Yoshihira, Kenji
TI Understanding Internet Video sharing site workload: A view from data
   center design
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Measurement; Data center design; Media system; Online video; Workload
   management; Capacity planning; SLAs; Queueing model; Quality of service
AB Internet Video sharing sites, led by YouTube, have been gaining popularity in a dazzling speed, which also brings massive workload to their service data centers. In this paper we analyze Yahoo! Video, the 2nd largest U.S. video sharing site, to understand the nature of such unprecedented massive workload as well as its impact on online video data center design. We crawled the Yahoo! Video web site for 46 days. The measurement data allows us to understand the workload characteristics at different time scales (minutes, hours, days, weeks), and we discover interesting statistical properties on both static and temporal dimensions of the workload including file duration and popularity distributions, arrival rate dynamics and predictability, and workload stationarity and burstiness. Complemented with queueing-theoretic techniques, we further extend our understanding on the measurement data with a virtual design on the workload and capacity management components of a data center assuming the same workload as measured, which reveals key results regarding the impact of workload arrival distribution, Service Level Agreements (SLAs), and workload scheduling schemes on the design and operations of such large-scale video distribution systems. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Zhang, Hui; Jiang, Guofei; Chen, Haifeng; Yoshihira, Kenji] NEC Labs Amer, Princeton, NJ 08540 USA.
   [Kang, Xiaozhu] Columbia Univ, New York, NY 10027 USA.
   [Meng, Xiaoqiao] IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA.
C3 NEC Corporation; Columbia University; International Business Machines
   (IBM)
RP Zhang, H (corresponding author), NEC Labs Amer, Princeton Campus,4 Independence Way,Suite200, Princeton, NJ 08540 USA.
EM xk2001@columbia.edu; huizhang@nec-labs.com; gfj@nec-labs.com;
   haifeng@nec-labs.com; xmeng@u-s.ibm.com; kenji@nec-labs.com
RI chen, haifeng/GSM-9693-2022
CR Abendroth D., 2002, P INFOCOM 2002
   ABUNDO M, 2007, YOUTUBE TRACKS OUTAG
   ALMEIDA JM, 2001, NOSSDAV 01, P21
   [Anonymous], 2007, COMSCORE VIDEO METRI
   Bobroff N, 2007, 2007 10TH IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2009), VOLS 1 AND 2, P119, DOI 10.1109/INM.2007.374776
   CHA M, 2007, ACM P INT MEAS C SAN
   CHENG X, 2007, 707 ARXIV
   Cherkasova L., 2002, MULTIMEDIA 02, P299
   GILL P, 2007, ACM P INT MEAS C SAN
   GUO L, 2005, WWW 2005, P519
   Harchol-Balter M, 2003, ACM T COMPUT SYST, V21, P207, DOI 10.1145/762483.762486
   Harchol-Balter M, 1999, J PARALLEL DISTR COM, V59, P204, DOI 10.1006/jpdc.1999.1577
   HUANG C, 2007, SIGCOMM 07, P133
   KAWAMOTO D, 2007, ZDNET NEWS       MAR
   O'Reilly T., 2006, What Is Web 2.0: Design patterns and business models for the next generation of software
   PAXSON V, 1994, SIGCOMM COMPUT COMMU, V24, P257
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TANG W, 2007, INT J COMPUTER T JAN, P336
   Whitt W, 1999, MANAGE SCI, V45, P1579, DOI 10.1287/mnsc.45.11.1579
   Whitt W., 1993, Production and Operations Management, V2, P114, DOI 10.1111/j.1937-5956.1993.tb00094.x
   Wolff RW, 1989, Stochastic Modeling and the Theory of Queues
   *YAH, VID
   YU H, 2006, P 2006 EUROSYS C LEU
   Zhang Q, 2005, IEEE T PARALL DISTR, V16, P219, DOI 10.1109/TPDS.2005.38
NR 24
TC 8
Z9 9
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 129
EP 138
DI 10.1016/j.jvcir.2009.06.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800007
DA 2024-07-18
ER

PT J
AU Camarena, JG
   Gregori, V
   Morillas, S
   Sapena, A
AF Camarena, Joan-Gerard
   Gregori, Valentin
   Morillas, Samuel
   Sapena, Almanzor
TI Fast detection and removal of impulsive noise using peer groups and
   fuzzy metrics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE color image filter; fuzzy metric; non-linear vector filter; peer group;
   vector median filter
ID VECTOR FILTER; COLOR; REDUCTION; SUPPRESSION; ALGORITHM
AB A novel approach to impulsive noise detection in color images is introduced. In the paper, the peer group concept is redefined by means of a certain fuzzy metric. This concept is employed for the fast detection of noisy pixels by taking advantage of the fuzzy metric properties. On the basis of the noisy pixel detection a switching filter between the arithmetic mean filter (AMF) and the identity operation is proposed. The proposed switching filter achieves a trade-off between noise suppression and signal-detail preservation and is faster than recently introduced switching filters based on the peer group concept. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Camarena, Joan-Gerard; Gregori, Valentin; Morillas, Samuel; Sapena, Almanzor] Univ Politecn Valencia, EPS Gandia, Valencia 46730, Spain.
C3 Universitat Politecnica de Valencia
RP Morillas, S (corresponding author), Univ Politecn Valencia, EPS Gandia, Valencia 46730, Spain.
EM smorillas@ieee.org
RI Morillas, Samuel/H-2610-2015; Sapena, Almanzor/H-5102-2015; Gregori,
   Valentin/B-8233-2014
OI Morillas, Samuel/0000-0001-9262-6139; Sapena,
   Almanzor/0000-0001-8473-6063; Gregori, Valentin/0000-0002-5983-6182
CR Allende H, 2004, PATTERN RECOGN LETT, V25, P841, DOI 10.1016/j.patrec.2004.01.009
   [Anonymous], 1981, ORDER STAT
   Arakawa K, 1996, FUZZY SET SYST, V77, P3, DOI 10.1016/0165-0114(95)00122-0
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Camacho J, 2006, J IMAGING SCI TECHN, V50, P427, DOI [10.2352/J.ImagingSci.Technol.(2006)50:5(427), 10.2352/J.lmagingSci.Technol.(2006)50:5(427)]
   Chatzis V, 1999, IEEE T IMAGE PROCESS, V8, P731, DOI 10.1109/83.760339
   Deng Y., 1999, P IEEE INT S CIRC SY, V4, P21, DOI DOI 10.1109/ISCAS.1999.779933
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   GEORGE A, 1994, FUZZY SET SYST, V64, P395, DOI 10.1016/0165-0114(94)90162-7
   George A., 1995, J. Fuzzy Math., V3, P933
   Gregori V, 2004, FUZZY SET SYST, V144, P411, DOI 10.1016/S0165-0114(03)00161-1
   Huber P., 1981, Robust Statistics
   Karakos DG, 1997, IEEE T IMAGE PROCESS, V6, P1038, DOI 10.1109/83.597278
   Kenney C, 2001, IEEE T IMAGE PROCESS, V10, P326, DOI 10.1109/83.902298
   Khriji L, 2002, FUZZY SET SYST, V128, P35, DOI 10.1016/S0165-0114(01)00181-6
   Lucat L, 2002, SIGNAL PROCESS-IMAGE, V17, P509, DOI 10.1016/S0923-5965(02)00023-1
   Lucchese L, 2004, IEEE T IMAGE PROCESS, V13, P534, DOI 10.1109/TIP.2003.822609
   Lukac R, 2005, INT J IMAG SYST TECH, V15, P236, DOI 10.1002/ima.20058
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2005, J INTELL ROBOT SYST, V42, P361, DOI 10.1007/s10846-005-1730-2
   Lukac R, 2004, EURASIP J APPL SIG P, V2004, P1870, DOI 10.1155/S1110865704312126
   Lukac R, 2004, IEEE T NANOBIOSCI, V3, P272, DOI 10.1109/TNB.2004.837907
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2004, MULTIDIM SYST SIGN P, V15, P169, DOI 10.1023/B:MULT.0000017024.66297.a0
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   LUKAC R, 2005, SPECIAL ISSUE FUZZY, V152, P17
   Lukac R, 2006, J VIS COMMUN IMAGE R, V17, P1, DOI 10.1016/j.jvcir.2005.08.007
   Ma ZH, 2005, IEEE T IMAGE PROCESS, V14, P1990, DOI 10.1109/TIP.2005.857269
   Ma ZH, 2005, REAL-TIME IMAGING, V11, P403, DOI 10.1016/j.rti.2005.07.002
   Morillas S, 2005, REAL-TIME IMAGING, V11, P417, DOI 10.1016/j.rti.2005.06.007
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Sapena A., 2001, APPL GEN TOPOL, V2, P63, DOI DOI 10.4995/AGT.2001.3016
   Smolka B, 2005, REAL-TIME IMAGING, V11, P389, DOI 10.1016/j.rti.2005.07.003
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Smolka B, 2004, MATH PROBL ENG, P77, DOI 10.1155/S1024123X04110016
   Smolka B, 2002, PATTERN RECOGN, V35, P1771, DOI 10.1016/S0031-3203(01)00169-8
   SMOLKA B, 2003, INT C IM PROC ICIP
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Tsai HH, 2000, FUZZY SET SYST, V114, P203, DOI 10.1016/S0165-0114(99)00094-9
NR 40
TC 65
Z9 67
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2008
VL 19
IS 1
BP 20
EP 29
DI 10.1016/j.jvcir.2007.04.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 257SY
UT WOS:000252820000003
DA 2024-07-18
ER

PT J
AU Ye, QX
   Hao, JB
   Huang, J
   Yu, H
AF Ye, Qixiang
   Hao, Jianbin
   Huang, Jun
   Yu, Hua
TI Text detection and restoration in natural scene images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE text detection; text recognition; text restoration
ID SEGMENTATION; EXTRACTION
AB A new method for text detection and recognition in natural scene images is presented in this paper. In the detection process, color, texture. and OCR statistic features are combined in a coarse-to-fine framework to discriminate texts from non-text patterns. In this approach, color feature is used to group text pixels into candidate text lines. Texture feature is used to capture the "dense intensity variance" property of text pattern. Statistic features from OCR (Optical Character Reader) results are employed to further reduce detection false alarms empirically. After the detection process, a restoration process is used. This process is based on plane-to-plane homography. It is carried out to refine the background plane of text when an affine transformation is detected on a located text and independent of camera parameters. Experimental results tested from a large dataset have demonstrated that the proposed method is effective and practical. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Ye, Qixiang; Hao, Jianbin; Huang, Jun; Yu, Hua] Grad Univ Chinese Acad Sci, Coll Engn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Ye, QX (corresponding author), Grad Univ Chinese Acad Sci, Coll Engn, No 19 Yu Quan Rd,Shi Jing Distr, Beijing, Peoples R China.
EM qxye@gucas.ac.cn
CR Baba Y, 2004, IEEE IMAGE PROC, P211
   Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   Chen XR, 2004, PROC CVPR IEEE, P366
   CLARK P, 2004, PATTERN RECOGNITION
   Ezaki N, 2004, INT C PATT RECOG, P683, DOI 10.1109/ICPR.2004.1334351
   GAO J, 2001, INT C COMP VIS PATT
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   Karatzas D, 2004, INT C PATT RECOG, P634, DOI 10.1109/ICPR.2004.1334328
   Kim KC, 2004, INT C PATT RECOG, P679, DOI 10.1109/ICPR.2004.1334350
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mundy J., 1992, GEOMETRIC INVARIANCE
   SUNG KK, 1994, AI MEMO, V1521
   Vapnik V., 1999, NATURE STAT LEARNING
   Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116
   YANG XLC, 2002, APPL COMPUTER VISION, P32
   Ye QX, 2004, IEEE IMAGE PROC, P2905
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   ZHANG J, 2002, INT C MULT INT, P204
NR 22
TC 43
Z9 49
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2007
VL 18
IS 6
BP 504
EP 513
DI 10.1016/j.jvcir.2007.07.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 243NA
UT WOS:000251803400005
DA 2024-07-18
ER

PT J
AU Chen, Q
   Luo, J
   Heng, PA
   Xia, DS
AF Chen, Qiang
   Luo, Jian
   Heng, Pheng Ann
   Xia, De-shen
TI Fast and active texture segmentation based on orientation and local
   variance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE texture segmentation; orientation and local variance; separability;
   nonlinear diffusions level set; active image segmentation
ID IMAGE SEGMENTATION; CLASSIFICATION; FRAMEWORK; CONTOURS; REGIONS
AB This paper describes a fast and active texture segmentation approach based on the orientation and the local variance. First, a set of feature images are extracted using the orientation and the local variance. To reduce the computational complexity, a separability measurement method, which is used for selecting four feature images with good separability in four orientations, is proposed in this paper. To improve the segmentation, we adopt a nonlinear diffusion filtering to smooth the four feature images. Finally, a variational framework incorporating these features in a level set based, unsupervised segmentation process is adopted. To improve the computational speed, instead of solving the Euler-Lagrange equation, we calculate the energy, with level set representation, to solve the variational framework. Segmentation results of various synthetic and real textured images has demonstrated that our method has good performance and efficiency. (C) 2006 Elsevier Inc. All rights reserved.
C1 Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing, Peoples R China.
   Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   Chinese Univ Hong Kong, Shun Hing Inst Adv Engn, Shatin, Hong Kong, Peoples R China.
C3 Nanjing University of Science & Technology; Chinese University of Hong
   Kong; Chinese University of Hong Kong
RP Chen, Q (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing, Peoples R China.
EM chen2qiang@163.com
RI chen, qiang/HGU-5418-2022; chen, qiang/GWZ-7308-2022
OI Heng, Pheng Ann/0000-0003-3055-5034
CR Andreu F., 2001, DIFFERENTIAL INTEGRA, V14, P321
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P3197, DOI 10.1016/j.patrec.2003.08.005
   Bajcsy R., 1973, P 3 INT JOINT C ART
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Brodatz P., 1966, PHOTOGRAPHIC ALBUM A
   BROX T, 2004, P 8 EUR C COMP VIS B
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   CHEN PC, 1983, IEEE T PATTERN ANAL, V5, P64, DOI 10.1109/TPAMI.1983.4767346
   CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Deng HW, 2004, PATTERN RECOGN, V37, P2323, DOI [10.1016/S0031-3203(04)00195-5, 10.1016/j.patcog.2004.04.015]
   DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X
   DORETTO G, 2003, 9 IEEE INT C COMP VI
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   ELFADEL IM, 1994, IEEE T PATTERN ANAL, V16, P24, DOI 10.1109/34.273719
   Fischer B, 2003, IEEE T PATTERN ANAL, V25, P513, DOI 10.1109/TPAMI.2003.1190577
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   GREENSPAN H, 1994, IEEE T PATTERN ANAL, V16, P894, DOI 10.1109/34.310685
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   KAPLAN LM, 1995, J VIS COMMUN IMAGE R, V6, P387, DOI 10.1006/jvci.1995.1032
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Li F, 2004, PATTERN RECOGN LETT, V25, P129, DOI 10.1016/j.patrec.2003.09.006
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   NG I, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P627, DOI 10.1109/ICPR.1992.202065
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   PARAGIOS N, 1999, P IEEE C CVPR, P1034
   PAVLIDIS T, 1979, COMPUTER GRAPHICS IM, V10, P172
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PIETIKAINEN M, 1981, IEEE T SYST MAN CYB, V11, P822
   Raghu PP, 1996, IEEE T IMAGE PROCESS, V5, P1625, DOI 10.1109/83.544570
   ROUSSON M, 2003, P IEEE COMP SOC C CO
   Rousson M., 2002, P IEEE WORKSH MOT VI
   SAGIV C, 2002, P TEXT 2002 2 INT WO
   SCHACHTER BJ, 1979, PATTERN RECOGN, V11, P19, DOI 10.1016/0031-3203(79)90025-6
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   SONG B, 2002, UCLA CAM REP, V2
   THERRIEN CW, 1983, COMPUT VISION GRAPH, V22, P313, DOI 10.1016/0734-189X(83)90079-8
   Tsai DM, 2001, IMAGE VISION COMPUT, V19, P299, DOI 10.1016/S0262-8856(00)00078-0
   UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Wu Gao-Hong, 2001, Acta Electronica Sinica, V29, P48
   Yang XY, 2001, PATTERN RECOGN LETT, V22, P1073, DOI 10.1016/S0167-8655(01)00057-5
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
   [No title captured]
NR 51
TC 7
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 119
EP 129
DI 10.1016/j.jvcir.2006.11.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700003
DA 2024-07-18
ER

PT J
AU Yin, PY
   Li, SH
AF Yin, Peng-Yeng
   Li, Shin-Huei
TI Content-based image retrieval using association rule mining with soft
   relevance feedback
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE association rules; confidence quantization; content-based image
   retrieval; redundancy detection; soft relevance feedback
AB With the rapid development of internet technology, the transmission and access of image items have become easier and the volume of image repository is exploding. An efficient and effective query reformulation is needed for finding the relevant images from the database. Relevance feedback (RF) is an interactive process which refines the retrieval results to a particular query by utilizing the user's feedback on previously retrieved images. Most of the existing approaches deal with hard feedback (relevant and nonrelevant) and focus on individual experience only. We propose to facilitate the use of soft feedback (involving excellent, fair, don't care, and bad) to better capture user's intention. To add this feature, all of the traditional RF techniques should be modified accordingly. Further, the meta-knowledge exploited from multiple users' experiences can improve the performance of future retrieval results. We propose a soft association rule mining algorithm to infer image relevance from the collective feedback. The number of association rules is kept minimum based on confidence quantization and redundancy detection. Also, binary search and best-first search techniques are implemented to expedite the process of relevance inference from the association rules. The proposed model provides a more flexible interface for relevance feedback and the experimental results manifest that the retrieval performance of the proposed model is better than that of traditional methods. (c) 2006 Elsevier Inc. All rights reserved.
C1 Natl Chi Nan Univ, Dept Informat Management, Puli 545, Nantou, Taiwan.
C3 National Chi Nan University
RP Yin, PY (corresponding author), Natl Chi Nan Univ, Dept Informat Management, 303 Univ Rd, Puli 545, Nantou, Taiwan.
EM pyyin@ncnu.edu.tw
RI cai, bo/G-1491-2010
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Bhanu B, 2002, ENG APPL ARTIF INTEL, V15, P123, DOI 10.1016/S0952-1976(02)00026-X
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   Han J., 2012, Data Mining, P393, DOI [DOI 10.1016/B978-0-12-381479-1.00009-5, 10.1016/B978-0-12-381479-1.00009-5]
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Hoi C.-H., 2004, PROC 12 ANN ACM INT, P24
   Huang TS, 2002, 2ND INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING, PROCEEDINGS, P155, DOI 10.1109/DEVLRN.2002.1011829
   Ide E., 1971, SMART RETRIEVAL SYST, P373
   Jiang W, 2004, IEEE IMAGE PROC, P2215
   LEE JCM, 1997, SPECIAL ISSUE IMAGE
   Li MJ, 2002, PATTERN RECOGN, V35, P2687, DOI 10.1016/S0031-3203(01)00249-7
   Meilhac C, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P512, DOI 10.1109/MMCS.1999.779254
   Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Yin PY, 2005, IEEE T PATTERN ANAL, V27, P1536, DOI 10.1109/TPAMI.2005.201
   Yin PY, 2002, INT C PATT RECOG, P533, DOI 10.1109/ICPR.2002.1047994
NR 23
TC 18
Z9 22
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1108
EP 1125
DI 10.1016/j.jvcir.2006.04.004
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700011
DA 2024-07-18
ER

PT J
AU Lukac, R
   Smolka, B
   Plataniotis, KN
   Venetsanopoulos, AN
AF Lukac, Rastislav
   Smolka, Bogdan
   Plataniotis, Konstantinos N.
   Venetsanopoulos, Anastasios N.
TI Vector sigma filters for noise detection and removal in color images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE multichannel image processing; nonlinear vector filtering;
   order-statistic theory; adaptive filter design
ID IMPULSIVE NOISE; REDUCTION; ALGORITHM
AB This paper presents a new adaptive filtering approach capable of detecting and removing impulsive noise in multichannel images. The proposed methodology constitutes a powerful unified framework for multichannel signal processing. Robust order-statistic concepts and statistical measure of vectors' deviation are used in conjunction with different distance measures among multichannel inputs to determine an efficient switching rule between filter output and no filtering (identity operation). The special case of color image filtering is studied as an important example of multichannel signal processing. Simulation studies reported in this paper indicate that the proposed filter class is computationally attractive, has excellent performance, and is able to preserve fine details while suppressing impulsive noise. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, Multimedia Lab, Toronto, ON M5S 3G4, Canada.
   Silesian Tech Univ, Dept Automat Control, PL-44101 Gliwice, Poland.
C3 University of Toronto; Silesian University of Technology
RP Lukac, R (corresponding author), Univ Toronto, Edward S Rogers Sr Dept Elect & Comp Engn, Multimedia Lab, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.
EM lukacr@dsp.utoronto.ca
RI Smolka, Bogdan/AFK-4617-2022
OI Smolka, Bogdan/0000-0003-1883-3580
CR Anderson T.W, 1984, An Introduction to Multivariate Statistical Analysis
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   Bami M, 1994, IEEE SIGNAL PROC LET, V1, P92, DOI 10.1109/97.295343
   BARDOS AJ, 1997, P 6 INT C IM PROC IT, V2, P708
   Barner KE, 1997, IEEE T CIRCUITS-II, V44, P531, DOI 10.1109/82.598425
   Barni M, 2000, IEEE MULTIMEDIA, V7, P34, DOI 10.1109/93.848424
   Beghdadi A, 1997, IEEE T IMAGE PROCESS, V6, P879, DOI 10.1109/83.585237
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   GABBOUJ M, 1996, P EUSIPCO 96, P879
   Garber NicholasJ., 1999, TRAFFIC HIGHWAY ENG
   Hashimoto Y, 2002, ELECTRON COMM JPN 3, V85, P22, DOI 10.1002/ecjc.1076
   Hashimoto Y, 2002, ELECTRON COMM JPN 3, V85, P74, DOI 10.1002/ecjc.1073
   Karakos DG, 1997, IEEE T IMAGE PROCESS, V6, P1038, DOI 10.1109/83.597278
   Kokaram A., 1998, Motion Picture Restoration
   LEE JS, 1983, COMPUT VISION GRAPH, V24, P255, DOI 10.1016/0734-189X(83)90047-6
   Li XY, 2000, IEEE MULTIMEDIA, V7, P38, DOI 10.1109/93.848425
   Lucat L, 2002, SIGNAL PROCESS-IMAGE, V17, P509, DOI 10.1016/S0923-5965(02)00023-1
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2005, J INTELL ROBOT SYST, V42, P361, DOI 10.1007/s10846-005-1730-2
   Lukac R, 2005, FUZZY SET SYST, V152, P17, DOI 10.1016/j.fss.2004.10.012
   Lukac R, 2004, EURASIP J APPL SIG P, V2004, P1870, DOI 10.1155/S1110865704312126
   Lukac R, 2004, IEEE T NANOBIOSCI, V3, P272, DOI 10.1109/TNB.2004.837907
   Lukac R, 2004, COMPUT VIS IMAGE UND, V94, P140, DOI 10.1016/j.cviu.2003.10.013
   Lukac R, 2004, MULTIDIM SYST SIGN P, V15, P169, DOI 10.1023/B:MULT.0000017024.66297.a0
   Lukac R, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P745
   Lukac R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P537
   Lukac R., 2002, Pattern Recognition and Image Analysis, V12, P279
   Lukac R, 2003, PATTERN RECOGN LETT, V24, P1889, DOI 10.1016/S0167-8655(03)00016-3
   LUKAC R, 2002, P IWSSIP 02 MANCH UK, P559
   Mardia K. V., 1979, MULTIVARIATE ANAL, P457
   Mitra SanjitK., 2001, Nonlinear Image Processing
   Mustonen S, 1997, COMPUT STAT DATA AN, V23, P321, DOI 10.1016/S0167-9473(96)00042-4
   Peltonen S, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P102, DOI 10.1109/ISPA.2001.938611
   PITAS I, 1992, P IEEE, V80, P1893, DOI 10.1109/5.192071
   Pitas I., 1990, NONLINEAR DIGITAL FI
   Pitas I, 1991, IEEE T CIRC SYST VID, V1, P247, DOI 10.1109/76.97987
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Plataniotis KN, 1998, IEEE T CIRCUITS-II, V45, P1414, DOI 10.1109/82.728854
   Plataniotis KN, 1999, P IEEE, V87, P1601, DOI 10.1109/5.784243
   RANTANEN H, 1992, IEEE T CONSUM ELECTR, V38, P157, DOI 10.1109/30.156677
   Seber G A., 2009, Multivariate observations, DOI DOI 10.1002/9780470316641
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   Smolka B, 2002, PATTERN RECOGN, V35, P1771, DOI 10.1016/S0031-3203(01)00169-8
   Smolka B, 2001, OPT ENG, V40, P902, DOI 10.1117/1.1367347
   SMOLKA B, 2002, P DSP2002 SANT GREEC, V2, P939
   Szczepanski M, 2003, SIGNAL PROCESS, V83, P1309, DOI 10.1016/S0165-1684(03)00058-6
   TANG KJ, 1995, IEEE T IMAGE PROCESS, V4, P788, DOI 10.1109/83.388080
   Tenze L, 2002, IEEE SIGNAL PROC LET, V9, P309, DOI 10.1109/LSP.2002.803410
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
   VIERO T, 1994, IEEE T CIRC SYST VID, V4, P129, DOI 10.1109/76.285620
   Wilks SS, 1932, BIOMETRIKA, V24, P471
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   ZHENG J, 1993, J INTELL ROBOT SYST, V7, P257, DOI 10.1007/BF01257768
NR 56
TC 82
Z9 91
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 1
EP 26
DI 10.1016/j.jvcir.2005.08.007
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900001
DA 2024-07-18
ER

PT J
AU Huang, YR
   Kuo, CM
   Huang, FC
AF Huang, Yong-Ren
   Kuo, Chung-Ming
   Huang, Feng-Chung
TI Block-based motion field segmentation for video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE motion compensation; block-based; moving objects; motion field; MAP
ID GIBBS RANDOM-FIELDS; IMAGE; NOISY; MPEG
AB In the past few years, motion compensation has been widely used in the coding of image sequences. Most of motion estimation and compensation schemes belong to block-based framework. The framework simplifies the complexity of motion estimation, but gives over constraints to the motion field, which results in worse accuracy on the boundary of moving objects. This paper presents a novel technique for raising motion field accuracy. It uses several pre-defined pattern types to segment the motion fields of the previous frame of a sequence. The segmentation is based on the MAP framework that uses iterative method to obtain the solution. In addition, we develop a predictive scheme to predict the location of motion field discontinuities in the current frame, which further reduces the side information for the representation of segmentation. (c) 2005 Elsevier Inc. All rights reserved.
C1 I Shou Univ Tahsu, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Kuo, CM (corresponding author), I Shou Univ Tahsu, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
CR Chiariglione L, 1997, IEEE T CIRC SYST VID, V7, P5, DOI 10.1109/76.554414
   DERIN H, 1986, COMPUT VISION GRAPH, V35, P72, DOI 10.1016/0734-189X(86)90126-X
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   GERMAN S, 1984, IEEE T PATTERN ANAL, V6, P721
   HOTTER M, 1988, SIGNAL PROCESS, V15, P315, DOI 10.1016/0165-1684(88)90021-7
   *ISO IEC JTC SC29, 2001, MPEG4 VID VER MOD VE
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Koenen R, 1997, SIGNAL PROCESS-IMAGE, V9, P295, DOI 10.1016/S0923-5965(97)00003-9
   KONARD J, 1993, IEEE T PATTERN ANAL, V14, P910
   KUO CM, 2000, IEEE COMPSAC 2000, P395
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   MICHALE M, 1997, IEEE T IMAGE PROCESS, V6, P1326
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   NETRAVALI AN, 1979, AT&T TECH J, V58, P631, DOI 10.1002/j.1538-7305.1979.tb02238.x
   Orchard MT, 1993, IEEE T CIRC SYST VID, V3, P54, DOI 10.1109/76.180690
   Won CS, 1998, IEEE T CIRC SYST VID, V8, P592, DOI 10.1109/76.718506
   WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C
NR 17
TC 2
Z9 3
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2005
VL 16
IS 6
BP 668
EP 687
DI 10.1016/j.jvcir.2005.03.004
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JQ
UT WOS:000242026600003
DA 2024-07-18
ER

PT J
AU Belloulata, K
AF Belloulata, K
TI Fast fractal coding of subbands using a non-iterative block clustering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE fractal coding; hybrid image coding; hybrid subband/fractal coding;
   clustering
ID IMAGE COMPRESSION; VECTOR QUANTIZATION
AB We propose a new image coding scheme which uses a fast non-iterative algorithm for block clustering in fractal coding of wavelet transform coefficients. The original image is first decomposed into subbands containing information in different spatial directions and different scales, using an orthogonal wavelet filter bank. Subbands are encoded using local iterated function systems (LIFS) with range and domain blocks presenting horizontal or vertical directionalities. Their sizes are adapted to the correlation lengths and the resolution of each subband. This hybrid compression scheme allows to use the natural classification obtained by using a subband decomposition and reduce the computational complexity by a 12:1 factor. In order to increase this speedup, we propose a fast non-iterative algorithm for block clustering which classifies the directional domain and range blocks and leads to an accelerated LIFS generation in each subband. The proposed approach reduces the computational complexity of the basic fractal compression algorithm by a 50:1 factor and gives better PSNR/bit rate results, especially for images presenting directionalities. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Sherbrooke, Dept Genie Elect & Genie Informat, Sherbrooke, PQ J1K 2R1, Canada.
C3 University of Sherbrooke
RP Univ Sherbrooke, Dept Genie Elect & Genie Informat, Sherbrooke, PQ J1K 2R1, Canada.
EM kamel.belloulata@usherbrooke.ca
RI , Belloulata/V-9150-2019
OI , Belloulata/0000-0002-6044-4389
CR AKROUT N, 1994, IMAGE VISION COMPUT, V12, P627, DOI 10.1016/0262-8856(94)90038-8
   AKROUT N, 1992, P EUR SIGN PROC C EU, V3, P1227
   [Anonymous], 1995, SELF ORG MAPS
   Barnsley M.F., 1993, Fractal Image Compression
   Belloulata K, 1998, SIGNAL PROCESS-IMAGE, V12, P243, DOI 10.1016/S0923-5965(97)00040-4
   Belloulata K, 1996, P SOC PHOTO-OPT INS, V2707, P598, DOI 10.1117/12.238491
   BELLOULATA K, 1997, P IEEE INT C AC SPEE, V4, P3121
   BELLOULATA K, 1996, P EUR SIGN PROC C EU, V2, P1167
   Davis GM, 1998, IEEE T IMAGE PROCESS, V7, P141, DOI 10.1109/83.660992
   Davoine F, 1996, IEEE T IMAGE PROCESS, V5, P338, DOI 10.1109/83.480769
   DUBRIDGE F, 1994, FRACTAL IMAGE COMPRE
   EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395
   FISCHER TR, 1986, IEEE T INFORM THEORY, V32, P568, DOI 10.1109/TIT.1986.1057198
   Fisher Y., 1994, Fractal Image Compression
   Gersho A., 2003, Vector Quantization and Signal Compression
   Hamzaoui R, 2001, J VIS COMMUN IMAGE R, V12, P450, DOI 10.1006/jvci.2001.0492
   Hamzaoui R, 2000, IEEE T IMAGE PROCESS, V9, P197, DOI 10.1109/83.821730
   JACQUIN AE, 1993, P IEEE, V81, P1451, DOI 10.1109/5.241507
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   KURPNIK H, 1995, IEEE 18 CONV EE ISR
   Lee CK, 1998, IEEE T IMAGE PROCESS, V7, P888, DOI 10.1109/83.679437
   LEPSOY S, 1994, FRACTAL IMAGE COMPRE
   Oien G.E., 1994, FRACTAL IMAGE COMPRE
   Ramchandran K, 1993, IEEE T IMAGE PROCESS, V2, P160, DOI 10.1109/83.217221
   Ribés JMM, 2001, SIGNAL PROCESS-IMAGE, V16, P643, DOI 10.1016/S0923-5965(00)00041-2
   RINALDO R, 1995, IEEE T IMAGE PROCESS, V4, P909, DOI 10.1109/83.392333
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SIMON B, 1995, P IEEE ICIP 95 23 26, V1, P278
   Ten Daubechies I., 1992, lecture on wavelets
   Wein CJ, 1996, IEEE T IMAGE PROCESS, V5, P522, DOI 10.1109/83.491325
   Wohlberg B, 1999, IEEE T IMAGE PROCESS, V8, P1716, DOI 10.1109/83.806618
   Zhang Y, 1999, SIGNAL PROCESS-IMAGE, V14, P195, DOI 10.1016/S0923-5965(98)00008-3
NR 32
TC 13
Z9 15
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2005
VL 16
IS 1
BP 55
EP 67
DI 10.1016/j.jvcir.2004.02.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 885SN
UT WOS:000226177300004
DA 2024-07-18
ER

PT J
AU Amir, A
   Ashour, G
   Srinivasan, S
AF Amir, A
   Ashour, G
   Srinivasan, S
TI Automatic generation of conference video proceedings
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video proceedings; video on demand; video indexing; information
   retrieval; remote education; distance learning; video segmentation;
   multimedia browsing
AB How many times did you miss a conference talk in a parallel track and wish you had a second chance to see it? Or you just wanted to see a few talks from a recent conference you did not attend? Video proceedings, which contain videos of all the conference talks, would be of great value in these cases. With recent progress in digital video, streaming technology, large storage, Internet and especially video indexing and retrieval technology, video proceedings finally become a reality. The key challenges are efficient production with minimal labor and easy, intuitive, and rapid user access to talks and thought-for snippet of information. This paper describes an application that allows a nearly automatic, real time creation of video proceedings. All the talks are captured in video, and are automatically indexed by speech recognition and video analysis tools. Free text search in speech and efficient multi-view video browsing are combined with the conference table of contents and speakers biography to make fully searchable and browsable video proceedings. The paper covers the work flow, processing steps, and technical details of the video segmentation, visualization, and user study results. The system was used to produce video proceedings for three local conferences. (C) 2004 Elsevier Inc. All rights reserved.
C1 IBM Corp, Almaden Res Ctr, San Jose, CA 95120 USA.
   IBM Haifa Res Lab, Haifa, Israel.
C3 International Business Machines (IBM); International Business Machines
   (IBM)
RP IBM Corp, Almaden Res Ctr, 650 Harry Rd, San Jose, CA 95120 USA.
EM arnon@almaden.ibm.com; ashour@il.ibm.com; savitha@almaden.ibm.com
OI Amir, Arnon/0009-0000-6814-165X
CR ADAMS B, 2002, IBM RES TREC 2002 VI, P20
   Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Amir A, 1998, IEEE T PATTERN ANAL, V20, P186, DOI 10.1109/34.659936
   Amir A, 2003, EURASIP J APPL SIG P, V2003, P209, DOI 10.1155/S111086570321012X
   AMIR A, 2000, P HAW INT C SYST SCI
   ANER A, 2002, P EUR C COMP VIS DEN
   [Anonymous], P SPEC INT GROUP INF
   [Anonymous], 1995, CMUCS95186
   Armitage LH, 1997, J INFORM SCI, V23, P287, DOI 10.1177/016555159702300403
   BAEZAYATES R, 1999, MODERIN INFORMATION
   BAHL LR, 1995, P ICASSP, P41
   BIANCHI MH, 1998, JOINT DARPA NIST SMA
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   BRUNELLI R, 1996, 961206 IRST
   Byrd RJ, 1999, P 4 INT C APPL NAT L
   CHANS, 1998, P IEEE SPECI ISS MUL, P884
   CHRISTEL MG, 1998, P CHI 98
   DELBIMBO A, 1999, VISUAL INFORMATION R
   DHARANIPRAGADA S, 1997, NIST SPECIAL PUBLICA
   Enser P. G. B., 1993, Journal of Document and Text Management, V1, P25
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   GAROFOLO J, 1999, NIST SPEICAL PUBLICA, V500
   GREENSPAN H, 2000, IEEE WORKSH CONT BAS
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Hauptmann AlexanderG., 1997, Informedia: news-on-demand multimedia information acquisition and retrieval, P215
   HE L, 1998, MSRTR9862
   LEINHART R, 2001, J IMAGE GRAPHICS, V1, P469
   LI FC, 2000, BROWSING DIGITAL VID, P169
   LI Y, 2001, IMAGE DATABASES SEAR
   LIU Q, 2000, ACH CHI
   MALAH D, 1979, IEEE T ACOUST SPEECH, V27, P121, DOI 10.1109/TASSP.1979.1163210
   Maybury M.T., 1997, Intelligent multimedia information retrieval
   MUKHOPADHYAY S, 1997, P ACM MULTIMEDIA 99, P477
   Naphade MR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P536, DOI 10.1109/ICIP.1998.999041
   OMOIGUI N, 1999, TIME COMPRESSION SYS, P136
   OVER P, 2001, 10 TEXT RETR C TREC
   PONCELEON DB, 2001, ACM SIGIR, P404
   RATAKONDA K, 1999, P SPIE, V3653
   Rosenfeld A., 2003, VIDEO MINING
   Rubner Y., 2000, PERCEPTUAL METRICS I
   SINGHAL A, 1998, NIST SPECIAL PUBLICA
   SMEATON AF, 2002, 11 TEXT RETR C TREC
   Srinivasan S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P388, DOI 10.1109/MMCS.1999.779235
   SRINIVASAN S, 2001, LNCS, V2016
   SRINIVASAN S, 2001, IBM CUE VID TOOLKIT
   SRINIVASAN S, 2000, P SIGIR 2000 GREEC I
   SYEDAMAHMOOD T, 2000, P COMP VIS PATT REC
   Verhelst W., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P554, DOI 10.1109/ICASSP.1993.319366
   Wactlar Howard D., 1999, IEEE Computer, V32, P66
   1999, 2 NW DIR SEED CROPP
NR 50
TC 4
Z9 5
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 467
EP 488
DI 10.1016/j.jvcir.2004.04.008
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100011
DA 2024-07-18
ER

PT J
AU Chan, HC
   Wang, Y
AF Chan, HC
   Wang, Y
TI Human factors in color-based image retrieval: an empirical study on size
   estimate accuracies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE color-based image retrieval; human factors; percentage estimate;
   laboratory study; estimate accuracy
ID FEATURES
AB In color histogram based image retrieval, a user query specification forms a histogram to be matched with those of the images in the database. The accuracy of this specification determines the matching latitude and affects directly the effectiveness of the retrieval process. The retrieval process suggests some relevant human factors, such as people's ability to estimate percentages and individual characteristies such as training, experience, and background. A two-part laboratory study was made to understand people's ability to estimate percentages of single-block and multiple-block color. The results can be applied to enhance image retrieval systems. For example, the results provide different ranges of estimates, based on statistical percentiles. Retrieval systems can use these to determine appropriate values for retrieval control parameters. The statistics can be used to help determine likely recall and precision performance. Overall, the study provides deeper understanding of people's estimate of color percentages in images. (C) 2003 Elsevier Inc. All rights reserved.
C1 Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.
EM chanhc@comp.nus.edu.sg
CR Androutsos D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P770, DOI 10.1109/ICIP.1998.723652
   ANG YH, 1992, P 2 SING INT C IM PR, P547
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P 1994 INT C APPL DA
   [Anonymous], 1997, Design and Analysis of Experiments
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Ashley J., 1995, P INT C MANAGEMENT D, P475
   Binaghi E., 1994, International Journal of Pattern Recognition and Artificial Intelligence, V8, P945, DOI 10.1142/S0218001494000486
   Brunelli R, 2001, PATTERN RECOGN, V34, P1625, DOI 10.1016/S0031-3203(00)00054-6
   CARD SK, 1993, PSYCHOL HUMAN COMPUT
   Chang EY, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P101, DOI 10.1109/IVL.2000.853848
   Chen SS, 1996, J VIS COMMUN IMAGE R, V7, P1, DOI 10.1006/jvci.1996.0001
   CHIA YY, 1998, P IEEE INT C MULT CO, P218
   CHUA TS, 1996, ENCY COMPUTER SCI TE, V35
   Cinque L, 2001, IMAGE VISION COMPUT, V19, P979, DOI 10.1016/S0262-8856(01)00060-9
   DELBIMBO A, 1995, P 8 INT C IM AN PROC, P185
   Di Lecce V, 1999, J VIS COMMUN IMAGE R, V10, P351, DOI 10.1006/jvci.1999.0423
   Dooley David., 1995, SOCIAL RES METHODS, V3rd
   Douglas SA, 1999, ACM T GRAPHIC, V18, P96, DOI 10.1145/318009.318011
   Enser P, 2000, J INF SCI, V26, P199, DOI 10.1177/016555150002600401
   Enser P. G. B., 1993, Journal of Document and Text Management, V1, P25
   GONG Y, 1994, P IEEE 10 9 ANN INT, P407
   GUDIVADA V, 1995, ACM T INFORMATION SY, V13
   Guglielmo EJ, 1996, ACM T INFORM SYST, V14, P237, DOI 10.1145/230538.230539
   Hill G, 1997, BRIT TELECOMMUN ENG, V16, P2
   Hirakawa M., 1991, Proceedings. 1991 IEEE Workshop on Visual Languages (Cat. No.91TH0402-8), P192, DOI 10.1109/WVL.1991.238833
   Hirata K., 1992, P 3 INT C EXT DAT TE
   JAIMES A, 2001, IMAGE DATABASES SEAR
   JAIMES A, 2001, IS T SPIE HUMAN VISI
   JORGENSEN B, 2001, J AM SOC INF SCI SEP
   LI CS, 2000, P 2000 AM SIGMOD MAN, P598
   LI R, 2003, P INT C MULT MOD, P402
   Lu GJ, 1996, P SOC PHOTO-OPT INS, V2670, P310, DOI 10.1117/12.234811
   Ma WY, 1996, MULTIMED TOOLS APPL, V2, P35
   Mathias E, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P371, DOI 10.1109/SIBGRA.1998.722775
   McDonald S., 2001, SIGIR Forum, P232
   MEHROTRA R, 1995, P 3 IFIP 2 6 WORK C, P46
   MEHTRE BM, 1995, PATTERN RECOGN LETT, V16, P325, DOI 10.1016/0167-8655(94)00096-L
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Ng V, 1995, P SOC PHOTO-OPT INS, V2606, P202, DOI 10.1117/12.227243
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   NISHIYAMA H, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P30, DOI 10.1145/191666.191685
   PETKOVIC D, 1996, ACM S APPL COMP, P2
   Picard Rosalind W., 1994, Spatial Vision, V8, P221, DOI 10.1163/156856894X00341
   RAO A, 1999, P IEEE INT C TOOLS A, P183
   RAO AR, 1993, CVGIP-GRAPH MODEL IM, V55, P218, DOI 10.1006/cgip.1993.1016
   Rickman R, 1996, P SOC PHOTO-OPT INS, V2670, P2, DOI 10.1117/12.234772
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SAKAMOTO H, 1994, P SOC PHOTO-OPT INS, V2185, P25, DOI 10.1117/12.171785
   SAWHNEY HS, 1994, IEEE IMAGE PROC, P66, DOI 10.1109/ICIP.1994.413532
   SCASSELLATI B, 1994, P SOC PHOTO-OPT INS, V2185, P2, DOI 10.1117/12.171777
   SHIMA N, 1992, P 4 INT S SPAT DAT H, P792
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   Stricker M, 1996, P SOC PHOTO-OPT INS, V2670, P29, DOI 10.1117/12.234802
   STRICKER M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P704, DOI 10.1109/CVPR.1994.323774
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Vellaikal A, 1995, P SOC PHOTO-OPT INS, V2606, P312, DOI 10.1117/12.227254
   Yoo HW, 2002, PATTERN RECOGN, V35, P749, DOI 10.1016/S0031-3203(01)00072-3
NR 60
TC 7
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 113
EP 131
DI 10.1016/j.jvcir.2003.09.001
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800001
DA 2024-07-18
ER

PT J
AU Jung, JH
   Joung, S
   Shin, J
   Paik, J
AF Jung, JH
   Joung, S
   Shin, J
   Paik, J
TI Restoration of differential images for enhancement of compressed video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image restoration; regularization; video compression; motion
   compensation; block discrete cosine transformation; image compression;
   video coding; projections onto convex sets; JPEG; MPEG; H.261; H.263
ID RECONSTRUCTION; PROJECTION; REDUCTION; ARTIFACTS
AB A modified regularization algorithm is proposed to enhance compressed video by restoring predictive-coded pictures. Since most video coding standards adopt a hybrid structure of macroblock-based motion compensation and block discrete cosine transform, the blocking artifacts occurs at both the block boundary and block interior, and the degradation process due to quantization is generated on differential images. Based on this observation, a new degradation model of differential images is presented first. Then the corresponding restoration algorithm directly processes the differential images before reconstructing decoded images. Two constraints, such as directional continuities on the block boundary and on the block interior, have been used for defining convex sets for restoring differential images. The proposed differential domain restoration algorithm is compared with the corresponding reconstructed domain algorithm using the same degradation model and equivalent set of constraints. The proposed algorithm outperforms the reconstructed domain algorithm in both analytic and experimental senses. (C) 2003 Elsevier Inc. All rights reserved.
C1 Chung Ang Univ, Image Proc & Intelligent Syst Lab, Dept Image Engn, Grad Sch Imaging Sci Multimedia & Film,Tongjak Ku, Seoul 156756, South Korea.
C3 Chung Ang University
RP Chung Ang Univ, Image Proc & Intelligent Syst Lab, Dept Image Engn, Grad Sch Imaging Sci Multimedia & Film,Tongjak Ku, 221 Huksuk Dong, Seoul 156756, South Korea.
EM paikj@cau.ac.kr
RI Paik, Joonki/AAN-7017-2020; Paik, Joonki/D-7635-2012
OI Paik, Joonki/0000-0002-8593-7155
CR Chang-Tsun Li, 1999, 1999 IEEE Workshop on Signal Processing Systems. SiPS 99. Design and Implementation (Cat. No.99TH8461), P686, DOI 10.1109/SIPS.1999.822376
   Choi MG, 2001, IEEE T CIRCUITS-II, V48, P376, DOI 10.1109/82.933797
   JEON B, 1995, P SOC PHOTO-OPT INS, V2501, P198, DOI 10.1117/12.206723
   Joung SC, 2000, PROC SPIE, V3974, P396, DOI 10.1117/12.382972
   KANG MG, 1995, IEEE T IMAGE PROCESS, V4, P594, DOI 10.1109/83.382494
   KATSAGGELOS AK, 1989, OPT ENG, V28, P735, DOI 10.1117/12.7977030
   Kim TK, 2000, SIGNAL PROCESS-IMAGE, V15, P869, DOI 10.1016/S0923-5965(99)00033-8
   Kim TK, 1998, J VIS COMMUN IMAGE R, V9, P234, DOI 10.1006/jvci.1998.0386
   KIM TK, 1998, P IEEE INT TECH C CI, P55
   MINAMI S, 1995, IEEE T CIRC SYST VID, V5, P74, DOI 10.1109/76.388056
   MITCHELL JL, 1996, MPEG VIDO COMPRESSIO
   ORourke TP, 1995, IEEE T CIRC SYST VID, V5, P490, DOI 10.1109/76.475891
   REEVE HC, 1984, OPT ENG, V23, P34, DOI 10.1117/12.7973248
   ROSENTHAL M, 1992, NEUROREHABILITATION, V2, P1
   Shi Chang Jung, 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P474, DOI 10.1109/ICIP.1999.817159
   Shin J.H., 1999, P 1999 INT C IM PROC, V3, P676
   STEVENSON RL, 1995, P 38 MIDW S CIRC SYS, P854
   Wang C., 1998, P 1998 INT C CONTR A, P1461
   Yang Y., 1998, SIGNAL RECOVERY TECH, P69
   Yang YY, 1993, IEEE T CIRC SYST VID, V3, P421, DOI 10.1109/76.260198
   YANG YY, 1995, IEEE T IMAGE PROCESS, V4, P896, DOI 10.1109/83.392332
NR 21
TC 3
Z9 3
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2004
VL 15
IS 1
BP 91
EP 109
DI 10.1016/j.jvcir.2003.06.002
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 772PV
UT WOS:000188851200005
DA 2024-07-18
ER

PT J
AU Zheng, YP
   Xu, Y
   Shu, SQ
   Sarem, M
AF Zheng, Yunping
   Xu, Yuan
   Shu, Shiqiang
   Sarem, Mudar
TI Indoor semantic segmentation based on Swin-Transformer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Transformer; RGB-D semantic segmentation
ID IMAGE
AB In recent years, with the rapid development of Transformer in the field of natural language processing, many researchers have realized its potential and gradually applied it to the field of computer vision, with a proliferation of theoretical approaches represented by Vision Transformer (ViT) and Data-efficient image Transformer (DeiT). On the basis of ViT, the famous Swin-Transformer was proposed as one of the best computer vision neural network backbones, which can be widely used in tasks such as image classification, target detection and video recognition. However, in the field of image segmentation, the semantic segmentation of indoor scenes is still very challenging due to the wide variety of objects, large differences in object sizes, and a large number of overlapping objects with occlusion. Aiming at the problem that the existing semantic segmentation of RGB-D indoor scenes cannot effectively fuse multimodal features, in this paper, we propose a novel indoor semantic segmentation algorithm based on Swin-Transformer. It attempts to apply Swin-Transformer to the field of indoor RGBD semantic segmentation, and tests the performance of the model by conducting extensive experiments on the mainstream indoor semantic segmentation datasets NYU-Depth V2 and SUN RGB-D. The experimental results show that the Swin-L RGB+Depth setting achieves 52.44% MIoU on the NYU-Depth V2 data and 51.15% MIoU on the SUN RGB-D data set, which reflects an excellent performance in the field of indoor semantic segmentation. The improved performance of the Depth features on the indoor semantic segmentation model has also been demonstrated in the experiments by controlling the type of input features. Our source code is publicly available at https://github.com/YunpingZheng/ISSSW.
C1 [Zheng, Yunping; Xu, Yuan; Shu, Shiqiang] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Sarem, Mudar] Gen Org Remote Sensing, Damascus, Syria.
C3 South China University of Technology
RP Zheng, YP (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM zhengyp@scut.edu.cn
OI Zheng, Yunping/0000-0001-8639-2479
FU Natural Science Founda-tion of Guangdong Province of China
   [2017A030313349, 2021A1515011517, 2023A1515011288]; National Natural
   Science Foundation of China [61300134]
FX <B>Acknowledgments</B> This work was supported in part by the Natural
   Science Founda-tion of Guangdong Province of China under Grant
   2017A030313349, Grant 2021A1515011517, and Grant 2023A1515011288; in
   part by the National Natural Science Foundation of China under Grant
   61300134.
CR Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Cao JM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7068, DOI 10.1109/ICCV48922.2021.00700
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LZ, 2021, IEEE T IMAGE PROCESS, V30, P2313, DOI 10.1109/TIP.2021.3049332
   Couprie C, 2013, Arxiv, DOI arXiv:1301.3572
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fooladgar F, 2019, Arxiv, DOI arXiv:1912.11691
   Gu R, 2021, IEEE T MED IMAGING, V40, P699, DOI 10.1109/TMI.2020.3035253
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Jiang JD, 2018, Arxiv, DOI arXiv:1806.01054
   Liu W, 2015, Arxiv, DOI [arXiv:1506.04579, 10.48550/arXiv.1506.04579]
   Liu Z, 2022, PROC CVPR IEEE, P11999, DOI 10.1109/CVPR52688.2022.01170
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pang SM, 2021, IEEE T MED IMAGING, V40, P262, DOI 10.1109/TMI.2020.3025087
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YK, 2022, PROC CVPR IEEE, P12176, DOI 10.1109/CVPR52688.2022.01187
   Wang YK, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3902, DOI 10.1145/3394171.3413621
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xiaokang Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P561, DOI 10.1007/978-3-030-58621-8_33
   Xie EZ, 2021, ADV NEUR IN, V34
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang J, 2023, Arxiv, DOI arXiv:2302.11951
   Ying XW, 2022, LECT NOTES COMPUT SC, V13690, P20, DOI 10.1007/978-3-031-20056-4_2
   Yu Q., 2021, arXiv
   Zhang JM, 2023, Arxiv, DOI [arXiv:2203.04838, 10.48550/arXiv.2203.04838]
   Zhang Y., 2022, ARXIV
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao QK, 2023, NEUROCOMPUTING, V548, DOI 10.1016/j.neucom.2023.126389
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
NR 42
TC 1
Z9 1
U1 25
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 103991
DI 10.1016/j.jvcir.2023.103991
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ0Q1
UT WOS:001133409000001
DA 2024-07-18
ER

PT J
AU Veluchamy, S
   Mahesh, KM
   Muthukrishnan, R
   Karthi, S
AF Veluchamy, S.
   Mahesh, K. Michael
   Muthukrishnan, R.
   Karthi, S.
TI HY-LSTM: A new time series deep learning architecture for estimation of
   pedestrian time to cross in advanced driver assistance system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Advanced driver assistance system; Pedestrian time; LSTM; OCNN; Deep
   joint segmentation
AB Advanced driver assistance systems (ADASs), particularly pedestrian protection systems (PPSs), have emerged as a hot research topic with the goal of enhancing traffic safety. The development of reliable on-board pedestrian detection systems is a critical problem for PPSs. It is extremely difficult to provide the required resilience of this type of system due to the fluctuating look of pedestrians (e.g., varied attire, changing size, aspect ratio, and dynamic shape) and the unstructured surroundings. The detection of pedestrians has gained huge focus among researchers because of its huge applications in the domain of automated vehicles. In the previous decades, the majority of examinations are done to obtain better solutions for detecting pedestrians, but fewer of them concentrated on determining the pedestrian. It is one of crucial interest to study regarding transport safety as it implies minimizing the count of traffic collisions and protecting pedestrians who are more susceptible to accidents. Predicting pedestrian conduct is critical for road safety, traffic management systems, ADAS, and autonomous vehicles in general. The fundamental problem in the field of self-driving and smart automobiles is identifying impediments, particularly people, and taking action to avoid collisions with them. Various studies have been conducted in this sector by many researchers, yet there are still many mistakes in the proper identification of pedestrians. Hence, this paper devises an approach to estimate pedestrian time for crossing in an advanced driving assistance system (ADAS). The inputted videos undergo keyframe extraction wherein crucial keyframes are extracted. The deep joint segmentation is further applied for identifying the pedestrian followed by intention classification. Then, the estimation of pedestrian time to cross is predicted using Hybrid-Long short term memory (HY-LSTM), and it is a new time series model obtained by unifying LSTM and Object-based convolution neural network (OCNN), where the layer and hyperparameters of OCNN are optimally derived using Gradient Chef Based Optimization (GCBO). The proposed GCBO-HY-LSTM outperformed showing the least Mean absolute error (MAE) of 0.038, Mean square error (MSE) of 0.029, and Root Mean square error (RMSE) of 0.170.
C1 [Veluchamy, S.] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept CSE, Chennai Campus,337-1A, Vengal Village 601103, Tamil Nadu, India.
   [Mahesh, K. Michael] St Joseph Coll Engn, ECE, Chennai, India.
   [Muthukrishnan, R.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Science, Dept CSE, Chennai, Tamil Nadu, India.
   [Karthi, S.] St Joseph Coll Engn, IT, Chennai, India.
C3 Amrita Vishwa Vidyapeetham; St. Joseph's College of Engineering,
   Chennai; Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science &
   Technology; St. Joseph's College of Engineering, Chennai
RP Veluchamy, S (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept CSE, Chennai Campus,337-1A, Vengal Village 601103, Tamil Nadu, India.
EM veluchamy1834@gmail.com
RI K, Michael Mahesh/AAU-5370-2021; A, Muthukrishnan/IZD-8967-2023
OI K, Michael Mahesh/0000-0002-9948-5743; A,
   Muthukrishnan/0000-0003-3105-3319
CR Aldelfy H.A., 2018, TELKOMNIKA, V16, DOI [10.12928/TELKOMNIKA.v16i2.7692, DOI 10.12928/TELKOMNIKA.V16I2.7692]
   Atlam ES, 2018, MATH METHOD APPL SCI, V41, P5780, DOI 10.1002/mma.4713
   Ayachi R, 2020, NEURAL PROCESS LETT, V52, P2655, DOI 10.1007/s11063-020-10367-9
   Bai XZ, 2018, IEEE T FUZZY SYST, V26, P1946, DOI 10.1109/TFUZZ.2017.2756827
   Ben Khalifa A, 2020, COGN SYST RES, V60, P77, DOI 10.1016/j.cogsys.2019.12.003
   Bouti A, 2020, SOFT COMPUT, V24, P6721, DOI 10.1007/s00500-019-04307-6
   data.nvision2.eecs, The Joint Attention Autonomous Driving (JAAD)dataset
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Gawande U. H., 2020, ELCVIA ELECT LETT CO, V19, P98
   Helali A, 2020, NEURAL COMPUT APPL, V32, P12859, DOI 10.1007/s00521-020-04731-y
   Hosseinzadeh M, 2020, CONTROL APPLICATIONS FOR BIOMEDICAL ENGINEERING SYSTEMS, P89, DOI 10.1016/B978-0-12-817461-6.00004-4
   Ismail A, 2022, NEURAL COMPUT APPL, V34, P21777, DOI 10.1007/s00521-022-07633-3
   Ismail A, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.730
   Ismail A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165413
   Jeong J, 2019, INT J EMBED REAL-TIM, V10, P53, DOI 10.4018/IJERTCS.2019040104
   Kalatian A, 2019, IEEE INT C INTELL TR, P2034, DOI 10.1109/ITSC.2019.8916908
   Kingma D. P., 2014, arXiv
   Lai WC, 2020, INT MICRO PACK ASS, P204
   Li T, 2020, IEEE T VEH TECHNOL, V69, P9330, DOI 10.1109/TVT.2020.2976958
   Mahesh KM, 2020, IET IMAGE PROCESS, V14, P2541, DOI 10.1049/iet-ipr.2018.6682
   Maurya S.K., 2019, 2019 2 INT C ADV COM, P1
   Nataprawira J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072536
   Pop D.O., 2019, Detection of pedestrian actions based on deep learning approach
   Pop DO, 2019, IEEE ACCESS, V7, P149318, DOI 10.1109/ACCESS.2019.2944792
   Ragesh NK, 2019, IEEE ACCESS, V7, P47864, DOI 10.1109/ACCESS.2019.2909992
   Ruder S, 2017, Arxiv, DOI arXiv:1609.04747
   Sarraf S, 2016, Arxiv, DOI arXiv:1603.08631
   Trojovská E, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19313-2
   Tumas P, 2020, IEEE ACCESS, V8, P62775, DOI 10.1109/ACCESS.2020.2982539
   Ullah M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4090107
   Wang H, 2020, IEEE T INTELL TRANSP, V21, P5086, DOI 10.1109/TITS.2019.2948398
   Wang P, 2019, IEEE T IMAGE PROCESS, V28, P6007, DOI 10.1109/TIP.2019.2924171
   Xu ZW, 2019, INFRARED PHYS TECHN, V96, P199, DOI 10.1016/j.infrared.2018.11.007
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 34
TC 0
Z9 0
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103982
DI 10.1016/j.jvcir.2023.103982
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CN9I1
UT WOS:001126041400001
DA 2024-07-18
ER

PT J
AU Meng, XZ
   Feng, YX
   Zhou, F
   Liang, Y
   Su, Z
AF Meng, Xiaozhe
   Feng, Yuxin
   Zhou, Fan
   Liang, Yun
   Su, Zhuo
TI Towards real-world haze removal with uncorrelated graph model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Quality interference; Feature decorrelation; Light
   control
AB The scene restoration effect of the dehazing algorithms usually suffers from double quality interference. First, the dehazing methods based on the atmospheric scattering model (ASM) lead to light loss. Second, the synthetic data used for supervised learning may produce apparent data deviation from the real hazy scene, which seriously weakens the generalization ability of the model. To address the above problems, we propose an uncorrelated graph dehazing model for real-world scenes. The process firstly eliminates the correlation in the representation space by establishing a directed acyclic graph with isolated points, thus enhancing the generalization performance of the model. Secondly, to suppress over-exposure that may occur on real-world data, the proposed model training is performed with a combination of light control. This work improves the ASM and constructs a new dataset applicable to natural haze scenes. Finally, the effectiveness of the proposed method can be verified through multiple experimental comparisons.
C1 [Meng, Xiaozhe; Feng, Yuxin; Zhou, Fan; Su, Zhuo] Sun Yat Sen Univ, Sun Yat Sen Univ Shenzhen, Res Inst, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Liang, Yun] South China Agr Univ, Coll Math & Informat, Guangzhou Key Lab Intelligent Agr, Guangzhou, Peoples R China.
C3 Sun Yat Sen University; South China Agricultural University
RP Su, Z (corresponding author), Sun Yat Sen Univ, Sun Yat Sen Univ Shenzhen, Res Inst, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
EM suzhuo3@mail.sysu.edu.cn
RI Su, Zhuo/AAO-4506-2020; Feng, Yuxin/KVB-0912-2024; Zhou,
   fan/KIL-4066-2024
OI Su, Zhuo/0000-0002-6090-0110; Feng, Yuxin/0009-0001-7793-0957; 
FU Natural Science Foundation of Guangdong Province, China
   [2021A1515012313]; Shenzhen Fundamental Research Program, China
   [JCYJ20200109142612234]; key R&D project of Guangzhou, China
   [202206010091, 2023B03J1363]
FX <B>Acknowledgments</B> This research is supported by the Natural Science
   Foundation of Guangdong Province, China (No. 2021A1515012313) , the
   Shenzhen Fundamental Research Program, China (No. JCYJ20200109142612234)
   , and the key R&D project of Guangzhou, China (No. 202206010091, No.
   2023B03J1363) .
CR Anguita JV, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1501238
   Arjovsky M, 2020, Arxiv, DOI arXiv:1907.02893
   Bai HR, 2022, IEEE T IMAGE PROCESS, V31, P1217, DOI 10.1109/TIP.2022.3140609
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Chen ZY, 2021, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR46437.2021.00710
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gu K, 2019, IEEE T IND ELECTRON, V66, P3176, DOI 10.1109/TIE.2018.2840515
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Guo CL, 2022, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR52688.2022.00572
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hong M, 2022, AAAI CONF ARTIF INTE, P906
   Hongyu Li, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2577, DOI 10.1145/3474085.3475432
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   Kim G, 2022, IEEE T INTELL TRANSP, V23, P2494, DOI 10.1109/TITS.2021.3117868
   Kuang K, 2020, AAAI CONF ARTIF INTE, V34, P4485
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2020, IEEE T IMAGE PROCESS, V29, P8457, DOI 10.1109/TIP.2020.3016134
   Li LRH, 2020, IEEE T IMAGE PROCESS, V29, P2766, DOI 10.1109/TIP.2019.2952690
   Li Y, 2018, AAAI CONF ARTIF INTE, P3579
   Liang Y., 2022, P 31 INT JOINT C ART, P1137, DOI DOI 10.24963/IJCAI.2022/159
   Liu C, 2021, ADV NEURAL INFORM PR, V34
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Mehra A, 2021, IEEE T INTELL TRANSP, V22, P4256, DOI 10.1109/TITS.2020.3013099
   Meng X., 2022, 2022 IEEE INT C MULT, P1
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Rahman ZU, 2004, J ELECTRON IMAGING, V13, P100, DOI 10.1117/1.1636183
   Schölkopf B, 2021, P IEEE, V109, P612, DOI 10.1109/JPROC.2021.3058954
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Spirtes Peter, 2016, Appl Inform (Berl), V3, P3
   Sun YX, 2022, IEEE T CIRC SYST VID, V32, P6029, DOI 10.1109/TCSVT.2022.3155182
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Venkatanath N, 2015, NATL CONF COMMUN
   Vondrick Carl, 2022, CVPR, P7521
   Wang XY, 2016, PR MACH LEARN RES, V48
   Wei YY, 2021, IEEE T IMAGE PROCESS, V30, P4788, DOI 10.1109/TIP.2021.3074804
   Wiles Olivia, 2021, INT C LEARN REPR
   Yang Y, 2022, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR52688.2022.00208
   Yue ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8579, DOI 10.1109/ICCV48922.2021.00848
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang XX, 2021, PROC CVPR IEEE, P5368, DOI 10.1109/CVPR46437.2021.00533
   Zhang Z, 2023, PATTERN RECOGN, V143, DOI 10.1016/j.patcog.2023.109740
   Zheng X., 2018, Advances in neural information processing systems, P31
NR 48
TC 0
Z9 0
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103927
DI 10.1016/j.jvcir.2023.103927
EA AUG 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T3VA9
UT WOS:001077285600001
DA 2024-07-18
ER

PT J
AU Nagarajan, B
   Bolanos, M
   Aguilar, E
   Radeva, P
AF Nagarajan, Bhalaji
   Bolanos, Marc
   Aguilar, Eduardo
   Radeva, Petia
TI Deep ensemble-based hard sample mining for food recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Knowledge representation; Hard-sample mining; Food recognition; Deep
   ensembles; Data augmentation
AB Deep neural networks represent a compelling technique to tackle complex real-world problems, but are over-parameterized and often suffer from over-or under-confident estimates. Deep ensembles have shown better parameter estimations and often provide reliable uncertainty estimates that contribute to the robustness of the results. In this work, we propose a new metric to identify samples that are hard to classify. Our metric is defined as coincidence score for deep ensembles which measures the agreement of its individual models. The main hypothesis we rely on is that deep learning algorithms learn the low-loss samples better compared to large-loss samples. In order to compensate for this, we use controlled over-sampling on the identified "hard" samples using proper data augmentation schemes to enable the models to learn those samples better. We validate the proposed metric using two public food datasets on different backbone architectures and show the improvements compared to the conventional deep neural network training using different performance metrics.
C1 [Nagarajan, Bhalaji; Aguilar, Eduardo; Radeva, Petia] Univ Barcelona, Dept Matemat & Informat, Gran Via Corts Catalanes 585, Barcelona 08007, Spain.
   [Bolanos, Marc] AIGecko Technol SL, Barcelona, Spain.
   [Aguilar, Eduardo] Univ Catolica Norte, Dept Ingn Sistemas & Comp, Ave Angamos 0610, Antofagasta 1270709, Chile.
   [Aguilar, Eduardo; Radeva, Petia] Comp Vis Ctr, Cerdanyola Del Valles, Barcelona, Spain.
C3 University of Barcelona; Universidad Catolica del Norte; Centre de Visio
   per Computador (CVC)
RP Nagarajan, B (corresponding author), Univ Barcelona, Dept Matemat & Informat, Gran Via Corts Catalanes 585, Barcelona 08007, Spain.
EM bhalaji.nagarajan@ub.edu; marc.bolanos@aigecko.com; eaguilar02@ucn.cl;
   petia.ivanova@ub.edu
RI Nagarajan, Bhalaji/IYI-9818-2023
OI Nagarajan, Bhalaji/0000-0003-2473-2057
FU Horizon EU project MUSAE [01070421]; AGAUR [2021-SGR-01094]; Icrea
   Academia'2022 (Generalitat de Catalunya); Robo STEAM (Erasmus+ EU)
   [2022-1-BG01-KA220-VET-000089434]; DeepSense (ACCIO) [ACE053/22/000029];
   DeepFoodVol (AEI-MICINN) [PDC2022-133642-I00]; CERCA
   Programme/Generalitat de Catalunya; AEI-MICINN [PID2022-141566NB-I00];
   Agencia Nacional de Investigacion y Desarrollo de Chile (ANID) [FONDECYT
   INICIACION 11230262]; FPI Becas, MICINN, Spain; NVIDIA Corporation
FX This work was partially funded by the Horizon EU project MUSAE (No.
   01070421), 2021-SGR-01094 (AGAUR), Icrea Academia'2022 (Generalitat de
   Catalunya), Robo STEAM (2022-1-BG01-KA220-VET-000089434, Erasmus+ EU),
   DeepSense (ACE053/22/000029, ACCIO), DeepFoodVol (AEI-MICINN,
   PDC2022-133642-I00), CERCA Programme/Generalitat de Catalunya,
   PID2022-141566NB-I00 (AEI-MICINN), and Agencia Nacional de Investigacion
   y Desarrollo de Chile (ANID) (Grant No. FONDECYT INICIACION 11230262).
   B. Nagarajan acknowledges the support of FPI Becas, MICINN, Spain. We
   acknowledge the support of NVIDIA Corporation with the donation of the
   Titan Xp GPUs.
CR Agarwal C, 2022, PROC CVPR IEEE, P10358, DOI 10.1109/CVPR52688.2022.01012
   Aguilar E, 2021, INT C PATT RECOG, P4017, DOI 10.1109/ICPR48806.2021.9412706
   Aguilar E, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 3: BIOINFORMATICS, P9, DOI 10.5220/0009429400090016
   Aguilar E, 2019, LECT NOTES COMPUT SC, V11679, P182, DOI 10.1007/978-3-030-29891-3_17
   Alain G, 2016, Arxiv, DOI arXiv:1511.06481
   Amugongo LM, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11010059
   Arslan B., 2021, IEEE Trans Artif Intell
   Baldock R. J. N., 2021, ADV NEURAL INF PROCE
   Bansal A, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3502287
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Chao XW, 2023, MULTIMEDIA SYST, V29, P2843, DOI 10.1007/s00530-021-00827-0
   Csiba D, 2018, J MACH LEARN RES, V19
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Deng LX, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P112, DOI 10.1145/3343031.3351147
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   Fabbrizzi S, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103552
   Ganaie MA, 2022, Arxiv, DOI [arXiv:2104.02395, 10.48550/arXiv.2104.02395]
   Hacohen G, 2019, PR MACH LEARN RES, V97
   Hataya R., 2020, COMPUTER VISION ECCV, P1
   He JP, 2022, Arxiv, DOI arXiv:2202.05491
   He JP, 2021, IEEE INT CONF COMP V, P2337, DOI 10.1109/ICCVW54120.2021.00265
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hooker S, 2021, Arxiv, DOI [arXiv:1911.05248, DOI 10.48550/ARXIV.1911.05248]
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Jiang Z., 2021, P MACHINE LEARNING R, P5034
   Johnson TB, 2018, ADV NEUR IN, V31
   Katharopoulos A, 2018, PR MACH LEARN RES, V80
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Khalifa NE, 2022, ARTIF INTELL REV, V55, P2351, DOI 10.1007/s10462-021-10066-4
   Lakshminarayanan B, 2017, ADV NEUR IN, V30
   Liao YH, 2021, PROC CVPR IEEE, P4348, DOI 10.1109/CVPR46437.2021.00433
   Lim S., 2019, Adv. Neural Inf. Process. Syst, P6665
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Meng DY, 2017, INFORM SCIENCES, V414, P319, DOI 10.1016/j.ins.2017.05.043
   Meng L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P557, DOI 10.1145/3343031.3350870
   Min WQ, 2023, IEEE T PATTERN ANAL, V45, P9932, DOI 10.1109/TPAMI.2023.3237871
   Min WQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P393, DOI 10.1145/3394171.3414031
   Min WQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1331, DOI 10.1145/3343031.3350948
   Min WQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329168
   Moon J., 2020, P INT C MACH LEARN, P7034
   Mullick SS, 2019, IEEE I CONF COMP VIS, P1695, DOI 10.1109/ICCV.2019.00178
   Nagarajan B, 2021, RES DEVELOP, P77, DOI 10.1007/978-3-030-72663-8_5
   Rahaman R., 2021, Adv. Neural Inf. Process. Syst., V34
   Reed R., 1999, NEURAL SMITHING SUPE
   Rodenas Javier, 2022, MADiMa '22: Proceedings of the 7th International Workshop on Multimedia Assisted Dietary Management on Multimedia Assisted Dietary Management, P17, DOI 10.1145/3552484.3555754
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sahoo D, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2260, DOI 10.1145/3292500.3330734
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Tahir GA, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9121676
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thames Q, 2021, PROC CVPR IEEE, P8899, DOI 10.1109/CVPR46437.2021.00879
   Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2
   Wang B, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P34, DOI 10.1145/3292500.3330841
   Wang QPA, 2008, J PHYS A-MATH THEOR, V41, DOI 10.1088/1751-8113/41/6/065004
   Wang W, 2022, TRENDS FOOD SCI TECH, V122, P223, DOI 10.1016/j.tifs.2022.02.017
   Wang YN, 2019, CEA'19: PROCEEDINGS OF THE 11TH WORKSHOP ON MULTIMEDIA FOR COOKING AND EATING ACTIVITIES, P1, DOI 10.1145/3326458.3326929
   Zahisham Z., 2020, 2020 IEEE 2 INT C AR, P1
   Zhao H, 2021, IEEE WINT CONF APPL, P1710, DOI 10.1109/WACV48630.2021.00175
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zoph Barret, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P566, DOI 10.1007/978-3-030-58583-9_34
NR 65
TC 1
Z9 1
U1 2
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103905
DI 10.1016/j.jvcir.2023.103905
EA AUG 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R5PM9
UT WOS:001064871200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhu, SW
   Xiang, SJ
AF Zhu, Shiwei
   Xiang, Shijun
TI Multiscale residual gradient attention for face anti-spoofing✩
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face anti-spoofing; Residual gradient convolution; Adjacent depth loss;
   Local depth auxiliary supervision
ID SPOOFING DETECTION; REAL; INTEGRATION; FUSION
AB In the field of face anti-spoofing (FAS), how to extract the representative features to distinguish between real and spoof faces and train the corresponding deep networks are two vital issues. In this paper, we propose a simple but effective end-to-end FAS model based on an innovative texture extractor and a depth auxiliary supervision mechanism. In the feature extraction stage, we first design the residual gradient convolutions based on the redesigned gradient operators, which are used to extract fine-grained texture features. The extraction of texture features is based on multiple scales by dividing the texture differences between living and spoofing faces into three levels reasonably. Then we construct a multiscale residual gradient attention (MRGA) to obtain representative texture features from multiple levels texture features. By combining the proposed feature extractor MRGA and existing vision transformer (ViT), the MRGA-ViT is proposed to generate related semantics and obtain final classification results. In the training stage, we also propose a local depth auxiliary supervision based on a novel adjacent depth loss, which utilizes the correlation information of adjacent pixels adequately compared with traditional depth loss. The proposed MRGA-ViT model achieves competitive performance in generalization and stability ability, e.g., the ACER(%) values of intra testing on OULU-NPU database are 1.8, 2.6, 1.6 & PLUSMN; 1.2 and 1.9 & PLUSMN; 2.7 respectively, the AUC(%) of cross type testing attains 99.45 & PLUSMN; 0.57, the ACER(%) values of cross dataset testing are 28.1 and 36.7 respectively. Experimental results prove that the proposed model is competitive to other state-of-the-art works on generalization and stability performance.
C1 [Zhu, Shiwei; Xiang, Shijun] Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Peoples R China.
C3 Jinan University
RP Xiang, SJ (corresponding author), Jinan Univ, Coll Informat Sci & Technol, Guangzhou 510632, Peoples R China.
EM shijun_xiang@qq.com
FU National Natural Science Founda-tion of China [62272197]; Guangdong
   Ba-sic and Applied Basic Research Foundation [2023A1515011928]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Grant 62272197 and in part by the Guangdong
   Ba-sic and Applied Basic Research Foundation under Grant
   2023A1515011928.
CR Arashloo SR, 2017, IEEE ACCESS, V5, P13868, DOI 10.1109/ACCESS.2017.2729161
   Arashloo SR, 2015, IEEE T INF FOREN SEC, V10, P2396, DOI 10.1109/TIFS.2015.2458700
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688, DOI 10.1109/BTAS.2017.8272758
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   De Leon PL, 2012, IEEE T AUDIO SPEECH, V20, P2280, DOI 10.1109/TASL.2012.2201472
   Ding RX, 2015, J VIS COMMUN IMAGE R, V30, P35, DOI 10.1016/j.jvcir.2015.03.001
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Elliott S, 2002, JTC 1 SC 37 BIOMETRI
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gan JY, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP), P1, DOI 10.1109/ICMIP.2017.9
   Garcia DC, 2015, IEEE T INF FOREN SEC, V10, P778, DOI 10.1109/TIFS.2015.2411394
   George A., 2019, 2019 INT C BIOMETRIC, P1
   George A, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI 10.1109/IJCB52358.2021.9484333
   Hou JL, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3176028
   Jia S, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107032
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   KANOPOULOS N, 1988, IEEE J SOLID-ST CIRC, V23, P358, DOI 10.1109/4.996
   Khatab ZE, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107915
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Komulainen J, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Li L, 2022, J KING SAUD UNIV-COM, V34, P1455, DOI 10.1016/j.jksuci.2022.02.019
   Li L, 2016, INT CONF IMAG PROC
   Li L, 2018, J VIS COMMUN IMAGE R, V54, P182, DOI 10.1016/j.jvcir.2018.05.009
   Li X., 2020, 2020 IEEE INT JOINT, P1
   Liu A., 2022, P 31 INT JOINT C ART, P1180, DOI DOI 10.24963/IJCAI.2022/165
   Liu AJ, 2021, IEEE WINT CONF APPL, P1178, DOI 10.1109/WACV48630.2021.00122
   Liu AJ, 2021, IEEE T INF FOREN SEC, V16, P2759, DOI 10.1109/TIFS.2021.3065495
   Liu YJ, 2019, PROC CVPR IEEE, P4675, DOI 10.1109/CVPR.2019.00481
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Lucena O, 2017, LECT NOTES COMPUT SC, V10317, P27, DOI 10.1007/978-3-319-59876-5_4
   Ma L, 2003, IEEE T PATTERN ANAL, V25, P1519, DOI 10.1109/TPAMI.2003.1251145
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Patel K, 2015, INT CONF BIOMETR, P98, DOI 10.1109/ICB.2015.7139082
   Peng F, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102746
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Qin YX, 2020, AAAI CONF ARTIF INTE, V34, P11916
   Rehman YAU, 2019, J VIS COMMUN IMAGE R, V59, P574, DOI 10.1016/j.jvcir.2019.02.014
   Seif A., 2010, 2010 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology (STUDENT 2010), P99, DOI 10.1109/STUDENT.2010.5686999
   Sun L, 2007, LECT NOTES COMPUT SC, V4642, P252
   Sun WY, 2020, IEEE T INF FOREN SEC, V15, P3181, DOI 10.1109/TIFS.2020.2985530
   Suthaharan S, 2020, SIGNAL PROCESS, V177, DOI 10.1016/j.sigpro.2020.107733
   Szwoch M, 2012, LECT NOTES COMPUT SC, V7594, P669, DOI 10.1007/978-3-642-33564-8_80
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2022, IEEE T INF FOREN SEC, V17, P1254, DOI 10.1109/TIFS.2022.3158062
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiong F, 2018, INT CONF BIOMETR THE
   Yang J., 2014, arXiv
   Yang JS, 2013, IEEE GLOB COMM CONF, P1, DOI 10.1109/GLOCOM.2013.6831038
   Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362
   Yu ZT, 2021, IEEE T PATTERN ANAL, V43, P3005, DOI 10.1109/TPAMI.2020.3036338
   Yu ZT, 2020, PROC CVPR IEEE, P5294, DOI 10.1109/CVPR42600.2020.00534
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zitong Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P557, DOI 10.1007/978-3-030-58571-6_33
NR 64
TC 1
Z9 1
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103886
DI 10.1016/j.jvcir.2023.103886
EA JUL 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O8UH8
UT WOS:001046509500001
DA 2024-07-18
ER

PT J
AU Liu, N
   Zhang, F
   Duan, FQ
AF Liu, Na
   Zhang, Fan
   Duan, Fuqing
TI Age estimation by extracting hierarchical age-related features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Age estimation; Convolutional neural network (CNN); Deep learning;
   Global and local features; Multi-task learning
ID CLASSIFICATION
AB Image-based facial age estimation is considered an intractable problem because aging characteristics are hard to obtain. Most previous works have focused on extracting age-related features, but rarely explored which local region plays an important role. Several works combine local face regions with global face to estimate age in a heuristic way, where the local regions are uniformly cropped for each individual. In this paper, we design an individual adaptive segmentation of local regions of interest to perform personalized local features extraction and build hierarchical age features by erasing the local regions of interest iteratively for each individual. A joint multi-input and multi-output (MIMO) network for multi-task learning of age classification and regression tasks is designed by combining global features and personalized local features as inputs. In addition, we conduct extensive experiments to validate the effectiveness of the proposed method for age estimation, which beats most state-of-the-art methods in three public datasets and also works well for gender and race estimation.
C1 [Liu, Na; Zhang, Fan; Duan, Fuqing] Beijing Normal Univ, Coll Artificial Intelligence, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Duan, FQ (corresponding author), Beijing Normal Univ, Coll Artificial Intelligence, Beijing 100875, Peoples R China.
EM na_liu1994@126.com; fzhang@mail.bnu.edu.cn; fqduan@bnu.edu.cn
OI Liu, Na/0000-0001-6993-6331
FU National Key Research and Devel-opment Project Grant [2018AAA0100802];
   Opening Foundation of National Engineering Laboratory for Intelligent
   Video Analysis and Application
FX Acknowledgments This work was supported by the National Key Research and
   Devel-opment Project Grant, Grant/Award Number: 2018AAA0100802 and
   Opening Foundation of National Engineering Laboratory for Intelligent
   Video Analysis and Application.
CR [Anonymous], 2016, ACCV 3
   Bao Z., 2021, P INT C COMP AN IM P, P308
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen SX, 2017, PROC CVPR IEEE, P742, DOI 10.1109/CVPR.2017.86
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng YL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134597
   Gangwar A, 2021, NEUROCOMPUTING, V445, P81, DOI 10.1016/j.neucom.2021.02.056
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Guehairia O, 2020, NEURAL NETWORKS, V130, P238, DOI 10.1016/j.neunet.2020.07.006
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herbrich R, 1999, IEE CONF PUBL, P97, DOI 10.1049/cp:19991091
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Li K, 2017, PATTERN RECOGN, V66, P95, DOI 10.1016/j.patcog.2017.01.007
   Li PP, 2019, IEEE T INF FOREN SEC, V14, P2943, DOI 10.1109/TIFS.2019.2907973
   Li SX, 2015, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2015.7298618
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu N, 2020, IEEE ACCESS, V8, P92441, DOI 10.1109/ACCESS.2020.2994322
   Liu N, 2019, INT CONF ACOUST SPEE, P2377, DOI 10.1109/ICASSP.2019.8683005
   Ni B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P85
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shen W, 2021, IEEE T PATTERN ANAL, V43, P404, DOI 10.1109/TPAMI.2019.2937294
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Song Z, 2011, IEEE I CONF COMP VIS, P241, DOI 10.1109/ICCV.2011.6126248
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22
   Tan ZC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3548
   Tan ZC, 2018, IEEE T PATTERN ANAL, V40, P2610, DOI 10.1109/TPAMI.2017.2779808
   Tian Q, 2021, NEUROCOMPUTING, V444, P158, DOI 10.1016/j.neucom.2020.07.149
   Wan J, 2018, IEEE T CYBERNETICS, V48, P2531, DOI 10.1109/TCYB.2017.2741998
   Wan LP, 2018, INT CONF BIOMETR, P98, DOI 10.1109/ICB2018.2018.00025
   Wang MJ, 2021, TECHNOL HEALTH CARE, V29, pS497, DOI 10.3233/THC-218047
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wong W.S., 2000, US Patent, Patent No. [6,128,613, 6128613]
   Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005
   Yang TY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1078
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10
   Zhang C, 2019, PROC CVPR IEEE, P12579, DOI 10.1109/CVPR.2019.01287
   ZHENG S., 2012, Visual image recognition system with object-level image representation
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 49
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103884
DI 10.1016/j.jvcir.2023.103884
EA JUL 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N6LV5
UT WOS:001038112400001
OA Bronze
DA 2024-07-18
ER

PT J
AU Jin, X
   Feng, RY
   Sun, SM
   Feng, RS
   He, TY
   Chen, ZB
AF Jin, Xin
   Feng, Ruoyu
   Sun, Simeng
   Feng, Runsen
   He, Tianyu
   Chen, Zhibo
TI Semantical video coding: Instill static-dynamic clues into structured
   bitstream for AI tasks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Semantically structured bitstream; Intelligent analytics
ID IMAGE COMPRESSION; REPRESENTATION
AB Traditional media coding schemes typically encode image or video into a semantic-unknown binary stream, which fails to directly support downstream intelligent tasks at the bitstream level. Semantically Structured Image Coding (SSIC) (Sun et al., 2020) makes the first attempt to enable partial-decoding image intelligent task analysis via a Semantically Structured Bitstream (SSB). However, the SSIC considers image coding and its generated SSB only contains the static object information. In this paper, we propose an advanced Semantically Structured Video Coding (SSVC). Video signals contain more rich dynamic motion information and redundancy. Thus, we present a reformulation of semantically structured bitstream (SSB) in SSVC which contains both static object characteristics and dynamic motion clues. Specifically, we introduce optical flow to encode continuous motion information and reduce cross-frame redundancy via a predictive coding architecture, then the optical flow and residual information are reorganized into SSB, which enables the proposed SSVC could better adaptively support video-based downstream intelligent applications. Extensive experiments on various vision tasks demonstrate that the proposed SSVC framework could directly support multiple intelligent tasks just depending on a partially decoded bitstream, saving bitrate consumption for intelligent analytics.
C1 [Jin, Xin] Eastern Inst Adv Study, Ningbo, Peoples R China.
   [Feng, Ruoyu; Sun, Simeng; Feng, Runsen; Chen, Zhibo] Univ Sci & Technol China, Hefei, Peoples R China.
   [He, Tianyu] Microsoft Res Asia, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft; Microsoft Research Asia
RP Chen, ZB (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
EM jinxin@eias.ac.cn; fengruns@mail.ustc.edu.cn; smsun20@mail.ustc.edu.cn;
   fengruns@mail.ustc.edu.cn; tianyuhe@microsoft.com; chenzhibo@ustc.edu.cn
RI jin, xin/GQZ-5811-2022; feng, ruoyu/KVB-6685-2024
FU NSFC [U1908209, 62021001]; ZJNSFC [LQ23F010008]
FX Acknowledgements This work was supported in part by NSFC under Grant
   U1908209, 62021001. This work was also supported in part by ZJNSFC under
   Grant LQ23F010008.
CR Balle J, 2018, ICLR
   Balle J, 2017, 5 INT C LEARN REPR I
   Bjontegaard G., 2001, Document VCEG-M33
   Blau Y, 2019, PR MACH LEARN RES, V97
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Canterle DR, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107685
   CCITT SGXV Working Party XV, 1989, DRAFT REV REC H 261
   Chen ZZ, 2018, SIGNAL PROCESS, V146, P66, DOI 10.1016/j.sigpro.2018.01.004
   Chen ZB, 2020, IEEE T CIRC SYST VID, V30, P566, DOI 10.1109/TCSVT.2019.2892608
   Chen ZB, 2019, NEUROCOMPUTING, V338, P16, DOI 10.1016/j.neucom.2019.01.086
   Cheng-Tie Chen, 1993, Journal of Visual Communication and Image Representation, V4, P103, DOI 10.1006/jvci.1993.1009
   Coene WMJ, 1996, SIGNAL PROCESS, V55, P369, DOI 10.1016/S0165-1684(96)00181-8
   Davisson L., 1972, IEEE Transactions on Communications, V20, P1202
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Djelouah A, 2019, IEEE I CONF COMP VIS, P6430, DOI 10.1109/ICCV.2019.00652
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Duan LY, 2020, Arxiv, DOI arXiv:2001.03569
   Feng RS, 2020, IEEE COMPUT SOC CONF, P529, DOI 10.1109/CVPRW50498.2020.00068
   Forchheimer R., 1981, PROC PICTURE CODING, P15
   Habibian A, 2019, IEEE I CONF COMP VIS, P7032, DOI 10.1109/ICCV.2019.00713
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   hevc, HEVC OFF TEST MOD HM
   Hu Y, 2012, J VIS COMMUN IMAGE R, V23, P634, DOI 10.1016/j.jvcir.2012.02.008
   Hu YY, 2019, IEEE T MULTIMEDIA, V21, P3024, DOI 10.1109/TMM.2019.2920603
   I JTC, 144962 ISOIEC
   ISO/IEC, 1993, 111722 ISOIEC
   ISO ITU-T IEC JTC, 2013, GEN COD MOV PICT A 2
   ITU Telecom, 2003, ITU-T Recommendation H. 264
   ITU-T SG15, 1996, SG15 ITUT
   Jiao SM, 2019, OPT LETT, V44, P5186, DOI 10.1364/OL.44.005186
   jvet, VVC OFF TEST MOD VTM
   Kaminsky E, 2008, J VIS COMMUN IMAGE R, V19, P56, DOI 10.1016/j.jvcir.2007.05.002
   Kingma D. P., 2014, arXiv
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li DW, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103573
   Lin JP, 2020, Arxiv, DOI arXiv:2004.10290
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H., 2019, P IEEECVF C COMPUTER
   Liu HY, 2023, OPT LASER TECHNOL, V157, DOI 10.1016/j.optlastec.2022.108600
   Liu HJ, 2019, Arxiv, DOI arXiv:1912.06348
   Liu HJ, 2019, Arxiv, DOI arXiv:1904.09757
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Lu G, 2020, Arxiv, DOI arXiv:2003.11282
   Lu G, 2019, PROC CVPR IEEE, P10998, DOI 10.1109/CVPR.2019.01126
   Ma SW, 2019, IEEE T CIRC SYST VID, V29, P3095, DOI 10.1109/TCSVT.2018.2873102
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Mao J, 2020, IEEE T CIRC SYST VID, V30, P1856, DOI 10.1109/TCSVT.2019.2954853
   Meng XD, 2019, IEEE IMAGE PROC, P1193, DOI [10.1109/icip.2019.8804469, 10.1109/ICIP.2019.8804469]
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Mercat A, 2020, MMSYS'20: PROCEEDINGS OF THE 2020 MULTIMEDIA SYSTEMS CONFERENCE, P297, DOI 10.1145/3339825.3394937
   Minnen D, 2018, ADV NEUR IN, V31
   Mishra D, 2022, SIGNAL PROCESS, V191, DOI 10.1016/j.sigpro.2021.108346
   Naqvi SAR, 2014, SIGNAL PROCESS, V103, P331, DOI 10.1016/j.sigpro.2014.01.024
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Pau D., 2013, JTC1SC29WG11 ISOIEC
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Perazzi F, 2017, PROC CVPR IEEE, P3491, DOI 10.1109/CVPR.2017.372
   Pu LL, 2014, IEEE IMAGE PROC, P4817, DOI 10.1109/ICIP.2014.7025976
   REEVE HC, 1984, OPT ENG, V23, P34, DOI 10.1117/12.7973248
   Roese J. A., 1975, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.66. Efficient Transmission of Pictorial Information, P172
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shou Z, 2019, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2019.00136
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun JJ, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107990
   Sun S., 2020, IEEE T CIRC SYST VID
   Sze V., 2014, INTEGRATED CIRCUIT S, V39, P49
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Toderici G, 2016, Arxiv, DOI arXiv:1511.06085
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Torfason R, 2018, Arxiv, DOI arXiv:1803.06131
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Versatile Video Coding VVC Standard, QUANT ENTR COD VERS
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu CY, 2018, LECT NOTES COMPUT SC, V11212, P425, DOI 10.1007/978-3-030-01237-3_26
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang Ren, 2020, P IEEECVF C COMPUTER, P6628
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu ST, 2019, J VIS COMMUN IMAGE R, V58, P25, DOI 10.1016/j.jvcir.2018.11.016
   Yuan SY, 2019, J VIS COMMUN IMAGE R, V59, P33, DOI 10.1016/j.jvcir.2018.12.043
   Zhang F, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102912
   Zhang X, 2017, IEEE T IMAGE PROCESS, V26, P633, DOI 10.1109/TIP.2016.2629447
   Zhao L, 2019, IEEE T IMAGE PROCESS, V28, P4832, DOI 10.1109/TIP.2019.2913545
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 92
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103816
DI 10.1016/j.jvcir.2023.103816
EA MAR 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M0EZ6
UT WOS:001026933500001
DA 2024-07-18
ER

PT J
AU Sabat, N
   Raj, MSS
   George, SN
   Kumar, TKS
AF Sabat, Neelesh
   Raj, M. S. Subodh
   George, Sudhish N.
   Kumar, T. K. Sunil
TI A computationally efficient moving object detection technique using
   tensor QR decomposition based TRPCA framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving object detection; Tensor QR decomposition; Robust principal
   component analysis; Half thresholding
ID L-1/2 REGULARIZATION
AB Advancements in high-quality video cameras and the consequent capture of minute details of the scene have led the field of computer vision to remarkable heights. This paper develops a tensor QR decomposition-based approach for Moving Object Detection (MOD), which aims to reduce the computational complexity without disturbing the structural framework of the input video frames. The increased performance and efficiency of the proposed method lie in the usage of tensor QR decomposition along with 12,1 norm and 11/2 norm. It is designed on top of a tensor-based Robust Principal Component Analysis (TRPCA) framework. In addition, this work safeguards the variation along the spatio-temporal directions with the effective use of Tensor Total Variation (TTV) regularization. The results and the analysis prove that the proposed method improves the F-measure by 15%-45% and reduces the computational complexity by 75%-85% with respect to the counterparts.
C1 [Sabat, Neelesh; Kumar, T. K. Sunil] Natl Inst Technol Calicut, Dept Elect Engn, Kozhikode 673601, India.
   [Raj, M. S. Subodh; George, Sudhish N.] Natl Inst Technol Calicut, Dept Elect & Commun Engn, Kozhikode 673601, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut; National Institute of Technology (NIT System);
   National Institute of Technology Calicut
RP Raj, MSS (corresponding author), Natl Inst Technol Calicut, Dept Elect & Commun Engn, Kozhikode 673601, India.
EM neeleshsabat38@gmail.com; subodhrajms@gmail.com; sudhish@nitc.ac.in;
   tksunil@nitc.ac.in
RI M S, Subodh Raj/K-6771-2018
OI M S, Subodh Raj/0000-0002-1111-9520
CR Amato A, 2014, MOVING CAST SHADOWS, P23
   [Anonymous], 2015, 2015 IEEE INT C COMP
   Benzer R, 2018, 2018 INTERNATIONAL CONGRESS ON BIG DATA, DEEP LEARNING AND FIGHTING CYBER TERRORISM (IBIGDELFT), P35, DOI 10.1109/IBIGDELFT.2018.8625314
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Chen YY, 2019, IEEE T CIRC SYST VID, V29, P2567, DOI 10.1109/TCSVT.2017.2770319
   Clemente C, 2017, IEEE T AERO ELEC SYS, V53, P493, DOI 10.1109/TAES.2017.2649160
   Dehariya V. K., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P386, DOI 10.1109/CICN.2010.80
   Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204
   Ghadimi E, 2015, IEEE T AUTOMAT CONTR, V60, P644, DOI 10.1109/TAC.2014.2354892
   He J, 2014, IMAGE VISION COMPUT, V32, P800, DOI 10.1016/j.imavis.2014.02.015
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   Ismail A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165413
   Lai K.C., 2010, 2010 2 INT C COMPUTE, V3
   Liu H, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P221, DOI 10.1109/IAEAC.2015.7428551
   Liu Q, 2019, IEEE T NEUR NET LEAR, V30, P803, DOI 10.1109/TNNLS.2018.2851957
   Liu SL, 2014, 2014 Fifth International Conference on Intelligent Systems Design and Engineering Applications (ISDEA), P138, DOI 10.1109/ISDEA.2014.38
   Liu YP, 2018, IEEE J-STSP, V12, P1378, DOI 10.1109/JSTSP.2018.2873142
   Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760
   Mandal M, 2022, IEEE T INTELL TRANSP, V23, P6101, DOI [10.1109/TITS.2021.3077883, 10.3233/IP-200233]
   Mane S, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1809, DOI 10.1109/ICCONS.2018.8662921
   Morison G, 2021, EUR SIGNAL PR CONF, P2001, DOI 10.23919/Eusipco47968.2020.9287726
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Nakouri Halfa, 2017, 2017 18th International Conference on Parallel and Distributed Computing, Applications and Technologies (PDCAT). Proceedings, P196, DOI 10.1109/PDCAT.2017.00040
   Roemer Florian, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3963, DOI 10.1109/ICASSP.2014.6854345
   Selesnick IW, 2015, IEEE SIGNAL PROC LET, V22, P141, DOI 10.1109/LSP.2014.2349356
   Shijila B, 2018, J VIS COMMUN IMAGE R, V56, P188, DOI 10.1016/j.jvcir.2018.09.009
   Shijila B, 2019, FUTURE GENER COMP SY, V90, P198, DOI 10.1016/j.future.2018.07.065
   Tom AJ, 2020, IEEE T IMAGE PROCESS, V29, P7590, DOI 10.1109/TIP.2020.3004696
   Tom AJ, 2021, IEEE T CYBERNETICS, V51, P1004, DOI 10.1109/TCYB.2019.2921827
   Tom AJ, 2018, INT CO SIG PROC COMM, P327, DOI 10.1109/SPCOM.2018.8724459
   Tom AJ, 2019, IEEE SIGNAL PROC LET, V26, P577, DOI 10.1109/LSP.2019.2900126
   Xie Tingyao, 2022, 2022 3rd China International SAR Symposium (CISS), P1, DOI 10.1109/CISS57580.2022.9971223
   Xie XX, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P226, DOI 10.1109/ICICI.2017.8365343
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Yan C., 2020, ACM Trans. Multimedia Comput. Commun. Appl., V16
   Yang S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P641
   Yin Q, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3130436
   Yuan JY, 2021, IEEE SENS J, V21, P11522, DOI 10.1109/JSEN.2020.3025613
   Yulita I.N., 2021, 2021 INT C ARTIFICIA, P1
   Zeng JS, 2014, IEEE T SIGNAL PROCES, V62, P2317, DOI 10.1109/TSP.2014.2309076
   Zhang FL, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P394, DOI 10.1109/ACPR.2017.8
   Zhang JMY, 2019, Arxiv, DOI arXiv:1905.02292
   Zheng YM, 2021, SIGNAL PROCESS, V189, DOI 10.1016/j.sigpro.2021.108240
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zhou ZH, 2010, IEEE INT SYMP INFO, P1518, DOI 10.1109/ISIT.2010.5513535
NR 46
TC 0
Z9 0
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103785
DI 10.1016/j.jvcir.2023.103785
EA FEB 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9P6ZP
UT WOS:000944431300001
DA 2024-07-18
ER

PT J
AU Song, X
   Zhang, XD
   Ji, JZ
   Liu, Y
AF Song, Xiao
   Zhang, Xiaodan
   Ji, Junzhong
   Liu, Ying
TI Multi-scale Superpixel based Hierarchical Attention model for brain CT
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Brian CT classification; Medical image processing; Multi-scale
   superpixel; Hierarchical attention
AB Brain CT image classification is critical for assisting brain disease diagnosis. The brain CT images contain much noisy information, and the lesions are unstable in shape and location, making the classification task more difficult when using conventional CNN models. In this paper, we propose a novel Multi-scale Superpixel based Hierarchical Attention (MSHA) model for brain CT classification by introducing the multi-scale superpixels to a hierarchical fusion structure to remove noise and help the model focus on the lesion areas. MSHA contains three modules: (1) a Semantic-level Information Extractor that extracts appearance and geometry information based on the superpixel of the image, (2) a Mixed Multi-head Attention module that obtains the mixed attention features from the semantic-level information, and (3) a Hierarchical Fusion Structure that fuses the multi-scale attention features from coarse to fine. Experiments on the brain CT dataset demonstrate the effectiveness of the proposed model.
C1 [Song, Xiao; Zhang, Xiaodan; Ji, Junzhong] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Liu, Ying] Peking Univ Third Hosp, Dept Radiol, Beijing 100191, Peoples R China.
C3 Beijing University of Technology; Peking University
RP Zhang, XD (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.; Liu, Y (corresponding author), Peking Univ Third Hosp, Dept Radiol, Beijing 100191, Peoples R China.
EM zhangxiaodan@bjut.edu.cn; liuying@bjmu.edu.cn
RI Ji, Junzhong/GLU-8838-2022; Zhang, Xiaodan/GQR-0608-2022
OI Zhang, Xiaodan/0000-0001-8192-0666; Zhang, Xiaodan/0000-0001-7002-5447;
   Song, Xiao/0000-0001-6352-6542
FU National Natural Science Foundation of China [61906007, 62276010]; R&D
   Program of Beijing Municipal Education Commission [KM202110005022,
   KZ202210005009]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China under Grant 61906007 and 62276010, in part
   by the R&D Program of Beijing Municipal Education Commission under Grant
   KM202110005022 and KZ202210005009.
CR Anupama CSS, 2020, PERS UBIQUIT COMPUT, DOI 10.1007/s00779-020-01492-2
   Bengio Y., 2014, TECHNICAL REPORT
   Chilamkurthy S, 2018, LANCET, V392, P2388, DOI 10.1016/S0140-6736(18)31645-3
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fernando SM, 2021, STROKE, V52, P1673, DOI 10.1161/STROKEAHA.120.032550
   Garland J, 2020, J FORENSIC SCI, V65, P2019, DOI 10.1111/1556-4029.14502
   Gautam A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102178
   Guan QJ, 2020, PATTERN RECOGN LETT, V131, P38, DOI 10.1016/j.patrec.2019.11.040
   Guan QJ, 2020, PATTERN RECOGN LETT, V130, P259, DOI 10.1016/j.patrec.2018.10.027
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herdade S, 2019, ADV NEUR IN, V32
   Hu J, 2020, IEEE T PATTERN ANAL, V42, P2011, DOI 10.1109/TPAMI.2019.2913372
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Mansour RF, 2021, NEURAL COMPUT APPL, V33, P13831, DOI 10.1007/s00521-021-06020-8
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tighe J, 2013, INT J COMPUT VISION, V101, P329, DOI 10.1007/s11263-012-0574-z
   van Asch CJJ, 2010, LANCET NEUROL, V9, P167, DOI 10.1016/S1474-4422(09)70340-0
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wei X, 2018, IEEE T IMAGE PROCESS, V27, P4838, DOI 10.1109/TIP.2018.2836300
   West D. B., 2001, Introduction to graph theory, V2
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Zhang ZJ, 2019, LECT NOTES COMPUT SC, V11764, P442, DOI 10.1007/978-3-030-32239-7_49
   Zhou T, 2020, IEEE T MED IMAGING, V39, P2772, DOI 10.1109/TMI.2020.2975344
NR 28
TC 1
Z9 1
U1 11
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103773
DI 10.1016/j.jvcir.2023.103773
EA FEB 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8Y3LX
UT WOS:000932601000001
DA 2024-07-18
ER

PT J
AU Fang, ZY
   Gao, GY
   Zhang, ZK
   Zhang, AQ
AF Fang, Zhiyuan
   Gao, Guangyu
   Zhang, Zekang
   Zhang, Anqi
TI Hierarchical context-agnostic network with contrastive feature diversity
   for one-shot semantic segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Few-shot learning; Unsupervised clustering;
   Hierarchical pyramid; Background exclusion
AB One-shot semantic segmentation aims at distinguishing pixels of an unseen category from the background, using merely one annotated image from the same category. However, most previous works neglect the feature diversity of foreground and the context information of background by using the masked average pooling. To solve these issues, we propose the Hierarchical Context-Agnostic Network (HCNet). It mainly includes two modules: (1) a Hierarchical Pyramid Supportive (HPS) module that generate the hierarchical supportive prototypes from coarse to fine to ensure feature diversity, and (2) a Background Exclusion Supportive (BES) module that explicitly introduces the contrastive information from the background for more precise category features. We conduct extensive experiments on Pascal-5(i) and COCO-20(i) to evaluate the performance of HCNet. HCNet achieves the mIoU score of 62.1% on Pascal-5(i) and 40.7% on COCO-20(i). and outperforms other works for the challenging one-shot segmentation, which has proved the efficiency of the whole network. Code is available at https://github.com/fangzy97/hcnet.
C1 [Fang, Zhiyuan; Gao, Guangyu; Zhang, Zekang; Zhang, Anqi] Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing, Peoples R China.
C3 Beijing Institute of Technology
RP Gao, GY (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing, Peoples R China.
EM guangyugao@bit.edu.cn
RI Fang, Zhiyuan/AHA-5840-2022; Zhang, Anqi/GLU-9033-2022
OI Zhang, Anqi/0000-0002-0195-5429
FU National Natural Science Founda-tion of China [61972036]
FX This work was supported by the National Natural Science Founda-tion of
   China under Grant No. 61972036.
CR Boudiaf M, 2021, PROC CVPR IEEE, P13974, DOI 10.1109/CVPR46437.2021.01376
   Boyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P763, DOI 10.1007/978-3-030-58598-3_45
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Deng J., 2009, IEEE C COMP VIS PATT
   Dong N., 2018, BMVC, V4, P4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Finn C, 2017, PR MACH LEARN RES, V70
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gutmann Michael, 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Harley AW, 2017, IEEE I CONF COMP VIS, P5048, DOI 10.1109/ICCV.2017.539
   He K., 2019, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu T, 2019, AAAI CONF ARTIF INTE, P8441
   Nguyen K, 2019, IEEE I CONF COMP VIS, P622, DOI 10.1109/ICCV.2019.00071
   Koch G, 2015, P 32 INT C MACHINE L
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li G., 2021, P IEEE CVF C COMP VI, P8334
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Liu WD, 2022, INT J COMPUT VISION, V130, P3140, DOI 10.1007/s11263-022-01677-7
   Liu WD, 2020, PROC CVPR IEEE, P4164, DOI 10.1109/CVPR42600.2020.00422
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lu Z., 2021, PROC IEEE INT C COMP, P8741
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Rakelly K, 2018, CONDITIONAL NETWORKS
   Ravi S, 2016, OPTIMIZATION MODEL F
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santoro A., 2016, ICML, P1842
   Shaban A, 2017, ARXIV PREPRINT ARXIV, DOI 10.5244/C.31.167
   Siam M, 2019, IEEE I CONF COMP VIS, P5248, DOI 10.1109/ICCV.2019.00535
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tian PZ, 2020, AAAI CONF ARTIF INTE, V34, P12087
   Tian ZH, 2020, IEEE INTERNET THINGS, V7, P3901, DOI [10.1109/TPAMI.2020.3013717, 10.1109/JIOT.2019.2951620]
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Wang H., 2022, CHIN C PATT REC COMP, P287
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang WJ, 2022, COMPUT ELECTR ENG, V103, DOI 10.1016/j.compeleceng.2022.108326
   Wu ZH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P497, DOI 10.1109/ICCV48922.2021.00056
   Yang XH, 2022, IEEE IMAGE PROC, P1126, DOI 10.1109/ICIP46576.2022.9897329
   Yang YW, 2020, LECT NOTES COMPUT SC, V11962, P76, DOI 10.1007/978-3-030-37734-2_7
   Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang XL, 2020, Arxiv, DOI arXiv:1810.09091
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu K, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1019
NR 58
TC 1
Z9 1
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103754
DI 10.1016/j.jvcir.2023.103754
EA JAN 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8H2AG
UT WOS:000920837300001
DA 2024-07-18
ER

PT J
AU Zhong, KR
   Chen, ZX
   Liu, CY
   Wu, QMJ
   Duan, SC
AF Zhong, Kunru
   Chen, Zhenxue
   Liu, Chengyun
   Wu, Q. M. Jonathan
   Duan, Shuchao
TI Unsupervised self-attention lightweight photo-to-sketch synthesis with
   feature maps
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Photo-to-sketch synthesis; Unsupervised learning; Self-attention
   mechanism; Feature map
AB Face-sketch synthesis is important for gaining a clear portrait photo of suspects when solving crimes. Recent research has made a great process in self-attention generative adversarial networks. We propose a method of unsupervised learning in the synthesis of face sketch-to-photo using a new attention module. The method of processing on a small reference set of photo-sketch pairs adds to the attention module, a focus on the regions distinguishing photos from sketches on the basis of the feature maps obtained by the auxiliary classifier. Unlike previous attention-based methods, which cannot handle the geometric changes between domains, our model can translate images requiring holistic changes. At the same time, we reduce the layers of the discriminator according to different residual layers to optimize our network. With the proposed approach, we can train our networks using a small reference set of photo-sketch pairs together with a large number of face-photo datasets and more distinguishing facial-feature regions in the self-attention model. Experiments have shown the superiority of the proposed method to existing face sketch-to-photo synthesis models using fixed network architectures and hyper-parameters.
C1 [Zhong, Kunru; Chen, Zhenxue; Liu, Chengyun; Duan, Shuchao] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
   [Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 Shandong University; University of Windsor
RP Chen, ZX (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China.
EM 202014815@mail.sdu.edu.cn; chenzhenxue@sdu.edu.cn;
   liuchengyun@sdu.edu.cn; jwu@uwindsor.ca; dscvincent1995@gmail.com
RI WANG, Bin/JGM-2639-2023; liu, huan/JKI-3764-2023; cheng,
   cheng/JBR-8359-2023; liu, huan/JEO-4705-2023; wang, wei/JBS-7400-2023;
   Wang, Minghao/JMD-0670-2023; yang, yue/KCK-7870-2024; Li,
   jiaqi/JOZ-6395-2023; LIU, HAO/JBI-9623-2023; CHEN, AN/KFT-3370-2024;
   Wang, Hao/ABB-8923-2020; wang, hang/JND-8481-2023; wang,
   yixuan/JGM-3893-2023; Chen, Xin/JDN-2017-2023; zhang,
   yueqi/JXM-4287-2024; wang, hao/JKH-5890-2023; Liu, Yilin/JWP-9153-2024;
   Yu, Yue/JWP-9103-2024; luo, yuan/JLS-6416-2023; li,
   xiaomin/KCX-9845-2024; zhou, yang/JED-3951-2023; WANG,
   HUI/JFA-9683-2023; wang, wenxin/JOZ-3291-2023; LI,
   Xiang-Yang/JZE-0275-2024; zhang, zheng/KBQ-7815-2024; LIU,
   HUI/JPX-8014-2023
OI Wang, Hao/0000-0001-9109-6017; Liu, Yilin/0000-0002-7581-3933; Chen,
   Zhenxue/0000-0001-9637-5170; Duan, Shuchao/0000-0002-3168-3196
FU National Natural Science Foundation of China [61876099]; Key R&D Project
   of Shandong Province [2022CXGC010503]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China (61876099) and in part by the Key R&D
   Project of Shandong Province (2022CXGC010503) . Kunru Zhong and Zhenxue
   Chen contributed equally to this work and should be considered as the
   co-first authors.
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]
   Chen CF, 2019, LECT NOTES COMPUT SC, V11361, P216, DOI 10.1007/978-3-030-20887-5_14
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chen WL, 2018, PROC CVPR IEEE, P9416, DOI 10.1109/CVPR.2018.00981
   Chen ZX, 2018, J VIS COMMUN IMAGE R, V51, P112, DOI 10.1016/j.jvcir.2017.12.010
   Cho M, 2021, IEEE T INF FOREN SEC, V16, P376, DOI 10.1109/TIFS.2020.3013186
   Duan SC, 2021, IEEE T INF FOREN SEC, V16, P1218, DOI 10.1109/TIFS.2020.3031386
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hang H.-M., 2020, 2020 IEEE CVF C COMP
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang KX, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P182, DOI 10.1109/dicta47822.2019.8946068
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002
   Jiang JJ, 2019, IEEE T IMAGE PROCESS, V28, P628, DOI 10.1109/TIP.2018.2870936
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kim J, 2020, Arxiv, DOI [arXiv:1907.10830, DOI 10.48550/ARXIV.1907.10830]
   Kumar Anukriti, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P917, DOI 10.1109/ICCMC51019.2021.9418040
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li Y.-h., 2006, 2006 IEEE INT C AC S
   Lin CH, 2018, PROC CVPR IEEE, P9455, DOI 10.1109/CVPR.2018.00985
   Lin Y, 2020, IEEE SIGNAL PROC LET, V27, P1095, DOI 10.1109/LSP.2020.3005039
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   McGonigle D, 2020, PROC INT C TOOLS ART, P773, DOI 10.1109/ICTAI50040.2020.00123
   Messer K., 1999, 2 INT C AUD VID BAS
   Pereira TD, 2019, IEEE T INF FOREN SEC, V14, P1803, DOI 10.1109/TIFS.2018.2885284
   Philip C, 2017, I C INF COMM TECH CO, P373, DOI 10.1109/ICTC.2017.8191006
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Rahmayanti SR, 2021, INT CONF INFORM COMM, P134, DOI 10.1109/ICTS52701.2021.9608634
   Song JF, 2018, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2018.00090
   Tagaris T, 2019, IEEE IMAGE PROC, P4514, DOI [10.1109/ICIP.2019.8803474, 10.1109/icip.2019.8803474]
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Tu CT, 2010, IEEE T SYST MAN CY B, V40, P1158, DOI 10.1109/TSMCB.2009.2035154
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Xia WH, 2021, PROC CVPR IEEE, P2256, DOI 10.1109/CVPR46437.2021.00229
   Yang S, 2021, IEEE T IMAGE PROCESS, V30, P8797, DOI 10.1109/TIP.2021.3120669
   Yedidia J.S., 2003, J AM SOC INF SCI TEC
   Yi R, 2019, PROC CVPR IEEE, P10735, DOI 10.1109/CVPR.2019.01100
   Yu J, 2021, IEEE T CYBERNETICS, V51, P4350, DOI 10.1109/TCYB.2020.2972944
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang MJ, 2020, IEEE T CYBERNETICS, V50, P2701, DOI 10.1109/TCYB.2019.2924589
   Zhang SC, 2016, IEEE T IMAGE PROCESS, V25, P220, DOI 10.1109/TIP.2015.2501755
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhong X, 2019, IEEE IMAGE PROC, P395, DOI [10.1109/icip.2019.8803000, 10.1109/ICIP.2019.8803000]
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu M., 2021, INT JOINT C ARTIFICI
NR 49
TC 2
Z9 2
U1 3
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103747
DI 10.1016/j.jvcir.2022.103747
EA JAN 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7Z9AY
UT WOS:000915844900001
DA 2024-07-18
ER

PT J
AU Kaplan, NH
AF Kaplan, Nur Huseyin
TI Real-world image dehazing with improved joint enhancement and exposure
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Image enhancement; Image sharpening; Image filtering
ID ADAPTIVE HISTOGRAM EQUALIZATION
AB In this work, a single image dehazing method that improves the haze removal capacity of the Joint Contrast Enhancement and Exposure Fusion (CEEF) method with Smoothing-Sharpening Image Filter (SSIF) is presented. In this method, the hazy image is first sharpened with SSIF to obtain a sharper image. In this way, the difference between haze and objects is amplified. Then, the AHE procedure in CEEF is replaced by CLAHE to obtain an enhanced CEEF. The enhanced CEEF is applied to the filtering result to obtain the final dehazed image. Observations demonstrate that the proposed method obtains enhanced results while reducing the amount of haze. The visual and quantitative comparisons between the proposed method and state-of-the-art dehazing methods show that the proposed method has better dehazing performance and has a 50% improvement in terms of the FADE metric compared to the closest result.
C1 [Kaplan, Nur Huseyin] Erzurum Tech Univ, Dept Elect & Elect Engn, TR-25050 Erzurum, Turkey.
C3 Erzurum Technical University
RP Kaplan, NH (corresponding author), Erzurum Tech Univ, Dept Elect & Elect Engn, TR-25050 Erzurum, Turkey.
EM huseyin.kaplan@erzurum.edu.tr
RI Kaplan, Nur Hüseyin/H-1771-2016; Kaplan, Nur Hüseyin/JCO-4465-2023
OI Kaplan, Nur Hüseyin/0000-0002-4740-3259; Kaplan, Nur
   Hüseyin/0000-0002-4740-3259
CR Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Deng G, 2021, IEEE OPEN J SIGNAL P, V2, P119, DOI 10.1109/OJSP.2021.3063076
   Ehsan SM, 2021, IEEE ACCESS, V9, P89055, DOI 10.1109/ACCESS.2021.3090078
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Galdran A, 2018, PROC CVPR IEEE, P8212, DOI 10.1109/CVPR.2018.00857
   Guo JM, 2017, IEEE T IMAGE PROCESS, V26, P4217, DOI 10.1109/TIP.2017.2706526
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   Kaplan NH, 2017, SIGNAL IMAGE VIDEO P, V11, P1389, DOI 10.1007/s11760-017-1097-4
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim TK, 1998, IEEE T CONSUM ELECTR, V44, P82, DOI 10.1109/30.663733
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li RD, 2020, IEEE T IMAGE PROCESS, V29, P6523, DOI 10.1109/TIP.2020.2991509
   Li Z, 2021, INT C PATT RECOG, P8267, DOI 10.1109/ICPR48806.2021.9412595
   Li ZG, 2021, IEEE T IMAGE PROCESS, V30, P9270, DOI 10.1109/TIP.2021.3123551
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu XN, 2022, IEEE T MULTIMEDIA, V24, P3934, DOI 10.1109/TMM.2021.3110483
   Lu ZW, 2020, IEEE SIGNAL PROC LET, V27, P665, DOI 10.1109/LSP.2020.2985570
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Raikwar SC, 2020, IEEE T IMAGE PROCESS, V29, P4832, DOI 10.1109/TIP.2020.2975909
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 36
TC 11
Z9 11
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103720
DI 10.1016/j.jvcir.2022.103720
EA DEC 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7K2ZM
UT WOS:000905154600001
DA 2024-07-18
ER

PT J
AU Li, X
   Huang, Q
   Wang, ZJ
AF Li, Xing
   Huang, Qian
   Wang, Zhijian
TI Spatial and temporal information fusion for human action recognition via
   Center Boundary Balancing Multimodal Classifier
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Gaussian pyramid depth motion images; Depth
   temporal maps; Center Boundary Balancing Multimodal; Classifier
ID MOTION
AB This paper proposes a novel multimodal data classifier named Center Boundary Balancing Multimodal Classifier (CBBMC) to fuse and classify the spatial and temporal descriptors for recognizing human actions from depth video sequences. CBBMC is a composite algorithm integrating feature fusion and feature classification, in which Center Boundary Balancing Projection (CBBP) is used to balance the center and boundary information of feature class spaces. In order to solve the problem of multimodal information redundancy and isolation, two feature selection and fusion schemes of CBBMC based on embedded feature selection are presented. Moreover, two new action descriptors called Gaussian Pyramid Depth Motion Images (GP-DMI) and Depth Temporal Maps (DTM) are introduced to capture the multi-scale spatial and fine-grained temporal information of human activities. Finally, we present an effective spatial and temporal information fusion framework based on CBBMC for human action recognition. In order to evaluate the performance of the proposed approach, extensive experiments are conducted. The proposed method achieved impressive results on four benchmark datasets, namely MSR Action3D (96.33%), UTD-MHAD (94.41%), DHA (95.65%), and NTU RGB+D (83.31% cross-subject and 87.66% cross-view), even though only the depth modality was used. The experimental results demonstrate the effectiveness of our method.
C1 [Huang, Qian] Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, Nanjing, Jiangsu, Peoples R China.
   Hohai Univ, Sch Comp & Informat, Nanjing, Jiangsu, Peoples R China.
C3 Hohai University; Hohai University
RP Huang, Q (corresponding author), Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, Nanjing, Jiangsu, Peoples R China.
EM lixing@hhu.edu.cn; huangqian@hhu.edu.cn; zhjwang@hhu.edu.cn
RI Huang, Qian/GPX-9181-2022
OI Huang, Qian/0000-0001-5625-0402; Li, Xing/0000-0002-0881-0978
FU National Key Research and De-velopment Program of China; Jiangsu Water
   Conservancy Science and Technology Project; Fundamental Research Funds
   of China for the Central Universities;  [2018YFC0407905];  [2018057]; 
   [B200202188]
FX Acknowledgments This research is sponsored by the National Key Research
   and De-velopment Program of China under Grant No. 2018YFC0407905, the
   Jiangsu Water Conservancy Science and Technology Project under Grant No.
   2018057, and the Fundamental Research Funds of China for the Central
   Universities under Grant No. B200202188.
CR [Anonymous], 2018, P IEEE INT C MULT EX
   Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Barkoky A., 2021, J VIS COMMUN IMAGE R
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bulbul MF, 2019, MULTIMED TOOLS APPL, V78, P21085, DOI 10.1007/s11042-019-7365-2
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao X, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185180
   Chatfield K, 2014, Arxiv, DOI arXiv:1405.3531
   Chen C., 2016, P 25 INT JOINT C ART, P3331
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Chen C, 2016, J REAL-TIME IMAGE PR, V12, P155, DOI 10.1007/s11554-013-0370-1
   Chi WZ, 2018, IEEE T SYST MAN CY-S, V48, P1429, DOI 10.1109/TSMC.2017.2660547
   Coelho GP, 2012, IEEE IJCNN
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elharrouss O, 2021, APPL INTELL, V51, P690, DOI 10.1007/s10489-020-01823-z
   Elmadany NE, 2019, IEEE T MULTIMEDIA, V21, P1317, DOI 10.1109/TMM.2018.2875510
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Fan Hehe, 2021, IEEECVFCONF COMPUT V, P14204
   Gao Z, 2015, NEUROCOMPUTING, V151, P554, DOI 10.1016/j.neucom.2014.06.085
   Guo YN, 2017, IEEE T SYST MAN CY-S, V47, P617, DOI 10.1109/TSMC.2016.2617465
   Haghighat M, 2016, IEEE T INF FOREN SEC, V11, P1984, DOI 10.1109/TIFS.2016.2569061
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hu G, 2019, IEEE INT CON MULTI, P1216, DOI 10.1109/ICME.2019.00212
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Koniusz P, 2022, IEEE T PATTERN ANAL, V44, P648, DOI 10.1109/TPAMI.2021.3107160
   Li JN, 2018, Arxiv, DOI arXiv:1809.01844
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liang CW, 2018, IEEE T CIRC SYST VID, V28, P2920, DOI 10.1109/TCSVT.2017.2715045
   Liang GQ, 2018, IEEE T SYST MAN CY-S, V48, P1080, DOI 10.1109/TSMC.2016.2639788
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu H, 2015, IEEE IMAGE PROC, P4674, DOI 10.1109/ICIP.2015.7351693
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2018, IEEE T CIRC SYST VID, V28, P1824, DOI 10.1109/TCSVT.2017.2655521
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Lu JS, 2015, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2015.7299000
   Mengyuan Liu, 2017, 2017 IEEE International Conference on Multimedia and Expo: Workshops (ICMEW), P623, DOI 10.1109/ICMEW.2017.8026280
   Min YC, 2020, PROC CVPR IEEE, P5760, DOI 10.1109/CVPR42600.2020.00580
   Nguyen XS, 2018, MULTIMED TOOLS APPL, V77, P21617, DOI 10.1007/s11042-017-5593-x
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Qin XL, 2020, NEUROCOMPUTING, V406, P127
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Song Y, 2014, IEEE T CIRC SYST VID, V24, P952, DOI 10.1109/TCSVT.2014.2302558
   Tran QD, 2013, PROCEEDINGS OF 2013 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING AND COMMUNICATION TECHNOLOGIES: RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF), P253, DOI 10.1109/RIVF.2013.6719903
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van Rest J, 2014, MULTIMED TOOLS APPL, V70, P573, DOI 10.1007/s11042-013-1575-9
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Vyas Shruti, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P427, DOI 10.1007/978-3-030-58583-9_26
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang L, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4324, DOI 10.1145/3474085.3475572
   Wang L, 2019, IEEE I CONF COMP VIS, P8697, DOI 10.1109/ICCV.2019.00879
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang YC, 2020, PROC CVPR IEEE, P508, DOI 10.1109/CVPR42600.2020.00059
   Wu HB, 2022, IEEE T CIRC SYST VID, V32, P1250, DOI [10.1109/TAI.2021.3092698, 10.1109/TCSVT.2021.3077512]
   Wu HB, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881418825093
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xu HN, 2015, IEEE INT WORKSH MULT
   Yang TJ, 2020, IEEE ACCESS, V8, P135118, DOI 10.1109/ACCESS.2020.3006067
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
NR 66
TC 2
Z9 2
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103716
DI 10.1016/j.jvcir.2022.103716
EA DEC 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7J5QH
UT WOS:000904636200001
DA 2024-07-18
ER

PT J
AU Sang, QB
   Shu, ZR
   Liu, LX
   Hu, C
   Wu, Q
AF Sang, Qingbing
   Shu, Ziru
   Liu, Lixiong
   Hu, Cong
   Wu, Qin
TI Image quality assessment based on self-supervised learning and knowledge
   distillation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Knowledge distillation; Self-supervised learning; Image quality
   evaluation
AB Deep neural networks have achieved great success in a wide range of machine learning tasks due to their excellent ability to learn rich semantic features from high-dimensional data. Deeper networks have been successful in the field of image quality assessment to improve the performance of image quality assessment models. The success of deep neural networks majorly comes along with both big models with hundreds of millions of parameters and the availability of numerous annotated datasets. However, the lack of large-scale labeled data leads to the problems of over-fitting and poor generalization of deep learning models. Besides, these models are huge in size, demanding heavy computation power and failing to be deployed on edge devices. To deal with the challenge, we propose an image quality assessment based on self-supervised learning and knowledge distillation. First, the self-supervised learning of soft target prediction given by the teacher network is carried out, and then the student network is jointly trained to use soft target and label on knowledge distillation. Experiments on five benchmark databases show that the proposed method is superior to the teacher network and even outperform the state-of-the-art strategies. Furthermore, the scale of our model is much smaller than the teacher model and can be deployed in edge devices for smooth inference.
C1 [Sang, Qingbing; Shu, Ziru; Hu, Cong; Wu, Qin] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
   [Sang, Qingbing; Liu, Lixiong] Jiangnan Univ, Jiangsu Key Lab Media Design & Software Technol, Wuxi 214122, Peoples R China.
   [Liu, Lixiong] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
C3 Jiangnan University; Jiangnan University; Beijing Institute of
   Technology
RP Sang, QB (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi 214122, Peoples R China.
EM qingbings@jiangnan.edu.cn
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Cheon M, 2021, IEEE COMPUT SOC CONF, P433, DOI 10.1109/CVPRW53098.2021.00054
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Cui C, 2023, ANIM BIOTECHNOL, V34, P122, DOI 10.1080/10495398.2021.1941071
   de Sa V. R., 1993, LEARNING CLASSIFICAT, P112
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Finn C., 2016, arXiv, Vabs/1611.03852
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Golestaneh SA, 2022, IEEE WINT CONF APPL, P3989, DOI 10.1109/WACV51458.2022.00404
   Hancheng Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14131, DOI 10.1109/CVPR42600.2020.01415
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Kazmierczak R., 2022, ARXIV, Vabs/2202.0
   Ke JJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5128, DOI 10.1109/ICCV48922.2021.00510
   Kong H., 2019, ARXIV
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Macko V., 2019, ARXIV
   Mishra A., 2018, ARXIV
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Varga D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010101
   Wang GR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9485, DOI 10.1109/ICCV48922.2021.00937
   Yin G., 2022, Content-variant reference image quality assessment via knowledge distillation
   You JY, 2021, IEEE IMAGE PROC, P1389, DOI 10.1109/ICIP42928.2021.9506075
   Zeng H., 2017, CARR, P1
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang W., 2020, IEEE T CIRC SYST VID, V30
NR 33
TC 2
Z9 2
U1 3
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103708
DI 10.1016/j.jvcir.2022.103708
EA DEC 2022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5GZ0
UT WOS:000975835700001
DA 2024-07-18
ER

PT J
AU Narwal, P
   Duhan, N
   Bhatia, KK
AF Narwal, Pulkit
   Duhan, Neelam
   Bhatia, Komal Kumar
TI A comprehensive survey and mathematical insights towards video
   summarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Video Summarization; Video Abstraction; Video Segmentation; Prior
   Knowledge; Dynamic Video Summary; Personalized Video Summary
ID SPORTS VIDEO; PERSONALIZED RETRIEVAL; FEATURE-EXTRACTION; SOCCER VIDEO;
   USER; FRAMEWORK; ABSTRACTION; RECOGNITION; HIGHLIGHTS; TRACKING
AB Video Summarization is a technique to reduce the original raw video into a short video summary. Video summarization automates the task of acquiring key frames/segments from the video and combining them to generate a video summary. This paper provides a framework for summarization based on different criteria and also compares different literature work related to video summarization. The framework deals with formulating model for video summarization based on different criteria. Based on target audience/ viewership, number of videos, type of output intended, type of video summary and summarization factor; a model generating video summarization framework is proposed. The paper examines significant research works in the area of video summarization to present a comprehensive review against the framework. Different techniques, perspectives and modalities are considered to preserve the diversity of survey. This paper examines important mathematical formulations to provide meaningful insights for video summarization model creation.
C1 [Narwal, Pulkit; Duhan, Neelam; Bhatia, Komal Kumar] JC Bose Univ Sci & Technol, Dept Comp Engn, YMCA, Faridabad, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Narwal, P (corresponding author), JC Bose Univ Sci & Technol, Dept Comp Engn, YMCA, Faridabad, India.
EM pulkitnarwal2@gmail.com
CR Aizawa Kiyoharu., 2004, CARPE 04 P THE 1 ACM, P22, DOI DOI 10.1145/1026653.1026656
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], OPEN VIDEO PROJECT
   [Anonymous], 2015, COMPUT VIS MEDIA, DOI DOI 10.1007/S41095-015-0015-3
   ATON, ATON
   Badre SR, 2016, PROCEDIA COMPUT SCI, V79, P474, DOI 10.1016/j.procs.2016.03.061
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Boukadida H, 2017, IEEE T CIRC SYST VID, V27, P920, DOI 10.1109/TCSVT.2015.2513678
   Chen B, 2013, INFORM PROCESS MANAG, V49, P1, DOI 10.1016/j.ipm.2011.12.002
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen F., 2012, LECT NOTES I COMPUTE, P113, DOI [10.1007/978-3-642-35145-7_15, DOI 10.1007/978-3-642-35145-7_15]
   Chen KY, 2016, SPEECH COMMUN, V80, P49, DOI 10.1016/j.specom.2016.03.006
   Cheng Yan, 2021, 2021 16th International Conference on Computer Science & Education (ICCSE), P653, DOI 10.1109/ICCSE51940.2021.9569708
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Chung CT, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P173, DOI 10.1109/ISCSLP.2014.6936592
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Daneva Maya, 2013, Requirements Engineering: Foundation for Software Quality. 19th International Working Conference, REFSQ 2013. Proceedings, P1, DOI 10.1007/978-3-642-37422-7_1
   Dao MS, 2010, MULTIMED TOOLS APPL, V50, P227, DOI 10.1007/s11042-009-0379-4
   Darabi K, 2017, MULTIMED TOOLS APPL, V76, P2353, DOI 10.1007/s11042-015-3210-4
   Darabi K, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P310, DOI 10.1109/ChinaSIP.2014.6889254
   Dastjerdi NS, 2017, INT CONF IMAG PROC
   del Molino AG, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P600, DOI 10.1145/3240508.3240599
   del Molino AG, 2017, IEEE T HUM-MACH SYST, V47, P65, DOI 10.1109/THMS.2016.2623480
   Dong P, 2010, LECT NOTES COMPUT SC, V6297, P203, DOI 10.1007/978-3-642-15702-8_19
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fei M., 2018, J AMB INTEL HUM COMP, DOI [10.1007/s12652-018-0797-0, DOI 10.1007/S12652-018-0797-0]
   Fei MJ, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114036
   Fei MJ, 2018, NEUROCOMPUTING, V275, P1911, DOI 10.1016/j.neucom.2017.10.030
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Gkalelis N, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P159, DOI 10.1109/CVMP.2009.19
   Gong YH, 2003, EURASIP J APPL SIG P, V2003, P160, DOI 10.1155/S1110865703211082
   GTEA, GTEA
   Guo Y., 2012, 2012 WORLD C INFORM, DOI [10.1109/wict.2012.6409226, DOI 10.1109/WICT.2012.6409226]
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Han JW, 2014, INFORM SCIENCES, V281, P781, DOI 10.1016/j.ins.2013.12.039
   Han M., 2002, Proc. ACM Multimedia, P347, DOI [DOI 10.1145/641007.641081, 10.1145/641007.641081]
   Hari R, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P245, DOI 10.1109/RAICS.2013.6745481
   Hesham M, 2018, PROCEEDINGS OF 2018 FIRST INTERNATIONAL WORKSHOP ON DEEP AND REPRESENTATION LEARNING (IWDRL), P26, DOI 10.1109/IWDRL.2018.8358211
   Hu SH, 2010, LECT NOTES COMPUT SC, V6297, P537, DOI 10.1007/978-3-642-15702-8_49
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   Hussain T, 2020, IEEE T IND INFORM, V16, P77, DOI 10.1109/TII.2019.2929228
   ICEWS, ICEWS
   Jadhav PS, 2015, PROCEDIA COMPUT SCI, V45, P275, DOI 10.1016/j.procs.2015.03.140
   Jaimes A, 2002, IEEE IMAGE PROC, P133
   Jangra Anubhav, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P190, DOI 10.1007/978-3-030-45442-5_24
   Javed A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS-ASIA (ICCE-ASIA)
   Jeong DJ, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0122-9
   Ji Z, 2020, PATTERN RECOGN LETT, V135, P131, DOI 10.1016/j.patrec.2020.04.011
   Ji Z, 2020, NEUROCOMPUTING, V405, P200, DOI 10.1016/j.neucom.2020.04.132
   Ji Z, 2020, IEEE T CIRC SYST VID, V30, P1709, DOI 10.1109/TCSVT.2019.2904996
   Ji Z, 2019, INFORM SCIENCES, V478, P152, DOI 10.1016/j.ins.2018.09.050
   Ji Z, 2018, SIGNAL PROCESS, V148, P114, DOI 10.1016/j.sigpro.2018.01.028
   Jiang RM, 2009, STUD COMPUT INTELL, V231, P27
   Jianguo Wang, 2011, Proceedings of the 2011 2nd International Conference on Control, Instrumentation, and Automation (ICCIA), P1, DOI 10.1109/ICCIAutom.2011.6183890
   Jin-Woo Jeong, 2007, 2007 3rd International Conference on Semantics, Knowledge and Grid, P170, DOI 10.1109/SKG.2007.112
   Jodoin JP, 2014, IEEE WINT CONF APPL, P885, DOI 10.1109/WACV.2014.6836010
   Johansen D, 2010, IEEE INT CON MULTI, P1534, DOI 10.1109/ICME.2010.5583236
   Joho H, 2011, MULTIMED TOOLS APPL, V51, P505, DOI 10.1007/s11042-010-0632-x
   Joshi Vaishali M., 2022, ICDSMLA 2020: Proceedings of the 2nd International Conference on Data Science, Machine Learning and Applications. Lecture Notes in Electrical Engineering (783), P395, DOI 10.1007/978-981-16-3690-5_34
   kaggle, KAGGLE
   Kannan R, 2015, INFORM PROCESS MANAG, V51, P286, DOI 10.1016/j.ipm.2014.12.001
   Kasamwattanarote S, 2010, LECT NOTES COMPUT SC, V6297, P136, DOI 10.1007/978-3-642-15702-8_13
   Katti H., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P319, DOI 10.1109/ISM.2011.57
   Kavitha J, 2015, PROCEDIA COMPUT SCI, V47, P292, DOI 10.1016/j.procs.2015.03.209
   Kawai Y., 2007, P 6 ACM INT C IMAG, DOI [10.1145/1282280.1282287, DOI 10.1145/1282280.1282287]
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Kim G, 2014, PROC CVPR IEEE, P4225, DOI 10.1109/CVPR.2014.538
   Lee J., 2018, INT C LEARN REPR ICL
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lei J, 2019, IEEE T CIRC SYST VID, V29, P2126, DOI 10.1109/TCSVT.2018.2860797
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li BX, 2004, J VIS COMMUN IMAGE R, V15, P393, DOI 10.1016/j.jvcir.2004.04.006
   Li HR, 2019, IEEE T KNOWL DATA EN, V31, P996, DOI 10.1109/TKDE.2018.2848260
   Li P, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107677
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Liu CX, 2009, COMPUT VIS IMAGE UND, V113, P415, DOI 10.1016/j.cviu.2008.08.002
   Liu TR, 2022, IEEE T IMAGE PROCESS, V31, P1573, DOI 10.1109/TIP.2022.3143699
   Liu ZX, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820744
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Ma MY, 2022, IEEE T IMAGE PROCESS, V31, P1789, DOI 10.1109/TIP.2022.3146012
   Ma MY, 2020, NEUROCOMPUTING, V378, P197, DOI 10.1016/j.neucom.2019.07.108
   Mademlis I, 2018, INFORM SCIENCES, V432, P319, DOI 10.1016/j.ins.2017.12.020
   Mademlis I, 2016, IEEE T IMAGE PROCESS, V25, P5828, DOI 10.1109/TIP.2016.2615289
   Mahapatra A, 2016, SIGNAL PROCESS-IMAGE, V42, P31, DOI 10.1016/j.image.2016.01.002
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Masumitsu K, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P267, DOI 10.1109/ICIP.2000.899351
   Mehmood I, 2016, NEUROCOMPUTING, V174, P393, DOI 10.1016/j.neucom.2015.05.126
   Mendi E, 2013, COMPUT ELECTR ENG, V39, P790, DOI 10.1016/j.compeleceng.2012.11.020
   Meng JJ, 2017, IEEE INT CONF COMP V, P1189, DOI 10.1109/ICCVW.2017.144
   Miniakhmetova M, 2015, I C APPL INF COMM TE, P153, DOI 10.1109/ICAICT.2015.7338536
   MOCAP, ABOUT US
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Money AG, 2008, LECT NOTES COMPUT SC, V4868, P194, DOI 10.1007/978-3-540-85099-1_17
   Money AG, 2009, DISPLAYS, V30, P59, DOI 10.1016/j.displa.2008.12.003
   Muhammad K, 2020, IEEE INTERNET THINGS, V7, P4455, DOI 10.1109/JIOT.2019.2950469
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Nagar P, 2023, IEEE T PATTERN ANAL, V45, P6832, DOI 10.1109/TPAMI.2021.3118077
   Nitta N, 2009, MULTIMED TOOLS APPL, V41, P1, DOI 10.1007/s11042-008-0217-0
   Oh SM, 2011, PROC CVPR IEEE
   Oskouie P, 2014, ARTIF INTELL REV, V42, P173, DOI 10.1007/s10462-012-9332-4
   Ou SH, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2331916
   Pan G, 2018, LECT NOTES COMPUT SC, V11166, P112, DOI 10.1007/978-3-030-00764-5_11
   Panagiotakis Costas, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P305, DOI 10.1007/978-3-030-45442-5_38
   Panda R, 2017, IEEE I CONF COMP VIS, P3677, DOI 10.1109/ICCV.2017.395
   Panda R, 2017, IEEE T MULTIMEDIA, V19, P2010, DOI 10.1109/TMM.2017.2708981
   Panda R, 2017, IEEE T IMAGE PROCESS, V26, P4712, DOI 10.1109/TIP.2017.2708902
   Panda R, 2014, INT C PATT RECOG, P3481, DOI 10.1109/ICPR.2014.599
   Papadopoulos DP, 2013, EXPERT SYST APPL, V40, P5765, DOI 10.1016/j.eswa.2013.02.016
   Parihar AS, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102991
   Pei MT, 2011, IEEE I CONF COMP VIS, P487, DOI 10.1109/ICCV.2011.6126279
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Qayyum H, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102672
   Rochan M, 2019, PROC CVPR IEEE, P7894, DOI 10.1109/CVPR.2019.00809
   Sah S, 2017, IEEE WINT CONF APPL, P989, DOI 10.1109/WACV.2017.115
   Sahu A, 2021, PATTERN RECOGN LETT, V146, P185, DOI 10.1016/j.patrec.2021.03.013
   Sahu A, 2021, IEEE T IMAGE PROCESS, V30, P4330, DOI 10.1109/TIP.2021.3070732
   Sahu A, 2020, NEUROCOMPUTING, V398, P209, DOI 10.1016/j.neucom.2020.02.099
   Sanabria M., 2021, P 2020 25 INT C PATT
   Saravanou Antonia, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P352, DOI 10.1007/978-3-030-45442-5_44
   Seman N, 2015, PROCEDIA COMPUT SCI, V51, P620, DOI 10.1016/j.procs.2015.05.330
   Shen JL, 2011, MULTIMEDIA SYST, V17, P421, DOI 10.1007/s00530-010-0223-8
   Shukla P, 2018, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2018.00233
   Singhal A, 2018, COGN SYST RES, V52, P917, DOI 10.1016/j.cogsys.2018.09.019
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Song YL, 2015, PROC CVPR IEEE, P5179, DOI 10.1109/CVPR.2015.7299154
   Sreeja MU, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107161
   Sreeja MU, 2019, J VIS COMMUN IMAGE R, V62, P340, DOI 10.1016/j.jvcir.2019.06.004
   Sridevi M, 2020, PROCEDIA COMPUT SCI, V167, P1839, DOI 10.1016/j.procs.2020.03.203
   Subudhi BN, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113341
   Sun M, 2014, LECT NOTES COMPUT SC, V8689, P787, DOI 10.1007/978-3-319-10590-1_51
   Tang Anthony., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. CHI '12, P1569
   Tejero-de-Pablos A, 2016, IEEE INT CON MULTI
   Tejero-de-Pablos A, 2018, IEEE T MULTIMEDIA, V20, P2000, DOI 10.1109/TMM.2018.2794265
   Theodoridis T, 2016, IEEE IMAGE PROC, P3947, DOI 10.1109/ICIP.2016.7533100
   Thomas SS, 2018, IEEE T INTELL TRANSP, V19, P2944, DOI 10.1109/TITS.2017.2769719
   Thomas SS, 2017, IEEE T CIRC SYST VID, V27, P1790, DOI 10.1109/TCSVT.2016.2556558
   Traver VJ, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116079
   TRECVID, TRECVID
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Ukita N, 2017, INT C ADV COMP SCI I, P9, DOI 10.1109/ICACSIS.2017.8355005
   Varini P, 2017, IEEE T MULTIMEDIA, V19, P2832, DOI 10.1109/TMM.2017.2705915
   Vasconcelos N, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P153, DOI 10.1109/ICIP.1998.999006
   Vivekraj VK, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3347712
   Vivekraj VK, 2016, INT C PATT RECOG, P871, DOI 10.1109/ICPR.2016.7899745
   Vladimirova M, 2019, PR MACH LEARN RES, V97
   Wang H, 2020, MULTIMED TOOLS APPL, V79, P15015, DOI 10.1007/s11042-020-08668-1
   Wang LB, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P179, DOI 10.1109/CW.2016.38
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Wu F, 2016, IEEE T CIRC SYST VID, V26, P1931, DOI 10.1109/TCSVT.2015.2477938
   Wu JX, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107382
   Xiao SW, 2020, IEEE T IMAGE PROCESS, V29, P5889, DOI 10.1109/TIP.2020.2985868
   Xu J, 2015, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2015.7298836
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yeung S., 2014, arXiv
   Yin YF, 2018, IEEE T CIRC SYST VID, V28, P181, DOI 10.1109/TCSVT.2016.2602832
   Yoshitaka A, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P661, DOI 10.1109/SITIS.2012.100
   Zawbaa HM, 2011, COMM COM INF SC, V263, P19
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang YF, 2009, MULTIMED TOOLS APPL, V44, P305, DOI 10.1007/s11042-009-0291-y
   Zhang YJ, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106913
   Zhang YJ, 2020, PATTERN RECOGN LETT, V130, P376, DOI 10.1016/j.patrec.2018.07.030
   Zhao B, 2023, IEEE T NEUR NET LEAR, V34, P5181, DOI 10.1109/TNNLS.2021.3119969
   Zhao B, 2022, IEEE T PATTERN ANAL, V44, P2793, DOI 10.1109/TPAMI.2021.3072117
   Zhao B, 2021, IEEE T IND ELECTRON, V68, P3629, DOI 10.1109/TIE.2020.2979573
   Zhao B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P863, DOI 10.1145/3123266.3123328
   Zhao B, 2018, PROC CVPR IEEE, P7405, DOI 10.1109/CVPR.2018.00773
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
   Zhu SH, 2010, LECT NOTES COMPUT SC, V6297, P308, DOI 10.1007/978-3-642-15702-8_28
   Zimmerman J., 2003, CHI 03 EXTENDED ABST, DOI [10.1145/765891.766058, DOI 10.1145/765891.766058]
   Zlatintsi A., 2015 7 INT WORKSH QU, DOI [10.1109/qomex.2015.7148146, DOI 10.1109/QOMEX.2015.7148146]
   Zlatintsi A, 2015, EUR SIGNAL PR CONF, P2311, DOI 10.1109/EUSIPCO.2015.7362797
NR 183
TC 3
Z9 3
U1 9
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103670
DI 10.1016/j.jvcir.2022.103670
EA OCT 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V0XW
UT WOS:000876962300001
DA 2024-07-18
ER

PT J
AU Shamsuddin, AF
   Ragunathan, K
   Abhijith, P
   Sekar, PMDR
   Sankaran, P
AF Shamsuddin, Abdul Fathaah
   Ragunathan, Krupasankari
   Abhijith, P.
   Sekar, P. M. Deepak Raja
   Sankaran, Praveen
TI From synthetic to natural - single natural image dehazing deep networks
   using synthetic dataset domain randomization?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dehazing; Deep learning; Domain randomization; Dataset
AB Image dehazing methods aim to solve the problem of poor visibility in images due to haze. Techniques proposed for image dehazing in literature focus on image priors, haze lines or data driven statistical models. Variations of the classical methods relying on prior model or haze line model use no-reference image quality metrics to prove their dehazing performance. Recently developed deep learning models rely on huge amounts of hazy, haze-free pairs for training, and uses PSNR and SSIM like image reconstruction metrics to show their performance. These methods perform poorly on no-reference image quality assessments and also dehazes poorly at the depths of the image. These methods though can be optimized for memory usage and are faster. This work presents a deep learning model (Feature Fusion Attention Network) trained on a domain randomized synthetic dataset generated in simulation. The proposed model achieves the highest scores on blind image assessments through the gradient rationing technique for a deep learning-based approach by a significant margin. The images were evaluated on full-reference metrics as well and obtained favorable results. This approach also yields one of the highest edge sharpness obtained after dehazing. The training procedure adopted to obtain significant gains on real-world dehazing, without using any real-world data is also detailed in this paper.
C1 [Shamsuddin, Abdul Fathaah; Ragunathan, Krupasankari; Abhijith, P.; Sekar, P. M. Deepak Raja; Sankaran, Praveen] Natl Inst Technol Calicut, Dept Elect & Commun Engn, Kattangal, India.
   [Sankaran, Praveen] NIT Calicut, Dept Elect & Commun Engn, Kozhikode 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut; National Institute of Technology (NIT System);
   National Institute of Technology Calicut
RP Shamsuddin, AF (corresponding author), Natl Inst Technol Calicut, Dept Elect & Commun Engn, Kattangal, India.
EM psankaran@nitc.ac.in
OI Shamsuddin, Abdul Fathaah/0000-0001-7721-2296
CR Ancuti CO, 2021, IEEE COMPUT SOC CONF, P627, DOI 10.1109/CVPRW53098.2021.00074
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Anvari Z, 2020, Arxiv, DOI arXiv:2008.06632
   Bae W, 2017, IEEE COMPUT SOC CONF, P1141, DOI 10.1109/CVPRW.2017.152
   Bastidas AA, 2019, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2019.00117
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bousmalis K, 2017, Arxiv, DOI arXiv:1612.05424
   Cai BL, 2016, Arxiv, DOI arXiv:1601.07661
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Clevert DA, 2016, Arxiv, DOI arXiv:1511.07289
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu MH, 2021, IEEE COMPUT SOC CONF, P203, DOI 10.1109/CVPRW53098.2021.00029
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jhang Y.-C., 2020, Training a performant object detection ML model on synthetic data using unity perception tools
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Mehta A, 2020, IEEE COMPUT SOC CONF, P846, DOI 10.1109/CVPRW50498.2020.00114
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Owusu-Agyeman Prince, 2019, International Journal of Computer and Electrical Engineering, V11, P118, DOI 10.17706/ijcee.2019.11.3.118-132
   Prakash A, 2019, IEEE INT CONF ROBOT, P7249, DOI [10.1109/icra.2019.8794443, 10.1109/ICRA.2019.8794443]
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Saxena D, 2020, Arxiv, DOI arXiv:2005.00065
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Shamsuddin A.F., 2021, 2021 NATL C COMMUNIC
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tobin J, 2017, Arxiv, DOI [arXiv:1703.06907, DOI 10.48550/ARXIV.1703.06907]
   Unity Technologies, UN SOFTW
   Unity Technologies, UN HIGH DEF REND PIP
   Venkatanath N, 2015, NATL CONF COMMUN
   Vuong Q, 2019, Arxiv, DOI arXiv:1903.11774
   Weng L., 2019, Domain randomization for Sim2Real transfer
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Yang X, 2021, IET IMAGE PROCESS, V15, P2508, DOI 10.1049/ipr2.12236
   Yang X, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103019
   Yang X, 2021, MULTIMED TOOLS APPL, V80, P7063, DOI 10.1007/s11042-020-09958-4
NR 49
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103636
DI 10.1016/j.jvcir.2022.103636
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300008
DA 2024-07-18
ER

PT J
AU Rossi, L
   Karimi, A
   Prati, A
AF Rossi, Leonardo
   Karimi, Akbar
   Prati, Andrea
TI Self-Balanced R-CNN for instance segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Instance segmentation; Imbalance in R-CNN networks;
   Two-stage deep learning architectures
ID PROPOSAL
AB Current state-of-the-art two-stage models on instance segmentation task suffer from several types of imbalances. In this paper, we address the Intersection over the Union (IoU) distribution imbalance of positive input Regions of Interest (RoIs) during the training of the second stage. Our Self-Balanced R-CNN (SBR-CNN), an evolved version of the Hybrid Task Cascade (HTC) model, brings brand new loop mechanisms of bounding box and mask refinements. With an improved Generic RoI Extraction (GRoIE), we also address the feature-level imbalance at the Feature Pyramid Network (FPN) level, originated by a non-uniform integration between lowand high-level features from the backbone layers. In addition, the redesign of the architecture heads toward a fully convolutional approach with FCC further reduces the number of parameters and obtains more clues to the connection between the task to solve and the layers used. Moreover, our SBR-CNN model shows the same or even better improvements if adopted in conjunction with other state-of-the-art models. In fact, with a lightweight ResNet-50 as backbone, evaluated on COCO minival 2017 dataset, our model reaches 45.3% and 41.5% AP for object detection and instance segmentation, with 12 epochs and without extra tricks. The code is available at https://github.com/IMPLabUniPr/mmdetection/tree/sbr_cnn.
C1 [Rossi, Leonardo; Karimi, Akbar; Prati, Andrea] Univ Parma, Dept Engn & Architecture, Parco Area Sci 181-A, I-43124 Parma, Italy.
C3 University of Parma
RP Rossi, L (corresponding author), Univ Parma, Dept Engn & Architecture, Parco Area Sci 181-A, I-43124 Parma, Italy.
EM leonardo.rossi@unipr.it; akbar.karimi@unipr.it; andrea.prati@unipr.it
RI ; Prati, Andrea/B-7440-2014
OI Rossi, Leonardo/0000-0002-9316-595X; Karimi, Akbar/0000-0002-5132-2435;
   Prati, Andrea/0000-0002-1211-529X
FU International Foundation Big Data and Artificial Intelligence for Human
   Development (IFAB) through the project ``ROADSTER: ROAd Digital
   Sustainable Twins in EmiliaRomagna
FX This project is partially funded by International Foundation Big Data
   and Artificial Intelligence for Human Development (IFAB) through the
   project ``ROADSTER: ROAd Digital Sustainable Twins in EmiliaRomagna:
   Artificial intelligence for industrial areas''.
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen H, 2017, MED IMAGE ANAL, V36, P135, DOI 10.1016/j.media.2016.11.004
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Cheng BW, 2018, LECT NOTES COMPUT SC, V11219, P473, DOI 10.1007/978-3-030-01267-0_28
   Elkan C., 2001, P 17 INT JOINT C ART, V17, P973
   Ge YY, 2019, IFAC PAPERSONLINE, V52, P294, DOI 10.1016/j.ifacol.2019.12.537
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guanglu Song, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11560, DOI 10.1109/CVPR42600.2020.01158
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang LQ, 2019, IEEE ACCESS, V7, P46059, DOI 10.1109/ACCESS.2019.2907984
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Linh T.D., 2018, INT J COMPUT THEORY, V10
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Masnadi-Shirazi H, 2011, IEEE T PATTERN ANAL, V33, P294, DOI 10.1109/TPAMI.2010.71
   Oksuz K, 2020, IEEE WINT CONF APPL, P883, DOI [10.1109/WACV45572.2020.9093503, 10.1109/wacv45572.2020.9093503]
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1476, DOI 10.1109/TPAMI.2016.2601099
   Rossi L, 2021, LECT NOTES COMPUT SC, V13052, P476, DOI 10.1007/978-3-030-89128-2_46
   Rossi L, 2021, INT C PATT RECOG, P2203
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Vu T, 2019, ADV NEUR IN, V32
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu H, 2019, IEEE I CONF COMP VIS, P6648, DOI 10.1109/ICCV.2019.00675
   Yue Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10183, DOI 10.1109/CVPR42600.2020.01020
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhi Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P282, DOI 10.1007/978-3-030-58452-8_17
   Zhong QY, 2020, NEUROCOMPUTING, V395, P170, DOI 10.1016/j.neucom.2017.12.070
   Zhu L, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2021.107816
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 51
TC 3
Z9 3
U1 4
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103595
DI 10.1016/j.jvcir.2022.103595
EA AUG 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4U2UR
UT WOS:000858655700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, XY
   Shen, X
   Niu, PP
   Yang, HY
AF Wang, Xiang-yang
   Shen, Xin
   Niu, Pan-pan
   Yang, Hong-ying
TI BGGMM-HMT based locally optimum image watermark detector in high-order
   NSST difference domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking; Statistical watermark detector; High-order
   difference coefficients; Bounded generalized Gaussian mixture; Hidden
   Markov tree; Nonsubsampled Shearlet transform
ID HIDDEN MARKOV MODEL; DECODER
AB Imperceptibility, robustness and data payload are three main requirements of any image watermarking systems to guarantee desired functionalities, but there is a tradeoff among them from the information-theoretic perspective. How to achieve this balance is a major challenge. In this paper, we propose a new statistical image watermarking scheme, which is based on the high-order difference coefficients in nonsubsampled Shearlet transform (NSST) domain and the bounded generalized Gaussian mixture model-based hidden Markov tree (BGGMM-HMT). In the watermark embedding process, we use a nonlinear embedding approach to hide the digital watermark into the robust high-order difference coefficients, which can achieve better imperceptibility. In the watermark detection process, high-order difference coefficients are accurately modeled by using BGGMMHMT, where the distribution characteristics of high-order difference coefficients can be captured through BGGMM, and the scale dependencies of high-order difference coefficients can be captured through HMT. Statistical model parameters are then estimated by combining the approach of minimizing the higher bound on data negative log-likelihood function and upward-downward algorithm. Finally, an image watermark detector based on BGGMM-HMT is developed using the locally optimum (LO) decision rule. For the proposed detector, the receiver operating characteristic (ROC) expression is derived in detail. We evaluate the proposed scheme from different aspects and compare it with the state-of-the-art schemes. After a large number of experimental tests, the encouraging results obtained prove the effectiveness of our watermarking scheme.
C1 [Wang, Xiang-yang; Shen, Xin; Niu, Pan-pan; Yang, Hong-ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023; Shen, Xin/JBI-6913-2023; Niu,
   Panpan/Q-9953-2017
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61701212];
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKZ0985]; Natural Science Foundation of Liaoning Province
   [2019-ZD-0468]
FX Acknowledgments This work was supported partially by the National
   Natural Science Foundation of China (Nos. 61472171 & 61701212) ,
   Scientific Research Project of Liaoning Provincial Education Department
   (No. LJKZ0985) ,and Natural Science Foundation of Liaoning Province
   (2019-ZD-0468) .
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Amini M, 2017, IEEE INT SYMP CIRC S
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, MIDWEST SYMP CIRCUIT, P611, DOI 10.1109/MWSCAS.2017.8052997
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Amini M, 2017, MULTIMED TOOLS APPL, V76, P3731, DOI 10.1007/s11042-016-3975-0
   Amirmazlaghani M, 2019, IET COMPUT VIS, V13, P249, DOI 10.1049/iet-cvi.2018.5254
   Amirmazlaghani M, 2017, LECT NOTES COMPUT SC, V10485, P547, DOI 10.1007/978-3-319-68548-9_50
   Amirmazlaghani M, 2016, INFORM SCIENCES, V370, P1, DOI 10.1016/j.ins.2016.06.037
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   [Anonymous], 2012, Signal Detection in Non-Gaussian Noise
   Barazandeh M, 2016, 2016 2ND INTERNATIONAL CONFERENCE OF SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P98
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Bi HB, 2016, MATH PROBL ENG, V7, P1
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Etemad S, 2016, 2016 2ND INTERNATIONAL CONFERENCE OF SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), P103
   Fisher NI, 2001, AM STAT, V55, P233, DOI 10.1198/000313001317098248
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Koen JD, 2017, BEHAV RES METHODS, V49, P1399, DOI 10.3758/s13428-016-0796-z
   Kutyniok G., 2005, Wavelets XI, V5914, P254, DOI DOI 10.1117/12.613494
   Liu JH, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P668, DOI 10.1109/ICIVC.2018.8492868
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P33071, DOI 10.1007/s11042-020-09621-y
   Niu PP, 2021, CIRC SYST SIGNAL PR, V40, P4516, DOI 10.1007/s00034-021-01678-w
   Niu PP, 2020, IEEE ACCESS, V8, P46624, DOI 10.1109/ACCESS.2020.2978119
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Sadreazami H, 2015, IEEE T CIRCUITS-II, V62, P1159, DOI 10.1109/TCSII.2015.2468995
   Sadreazami H, 2015, IEEE INT SYMP CIRC S, P1050, DOI 10.1109/ISCAS.2015.7168817
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Nguyen TM, 2014, PATTERN RECOGN, V47, P3132, DOI 10.1016/j.patcog.2014.03.030
   Wang XY, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115972
   Wang XY, 2020, INFORM SCIENCES, V535, P81, DOI 10.1016/j.ins.2020.05.034
   Wang XY, 2019, J VIS COMMUN IMAGE R, V62, P309, DOI 10.1016/j.jvcir.2019.05.012
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
NR 40
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103450
DI 10.1016/j.jvcir.2022.103450
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800006
DA 2024-07-18
ER

PT J
AU Ma, XL
   Wang, ZH
   Hu, SH
AF Ma, Xiaole
   Wang, Zhihai
   Hu, Shaohai
TI Multi-focus image fusion based on multi-scale sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-scale decomposition; Sparse representation; Adaptive fusion rule;
   Sum modified Laplacian; Multi-focus image fusion
ID ALGORITHM; INFORMATION; PERFORMANCE; FRAMEWORK; TRANSFORM
AB Although colorful information in natural scenes can be collected, due to the limitation of camera depth of field, it is hard to capture an image with all-in-focus. Sparse representation (SR)-based methods have shown their powerful potentiality and ability in multi-focus image fusion. However, because of sparse coding and information compress, the existing fusion methods based on SR are imperfect to seize the rich details and significant texture information in source images. As a result, a fusion method based on multi-scale sparse representation for registered multi-focus images (MIF-MsSR) is proposed in this paper, where an adaptive fusion rule for sparse coefficients is presented. At first, source images are processed by multi-scale decomposition and sub-images with different scales can be obtained. According to image features with different richness in these sub-images, dictionaries with different sizes and redundancy are thereby trained. By comprehensively considering the relationships of focused areas, out-of-focused areas and boundary areas between the source images, an adaptive fusion rule based on l(0) - max and Sum Modified Laplacian (SML) is proposed. Finally, a fused image with all-in-focus can be obtained by sparse reconstruction and inverse multi-scale decomposition. Excessive experiments on multi-focus images have demonstrated that the proposed MIF-MsSR not only reserves the integrity of the information in source images, but also has better fusion performance on subjective and objective indicators than other state-of-the-art methods.
C1 [Ma, Xiaole; Wang, Zhihai; Hu, Shaohai] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
   [Ma, Xiaole; Hu, Shaohai] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Ma, XL (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM maxiaole@bjtu.edu.cn
OI Ma, Xiaole/0000-0001-7578-7969
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Bashir R, 2019, MULTIMED TOOLS APPL, V78, P1235, DOI 10.1007/s11042-018-6229-5
   Bavirisetti DP, 2018, AIN SHAMS ENG J, V9, P1103, DOI 10.1016/j.asej.2016.06.011
   Chen J., IEEE T MULTIMED, P1
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Dian RW, 2019, INFORM FUSION, V49, P262, DOI 10.1016/j.inffus.2018.11.012
   Ding SF, 2018, IET COMPUT VIS, V12, P377, DOI 10.1049/iet-cvi.2017.0285
   Dong YS, 2018, VISUAL COMPUT, V34, P1315, DOI 10.1007/s00371-017-1415-4
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gai D, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107681
   Ganasala P, 2016, J DIGIT IMAGING, V29, P73, DOI 10.1007/s10278-015-9806-4
   Jiao Y, 2019, IEEE J BIOMED HEALTH, V23, P631, DOI 10.1109/JBHI.2018.2832538
   Li H, 2019, IEEE T EVOLUT COMPUT, V23, P733, DOI 10.1109/TEVC.2018.2881955
   Li LL, 2020, MULTIMED TOOLS APPL, V79, P24303, DOI 10.1007/s11042-020-09154-4
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li WS, 2019, IEEE ACCESS, V7, P173019, DOI 10.1109/ACCESS.2019.2953786
   Liang XC, 2019, IEEE SENS J, V19, P7107, DOI 10.1109/JSEN.2019.2913281
   Liang Y, 2020, ACM T MULTIM COMPUT, V16
   Liao B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9173612
   Liu XB, 2019, INT J THEOR PHYS, V58, P734, DOI 10.1007/s10773-018-3971-4
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Ma J., IEEE T COMPUT IMAGIN, P1
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Panigrahy C, 2020, APPL OPTICS, V59, P5642, DOI 10.1364/AO.391234
   Panigrahy C, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106141
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Srivastava G, 2019, IEEE MULTIMEDIA, V26, P7, DOI 10.1109/MMUL.2019.2915078
   Sun L, 2016, MULTIMED TOOLS APPL, V75, P667, DOI 10.1007/s11042-014-2314-6
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang SC, 2019, IEEE T INF FOREN SEC, V14, P251, DOI 10.1109/TIFS.2018.2849883
   Yang YK, 2020, FUTURE GENER COMP SY, V112, P243, DOI 10.1016/j.future.2020.05.016
   Yin M, 2014, OPTIK, V125, P2274, DOI 10.1016/j.ijleo.2013.10.064
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang Q, 2018, PATTERN RECOGN, V83, P299, DOI 10.1016/j.patcog.2018.06.003
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhao W, 2018, J SYST ENG ELECTRON, V29, P471, DOI 10.21629/JSEE.2018.03.04
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 52
TC 8
Z9 8
U1 4
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103328
DI 10.1016/j.jvcir.2021.103328
EA OCT 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700005
DA 2024-07-18
ER

PT J
AU Hussain, I
   Tan, SQ
   Li, B
   Qin, XH
   Hussain, D
   Huang, JW
AF Hussain, Israr
   Tan, Shunquan
   Li, Bin
   Qin, Xinghong
   Hussain, Dostdar
   Huang, Jiwu
TI A novel deep learning framework for double JPEG compression detection of
   small size blocks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia forensics; Discrete cosine transform; Deep learning; Double
   JPEG compression; Convolutional neural network
AB Double JPEG compression detection plays a vital role in multimedia forensics, to find out whether a JPEG image is authentic or manipulated. However, it still remains to be a challenging task in the case when the quality factor of the first compression is much higher than that of the second compression, as well as in the case when the targeted image blocks are quite small. In this work, we present a novel end-to-end deep learning framework taking raw DCT coefficients as input to distinguish between single and double compressed images, which performs superior in the above two cases. Our proposed framework can be divided into two stages. In the first stage, we adopt an auxiliary DCT layer with sixty-four 8 x 8 DCT kernels. Using a specific layer to extract DCT coefficients instead of extracting them directly from JPEG bitstream allows our proposed framework to work even if the double compressed images are stored in spatial domain, e.g. in PGM, TIFF or other bitmap formats. The second stage is a deep neural network with multiple convolutional blocks to extract more effective features. We have conducted extensive experiments on three different image datasets. The experimental results demonstrate the superiority of our framework when compared with other state-of-the-art double JPEG compression detection methods either hand-crafted or learned using deep networks in the literature, especially in the two cases mentioned above. Furthermore, our proposed framework can detect triple and even multiple JPEG compressed images, which is scarce in the literature as far as we know.
C1 [Tan, Shunquan] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.
   [Hussain, Israr; Tan, Shunquan; Li, Bin; Qin, Xinghong; Huang, Jiwu] Guangdong Lab Artificial Intelligence & Digital E, Guangdong Key Lab Intelligent Informat Proc, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Hussain, Israr; Tan, Shunquan; Li, Bin; Qin, Xinghong; Huang, Jiwu] Shenzhen Univ, Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen 518000, Peoples R China.
   [Hussain, Dostdar] Karakoram Int Univ Gilgit, Dept Comp Sci, Gilgit 15100, Pakistan.
C3 Shenzhen University; Guangming Laboratory; Shenzhen University; Shenzhen
   Institute of Artificial Intelligence & Robotics for Society
RP Tan, SQ (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen 518060, Peoples R China.; Tan, SQ (corresponding author), Guangdong Lab Artificial Intelligence & Digital E, Guangdong Key Lab Intelligent Informat Proc, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.; Tan, SQ (corresponding author), Shenzhen Univ, Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen 518000, Peoples R China.
EM tansq@szu.edu.cn
RI Hussain, Israr/GQZ-2944-2022; huang, jw/KVY-9917-2024
OI Hussain, Israr/0000-0001-6579-1016; 
CR Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2003, P DIG FOR RES WORKSH
   Ayaburi EW, 2020, INT J INFORM MANAGE, V50, P171, DOI 10.1016/j.ijinfomgt.2019.05.014
   Bakas J, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.2.023006
   Barni M, 2017, J VIS COMMUN IMAGE R, V49, P153, DOI 10.1016/j.jvcir.2017.09.003
   Barni M, 2016, IEEE INT WORKS INFOR
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bhardwaj D, 2018, SIGNAL PROCESS-IMAGE, V68, P155, DOI 10.1016/j.image.2018.07.011
   Cogranne R, 2020, ALASKA CHALLENGE
   Deng C, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3301274
   Deshpande Ajit Umesh, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P828, DOI 10.1109/SPIN48934.2020.9070977
   Finizola JS, 2018, LECT NOTES ARTIF INT, V11238, P217, DOI 10.1007/978-3-030-03928-8_18
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Hussain I, 2020, KSII T INTERNET INF, V14, P1228, DOI 10.3837/tiis.2020.03.017
   Kingma D. P., 2014, arXiv
   Li B, 2019, MULTIMED TOOLS APPL, V78, P8577, DOI 10.1007/s11042-018-7073-3
   Liu XJ, 2020, MULTIMED TOOLS APPL, V79, P12891, DOI 10.1007/s11042-019-08519-8
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P27
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Verma V, 2018, SIGNAL PROCESS-IMAGE, V67, P22, DOI 10.1016/j.image.2018.04.014
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Wang JW, 2020, J REAL-TIME IMAGE PR, V17, P7, DOI 10.1007/s11554-019-00929-z
   Wang Q, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0047-y
   Wang ZF, 2017, INT CONF MACH LEARN, P379
   Yang PP, 2020, J IMAGING, V6, DOI 10.3390/jimaging6030009
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107430
   Zeng XM, 2019, MULTIMED TOOLS APPL, V78, P8183, DOI 10.1007/s11042-018-6737-3
   Zhang QC, 2018, INFORM FUSION, V42, P146, DOI 10.1016/j.inffus.2017.10.006
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 35
TC 8
Z9 9
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103269
DI 10.1016/j.jvcir.2021.103269
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600003
DA 2024-07-18
ER

PT J
AU Yao, P
   Feng, JQ
AF Yao, Peng
   Feng, Jieqing
TI Stacking learning with coalesced cost filtering for accurate stereo
   matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Stacking; Random Forest; One-view disparity refinement
ID AGGREGATION
AB Deep learning based stereo matching algorithms have produced impressive disparity estimation for recent years; and the success of them has once overshadowed the conventional ones. In this paper, we intend to reverse this inferiority, by leveraging Stacking Learning with Coalesced Cost Filtering to make the conventional algorithms achieve or even surpass the results of deep learning ones. Four classical and Discriminative Dictionary Learning (DDL) algorithms are adopted as base-models for Stacking. For the former ones, four classical stereo matching algorithms are employed and regarded as 'Coalesced Cost Filtering Module'; for the latter supervised learning one, we utilize the Discriminative Dictionary Learning (DDL) stereo matching algorithm. Then three categories of features are extracted from the predictions of base-models to train the meta-model. For the meta-model (final classifier) of Stacking, the Random Forest (RF) classifier is selected. In addition, we also employ an advanced one-view disparity refinement strategy to compute the final refined results more efficiently. Performance evaluations on Middlebury v.2 and v.3 stereo data sets demonstrate that the proposed algorithm outperforms other four most challenging stereo matching algorithms. Besides, the submitted online results even show better results than deep learning ones.
C1 [Yao, Peng; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou, Peoples R China.
EM jqfeng@cad.zju.edu.cn
FU National Natural Science Foundation of China [61732015, 61932018,
   61472349]
FX This work was jointly supported by the National Natural Science
   Foundation of China under Grants Nos. 61732015, 61932018 and 61472349.
CR [Anonymous], 2016, J MACH LEARN RES
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Batsos K, 2018, PROC CVPR IEEE, P2060, DOI 10.1109/CVPR.2018.00220
   Besse F, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.132
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Birchfield S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1073, DOI 10.1109/ICCV.1998.710850
   Bleyer M, 2013, ADV COMPUT VIS PATT, P143, DOI 10.1007/978-1-4471-5520-1_6
   Cao CJ, 2018, KNOWL-BASED SYST, V150, P27, DOI 10.1016/j.knosys.2018.02.031
   Chen DM, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.96
   Chen DM, 2015, IEEE T CIRC SYST VID, V25, P730, DOI 10.1109/TCSVT.2014.2361422
   Facciolo G., 2015, Procedings of the British Machine Vision Conference 2015 (Swansea: British Machine Vision Association), p90.1, DOI DOI 10.5244/C.29.90
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Haeusler R, 2013, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2013.46
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Keselman L, 2017, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2017.167
   Knöbelreiter P, 2017, PROC CVPR IEEE, P1456, DOI 10.1109/CVPR.2017.159
   Maringer D, 2014, IEEE C COMP INTEL FI, P407, DOI 10.1109/CIFEr.2014.6924102
   Mei X, 2013, PROC CVPR IEEE, P313, DOI 10.1109/CVPR.2013.47
   Mozerov MG, 2019, IEEE T IMAGE PROCESS, V28, P2936, DOI 10.1109/TIP.2019.2892668
   Park MG, 2015, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2015.7298605
   Poggi M, 2016, INT CONF 3D VISION, P509, DOI 10.1109/3DV.2016.61
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Seki A, 2017, PROC CVPR IEEE, P6640, DOI 10.1109/CVPR.2017.703
   Spyropoulos A, 2016, INT J COMPUT VISION, V118, P300, DOI 10.1007/s11263-015-0877-y
   Spyropoulos A, 2014, PROC CVPR IEEE, P1621, DOI 10.1109/CVPR.2014.210
   Taniai T, 2018, IEEE T PATTERN ANAL, V40, P2725, DOI 10.1109/TPAMI.2017.2766072
   Taniai T, 2014, PROC CVPR IEEE, P1613, DOI 10.1109/CVPR.2014.209
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tosic I, 2011, IEEE J-STSP, V5, P941, DOI 10.1109/JSTSP.2011.2158063
   Tulyakov S, 2017, IEEE I CONF COMP VIS, P1348, DOI 10.1109/ICCV.2017.150
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Yan TM, 2019, IEEE T IMAGE PROCESS, V28, P3885, DOI 10.1109/TIP.2019.2903318
   Yang QQ, 2015, IEEE SIGNAL PROC LET, V22, P1429, DOI 10.1109/LSP.2015.2409203
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yao P, 2019, IET IMAGE PROCESS, V13, P98, DOI 10.1049/iet-ipr.2018.5801
   Yao P, 2018, IET COMPUT VIS, V12, P908, DOI 10.1049/iet-cvi.2017.0599
   Yao P, 2018, LECT NOTES COMPUT SC, V10704, P67, DOI 10.1007/978-3-319-73603-7_6
   Yin JH, 2017, PATTERN RECOGN, V71, P278, DOI 10.1016/j.patcog.2017.06.015
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang C, 2014, LECT NOTES COMPUT SC, V8690, P112, DOI 10.1007/978-3-319-10605-2_8
   Zhang K, 2017, IEEE T CIRC SYST VID, V27, P965, DOI 10.1109/TCSVT.2015.2513663
NR 51
TC 4
Z9 4
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103169
DI 10.1016/j.jvcir.2021.103169
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LW
UT WOS:000674617500003
DA 2024-07-18
ER

PT J
AU Hagag, A
   Omara, I
   Chaib, S
   Ma, GZ
   Abd El-Samie, FE
AF Hagag, Ahmed
   Omara, Ibrahim
   Chaib, Souleyman
   Ma, Guangzhi
   Abd El-Samie, Fathi E.
TI Dual link distributed source coding scheme for the transmission of
   satellite hyperspectral imagery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral image compression; Temporal redundancy in hyperspectral
   images; Dual link; Distributed source coding (DSC); Coset values;
   Lossless compression
ID SCALAR DEADZONE QUANTIZATION; LOSSLESS COMPRESSION
AB Traditional lossless compression methods for satellite hyperspectral imagery focus on exploiting spatial and/or spectral redundancy. Those methods do not consider the temporal redundancy between images of the same area that are captured at different times. To exploit the temporal redundancy between hyperspectral images and reduce the amount of information to be transmitted from the space-satellite to the ground station via the downlink, this paper introduces a dual link distributed source coding (DLDSC) scheme for hyperspectral spacesatellite communication. The proposed scheme employs the space-satellite dual link (i.e., the downlink and the uplink). The satellite onboard uses some side information from the ground station to calculate the hyperspectral image band coset values, and then, without syndrome coding, transmits to the ground station via the downlink. Coset coding is a typical technique used in distributed source coding (DSC), and here the coset values represent the timely hyperspectral image details. Typically, the coset values have lower entropy than that of the original source values. To exploit the temporal redundancy, the side information is computed in the ground station using the image captured at the previous time for the same area and transmitted to the space-satellite via the uplink. Hyperspectral images from the Hyperion satellite are used for the validation of the proposed scheme. The experimental results indicate that the proposed DLDSC scheme can reduce the original signal entropy by approximately 3.2 bits per sample (bps) and can achieve up to 1.0 bps and 1.6 bps gains over the lossless JPEG2000 standard and the state-of-art predictive CCSDS-123 method, respectively.
C1 [Hagag, Ahmed] Benha Univ, Fac Comp & Artificial Intelligence, Dept Sci Comp, Banha 13518, Egypt.
   [Omara, Ibrahim; Ma, Guangzhi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Omara, Ibrahim] Menoufia Univ, Fac Sci, Dept Math & Comp Sci, Shebin El Kam 32511, Egypt.
   [Chaib, Souleyman] Ecole Super Informat, LabRI, SBA Lab, Sidi Bel Abbes, Algeria.
   [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [Abd El-Samie, Fathi E.] Princess Nourah Bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, Riyadh 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Benha University; Huazhong University of
   Science & Technology; Egyptian Knowledge Bank (EKB); Menofia University;
   Egyptian Knowledge Bank (EKB); Menofia University; Princess Nourah bint
   Abdulrahman University
RP Hagag, A (corresponding author), Benha Univ, Fac Comp & Artificial Intelligence, Dept Sci Comp, Banha 13518, Egypt.
EM ahagag@fci.bu.edu.eg
RI CHAIB, Souleyman/JGM-1568-2023; Sayed, Fathi/HRA-4752-2023; Omara,
   Ibrahim/ABG-5600-2020; omara, ibrahim/JWO-4261-2024
OI Sayed, Fathi/0000-0001-8749-9518; Omara, Ibrahim/0000-0003-3243-990X;
   chaib, souleyman/0000-0002-5911-3128; Hagag, Ahmed/0000-0003-2631-1846
FU Higher Education Commission of Egypt; Chinese Government; National
   Natural Science Foundation of China [81671768]; National Key R&D program
   of China [2017YFC0112804]
FX This work was supported in part by the cooperation between Higher
   Education Commission of Egypt and Chinese Government, the National
   Natural Science Foundation of China (No. 81671768) and the National Key
   R&D program of China (Grant No. 2017YFC0112804) .
CR Abrardo A, 2010, IEEE T GEOSCI REMOTE, V48, P1892, DOI 10.1109/TGRS.2009.2033470
   Alvarez-Cortés S, 2020, IEEE T GEOSCI REMOTE, V58, P790, DOI 10.1109/TGRS.2019.2940553
   Amrani N, 2016, IEEE T GEOSCI REMOTE, V54, P5616, DOI 10.1109/TGRS.2016.2569485
   Auli-Llinas F., 2020, BOI CODEC
   Aulí-Llinàs F, 2016, IEEE DATA COMPR CONF, P427, DOI 10.1109/DCC.2016.29
   Aulí-Llinàs F, 2013, IEEE T IMAGE PROCESS, V22, P4678, DOI 10.1109/TIP.2013.2277801
   Barret M, 2011, IEEE T GEOSCI REMOTE, V49, P1557, DOI 10.1109/TGRS.2010.2083671
   Bartrina-Rapesta J, 2015, IEEE GEOSCI REMOTE S, V12, P1893, DOI 10.1109/LGRS.2015.2436438
   Blanes I, 2014, IEEE GEOSC REM SEN M, V2, P8, DOI 10.1109/MGRS.2014.2352465
   C. C. f. S. D. Systems, 2012, LOSSLESS MULTISPECTR
   Cover T. M., 2012, ELEMENTS INFORM THEO
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P201, DOI 10.1109/LGRS.2006.888109
   G. Group, 2020, U AUT BARC EMP SOFTW
   Hagag A, 2017, MULTIMED TOOLS APPL, V76, P23757, DOI 10.1007/s11042-016-4158-8
   Hagag A, 2017, MULTIDIM SYST SIGN P, V28, P1717, DOI 10.1007/s11045-016-0443-y
   Hagag A, 2017, J VIS COMMUN IMAGE R, V42, P14, DOI 10.1016/j.jvcir.2016.11.006
   Hagag A, 2017, OPTIK, V131, P1023, DOI 10.1016/j.ijleo.2016.11.172
   Hagag A, 2015, SIGNAL IMAGE VIDEO P, V9, P769, DOI 10.1007/s11760-013-0516-4
   Hagag A, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073511
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Kong WQ, 2019, J VIS COMMUN IMAGE R, V62, P174, DOI 10.1016/j.jvcir.2019.05.006
   Nian YJ, 2015, J VIS COMMUN IMAGE R, V28, P113, DOI 10.1016/j.jvcir.2014.06.008
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P1181, DOI 10.1109/TIT.2003.810622
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P626, DOI 10.1109/TIT.2002.808103
   Shi CP, 2019, IEEE J-STARS, V12, P934, DOI 10.1109/JSTARS.2019.2897344
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Taubman D. S, 2002, JPEG2000: Image Compression Fundamentals, Standards and Practice, V11
   U. S. G. Survey, 2019, EARTHEXPLORER
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
   Zhang JL, 2015, IEEE J-STSP, V9, P977, DOI 10.1109/JSTSP.2015.2402118
NR 30
TC 2
Z9 2
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103117
DI 10.1016/j.jvcir.2021.103117
EA MAY 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200001
DA 2024-07-18
ER

PT J
AU Wen, Y
   Chen, LT
   Deng, Y
   Zhou, C
AF Wen, Yang
   Chen, Leiting
   Deng, Yu
   Zhou, Chuan
TI Rethinking pre-training on medical imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Transfer learning; Medical image analysis; Convolutional neural network;
   Survival prediction
ID IMAGES; CANCER
AB Transfer learning from natural image datasets, such as ImageNet, is common for applying deep learning to medical imaging. However, the modalities of natural and medical images differ considerably, and the reason for the latest medical research preferring ImageNet to medical data is questionable. In this study, we investigated the properties of medical pre-training and its transfer effectiveness on various medical tasks. Through an intuitive convolution-based analysis, we determined the modality characteristics of images. Surprisingly, medical pre-training showed exceptional performance for a classification task but not for a segmentation task since medical data are visually homogeneous and lack morphological information. Using data with diverse modalities helped overcome such drawbacks, resulting in medical pre-training achieving performance comparable to pre-training with ImageNet with considerably fewer samples than ImageNet for both aforementioned tasks. Finally, a study of learned representations and realistic scenarios indicated that while ImageNet is the best choice for medical imaging, medical pre-training has significant potential.
C1 [Wen, Yang; Chen, Leiting; Zhou, Chuan] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Key Lab Digital Media Technol Sichuan Prov, Chengdu 611731, Sichuan, Peoples R China.
   [Chen, Leiting] Univ Elect Sci & Technol China, Inst Elect & Informat Engn Guangdong, Chengdu 611731, Sichuan, Peoples R China.
   [Deng, Yu] Kings Coll London, Dept Biomed Engn, London, England.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; University of London; King's
   College London
RP Zhou, C (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Key Lab Digital Media Technol Sichuan Prov, Chengdu 611731, Sichuan, Peoples R China.
EM zhouchuan@uestc.edu.cn
RI Wen, Yang/AGZ-0325-2022
OI Wen, Yang/0000-0003-0561-6229; Zhou, Chuan/0000-0001-7700-7188
FU KeyArea Research and Development Program of Guangdong Province, China
   [2019B010136003]; Sichuan Science and Technology Program, China
   [2019YJ0176/2019YJ0177/2019YFQ0005]
FX This study was supported by KeyArea Research and Development Program of
   Guangdong Province, China (No. 2019B010136003) , and Sichuan Science and
   Technology Program, China (No. 2019YJ0176/2019YJ0177/2019YFQ0005) .
CR Andreopoulos A, 2008, MED IMAGE ANAL, V12, P335, DOI 10.1016/j.media.2007.12.003
   [Anonymous], 2017, MURA LARGE DATASET A
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Chen L. -C., 2018, PROC EUR C COMPUT VI, P801
   Chen L, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101539
   Chen S., 2019, ARXIV COMPUTER VISIO
   Codella N.C.F., 2016, ARXIV COMPUTER VISIO
   Combalia Marc, 2019, ARXIV190802288
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Dou Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P691
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   EyePacs, 2015, CAL HLTHC FDN
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gu Z., 2019, INT CONF ASIC, V38, P2281, DOI DOI 10.1109/asicon47005.2019.8983520
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Ishwaran H, 2008, ANN APPL STAT, V2, P841, DOI 10.1214/08-AOAS169
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kandoth C, 2013, NATURE, V502, P333, DOI 10.1038/nature12634
   Kavur AE, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2020.101950
   Kermany DS, 2018, CELL, V172, P1122, DOI 10.1016/j.cell.2018.02.010
   Kingma D. P., 2014, arXiv
   Kornblith S., 2018, CoRR
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee H, 2019, NAT BIOMED ENG, V3, P173, DOI 10.1038/s41551-018-0324-9
   Li Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1715, DOI 10.1145/2939672.2939857
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mayr A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0084483
   Mobadersany P, 2018, P NATL ACAD SCI USA, V115, pE2970, DOI 10.1073/pnas.1717139115
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Orlando JI, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101570
   Puig X., 2016, ARXIV PREPRINT ARXIV
   Raghu M., 2017, SVCCA SINGULAR VECTO, P6076
   Raghu Maithra., 2019, Advances in Neural Information Processing Systems, P3342
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roth HR, 2015, LECT NOTES COMPUT SC, V9349, P556, DOI 10.1007/978-3-319-24553-9_68
   Saxe A. M., 2013, arXiv preprint arXiv:1312.6120
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Skilling J., 2010, LECT NOTES COMPUTER, V14, P83
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Wang SJ, 2019, IEEE T MED IMAGING, V38, P2485, DOI 10.1109/TMI.2019.2899910
   Wen Y, 2020, IEEE INT C BIOINFORM, P835, DOI 10.1109/BIBM49941.2020.9313558
   Wen Y, 2020, IEEE INT C BIOINFORM, P349, DOI 10.1109/BIBM49941.2020.9313481
   Wulczyn E, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0233678
   Yan K., 2017, ARXIV COMPUTER VISIO
   Yao JW, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101789
   Yu Z, 2019, IEEE T BIO-MED ENG, V66, P1006, DOI 10.1109/TBME.2018.2866166
   Zhang ZJ, 2019, LECT NOTES COMPUT SC, V11764, P442, DOI 10.1007/978-3-030-32239-7_49
   Zhou ZW, 2019, LECT NOTES COMPUT SC, V11767, P384, DOI 10.1007/978-3-030-32251-9_42
   Zhu XL, 2017, PROC CVPR IEEE, P6855, DOI 10.1109/CVPR.2017.725
NR 61
TC 31
Z9 31
U1 1
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103145
DI 10.1016/j.jvcir.2021.103145
EA MAY 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200005
DA 2024-07-18
ER

PT J
AU Kang, H
   Hwang, D
   Lee, J
AF Kang, Hosun
   Hwang, Dokyung
   Lee, Jangmyung
TI Specular highlight region restoration using image clustering and
   inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Specular highlight detection; Highlight identification; Pixel analysis;
   Pixel clustering; Image inpainting
ID REMOVAL; ALGORITHM
AB A novel specular highlight restoration algorithm has been proposed to remove the specular highlight in a realtime vision system. In this paper, the specular highlight region has been detected and it has been restored by image inpainting method. Most of specular highlight detection algorithms are effective only for a single image. And the auto-threshold algorithm has been implemented in real time, but, it has still low reliability with a heavy computational cost. The proposed system detects pixels corresponding to the specular highlight region in the HSI color space through a newly defined classification table. So, Specular highlight can be detected quickly with these simplified classification table. In addition, it has versatility because it can be combined with various existing high-performance image inpainting method. The superiority of the proposed algorithm is compared with the conventional specular highlight removal algorithm by combining proposed algorithm with two highperformance image inpainting techniques.
C1 [Lee, Jangmyung] Pusan Natl Univ, SPENALO Natl Robot Res Ctr, Busan 609735, South Korea.
   [Kang, Hosun; Hwang, Dokyung; Lee, Jangmyung] Pusan Natl Univ, Dept Elect Engn, Busan 609735, South Korea.
C3 Pusan National University; Pusan National University
RP Lee, J (corresponding author), Pusan Natl Univ, SPENALO Natl Robot Res Ctr, Busan 609735, South Korea.; Lee, J (corresponding author), Pusan Natl Univ, Dept Elect Engn, Busan 609735, South Korea.
EM jmlee@pusan.ac.kr
OI Hwang, Dokyung/0000-0003-4271-5672
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2019R1A2C2088859]; KARI - Ministry of science and ICT [SR18040]
FX This research was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT)
   (No.2019R1A2C2088859).; This research was supported by the Lunar
   Exploration Program through the KARI grant funded by the Ministry of
   science and ICT (No. SR18040).
CR Pérez MAA, 2009, OPT REV, V16, P91, DOI 10.1007/s10043-009-0016-5
   Azhar Faisal, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P246
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Boiangiu C.A, 2015, P 6 INT C APPL INF C
   Chi Z., 2018, C CVPR COMP VIS PATT
   Cho T.H., 2014, J KOREA I INF COMMUN, V18, P1162
   Das A., 2011, IEEE INT C IM SYST T
   Demir U., 2018, Patch-based image inpainting with generative adversarial networks
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Fu G, 2019, COMPUT GRAPH FORUM, V38, P253, DOI 10.1111/cgf.13834
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Hanbury A, 2008, PATTERN RECOGN LETT, V29, P494, DOI 10.1016/j.patrec.2007.11.002
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kender J, SATURATION HUE NORMA, P197
   엄태하, 2013, [JOURNAL OF BROADCAST ENGINEERING, 방송공학회 논문지], V18, P140
   맹형열, 2014, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V17, P1041, DOI 10.9717/kmms.2014.17.9.1041
   Lee M.C., 2013, J KOREAN I INTELLIGE, V23, P35
   Lee S.T, 2010, INT C SIGN PROC SYST
   Li C, 2017, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2017.297
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P3050, DOI 10.1109/TIFS.2017.2730822
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Miao RH, 2015, J VIS COMMUN IMAGE R, V29, P138, DOI 10.1016/j.jvcir.2015.02.011
   Morgand A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P274
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Park JB, 2003, IEEE INT CONF ROBOT, P1397
   Qureshi MA, 2017, J VIS COMMUN IMAGE R, V49, P177, DOI 10.1016/j.jvcir.2017.09.006
   Shen HL, 2013, APPL OPTICS, V52, P4483, DOI 10.1364/AO.52.004483
   Shor Y, 2008, COMPUT GRAPH FORUM, V27, P577, DOI 10.1111/j.1467-8659.2008.01155.x
   Souza ACS, 2018, SIBGRAPI, P56, DOI 10.1109/SIBGRAPI.2018.00014
   Stehle T, 2006, ACTA POLYTECH, V46, P32
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang Y, 2018, ADV NEUR IN, V31
   Wazarkar S, 2018, J VIS COMMUN IMAGE R, V55, P596, DOI 10.1016/j.jvcir.2018.07.009
   Xu R, 2019, PROC CVPR IEEE, P3718, DOI 10.1109/CVPR.2019.00384
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402
   Yang QX, 2010, LECT NOTES COMPUT SC, V6314, P87, DOI 10.1007/978-3-642-15561-1_7
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng JX, 2019, ARAB J SCI ENG, V44, P3549, DOI 10.1007/s13369-018-3592-5
   고진석, 2017, [Journal of the Korean Society for Precision Engineering, 한국정밀공학회지], V34, P557
   정준우, 2010, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V13, P535
NR 47
TC 2
Z9 2
U1 3
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103106
DI 10.1016/j.jvcir.2021.103106
EA MAY 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700009
DA 2024-07-18
ER

PT J
AU Nath, CD
   Hazarika, SM
AF Nath, Chayanika D.
   Hazarika, Shyamanta M.
TI Activity recognition in video sequences over qualitative abstracts of a
   diagram-based representation schema
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cognitive vision; Video analysis; Activity recognition; Qualitative
   spatial and temporal reasoning; Diagrammatic reasoning
AB Explicit reasoning over a spatial substrate, i.e., space?time information structures underlying a spatial problem, simplifies reasoning. Diagrammatic reasoning makes use of diagrams for exploiting such underlying structures. This paper proposes a novel approach combining diagrammatic reasoning with qualitative spatial and temporal reasoning techniques to visualize and perceive spatio-temporal relations among objects in a video. The hybrid techniques explore information over the spatial substrate for relational extractions. Different relations among objects in transition define short-term activities. Mealy machines are learned over patterns of short-term activities as activity recognizers. The proposed representation and recognition mechanism is validated by conducting experiments for video activity recognition from DARPA Mind?s Eye and J-HMDB dataset.
C1 [Nath, Chayanika D.] Tezpur Univ, Biomimet & Cognit Robot Lab, Comp Sc & Engn, Tezpur 784028, Assam, India.
   [Hazarika, Shyamanta M.] Indian Inst Technol Guwahati, Biomimet Robot & Artificial Intelligence Lab, Mech Engn, Gauhati 781039, India.
C3 Tezpur University; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (IIT) - Guwahati
RP Nath, CD (corresponding author), Tezpur Univ, Biomimet & Cognit Robot Lab, Comp Sc & Engn, Tezpur 784028, Assam, India.
EM cnath.nath@gmail.com; s.m.hazarika@iitg.ac.in
RI Hazarika, Shyamanta M/AGZ-3776-2022
OI Hazarika, Shyamanta M/0000-0003-4547-6013; Nath, Chayanika
   Deka/0000-0003-2200-9631
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   An GY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102650
   Anderson M, 2003, ARTIF INTELL, V145, P181, DOI 10.1016/S0004-3702(02)00383-1
   Baekgaard L, 2004, P C ACT LANG 2004, P103
   Banerjee B., 2007, Spatial Problem Solving for Diagrammatic Reasoning
   Baruah Rupam, 2014, International Journal of Computer Information Systems and Industrial Management Applications, V6, P344
   Bouma H, 2013, PROC SPIE, V8711, DOI 10.1117/12.2015877
   Burghouts GJ, 2013, PATTERN RECOGN LETT, V34, P1861, DOI 10.1016/j.patrec.2013.01.024
   Cherian A, 2017, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR.2017.172
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Dylla F, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038927
   Frank A. U., 1992, Journal of Visual Languages and Computing, V3, P343, DOI 10.1016/1045-926X(92)90007-9
   Freksa C., 2015, INT J SOFTWARE INFOR, V9, P279
   Freksa C, 2019, SPAT COGN COMPUT, V19, P46, DOI 10.1080/13875868.2018.1531415
   Glasgow Janice., 1995, DIAGRAMMATIC REASONI
   Gottfried B, 2008, J VISUAL LANG COMPUT, V19, P321, DOI 10.1016/j.jvlc.2007.11.001
   Hall A, 2017, J SPAT INT SCI, P65, DOI 10.5311/JOSIS.2017.15.337
   Hao WL, 2019, PATTERN RECOGN, V92, P13, DOI 10.1016/j.patcog.2019.03.005
   Hazarika S.M, 2016, P 10 IND C COMP VIS, P1
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Kerr W., 2011, 22 INT JOINT C, P1348
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Lovett A, 2017, PSYCHOL REV, V124, P60, DOI 10.1037/rev0000039
   Nath C.D., 2015, 2015 5 NAT C COMP VI, P1
   Nath C.D., 2018, LECT NOTES COMPUTER, V10871
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Perez-Kriz S., 2018, 10 INT C DIAGGR 2018, V10871
   Rodriguez-Benitez L, 2011, INT J APPROX REASON, V52, P526, DOI 10.1016/j.ijar.2010.12.003
   Santos L, 2015, PATTERN RECOGN, V48, P568, DOI 10.1016/j.patcog.2014.08.015
   Soomro K, 2016, PROC CVPR IEEE, P2648, DOI 10.1109/CVPR.2016.290
   Tiger M, 2020, INT J APPROX REASON, V119, P325, DOI 10.1016/j.ijar.2020.01.009
   Wang TW, 2019, J VIS COMMUN IMAGE R, V61, P315, DOI 10.1016/j.jvcir.2019.04.001
   Xiao JH, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102722
   Zabkar J., 2008, 22 INT WORKSH QUAL R, P146
NR 34
TC 3
Z9 3
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103061
DI 10.1016/j.jvcir.2021.103061
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700007
DA 2024-07-18
ER

PT J
AU Cao, FL
   Chen, BJ
AF Cao, Feilong
   Chen, Baijie
TI Densely connected network with improved pyramidal bottleneck residual
   units for super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Convolution neural network; Pyramidal network;
   Residual-feature learning
ID SINGLE-IMAGE SUPERRESOLUTION; CONVOLUTIONAL NETWORK; INTERPOLATION
AB Recent studies have shown that super-resolution can be significantly improved by using deep convolution neural network. Although applying a larger number of convolution kernels can extract more features, increasing the number of feature mappings will dramatically increase the training parameters and time complexity. In order to balance the workload among all units and maintain appropriate time complexity, this paper proposes a new network structure for super-resolution. For the sake of making full use of context information, in the structure, the operations of division (S) and fusion (C) are added to the pyramidal bottleneck residual units, and the dense connected methods are used. The proposed network include a preliminary feature extraction net, seven residual units with dense connections, seven convolution layers with the size of 1 x 1 after each residual unit, and a deconvolution layer. The experimental results show that the proposed network has better performance than most existing methods.
C1 [Cao, Feilong; Chen, Baijie] China Jiliang Univ, Dept Appl Math, Coll Sci, Hangzhou 310018, Zhejaing Provin, Peoples R China.
C3 China Jiliang University
RP Cao, FL (corresponding author), China Jiliang Univ, Dept Appl Math, Coll Sci, Hangzhou 310018, Zhejaing Provin, Peoples R China.
EM feilongcao@gmail.com; 1161202542@qq.com
FU National Natural Science Foundation of China [61672477]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61672477.
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cao FL, 2015, IEEE T CIRC SYST VID, V25, P1261, DOI 10.1109/TCSVT.2014.2372351
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fan Y, 2017, 2017 INTERNATIONAL CONFERENCE ON SOCIAL SCIENCES, ARTS AND HUMANITIES (SSAH 2017), P163
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hu X., 2019, ARXIV190300875V4
   Hung KW, 2012, INT CONF ACOUST SPEE, P1269, DOI 10.1109/ICASSP.2012.6288120
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Jing Y., 2019, ARXIV191106953CSCV
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   Liu Y., 2018, P 24 INT C PATT REC
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Wang RX, 2020, IEEE T IMAGE PROCESS, V29, P1669, DOI 10.1109/TIP.2019.2941327
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xu HT, 2013, IEEE T CIRC SYST VID, V23, P1740, DOI 10.1109/TCSVT.2013.2248305
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WM, 2019, IEEE SIGNAL PROC LET, V26, P538, DOI 10.1109/LSP.2018.2890770
   Yu J., 2018, ARXIV180808718CSCV
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2013, IEEE T NEUR NET LEAR, V24, P1648, DOI 10.1109/TNNLS.2013.2262001
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 38
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102963
DI 10.1016/j.jvcir.2020.102963
EA JAN 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OJ
UT WOS:000613150700001
DA 2024-07-18
ER

PT J
AU Parihar, AS
   Pal, J
   Sharma, I
AF Parihar, Anil Singh
   Pal, Joyeeta
   Sharma, Ishita
TI Multiview video summarization using video partitioning and clustering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video summarization; Surveillance videos; Multiview video; Video
   partition; Clustering
ID EXTRACTION
AB Multiview video summarization plays a crucial role in abstracting essential information form multiple videos of the same location and time. In this paper, we propose a new approach for the multiview summarization. The proposed approach uses the BIRCH clustering algorithm for the first time on the initial set of frames to get rid of the static and redundant. The work presents a new approach for shot boundary detection using frame similarity measures Jaccard and Dice. The algorithm performs effectively synchronized merging of keyframes from all camera-views to obtain the final summary. Extensive experimentation conducted on various datasets suggests that the proposed approach significantly outperforms most of the existing video summarization approaches. To state a few, a 1.5% improvement on video length reduction, 24.28% improvement in compression ratio, and 6.4% improvement in quality assessment ratio is observed on the lobby dataset.
C1 [Parihar, Anil Singh; Pal, Joyeeta; Sharma, Ishita] Delhi Technol Univ, Machine Learning Res Lab, Dept Comp Engn, New Delhi, India.
C3 Delhi Technological University
RP Parihar, AS (corresponding author), Delhi Technol Univ, Machine Learning Res Lab, Dept Comp Engn, New Delhi, India.
EM parihar.anil@gmail.com; joyeetapal26@gmail.com;
   ishitasharma12699@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671
CR [Anonymous], 2019, IEEE T CIRCUITS SYST
   Chu WS, 2015, PROC CVPR IEEE, P3584, DOI 10.1109/CVPR.2015.7298981
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Elfeki M, 2019, IEEE WINT CONF APPL, P754, DOI 10.1109/WACV.2019.00085
   Fei MJ, 2017, J VIS COMMUN IMAGE R, V42, P207, DOI 10.1016/j.jvcir.2016.12.001
   Fu TJ, 2019, IEEE WINT CONF APPL, P1579, DOI 10.1109/WACV.2019.00173
   Fu Y., 2014, ARXIV14056434
   Fu YW, 2010, IEEE T MULTIMEDIA, V12, P717, DOI 10.1109/TMM.2010.2052025
   Hannane R, 2018, J VIS COMMUN IMAGE R, V55, P179, DOI 10.1016/j.jvcir.2018.06.002
   Hussain T, 2020, IEEE T IND INFORM, V16, P77, DOI 10.1109/TII.2019.2929228
   Ju Z., 2016, 2016 IEEE INT C MULT, P1
   Kuanar SK, 2015, IEEE T MULTIMEDIA, V17, P1166, DOI 10.1109/TMM.2015.2443558
   Kuanar S, 2019, CIRC SYST SIGNAL PR, V38, P5081, DOI 10.1007/s00034-019-01110-4
   Kuanar S, 2018, IEEE INT CONF MULTI
   Kuanar S, 2018, PICT COD SYMP, P164, DOI 10.1109/PCS.2018.8456278
   Kumar K, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN ELECTRONICS, SIGNAL PROCESSING AND COMMUNICATION (IESC), P106, DOI 10.1109/IESPC.2017.8071874
   Kumar K, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS (SITIS), P119, DOI 10.1109/SITIS.2016.27
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Ma MY, 2020, NEUROCOMPUTING, V378, P197, DOI 10.1016/j.neucom.2019.07.108
   Madzarov G., 2008, COMP AUTOMATIC SHOT
   Mahapatra A, 2015, IEEE IMAGE PROC, P1260, DOI 10.1109/ICIP.2015.7351002
   Meng JJ, 2017, IEEE INT CONF COMP V, P1189, DOI 10.1109/ICCVW.2017.144
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Ou S. H., 2014, IEEE J SEL TOP QUANT, V9, P165
   Panda R, 2017, IEEE T MULTIMEDIA, V19, P2010, DOI 10.1109/TMM.2017.2708981
   Papa J. P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4162, DOI 10.1109/ICPR.2010.1012
   Parekh H., 2017, INT J ENG RES COMPUT, V4, P35
   Rocha LM, 2009, INT J IMAG SYST TECH, V19, P50, DOI 10.1002/ima.20191
   Tank D., 2016, IJSART, V2, P1
   Tirupathamma S.M., 2017, INT J INNOV COMPUT S, V4, P160
   Tseng BL, 2004, J VIS COMMUN IMAGE R, V15, P370, DOI 10.1016/j.jvcir.2004.04.011
   Zhang S, 2016, IEEE T IMAGE PROCESS, V25, P5469, DOI 10.1109/TIP.2016.2601493
   Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328
   Zhou S, 2018, IEEE C ELECTR PERFOR, P127, DOI 10.1109/EPEPS.2018.8534293
NR 34
TC 11
Z9 11
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102991
DI 10.1016/j.jvcir.2020.102991
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900003
DA 2024-07-18
ER

PT J
AU Chen, BJ
   Qi, XM
   Zhou, Y
   Yang, GY
   Zheng, YH
   Xiao, B
AF Chen, Beijing
   Qi, Xiaoming
   Zhou, Yang
   Yang, Guanyu
   Zheng, Yuhui
   Xiao, Bin
TI Image splicing localization using residual image and residual-based
   fully convolutional network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Splicing localization; Fully convolutional network; Residual block;
   Residual image; Condition random field
ID EXPOSING DIGITAL FORGERIES; FORENSICS
AB Fully convolutional networks (FCNs) have been efficiently applied in splicing localization. However, the existing FCN-based methods still have three drawbacks: (a) their performance in detecting image details is unsatisfactory; (b) deep FCNs are difficult to train; (c) results of multiple FCNs are merged using fixed parameters to weigh their contributions. So, an improved method is proposed. Firstly, both the original spliced image and its corresponding residual image are regarded as the inputs of the network. Secondly, the residual block is introduced into FCN as residual-based FCN (RFCN) to make the network easier to optimize. Thirdly, three different RFCNs are merged to enhance locating maps with two learnable weight parameters. Besides, condition random field is introduced into the whole network to improve the results further. Experimental results on five datasets show that the proposed method performs better than some existing methods in localization ability, generalization ability, and robustness against additional operations.
C1 [Chen, Beijing; Qi, Xiaoming; Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Peoples R China.
   [Chen, Beijing] Nanjing Univ Informat Sci & Technol, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Peoples R China.
   [Qi, Xiaoming; Yang, Guanyu] Southeast Univ, Lab Image Sci & Technol, Nanjing 210096, Peoples R China.
   [Zhou, Yang] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Jiangsu, Peoples R China.
   [Xiao, Bin] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Southeast University -
   China; Jiangsu University of Science & Technology; Chongqing University
   of Posts & Telecommunications
RP Xiao, B (corresponding author), Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing 400065, Peoples R China.
EM xiaobin@cqupt.edu.cn
RI Xiao, Bin/E-2722-2012
FU National Nature Science Foundation of China [62072251, 61972206];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD) fund; Qing Lan Project of Jiangsu Higher Education
   Institutions
FX This work was partly supported by the National Nature Science Foundation
   of China under Grants 62072251, and 61972206, the Priority Academic
   Program Development of Jiangsu Higher Education Institutions (PAPD)
   fund, and the Qing Lan Project of Jiangsu Higher Education Institutions.
CR Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen BJ, 2018, IEEE ACCESS, V6, P69472, DOI 10.1109/ACCESS.2018.2880433
   Chen BJ, 2017, J VIS COMMUN IMAGE R, V49, P283, DOI 10.1016/j.jvcir.2017.08.011
   Cozzolino D, 2016, IEEE INT WORKS INFOR
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Cozzolino D, 2015, IEEE INT WORKS INFOR
   Cozzolino D, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P159, DOI 10.1145/3082031.3083247
   Dong J., 2011, CASIA TAMPERED IMAGE
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Guan HY, 2019, IEEE WINT CONF APPL, P63, DOI 10.1109/WACVW.2019.00018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu YF, 2010, IEEE T INF FOREN SEC, V5, P816, DOI 10.1109/TIFS.2010.2077628
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Li HD, 2017, IEEE T INF FOREN SEC, V12, P1240, DOI 10.1109/TIFS.2017.2656823
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B, 2018, SIGNAL PROCESS-IMAGE, V66, P103, DOI 10.1016/j.image.2018.04.011
   Liu YQ, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P85, DOI 10.1145/3206004.3206010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   National Institute of Standards and Technology, 2020, NIST CHEM WEBBOOK, DOI [10.18434/T4D303, DOI 10.18434/T4D303]
   Ng T.T., 2004, ADVENT Technical Report
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Rao Y, 2016, IEEE INT WORKS INFOR
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Verdoliva L, 2014, IEEE INT WORKS INFOR, P149, DOI 10.1109/WIFS.2014.7084319
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yao H, 2012, IEEE SIGNAL PROC LET, V19, P123, DOI 10.1109/LSP.2011.2182191
   Zhang DP, 2019, MULTIMED TOOLS APPL, V78, P22223, DOI 10.1007/s11042-019-7408-8
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 36
TC 8
Z9 8
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102967
DI 10.1016/j.jvcir.2020.102967
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QO
UT WOS:000598558100001
DA 2024-07-18
ER

PT J
AU Chandrasekar, KS
   Geetha, P
AF Chandrasekar, K. Silpaja
   Geetha, P.
TI Multiple objects tracking by a highly decisive three-frame
   differencing-combined-background subtraction method with GMPFM-GMPHD
   filters and VGG16-LSTM classifier
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tracking; Vehicles; Pedestrians; Gaussian mixture particle filter model;
   VGG16 and LSTM
ID VEHICLE TRACKING; MULTIVEHICLE TRACKING; PARTICLE FILTER; ALGORITHM;
   VISION; SYSTEM; MODEL; VIDEO; FLOW
AB Tracking of moving vehicles and pedestrians is the most important application in traffic surveillance videos. This study develops a highly efficient and fast multi-object tracking method using three-frame differencing-combined-background subtraction (TFDCBS)-coupled-automatic and fast histogram-entropy-based thresholding (HEBT) method together with GMPFM-GMPHD filters and VGG16-LSTM classifier. Here TFDCBS-HEBT methods identify the targeted objects with enclosed 3D bounding boxes and extracts multiple features from the raw images. Maximum number of error-free extracted multiple features (key points, multiple local convolutions, corners, and descriptors) are processed subsequently for object tracking by GMPFM-GMPHD Filters and an upgraded VGG16- LSTM classifier. The proposed method has been validated on KITTI 3D bounding boxdataset and its performance compared with three state-of-the-art tracking methods. Highest values of several performance parameters and the lowest computation time clearly demonstrate the promising feature of our new method for its application towards a fast and effective multi-target tracking of moving objects.
C1 [Chandrasekar, K. Silpaja; Geetha, P.] Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai
RP Chandrasekar, KS (corresponding author), Anna Univ, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM silpajachandrasekar@gmail.com
RI Chandrasekar, Silpaja/AAJ-9571-2021; P, Geetha/ADG-6534-2022
OI P, Geetha/0000-0002-5637-3856
CR Amer NH, 2017, J INTELL ROBOT SYST, V86, P225, DOI 10.1007/s10846-016-0442-0
   Anandhalli M, 2018, J INTELL SYST, V27, P363, DOI 10.1515/jisys-2016-0073
   [Anonymous], 2013, P 22 INT C MECH ENG
   [Anonymous], IEEE ROBOT AUTOM LET
   [Anonymous], 1981, 7 INT JOINT C ARTIFI
   [Anonymous], 2005, CMURITR0507
   Arras KO, 2003, ROBOT AUTON SYST, V44, P41, DOI 10.1016/S0921-8890(03)00009-5
   Battiato S, 2015, EXPERT SYST APPL, V42, P7263, DOI 10.1016/j.eswa.2015.05.055
   Belbachir N., 2019, P IEEE INT C COMP VI
   Brooks RR, 2003, P IEEE, V91, P1163, DOI 10.1109/JPROC.2003.814923
   Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055
   Chandran R., 2017, INT J ADV COMPUT ELE, V5, P7
   Chandrasekar KS, 2020, IET IMAGE PROCESS, V14, P354, DOI 10.1049/iet-ipr.2018.5555
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Colonna JG, 2018, EXPERT SYST APPL, V106, P107, DOI 10.1016/j.eswa.2018.03.062
   Dener Murat, 2016, Journal of Advances in Computer Networks, V4, P156, DOI 10.18178/jacn.2016.4.3.223
   Elfring J, 2016, IEEE INT VEH SYM, P630, DOI 10.1109/IVS.2016.7535453
   Espsoito N., 2020, P AIAA SCITECH 2020, P1345
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Facts T.S., 2003, COMPILATION MOTOR VE, V809, P775
   Fanani N, 2016, IEEE INT VEH SYM, P933, DOI 10.1109/IVS.2016.7535500
   Fang YK, 2019, IEEE T INTELL TRANSP, V20, P4538, DOI 10.1109/TITS.2018.2888500
   Frossard D, 2018, IEEE INT CONF ROBOT, P635, DOI 10.1109/ICRA.2018.8462884
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gunnarsson J, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P975
   Habtie AB, 2017, STUD COMPUT INTELL, V676, P73, DOI 10.1007/978-3-319-47715-2_4
   Hassannejad H, 2015, EXPERT SYST APPL, V42, P4167, DOI 10.1016/j.eswa.2015.01.032
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hoogendoorn SP, 2003, TRANSPORT RES REC, P121
   Hu HN, 2019, IEEE I CONF COMP VIS, P5389, DOI 10.1109/ICCV.2019.00549
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Lämmer S, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/04/P04019
   Lamard L, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P414, DOI 10.1109/IVS.2012.6232173
   Li H, 2020, IEEE ACCESS, V8, P44325, DOI 10.1109/ACCESS.2020.2977841
   Liu YC, 2016, NEUROCOMPUTING, V196, P1, DOI 10.1016/j.neucom.2016.02.042
   Lu XF, 2014, IEEJ J IND APPL, V3, P182, DOI 10.1541/ieejjia.3.182
   Ma YL, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040446
   Ma YL, 2019, PHYSICA A, V535, DOI 10.1016/j.physa.2019.122291
   Mandellos NA, 2011, EXPERT SYST APPL, V38, P1619, DOI 10.1016/j.eswa.2010.07.083
   Mathis A., 2018, ARXIV180403142
   Meissner D, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P630, DOI 10.1109/IVS.2012.6232226
   Memon S., 2018, INT J IMAGE GRAPH SI, V10
   Mithun NC, 2016, EXPERT SYST APPL, V62, P17, DOI 10.1016/j.eswa.2016.06.020
   Niknejad HT, 2012, IEEE T INTELL TRANSP, V13, P748, DOI 10.1109/TITS.2012.2187894
   Ong LY, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P385, DOI 10.1109/ICCAR.2017.7942723
   Ortuzar J., 2002, MODELING TRANSPORT, DOI [10.1002/9781119993308, DOI 10.1016/J.TRA.2015.02.002]
   Otanasap N, 2017, PROC SPIE, V10225, DOI 10.1117/12.2266822
   Price E, 2018, IEEE ROBOT AUTOM LET, V3, P3193, DOI 10.1109/LRA.2018.2850224
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Seki M, 2000, FIFTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P207, DOI 10.1109/WACV.2000.895424
   Seong S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194263
   Shen XT, 2015, PROCEEDINGS OF THE 2015 7TH IEEE INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (CIS) AND ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P173, DOI 10.1109/ICCIS.2015.7274568
   Shen Y, 2014, IEEE T CIRC SYST VID, V24, P361, DOI 10.1109/TCSVT.2013.2280073
   Singh V., 2020, P 4 INT C INT THINGS, P1
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Song D, 2019, AUTOMATICA, V105, P28, DOI 10.1016/j.automatica.2019.03.016
   Song YM, 2019, IEEE ACCESS, V7, P165103, DOI 10.1109/ACCESS.2019.2953276
   Spanhel J., P CVPR WORKSH, V2
   Tokoro S, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P304, DOI 10.1109/IVS.2003.1212927
   Usman F.K., 2019, J SCI RES REPORTS, P1
   Vallejo D, 2009, EXPERT SYST APPL, V36, P10503, DOI 10.1016/j.eswa.2009.01.034
   Wang Z., 2017, COMPUT ENG DES, P2750
   Wittmann David, 2014, Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics ICINCO 2014, P794
   Wu JQ, 2018, ITE J, V88, P32
   Xiang TZ, 2019, IEEE GEOSC REM SEN M, V7, P29, DOI 10.1109/MGRS.2019.2918840
   Xiang XZ, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P818, DOI 10.1109/WCICA.2016.7578324
   Xin J, 2017, IEEE INT CON MULTI, P613, DOI 10.1109/ICME.2017.8019329
   Yang T, 2019, J VIS COMMUN IMAGE R, V58, P178, DOI 10.1016/j.jvcir.2018.11.034
   Ye E, 2019, IEEE INT C INTELL TR, P1128, DOI 10.1109/ITSC.2019.8917226
   Yu J., 2020, IEEE T CYBERN
   Yu J, 2020, IEEE T NEUR NET LEAR, V31, P661, DOI 10.1109/TNNLS.2019.2908982
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang K, 2014, IEEE GEOSCI REMOTE S, V11, P469, DOI 10.1109/LGRS.2013.2267771
   Zhenxiong Xu, 2017, 2017 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII). Proceedings, P79, DOI 10.1109/ICIICII.2017.79
NR 79
TC 12
Z9 12
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102905
DI 10.1016/j.jvcir.2020.102905
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400016
DA 2024-07-18
ER

PT J
AU Zhou, ZY
   Wang, XS
   Li, C
   Zeng, M
   Li, ZY
AF Zhou, Ziyao
   Wang, Xinsheng
   Li, Chen
   Zeng, Ming
   Li, Zhongyu
TI Adaptive deep feature aggregation using Fourier transform and low-pass
   filtering for robust object retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Convolutional neural networks; Feature aggregation;
   Fourier transform; Low-pass filtering
ID IMAGE; RECONSTRUCTION
AB With the rapid development of deep learning techniques, convolutional neural networks (CNN) have been widely investigated for the feature representations in the image retrieval task. However, the key step in CNN-based retrieval, i.e., feature aggregation has not been solved in a robust and general manner when tackling different kinds of images. In this paper, we present a deep feature aggregation method for image retrieval using the Fourier transform and low-pass filtering, which can adaptively compute the weights for each feature map with discrimination. Specifically, the low-pass filtering can preserve the semantic information in each feature map by transforming images to the frequency domain. In addition, we develop three adaptive methods to further improve the robustness of feature aggregation, i.e., Region of Interests (ROI) selection, spatial weighting and channel weighting. Experimental results demonstrate the superiority of the proposed method in comparison with other state-of-the-art, in achieving robust and accurate object retrieval under five benchmark datasets. (C) 2020 Published by Elsevier Inc.
C1 [Zhou, Ziyao; Wang, Xinsheng; Li, Chen; Zeng, Ming; Li, Zhongyu] Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Li, C (corresponding author), Xi An Jiao Tong Univ, Sch Software Engn, Xian 710049, Peoples R China.
EM cclidd@xjtu.edu.cn
RI Zeng, Ming/GXF-3628-2022; li, zy/HZM-1892-2023
OI Zeng, Ming/0000-0003-2836-9240; 
FU National Natural Science Foundation of China (NSFC) [61573273]
FX This work was supported by National Natural Science Foundation of China
   (NSFC) [Grant No. 61573273].
CR [Anonymous], 2015, INT C LEARN REPR MAY
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chen JY, 2017, IEEE CONF IMAGING SY, P49
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng H., 2017, J FRONT COMPUT SCI T
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   He L, 2017, IEEE INT CON MULTI, P1153, DOI 10.1109/ICME.2017.8019549
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Kalantidis Y., EUR C COMP VIS, P685
   Kim DS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040960
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S, 2017, CIRC SYST SIGNAL PR, V36, P1493, DOI 10.1007/s00034-016-0364-x
   Li Xuelong, 2019, IEEE T CYBERNET
   Li YD, 2017, IEEE T AUTOM SCI ENG, V14, P1256, DOI 10.1109/TASE.2016.2520955
   Li ZY, 2018, MED IMAGE ANAL, V43, P66, DOI 10.1016/j.media.2017.09.007
   Liu PP, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111037
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HM, 2018, MULTIMED TOOLS APPL, V77, P21847, DOI 10.1007/s11042-017-4585-1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Mao XJ, 2016, ADV NEUR IN, V29
   Philbin J., IEEE C COMP VIS PATT
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Ran LY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102421
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saxena N, 2018, IET IMAGE PROCESS, V12, P1013, DOI 10.1049/iet-ipr.2017.0961
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sicre R., 2015, COMPUT SCI
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun S, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.3.034113
   Do TT, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3314051
   Wang L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030769
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang D, 2018, MULTIMED TOOLS APPL, V77, P2191, DOI 10.1007/s11042-017-4370-1
   Zhang X., 2018 IEEE VISUAL COM, P1
   Zhu AB, 2017, INT J ADV MANUF TECH, V88, P1111, DOI 10.1007/s00170-016-8846-3
NR 50
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102860
DI 10.1016/j.jvcir.2020.102860
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400002
DA 2024-07-18
ER

PT J
AU Huang, ZW
   Li, Y
   Luo, SG
AF Huang, Zhiwei
   Li, Yan
   Luo, Shiguang
TI Hierarchical Learning-Guided human motion quality assessment in big data
   environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality assessment; Reinforcement learning; Human activities; Big data;
   Hierarchical networks
ID IMAGE; INFORMATION
AB Image information may be distorted during acquisition, processing, compression, and transmission. It is necessary to propose an intelligent image quality assessment model toward big data environment to quantify the degree of distortion of the image. This paper proposes a quality assessment model for human motion images. In complex scenes, the human body's action posture can be taken as an important feature point. Usually, in different scenes, the parts that affect the quality of the human body's posture are different. In other words, the weights of feature points that affect quality are different in different scenarios. However, due to the categorization of human movements, we can learn the quality assessment methods of different types of movements through sample training. Inspired by feature learning in the field of machine learning, we propose a hierarchical quality learning approach. We cast quality assessment as quality feature learning and layer by layer. The hierarchical quality learning method is based on deep reinforcement learning. The key part is that the method focuses on the region that containing more information on the features of the quality and enlarges the region layer by layer. Finally, we can determine the part of the body that affects the quality assessment. We compare this method with the subjective quality assessment results of the human observers and find that the proposed method achieves effective performance in big data environment to evaluate human motion quality. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Huang, Zhiwei] South China Univ Technol, Sch Architecture, Guangzhou 510641, Peoples R China.
   [Li, Yan] Guang Zhou Vocat Sch Finance & Econ, Foreign Language Teaching Dept, Guang Zhou 510080, Peoples R China.
   [Luo, Shiguang] GuangDong Univ Finance, Sch Financial Math & Stat, Guangzhou 510521, Peoples R China.
C3 South China University of Technology; Guangdong University of Finance
RP Luo, SG (corresponding author), GuangDong Univ Finance, Sch Financial Math & Stat, Guangzhou 510521, Peoples R China.
EM sgluomaths@gduf.edu.cn
FU National Natural Science Foundation of China [51678239]; Ministry of
   Science and Technology of China [2017YFC0112900]
FX This project was supported by National Natural Science Foundation of
   China (No. 51678239), and Ministry of Science and Technology of China
   (No. 2017YFC0112900).
CR [Anonymous], 2015, ARXIV151106984
   Ba J., 2014, ARXIV PREPRINT ARXIV
   Bellver M., 2016, DEEP REINFORCEMENT L
   Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Kingma D. P., 2014, arXiv
   Mnih V., 2014, Neural Information Processing Systems, P2204
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Pont-Tuset Jordi., 2016, IEEE transactions on pattern analysis and machine
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 28
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102700
DI 10.1016/j.jvcir.2019.102700
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900008
DA 2024-07-18
ER

PT J
AU Zhang, C
   Ou, B
   Tian, HW
   Qin, Z
AF Zhang, Cheng
   Ou, Bo
   Tian, Huawei
   Qin, Zheng
TI Reversible data hiding in JPEG bitstream using optimal VLC mapping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; JPEG bitstream; VLC mapping; File size
   preservation
AB The traditional RDH method for JPEG bitstream is conducted by building the mapping between the variable length codes (VLC). However, the capacity is limited, and the file size may not be well preserved as the capacity is increased. This is because that the trade-off between the capacity and the file size has not been deeply investigated, neither explicitly formulated nor appropriately optimized. In this paper, we propose to take the file size preservation into consideration and minimize the file size increase for a given capacity. We use the value transfer matrix to simulate a theoretical model and then design some optimization rules to reach the reversible solution. Consequently, a better reversible VLC mapping can be obtained in terms of both the capacity and the file size preservation. The experimental results show that the proposed method can increase the capacity with a relatively low cost of file size increase. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Zhang, Cheng; Ou, Bo; Qin, Zheng] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Tian, Huawei] Peoples Publ Secur Univ China, Sch Natl Secur & Counter Terrorism, Beijing 100038, Peoples R China.
C3 Hunan University; People's Public Security University of China
RP Ou, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM zcheng@hnu.edu.cn; oubo@hnu.edu.cn; hwtian@live.cn; zqin@hnu.edu.cn
RI OU, BO/L-2212-2013; cheng, zhang/IUO-9683-2023
OI cheng, zhang/0000-0001-5669-162X; Ou, Bo/0000-0001-6936-9955
FU National Science Foundation of China [61872128, 61772539, 61972405,
   61772191]; Hunan Provincial Natural Science Foundation of China
   [2018JJ3078]; Science and Technology Key Projects of Hunan Province
   [2015TP1004]
FX This work was supported by the National Science Foundation of China
   (Nos. 61872128, 61772539, 61972405, 61772191), the Hunan Provincial
   Natural Science Foundation of China (No. 2018JJ3078), and the Science
   and Technology Key Projects of Hunan Province (No. 2015TP1004).
CR Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hu YJ, 2013, J SYST SOFTWARE, V86, P2166, DOI 10.1016/j.jss.2013.03.102
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo T, 2019, J VIS COMMUN IMAGE R, V61, P61, DOI 10.1016/j.jvcir.2019.03.017
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Nikolaidis A, 2016, MULTIMED TOOLS APPL, V75, P1869, DOI 10.1007/s11042-014-2377-4
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2019, IEEE T INF FOREN SEC, V14, P2400, DOI 10.1109/TIFS.2019.2899520
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qin C, 2019, IEEE T CIRC SYST VID, V29, P3341, DOI 10.1109/TCSVT.2018.2878026
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Qiu YQ, 2018, J VIS COMMUN IMAGE R, V52, P86, DOI 10.1016/j.jvcir.2018.02.005
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Xie X.-Z., 2018, MULTIMED TOOLS APPL, P1
   Xuan GR, 2019, J INF SECUR APPL, V45, P1, DOI 10.1016/j.jisa.2018.12.007
   Xue BW, 2017, MULTIMED TOOLS APPL, V76, P13473, DOI 10.1007/s11042-016-3763-x
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 35
TC 12
Z9 14
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102821
DI 10.1016/j.jvcir.2020.102821
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400020
DA 2024-07-18
ER

PT J
AU Li, QN
   Hu, RM
   Xiao, J
   Wang, ZY
   Chen, Y
AF Li, Qingnan
   Hu, Ruimin
   Xiao, Jing
   Wang, Zhongyuan
   Chen, Yu
TI Learning latent geometric consistency for 6D object pose estimation in
   heavily cluttered scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geometric consistency; Geometric reasoning; Pose estimation;
   Convolutional neural networks
ID RECOGNITION
AB 6D object pose (3D rotation and translation) estimation from RGB-D image is an important and challenging task in computer vision and has been widely applied in a variety of applications such as robotic manipulation, autonomous driving, augmented reality etc. Prior works extract global feature or reason about local appearance from an individual frame, which neglect the spatial geometric relevance between two frames, limiting their performance for occluded or truncated objects in heavily cluttered scenes. In this paper, we present a dual-stream network for estimating 6D pose of a set of known objects from RGB-D images. Our novelty stands in contrast to prior work that learns latent geometric consistency in pairwise dense feature representations from multiple observations of the same objects in a self-supervised manner. We show in experiments that our method outperforms state-of-the-art approaches on 6D object pose estimation in two challenging datasets, YCB-Video and LineMOD. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Qingnan; Hu, Ruimin] Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Xiao, Jing; Wang, Zhongyuan] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
   [Chen, Yu] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
   [Li, Qingnan] Wuhan Univ Technol, Wuhan 430070, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University of Technology
RP Hu, RM (corresponding author), Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
EM qingqing@whu.edu.cn; hrm@whu.edu.cn; jing@whu.edu.cn
RI JIN, LIYING/JFB-1980-2023; Liu, Shao/JFK-0166-2023; Wang,
   Zhongyuan/ABD-2189-2020; liang, shuang/JOK-5869-2023; He,
   Chen/JLM-5059-2023
OI Xiao, Jing/0000-0002-0833-5679
FU National Nature Science Foundation of China [61502348, 61671336,
   91738302, 61671332, U1903214, U1736206]; Natural Science Foundation of
   Jiangsu Province [BK20180234]; Open Research Fund of State Key
   Laboratory of Information Engineering in Sureying, Mapping and Remote
   Sensing, Wuhan University [17E03]; Hubei Province Technological
   Innovation Major Project [2019AAA049]
FX This work was supported by the National Nature Science Foundation of
   China under Grant 61502348, 61671336, 91738302, 61671332, U1903214,
   U1736206, by the Natural Science Foundation of Jiangsu Province under
   Grant BK20180234, by the Open Research Fund of State Key Laboratory of
   Information Engineering in Sureying, Mapping and Remote Sensing, Wuhan
   University under Grant 17E03, by the Hubei Province Technological
   Innovation Major Project under Grant 2019AAA049.
CR Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Bui M, 2018, IEEE INT CONF ROBOT, P6140, DOI 10.1109/ICRA.2018.8460654
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Collet A, 2011, INT J ROBOT RES, V30, P1284, DOI 10.1177/0278364911401765
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390
   Ferrari V, 2006, INT J COMPUT VISION, V67, P159, DOI 10.1007/s11263-005-3964-7
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gu CH, 2010, LECT NOTES COMPUT SC, V6315, P408
   Hinterstoisser S, 2011, IEEE I CONF COMP VIS, P858, DOI 10.1109/ICCV.2011.6126326
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hinton G.E., 2018, P INT C LEARN REPR I
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hu YL, 2019, PROC CVPR IEEE, P3380, DOI 10.1109/CVPR.2019.00350
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li C, 2018, LECT NOTES COMPUT SC, V11220, P263, DOI 10.1007/978-3-030-01270-0_16
   Ma J., 2019, IEEE T IND ELECT
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Pavlakos G, 2017, PROC CVPR IEEE, P1263, DOI 10.1109/CVPR.2017.139
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Sabour S, 2017, ADV NEUR IN, V30
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Suwajanakorn S, 2018, ADV NEUR IN, V31
   Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Tulsiani S, 2015, PROC CVPR IEEE, P1510, DOI 10.1109/CVPR.2015.7298758
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yi P, 2020, IEEE T CIRC SYST VID, V30, P2503, DOI 10.1109/TCSVT.2019.2925844
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
   Zhou LG, 2019, IEEE T NEUR NET LEAR, V30, P3275, DOI 10.1109/TNNLS.2018.2890550
NR 42
TC 2
Z9 2
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102790
DI 10.1016/j.jvcir.2020.102790
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900008
DA 2024-07-18
ER

PT J
AU Tsai, CY
   Gao, DQ
   Ruan, SJ
AF Tsai, Chun-Ya
   Gao, De-Qin
   Ruan, Shanq-Jang
TI An effective hybrid pruning architecture of dynamic convolution for
   surveillance videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Optimize CNN; Dynamic convolution; Pruning; Smart surveillance
   application
AB The large-scale surveillance videos analysis becomes important as the development of the intelligent city; however, the heavy computational resources necessary for the state-of-the-art deep learning model makes real-time processing hard to be implemented. As the characteristic of high scene similarity generally existing in surveillance videos, we propose an effective compression architecture called dynamic convolution, which can reuse the previous feature maps to reduce the calculation amount; and combine with filter pruning to further speed up the performance. In this paper, we tested the presented method on 45 surveillance videos with various scenes. The experimental results show that the hybrid pruning architecture can reduce up to 80.4% of FLOPs while preserving the precision within 1.34% mAP; furthermore, the method can improve the processing speed up to 2.8 times compared to the traditional Single Shot MultiBox Detection. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Tsai, Chun-Ya; Gao, De-Qin; Ruan, Shanq-Jang] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Ruan, SJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
EM sjruan@mail.ntust.edu.tw
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2015, BBC NEWS
   [Anonymous], 2014, ARXIV14114464
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ferryman J, 2014, PATTERN RECOGN LETT, V44, P3, DOI 10.1016/j.patrec.2014.01.005
   Guo J, 2018, BRIT MACH VIS C
   Han S., 2016, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Y, 2017, I IEEE EMBS C NEUR E, P138, DOI 10.1109/NER.2017.8008311
   Honghai Liu, 2012, 2012 International Conference on Computer Science and Service System (CSSS), P258, DOI 10.1109/CSSS.2012.72
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang XW, 2015, ACTA POLYM SIN, P1133
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kim Y.D, 2016, P 4 INT C LEARN REPR
   Li H., 2017, PRUNING FILTERS EFFI, DOI DOI 10.48550/ARXIV.1608.08710
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Luo JH, 2019, IEEE T PATTERN ANAL, V41, P2525, DOI 10.1109/TPAMI.2018.2858232
   Maggio E., 2007, IEEE INT C AC SPEECH, V1, pI
   Oh S., 2011, P CVPR, P3153, DOI DOI 10.1109/CVPR.2011.5995586
   Polyak A, 2015, IEEE ACCESS, V3, P2163, DOI 10.1109/ACCESS.2015.2494536
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xu Y, 2018, AAAI C ART INT
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 39
TC 3
Z9 3
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102798
DI 10.1016/j.jvcir.2020.102798
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900013
DA 2024-07-18
ER

PT J
AU Tariq, J
   Armghan, A
   Ijaz, A
   Ashraf, I
AF Tariq, Junaid
   Armghan, Ammar
   Ijaz, Amir
   Ashraf, Imran
TI Pure intra mode decision in HEVC using optimized firefly algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Intra mode; Firefly algorithm; Video coding; Most probable mode
ID PREDICTION
AB High Efficiency Video Coding (HEVC) is the latest encoder that increased the intra modes from 9 to 35 to efficiently handle the contents of the video. The HEVC's test model (HM) selects the optimal intra mode using the brute force method which increases the complexity of HEVC. This work, firstly, investigates the feasibility of firefly algorithm (FFA) due to its exploration and exploitation characteristics to expedite the intra mode decision in HEVC. Secondly, a novel objective function is formulated for FFA to efficiently compute the brightness for intra modes in FFA. Thirdly, the parameters of FFA are made dynamic to adjust according to the contents of video sequences. Simulation results demonstrate that the nature inspired algorithm, FFA, pays off by saving a minimum of 27% of the total coding time on average and doesn't sacrifice quality by limiting Bjontegaard delta bit rate (BD-BR) increase to only 0.98% on average. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Tariq, Junaid; Ijaz, Amir; Ashraf, Imran] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
   [Armghan, Ammar] Jouf Univ, Dept Elect Engn, Sakaka, Saudi Arabia.
C3 NITEC University; Al Jouf University
RP Tariq, J (corresponding author), HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
EM jtariq2-c@my.cityu.edu.hk; aarmghan@ju.edu.sa; amirijaz@live.com;
   imran.ashraf@hitecuni.edu.pk
RI Armghan, Ammar/ABA-9560-2021; ashraf, imran/HJA-5212-2022; Ijaz,
   Amir/D-2503-2016
OI Armghan, Ammar/0000-0002-9062-7493; ashraf, imran/0000-0003-4480-2489;
   Ijaz, Amir/0000-0002-6764-667X
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2011, JCTVCF900
   [Anonymous], [No title captured]
   [Anonymous], 2014, ADCONP
   [Anonymous], HIGH EFFICIENCY VIDE
   [Anonymous], [No title captured]
   Bjontegaard G., 2001, Document VCEG-M33
   Chao CF, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/343217
   Chen K, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/1578056
   Hanmadhu M, 2013, INT CONF CONTEMP, P41, DOI 10.1109/IC3.2013.6612237
   Khan HUR, 2019, ARAB J SCI ENG, V44, P2151, DOI 10.1007/s13369-018-3367-z
   Li W, 2019, SIGNAL IMAGE VIDEO P, V13, P17, DOI 10.1007/s11760-018-1323-8
   Lin WY, 2011, IEEE T CIRC SYST VID, V21, P237, DOI 10.1109/TCSVT.2011.2106290
   Shi W, 2018, J REAL-TIME IMAGE PR, V15, P57, DOI 10.1007/s11554-017-0677-4
   Sun XM, 2017, J INEQUAL APPL, DOI 10.1186/s13660-017-1424-x
   TARIQ J, 2019, MULTIMED TOOLS APPL, V78, P1, DOI DOI 10.1007/S11042-018-6670-5
   Tariq J, 2018, J VIS COMMUN IMAGE R, V51, P1, DOI 10.1016/j.jvcir.2017.12.008
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/SMC.2015.311
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1782, DOI 10.1109/SMC.2015.312
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wali I, 2019, SIGNAL IMAGE VIDEO P, V13, P145, DOI 10.1007/s11760-018-1339-0
   Wang HL, 2014, J VIS COMMUN IMAGE R, V25, P1784, DOI 10.1016/j.jvcir.2014.08.007
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Yang, 2008, NATURE INSPIRED META, P242
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhao TS, 2012, IEEE T IMAGE PROCESS, V21, P2607, DOI 10.1109/TIP.2012.2186148
   Zhe Sheng, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P541, DOI 10.1007/978-3-319-04114-8_46
NR 35
TC 14
Z9 14
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2020
VL 68
AR 102766
DI 10.1016/j.jvcir.2020.102766
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LO3GK
UT WOS:000533516900001
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
AF Al-Otum, Hazem Munawer
TI Secure and robust host-adapted color image watermarking using
   inter-layered wavelet-packets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image watermarking; Wavelet-packets; Multispectral analysis
ID SCHEME; OPTIMIZATION
AB This work presents a secure and robust color image watermarking for copyright protection applications, that is based on exploiting the multi-spectral properties of the primary color components of the RGB image. The proposed scheme employs the interconnection between the subbands of the primary color components in the wavelet-packet domain. The scheme is constructed to be adaptive, in the sense that the watermark bits are embedded in safe locations, depending on the inter-layer energy of coefficients in the wavelet-packets. The scheme immunity to attacks is improved by applying a two-level security procedure. To validate the high performance of the proposed scheme, several experimental tests were conducted and a comparative analysis was provided. The obtained results have shown improved water-marking robustness against a wide range of attacks while preserving a high watermarking imperceptibility. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Al-Otum, Hazem Munawer] Jordan Univ Sci & Technol, Fac Engn, EE Dept, Irbid, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, Fac Engn, EE Dept, Irbid, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Al-Otum HM, 2019, MULTIMED TOOLS APPL, V78, P2199, DOI 10.1007/s11042-018-6328-3
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Cedillo-Hernández M, 2014, SIGNAL IMAGE VIDEO P, V8, P49, DOI 10.1007/s11760-013-0459-9
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   COIFMAN RR, 1994, NATO ADV SCI INST SE, V442, P363
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Moghaddam ME, 2013, FORENSIC SCI INT, V233, P193, DOI 10.1016/j.forsciint.2013.09.005
   Nematollahi Mohammad Ali, 2017, Digital watermarking
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Prathap I, 2014, COMPUT ELECTR ENG, V40, P920, DOI 10.1016/j.compeleceng.2014.01.006
   Pun CM, 2008, INT CONF SYST SIGNAL, P173, DOI 10.1109/IWSSIP.2008.4604395
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Rawat S, 2012, OPT COMMUN, V285, P2563, DOI 10.1016/j.optcom.2012.01.067
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Sharma R, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P513, DOI 10.1109/SPIN.2018.8474052
   Singh S, 2017, MULTIMED TOOLS APPL, V76, P19113, DOI 10.1007/s11042-017-4570-8
   Song W, 2015, UBIQUITOUS INT J INF, V6, P613
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Taherinia AH, 2009, 2009 INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY, AND SECURITY (ARES), VOLS 1 AND 2, P150, DOI 10.1109/ARES.2009.132
   Thirugnanam G., 2010, INT J SIGNAL IMAGE P, V1, p80 
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
NR 29
TC 14
Z9 14
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102726
DI 10.1016/j.jvcir.2019.102726
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200009
DA 2024-07-18
ER

PT J
AU Munir, R
   Khan, RA
AF Munir, Rumaisah
   Khan, Rizwan Ahmed
TI An extensive review on spectral imaging in biometric systems: Challenges
   & advancements
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spectral imaging; Biometrics; Face recognition; Spoof attacks; Deep
   learning
ID INFRARED FACE RECOGNITION; ZERNIKE MOMENTS; RANGE SELECTION; INVARIANT;
   REPRESENTATION; PATTERNS; KERNEL; BAND; SPARSITY; TEXTURE
AB Spectral imaging has recently gained traction for face recognition in biometric systems. We investigate the merits of spectral imaging for face recognition and the current challenges that hamper the widespread deployment of spectral sensors for face recognition. The reliability of conventional face recognition systems operating in the visible range is compromised by illumination changes, pose variations and spoof attacks. Recent works have reaped the benefits of spectral imaging to counter these limitations in surveillance activities (defence, airport security checks, etc.). However, the implementation of this technology for biometrics, is still in its infancy due to multiple reasons. We present an overview of the existing work in the domain of spectral imaging for face recognition, different types of modalities and their assessment, availability of public databases for sake of reproducible research as well as evaluation of algorithms, and recent advancements in the field, such as, the use of deep learning-based methods for recognizing faces from spectral images. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Munir, Rumaisah; Khan, Rizwan Ahmed] Barrett Hodgson Univ, Fac IT, Karachi, Pakistan.
   [Khan, Rizwan Ahmed] Univ Claude Bernard Lyon1, LIRIS, Villeurbanne, France.
C3 Universite Claude Bernard Lyon 1; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon
RP Munir, R (corresponding author), Barrett Hodgson Univ, Fac IT, Karachi, Pakistan.
EM rumaisah.m@gmail.com
RI Khan, Dr Rizwan/JQW-7885-2023; Khan, Rizwan Hasan/F-8276-2014; Khan,
   PhD, Rizwan Ahmed/N-7134-2018
OI Khan, Rizwan Hasan/0000-0002-9965-8982; Khan, PhD, Rizwan
   Ahmed/0000-0003-0819-800X
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Allen D, 2016, FACE RECOGNITION IMA, P1, DOI DOI 10.1007/978-3-319-28501-6_1
   [Anonymous], COMPOSITE MULTILOBE
   [Anonymous], 2016, ARXIV160503428
   [Anonymous], 2006, Computer Vision and Pattern Recognition Workshop, page, DOI DOI 10.1109/CVPRW.2006.28
   [Anonymous], THESIS
   [Anonymous], 2002, Hyperspectral face database
   [Anonymous], 2008, INFORM SCI STAT
   [Anonymous], THERMAL VISIBLE FACE
   [Anonymous], THESIS
   [Anonymous], MULTISPECTRAL BIOMET
   [Anonymous], AUTOMATED LONG RANGE
   [Anonymous], WORKSH FACES INR LIF
   [Anonymous], P 2004 IEEE COMP SOC
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], TECH REP
   [Anonymous], 2018, CORR
   [Anonymous], CORR
   [Anonymous], STUDY USING MIDWAVE
   [Anonymous], 2005, BMVC
   [Anonymous], THESIS
   [Anonymous], MULTIPLE HDB FACE RE
   [Anonymous], 2013, BMVC
   [Anonymous], 2015, DEEP PERCEPTUAL MAPP
   [Anonymous], 1999, Technical Report MS-CIS-99-29
   [Anonymous], 2016, MULTISPECTRAL BIOMET
   [Anonymous], 2005, QUANTITATIVE SUBSURF
   [Anonymous], 2001, IEEE XPLORE, DOI DOI 10.1109/CVPR.2001.990519
   [Anonymous], 2017, 2017 IEEE International Conference on Identity, Security and Behavior Analysis (ISBA)
   [Anonymous], 1998, Independent Component Analysis: Theory and Applications, DOI DOI 10.1007/978-1-4757-2851-4
   [Anonymous], 2005, Encyclopedia Statist. Behav. Sci.
   [Anonymous], 28 AAAI C ART INT
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Bouchech HJ, 2015, MULTIMED TOOLS APPL, V74, P8631, DOI 10.1007/s11042-014-2350-2
   Bourlai T., 2012, Proceedings of the 2012 IEEE International Conference on Intelligence and Security Informatics. Cyberspace, Border, and Immigration Securities (ISI 2012), P196, DOI 10.1109/ISI.2012.6284307
   Bourlai T., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1343, DOI 10.1109/ICPR.2010.1115
   Boyce C., 2006, Computer Vision and Pattern Recognition Workshop, P51
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Cabib D., 2003, uS Patent, Patent No. [6,556,853, 6556853]
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chai ZH, 2014, IEEE T INF FOREN SEC, V9, P14, DOI 10.1109/TIFS.2013.2290064
   Chang H, 2010, MACH VISION APPL, V21, P201, DOI 10.1007/s00138-008-0151-1
   Chang H, 2008, IEEE IMAGE PROC, P2756, DOI 10.1109/ICIP.2008.4712365
   Chang HC, 2008, INT C COMMUN CIRCUIT, P1, DOI 10.1109/ICCCAS.2008.4657714
   Chang H, 2009, IEEE T INF FOREN SEC, V4, P111, DOI 10.1109/TIFS.2008.2012211
   Chang Hui-Chen, 2006, Bulletin of Taichung District Agricultural Improvement Station, P1
   Chang KY, 2012, INT C PATT RECOG, P2985
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Dhamecha TI, 2013, INT CONF BIOMETR
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   Farkas DL, 2001, PIGM CELL RES, V14, P2, DOI 10.1034/j.1600-0749.2001.140102.x
   Farokhi S, 2015, INFORM SCIENCES, V316, P234, DOI 10.1016/j.ins.2015.04.030
   Farokhi S, 2014, DIGIT SIGNAL PROCESS, V31, P13, DOI 10.1016/j.dsp.2014.04.008
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Ghiass RS, 2014, PATTERN RECOGN, V47, P2807, DOI 10.1016/j.patcog.2014.03.015
   Gong DY, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P589, DOI 10.1109/ACPR.2011.6166675
   Goswami D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2160, DOI 10.1109/ICCVW.2011.6130515
   Guo H, 2008, P REL MAINT S, P1
   Guo ZH, 2012, IEEE T INF FOREN SEC, V7, P1094, DOI 10.1109/TIFS.2012.2189206
   Gurton KP, 2014, OPT LETT, V39, P3857, DOI 10.1364/OL.39.003857
   Haddadnia J, 2003, INT J PATTERN RECOGN, V17, P41, DOI 10.1142/S0218001403002265
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Hadid A, 2014, IEEE COMPUT SOC CONF, P113, DOI 10.1109/CVPRW.2014.22
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hermosilla G, 2012, PATTERN RECOGN, V45, P2445, DOI 10.1016/j.patcog.2012.01.001
   Hu SW, 2015, J OPT SOC AM A, V32, P431, DOI 10.1364/JOSAA.32.000431
   Hu YQ, 2012, IEEE T PATTERN ANAL, V34, P1992, DOI 10.1109/TPAMI.2011.283
   Hyvarinen T, 1998, P SOC PHOTO-OPT INS, V3302, P165, DOI 10.1117/12.304581
   Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
   Jain AK, 1997, PATTERN RECOGN, V30, P295, DOI 10.1016/S0031-3203(96)00068-4
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jie Liang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163115
   Jing XY, 2016, PATTERN RECOGN, V59, P14, DOI 10.1016/j.patcog.2016.01.023
   Jinyu Zuo, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P203, DOI 10.1109/BTAS.2012.6374578
   Kalka NathanD., 2011, BIOMETRICS IJCB 2011, P1, DOI DOI 10.1109/1JCB.2011.6117586
   Kang JW, 2006, IEEE IMAGE PROC, P2757, DOI 10.1109/ICIP.2006.313118
   Kannala J, 2012, INT C PATT RECOG, P1363
   Khan RA, 2019, IMAGE VISION COMPUT, V83-84, P61, DOI 10.1016/j.imavis.2019.02.004
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lee SH, 2012, IEEE T IMAGE PROCESS, V21, P2347, DOI 10.1109/TIP.2011.2181526
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Li DQ, 2012, MACH VISION APPL, V23, P391, DOI 10.1007/s00138-011-0331-2
   Li L, 2018, IET BIOMETRICS, V7, P3, DOI 10.1049/iet-bmt.2017.0089
   Li S.Z., 2009, CVPR WORKSHOPS 2009, P1
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Martinez Brais., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010, P48
   Méndez H, 2009, LECT NOTES COMPUT SC, V5558, P327, DOI 10.1007/978-3-642-01793-3_34
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   MUSAVI MT, 1992, NEURAL NETWORKS, V5, P595, DOI 10.1016/S0893-6080(05)80038-3
   Nadya S, 2016, FRONT CELL INFECT MI, V6, DOI 10.3389/fcimb.2016.00036
   Narang N, 2015, IMAGE VISION COMPUT, V33, P26, DOI 10.1016/j.imavis.2014.10.005
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Nicolò F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813
   Nicolo F, 2011, LECT NOTES COMPUT SC, V6754, P180, DOI 10.1007/978-3-642-21596-4_19
   Nischan M. L., 2003, Lincoln Laboratory Journal, V14, P131
   Nixon KA, 2005, P SOC PHOTO-OPT INS, V5779, P214, DOI 10.1117/12.606643
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Osia N, 2014, IMAGE VISION COMPUT, V32, P847, DOI 10.1016/j.imavis.2014.06.010
   Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   Peng M, 2016, INFORMATION, V7, DOI 10.3390/info7040061
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P672, DOI 10.1109/CVPRW.2017.96
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Reale C, 2014, IEEE IMAGE PROC, P328, DOI 10.1109/ICIP.2014.7025065
   Ross A, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P1
   Rowe RK, 2005, Proceedings from the Sixth Annual IEEE Systems, Man and Cybernetics Information Assurance Workshop, P14, DOI 10.1109/IAW.2005.1495928
   Sarfraz MS, 2017, INT J COMPUT VISION, V122, P426, DOI 10.1007/s11263-016-0933-2
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shaw G. A., 2003, Lincoln Laboratory Journal, V14, P3
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shikhaliev PM, 2011, PHYS MED BIOL, V56, P1905, DOI 10.1088/0031-9155/56/7/001
   Short N, 2015, OPT LETT, V40, P882, DOI 10.1364/OL.40.000882
   Shoujia Wang, 2012, Journal of Multimedia, V7, P429, DOI 10.4304/jmm.7.6.429-433
   Sim T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P214, DOI 10.1109/AFGR.2000.840637
   Socolinsky DA, 2002, INT C PATT RECOG, P217, DOI 10.1109/ICPR.2002.1047436
   SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2
   Steiner H, 2016, INT CONF BIOMETR
   Steiner H, 2016, J SENSORS, V2016, DOI 10.1155/2016/9682453
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Uzair M, 2015, OPT EXPRESS, V23, P15160, DOI 10.1364/OE.23.015160
   Uzair M, 2015, IEEE T IMAGE PROCESS, V24, P1127, DOI 10.1109/TIP.2015.2393057
   Vetrekar NT, 2017, IEEE INT CONF AUTOMA, P924, DOI 10.1109/FG.2017.132
   Vetrekar NT, 2016, IEEE CONF IMAGING SY, P324, DOI 10.1109/IST.2016.7738245
   Wang H, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.10.103102
   Wang R., 2008, 2008 IEEE C COMPUTER, P1
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Whitelam C, 2015, COMPUT VIS IMAGE UND, V139, P59, DOI 10.1016/j.cviu.2015.05.001
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu D, 2008, J FOOD ENG, V88, P474, DOI 10.1016/j.jfoodeng.2008.03.005
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang D, 2010, IEEE T INSTRUM MEAS, V59, P480, DOI 10.1109/TIM.2009.2028772
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao HT, 2014, NEUROCOMPUTING, V133, P427, DOI 10.1016/j.neucom.2013.12.019
   Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
   Zimmermann T, 2003, FEBS LETT, V546, P87, DOI 10.1016/S0014-5793(03)00521-0
NR 164
TC 10
Z9 10
U1 2
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102660
DI 10.1016/j.jvcir.2019.102660
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, QC
   Guo, GD
AF Wang, Qiangchang
   Guo, Guodong
TI Benchmarking deep learning techniques for face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Convolutional neural networks; Face recognition; GPU;
   PyTorch; TensorFlow; Caffe; AlexNet; ArcFace; Center-loss; CosFace;
   DenseNet; GoogLeNet; Inception-v3; LightCNN; ResNet; SphereFace; VGG
AB Recent progresses in Convolutional Neural Networks (CNNs) and GPUs have greatly advanced the state-of-the-art performance for face recognition. However, training CNNs for face recognition is complex and time-consuming. Multiple factors need to be considered: deep learning frameworks, GPU platforms, deep network models, training datasets and test datasets. The deep models under different frameworks may perform differently. Based on this concern, we compare three deep learning frameworks and benchmark the performance of different CNN models on five GPU platforms. The scalability issue is also explored. Our findings can help researchers select appropriate face recognition models, deep learning frameworks, GPU platforms, and training datasets for their face recognition tasks. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Qiangchang; Guo, Guodong] West Virginia Univ, 109 Res Way POB 6109, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Guo, GD (corresponding author), West Virginia Univ, 109 Res Way POB 6109, Morgantown, WV 26506 USA.
EM guodong.guo@mail.wvu.edu
RI Wang, Qiangchang/ABG-7648-2021; Guo, Guodong/M-5066-2015
OI Wang, Qiangchang/0000-0003-3707-1761; Guo, Guodong/0000-0001-9583-0055
FU NSF CITeR grant
FX The work was partly supported by a NSF CITeR grant.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], ARXIV181011112
   [Anonymous], PROC INT C
   [Anonymous], ARXIV171110103
   [Anonymous], 2015, CVPR
   [Anonymous], NIPS W
   [Anonymous], ARXIV180308494
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322
   [Anonymous], ARXIV190712411
   [Anonymous], CVPR
   [Anonymous], ARXIV151102683
   [Anonymous], PLOS ONE
   [Anonymous], IEEE J BIOMED HLTH I
   [Anonymous], ARXIV14045997
   [Anonymous], MONTHLY ARXIV ORG ME
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], ARXIV171008092
   [Anonymous], PERFORMANCE ANAL CNN
   [Anonymous], 0749 U MASS
   [Anonymous], ARXIV181108201
   [Anonymous], ARXIV14100759
   [Anonymous], ARXIV180109414
   [Anonymous], ARXIV160206709
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   [Anonymous], ARXIV160400981
   [Anonymous], ARXIV14117923
   [Anonymous], ARXIV150607310
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Bansal Ankan, 2017, 2017 IEEE International Joint Conference on Biometrics (IJCB), P464, DOI 10.1109/BTAS.2017.8272731
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P90, DOI 10.1109/LSP.2014.2347419
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding Y, 2019, J VIS COMMUN IMAGE R, V61, P1, DOI 10.1016/j.jvcir.2019.03.019
   Duan YQ, 2019, PROC CVPR IEEE, P3410, DOI 10.1109/CVPR.2019.00353
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Ferrari C, 2018, IEEE T IMAGE PROCESS, V27, P5638, DOI 10.1109/TIP.2018.2861359
   Guo GD, 2018, IEEE INT CONF AUTOMA, P436, DOI 10.1109/FG.2018.00070
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Huang G.B., 2014, LABELED FACES WILD U
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang M, 2019, IEEE T INF FOREN SEC, V14, P2676, DOI 10.1109/TIFS.2019.2904840
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Liu J, 2016, IEEE SYS MAN CYBERN, P1753, DOI 10.1109/SMC.2016.7844491
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi SH, 2016, INT C CLOUD COMP BIG, P99, DOI [10.1109/CCBD.2016.029, 10.1109/CCBD.2016.33]
   Silberman N., 2017, Tensorflowslim image classification model library
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu JH, 2019, IEEE INT CON MULTI, P1480, DOI 10.1109/ICME.2019.00256
   Wu TY, 2019, IEEE INT CON MULTI, P940, DOI 10.1109/ICME.2019.00166
   Yang M, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P629, DOI 10.1109/ACPR.2017.138
   Zalluhoglu C, 2019, J VIS COMMUN IMAGE R, V60, P170, DOI 10.1016/j.jvcir.2019.02.016
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 61
TC 23
Z9 25
U1 5
U2 51
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102663
DI 10.1016/j.jvcir.2019.102663
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700025
DA 2024-07-18
ER

PT J
AU Nan, LD
   Rui, H
   Zhuo, WW
   Wen, HJ
   Yuan, WX
   Bo, P
AF Nan, Liu Dun
   Rui, Hou
   Zhuo, Wu Wen
   Wen, Hua Jing
   Yuan, Wang Xuan
   Bo, Pang
TI Research on infrared image enhancement and segmentation of power
   equipment based on partial differential equation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Partial differential equation; Power equipment; Infrared image; Quality
   model
ID OBJECT DETECTION; LEVEL; NOISE; DIFFUSION
AB With the development of science and technology, image processing is applied more and more widely. In power system, a large number of power equipment always work in harsh environment, which easily leads to equipment damage, not only affects the normal operation of equipment, but also may lead to accidents. In order to ensure the normal operation of power equipment, it is necessary to monitor the operation status of power equipment in real time. The key of real-time monitoring is how to analyze the quality of infrared image. In order to improve the quality of infrared image of power equipment, this paper analyses the traditional image processing technology, mainly using partial differential equation to optimize and improve the image enhancement algorithm and segmentation method, so as to improve the quality of infrared image of power equipment. Firstly, in the aspect of infrared image enhancement, partial differential equation is used to improve the shortcomings of the traditional contrast enhancement method, enhance the texture details of the image while effectively improving the brightness visual effect of the image; then, in image segmentation, the stopping function of GAC model of classical partial differential equation is improved to improve the effect of infrared image segmentation of power equipment. Through the analysis of simulation experiments, this paper improves the traditional method by using partial differential equation in image enhancement and image segmentation, which can effectively improve the quality and segmentation effect of infrared image of power equipment. (C) 2019 Published by Elsevier Inc.
C1 [Nan, Liu Dun; Rui, Hou; Zhuo, Wu Wen; Wen, Hua Jing] North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
   [Nan, Liu Dun] North China Elect Power Univ, Beijing Key Lab New Energy & Low Carbon Dev, Beijing 102206, Peoples R China.
   [Yuan, Wang Xuan] Jibei Power Exchange Ctr, Beijing 100053, Peoples R China.
   [Bo, Pang] Beijing Power Exchange Ctr, Beijing 100031, Peoples R China.
C3 North China Electric Power University; North China Electric Power
   University
RP Rui, H (corresponding author), North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
EM hankrui@aliyun.com; wang.xuanyuan@jibei.sgcc.com; bo-pang@sgcc.com.cn
RI bo, pang/KGL-7524-2024
FU Key Projects of Philosophy and Social Sciences Research, Ministry of
   Education [:18JZD032, JB2019078]
FX Key Projects of Philosophy and Social Sciences Research, Ministry of
   Education:18JZD032; Fundamental Research Funding for the Central
   Universities: JB2019078
CR Abu-Siada A, 2018, IET SCI MEAS TECHNOL, V12, P492, DOI 10.1049/iet-smt.2017.0412
   Amaya I, 2017, INVERSE PROBL SCI EN, V25, P864, DOI 10.1080/17415977.2016.1209747
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Aubert G., 2006, APPL INTELL, V40, P291
   Balovsyak SV, 2018, CYBERN SYST ANAL+, V54, P662, DOI 10.1007/s10559-018-0067-3
   Bondzulic BP, 2016, ELECTRON LETT, V52, P454, DOI 10.1049/el.2015.3784
   Bourlioux A, 2002, PHYS FLUIDS, V14, P881, DOI 10.1063/1.1430736
   Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P269, DOI 10.1109/TIP.1998.661176
   Chang J., 2018, J VISUAL COMMUN IMAG
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   DeCarli C, 1996, JMRI-J MAGN RESON IM, V6, P519, DOI 10.1002/jmri.1880060316
   Di Y, 2017, INT J OPHTHALMOL-CHI, V10, P336, DOI 10.18240/ijo.2017.03.02
   Fan HP, 2005, PATTERN RECOGN LETT, V26, P1139, DOI 10.1016/j.patrec.2004.10.010
   Gotzmann M, 2012, EUR J HEART FAIL, V14, P1155, DOI 10.1093/eurjhf/hfs108
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   JAIN AK, 1978, IEEE T AUTOMAT CONTR, V23, P817, DOI 10.1109/TAC.1978.1101881
   Malek-Mohammadi M, 2016, IEEE T SIGNAL PROCES, V64, P6650, DOI 10.1109/TSP.2016.2612179
   Carbonell JM, 2010, J ENG MECH, V136, P455, DOI 10.1061/(ASCE)EM.1943-7889.0000086
   Mayers D.F., 2005, AM MATH MONTHLY, V54, P3
   Meng XY, 2017, MULTIMED TOOLS APPL, V76, P17651, DOI 10.1007/s11042-015-2881-1
   Moo EK, 2013, J BIOMECH, V46, P2024, DOI 10.1016/j.jbiomech.2013.06.007
   Murahira K, 2013, ELECTR COMMUN JPN, V96, P57, DOI 10.1002/ecj.11397
   Odibat Z, 2008, APPL MATH MODEL, V32, P28, DOI 10.1016/j.apm.2006.10.025
   Rajeswari C., 2014, INT J COMPUT APPL, V98, P34
   ROGERS MM, 1991, PHYS FLUIDS A-FLUID, V3, P144, DOI 10.1063/1.857873
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Sun Y L., 2014, COMPUTER KNOWLEDGE T, V43, P183
   Tanabe Y, 2016, RADIOLOGICAL PHYS TE, V10, P1
   Wang FB, 2018, MICROW OPT TECHN LET, V60, P854, DOI 10.1002/mop.31062
   Wu YF, 2012, IEEE T PLASMA SCI, V40, P1371, DOI 10.1109/TPS.2012.2187802
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang X., 2017, J FUNCT ANAL, V258, P1361
NR 38
TC 9
Z9 9
U1 2
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102610
DI 10.1016/j.jvcir.2019.102610
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600008
DA 2024-07-18
ER

PT J
AU Yuan, Y
   Wang, C
AF Yuan, Ying
   Wang, Cong
TI IPTV video quality assessment model based on neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE BP neural network; IPTV video; Quality assessment; Clustering analysis
ID OBJECT DETECTION
AB In recent years, with the continuous development of network science and technology and the continuous promotion of "three networks convergence", IPTV (Interactive Network Television) has shown a rapid development trend. IPTV is different from the traditional one-way broadcasting mode of television, it can achieve interaction with the audience, and provide more personalized and diversified videos. With the rapid development of new media, massive video resources and a large number of video-related information are sweeping in. The evaluation of video can no longer be limited to the ratings of traditional platforms. Video playback on new media platforms, network impact, video content and other related data are also important indicators affecting video evaluation. Video quality is closely related to video content characteristics. Different videos have different sensitivity to the same packet loss rate. The IPTV video quality evaluation model based on content features considers the video content characteristics. Firstly, the QP, bit rate and motion vector (MV) information of the video is obtained by analyzing the video stream. Then, the time complexity of the video is calculated by using the obtained MV, and the spatial complexity of the video is calculated by quantization parameters and bit rate. Videos are classified by clustering analysis. On this basis, the BP neural network is used to establish the model and evaluate the video quality, so as to better reflect the visual perception of the human eye. The model has low computational complexity and is suitable for IPTV video quality assessment with certain computing power in network nodes. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yuan, Ying] Northeastern Univ Qinhuangdao, Comp Ctr, Qinhuangdao, Hebei, Peoples R China.
   [Wang, Cong] Northeastern Univ Qinhuangdao, Dept Comp & Commun Engn, Qinhuangdao, Hebei, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Wang, C (corresponding author), Northeastern Univ Qinhuangdao, Dept Comp & Commun Engn, Qinhuangdao, Hebei, Peoples R China.
EM yuanying@neuq.edu.cn; congw@neuq.edu.cn
FU Basic scientific research operating found of central universities
   [N182304021]; Scientific research plan for institutions of higher
   learning of Hebei province [ZD2019306]
FX This work was supported by the Basic scientific research operating found
   of central universities under Grant No. N182304021, and the Scientific
   research plan for institutions of higher learning of Hebei province
   under Grant No. ZD2019306.
CR Abdollahpouri A, 2014, TELECOMMUN SYST, V55, P185, DOI 10.1007/s11235-013-9774-2
   Adilov N, 2014, J MEDIA ECON, V27, P118, DOI 10.1080/08997764.2014.934560
   [Anonymous], NEUR PROCESS LETT
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Ben Amor M, 2016, J SOC INF DISPLAY, V24, P696, DOI 10.1002/jsid.517
   Calixto G.M., 2014, TEL S
   Chang HY, 2014, COMPUT J, V57, P1776, DOI 10.1093/comjnl/bxt093
   Chang QQ, 2018, J DISCRET MATH SCI C, V21, P849, DOI 10.1080/09720529.2018.1479167
   Elmisery A.M., 2016, MULTIMED TOOLS APPL, V75, P1
   Gaber SMA, 2014, MULTIMED TOOLS APPL, V70, P1987, DOI 10.1007/s11042-012-1209-7
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hassan MM, 2015, CLUSTER COMPUT, V18, P1539, DOI 10.1007/s10586-015-0476-2
   Hu SD, 2017, IEEE T CIRC SYST VID, V27, P1844, DOI 10.1109/TCSVT.2016.2556499
   Hwang IS, 2014, J OPT COMMUN NETW, V6, P695, DOI 10.1364/JOCN.6.000695
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Jiang GY, 2018, J VIS COMMUN IMAGE R, V50, P247, DOI 10.1016/j.jvcir.2017.12.001
   Kang L, 2018, COMPLEXITY, DOI 10.1155/2018/6703908
   Kim H, 2017, ANN WORK NETW, P1
   Kumcu A, 2017, IEEE J-STSP, V11, P48, DOI 10.1109/JSTSP.2016.2638681
   Li ZJ, 2014, APPL MECH MATER, V469, P278, DOI 10.4028/www.scientific.net/AMM.469.278
   Loh WT, 2018, SENS IMAGING, V19, DOI 10.1007/s11220-018-0216-9
   Luo DX, 2014, IEEE T BROADCAST, V60, P61, DOI 10.1109/TBC.2013.2295894
   Moldovan AN, 2016, IEEE T BROADCAST, V62, P610, DOI 10.1109/TBC.2016.2570002
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Oliveira M.D., 2016, IEEE INT S BROADB MU
   Oliveira R, 2014, PROCEDIA COMPUT SCI, V27, P113, DOI 10.1016/j.procs.2014.02.014
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Qiang Luo, 2017, Key Engineering Materials, V726, P338, DOI 10.4028/www.scientific.net/KEM.726.338
   Rodríguez DZ, 2014, IEEE T CONSUM ELECTR, V60, P436, DOI 10.1109/TCE.2014.6937328
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   [宋洋 Song Yang], 2014, [光电子·激光, Journal of Optoelectronics·Laser], V25, P1983
   Steiding C, 2014, MED PHYS, V41, DOI 10.1118/1.4863507
   Storrs K, 2018, PICT COD SYMP, P169, DOI 10.1109/PCS.2018.8456273
   Tavakoli S, 2015, SIGNAL PROCESS-IMAGE, V39, P432, DOI 10.1016/j.image.2015.05.001
   Tzelepis C, 2016, IEEE IMAGE PROC, P2410, DOI 10.1109/ICIP.2016.7532791
   Vranjes M, 2018, MULTIMED TOOLS APPL, V77, P21053, DOI 10.1007/s11042-017-5544-6
   Wang Q., 2018, INT J PATTERN RECOGN, V32
   Wang Q., 2018, INT J PATTERN RECOGN, V32
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Yao Jun-cai, 2016, Optics and Precision Engineering, V24, P659, DOI 10.3788/OPE.20162403.0659
   Zhang JR, 2014, APPL MECH MATER, V556-562, P5582, DOI 10.4028/www.scientific.net/AMM.556-562.5582
NR 45
TC 6
Z9 7
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102629
DI 10.1016/j.jvcir.2019.102629
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600019
DA 2024-07-18
ER

PT J
AU Zhang, XK
   Hou, J
AF Zhang, Xikun
   Hou, Jie
TI Quality assessment towards cell diffraction image based on multi-channel
   feature fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Cell diffraction image; Deep neural network
ID DEEP
AB Image quality assessment towards cell diffraction image is significant for both the academic and medical domain. It plays an important role in medical detection and recognition, such as cell morphology and heterogeneity classification. However, cell diffraction image quality assessment is still a challenging task due to the high heterogeneity of cells and various appearance. To solve this problem, we propose a cell diffraction image quality assessment. More specifically, we first collect cell diffraction images including Jurkat and Ramos. To remove cell impurity and debris images, we leverage the IC-means clustering algorithm and support vector machine (SVM) to eliminate these images. Subsequently, we calculate the Gray Level Co-occurrence Matrix (GLCM) of each image and extract deep representation by using DNN. Afterward, we fuse luminance, contrast, GLCM, and deep representation to calculate the feature similarity between the reference image and the test image. Extensive experiments conducted on Jurkat cells and Ramos cells datasets have shown the effectiveness of our proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Xikun] Tianjin Univ, Sch Precis Instrument & Optoelect Engn, Tianjin, Peoples R China.
   [Zhang, Xikun] Tianjin Open Univ, Tianjin, Peoples R China.
   [Hou, Jie] Tianjin Med Univ, Sch Basic Med Sci, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin Medical University
RP Zhang, XK (corresponding author), Tianjin Univ, Sch Precis Instrument & Optoelect Engn, Tianjin, Peoples R China.
EM zhangxk@tju.edu.cn; houj@tmu.edu.cn
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2008, ADV NEURAL INFORM PR, DOI DOI 10.1109/ICISS.2008.7
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], COMPUT VISION PATTER
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   [Anonymous], 2011, AISTATS
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   CHEN PF, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P2942, DOI 10.1109/ICNN.1994.374700
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Raina R., 2007, P 24 INT C MACH LEAR, P759
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 24
TC 0
Z9 0
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102632
DI 10.1016/j.jvcir.2019.102632
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600020
DA 2024-07-18
ER

PT J
AU Wang, MR
   Liu, XB
   Soomro, NQ
   Han, GH
   Liu, WH
AF Wang, Murong
   Liu, Xiabi
   Soomro, Nouman Q.
   Han, Guanhui
   Liu, Weihua
TI Content-sensitive superpixel segmentation via self-organization-map
   neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Superpixel segmentation; Content sensitive; Self-Organization Map (SOM);
   Clustering
ID IMAGE; SHIFT
AB Content-sensitive superpixel segmentation generates small superpixels in content-dense regions and large superpixels in content-sparse regions. It achieves higher segmentation accuracy than traditional superpixels. In this paper, we propose a content-sensitive superpixel segmentation algorithm based on Self-Organization-Map (SOM) neural network. First, we propose a novel metric to measure the content-sensitiveness of superpixels. Second, by using this metric, we develop a sampling algorithm to sample pixels from image according to their content-sensitiveness. Finally, a SOM neutral network is trained with the sampled pixels and used to segment the image into content-sensitive superpixels. The Berkeley Image Segmentation database and INRIA database are used to evaluate the proposed method. The experiment results show that the proposed approach outperforms state-of-the-art methods. (C) 2019 Published by Elsevier Inc.
C1 [Wang, Murong; Liu, Xiabi; Liu, Weihua] Beijing Inst Technol, Dept Comp Sci, Beijing, Peoples R China.
   [Soomro, Nouman Q.] Mehran Univ Engn & Technol, Dept Software Engn, SZAB Campus, Khairpur, Pakistan.
   [Han, Guanhui] Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou, Henan, Peoples R China.
C3 Beijing Institute of Technology; Henan University of Technology
RP Liu, XB; Liu, WH (corresponding author), Beijing Inst Technol, Dept Comp Sci, Beijing, Peoples R China.; Soomro, NQ (corresponding author), Mehran Univ Engn & Technol, Dept Software Engn, SZAB Campus, Khairpur, Pakistan.; Han, GH (corresponding author), Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou, Henan, Peoples R China.
EM wangmurong@bit.edu.cn; liuxiabi@bit.edu.cn; noumansoomro@gmail.com;
   hanguanghui@outlook.com; liu_weihua@126.com
RI Han, Guanghui/ABH-8627-2022; Liu, Wenjing/ACS-5787-2022; Han,
   Guanghui/AAE-9435-2022
OI Han, Guanghui/0000-0001-9043-722X; liu, weihua/0000-0001-5787-4372
FU National Natural Science Foundation of China [60973059, 81171407];
   Program for New Century Excellent Talents in University of China
   [NCET-10-0044]
FX This work was supported in part by National Natural Science Foundation
   of China [grant numbers 60973059, 81171407) and Program for New Century
   Excellent Talents in University of China [grant number NCET-10-0044].
CR Abdelsamea MM, 2015, NEUROCOMPUTING, V149, P820, DOI 10.1016/j.neucom.2014.07.052
   Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   [Anonymous], 2015, COMPUT VIS MEDIA
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bódis-Szomorú A, 2015, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2015.7298812
   Cai KH, 2012, INT CONF SIGN PROCES, P993, DOI 10.1109/ICoSP.2012.6491746
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai Tang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P765, DOI 10.1109/ICME.2012.184
   Deng D, 2007, PATTERN RECOGN, V40, P718, DOI 10.1016/j.patcog.2006.05.022
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kohonen T, 2006, NEURAL NETWORKS, V19, P723, DOI 10.1016/j.neunet.2006.05.001
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li L, 2013, PROC CVPR IEEE, P3174, DOI 10.1109/CVPR.2013.408
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81
   Rynkiewicz J, 2006, NEURAL NETWORKS, V19, P830, DOI 10.1016/j.neunet.2006.05.016
   Schick A, 2012, INT C PATT RECOG, P930
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stutz D., 2015, SUPERPIXEL SEGMENTAT
   Sun X, 2017, INT CONF INFO SCI, P230, DOI 10.1109/ICIST.2017.7926761
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang F, 2014, PROC CVPR IEEE, P3142, DOI 10.1109/CVPR.2014.402
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P1241, DOI 10.1109/TPAMI.2012.47
   Wang MR, 2017, SIGNAL PROCESS-IMAGE, V56, P28, DOI 10.1016/j.image.2017.04.007
   Zeng G, 2011, IEEE I CONF COMP VIS, P447, DOI 10.1109/ICCV.2011.6126274
NR 34
TC 3
Z9 3
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102572
DI 10.1016/j.jvcir.2019.102572
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200016
DA 2024-07-18
ER

PT J
AU Tiirola, J
AF Tiirola, Juha
TI A learning based approach to additive, correlated noise removal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Correlated noise; Convolutional neural networks; Deep
   learning
AB In this paper, removal of additive, signal-independent, correlated noise from images is considered. We consider the non-blind case, meaning that the stationary autocovariance function of the noise is assumed to be known. The denoising method is based on unrolled optimization where in the half-quadratic energy minimization each proximal step is replaced by a learnt convolutional neural network. The proximal steps take place in learnt transform domains. Functions producing the regularization parameters are also learnt. We assume that we have a distribution for autocovariance functions in order to be able to draw samples. For simplicity, we assume that the noise has low-pass spectral character and a typical autoco-variance function has a relatively simple form. The experimental results demonstrate that in terms of PSNR values, the method performs better than two classical methods and a method based on a learnt patch prior. (C) 2019 Elsevier Inc. All rights reserved.
EM juha.a.tiirola@gmail.com
CR Aelterman J., 2010, RECENT ADVANCES IN S, P211
   [Anonymous], WAVELET TOUR SIGNAL
   Bigdeli SA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P33, DOI 10.5220/0006532100330044
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Cao B, 2011, AIP ADV, V1, DOI 10.1063/1.3647307
   Chang JHR, 2017, IEEE I CONF COMP VIS, P5889, DOI 10.1109/ICCV.2017.627
   Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163
   Colom M, 2015, IEEE T IMAGE PROCESS, V24, P3162, DOI 10.1109/TIP.2015.2438537
   Diamond S., 2017, ABS170508041 CORR
   Duchi J., 2009, P 22 INT C NEUR INF
   Gong D., 2018, ABS180403368 CORR
   Goossens Bart, 2011, Discrete Wavelet Transforms - Algorithms and Applications, P255
   Goossens B., 2008, 2008 International Workshop on Local and Non-Local Approximation in Image Processing, P143
   Heide F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661260
   Kokaram A, 2012, IEEE IMAGE PROC, P1201, DOI 10.1109/ICIP.2012.6467081
   Kruse J, 2017, IEEE I CONF COMP VIS, P4596, DOI 10.1109/ICCV.2017.491
   Lebrun M, 2015, IEEE T IMAGE PROCESS, V24, P3149, DOI 10.1109/TIP.2015.2439041
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meinhardt T, 2017, IEEE I CONF COMP VIS, P1799, DOI 10.1109/ICCV.2017.198
   Ponomarenko N. N., 2008, SPIE P, V68, P68120
   Portilla J, 2004, IEEE IMAGE PROC, P1217
   Rond A, 2016, J VIS COMMUN IMAGE R, V41, P96, DOI 10.1016/j.jvcir.2016.09.009
   RUBEL AS, 2015, SPIE P, V9399
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Stoica P., 2005, SPECTRAL ANAL SIGNAL
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang RX, 2018, IEEE T IMAGE PROCESS, V27, P2897, DOI 10.1109/TIP.2018.2815084
   Xiao L, 2018, IEEE T IMAGE PROCESS, V27, P4091, DOI 10.1109/TIP.2018.2831925
   Zhang JW, 2017, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2017.737
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zoran D., 2011, P 2011 INT C COMP VI
NR 34
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 286
EP 294
DI 10.1016/j.jvcir.2019.06.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600028
DA 2024-07-18
ER

PT J
AU Wang, TW
   Duan, P
   Ma, BX
   Wu, P
   Lu, WZ
AF Wang, Tingwei
   Duan, Peng
   Ma, Bingxian
   Wu, Peng
   Lu, Weizhi
TI Action recognition using dynamic hierarchical trees
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Hierarchical modeling; Evolution; Tree kernel
ID GRAPH KERNELS; REPRESENTATION
AB Hierarchical models have shown their effectiveness for action recognition. However, most of the existing hierarchy construction methods fail to model the complex motion patterns in videos, and thus are vulnerable to the interference of the inevitable noise in action videos. Therefore, we propose a Dynamic Hierarchical Tree (DHT) model to characterize such complex motion for better recognition performance. First, a minimum maximum DTW (mmDTW) is developed to produce more stable atomic actions by limiting the minimum and maximum lengths of atomic actions. Then an aggregation method is utilized to construct a DHT for each video by merging atomic actions from bottom to top. Not only the similarity between frames but also the compatibility of dynamic evolution between frames and segments is exploited for the mmDTW and the aggregation process, making the DHTs more suitable for modeling actions in videos. Finally, a k-Nearest Neighbors Edge Pairs (kNNEP) kernel is proposed to compare two DHTs by using the mean similarity of k nearest neighbors edge pairs. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Tingwei; Ma, Bingxian; Wu, Peng] Univ Jinan, Sch Informat Sci & Engn, Jinan 250013, Shandong, Peoples R China.
   [Duan, Peng] Liaocheng Univ, Sch Comp Sci, Liaocheng 252059, Shandong, Peoples R China.
   [Wang, Tingwei; Ma, Bingxian; Wu, Peng] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent C, Jinan 250013, Shandong, Peoples R China.
   [Lu, Weizhi] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
C3 University of Jinan; Liaocheng University; University of Jinan; Shandong
   University
RP Wang, TW (corresponding author), Univ Jinan, Sch Informat Sci & Engn, Jinan 250013, Shandong, Peoples R China.; Lu, WZ (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
EM tingweiwang@ujn.edu.cn; wzlu@sdu.edu.cn
RI Wang, Ting-Wei/ABB-6079-2021; Duan, Peng/ITV-2620-2023
OI Wang, Ting-Wei/0000-0003-3463-643X; Duan, Peng/0000-0002-7396-7592
FU Natural Science Foundation of Shandong Province [ZR2016FL13]; Special
   fund plan for local science and technology development lead by central
   authority universities [2015B03114]; Doctoral Scientific Fund Project of
   University of Jinan [XBS1837]
FX This research is partially supported by Natural Science Foundation of
   Shandong Province (Grant No. ZR2016FL13), Special fund plan for local
   science and technology development lead by central authority
   universities (Grant No. 2015B03114), and Doctoral Scientific Fund
   Project of University of Jinan (Grant No. XBS1837).
CR [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Borgwardt KM, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P74, DOI 10.1109/ICDM.2005.132
   Chen QQ, 2016, NEUROCOMPUTING, V173, P364, DOI 10.1016/j.neucom.2015.03.124
   Collins M, 2002, ADV NEUR IN, V14, P625
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feragen A., 2013, ADV NEURAL INFORM PR, P216
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Gaidon A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.30
   Gaidon A, 2014, INT J COMPUT VISION, V107, P219, DOI 10.1007/s11263-013-0677-1
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   GRUNDMANN M, 2010, PROC CVPR IEEE, P2141, DOI DOI 10.1109/CVPR.2010.5539893
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   Hoai M., 2014, Asian Conference on Computer Vision, P3, DOI DOI 10.1007/978-3-319-16814-21
   Jain A, 2013, PROC CVPR IEEE, P2571, DOI 10.1109/CVPR.2013.332
   Kriege N. M., 2012, P INT C MACH LEARN, P291
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Lan ZZ, 2015, PROC CVPR IEEE, P204, DOI 10.1109/CVPR.2015.7298616
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Lu JS, 2015, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2015.7299000
   Ma SG, 2015, PROC CVPR IEEE, P5024, DOI 10.1109/CVPR.2015.7299137
   Ma SG, 2013, IEEE I CONF COMP VIS, P2744, DOI 10.1109/ICCV.2013.341
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Ni BB, 2015, INT J COMPUT VISION, V111, P229, DOI 10.1007/s11263-014-0742-4
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Peng XJ, 2014, INT C PATT RECOG, P2607, DOI 10.1109/ICPR.2014.450
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Shervashidze Nino, 2009, P INT C ART INT STAT, P488
   Su B, 2017, IEEE T IMAGE PROCESS, V26, P5784, DOI 10.1109/TIP.2017.2745212
   Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Wang L, 2013, IEEE I CONF COMP VIS, P3168, DOI 10.1109/ICCV.2013.393
   Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334
   Zhang W., 2018, IEEE T CIRC SYST VID, DOI [10.1109/TCSVI-.2018.2872957, DOI 10.1109/TCSVI-.2018.2872957]
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
   2004, INT C PATT RECOG, P32, DOI DOI 10.1109/ICPR.2004.747
   2015, IEEE C COMP VIS PATT, P4305
NR 49
TC 7
Z9 7
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 315
EP 325
DI 10.1016/j.jvcir.2019.04.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100032
DA 2024-07-18
ER

PT J
AU Zhou, W
   Mok, PY
   Zhou, YH
   Zhou, YP
   Shen, JL
   Qu, Q
   Chau, KP
AF Zhou, Wei
   Mok, P. Y.
   Zhou, Yanghong
   Zhou, Yangping
   Shen, Jialie
   Qu, Qiang
   Chau, K. P.
TI Fashion recommendations through cross-media information retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fashion recommendations; Image retrieval; Human parsing; Image features
ID IMAGE RETRIEVAL; COLOR
AB Fashion recommendation has attracted much attention given its ready applications to e-commerce. Traditional methods usually recommend clothing products to users on the basis of their textual descriptions. Product images, although covering a large resource of information, are often ignored in the recommendation processes. In this study, we propose a novel fashion product recommendation method based on both text and image mining techniques. Our model facilitates two kinds of fashion recommendation, namely, similar product and mix-and-match, by leveraging text-based product attributes and image features. To suggest similar products, we construct a new similarity measure to compare the image colour and texture descriptors. For mix-and-match recommendation, we firstly adopt convolutional neural network (CNN) to classify fine-grained clothing categories and fine-grained clothing attributes from product images. Algorithm is developed to make mix-and-match recommendations by integrating the image extracted categories and attributes information are with text-based product attributes. Our comprehensive experimental work on a real-life online dataset has demonstrated the effectiveness of the proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhou, Wei; Qu, Qiang] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Mok, P. Y.; Zhou, Yanghong; Zhou, Yangping] Hong Kong Polytech Univ, Shenzhen Res Inst, Hong Kong, Peoples R China.
   [Mok, P. Y.; Zhou, Yanghong; Zhou, Yangping; Chau, K. P.] Hong Kong Polytech Univ, Inst Text & Clothing, Hong Kong, Peoples R China.
   [Shen, Jialie] Northumbria Univ, Newcastle Upon Tyne NE2 1XE, Tyne & Wear, England.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Hong Kong Polytechnic University; Hong Kong Polytechnic University;
   Northumbria University
RP Mok, PY (corresponding author), Hong Kong Polytech Univ, Hong Kong, Peoples R China.
EM tracy.mok@polyu.edu.hk
RI Qu, Qiang/IXD-9845-2023; Shen, Jialie/AAX-6851-2020; Mok,
   Tracy/A-1082-2011
OI Qu, Qiang/0000-0001-5814-8460; Mok, Tracy/0000-0002-0635-5318
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [152161/17E]; Innovation and Technology Fund [ITS/253/15]; Hong
   Kong Polytechnic University [G-UA9L]; Guangdong Provincial Department of
   Science and Technology [R2015A030401014]; Shenzhen Science and
   Technology Innovation Commission in China [JCYJ20170303160155330];
   National Natural Science Foundation of China [61602070]
FX The work described in this paper was supported by a grant from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China (Project No. 152161/17E). This work was also partially supported
   by The Innovation and Technology Fund (Grant No. ITS/253/15), The Hong
   Kong Polytechnic University (Grant No. G-YBRG and G-UA9L), Guangdong
   Provincial Department of Science and Technology (Project No.
   R2015A030401014) and Shenzhen Science and Technology Innovation
   Commission (Project No. JCYJ20170303160155330) in China. Wei Zhou was
   also supported by National Natural Science Foundation of China (Under
   Grant No. 61602070).
CR [Anonymous], 2013, ICMR
   [Anonymous], 2011, TOIS
   [Anonymous], ARXIV170707435
   Carlstadt  N., 2015, PANTONE FASHION HOME
   Chandra S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P436, DOI 10.1109/ICCVW.2015.64
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P129, DOI 10.1145/2733373.2806239
   Jagadeesh V, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1925, DOI 10.1145/2623330.2623332
   Jing  P., IEEE T CIRC SYST VID
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu LY, 2018, LECT NOTES COMPUT SC, V10827, P116, DOI 10.1007/978-3-319-91452-7_8
   McAuley J, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P43, DOI 10.1145/2766462.2767755
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Rahul  K., 2014, INTELL COMPUT NETW I, P1037, DOI DOI 10.1007/978-81-322-1665-0_106
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Tian D.P., 2013, International Journal of Multimedia and Ubiquitous Engineering, V8, P385
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Wang XW, 2013, IEEE T MULTIMEDIA, V15, P2035, DOI 10.1109/TMM.2013.2279658
   Wei Di, 2013, 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2013.6
   Yamaguchi K., 2015, BMVC, V1, P4, DOI DOI 10.5244/C.29.51
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zhou  Y., 2016, 3 INT C EXP COMP GRA
   2015, IEEE T PATTERN ANAL, V37, P2402, DOI DOI 10.1109/TPAMI.2015.2408360
NR 36
TC 25
Z9 25
U1 1
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 112
EP 120
DI 10.1016/j.jvcir.2019.03.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chen, FJ
AF Chen, Fujiang
TI Three dimensional image of stress space geotechnical constitutive model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rock and soil; Elastoplasticit; Constitutive model; Numerical simulation
ID OBJECT DETECTION; DYNAMIC DAMAGE; ROCK MASS; SIMULATION; FAILURE;
   PREDICTION; TUNNEL; DEEP
AB There are various discontinuities in geotechnical engineering problems, which can be roughly divided into two types: one is the discontinuities formed by various actions of rock and soil, such as joints, faults, fissures and shear failure surfaces in rock mass; The other is the contact surface between geotechnical structures such as various foundations, retaining structures, underground structures and geotechnical bodies. Therefore, we cannot ignore its existence in computation. At present, the finite element method and other numerical methods have been widely used to solve geotechnical engineering problems, but the solution of the above discontinuous deformation problems has not been well solved. In this paper, the constitutive model of rock and soil is established. Based on the theory of image processing technology, the common methods of dealing with discontinuous deformation problems in finite element method are pointed out, and the unreasonable points are pointed out. It is more reasonable to treat such problems as contact problems, because it can reflect the main characteristics of discontinuous deformation surface. Come on. The three-dimensional image of the constitutive model has three important functions: (1) it is helpful to enhance the theory of constitutive theory and lay a foundation for further mastery of the theory of constitutive theory; (2) Abstract constitutive theory is no longer just a bunch of boring formulas, which is helpful for beginners to improve their interest in learning the theory of constitutive theory. (3) Finally, a three-dimensional image constitutive model of rock and soil is established through experiments, and the program written by MATLAB is compared with the test results of conventional triaxial compression of rock and soil, which fully verifies the correctness and effectiveness of the constitutive model of rock and soil established in this paper. (C) 2019 Published by Elsevier Inc.
C1 [Chen, Fujiang] Sichuan Univ, State Key Lab Hydraul & Mt River Engn, Chengdu 610065, Sichuan, Peoples R China.
C3 Sichuan University
RP Chen, FJ (corresponding author), Sichuan Univ Wangjiang, 24 South,First Ring Rd, Chengdu, Sichuan, Peoples R China.
EM chenfujiang66@126.com
CR [Anonymous], 2018, J DIABETES RES, DOI DOI 10.1016/j.patrec.2018.02.001
   Chen HX, 2013, MECH SYST SIGNAL PR, V40, P469, DOI 10.1016/j.ymssp.2013.06.023
   Chen HX, 2013, SHOCK VIB, V20, P247, DOI [10.1155/2013/598490, 10.3233/SAV-2012-00741]
   Chen M, 2016, CERAM INT, V42, P3130, DOI 10.1016/j.ceramint.2015.10.102
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cui GY, 2015, ROCK SOIL MECH, V36, P439, DOI 10.16285/j.rsm.2015.S2.062
   Forest S, 2016, P ROY SOC A-MATH PHY, V472, DOI 10.1098/rspa.2015.0755
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Jiao YY, 2015, SCI CHINA TECHNOL SC, V58, P1533, DOI 10.1007/s11431-015-5898-9
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Li CB, 2015, ENVIRON EARTH SCI, V73, P5905, DOI 10.1007/s12665-015-4228-7
   Li G, 2015, ROCK MECH ROCK ENG, V48, P2235, DOI 10.1007/s00603-014-0698-2
   Li G, 2015, ROCK SOIL MECH, V36, P1633, DOI 10.16285/j.rsm.2015.06.015
   Liu H., 2018, EXPLO SHOCK WAVES
   Liu HY, 2015, INT J ROCK MECH MIN, V75, P132, DOI 10.1016/j.ijrmms.2015.01.013
   Liu QS, 2018, ROCK MECH ROCK ENG, V51, P1005, DOI 10.1007/s00603-017-1390-0
   Liu W., 2018, J HEBEI U SCI TECHNO
   Liu ZX, 2015, T NONFERR METAL SOC, V25, P954, DOI 10.1016/S1003-6326(15)63684-6
   Mansouri LZ, 2014, MECH MATER, V76, P64, DOI 10.1016/j.mechmat.2014.06.005
   Min Zhang, 2014, Applied Mechanics and Materials, V633-634, P234, DOI 10.4028/www.scientific.net/AMM.633-634.234
   Minga E., 2017, MECCANICA, V6, P1
   Özden UA, 2015, INT J REFRACT MET H, V49, P261, DOI 10.1016/j.ijrmhm.2014.07.022
   Panicaud B., 2015, HDB DAMAGE MECH, P963
   Papenfuss C, 2008, P EST ACAD SCI, V57, P132, DOI 10.3176/proc.2008.3.03
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Tang SB, 2017, ENG FRACT MECH, V178, P93, DOI 10.1016/j.engfracmech.2017.04.008
   Wan Y, 2015, J TEXT I, V107, P879
   Wan YM, 2016, MECH MATER, V94, P1, DOI 10.1016/j.mechmat.2015.11.012
   Wei Ching-Yeu, 2016, PHILOS MAG A, V47, P407
   Xu X., 2016, J APPL MECH, V83
   Xu XH, 2016, INT J COMPUT MAT SCI, V5, DOI 10.1142/S2047684116500044
   Xue-Feng S. I., 2018, ROCK SOIL MECH
   Yang D, 2014, ROCK SOIL MECH, V35, P1110
   Zeng L, 2018, CORROS SCI, V144, P258, DOI 10.1016/j.corsci.2018.08.045
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang YL, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/621264
   Zheng H, 2011, INT J NUMER ANAL MET, V35, P519, DOI 10.1002/nag.914
   Zhong S, 2018, ROCK SOIL MECH, V39, P356, DOI 10.16285/j.rsm.2017.0336
   Zhu JG, 2019, ADV DIFFER EQU-NY, DOI 10.1186/s13662-018-1908-0
   Zhu JG, 2019, J APPL REMOTE SENS, V13, DOI 10.1117/1.JRS.13.022006
NR 49
TC 0
Z9 0
U1 1
U2 66
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 398
EP 406
DI 10.1016/j.jvcir.2019.03.012
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000043
DA 2024-07-18
ER

PT J
AU Duan, C
   Wang, S
   Huang, QH
   Wen, T
   Zhu, C
   Xu, YY
AF Duan, Chang
   Wang, Shuai
   Huang, Qihong
   Wen, Tao
   Zhu, Ce
   Xu, Yuanyuan
TI Feature level MRI fusion based on 3D dual tree compactly supported
   Shearlet transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Medical image fusion; Shearlet transform; Structure tensor
ID IMAGE FUSION
AB A medical fusion method can combine multiple data into one, which is very useful and convenient in the medical diagnosis. We investigated the fusion problem for 3D Magnetic Resonance Imaging (MRI) data and proposed a feature level MRI fusion method based on 3D Dual Tree Compactly Supported Shearlet Transform (CSST) and Structure Tensor. By employing a 3D version of the traditional CSST with dual tree (DT) structure, the 3D DT CSST is shift-invariant and has directional analysis capability for volume data. Utilizing the structural feature extraction capability of Structure Tensor, the proposed fusion rule can preserve the critical structure information of scanned organ in source data. Experimental results using 51 groups of MRI data show the effectiveness of the proposed fusion method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Duan, Chang] Southwest Petr Univ, Chengdu, Sichuan, Peoples R China.
   [Wang, Shuai; Wen, Tao; Zhu, Ce] Univ Elect Sci & Technol China, Chengdu, Sichuan, Peoples R China.
   [Huang, Qihong] Chengdu Univ Informat Technol, Chengdu, Sichuan, Peoples R China.
   [Xu, Yuanyuan] Hohai Univ, Nanjing, Jiangsu, Peoples R China.
C3 Southwest Petroleum University; University of Electronic Science &
   Technology of China; Chengdu University of Information Technology; Hohai
   University
RP Xu, YY (corresponding author), 8 Focheng Rd, Nanjing 211100, Jiangsu, Peoples R China.
EM yuanyuan_xu@hhu.edu.cn
RI Zhu, Ce/AEN-1875-2022
FU Young Scholars Development Fund of SWPU (South West Petroleum
   University) in China [201499010119]; National Natural Science Foundation
   of China [61801167]; Natural Science Foundation of Jiangsu Province of
   China [BK20160874]
FX This work was supported by the Young Scholars Development Fund of SWPU
   (South West Petroleum University) in China under Grant No. 201499010119,
   National Natural Science Foundation of China under Grant No. 61801167,
   and Natural Science Foundation of Jiangsu Province of China under Grant
   No. BK20160874.
CR Chavhan GB, 2009, RADIOGRAPHICS, V29, P1433, DOI 10.1148/rg.295095034
   Chen CC, 2016, INT J DISTRIB SENS N, V12, DOI 10.1177/155014775780101
   Clevert DA, 2012, RADIOLOGE, V52, P63, DOI 10.1007/s00117-011-2252-5
   Duan  C., 2015, INT J ADV ROBOT SYST, V12, P1
   Duan C, 2014, INT J BIOMED IMAGING, V2014, DOI 10.1155/2014/469015
   Feng P.-M., 2013, COMPUT MATH METHODS, V2013
   Harris C., 1988, ALVEY VISION C, P147151
   Hatt CR, 2013, COMPUT MED IMAG GRAP, V37, P162, DOI 10.1016/j.compmedimag.2013.03.006
   HauSSecker Horst., 1996, 3D Image Analysis and Synthesis, P171
   Kingsbury N. G., 1998, IEEE DIG SIGN PROC W, P319
   Kumar M, 2009, IEEE T IMAGE PROCESS, V18, P2137, DOI 10.1109/TIP.2009.2025006
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lu HM, 2012, COMPUT MATH APPL, V64, P996, DOI 10.1016/j.camwa.2012.03.017
   Negi PS, 2012, IEEE T IMAGE PROCESS, V21, P2944, DOI 10.1109/TIP.2012.2183883
   Ningbo Zhu, 2011, Proceedings of the 2011 International Conference on Remote Sensing, Environment and Transportation Engineering (RSETE 2011), P3930, DOI 10.1109/RSETE.2011.5965178
   Petrovi  V., 2000, P 3 INT C
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   Wang L, 2014, INFORM FUSION, V19, P29, DOI 10.1016/j.inffus.2013.04.005
   Wang S, 2013, IEEE T BIO-MED ENG, V60, P3441, DOI 10.1109/TBME.2013.2266795
   Wu T, 2012, PROCEDIA ENGINEER, V29, P3991, DOI 10.1016/j.proeng.2012.01.607
   Xydeas C. S, 2000, MIL TECH COUR, V56, P181, DOI 10.5937/vojtehg0802181B
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Zhang Q., 2007, OPTICS PRECISION ENG, V7, P1131
   Zhang Q, 2013, SIGNAL PROCESS, V93, P2485, DOI 10.1016/j.sigpro.2013.03.018
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 27
TC 3
Z9 4
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 319
EP 327
DI 10.1016/j.jvcir.2019.02.027
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000035
DA 2024-07-18
ER

PT J
AU Fang, YM
   Liu, JY
   Zhang, YB
   Lin, WS
   Guo, ZM
AF Fang, Yuming
   Liu, Jiaying
   Zhang, Yabin
   Lin, Weisi
   Guo, Zongming
TI Reduced-reference quality assessment of image super-resolution by energy
   change and texture variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment (IQA); Image super-resolution;
   Reduced-reference (RR) quality assessment; Energy change; Texture
   variation
ID RECONSTRUCTION; INTERPOLATION; INFORMATION
AB In this paper, we propose a novel reduced-reference quality assessment metric for image super-resolution (RRIQA-SR) based on the low-resolution (LR) image information. With the pixel correspondence, we predict the perceptual similarity between image patches of LR and SR images by two components: the energy change in low-frequency regions, which can be used to capture the global distortion in SR images, and texture variation in high-frequency regions, which can be used to capture the local distortion in SR images. The overall quality of SR images is estimated by perceptual similarity calculated by energy change and texture variation between local image patches of LR and HR images. Experimental results demonstrate that the proposed method can obtain better performance of quality prediction for SR images than other existing ones, even including some full-reference (FR) metrics. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Jiangxi, Peoples R China.
   [Liu, Jiaying; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing 100080, Peoples R China.
   [Zhang, Yabin; Lin, Weisi] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
C3 Jiangxi University of Finance & Economics; Peking University; Nanyang
   Technological University
RP Liu, JY (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing 100080, Peoples R China.
EM fa0001ng@e.ntu.edu.sg; liujiaying@pku.edu.cn; zhan0398@e.ntu.edu.sg;
   wslin@ntu.edu.sg; guozong-ming@pku.edu.cn
RI Liu, JY/GYJ-0138-2022; Lin, Weisi/A-8011-2012; Lin, Weisi/A-3696-2011
OI Lin, Weisi/0000-0001-9866-1947; Liu, Jiaying/0000-0002-0468-9576
FU Natural Science Foundation of China [61571212, 61822109]; Natural
   Science Foundation of Jiangxi Province [20181BBH80002]; Fok Ying-Tong
   Education Foundation of China [161061]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61571212 and 61822109, the Natural Science Foundation
   of Jiangxi Province under Grant 20181BBH80002, and the Fok Ying-Tong
   Education Foundation of China under Grant 161061.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fang Y., 2016, IEEE INT C IM PROC
   Fang Y., 2015, MULTIMEDIA QUALITY E
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P2016, DOI 10.1109/TIP.2017.2669840
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Karam LJ, 2011, IEEE T IMAGE PROCESS, V20, P3470, DOI 10.1109/TIP.2011.2159324
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   Li S. Z., 2001, MACKAY RANDOM FIELD
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Pickup LC, 2009, COMPUT J, V52, P101, DOI 10.1093/comjnl/bxm091
   Reibman AR, 2006, IEEE IMAGE PROC, P2017, DOI 10.1109/ICIP.2006.312895
   Ren J, 2013, IEEE T IMAGE PROCESS, V22, P1454, DOI 10.1109/TIP.2012.2231690
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen MM, 2010, J VIS COMMUN IMAGE R, V21, P640, DOI 10.1016/j.jvcir.2010.04.003
   Song Wang, 2013, 2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), P193, DOI 10.1109/ESEM.2013.24
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wang C, 2006, IEEE T CIRC SYST VID, V16, P1411, DOI 10.1109/TCSVT.2006.883514
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, SYNTHESES LECT IMAGE
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Xing L, 2018, SIGNAL PROCESS, V145, P233, DOI 10.1016/j.sigpro.2017.12.013
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yeganeh H, 2012, IEEE IMAGE PROC, P1481, DOI 10.1109/ICIP.2012.6467151
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XH, 2012, VISUAL COMPUT, V28, P1167, DOI 10.1007/s00371-011-0666-8
   Zhang YMD, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-102
   Zhang YQ, 2013, IET IMAGE PROCESS, V7, P270, DOI 10.1049/iet-ipr.2012.0351
   Zhang YB, 2016, IEEE T MULTIMEDIA, V18, P405, DOI 10.1109/TMM.2015.2512046
   Zhang YQ, 2015, IEEE T IMAGE PROCESS, V24, P2797, DOI 10.1109/TIP.2015.2431435
NR 58
TC 17
Z9 18
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 140
EP 148
DI 10.1016/j.jvcir.2018.12.035
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000017
DA 2024-07-18
ER

PT J
AU Zhou, WJ
   Yu, L
   Qian, YG
   Qiu, WW
   Zhou, Y
   Luo, T
AF Zhou, Wujie
   Yu, Lu
   Qian, Yaguan
   Qiu, Weiwei
   Zhou, Yang
   Luo, Ting
TI Deep blind quality evaluator for multiply distorted images based on
   monogenic binary coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality assessment; Monogenic binary coding; Local structural
   information; Blind prediction; Deep neural network
ID MULTIRESOLUTION GRAY-SCALE; EFFICIENT
AB Perceptual quality evaluation of multiply distorted images has become a very challenging research topic. In this paper, we present a novel and efficient deep blind quality evaluator for multiply distorted images based on monogenic binary coding (MBC). Local complementary structural information and a deep learning method are employed to blindly evaluate the quality of multiply distorted images. First, a monogenic signal representation is utilized to decompose a multiply distorted image into three complementary components: orientation, phase, and magnitude. The quality-predictive features are then determined from the complementary components. Finally, the features are mapped to the human quality score of the multiply distorted image based on the deep neural network. The results on two newly established multiply distorted image subjective databases confirm that our metric has a better prediction performance than existing state-of-the-art full-reference and classical blind metrics. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhou, Wujie; Qian, Yaguan; Qiu, Weiwei; Zhou, Yang] Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Zhejiang, Peoples R China.
   [Zhou, Wujie; Yu, Lu] Zhejiang Univ, Coll Informat & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Luo, Ting] Ningbo Univ, Coll Sci & Technol, Ningbo 315211, Peoples R China.
C3 Zhejiang University of Science & Technology; Zhejiang University; Ningbo
   University
RP Zhou, WJ (corresponding author), Zhejiang Univ Sci & Technol, Sch Informat & Elect Engn, Hangzhou 310023, Zhejiang, Peoples R China.
EM wujiezhou@163.com
OI Yu, Lu/0000-0002-0550-7754; zhou, wujie/0000-0002-3055-2493
FU National Natural Science Foundation of China [61502429, 61505176,
   61501270, 61431015]; Zhejiang Provincial Natural Science Foundation of
   China [LY18F020012, LY17F020011]; Zhejiang Open Foundation of the Most
   Important Subjects; China Postdoctoral Science Foundation [2015M581932]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61502429, 61505176, 61501270, 61431015), the Zhejiang
   Provincial Natural Science Foundation of China (Grant Nos. LY18F020012,
   LY17F020011), the Zhejiang Open Foundation of the Most Important
   Subjects, and the China Postdoctoral Science Foundation (Grant No.
   2015M581932).
CR [Anonymous], 1980, VISION
   Bai C, 2018, J VIS COMMUN IMAGE R, V54, P123, DOI 10.1016/j.jvcir.2018.05.005
   Dai T, 2018, NEUROCOMPUTING, V290, P185, DOI 10.1016/j.neucom.2018.02.050
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Fezza SA, 2017, J VIS COMMUN IMAGE R, V49, P115, DOI 10.1016/j.jvcir.2017.08.009
   Gabarda S, 2018, J VIS COMMUN IMAGE R, V52, P101, DOI 10.1016/j.jvcir.2018.02.008
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Gu K, 2013, IEEE WORKSHOP SIG, P241, DOI 10.1109/SiPS.2013.6674512
   Gvozden G, 2018, J VIS COMMUN IMAGE R, V50, P145, DOI 10.1016/j.jvcir.2017.11.017
   Hadizadeh H, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2617743
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Karimi M, 2017, J VIS COMMUN IMAGE R, V43, P108, DOI 10.1016/j.jvcir.2016.12.011
   Lamb A. B., 2017, MULTIMED TOOLS APPL, P1
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Lu YA, 2015, IEEE SIGNAL PROC LET, V22, P1811, DOI 10.1109/LSP.2015.2436908
   Lv YQ, 2016, SIGNAL PROCESS-IMAGE, V47, P346, DOI 10.1016/j.image.2016.07.003
   Mahmoudpour S, 2018, J VIS COMMUN IMAGE R, V57, P125, DOI 10.1016/j.jvcir.2018.10.027
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oszust M, 2018, J VIS COMMUN IMAGE R, V56, P15, DOI 10.1016/j.jvcir.2018.08.019
   Pan XF, 2018, J VIS COMMUN IMAGE R, V57, P76, DOI 10.1016/j.jvcir.2018.10.016
   Qureshi MA, 2017, J VIS COMMUN IMAGE R, V49, P177, DOI 10.1016/j.jvcir.2017.09.006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Smola A., 2014, STAT COMPUT, V14, P199
   Tang LJ, 2017, J VIS COMMUN IMAGE R, V49, P204, DOI 10.1016/j.jvcir.2017.09.010
   Temel D., 2015, IEEE ICIP, P27
   Temel D, 2019, SIGNAL PROCESS-IMAGE, V70, P37, DOI 10.1016/j.image.2018.09.005
   Temel D, 2016, SIGNAL PROCESS-IMAGE, V48, P92, DOI 10.1016/j.image.2016.08.008
   Temel D, 2016, IEEE SIGNAL PROC LET, V23, P1414, DOI 10.1109/LSP.2016.2601119
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen Y, 2017, J VIS COMMUN IMAGE R, V43, P119, DOI 10.1016/j.jvcir.2016.12.005
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yue GH, 2018, IEEE T MULTIMEDIA, V20, P2722, DOI 10.1109/TMM.2018.2807589
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5433, DOI 10.1109/TIP.2018.2857413
   Zhou WJ, 2017, INFORM SCIENCES, V397, P1, DOI 10.1016/j.ins.2017.02.049
   Zhou WJ, 2018, IEEE T IMAGE PROCESS, V27, P2086, DOI 10.1109/TIP.2018.2794207
   Zhu CR, 2012, INFORM SCIENCES, V187, P93, DOI 10.1016/j.ins.2011.10.014
NR 46
TC 3
Z9 3
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 305
EP 311
DI 10.1016/j.jvcir.2019.03.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000033
DA 2024-07-18
ER

PT J
AU Liu, C
   Liu, WB
   Xing, WW
AF Liu, Cheng
   Liu, Weibin
   Xing, Weiwei
TI A weighted edge-based level set method based on multi-local statistical
   information for noisy image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Noisy image segmentation; Active contour model; Level set method;
   Weighted coefficients; Local statistical information; Edge stop function
ID SCALABLE FITTING ENERGY; ACTIVE CONTOURS DRIVEN; GAUSSIAN MIXTURE MODEL;
   RE-INITIALIZATION; EVOLUTION; DISTANCE
AB Image segmentation plays a fundamental role in image processing. Active contour models have been widely used since they handle topological change easily and provide smooth contours. However, noise presents challenges for edge-based level set methods since it leads contours easily passing through objects or falling into local minima. In this paper, we propose a weighted edge-based level set method based on multi-local statistical information to better segment noisy images. Through analysing the deficiencies of constant length and regional coefficients and traditional edge stop function in noisy image segmentation, weighted length and regional coefficients and modified edge stop function are proposed to overcome their shortcomings, respectively. The weighted edge-based level set method is used to segment synthetic and real images that have added different types and levels of noise. The experiments indicate that our method provides higher segmentation accuracies and more accurate segmentation results, which demonstrate its effectiveness and robustness. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Cheng; Liu, Weibin] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Xing, Weiwei] Beijing Jiaotong Univ, Sch Software Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Liu, WB (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM wbliu@bjtu.edu.cn
FU National Natural Science Foundation of China [61876018, 61370127,
   61473031, 61472030]; Program for New Century Excellent Talents in
   University [NCET-13-0659]
FX This research is partially supported by National Natural Science
   Foundation of China (Nos. 61876018, 61370127, 61473031, 61472030),
   Program for New Century Excellent Talents in University (NCET-13-0659).
CR Alush A, 2016, IEEE T NEUR NET LEAR, V27, P1358, DOI 10.1109/TNNLS.2015.2505181
   [Anonymous], 2007, 2007 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2007.383014
   [Anonymous], P IEEE C COMP VIS PA
   Arrieta C, 2017, BIOMED SIGNAL PROCES, V33, P88, DOI 10.1016/j.bspc.2016.11.002
   Boudaren MEY, 2016, IEEE GEOSCI REMOTE S, V13, P1865, DOI 10.1109/LGRS.2016.2615647
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen L, 2006, PATTERN RECOGN, V39, P1391, DOI 10.1016/j.patcog.2006.01.017
   Chen YT, 2017, MAGN RESON IMAGING, V39, P175, DOI 10.1016/j.mri.2017.02.008
   Chen YT, 2010, PATTERN RECOGN, V43, P3699, DOI 10.1016/j.patcog.2010.05.027
   Dai SF, 2015, NEUROCOMPUTING, V168, P799, DOI 10.1016/j.neucom.2015.05.044
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Fabijanska A, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2383323
   Feng CL, 2017, NEUROCOMPUTING, V219, P107, DOI 10.1016/j.neucom.2016.09.008
   Gupta D, 2017, BIOMED SIGNAL PROCES, V31, P116, DOI 10.1016/j.bspc.2016.06.012
   Han B, 2017, PATTERN RECOGN, V67, P396, DOI 10.1016/j.patcog.2017.02.022
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Orlando JI, 2017, IEEE T BIO-MED ENG, V64, P16, DOI 10.1109/TBME.2016.2535311
   Ji ZX, 2012, IEEE T INF TECHNOL B, V16, P339, DOI 10.1109/TITB.2012.2185852
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Khadidos A, 2017, IEEE T IMAGE PROCESS, V26, P1979, DOI 10.1109/TIP.2017.2666042
   Lee SH, 2006, IEEE T IMAGE PROCESS, V15, P2843, DOI 10.1109/TIP.2006.877308
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li GD, 2015, IEEE T IMAGE PROCESS, V24, P5315, DOI 10.1109/TIP.2015.2481326
   Liu B, 2010, PATTERN RECOGN, V43, P2028, DOI 10.1016/j.patcog.2010.01.002
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   Liu GY, 2015, IEEE T IMAGE PROCESS, V24, P3990, DOI 10.1109/TIP.2015.2456505
   Liu LM, 2014, ELECTRON LETT, V50, P1923, DOI 10.1049/el.2014.3161
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Pratondo A, 2016, IEEE SIGNAL PROC LET, V23, P222, DOI 10.1109/LSP.2015.2508039
   Ren ZM, 2015, SIGNAL PROCESS, V117, P138, DOI 10.1016/j.sigpro.2015.05.009
   Salehi SSM, 2017, IEEE T MED IMAGING, V36, P2319, DOI 10.1109/TMI.2017.2721362
   Selvathi D, 2017, PATTERN RECOGN LETT, V86, P9, DOI 10.1016/j.patrec.2016.12.002
   Shang RH, 2016, IEEE J-STARS, V9, P1640, DOI 10.1109/JSTARS.2016.2516014
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Wang LF, 2014, PATTERN RECOGN, V47, P1917, DOI 10.1016/j.patcog.2013.11.014
   Wang XF, 2010, PATTERN RECOGN, V43, P603, DOI 10.1016/j.patcog.2009.08.002
   Wang XC, 2014, NEUROCOMPUTING, V141, P223, DOI 10.1016/j.neucom.2014.03.011
   Wu JJ, 2014, PROC CVPR IEEE, P256, DOI 10.1109/CVPR.2014.40
   Wu YF, 2015, SIGNAL PROCESS, V106, P123, DOI 10.1016/j.sigpro.2014.07.013
   Xia Y, 2016, NEUROCOMPUTING, V204, P189, DOI 10.1016/j.neucom.2015.08.125
   Xu HY, 2017, COMPUT MATH APPL, V74, P1471, DOI 10.1016/j.camwa.2017.06.027
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Yang X, 2014, IEEE T IMAGE PROCESS, V23, P2854, DOI 10.1109/TIP.2014.2321506
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhang L, 2017, MACH VISION APPL, V28, P75, DOI 10.1007/s00138-016-0805-3
   Zheng Q, 2013, COMPUT BIOL MED, V43, P459, DOI 10.1016/j.compbiomed.2013.01.002
   Zhou SP, 2016, NEUROCOMPUTING, V186, P107, DOI 10.1016/j.neucom.2015.12.073
NR 55
TC 47
Z9 50
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 89
EP 107
DI 10.1016/j.jvcir.2019.01.001
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600010
DA 2024-07-18
ER

PT J
AU Zhao, KR
   He, TT
   Wu, S
   Wang, SL
   Dai, BL
   Yang, QF
   Lei, YT
AF Zhao, Kunrong
   He, Tingting
   Wu, Shuang
   Wang, Songling
   Dai, Bilan
   Yang, Qifan
   Lei, Yutao
TI Research on video classification method of key pollution sources based
   on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pollution sources; Deep learning; Surveillance video classification;
   Convolution neural network
ID FLUE-GAS; GROUNDWATER POLLUTION; OBJECT DETECTION; EXTRACTION; NO
AB China's environmental problems are not only related to the fundamental interests of the broad masses of the people, but also to China's national security and international image. At present, China's environmental protection work is facing a complex situation. Pollution sources can be divided into natural pollution sources and man-made pollution sources. Natural sources of pollution refer to places where nature releases harmful substances or causes harmful effects to the environment, such as active volcanoes. Man-made pollution source refers to the pollution source formed by human activities, and is also the main object of environmental protection research and control. Among the man-made pollution sources, air pollution sources, water pollution sources and soil pollution sources can be classified according to the main objects of pollution. Among them, air pollution sources and water pollution sources have the greatest impact on human life. Therefore, it has become an important subject worthy of in-depth discussion to take automatic and electronic measures for potential environmental pollution incidents, discover environmental pollution problems in time, reduce the probability of environmental pollution incidents, and even put some major environmental pollution incidents in their infancy. In this paper, deep learning method is used to classify the existing key pollution source video. Water pollution experiments show that the accuracy of video counting reaches 93.1%, which is better than other video processing schemes. The operation time of the system reaches acceptable range, and a solution to meet the real-time requirement is put forward. (C) 2019 Published by Elsevier Inc.
C1 [Zhao, Kunrong; Wang, Songling; Dai, Bilan; Lei, Yutao] South China Inst Environm Sci MEP, Guangzhou, Guangdong, Peoples R China.
   [He, Tingting; Yang, Qifan] Guangzhou Hexin Environm Protect Technol Co Ltd, Guangzhou, Guangdong, Peoples R China.
   [Wu, Shuang] Guangzhou Huake Environm Protect Engn CO LTD, Guangzhou, Guangdong, Peoples R China.
RP Lei, YT (corresponding author), South China Inst Environm Sci MEP, Guangzhou, Guangdong, Peoples R China.
EM zhaokunrong@scies.org; ivyhtt@mail.scut.edu.cn; wushuang@scies.org;
   wangsongling@scies.org; daibilan@scies.org; xuwj7@mail3.sysu.edu.cn;
   leiyutao@scies.org
RI yang, zhou/KBB-6972-2024
CR Birkner M.J., 2014, ECOL MODEL A, V155, P459
   Blais JM, 2015, DEV PALEOENVIRON RES, V18, P1, DOI 10.1007/978-94-017-9541-8_1
   Blum W., 2015, J SEP SCI, V11, P480
   Chen Z., 2018, MICROPROCESS MICROSY, V59
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Chenying H., INT C IEEE ENG MED B, P3110
   Deng H, 2013, IND ENG CHEM RES, V52, P6778, DOI 10.1021/ie303319f
   Fristrup K. M., 2016, ACOUST SOC AM J, V139, P1981
   Getto LP, 2016, J EMERG MED, V50, pE115, DOI 10.1016/j.jemermed.2015.09.048
   Gregor K, 2015, PR MACH LEARN RES, V37, P1462
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hipni A, 2013, WATER RESOUR MANAG, V27, P4113, DOI 10.1007/s11269-013-0406-0
   Hua Q., 2014, COMPUT ENG APPL
   Li Y., 2018, CHINA COMPUT COMMUN
   Pathak A.R., 2018, PROG COMPUT ANAL NET
   Reidl-Leuthner C, 2014, ANAL CHEM, V86, P9058, DOI 10.1021/ac5020244
   Saon G., 2014, AUTOMATIC SPEECH REC, P55
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Sigler T, 2016, URBAN GEOGR, V37, P416, DOI 10.1080/02723638.2015.1075318
   Tahmassebipoor N, 2016, ARAB J GEOSCI, V9, DOI 10.1007/s12517-015-2166-z
   Tang HJ, 2017, INT J COAL GEOL, V170, P19, DOI 10.1016/j.coal.2016.09.012
   Turker M, 2015, INT J APPL EARTH OBS, V34, P58, DOI 10.1016/j.jag.2014.06.016
   Wang D., 2017, J FRANKLIN I
   Wang Q., 2015, ELECT POWER
   Wang Y.C., 2015, J ECOL RURAL ENV
   Wycisk P, 2013, ENVIRON SCI POLLUT R, V20, P1907, DOI 10.1007/s11356-012-0963-4
   Yangyu H.U., 2016, INSUL SURGE ARRESTER
   Zhang B, 2016, MEAS SCI TECHNOL, V27, DOI 10.1088/0957-0233/27/7/074002
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang WS, 2017, SOFTWARE PRACT EXPER, V47, P1127, DOI 10.1002/spe.2487
   Zhao Y, 2016, ENVIRON FORENSICS, V17, P355, DOI 10.1080/15275922.2016.1230906
   Zhu W., 2016, AUTOMAT PETRO CHEM I
   Zhu Zhenyao, 2014, ADV NEURAL INFORM PR, DOI DOI 10.5555/2968826.2968851
NR 42
TC 5
Z9 5
U1 6
U2 51
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 283
EP 291
DI 10.1016/j.jvcir.2019.01.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600029
DA 2024-07-18
ER

PT J
AU Duo, TL
   Guo, JZ
   Wu, F
   Zhai, RJ
AF Duo Tianlin
   Guo Jianzhong
   Wu Fang
   Zhai Renjian
TI Application of entropy-based multi-attribute decision-making method to
   structured selection of settlement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Settlement; Cartographic generalization; Structured selection; Entropy
   method; Multi-attribute decision-making
AB Structured selection of settlements is a decision-making problem. The application of an entropy-based multi-attribute decision-making method to structured selection of settlements is actually the integration of the attribute method with the geometric method, which internalizes the consideration of geometric factors into attributes. Through avoiding the inaccuracy of subjective weighting via objective weighting and quantifying the importance degree of each settlement, it can solve the difficulties in structured selection of settlement to some extent. (C) 2018 Published by Elsevier Inc.
C1 [Duo Tianlin; Guo Jianzhong; Wu Fang; Zhai Renjian] Informat Engn Univ, Zhengzhou 450001, Henan, Peoples R China.
   [Duo Tianlin] Henan Univ Technol, Zhengzhou 450001, Henan, Peoples R China.
C3 PLA Information Engineering University; Henan University of Technology
RP Duo, TL (corresponding author), Henan Univ Technol, High & New Technol Ind Dev Zone, Acad Affairs, Lianhua Rd, Zhengzhou 450001, Henan, Peoples R China.
EM dtl@haut.edu.cn
FU National Natural Science Foundation of China [41471386, 41101362]
FX Project Source: National Natural Science Foundation of China (41471386,
   41101362).
CR [艾廷华 Ai Tinghua], 2002, [测绘学报, Acta Geodetica et Cartographica Sinica], V31, P175
   Berger H., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1105, DOI 10.1145/1141277.1141536
   Cai Yongxiang, 2007, Geomatics and Information Science of Wuhan University, V32, P626
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   [邓红艳 Deng Hongyan], 2003, [中国图象图形学报. A, Journal of image and graphics], V8, P970
   Guo Hongyu, 2013, Computer Engineering and Applications, V49, P140, DOI 10.3778/j.issn.1002-8331.1301-0023
   [胡慧明 Hu Huiming], 2016, [测绘学报, Acta Geodetica et Cartographica Sinica], V45, P740
   Hu Huiming, 2016, GEOMAT SPATIAL INFOR, V39, P49
   Hu Huiming, 2016, GEOMAT SPATIAL INFOR, V39, P41
   Pang Plying, 2013, CHIN J ENG DES, V20, P89
   Ribeiro RA, 1996, FUZZY SET SYST, V78, P155, DOI 10.1016/0165-0114(95)00166-2
   Shuai Di, 2016, N CHINA ELECT POWER, V41, P24
   Tzeng G.H., 2011, Boca Raton, V352, DOI [10.1201/B11032, DOI 10.1201/B11032]
   Wang JH., 2008, J GEOMAT SCI TECHNOL, V25, P3
   [王家耀 WANG Jiayao], 2006, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V31, P382
   Wang Jiayao, 2006, GEOMAT INFORM SCI WU, V31, P439
   Wei GW, 2012, KNOWL-BASED SYST, V31, P176, DOI 10.1016/j.knosys.2012.03.011
   [武芳 Wu Fang], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P1645
   [闫浩文 Yan Haowen], 2005, [中国图象图形学报. A, Journal of image and graphics], V10, P633
   Yu Shao Rong, 2006, Journal of Mechanical Strength, V28, P695
   Zhang Y, 2009, J COMPUT APPL MATH, V232, P415, DOI 10.1016/j.cam.2009.06.020
   Zhao CL, 2016, NETINFO SECURITY, V10, P40, DOI [10.3969, DOI 10.3969]
   Zhou W., 2010, Sci. Technol. Eng, V10, P5839
NR 23
TC 9
Z9 9
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 220
EP 232
DI 10.1016/j.jvcir.2018.11.026
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100023
DA 2024-07-18
ER

PT J
AU Li, YM
   Xiao, J
   Xie, D
   Shao, J
   Wang, JL
AF Li, Yimeng
   Xiao, Jun
   Xie, Di
   Shao, Jian
   Wang, Jinlong
TI Adversarial learning for viewpoints invariant 3D human pose estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D pose estimation; Adversarial learning
AB 2D pose estimation have achieve remarkable performance with deep convolutional neural networks. However 3D pose estimation is current constrained by the limited datasets of 3D annotations. Meanwhile most annotated images are captured using Motion Capture system in lab or certain studio, which has large variations with large-scale monocular 2D pose datasets. We propose an adversarial learning framework, which can learn invariant human pose latent from 3D annotated datasets to optimize the estimation of monocular images with only 2D annotations. However there is large difference in observation coordinates between 2D datasets and 3D datasets, and this viewpoints issue should be separated from invariant pose latent. We add a viewpoints invariant module to automatically regulate observation viewpoints for generated 3D pose, which transforming the generated pose to more suitable observation in the 3D datasets. Our method achieve competitive results on both 2D and 3D benchmarks. (C) 2018 Published by Elsevier Inc.
C1 [Li, Yimeng; Xiao, Jun; Shao, Jian] Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
   [Xie, Di] Hikvision Res Inst, Hangzhou, Zhejiang, Peoples R China.
   [Wang, Jinlong] Qingdao Univ Technol, Sch Informat & Control Engn, Qingdao, Peoples R China.
C3 Zhejiang University; Qingdao University of Technology
RP Xiao, J (corresponding author), Zhejiang Univ, Hangzhou, Zhejiang, Peoples R China.
EM aquaird@zju.edu.cn; junxiao@cs.zju.edu.cn; iedi@hikvision.com;
   jshao@cs.zju.edu.cn; qdwangjinlong@163.com
RI LI, 李伊濛/KGM-6775-2024; Wang, Rong/JQI-7854-2023; Wang,
   Jin/GYA-2019-2022; Wang, Jinlong/HKW-8927-2023
OI Wang, Rong/0009-0009-5350-5743; 
FU National Key Research and Development Program of China [2017YFB0203001];
   Zhejiang Natural Science Foundation [R19F020009, LZ17F020001]; National
   Natural Science Foundation of China [61572431]; Key R&D Program of
   Zhejiang Province [2018C03055]; Joint Research Program of ZJU &
   Hikvision Research Institute
FX This work is supported in part by the National Key Research and
   Development Program of China (2017YFB0203001), Zhejiang Natural Science
   Foundation (R19F020009 and LZ17F020001), National Natural Science
   Foundation of China (61572431), Key R&D Program of Zhejiang Province
   (2018C03055) and Joint Research Program of ZJU & Hikvision Research
   Institute.
CR Andriluka M., 2014, 2014 IEEE C COMP VIS
   [Anonymous], ECCV WORKSH
   [Anonymous], ICCV
   [Anonymous], 41 INT ACM SIGIR C R
   [Anonymous], IEEE INT C COMP COMP
   [Anonymous], 2018, P 32 AAAI C ART INT
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], P 2015 IEEE INT C CO
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], INT C 3D VIS 3DV
   [Anonymous], COMP VIS ECCV 2016 1
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], 2015, P 32 INT C MACH LEAR
   [Anonymous], P 40 INT ACM SIGIR C
   [Anonymous], CORR
   [Anonymous], IEEE C COMP COMP VIS
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], COMP VIS ECCV 2016 W
   [Anonymous], COMP VIS ECCV 2016 1
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], COMPUT VIS IMAGE UND
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], 2017, IEEE INT C COMP VIS
   [Anonymous], NIPS
   [Anonymous], 2017 INT C 3D VIS
   [Anonymous], COMPUTER VISION ACCV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Nie BX, 2017, IEEE I CONF COMP VIS, P3467, DOI 10.1109/ICCV.2017.373
   Pavlakos Georgios, 2018, IEEE C COMP VIS PATT
   Radford A., UNSUPERVISED REPRESE
   Rogez G, 2018, INT J COMPUT VISION, V126, P993, DOI 10.1007/s11263-018-1071-9
   Sejera M, 2017, I C HUMANOID NANOTEC
   Tekin Bugra, 2016, BRIT MACH VIS C BMVC
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Zhu Y., 2018, STUDY INFLUENCE EXTE
NR 37
TC 3
Z9 3
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 374
EP 379
DI 10.1016/j.jvcir.2018.11.021
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100037
DA 2024-07-18
ER

PT J
AU Liu, X
   Li, N
   Xia, Y
AF Liu, Xuan
   Li, Na
   Xia, Yong
TI Affective image classification by jointly using interpretable art
   features and semantic annotations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Affective image classification; Discrete emotion space; Deep
   convolutional neural network (DCNN); Feature extraction; Support vector
   machine (SVM)
ID FAST RADIAL SYMMETRY; COLOR PREFERENCE; NEURAL-NETWORKS; EMOTION
AB Affective image classification, which aims to classify images according to their affective characteristics of inducing human emotions, has drawn increasing research attentions in the multimedia community. Although many features have been attempted, the semantic gap between low-level visual features and high-level emotional semantics, however, remains a major challenge. In this paper, we propose an affective image classification algorithm by jointly using the visual features extracted under the guidance of the art theory and semantic image annotations, such as the categories of objects and scenes, generated by a pre-trained deep convolutional neural network. This algorithm has been evaluated against three state-ofthe-art approaches on three benchmark image datasets. Our results indicate that combining interpretable aesthetic features and semantic annotations can better characterize the emotional semantics and the proposed algorithm is able to produce more accurate affective image classification than the other three approaches. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Xuan; Li, Na; Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci & Engn, Natl Engn Lab Integrated Aerosp Ground Ocean Big, Xian 710072, Shaanxi, Peoples R China.
   [Xia, Yong] Northwestern Polytech Univ, CMCC, Sch Comp Sci & Engn, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Natl Engn Lab Integrated Aerosp Ground Ocean Big, Xian 710072, Shaanxi, Peoples R China.
EM yxia@nwpu.edu.cn
FU National Natural Science Foundation of China [61471297, 61771397]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61471297 and 61771397. We acknowledged
   the NIMH Center for the Study of Emotion and Attention, and their
   critical role in the creation of the free publicly available IAPS
   Database used in this work. We appreciate the efforts devoted by the
   Institute of Computer Aided Automation, Vienna University of Technology
   to collect and share the Art Photo Database and Abstract Database used
   in this work.
CR [Anonymous], 2004 IEEE INT C SYST
   [Anonymous], 2017, P 26 INT JOINT C ART
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2016 IEEE INT C OR T
   [Anonymous], 2013, P IEEE INT C COMP VI
   [Anonymous], 2014, ARXIV13126229
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2009, P 17 ACM INT C MULT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P 26 INT J C ART INT
   [Anonymous], PROC ACM INT CONF MU
   [Anonymous], IEEE T AFFECT COMPUT
   [Anonymous], 2018 IEEE C COMP VIS
   [Anonymous], INT J MACH LEARN CYB
   [Anonymous], LEARNING MULTILEVEL
   [Anonymous], ARXIV151204412
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Chatfield K., 2014, P BRIT MACH VIS C 20
   Chen Y, 2016, APPL SOFT COMPUT, V38, P1088, DOI 10.1016/j.asoc.2015.06.048
   Cheng B, 2018, IEEE CONF COMPUT
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   He XY, 2018, NEUROCOMPUTING, V291, P187, DOI 10.1016/j.neucom.2018.02.073
   Huh Minyoung, 2016, ABS160808614 CORR
   Ijjina EP, 2016, APPL SOFT COMPUT, V46, P936, DOI 10.1016/j.asoc.2015.08.025
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Lang P. J., 2005, A6 U FLOR CTR RES PS
   Lee J, 2011, IEEE T MULTIMEDIA, V13, P1031, DOI 10.1109/TMM.2011.2158530
   Li N, 2015, INT CONF AFFECT, P84, DOI 10.1109/ACII.2015.7344555
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Molavi M., 2012, 2012 6th Asia Modelling Symposium (AMS 2012), P50, DOI 10.1109/AMS.2012.53
   Ni J, 2012, PROC CVPR IEEE, P932, DOI 10.1109/CVPR.2012.6247768
   Ou LC, 2004, COLOR RES APPL, V29, P381, DOI 10.1002/col.20047
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846
   Tang JH, 2012, IEEE T IMAGE PROCESS, V21, P2354, DOI 10.1109/TIP.2011.2180916
   Wang J, 2010, P 6 INT C NATURAL LA, P1, DOI [DOI 10.1109/ISGT.2010.5434766, 10.1109/NLPKE.2010.5587852, DOI 10.1109/NLPKE.2010.5587852, 10.1109/CISE.2010.5677256]
   Wang ST, 2015, APPL SOFT COMPUT, V37, P125, DOI 10.1016/j.asoc.2015.07.040
   Wang XH, 2013, IEEE IMAGE PROC, P3230, DOI 10.1109/ICIP.2013.6738665
   Weijer J V D, 2007, IEEE C COMPUTER VISI, P1
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 50
TC 23
Z9 24
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 576
EP 588
DI 10.1016/j.jvcir.2018.12.032
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100056
DA 2024-07-18
ER

PT J
AU Liu, A
   Shi, YD
   Jing, PG
   Liu, J
   Su, YT
AF Liu, Anan
   Shi, Yingdi
   Jing, Peiguang
   Liu, Jing
   Su, Yuting
TI Low-rank regularized multi-view inverse-covariance estimation for visual
   sentiment distribution prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image sentiment; Label distribution learning; Structured sparsity;
   Low-rank
AB With the increasing tendency of using images to express opinions and share experiences, sentiment analysis of visual content has aroused considerable attention interests in the past few years. Traditional sentiment analysis methods mainly focus on predicting the most dominant sentiment category of images while neglecting the sentiment ambiguity problem restricted by various factors such as environment, subjectivity, and cultural background. To tackle this problem, visual sentiment distribution prediction has been put forward to characterize images by distributions over a set of sentiment labels instead of a single distinct label or multiple distinct labels. Nevertheless, existing approaches usually separate feature embedding and distribution prediction.
   In this paper, we propose a novel supervised visual sentiment distribution prediction model, termed as low-rank regularized multi-view inverse-covariance estimation, in which feature embedding and distribution prediction are jointly performed. Specifically, our proposed model contains two main components: multi-view embedding and inverse-covariance estimation terms. The multi-view embedding term is restricted by low-rank constraints to seek the lowest-rank representation of samples. The inverse-covariance estimation term is restricted by structured sparsity regularization to learn a more reasonable distribution prediction model. We develop an alternative heuristic optimization algorithm to solve the objective function of the proposed model. Experiment results performed on three publicly available datasets demonstrate the effectiveness of our proposed scheme compared with state-of-the-art algorithms. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Anan; Shi, Yingdi; Jing, Peiguang; Liu, Jing; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 30072, Peoples R China.
C3 Tianjin University
RP Jing, PG (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 30072, Peoples R China.
EM pgjing@tju.edu.cn
RI Liu-Zeng, Jing/F-8582-2011
OI Jing, Peiguang/0000-0003-2648-7358
CR Andrew Galen, 2007, P 24 INT C MACHINE L, P33, DOI DOI 10.1145/1273496.1273501
   [Anonymous], P VIS INT SOC SEM WE
   [Anonymous], 2018, ARXIV180207938
   [Anonymous], 2016, LEARNING MULTILEVEL
   [Anonymous], ARXIV161104636
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2011, P 19 ACM INT C MULTI
   [Anonymous], INT J MACH LEARN CYB
   [Anonymous], 2016, P IEEE C COMP VIS PA
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Candès EJ, 2011, IEEE T INFORM THEORY, V57, P2342, DOI 10.1109/TIT.2011.2111771
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen T., 2013, P 21 ACM INT C MULT, P781, DOI [DOI 10.1145/2502081.2502203, 10.1145/2502081, DOI 10.1145/2502081]
   Chen TH, 2014, PR IEEE COMP DESIGN, P367, DOI 10.1109/ICCD.2014.6974707
   Cheng ZY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P655, DOI 10.1145/3077136.3080772
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Danaher P, 2014, J R STAT SOC B, V76, P373, DOI 10.1111/rssb.12033
   Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Geng X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3511
   Geng X, 2016, IEEE T KNOWL DATA EN, V28, P1734, DOI 10.1109/TKDE.2016.2545658
   Geng X, 2014, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2014.237
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Gui MJ, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI), P148, DOI 10.1109/BMEI.2015.7401490
   Hartmann K, 2005, LECT NOTES COMPUT SC, V3638, P115
   He R, 2015, IEEE T IMAGE PROCESS, V24, P5543, DOI 10.1109/TIP.2015.2466106
   Hou P, 2017, AAAI CONF ARTIF INTE, P2015
   Huang LK, 2014, IEEE SIGNAL PROC LET, V21, P875, DOI 10.1109/LSP.2014.2319817
   Ji Z, 2013, SIGNAL PROCESS, V93, P2352, DOI 10.1016/j.sigpro.2012.05.006
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Parekh A, 2017, SIGNAL PROCESS, V139, P62, DOI 10.1016/j.sigpro.2017.04.011
   Peng KC, 2015, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2015.7298687
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Ren Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2648
   Rothman AJ, 2010, J COMPUT GRAPH STAT, V19, P947, DOI 10.1198/jcgs.2010.09188
   Salzmann Mathieu, 2010, P 13 INT C ARTIFICIA, V9, P701
   Sercu T, 2016, INT CONF ACOUST SPEE, P4955, DOI 10.1109/ICASSP.2016.7472620
   Shen Wei, 2017, Advances in Neural Information Processing Systems, V30, P834
   Sohn Kyung-Ah, 2012, Artificial Intelligence and Statistics, P1081
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Song XM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2371
   Sun M, 2015, I C INTELL COMPUT TE, P345, DOI 10.1109/ICICTA.2015.93
   Varma M., 2009, P 26 ANN INT C MACHI, P1065
   Wang HX, 2014, PROC CVPR IEEE, P4106, DOI 10.1109/CVPR.2014.523
   Xiao Cai, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1977, DOI 10.1109/CVPR.2011.5995740
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xing C, 2016, PROC CVPR IEEE, P4489, DOI 10.1109/CVPR.2016.486
   Xu B., 2016, IEEE T AFFECTIVE COM, VPP, P1
   Yang JF, 2017, AAAI CONF ARTIF INTE, P224
   Yang LX, 2017, SIGNAL PROCESS, V130, P93, DOI 10.1016/j.sigpro.2016.06.016
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhou T., 2011, P ICML, P33
   Zhou Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1247, DOI 10.1145/2733373.2806328
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944
NR 65
TC 5
Z9 5
U1 3
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 243
EP 252
DI 10.1016/j.jvcir.2018.11.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400029
DA 2024-07-18
ER

PT J
AU Tong, M
   Chen, YR
   Zhao, MG
   Tian, WJ
AF Tong, Ming
   Chen, Yiran
   Zhao, Mengao
   Tian, Weijuan
TI A new framework of action recognition with discriminative parts,
   spatio-temporal and causal interaction descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Spectral clustering; Discriminative constraint;
   Action part; Spatio-temporal relationship; Causal relationship
ID CONTEXT; FEATURES; REPRESENTATION; DICTIONARY; SIMILARITY; TRANSFORM;
   EVOLUTION
AB To improve action recognition performance, a novel discriminative spectral clustering method is firstly proposed, by which the candidate parts with the internal trajectories being close in spatial position, consistent in appearance and similar in motion velocity are mined. Furthermore, the discriminative constraint is introduced to select discriminative parts. Meanwhile, by fully considering the local and global distributions of data, a new similarity matrix is constructed, which enhances clustering effect. Secondly, the spatio-temporal interaction descriptor and causal interaction descriptor are constructed respectively, which fully mine the spatio-temporal and implicit causal interactive relationships between parts. Finally, a new framework is proposed. By associating the discriminative parts, spatio-temporal and causal interaction descriptors together as the inputs of Latent Support Vector Machine (LSVM), the correlations between action categories and action parts as well as interaction descriptors are mined. Consequently, accuracy is enhanced. The extensive and adequate experiments demonstrate the effectiveness of the proposed method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Tong, Ming; Chen, Yiran; Zhao, Mengao; Tian, Weijuan] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Tong, M (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM mtong@xidian.edu.cn; yiran_chen@stu.xidian.edu.cn;
   mazhao_1@stu.xidian.edu.cn; tianweijuan@stu.xidian.edu.cn
RI Tian, Weijuan/ABC-3902-2021
OI Chen, Yiran/0000-0003-4801-2716
FU National Natural Science Foundation of China [61072110]; Shaanxi
   Province key project of Research and Development Plan
   [S2018-YF-ZDGY-0187]; International Cooperation Project of Shaanxi
   Province [20161KW-042, S2018-YF-GHMS-0061]
FX This work was supported partially by National Natural Science Foundation
   of China (Grant No. 61072110), Shaanxi Province key project of Research
   and Development Plan (S2018-YF-ZDGY-0187), International Cooperation
   Project of Shaanxi Province (S2018-YF-GHMS-0061), and International
   Cooperation Project of Shaanxi Province (20161KW-042).
CR Anirudh R, 2016, INT J COMPUT VISION, V116, P161, DOI 10.1007/s11263-015-0835-8
   [Anonymous], C REC IEEE INSTRUM M, DOI DOI 10.1109/I2MTC.2016.7520444
   [Anonymous], IEEE T CIRCUITS SYST
   Azhar F, 2017, IEEE T CYBERNETICS, V47, P784, DOI 10.1109/TCYB.2016.2526970
   Bajcsy P, 1998, IEEE T PATTERN ANAL, V20, P1011, DOI 10.1109/34.713365
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316
   Byrne J, 2015, PROC CVPR IEEE, P502, DOI 10.1109/CVPR.2015.7298648
   Chatzis SP, 2015, IEEE I CONF COMP VIS, P2803, DOI 10.1109/ICCV.2015.321
   Chen HC, 2012, COMM COM INF SC, V267, P1, DOI 10.1109/TCSVT.2012.2225911
   Das S, 2008, IEEE T SYST MAN CY A, V38, P218, DOI 10.1109/TSMCA.2007.909595
   Georgogiannis A., 2016, PROC INT C NEURAL IN, P2891
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Goudelis G, 2013, PATTERN RECOGN, V46, P3238, DOI 10.1016/j.patcog.2013.06.006
   Guo YN, 2016, IEEE IJCNN, P3863, DOI 10.1109/IJCNN.2016.7727699
   Hsu YP, 2016, PATTERN RECOGN, V60, P215, DOI 10.1016/j.patcog.2016.05.010
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Ke QH, 2018, COMPUT VIS PATT REC, P127, DOI 10.1016/B978-0-12-813445-0.00005-8
   Ke QH, 2016, LECT NOTES COMPUT SC, V9914, P403, DOI 10.1007/978-3-319-48881-3_28
   Kihl O, 2015, PATTERN RECOGN, V48, P1174, DOI 10.1016/j.patcog.2014.11.013
   Kulkarni K, 2016, IEEE T PATTERN ANAL, V38, P772, DOI 10.1109/TPAMI.2015.2469288
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Leyva R, 2016, IEEE IMAGE PROC, P4185, DOI 10.1109/ICIP.2016.7533148
   Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu AA, 2015, NEUROCOMPUTING, V151, P544, DOI 10.1016/j.neucom.2014.04.090
   Liu J, 2014, INT C PATT RECOG, P2005, DOI 10.1109/ICPR.2014.350
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Liu L, 2014, PATTERN RECOGN, V47, P3819, DOI 10.1016/j.patcog.2014.07.006
   Mehrkanoon S, 2015, IEEE T NEUR NET LEAR, V26, P720, DOI 10.1109/TNNLS.2014.2322377
   Moayedi F, 2015, NEUROCOMPUTING, V161, P38, DOI 10.1016/j.neucom.2014.10.089
   Narayan S, 2014, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2014.337
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P77, DOI 10.1109/TCSVT.2014.2333151
   Parisi GermanIgnacio., 2017, The AAAI 2017 Spring Symposium on Science of Intelligence: Computational Principles of Natural and Artificial Intelligence, P608
   Poularakis S, 2017, SIGNAL PROCESS-IMAGE, V53, P1, DOI 10.1016/j.image.2017.01.005
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Ravichandran A, 2012, LECT NOTES COMPUT SC, V7585, P131, DOI 10.1007/978-3-642-33885-4_14
   Riyaz R, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P651, DOI [10.1109/ICMLA.2016.181, 10.1109/ICMLA.2016.0115]
   Rodriguez M. D., 2008, 2008 IEEE C COMPUTER, P1
   Sapienza M, 2014, INT J COMPUT VISION, V110, P30, DOI 10.1007/s11263-013-0662-8
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shi YM, 2017, IEEE T MULTIMEDIA, V19, P1510, DOI 10.1109/TMM.2017.2666540
   Starczewski A, 2017, PATTERN ANAL APPL, V20, P687, DOI 10.1007/s10044-015-0525-8
   Sun C, 2015, IEEE T IMAGE PROCESS, V24, P2488, DOI 10.1109/TIP.2015.2424316
   Tian Y., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P317
   Tian Y, 2015, NEUROCOMPUTING, V167, P359, DOI 10.1016/j.neucom.2015.04.059
   Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang HR, 2014, IEEE T IMAGE PROCESS, V23, P570, DOI 10.1109/TIP.2013.2292550
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334
   Wu XX, 2013, IEEE T CIRC SYST VID, V23, P1422, DOI 10.1109/TCSVT.2013.2244794
   Xu WR, 2017, IEEE T MULTIMEDIA, V19, P1494, DOI 10.1109/TMM.2017.2674622
   Yang XD, 2014, LECT NOTES COMPUT SC, V8690, P727, DOI 10.1007/978-3-319-10605-2_47
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P1635, DOI 10.1109/TPAMI.2012.253
   Yao TT, 2017, PATTERN RECOGN, V64, P236, DOI 10.1016/j.patcog.2016.11.012
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yi Y, 2017, EXPERT SYST APPL, V78, P259, DOI 10.1016/j.eswa.2017.02.020
   Yi Y, 2016, PATTERN RECOGN, V53, P148, DOI 10.1016/j.patcog.2015.11.022
   Yuan CF, 2016, INT J COMPUT VISION, V118, P151, DOI 10.1007/s11263-015-0867-0
   Yuan CF, 2013, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2013.99
   Yuan F, 2012, PATTERN RECOGN, V45, P4182, DOI 10.1016/j.patcog.2012.05.001
   Zhang H, 2014, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2014.265
   Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280
   Zhao DJ, 2013, NEUROCOMPUTING, V113, P88, DOI 10.1016/j.neucom.2013.01.022
   Zhao Q, 2013, PATTERN RECOGN LETT, V34, P1870, DOI 10.1016/j.patrec.2013.03.037
   Zhou TC, 2016, NEUROCOMPUTING, V201, P1, DOI 10.1016/j.neucom.2016.04.007
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
   Zhu GM, 2016, SIGNAL PROCESS-IMAGE, V42, P19, DOI 10.1016/j.image.2016.01.003
NR 75
TC 1
Z9 1
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 116
EP 130
DI 10.1016/j.jvcir.2018.09.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500010
DA 2024-07-18
ER

PT J
AU Jin, C
   Jin, SW
AF Jin, Cong
   Jin, Shu-Wei
TI Content-based image retrieval model based on cost sensitive learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Distance metric learning; Cost sensitive
   learning; Classification performance; Misclassification cost; Class
   imbalance
ID DISTANCE; CLASSIFICATION; ANNOTATION
AB How to retrieve the desired images quickly and accurately from the large scale image database has become a hot topic in the field of multimedia research. Many content-based image retrieval (CBIR) technologies already exist, but they are not always satisfactory. In many applications, the CBIR model based on machine learning relies heavily on the distance metric between samples. Although the traditional distance metric methods are simple and convenient, it is not always appropriate for CBIR tasks. In this paper, a novel distance metric learning (DML) method based on cost sensitive learning (CSL) is studied, and then it is used in a large margin distribution learning machine (LDM) to replace the traditional kernel functions. The improved LDM also takes into account CSL, and which is called CS-DLDM. Finally, CS-DLDM model is applied to CBIR tasks for implementation classification. We compare the proposed CS-DLDM model with other classifiers based on CSL. The experimental results show that the proposed CS-DLDM model not only has satisfactory classification performance but also the lowest misclassification cost, can effectively avoid the class imbalance of sample. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Jin, Cong] Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
   [Jin, Shu-Wei] Ecole Normale Super, Dept Phys, 24 Rue Lhomond, F-75231 Paris 5, France.
C3 Central China Normal University; Universite PSL; Ecole Normale
   Superieure (ENS)
RP Jin, C (corresponding author), Cent China Normal Univ, Sch Comp, Wuhan 430079, Hubei, Peoples R China.
EM jinc26@aliyun.com
OI , Cong/0000-0002-3703-359X
CR [Anonymous], 6 INT C CONTR AUT RO
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2006, P 2006 IEEE COMPUTER, DOI DOI 10.1109/CVPR.2006.167
   [Anonymous], 2014, GLOBAL J COMPUT SCI
   [Anonymous], P INT JOINT C ART IN
   [Anonymous], COST SENSITIVE CLASS
   Arar ÖF, 2015, APPL SOFT COMPUT, V33, P263, DOI 10.1016/j.asoc.2015.04.045
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Bar-Hillel A., 2003, ICML, P11
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cheng FY, 2016, PATTERN RECOGN LETT, V80, P107, DOI 10.1016/j.patrec.2016.06.009
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Davis J. V., 2007, ICML, P209
   García V, 2012, KNOWL-BASED SYST, V25, P13, DOI 10.1016/j.knosys.2011.06.013
   Hsieh C. J., 2008, P 25 INT C MACH LEAR, P408
   Jiang LX, 2014, INT J PATTERN RECOGN, V28, DOI 10.1142/S0218001414510021
   Jiang LX, 2014, PATTERN RECOGN LETT, V45, P211, DOI 10.1016/j.patrec.2014.04.017
   Jin C, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0132-0
   Jin C, 2016, J VIS COMMUN IMAGE R, V34, P167, DOI 10.1016/j.jvcir.2015.10.017
   Johnson DM, 2016, IEEE T KNOWL DATA EN, V28, P1035, DOI 10.1109/TKDE.2015.2507130
   Katsumata S, 2015, JMLR WORKSH CONF PRO, V38, P434
   Kubat M., 1997, ADDRESSING CURSE IMB, V97, P179
   Kumar V., 2006, Introduction to Data Mining
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Li J, 2017, IEEE T IMAGE PROCESS, V26, P3113, DOI 10.1109/TIP.2017.2651379
   Li J, 2016, NEUROCOMPUTING, V207, P202, DOI 10.1016/j.neucom.2016.04.047
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Liu M, 2018, IEEE T IMAGE PROCESS, V27, P1323, DOI 10.1109/TIP.2017.2781298
   Moepya SO, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P183, DOI 10.1109/ICDMW.2014.141
   Paredes R, 2008, LECT NOTES COMPUT SC, V5237, P260, DOI 10.1007/978-3-540-85853-9_24
   Persello C, 2014, IEEE T GEOSCI REMOTE, V52, P6652, DOI 10.1109/TGRS.2014.2300189
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Si L, 2006, MULTIMEDIA SYST, V12, P34, DOI 10.1007/s00530-006-0033-1
   Silva J, 2017, INT J REMOTE SENS, V38, P3294, DOI 10.1080/01431161.2017.1292073
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Uricchio T, 2017, PATTERN RECOGN, V71, P144, DOI 10.1016/j.patcog.2017.05.019
   Vandenberghe L, 1996, SIAM REV, V38, P49, DOI 10.1137/1038003
   Weinberger K.Q., 2008, Proceedings of the 25th international conference on Machine learning, P1160, DOI DOI 10.1145/1390156.1390302
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yang LM, 2007, PROCEEDINGS OF THE SECOND IASTED INTERNATIONAL CONFERENCE ON WATER RESOURCES MANAGEMENT, P1, DOI 10.1145/1362622.1362667
   Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273
   Zadrozny B, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P435, DOI 10.1109/icdm.2003.1250950
   Zhang T, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P313, DOI 10.1145/2623330.2623710
   Zhi-Hua Zhou, 2014, Artificial Neural Networks in Pattern Recognition. 6th IAPR TC 3 International Workshop, ANNPR 2014. Proceedings: LNCS 8774, P1, DOI 10.1007/978-3-319-11656-3_1
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
   Zhuang YT, 2011, SCI CHINA INFORM SCI, V54, P2508, DOI 10.1007/s11432-011-4483-5
NR 53
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 720
EP 728
DI 10.1016/j.jvcir.2018.08.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100062
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Sun, HJ
AF Zhang, Quan
   Sun, Huaijiang
TI Probabilistic collaborative representation based orthogonal
   discriminative projection for image set classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image set; Face recognition; Probabilistic collaborative representation;
   Orthogonal discriminative projection
ID FACE RECOGNITION; SPARSE REPRESENTATION
AB Image set based collaborative representation and classification(ISCRC) has been proposed and achieved state-of-the-art performance. Though ISCRC works well for Image set based face recognition(ISFR), the classification mechanism of ISCRC is still unclear. Besides, another challenge that ISCRC encountered is to deal with the high-dimensional data. In this paper, we first propose a novel Probabilistic Collaborative Representation based Classifier for Image Set (ProCRCIS), which is interpreted from a probabilistic viewpoint. Then, according to the reconstruction residual-based classification rule of ProCRCIS, we propose a novel dimensionality reduction method, called Probabilistic Collaborative Representation based Orthogonal Discriminative Projection for Image Set(ProCR-ODP-IS). The goal of ProCR-ODP-IS is to find a projection space such that the between-class reconstruction residual is maximized and the within-class reconstruction residual is minimized simultaneously. Hence, this projected space can fit ProCRCIS very well. Extensive experimental results on different datasets demonstrate the superiority of the proposed method compared to the state-of-the-arts.
C1 [Zhang, Quan; Sun, Huaijiang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Sun, HJ (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM sunhuaijiang@njust.edu.cn
FU National Natural Science Foundation of China [61772272]
FX The authors would like to thank P.Zhu for sharing the source code of
   ISCRC and providing the CMU MoBo dataset, R. Wang for sharing the source
   code of PDL and providing the YouTube Celebrities dataset. We thank S.
   Cai for the source code of ProCRC. We also thank G. Zhang for sharing
   the Extended Yale B dataset. This work was supported by the National
   Natural Science Foundation of China (No. 61772272).
CR [Anonymous], IEEE T CYBERNETICS
   [Anonymous], 2013, 10 INT C ASIC
   [Anonymous], 2002, Adv. Neural Inf. Process. Syst.
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Feng Q., 2017, KERNEL REGULARIZED D
   Feng Q., DISCRIMINANT PROJECT
   Feng QX, 2016, PROC CVPR IEEE, P4865, DOI 10.1109/CVPR.2016.526
   Feng QX, 2016, IEEE T MULTIMEDIA, V18, P1956, DOI 10.1109/TMM.2016.2602062
   Gaikwad K. P., 2011, INT C COMP INT COMM, P415
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross R., MONUMENTA NIPPONICA, V45
   Hajati F, 2017, IEEE T HUM-MACH SYST, V47, P970, DOI 10.1109/THMS.2017.2681425
   Ham J., 2004, P 21 INT C MACH LEAR, DOI DOI 10.1145/1015330.1015417
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu HF, 2015, IEEE T CIRC SYST VID, V25, P1599, DOI 10.1109/TCSVT.2014.2367357
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Huang GaryB., 2007, Labeled faces in the wild: A database for studying face recognition in unconstrained environments
   Jolliffe I.T., 1986, PRINCIPAL COMPONENT, P129, DOI 10.1007/978-1-4757-1904-8_8
   Kim MR, 2009, CLEAN TECHNOLOGY 2009: BIOENERGY, RENEWABLES, STORAGE, GRID, WASTE AND SUSTAINABILITY, P1
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Li F., 2017, IEEE INT C COMP COMM
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Lu YW, 2017, IEEE T CIRC SYST VID, V27, P1392, DOI 10.1109/TCSVT.2016.2539779
   Nadeem U., EFFICIENT IMAGE SET
   Ngo TT, 2010, SIAM J MATRIX ANAL A, V31, P2950, DOI 10.1137/090776603
   Ortiz EG, 2013, PROC CVPR IEEE, P3531, DOI 10.1109/CVPR.2013.453
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Qu X, 2015, IEEE IMAGE PROC, P4594, DOI 10.1109/ICIP.2015.7351677
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rubinstein R, 2008, Tech. rep.
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HQ, 2007, IEEE IPCCC, P1
   Wang RP, 2008, PROC CVPR IEEE, P2940
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wang W, 2017, IEEE SIGNAL PROC LET, V24, P1318, DOI 10.1109/LSP.2017.2723084
   Waqas J, 2013, PATTERN RECOGN LETT, V34, P201, DOI 10.1016/j.patrec.2012.09.024
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang M, 2012, PROC CVPR IEEE, P2224, DOI 10.1109/CVPR.2012.6247931
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yin J, 2016, PATTERN RECOGN LETT, V73, P83, DOI 10.1016/j.patrec.2016.01.012
   Zhang GQ, 2016, IEEE T IMAGE PROCESS, V25, P4271, DOI 10.1109/TIP.2016.2587119
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LM, 2012, PATTERN RECOGN, V45, P1205, DOI 10.1016/j.patcog.2011.08.015
   Zhang Y, 2016, IET SIGNAL PROCESS, V10, P1126, DOI 10.1049/iet-spr.2016.0067
   Zheng P, 2017, PATTERN RECOGN, V63, P206, DOI 10.1016/j.patcog.2016.09.043
NR 54
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 106
EP 114
DI 10.1016/j.jvcir.2018.05.016
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100010
DA 2024-07-18
ER

PT J
AU Zhu, WJ
   Yan, YH
AF Zhu, Wenjie
   Yan, Yunhui
TI Non-negative matrix factorization via discriminative label embedding for
   pattern classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-negative matrix factorization (NMF); Discriminative label embedding;
   Orthogonality constraint; Pattern classification
ID FEATURE-SELECTION; ALGORITHM; PARTS
AB As one of the most commonly used dimension reduction approaches, discriminant non-negative matrix factorization (NMF) has been widely used for data representation in the pattern classification task. However, the previous discriminant NMFs emphasize the Fisher criterion or maximum margin criterion which has high requirement to the distribution of data. Therefore, this work proposes a discriminative label embedded NMF (LENMF) algorithm. LENMF takes into account the discriminative label embedding to obtain the low-dimensional projected data and orthogonal property of the non-negative basis to strength the ability of parts-based representation. Besides, LENMF is extended in the kernel space to explore the nonlinear relations of data. By integrating the non-negative constraint, discriminative label embedding, and the orthogonal property into the proposed objective, the multiplicative updating rules have been given in this work. Experiment results on the challenging face, object, document, and digit databases illustrate the performance of the proposed algorithm.
C1 [Zhu, Wenjie; Yan, Yunhui] Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Zhu, WJ (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang 110819, Liaoning, Peoples R China.
EM wenjie_zh@126.com; yanyh@mail.neu.edu.cn
RI Yan, Yunhui/HDL-7343-2022
OI Yan, Yunhui/0000-0001-7121-2367
FU National Key Research and Development Program of China [2017YFB0304200];
   National Natural Science Foundation of China [51374063]; Fundamental
   Research Funds for the Central Universities [N150308001]
FX This work is supported by the National Key Research and Development
   Program of China (2017YFB0304200), the National Natural Science
   Foundation of China (51374063), and the Fundamental Research Funds for
   the Central Universities (N150308001).
CR [Anonymous], INT J FUZZY SYST
   [Anonymous], 2006, PROC 12 ACM SIGKDD I
   Buccoli M, 2014, IEEE INT WORKS INFOR, P131, DOI 10.1109/WIFS.2014.7084316
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Choi S., IEEE INT JOINT C NEU, P1828
   Dong YF, 2015, ADV MECH ENG, V7, DOI 10.1177/1687814015620332
   Dong YS, 2015, IEEE T CYBERNETICS, V45, P358, DOI 10.1109/TCYB.2014.2326059
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Gao B, 2011, IEEE J-STSP, V5, P989, DOI 10.1109/JSTSP.2011.2160840
   Gersho A., 2003, Vector Quantization and Signal Compression
   Guan NY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083291
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   Hoyer PO, 2003, NEUROCOMPUTING, V52-4, P547, DOI 10.1016/S0925-2312(02)00782-8
   Karygianni S, 2016, J VIS COMMUN IMAGE R, V36, P213, DOI 10.1016/j.jvcir.2016.01.013
   Kotsia I, 2007, IEEE T INF FOREN SEC, V2, P588, DOI 10.1109/TIFS.2007.902017
   Kumar BGV, 2012, IMAGE VISION COMPUT, V30, P279, DOI 10.1016/j.imavis.2012.02.010
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Lee D. D., INT C NEUR INF PROC, P535
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li SZ, 2001, PROC CVPR IEEE, P207
   Li X., 2017, REFINED GRAPH REGULA
   Li Xuelong, 2017, IEEE Trans Cybern, V47, P3840, DOI 10.1109/TCYB.2016.2585355
   Liu Da-kun, 2015, Journal of South China University of Technology (Natural Science Edition), V43, P120, DOI 10.3969/j.issn.1000-565X.2015.05.019
   Liu HF, 2012, IEEE T PATTERN ANAL, V34, P1299, DOI 10.1109/TPAMI.2011.217
   Liu WH, 2016, J VIS COMMUN IMAGE R, V40, P772, DOI 10.1016/j.jvcir.2016.06.028
   Liu XB, 2010, IEEE T IMAGE PROCESS, V19, P1126, DOI 10.1109/TIP.2009.2039050
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Meng F., 2017, IEEE T IMAGE PROCESS, P1
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Wang Y., P AS C COMP VIS, P1
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Wang YX, 2011, IEEE IMAGE PROC, P3409, DOI 10.1109/ICIP.2011.6116443
   Wu QX, 2013, J VIS COMMUN IMAGE R, V24, P1064, DOI 10.1016/j.jvcir.2013.07.001
   Yao C, 2017, IEEE T IMAGE PROCESS, V26, P5257, DOI 10.1109/TIP.2017.2733200
   Yao C, 2016, NEUROCOMPUTING, V207, P346, DOI 10.1016/j.neucom.2016.05.017
   Yao C, 2014, NEUROCOMPUTING, V138, P310, DOI 10.1016/j.neucom.2014.02.004
   Yoo Jiho, INT C INT DAT ENG AU, P140
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   Zhan K, 2017, J VIS COMMUN IMAGE R, V48, P411, DOI 10.1016/j.jvcir.2017.02.019
   Zhang DQ, 2003, NEURAL PROCESS LETT, V18, P155, DOI 10.1023/B:NEPL.0000011135.19145.1b
   Zhang Z, 2016, IEEE T IMAGE PROCESS, V25, P2429, DOI 10.1109/TIP.2016.2547180
   Zhu WJ, 2017, SIGNAL PROCESS-IMAGE, V55, P32, DOI 10.1016/j.image.2017.03.012
   Zhu WJ, 2016, KNOWL-BASED SYST, V113, P116, DOI 10.1016/j.knosys.2016.09.018
NR 43
TC 1
Z9 2
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 477
EP 488
DI 10.1016/j.jvcir.2018.06.030
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100042
DA 2024-07-18
ER

PT J
AU Navarro, LC
   Navarro, AKW
   Rocha, A
   Dahab, R
AF Navarro, Luiz C.
   Navarro, Alexandre K. W.
   Rocha, Anderson
   Dahab, Ricardo
TI Connecting the dots: Toward accountable machine-learning printer
   attribution methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Accountable machine learning; Digital forensics; Source printer
   attribution; Feature back-projection; Feature mapping; Feature
   importance
ID SECURITY; DOCUMENTS
AB Digital forensics is rapidly evolving as a direct consequence of the adoption of machine-learning methods allied with ever-growing amounts of data. Despite the fact that these methods yield more consistent and accurate results, they may face adoption hindrances in practice if their produced results are absent in a human-interpretable form. In this paper, we exemplify how human-interpretable (a.k.a., accountable) extensions can enhance existing algorithms to aid human experts, by introducing a new method for the source printer attribution problem. We leverage the recently proposed Convolutional Texture Gradient Filter (CTGF) algorithm's ability to capture local printing imperfections to introduce a new method that maps and highlights important attribution features directly onto the investigated printed document. Supported by Random Forest classifiers, we isolate and rank features that are pivotal for differentiating a printer from others, and back-project those features onto the investigated document, giving analysts further evidence about the attribution process.
C1 [Navarro, Luiz C.; Rocha, Anderson; Dahab, Ricardo] Univ Campinas Unicamp, Inst Comp, Campinas, SP, Brazil.
   [Navarro, Alexandre K. W.] Univ Cambridge, Engn Dept, Cambridge, England.
C3 Universidade Estadual de Campinas; University of Cambridge
RP Navarro, LC (corresponding author), Univ Campinas Unicamp, Inst Comp, Campinas, SP, Brazil.
EM luiz.navarro@students.ic.unicamp.br; akwn2@cam.ac.uk;
   anderson.rocha@ic.unicamp.br; rdahab@ic.unicamp.br
RI Dahab, Ricardo/IWD-7337-2023; Navarro, Luiz Claudio/HZH-2516-2023;
   Rocha, Anderson/KHU-9621-2024
OI Dahab, Ricardo/0000-0002-7002-875X; Navarro, Luiz
   Claudio/0000-0002-8041-8743; 
FU Intel Strategic Research Alliance [440850/2013-4]; National Council for
   Scientific and Technological Development - CNPq [302224/2015-7,
   304472/2015-8]; Sao Paulo Research Foundation - Fapesp (DejaVu Grant)
   [2017/12646-3]; Coordination for the Improvement of Higher Education
   Personnel - Capes (DeepEyes grant); Cambridge Trusts-CAPES grant [BEX
   9407-11-1]; Fundacao de Amparo a Pesquisa do Estado de Sao Paulo
   (FAPESP) [17/12646-3] Funding Source: FAPESP
FX We thank the financial support of Intel Strategic Research Alliance
   (Grant #440850/2013-4), the National Council for Scientific and
   Technological Development - CNPq (Grants #302224/2015-7 and
   #304472/2015-8), the Sao Paulo Research Foundation - Fapesp (DejaVu
   Grant #2017/12646-3), and the Coordination for the Improvement of Higher
   Education Personnel - Capes (DeepEyes grant), as well as Cambridge
   Trusts-CAPES grant BEX 9407-11-1.
CR Ali GN, 2003, IS&T'S NIP19: INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, P511
   Altmann A, 2010, BIOINFORMATICS, V26, P1340, DOI 10.1093/bioinformatics/btq134
   [Anonymous], 2016, ICML WORKSHOP HUMAN
   BLACKWELL D, 1947, ANN MATH STAT, V18, P105, DOI 10.1214/aoms/1177730497
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Brauns EB, 2006, APPL SPECTROSC, V60, P833, DOI 10.1366/000370206778062093
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 1996, Tech. Rep.
   Bulan O, 2009, INT CONF ACOUST SPEE, P1401, DOI 10.1109/ICASSP.2009.4959855
   Caruana R, 2006, P 23 INT C MACH LEAR, V148, P161, DOI DOI 10.1145/1143844.1143865
   CDT, 2017, DIG DEC
   Chiang P.-J., 2010, PRINTER SCANNER FORE, DOI [10.1007/978-3-642-11756-5_7, DOI 10.1007/978-3-642-11756-5_7]
   Chiang PJ, 2009, IEEE SIGNAL PROC MAG, V26, P72, DOI 10.1109/MSP.2008.931082
   Costa FD, 2014, PATTERN RECOGN LETT, V39, P92, DOI 10.1016/j.patrec.2013.09.006
   Criminisil A, 2011, FOUND TRENDS COMPUT, V7, P81, DOI [10.1561/0600000035, 10.1501/0000000035]
   Diakopoulos N., 2017, TECH REP
   Diakopoulos N., MIT TECHNOLOGY REV
   Ebrahimi M, 2016, DIGIT INVEST, V18, P33, DOI 10.1016/j.diin.2016.07.001
   Ferreira A, 2015, FORENSIC SCI INT, V247, P105, DOI 10.1016/j.forsciint.2014.11.030
   Gal T., APPL NOTE 409 DETERM
   Jain LP, 2014, LECT NOTES COMPUT SC, V8691, P393, DOI 10.1007/978-3-319-10578-9_26
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Ju YL, 2012, PROC SPIE, V8292, DOI 10.1117/12.912769
   LaPorte G. M., 2015, CHEM ANAL SCI EXAMIN
   Lee KY, 2010, PROC SPIE, V7529, DOI 10.1117/12.840480
   Louppe G., 2013, ADV NEURAL INFORM PR, P431, DOI DOI 10.5555/2999611.2999660
   Mikkilineni AK, 2005, PROC SPIE, V5681, P430, DOI 10.1117/12.593796
   Mikkilineni AK, 2004, PROC SPIE, V5306, P455, DOI 10.1117/12.531944
   Mikkilineni AK, 2011, PROC SPIE, V7880, DOI 10.1117/12.876742
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P543
   Narayanan A, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P1825, DOI 10.1109/IJCNN.2011.6033446
   Rattani A, 2015, IEEE T INF FOREN SEC, V10, P2447, DOI 10.1109/TIFS.2015.2464772
   Rocha A, 2014, IEEE T NEUR NET LEAR, V25, P289, DOI 10.1109/TNNLS.2013.2274735
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392
   Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
   Shang S., 2015, PRINTER SCANNER FORE
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Strobl C, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-25
   Talamadupula K., 2017, W11 HUMAN AWARE ARTI
   Tsai MJ, 2016, IEEE IMAGE PROC, P3927, DOI 10.1109/ICIP.2016.7533096
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Varshney K., 2017, WORKSH HUM INT MACH
   Wu YB, 2009, IEEE IMAGE PROC, P2909, DOI 10.1109/ICIP.2009.5413420
   Zhang J, 2015, PROC SPIE, V9396, DOI 10.1117/12.2083547
   Zhang J, 2013, PROC SPIE, V8653, DOI 10.1117/12.2008818
NR 48
TC 12
Z9 12
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 257
EP 272
DI 10.1016/j.jvcir.2018.04.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800024
DA 2024-07-18
ER

PT J
AU Fan, YX
   Wen, GJ
   Li, DR
   Qiu, SH
   Levine, MD
AF Fan, Yaxiang
   Wen, Gongjian
   Li, Deren
   Qiu, Shaohua
   Levine, Martin D.
TI Early event detection based on dynamic images of surveillance videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Early detection; Event detection; Dynamic image; Deep ConvNet
AB Early event detection is intended to flag an event as early as possible, but before it terminates. It is critical for detecting on-going events in many applications such as spotting dangerous or criminal incidents. In this letter, we address this issue by converting video clips of a proceeding event into so-called dynamic images, which are capable of simultaneously capturing both the appearance and temporal evolution of the occurrence. By using the dynamic images of two categories of video clips (complete target event as the positive set and random segments that do not contain the target event as the negative set), we propose a novel method for training a detector based on deep learning techniques. The approach is capable of scoring partial events by monitoring the degree of event completion as it monotonically increases toward termination. In particular, we discuss experiments on the detection of humans falling and the breakout of a fighting. Experiments on several datasets illustrate the effectiveness of the proposed method.
C1 [Fan, Yaxiang; Wen, Gongjian; Qiu, Shaohua] Natl Univ Def Technol, Sci & Technol Automat Target Recognit Lab ATR, Changsha, Hunan, Peoples R China.
   [Li, Deren] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan, Hubei, Peoples R China.
   [Levine, Martin D.] McGill Univ, Dept Elect & Comp Engn, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ, Canada.
C3 National University of Defense Technology - China; Wuhan University;
   McGill University
RP Fan, YX (corresponding author), Natl Univ Def Technol, Sci & Technol Automat Target Recognit Lab ATR, Changsha, Hunan, Peoples R China.
EM yaxiang.fan@mail.mcgill.ca
RI Qiu, Shaohua/T-9081-2019
OI Qiu, Shaohua/0000-0002-4018-5826
FU China Scholarship Council (CSC); Natural Science and Research Council
   [28266]
FX This research was supported by a China Scholarship Council (CSC)
   scholarship awarded to Yaxiang Fan and by a Natural Science and Research
   Council Grant (Grant NSERC #28266) to Martin D. Levine. We would also
   like to acknowledge a donation of Titan X GPU by Nvidia. The research
   was carried out at the Center for Intelligent Machines at McGill
   University in Montreal.
CR Aliakbarian M.S., 2017, P IEEE INT C COMP VI
   [Anonymous], 2012, P IEEE C COMP VIS PA
   [Anonymous], 2015, CORR
   Bermejo E., 2011, P COMP AN IM PATT
   BILEN H, 2016, PROC CVPR IEEE, P3034, DOI [10.1109/CVPR.2016.331, DOI 10.1109/CVPR.2016.331]
   Charfi I, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P218, DOI 10.1109/SITIS.2012.155
   Davis JW, 2006, IMAGE VISION COMPUT, V24, P455, DOI 10.1016/j.imavis.2006.01.012
   Fan Y., 2017, DEEP NETWORK DETECTI, V26, P43
   Goudelis G, 2015, 8TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2015), DOI 10.1145/2769493.2769562
   Jain A, 2016, IEEE INT CONF ROBOT, P3118, DOI 10.1109/ICRA.2016.7487478
   Ke Y., 2007, P IEEE INT C COMP VI
   Kolahi SS, 2013, IEEE SYMP COMP COMMU
   Lai K.-T., 2014, P IEEE C COMP VIS PA
   Ma SG, 2016, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2016.214
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Pirsiavash Hamed, 2014, P IEEE C COMP VIS PA
   Ryoo M. S., 2011, P IEEE INT C COMP VI
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Su LM, 2013, IEEE INT CONF AUTOMA
   Sun C., 2015, P ACM C MULT
   Vats E, 2015, IEEE INT FUZZY SYST
   Vats E, 2016, APPL SOFT COMPUT, V46, P953, DOI 10.1016/j.asoc.2015.11.007
   Wang J, 2014, IEEE INT CONF GROUP
   Xu L, 2014, INT CONF ACOUST SPEE
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P696, DOI 10.1109/TCSVT.2016.2589858
NR 27
TC 13
Z9 13
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 70
EP 75
DI 10.1016/j.jvcir.2018.01.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500007
DA 2024-07-18
ER

PT J
AU Bai, C
   Chen, JN
   Huang, L
   Kpalma, K
   Chen, SY
AF Bai, Cong
   Chen, Jia-nan
   Huang, Ling
   Kpalma, Kidiyo
   Chen, Shengyong
TI Saliency-based multi-feature modeling for semantic image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic gap; Bag of words; Visual saliency; Semantic image retrieval
ID SEARCH; SCALE; RERANKING
AB Semantic gap is an important challenging problem in content-based image retrieval (CBIR) up to now. Bag-of words (BOW) framework is a popular approach that tries to reduce the semantic gap in CBIR. In this paper, an approach integrating visual saliency model with BOW is proposed for semantic image retrieval. Images are firstly segmented into background regions and foreground objects by a visual saliency-based segmentation method. And then multi-features including Scale Invariant Feature Transform (SIFT) features packed in BOW are extracted from regions and objects respectively and fused considering different characteristics of background regions and foreground objects. Finally, a fusion of z-score normalized Chi-Square distance is adopted as the similarity measurement. This proposal has been implemented on two widely used benchmark databases and the results evaluated in terms of mean Average Precision (mAP) show that our proposal outperforms the referred state-of-the-art approaches.
C1 [Bai, Cong; Chen, Jia-nan; Huang, Ling; Chen, Shengyong] Zhejiang Univ Technol, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
   [Kpalma, Kidiyo] Univ Bretagne Loire, CNRS, INSA Rennes, IETR UMR 6164, Rennes, France.
C3 Zhejiang University of Technology; Centre National de la Recherche
   Scientifique (CNRS); CNRS - Institute for Engineering & Systems Sciences
   (INSIS); Institut National des Sciences Appliquees de Rennes; Universite
   de Rennes
RP Chen, SY (corresponding author), Zhejiang Univ Technol, Coll Comp Sci, Hangzhou, Zhejiang, Peoples R China.
EM sy@ieee.org
RI Chen, S./H-3083-2011; Bai, Cong/T-9188-2019
OI Bai, Cong/0000-0002-6177-3862; Chen, S.Y./0000-0002-6705-3831; KPALMA,
   Kidiyo/0000-0001-8179-6415
FU Zhejiang Provincial Natural Science Foundation of China [LY15F020028,
   LY18F020032]; National Natural Science Foundation of China [61502424,
   U1509207, 61325019]
FX This work is supported by Zhejiang Provincial Natural Science Foundation
   of China under Grants LY15F020028 and LY18F020032, National Natural
   Science Foundation of China under Grants 61502424, U1509207 and
   61325019.
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   Cao Y, 2010, PROC CVPR IEEE, P3352, DOI 10.1109/CVPR.2010.5540021
   Chatfield K, 2015, INT J MULTIMED INF R, V4, P75, DOI 10.1007/s13735-015-0077-0
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo CZ, 2016, IEEE T MULTIMEDIA, V18, P40, DOI 10.1109/TMM.2015.2495248
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Richang Hong, 2015, IEEE Transactions on Big Data, V1, P152, DOI 10.1109/TBDATA.2016.2515640
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shen XH, 2014, IEEE T PATTERN ANAL, V36, P1229, DOI 10.1109/TPAMI.2013.237
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wang M, 2015, IEEE T CYBERNETICS, V45, P1561, DOI 10.1109/TCYB.2014.2356136
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Weiss Y., 2008, NIPS, V1, P4
   Williams C.K.I., PASCAL VISUAL OBJECT
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Zhang J, 2015, J VIS COMMUN IMAGE R, V26, P37, DOI 10.1016/j.jvcir.2014.10.007
NR 34
TC 42
Z9 48
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 199
EP 204
DI 10.1016/j.jvcir.2017.11.021
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700020
DA 2024-07-18
ER

PT J
AU Karine, A
   El Maliani, AD
   El Hassouni, M
AF Karine, Ayoub
   El Maliani, Ahmed Drissi
   El Hassouni, Mohammed
TI A novel statistical model for content-based stereo image retrieval in
   the complex wavelet domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based stereo image retrieval; Gaussian copula; Non-Gaussian
   distribution; Jeffrey divergence; Complex wavelet transform; Feature
   extraction
ID CAUCHY-SCHWARZ DIVERGENCE; TEXTURE RETRIEVAL; OBJECT DETECTION; PART I;
   TRANSFORM; REPRESENTATION; DEPENDENCE; FRAMEWORK
AB This paper presents a new stereo image (SI) retrieval method based on a statistical model of complex wavelet coefficients subbands. In this context, a Gaussian copula-based multivariate model is used to capture the dependence between complex wavelet coefficients of both left and right images, and a non-Gaussian univariate model is used to characterize the statistical behavior of the disparity map. Thanks to its flexibility, the copula tool allows us to choose several marginal densities while keeping the multivariate properties. Features are extracted by estimating parameters for both multivariate and univariate models. Finally, a weighted Jeffrey divergence (JD) is used as a similarity measurement between the underlying models. Experimental results on a stereo image database demonstrate the performance of the proposed method in terms of the retrieval rates as well as the computational time.
C1 [Karine, Ayoub; El Hassouni, Mohammed] Mohammed Univ V Rabat, Fac Sci, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
   [El Maliani, Ahmed Drissi] USMBA, Fac Sci Dhar El Mahraz, LIM, Fes, Morocco.
   [El Hassouni, Mohammed] Mohammed Univ V Rabat, FLSH, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
C3 Centre National de la Recherche Scientifique & Technologique (CNRST);
   Mohammed V University in Rabat; Sidi Mohamed Ben Abdellah University of
   Fez; Mohammed V University in Rabat; Centre National de la Recherche
   Scientifique & Technologique (CNRST)
RP El Hassouni, M (corresponding author), Mohammed Univ V Rabat, Fac Sci, Rabat IT Ctr, LRIT CNRST URAC 29, Rabat, Morocco.
EM mohamed.elhassouni@gmail.com
RI Karine, Ayoub/Y-1901-2019; El Hassouni, Mohammed/AAL-8452-2020; Drissi
   el maliani, Ahmed/ITU-2063-2023
OI Karine, Ayoub/0000-0002-9304-4613; El Hassouni,
   Mohammed/0000-0002-6741-4799; 
CR [Anonymous], 1998, IEEE DIG SIGN PROC W
   [Anonymous], 1999, INTRO COPULAS
   Bombrun Lionel, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3637, DOI 10.1109/ICIP.2011.6116506
   Bombrun L, 2011, INT CONF ACOUST SPEE, P865
   Chaker A, 2015, SIGNAL PROCESS-IMAGE, V31, P174, DOI 10.1016/j.image.2014.12.004
   Cherubini U., 2004, Copula methods in finance
   Choy SK, 2010, IEEE T IMAGE PROCESS, V19, P281, DOI 10.1109/TIP.2009.2033400
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   El Maliani A.D., 2012, LECT NOTES COMPUT SC, V7340, P36
   Feldmann Ingo, 2010, 2010 3DTV C TRUE VIS, P1
   Feng Y, 2011, ELECTRON LETT, V47, P97, DOI 10.1049/el.2010.3267
   Feng Y, 2011, IEEE T BROADCAST, V57, P500, DOI 10.1109/TBC.2011.2131030
   FISHER NI, 1985, BIOMETRIKA, V72, P253
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709
   Jenssen R, 2006, J FRANKLIN I, V343, P614, DOI 10.1016/j.jfranklin.2006.03.018
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Krishnamoorthy K, 2006, STAT TEXTB MONOGR, P1
   Kullback S., 1968, INFORM THEORY STAT
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Kwitt R, 2010, IEEE T IMAGE PROCESS, V19, P241, DOI 10.1109/TIP.2009.2032313
   Kwitt R, 2008, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2008.4711909
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Li CR, 2015, IEEE T IMAGE PROCESS, V24, P2344, DOI 10.1109/TIP.2015.2422575
   Liu Y, 2011, IEEE T IMAGE PROCESS, V20, P2515, DOI 10.1109/TIP.2011.2118223
   Liu Y, 2008, J VISION, V8, DOI 10.1167/8.11.19
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Nguyen TT, 2008, IEEE T SIGNAL PROCES, V56, P4651, DOI 10.1109/TSP.2007.912897
   Peng FF, 2015, IEEE J-STARS, V8, P800, DOI 10.1109/JSTARS.2014.2363953
   Rami H, 2016, SIGNAL PROCESS-IMAGE, V42, P45, DOI 10.1016/j.image.2016.01.005
   Rami H, 2014, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2014.7025603
   Ren J, 2010, IET IMAGE PROCESS, V4, P294, DOI 10.1049/iet-ipr.2009.0071
   Sakji-Nsibi S, 2010, IEEE IMAGE PROC, P2333, DOI 10.1109/ICIP.2010.5653932
   Sakji-Nsibi S, 2009, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2009.5413483
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Simoncelli E.P., 1995, STEERABLE PYRAMID FL, P3444
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Tan P, 2014, IMAGE PROCESS ON LIN, V4, P252, DOI 10.5201/ipol.2014.78
   Tzovaras D, 1999, SIGNAL PROCESS-IMAGE, V14, P817, DOI 10.1016/S0923-5965(98)00046-0
   Verdoolaege G, 2012, J MATH IMAGING VIS, V43, P180, DOI 10.1007/s10851-011-0297-8
   Verdoolaege G, 2009, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2009.5413405
   Xu XD, 2014, 2014 IEEE PHOTONICS SOCIETY SUMMER TOPICAL MEETING SERIES, P1, DOI 10.1109/SUM.2014.8
   Zeng XX, 2014, SIGNAL PROCESS, V94, P691, DOI 10.1016/j.sigpro.2013.07.009
NR 50
TC 12
Z9 12
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 27
EP 39
DI 10.1016/j.jvcir.2017.11.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700004
DA 2024-07-18
ER

PT J
AU Liu, WF
   Zhang, LB
   Tao, DP
   Cheng, J
AF Liu, Weifeng
   Zhang, Lianbo
   Tao, Dapeng
   Cheng, Jun
TI Support vector machine active learning by Hessian regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active learning; Semi-supervised; Manifold regularization; Image
   segmentation; Activity recognition; Hessian
ID NONLINEAR DIMENSIONALITY REDUCTION; IMAGE; EIGENMAPS
AB It is time-consuming and expensive to gather and label the growing multimedia data that is easily accessible with the prodigious development of Internet technology and digital sensors. Hence, it is essential to develop a technique that can efficiently be utilized for the large-scale multimedia data especially when labeled data is rare. Active learning is showing to be one useful approach that greedily chooses queries from unlabeled data to be labeled for further learning and then minimizes the estimated expected learning error. However, most active learning methods only take into account the labeled data in the training of the classifier. In this paper, we introduce a semi-supervised algorithm to learn the classifier and then perform active learning scheme on top of the semi-supervised scheme. Particularly, we employ Hessian regularization into support vector machine to boost the classifier. Hessian regularization exploits the potential geometry structure of data space (including labeled and unlabeled data) and then significantly leverages the performance in each round. To evaluate the proposed algorithm, we carefully conduct extensive experiments including image segmentation and human activity recognition on popular data-sets respectively. The experimental results demonstrate that our method can achieve a better performance than the traditional active learning methods. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Weifeng; Zhang, Lianbo] China Univ Petr East China, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
   [Zhang, Lianbo] Univ Technol Sydney, Adv Analyt Inst, Sydney, NSW 2007, Australia.
   [Tao, Dapeng] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650091, Yunnan, Peoples R China.
   [Cheng, Jun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Cheng, Jun] Chinese Univ Hong Kong, Shatin, Hong Kong, Peoples R China.
C3 China University of Petroleum; University of Technology Sydney; Yunnan
   University; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS; Chinese University of Hong Kong
RP Liu, WF (corresponding author), China Univ Petr East China, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
EM liuwf@upc.edu.cn
RI liu, weifeng/B-7909-2008; Tao, Dapeng/E-8649-2013
OI Tao, Dapeng/0000-0003-0783-5273
CR [Anonymous], 2010, U WISCONSIN MADISON, V52, P11, DOI DOI 10.1016/J.MATLET.2010.11.072
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Cai D, 2012, IEEE T KNOWL DATA EN, V24, P707, DOI 10.1109/TKDE.2011.104
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Culotta Aron, 2005, Proceeding of the 20th National Conference on Artificial Intelligenc(AAAI-2005), V2, P746
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38
   Fu YF, 2013, IEEE T CYBERNETICS, V43, P464, DOI 10.1109/TSMCB.2012.2209177
   Fu YF, 2013, KNOWL INF SYST, V35, P249, DOI 10.1007/s10115-012-0507-8
   Guo YH, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P823
   He XF, 2010, IEEE T IMAGE PROCESS, V19, P254, DOI 10.1109/TIP.2009.2032342
   Hoi Steven C. H., 2006, Proceedings of the International Conference on the World Wide Web (WWW-2006), P633, DOI [10.1145/1135777.1135870, DOI 10.1145/1135777.1135870]
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Kim KwangI., 2009, Advances in Neural Information Processing Systems, P979
   Körner C, 2006, LECT NOTES COMPUT SC, V4212, P687
   Lewis D.D., 1994, MACH LEARN P 1994, P148
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Ma XL, 2015, J VIS COMMUN IMAGE R, V30, P201, DOI 10.1016/j.jvcir.2015.04.008
   Mamitsuka N.A.H., 1998, P 15 INT C ICML 98 M, V1
   Melville P., 2004, ICML, DOI DOI 10.1145/1015330.1015385
   Morik K, 1999, MACHINE LEARNING, PROCEEDINGS, P268
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Qi XY, 2016, J VIS COMMUN IMAGE R, V36, P1, DOI 10.1016/j.jvcir.2016.01.005
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Roy Nicholas, 2001, Toward optimal active learning through monte carlo estimation of error reduction, P441
   Scheffer Tobias, 2001, Advances in Intelligent Data Analysis, V2189, P309, DOI [DOI 10.1007/3-540-44816-031, DOI 10.1007/3-540-44816-0_31]
   Schein AI, 2007, MACH LEARN, V68, P235, DOI 10.1007/s10994-007-5019-5
   Settles B, 2008, ADV NEURAL INFORM PR, V21, P1289
   Settles B, 2008, P C EMP METH NAT LAN, P1070, DOI DOI 10.3115/1613715.1613855
   Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417
   Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807
   STEINKE F., 2009, Adv. Neural Inf. Process. Syst., P1561
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tianyi Zhou, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P679, DOI 10.1109/ICDM.2010.135
   Wang T, 2015, J VIS COMMUN IMAGE R, V33, P10, DOI 10.1016/j.jvcir.2015.08.013
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhan K, 2016, J VIS COMMUN IMAGE R, V40, P847, DOI 10.1016/j.jvcir.2016.08.016
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
NR 45
TC 14
Z9 14
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 47
EP 56
DI 10.1016/j.jvcir.2017.08.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800005
DA 2024-07-18
ER

PT J
AU Rahman, WU
   Chung, K
AF Rahman, Waqas ur
   Chung, Kwangsue
TI A novel adaptive logic for dynamic adaptive streaming over HTTP
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HTTP-based video streaming; Quality of experience; Video rate adaptation
   algorithm; Video streaming scheme
ID RATE ADAPTATION; ALGORITHM; QUALITY; EXPERIENCE
AB In this paper, we propose an estimation method that estimates the throughput of upcoming video segments based on variations in the network throughput observed during the download of previous video segments. Then, we propose a rate-adaptive algorithm for Hypertext Transfer Protocol (HTTP) streaming. The proposed algorithm selects the quality of the video based on the estimated throughput and playback buffer occupancy. The proposed method selects high-quality video segments, while minimizing video quality changes and the risk of playback interruption, improving user's experience. We evaluate the algorithm for single-and multi-user environments and demonstrate that it performs remarkably well under varying network conditions. Furthermore, we determine that it efficiently utilizes network resources to achieve a high video rate; competing HTTP clients achieve equitable video rates. We also confirm that variations in the playback buffer size and segment duration do not affect the performance of the proposed algorithm.
C1 [Rahman, Waqas ur; Chung, Kwangsue] Kwangwoon Univ, Dept Elect & Commun Engn, Chambit 809,447-1 Wolgye Dong, Seoul, South Korea.
C3 Kwangwoon University
RP Chung, K (corresponding author), Kwangwoon Univ, Dept Elect & Commun Engn, Chambit 809,447-1 Wolgye Dong, Seoul, South Korea.
EM kchung@kw.ac.kr
RI Rahman, Waqas ur/X-4387-2019
OI Rahman, Waqas ur/0000-0002-3849-6596
FU Institute for Information & communications Technology Promotion (IITP)
   grant - Korea government (MSIT) [2015-0-00195]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIT)
   (No. 2015-0-00195, Development of LifeMedia hub terminal and services
   based on life style analysis).
CR Akhshabi Saamer, 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video-NOSSDAV'13
   [Anonymous], 2011, Proc. second annu. acm conf. multimed. syst.-mmsys'11, DOI DOI 10.1145/1943552.1943574
   [Anonymous], CONFIGURE HTTP DYNAM
   [Anonymous], 2012, Proceedings of the 22nd international workshop on Network and Operating System Support for Digital Audio and Video
   [Anonymous], 2014, P 2014 WORKSH DES QU
   [Anonymous], VLC SOURECE CODE
   [Anonymous], 2014, CISC VIS NETW IND GL
   [Anonymous], MICROSOFT CORPORATIO
   Azumi M, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417622
   Dai H., 2011, Acta Horticulturae, P169, DOI 10.1145/1943552.1943575
   De Cicco L., 2011, P 2 ANN ACM C MULTIM, P145
   Dobrian F, 2013, COMMUN ACM, V56, P91, DOI 10.1145/2428556.2428577
   Dubin R, 2013, 2013 IEEE WIRELESS COMMUNICATIONS AND NETWORKING CONFERENCE (WCNC), P2178
   Houdaille R., 2012, P 3 MULTIMEDIA SYSTE, P1
   Huang T.Y., 2012, P 2012 ACM C INT MEA, P225, DOI 10.1145/2398776.2398800
   Huang TY, 2014, ACM SIGCOMM COMP COM, V44, P187, DOI 10.1145/2740070.2626296
   Jiang JC, 2014, IEEE ACM T NETWORK, V22, P326, DOI 10.1109/TNET.2013.2291681
   Juluri P, 2015, IEEE INT CONF COMM, P1765, DOI 10.1109/ICCW.2015.7247436
   Le HT, 2013, PROC INT CONF ADV, P33, DOI 10.1109/ATC.2013.6698072
   Li Z, 2014, IEEE J SEL AREA COMM, V32, P719, DOI 10.1109/JSAC.2014.140405
   Li ZR, 2013, 2013 5TH IEEE INTERNATIONAL CONFERENCE ON BROADBAND NETWORK & MULTIMEDIA TECHNOLOGY (IC-BNMT), P1, DOI 10.1109/ICBNMT.2013.6823903
   Miller K., 2012, 2012 Proceedings of the 19th International Packet Video Workshop (PV 2012), P173, DOI 10.1109/PV.2012.6229732
   Mok R.K., 2012, P 3 MULTIMEDIA SYSTE, P11
   Ni P., 2011, P 19 ACM INT C MULT, P463, DOI DOI 10.1145/2072298.2072359
   Pantos Roger., 2014, HTTP live streaming
   Rahman WU, 2016, IEEE T CONSUM ELECTR, V62, P371, DOI 10.1109/TCE.2016.7838089
   Rahman WU, 2016, IEICE T COMMUN, VE99B, P767, DOI 10.1587/transcom.2015EBP3398
   Rahman WU, 2015, KSII T INTERNET INF, V9, P4585, DOI 10.3837/tiis.2015.11.019
   Shen Y, 2015, IEICE T COMMUN, VE98B, P62, DOI 10.1587/transcom.E98.B.62
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Staelens N, 2014, IEEE T BROADCAST, V60, P707, DOI 10.1109/TBC.2014.2359255
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Thang TC, 2012, IEEE T CONSUM ELECTR, V58, P78, DOI 10.1109/TCE.2012.6170058
   Zhu XQ, 2013, IEEE INT WORKSH MULT, P230, DOI 10.1109/MMSP.2013.6659293
NR 34
TC 10
Z9 11
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 433
EP 446
DI 10.1016/j.jvcir.2017.10.007
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800037
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Peng, WJ
   Wang, XY
   Zhao, YL
   Su, YT
AF Nie, Wei-Zhi
   Peng, Wen-Juan
   Wang, Xiang-yu
   Zhao, Yi-liang
   Su, Yu-Ting
TI Multimedia venue semantic modeling based on multimodal data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Location-based; Multimedia modeling; Graph clustering; Image description
ID SVM
AB A huge amount of text and multimedia (images and videos) data concerning venues is constantly being generated. To model the semantics of these venues, it is essential to analyze both text and multimedia user-generated content (UGC) in an integral manner. This task, however, is difficult for location-based social networks (LBSNs) because their text and multimedia UGCs tend to be uncorrelated. In this paper, we propose a novel multimedia location topic modeling approach to address this problem. We first utilize Recurrent Convolutional Networks to build the correlation between multimedia UGCs and text. Then, a graph model is structured according to these correlations. Next, we employ a graph clustering method to detect the latent multimedia topics for each venue. Based on the obtained venue semantics, we propose techniques to model multimedia location topics and perform semantic-based location summarization, venue prediction and image description. Extensive experiments are conducted on a cross-platform dataset, and the promising results demonstrate the superiority of the proposed method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Nie, Wei-Zhi; Peng, Wen-Juan; Su, Yu-Ting] Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
   [Wang, Xiang-yu; Zhao, Yi-liang] Natl Univ Singapore, Sch Comp, Singapore, Singapore.
C3 Tianjin University; National University of Singapore
RP Nie, WZ (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin 300072, Peoples R China.
EM weizhinie@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021; Liu, yuqing/KEI-3260-2024
OI nie, weizhi/0000-0002-0578-8138
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahern S., 2007, JCDL
   Anaya-Sánchez H, 2010, PATTERN RECOGN LETT, V31, P502, DOI 10.1016/j.patrec.2009.11.013
   [Anonymous], 2012, ARXIV12104920
   [Anonymous], 2007, NIPS
   [Anonymous], SIGIR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], PAMI
   Beijbom O, 2012, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2012.6247798
   Belani A., 2010, ARXIV10010700
   Bian JW, 2015, IEEE T MULTIMEDIA, V17, P216, DOI 10.1109/TMM.2014.2384912
   Blei D.M., 2003, SIGIR
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Bradley P. S., 2000, ICPR
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen KY, 2007, IEEE T KNOWL DATA EN, V19, P1016, DOI 10.1109/TKDE.2007.1040
   Chen T., 2012, ACM MM
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Fang Q., 2013, MMM
   Gers FA, 2001, IEEE T NEURAL NETWOR, V12, P1333, DOI 10.1109/72.963769
   Hu Y., 2012, AAAI
   Kurashima T., 2013, WSDM
   Lei CY, 2016, IEEE T MULTIMEDIA, V18, P687, DOI 10.1109/TMM.2015.2477277
   Li F, 2013, LECT NOTES COMPUT SC, V8047, P37, DOI 10.1007/978-3-642-40261-6_4
   Liu H., 2010, ICML
   Liu Han., 2010, NIPS
   Maenpaa Topi., 2000, PATTERN RECOGN, V3, P3947
   Naaman M., 2004, ACM MM
   Pan C., 2011, JCDL
   Putthividhya D., 2010, CVPR
   Raper J, 2007, J LOCAT BASED SERV, V1, P89, DOI 10.1080/17489720701862184
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Sun AX, 2011, IEEE T SYST MAN CY A, V41, P834, DOI 10.1109/TSMCA.2011.2157129
   Tekin C, 2015, IEEE T MULTIMEDIA, V17, P549, DOI 10.1109/TMM.2015.2403234
   Wang J., 2004, AMCIS
   Wang Q, 2013, ACM T INFORM SYST, V31, DOI 10.1145/2414782.2414787
   Wang X., 2010, CVPR
   Wang XY, 2015, IEEE T MULTIMEDIA, V17, P409, DOI 10.1109/TMM.2014.2385473
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P64, DOI 10.1109/TMM.2014.2375793
   Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088
   Zahálka J, 2015, IEEE T MULTIMEDIA, V17, P2235, DOI 10.1109/TMM.2015.2480007
   Zhang R., 2002, ICPR
   Zhao Y, 2011, MENOPAUSE, V18, P690, DOI 10.1097/gme.0b013e3181fd7f4b
NR 47
TC 6
Z9 6
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 375
EP 385
DI 10.1016/j.jvcir.2016.11.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700031
DA 2024-07-18
ER

PT J
AU Lima, JAS
   Miosso, CJ
   Farias, MCQ
AF Lima, J. A. S.
   Miosso, C. J.
   Farias, M. C. Q.
TI Per-pixel mirror-based method for high-speed video acquisition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Computational photography; High-speed imaging
ID CODED EXPOSURE; UNCERTAINTY PRINCIPLES; SIGNAL RECOVERY; RECONSTRUCTION;
   PHOTOGRAPHY; CAMERA
AB High-speed imaging requires high-bandwidth, fast image sensors that are generally only available in high-end specialized cameras. Nevertheless, with the use of compressive sensing theory and computational photography techniques, new methods emerged that use spatial light modulators to reconstruct high-speed videos with low speed sensors. Although these methods represent a big step in the field, they still present some limitations, such as low light efficiency and the generation of measurements with time dependency. To tackle these problems, we propose a per-pixel mirror-based acquisition method that is based on a new kind of light modulator. The proposed method uses moving mirrors to scramble the light coming from different positions, thus ensuring better light efficiency and generating time independent measurements. Our results show that the proposed method and its variations perform better than methods available in the literature, generating videos that are less noisy and that display better content separation. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Lima, J. A. S.] Univ Brasilia, Dept Comp Sci, Brasilia, DF, Brazil.
   [Miosso, C. J.] Univ Brasilia, Gama, Brazil.
   [Farias, M. C. Q.] Univ Brasilia, Dept Elect Engn, Brasilia, DF, Brazil.
C3 Universidade de Brasilia; Universidade de Brasilia; Universidade de
   Brasilia
RP Lima, JAS (corresponding author), Univ Brasilia, Dept Comp Sci, Brasilia, DF, Brazil.
EM jonathanalis@gmail.com
RI Lima, Jonathan Alis/G-1149-2018; Farias, Mylene/C-4900-2015
OI Lima, Jonathan Alis/0000-0003-1680-6327; Farias,
   Mylene/0000-0002-1957-9943
FU Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPq);
   University of Brasilia; Coordenacao de Aperfeicoa-mento de Pessoal de
   Nivel Superior (CAPES)
FX This work was supported in part by Conselho Nacional de Desenvolvimento
   Cientifico e Tecnologico (CNPq), in part by the University of Brasilia,
   and in part by Coordenacao de Aperfeicoa-mento de Pessoal de Nivel
   Superior (CAPES).
CR Agrawal A, 2010, PROC CVPR IEEE, P599, DOI 10.1109/CVPR.2010.5540161
   [Anonymous], 2009, THESIS
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Bub G, 2010, NAT METHODS, V7, P209, DOI [10.1038/NMETH.1429, 10.1038/nmeth.1429]
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Davis A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601119
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Douglass MR, 2003, PROC SPIE, V4980, P1, DOI 10.1117/12.478212
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Feng W, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030331
   Gupta M, 2010, LECT NOTES COMPUT SC, V6311, P100, DOI 10.1007/978-3-642-15549-9_8
   Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254
   Holloway Jason, 2012, Computational Photography (ICCP), 2012 IEEE International Conference on, P1
   Koller R, 2015, OPT EXPRESS, V23, P15992, DOI 10.1364/OE.23.015992
   Li C., 2011, THESIS GUANGZHOU U C
   Li ChunLong Li ChunLong, 2009, China Vegetables, P46
   Lima JA, 2014, EUR SIGNAL PR CONF, P1058
   Miosso C. J., 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P799, DOI 10.1109/ACSSC.2009.5469970
   Muehlmann U, 2004, IEEE INT CONF ROBOT, P5195, DOI 10.1109/ROBOT.2004.1302542
   Nayar SK, 2006, INT J COMPUT VISION, V70, P7, DOI 10.1007/s11263-005-3102-6
   Postema M, 2005, MED PHYS, V32, P3707, DOI 10.1118/1.2133718
   Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957
   Reddy D, 2011, PROC CVPR IEEE, P329, DOI 10.1109/CVPR.2011.5995542
   SHEPP LA, 1974, IEEE T NUCL SCI, VNS21, P21, DOI 10.1109/TNS.1974.6499235
   Takhar Dharmpal, 2006, EL IM 2006
   Veeraraghavan A, 2011, IEEE T PATTERN ANAL, V33, P671, DOI 10.1109/TPAMI.2010.87
   WAKIN M. B., 2006, PICT COD S
   Wang Jenn-hwan., 2015, Border Crossing in Greater China: Production, Community and Identity, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Wilburn B., 2004, P 2004 IEEE COMP SOC, V2, P11
   Zhang L., 2015, US Patent, Patent No. [8,958,649, 8958649]
NR 35
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2017
VL 47
BP 23
EP 35
DI 10.1016/j.jvcir.2017.05.004
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX8TD
UT WOS:000403522200003
DA 2024-07-18
ER

PT J
AU Maiseli, B
   Gu, YF
   Gao, HJ
AF Maiseli, Baraka
   Gu, Yanfeng
   Gao, Huijun
TI Recent developments and trends in point set registration methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Point matching; Registration; Performance; Optimization; Point set
ID ABSOLUTE PERCENTAGE ERROR; GAUSSIAN MIXTURE-MODELS; MATCHING ALGORITHM;
   PARALLEL FRAMEWORK; DRIFT ALGORITHM; POSE ESTIMATION; ROBUST; IMAGE;
   OPTIMIZATION; HEVC
AB Point set registration (PSR) is the process of computing a spatial transformation that optimally aligns pairs of point sets. The method helps to amalgamate multiple datasets into a common coordinate system. Because of their immense practical applications, several studies have attempted to address challenges inherent in the PSR problem. However, limited works exist to discuss recent developments, failures, and trends of the PSR methods. To date, a classical work of Tam et al., published in 2013, can be regarded as a comprehensive review paper for registration methods. Nevertheless, this work has inadequately revealed a range of possible knowledge gaps of the previous studies. Additionally, since the publication year of their work, more superior and state-of-the-art methods have been proposed. The present study surveys PSR approaches until 2017, and our primary focus is to expose central ideas and limitations of the methods to facilitate experts and practitioners advance the field. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Maiseli, Baraka; Gu, Yanfeng] Harbin Inst Technol, Sch Elect & Informat Engn, Harbin 150001, Peoples R China.
   [Maiseli, Baraka] Univ Dar Es Salaam, Coll Informat & Commun Technol, Dept Elect & Telecommun Engn, POB 33335, Dar Es Salaam, Tanzania.
   [Gao, Huijun] Harbin Inst Technol, Res Inst Intelligent Control & Syst, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology; University of Dar es Salaam; Harbin
   Institute of Technology
RP Maiseli, B (corresponding author), Univ Dar Es Salaam, Coll Informat & Commun Technol, Dept Elect & Telecommun Engn, POB 33335, Dar Es Salaam, Tanzania.
EM barakamaiseli@yahoo.com
RI Gao, Huijun/B-6853-2013; Gu, Yanfeng/F-7781-2015; zhang,
   ye/HKN-5128-2023; Maiseli, Baraka/ABD-6700-2020; Maiseli, Baraka
   Jacob/M-2408-2016
OI Maiseli, Baraka Jacob/0000-0002-7551-0107
CR Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], MOL NEUROBIOL
   [Anonymous], ARTIFICIAL INTELLIGE
   [Anonymous], APPL INTELL
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bergstrom P., 2016, NUMER ALGORITHMS, P1
   Besl P J, 1992, P SENSOR FUSION 4 CO, V1611, P586
   BILBRO GL, 1991, IEEE T SYST MAN CYB, V21, P840, DOI 10.1109/21.108301
   Billings SD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117688
   Bonyadi MR, 2016, IEEE T EVOLUT COMPUT, V20, P814, DOI 10.1109/TEVC.2015.2508101
   Bonyadi MR, 2016, IEEE T EVOLUT COMPUT, V20, P370, DOI 10.1109/TEVC.2015.2460753
   Bouaziz S, 2013, COMPUT GRAPH FORUM, V32, P113, DOI 10.1111/cgf.12178
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Chen ECS, 2015, INT J COMPUT ASS RAD, V10, P867, DOI 10.1007/s11548-015-1199-9
   Chen J, 2015, SIGNAL PROCESS, V106, P62, DOI 10.1016/j.sigpro.2014.07.004
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   de Myttenaere A, 2016, NEUROCOMPUTING, V192, P38, DOI 10.1016/j.neucom.2015.12.114
   de Sousa S, 2015, PATTERN RECOGN, V48, P368, DOI 10.1016/j.patcog.2014.06.011
   Demantké J, 2011, INT ARCH PHOTOGRAMM, V38-5, P97
   Dong J., 2016, IET COMPUT VISION
   Dong JM, 2014, NEUROCOMPUTING, V140, P67, DOI 10.1016/j.neucom.2014.03.035
   Du SY, 2016, J VIS COMMUN IMAGE R, V38, P207, DOI 10.1016/j.jvcir.2016.02.019
   Du SY, 2015, NEUROCOMPUTING, V157, P187, DOI 10.1016/j.neucom.2015.01.019
   Du SY, 2010, J VIS COMMUN IMAGE R, V21, P442, DOI 10.1016/j.jvcir.2010.02.005
   Du SY, 2010, PATTERN RECOGN LETT, V31, P791, DOI 10.1016/j.patrec.2010.01.020
   Dupej J, 2015, PATTERN RECOGN LETT, V52, P53, DOI 10.1016/j.patrec.2014.10.005
   Elseberg J., 2012, Journal of Software Engineering for Robotics (JOSER), V3, P2
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Ganapathi V., 2010, Computer Vision and Pattern Recognition (CVPR 2010), P755, DOI DOI 10.1109/CVPR.2010.5540141
   Gao FC, 2012, COMPUT OPTIM APPL, V51, P259, DOI 10.1007/s10589-010-9329-3
   Gao Y, 2014, PATTERN ANAL APPL, V17, P379, DOI 10.1007/s10044-013-0324-z
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Geiger A., 2012, CVPR
   GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040
   Gelfand N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P260, DOI 10.1109/IM.2003.1240258
   Godin G., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2350, P279, DOI 10.1117/12.189139
   Gold S, 1996, NEURAL COMPUT, V8, P787, DOI 10.1162/neco.1996.8.4.787
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Gold S. A., 1996, MATCHING LEARNING ST
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Gressin A, 2012, P ISPRS ANN PHOT REM, V5, P2
   Guo H., 2016, INT J SIMUL SYST SCI, V17
   Guo HK, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148783
   Habert S., 2013, SPIE MED IMAGING
   Hermans J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2465, DOI 10.1109/CVPR.2011.5995744
   HILL DLG, 1991, BRIT J RADIOL, V64, P1030, DOI 10.1259/0007-1285-64-767-1030
   Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Javadi MS, 2015, INT J IMAGE GRAPH, V15, DOI 10.1142/S0219467815400021
   Jenzri S., 2016, US Patent, Patent No. [9,305,352, 9305352]
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Kabus S, 2004, P SOC PHOTO-OPT INS, V5370, P304, DOI 10.1117/12.533976
   Khoo Y, 2016, IEEE T IMAGE PROCESS, V25, P2956, DOI 10.1109/TIP.2016.2540810
   Kim S, 2016, INT J FORECASTING, V32, P669, DOI 10.1016/j.ijforecast.2015.12.003
   Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974
   Klein K, 2014, COMPUT ECON, V43, P447, DOI 10.1007/s10614-013-9377-8
   Klima O., 2016, SPIE MED IMAGING
   Klima O, 2016, IFAC PAPERSONLINE, V49, P121, DOI 10.1016/j.ifacol.2016.12.021
   Koo S, 2013, IEEE INT CONF ROBOT, P1114, DOI 10.1109/ICRA.2013.6630712
   KOSOWSKY JJ, 1994, NEURAL NETWORKS, V7, P477, DOI 10.1016/0893-6080(94)90081-7
   Krishnamurthy V., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P313, DOI 10.1145/237170.237270
   Lalonde JF, 2006, J FIELD ROBOT, V23, P839, DOI 10.1002/rob.20134
   Lalonde JF, 2005, Fifth International Conference on 3-D Digital Imaging and Modeling, Proceedings, P285, DOI 10.1109/3DIM.2005.71
   Lasko TA, 2005, J BIOMED INFORM, V38, P404, DOI 10.1016/j.jbi.2005.02.008
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Li H, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778769
   Li W, 2014, IEEE GEOSCI REMOTE S, V11, P153, DOI 10.1109/LGRS.2013.2250905
   Lian W., 2016, IEEE T PATTERN ANAL
   Lipman Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531378
   Liu SL, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.095085
   Lu M, 2016, IEEE GEOSCI REMOTE S, V13, P162, DOI 10.1109/LGRS.2015.2504268
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Ma JY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0092282
   Ma JY, 2013, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2013.279
   Maier-Hein L, 2012, IEEE T PATTERN ANAL, V34, P1520, DOI 10.1109/TPAMI.2011.248
   Manoj PS, 2015, 2015 14th IAPR International Conference on Machine Vision Applications (MVA), P526, DOI 10.1109/MVA.2015.7153246
   Masuda T., 1994, Proceedings of the 1994 Second CAD-Based Vision Workshop (Cat. No.94TH0595-9), P106, DOI 10.1109/CADVIS.1994.284510
   Mavridis P, 2015, COMPUT AIDED GEOM D, V35-36, P16, DOI 10.1016/j.cagd.2015.03.022
   Mehmetoglu MS, 2015, IEEE T COMMUN, V63, P5089, DOI 10.1109/TCOMM.2015.2494004
   Mitra NJ, 2004, INT J COMPUT GEOM AP, V14, P261, DOI 10.1142/S0218195904001470
   Mjolsness E., 1990, TECHNICAL REPORT
   Munoz D, 2009, PROC CVPR IEEE, P975, DOI 10.1109/CVPRW.2009.5206590
   Myronenko A., 2007, Advances in Neural Information Processing Systems, P1009
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Niedfeldt PC, 2016, IEEE T AUTOMAT CONTR, V61, P456, DOI 10.1109/TAC.2015.2437518
   Papazov C, 2011, COMPUT VIS IMAGE UND, V115, P1598, DOI 10.1016/j.cviu.2011.05.008
   Papazov C, 2009, LECT NOTES COMPUT SC, V5875, P1043, DOI 10.1007/978-3-642-10331-5_97
   Pappu S, 1996, ADV NEUR IN, V8, P795
   Peng L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148483
   Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814
   Pomerleau Francois, 2015, Found. Trends Robot., V4, P1
   Rasoulian A, 2012, IEEE T MED IMAGING, V31, P2025, DOI 10.1109/TMI.2012.2202913
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Sahillioglu Y, 2012, IEEE T PATTERN ANAL, V34, P2203, DOI 10.1109/TPAMI.2012.26
   Sarakhsi MK, 2016, J COMPUT APPL MATH, V292, P387, DOI 10.1016/j.cam.2015.07.027
   Schall O., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P71, DOI 10.1109/PBG.2005.194067
   Schellenberg G, 2016, PHYS MED BIOL, V61, pN90, DOI 10.1088/0031-9155/61/3/N90
   Schestowitz R.S., 2006, P MEDICAL IMAGE UNDE, V2, P151
   Servos J, 2017, ROBOT AUTON SYST, V87, P247, DOI 10.1016/j.robot.2016.10.016
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111
   Singh M., 2004, P IEEE C COMPUTER VI, P174, DOI DOI 10.1109/CVPR.2004.433
   Studholme C., 1995, BMVC, P1
   Süssmuth J, 2008, COMPUT GRAPH FORUM, V27, P1469, DOI 10.1111/j.1467-8659.2008.01287.x
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Nguyen TM, 2016, IEEE T MED IMAGING, V35, P1381, DOI 10.1109/TMI.2015.2511063
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Tippayawannakorn N, 2016, THAIL STATIST, V14, P63
   Torsello A., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P290, DOI 10.1109/3DIMPVT.2011.43
   Tsai CL, 2010, IEEE T MED IMAGING, V29, P636, DOI 10.1109/TMI.2009.2030324
   Tsin Y., 2004, Proceedings of European Conference on Computer Vision, P558
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   Wahba G., 1990, SPLINE MODELS OBSERV
   Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526
   Wang G, 2016, PROC CVPR IEEE, P5811, DOI 10.1109/CVPR.2016.626
   Wang P, 2011, SCI CHINA INFORM SCI, V54, P2639, DOI 10.1007/s11432-011-4465-7
   Weiss A, 2011, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2011.6126465
   Wiemann T., 2010, P 8 IEEE INT WORKSH, P22
   Wu C, 2014, NEUROCOMPUTING, V144, P546, DOI 10.1016/j.neucom.2014.04.012
   Wu GR, 2014, HUM BRAIN MAPP, V35, P1044, DOI 10.1002/hbm.22233
   Xu YW, 2014, IEEE T AUTOMAT CONTR, V59, P2807, DOI 10.1109/TAC.2014.2319473
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]
   Yang JB, 2014, IEEE T IMAGE PROCESS, V23, P4863, DOI 10.1109/TIP.2014.2344294
   Yang JQ, 2016, INFORM SCIENCES, V346, P163, DOI 10.1016/j.ins.2016.01.095
   Yang JZ, 2011, PATTERN RECOGN LETT, V32, P910, DOI 10.1016/j.patrec.2011.01.015
   Yang LJ, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.025014
   Yang MS, 2012, PATTERN RECOGN, V45, P3950, DOI 10.1016/j.patcog.2012.04.031
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zhang J., 2015, J APPL REMOTE SENS, V9
   Zhang J.-l., 2012, WORLD C MED PHYS BIO, P920
   Zhang K, 2014, IEEE GEOSCI REMOTE S, V11, P469, DOI 10.1109/LGRS.2013.2267771
   Zhang PP, 2017, NEUROCOMPUTING, V219, P455, DOI 10.1016/j.neucom.2016.09.058
   Zhang YH, 2016, SIAM J NUMER ANAL, V54, P2833, DOI 10.1137/15M1047891
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zheng YF, 2006, IEEE T PATTERN ANAL, V28, P643, DOI 10.1109/TPAMI.2006.81
   Zhou ZX, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112918
   Zhou ZY, 2017, BIOMED SIGNAL PROCES, V33, P10, DOI 10.1016/j.bspc.2016.11.009
   Zhu JH, 2014, IET IMAGE PROCESS, V8, P582, DOI 10.1049/iet-ipr.2013.0545
NR 152
TC 94
Z9 104
U1 3
U2 74
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 95
EP 106
DI 10.1016/j.jvcir.2017.03.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500009
DA 2024-07-18
ER

PT J
AU Yang, Y
   Li, DY
AF Yang, Ying
   Li, Danyang
TI Robust player detection and tracking in broadcast soccer video based on
   enhanced particle filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Particle filter; Salient region detection; Otsu
   algorithm
AB It is significant to detect and track soccer players in broadcast sports video, which is helpful to analysis player activity and team tactics. However, it is challenging to efficiently detect and track soccer players with shots switched and noise caused by auditorium and billboards. And for multi-player tracking how to treat the increase or decrease of player are also difficult. In this paper, a robust player detection algorithm based on salient region detection and tracking based on enhanced particle filtering are proposed. Salient region detection is used to segment sports fields, and then soccer players are detected by edge detection combined with Otsu algorithm. For soccer players tracking, we use an enhanced particle filter which we improve the algorithm in sample and the likelihood function combing the color feature and edge feature. Experimental results show the proposed algorithm can quickly and accurately detect and track soccer players in broadcast video. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yang, Ying; Li, Danyang] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Li, Danyang] 27 Qinghua East Rd, Beijing 100083, Peoples R China.
C3 China Agricultural University
RP Yang, Y (corresponding author), 27 Qinghua East Rd, Beijing 100083, Peoples R China.
EM hbxtyy@126.com; 276437131@qq.com
RI Li, Dan/HJA-0406-2022; li, danyang/HHS-3319-2022
FU National Natural Science Foundation of China [61202330]; National
   Science and Technology Support Program [2015BAK04B01]
FX This work was supported by National Natural Science Foundation of China
   (Grant No. 61202330) and the National Science and Technology Support
   Program (2015BAK04B01).
CR [Anonymous], COMPUT ENG APPL
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 11 ACM INT C MULT BE
   [Anonymous], INFRARED LASER ENG
   [Anonymous], USING LEARNING APPRO
   [Anonymous], NAT C INF RETR CONT
   [Anonymous], APPL ELECTRO TECH
   [Anonymous], INFORM TECHNOL
   [Anonymous], IEEE C EV COMP COMP
   [Anonymous], C HELL SOC EX BIOCH
   [Anonymous], COMPUT SCI
   [Anonymous], BRIT MACH VIS C
   Chai Y, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P735, DOI 10.1109/ICCE.2011.5722836
   Chen XZ, 2015, ADV NEUR IN, V28
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   de Pádua PHC, 2015, SIBGRAPI, P134, DOI 10.1109/SIBGRAPI.2015.10
   Fox D., 2001, Advances in Neural Information Processing Systems, V14, P713
   Gao KZ, 2012, IEEE C EVOL COMPUTAT
   Hao T, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17060907
   Hao T, 2016, NEUROCOMPUTING, V195, P6, DOI 10.1016/j.neucom.2015.06.106
   Heydari M, 2012, INT CONF ROBOT ARTIF, P195, DOI 10.1109/ICRAI.2012.6413398
   Li TC, 2014, EXPERT SYST APPL, V41, P3944, DOI 10.1016/j.eswa.2013.12.031
   Liu A. A., 2016, IEEE Trans Pattern Anal Mach Intell, P1
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008
   Mazzeo P. L., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P326, DOI 10.1109/AVSS.2008.33
   Najafzadeh N, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P310, DOI 10.1109/AISP.2015.7123503
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perera AGA, 2006, IEEE COMP SOC C COMP, P666
   Tsai TY, 2016, INT CONF ACOUST SPEE, P1826, DOI 10.1109/ICASSP.2016.7471992
   Wu Shidong, 2015, Journal of University of Science and Technology of China, V45, P934, DOI 10.3969/j.issn.0253-2778.2015.11.009
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   [许统德 Xu Tongde], 2013, [计算机应用与软件, Computer Applications and Software], V30, P287
   [杨大为 Yang Dawei], 2013, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V26, P680
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yang ZG, 2007, IEEE IMAGE PROC, P3001
   Yin MH, 2011, EXPERT SYST APPL, V38, P6313, DOI 10.1016/j.eswa.2010.11.111
   Yu JX, 2012, CHIN CONT DECIS CONF, P3936, DOI 10.1109/CCDC.2012.6243105
   Zhang Shigui, 2011, Journal of Detection & Control, V33, P46
   [郑玉凤 ZHENG Yufeng], 2011, [光电子·激光, Journal of Optoelectronics·Laser], V22, P1231
NR 45
TC 24
Z9 25
U1 2
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 81
EP 94
DI 10.1016/j.jvcir.2017.03.008
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500008
DA 2024-07-18
ER

PT J
AU Du, HS
   Zhao, ZL
   Wang, S
   Hu, QP
AF Du, Haishun
   Zhao, Zhaolong
   Wang, Sheng
   Hu, Qingpu
TI Two-dimensional discriminant analysis based on Schatten <i>p</i>-norm
   for image feature extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Schatten p-norm; Two-dimensional discriminant analysis; Feature
   extraction; Subspace learning; Image recognition
ID PRINCIPAL COMPONENT ANALYSIS; ROBUST MATRIX COMPLETION
AB A Schatten p-norm-based two-dimensional principal component analysis (2DPCA-SP) method was proposed for image feature extraction in our previous work. As an unsupervised method, 2DPCA-SP ignores the label information of training samples, which is essential to classification tasks. In this paper, we propose a novel Schatten p-norm-based two-dimensional discriminant analysis (2DDA-SP) method for image feature extraction, which learns an optimal projection matrix by maximizing the difference of Schatten p-norm-based between-class dispersion and Schatten p-norm-based within-class dispersion in low-dimensional feature space. By using both the Schatten p-norm metric and the label information of training samples, 2DDA-SP not only can efficiently extract discriminative features, but is also robust to outliers. We also propose an efficient iterative algorithm to solve the optimization problem of 2DDA-SP with 0 < p < 1. Experimental results on several image databases show that 2DDA-SP with 0 < p < 1 is effective and robust for image feature extraction. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Du, Haishun; Zhao, Zhaolong; Wang, Sheng; Hu, Qingpu] Henan Univ, Inst Image Proc & Pattern Recognit, Kaifeng 475004, Peoples R China.
C3 Henan University
RP Wang, S (corresponding author), Henan Univ, Inst Image Proc & Pattern Recognit, Kaifeng 475004, Peoples R China.
EM wangsheng1910@163.com
OI Du, Haishun/0000-0003-0883-8118
FU NSFC-Henan Talent Jointly Training Foundation of China [U1504621];
   Project of Science and Technology Development in Henan Province of China
   [172102210185]; Key Scientific Research Project of University in Henan
   Province of China [15A413009]
FX We would like to thank all reviewers and editors for their detailed
   reviews, constructive suggestions, and valuable comments. This work is
   supported in part by the NSFC-Henan Talent Jointly Training Foundation
   of China (No. U1504621), the Project of Science and Technology
   Development in Henan Province of China (No. 172102210185), and the Key
   Scientific Research Project of University in Henan Province of China
   (No. 15A413009).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Chen SB, 2007, NEUROCOMPUTING, V70, P912, DOI 10.1016/j.neucom.2006.10.032
   Ding C., 2006, P 23 INT C MACH LEAR, P281, DOI DOI 10.1145/1143844.1143880
   Du HS, 2015, J VIS COMMUN IMAGE R, V32, P55, DOI 10.1016/j.jvcir.2015.07.011
   Georghiades A., 1997, Yale face database
   Gu ZH, 2012, INT C PATT RECOG, P1213
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ke QF, 2005, PROC CVPR IEEE, P739
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Kwak N, 2014, IEEE T CYBERNETICS, V44, P594, DOI 10.1109/TCYB.2013.2262936
   Li CN, 2015, NEURAL NETWORKS, V65, P92, DOI 10.1016/j.neunet.2015.01.003
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li X, 2010, NEUROCOMPUTING, V73, P2571, DOI 10.1016/j.neucom.2010.05.016
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Luo L, 2014, COMM COM INF SC, V483, P140
   Nie F., 2011, P INT JOINT C ART IN
   Nie F., 2012, AAAI, P655
   Nie FP, 2015, KNOWL INF SYST, V42, P525, DOI 10.1007/s10115-013-0713-z
   Nie FP, 2012, IEEE DATA MINING, P566, DOI 10.1109/ICDM.2012.160
   Oh JH, 2013, PATTERN RECOGN LETT, V34, P679, DOI 10.1016/j.patrec.2013.01.016
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang JG, 2008, NEUROCOMPUTING, V72, P352, DOI 10.1016/j.neucom.2008.01.004
   XU L, 1995, IEEE T NEURAL NETWOR, V6, P131, DOI 10.1109/72.363442
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang FL, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P74, DOI 10.1109/ACPR.2013.10
   Zhong FJ, 2013, IEEE T IMAGE PROCESS, V22, P3018, DOI 10.1109/TIP.2013.2253476
NR 32
TC 14
Z9 15
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 87
EP 94
DI 10.1016/j.jvcir.2017.02.015
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100008
DA 2024-07-18
ER

PT J
AU Arashloo, SR
   Amirani, MC
   Noroozi, A
AF Arashloo, Shervin Rahimzadeh
   Amirani, Mehdi Chehel
   Noroozi, Ardeshir
TI Dynamic texture representation using a deep multi-scale convolutional
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic texture; Multilayer convolutional architectures; PCA;
   Multi-scale analysis
ID CLASSIFICATION; MODEL
AB This work addresses dynamic texture representation and recognition via a convolutional multilayer architecture. The proposed method considers an image sequence as a concatenation of spatial images along the time axis as well as spatio-temporal images along both horizontal and vertical axes of an image sequence and uses multilayer convolutional operations to describe each plane. The filters used are learned via principal component analysis (PCA) on each of the three orthogonal planes of an image sequence. A particularly advantageous attribute of the technique is the unsupervised training procedure of the proposed network. An inter-database evaluation has been performed to investigate the generalisation capability of the proposed approach. Moreover, a multi-scale extension of the proposed architecture is presented to capture texture details at multiple resolutions. Through extensive evaluations on different databases, it is shown that the proposed PCA-based network on three orthogonal planes (PCANet-TOP) yields very discriminative features for dynamic texture classification. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Arashloo, Shervin Rahimzadeh] Tarbiat Modares Univ, Fac Med Sci, Dept Med Informat, Tehran, Iran.
   [Amirani, Mehdi Chehel; Noroozi, Ardeshir] Urmia Univ, Fac Engn, Dept Elect Engn, Orumiyeh, Iran.
C3 Tarbiat Modares University; Urmia University
RP Arashloo, SR (corresponding author), Tarbiat Modares Univ, Fac Med Sci, Dept Med Informat, Tehran, Iran.
EM S.Rahimzadeh@modares.ac.ir; m.amirani@urmia.ac.ir
RI Arashloo, Shervin Rahimzadeh/A-6381-2019; Chehel Amirani,
   Mehdi/AGL-1681-2022
OI Rahimzadeh Arashloo, Shervin/0000-0003-0189-4774; Chehel Amirani,
   Mehdi/0000-0002-5179-9831
CR [Anonymous], COMP IMAG VIS
   [Anonymous], 7 INT C EMMCVPR 2009
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2014, P 2 INT C LEARN REPR
   [Anonymous], 2008, PROC INT C MACHINE L
   [Anonymous], 2013, BIOMETRIC RECOGNITIO
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], BIOM THEOR APPL SYST
   [Anonymous], DEEP LEARNING UNPUB
   [Anonymous], IET COMPUT VISION
   [Anonymous], HIERARCHICAL IMAGE M
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Arashloo SR, 2014, IEEE T MULTIMEDIA, V16, P2099, DOI 10.1109/TMM.2014.2362855
   Arashloo SR, 2014, IEEE T INF FOREN SEC, V9, P2100, DOI 10.1109/TIFS.2014.2359587
   Arashloo SR, 2014, PATTERN RECOGN LETT, V48, P49, DOI 10.1016/j.patrec.2014.05.017
   Bar-Joseph Z, 2001, IEEE T VIS COMPUT GR, V7, P120, DOI 10.1109/2945.928165
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bruce V., 1996, VISUAL PERCEPTION
   Chan A, 2007, 2007 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2007.382996, DOI 10.1109/CVPR.2007.382996]
   Chan AB, 2005, PROC CVPR IEEE, P846
   Chan AB, 2010, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2010.5539878
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chetverikov D, 2005, ADV SOFT COMP, P17
   Culibrk D, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1201, DOI 10.1145/2647868.2655048
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Derpanis KG, 2012, IEEE T PATTERN ANAL, V34, P1193, DOI 10.1109/TPAMI.2011.221
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Dubois S, 2015, SIGNAL IMAGE VIDEO P, V9, P819, DOI 10.1007/s11760-013-0532-4
   Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584
   Ghanem B., 2010, LECT NOTES COMPUT SC, P223
   Ji H, 2013, IEEE T IMAGE PROCESS, V22, P286, DOI 10.1109/TIP.2012.2214040
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kung T., 1988, NATURAL COMPUTATION, P224
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mumtaz A, 2015, IEEE T PATTERN ANAL, V37, P697, DOI 10.1109/TPAMI.2014.2359432
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Péteri R, 2005, LECT NOTES COMPUT SC, V3523, P223
   Qi XB, 2016, NEUROCOMPUTING, V171, P1230, DOI 10.1016/j.neucom.2015.07.071
   Qiao YL, 2015, IEEE SIGNAL PROC LET, V22, P509, DOI 10.1109/LSP.2014.2362613
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Ravichandran A, 2013, IEEE T PATTERN ANAL, V35, P342, DOI 10.1109/TPAMI.2012.83
   Ravichandran A, 2009, PROC CVPR IEEE, P1651, DOI 10.1109/CVPRW.2009.5206847
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Saisan P, 2001, PROC CVPR IEEE, P58
   Smith JR, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P437
   Sun Y, 2014, ADV NEUR IN, V27
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Szummer M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P823, DOI 10.1109/ICIP.1996.560871
   Taylor G, 2009, P 26 ANN INT C MACH
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Taylor Graham W, 2006, ADV NEURAL INFORM PR, V19, P2
   Thériault C, 2013, PROC CVPR IEEE, P2603, DOI 10.1109/CVPR.2013.336
   Wang YZ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P213, DOI 10.1109/ICCV.2003.1238343
   Wildes R., 2000, P EUROPEAN C COMPUTE, P768
   Woolfe F, 2006, LECT NOTES COMPUT SC, V3952, P549
   Xu Y, 2011, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2011.6126372
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 61
TC 38
Z9 38
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 89
EP 97
DI 10.1016/j.jvcir.2016.12.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400009
DA 2024-07-18
ER

PT J
AU Luo, LK
   Wang, XF
   Hu, SQ
   Hu, X
   Chen, LM
AF Luo, Lingkun
   Wang, Xiaofang
   Hu, Shiqiang
   Hu, Xin
   Chen, Liming
TI Interactive image segmentation based on samples reconstruction and FLDA
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FLDA; Interactive segmentation; Sample reconstruction; Superpixel;
   Multi-classification; Dictionary building
ID ENERGY MINIMIZATION; RANDOM-WALKS; RECOGNITION; EXTRACTION
AB Existing interactive image segmentation methods heavily rely on manual input, i.e. a sufficient quantity and correct locations of labels. In this paper, we propose a new interactive segmentation algorithm which aims to reduce human intervention and to generate high-quality segmentation results. In contrast to most energy minimizing based segmentation methods, the segmentation is cast as multi-classification in our proposed method. First, the input image is segmented into superpixels by using different methods. Then we build a dictionary consisting of all obtained superpixels and reconstruct samples represented by certain labeled superpixels. Finally, we learn a discriminative projection matrix through Fishers linear discriminant analysis (FLDA) algorithm, which learns a discriminative subspace for classification. The unlabeled superpixels are grouped into foreground or background, via calculating their minimal norm. Our method can capture long range grouping cues and reduce the sensitivity with respect to input label quantity and location of labels, by the combination of superpixels and discriminative dictionary. Extensive experiments are conducted both on MSRC and another challenging database in order to demonstrate the effectiveness of the proposed method. Quantitative and qualitative results show that our method is competitive to the state-of-the-art performance. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Luo, Lingkun; Hu, Shiqiang] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Wang, Xiaofang; Chen, Liming] Ecole Cent Lyon, CNRS, LIRIS, UMR 5205, F-69130 Ecully, France.
   [Hu, Xin] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University; Ecole Centrale de Lyon; Centre National
   de la Recherche Scientifique (CNRS); Institut National des Sciences
   Appliquees de Lyon - INSA Lyon; University of Shanghai for Science &
   Technology
RP Hu, SQ (corresponding author), Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM sqhu@sjtu.edu.cn
RI Lu, Rui/KCJ-8212-2024
FU National Natural Science Foundation of China [61374161, 61503173]; China
   Aviation Science Foundation [20142057006]
FX This paper is jointly supported by the National Natural Science
   Foundation of China "61374161", China Aviation Science Foundation
   "20142057006" and National Natural Science Foundation of China
   "61503173". We thank the reviewers and editors for their comments and
   suggestions.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 1973, PATTERN CLASSIFICATI
   [Anonymous], 7 IEEE INT S MULT
   [Anonymous], 2014, ABS14127062 CORR
   Arbelaez P., 2008, Proc. IEEE Conf. Computer Vision and Pattern Recognition CVPR 2008, P1
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dong L, 2016, PATTERN RECOGN, V59, P282, DOI 10.1016/j.patcog.2016.03.005
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Donoser M, 2007, PROC CVPR IEEE, P2000
   Duchenne O., 2008, IEEE COMPUTER VISION, P1, DOI DOI 10.1109/CVPR.2008.4587419
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Falcao AX, 2000, IEEE T MED IMAGING, V19, P55, DOI 10.1109/42.832960
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Kim TH, 2010, PROC CVPR IEEE, P3201, DOI 10.1109/CVPR.2010.5540078
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lu X., 2016, IEEE T CYBERNET, VPP, P1
   Mortensen EN, 1998, GRAPH MODEL IM PROC, V60, P349, DOI 10.1006/gmip.1998.0480
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Noma A, 2012, PATTERN RECOGN, V45, P1159, DOI 10.1016/j.patcog.2011.08.017
   Price BL, 2010, PROC CVPR IEEE, P3161, DOI 10.1109/CVPR.2010.5540079
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Vezhnevets V., 2005, Proc. Graphicon, V1, P150
   Wang T, 2015, J VIS COMMUN IMAGE R, V33, P10, DOI 10.1016/j.jvcir.2015.08.013
   Wang XF, 2015, IEEE T IMAGE PROCESS, V24, P1399, DOI 10.1109/TIP.2015.2397313
   Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611
NR 39
TC 6
Z9 6
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 138
EP 151
DI 10.1016/j.jvcir.2016.12.012
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400014
DA 2024-07-18
ER

PT J
AU Tian, XL
   Zhao, SJ
   Jiao, LC
   Gan, ZP
AF Tian, Xiaolin
   Zhao, Sujie
   Jiao, Licheng
   Gan, Zhipeng
TI Nonnegative coding based ensemble tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Haar-like features; Margin maximization; Nonnegative
   coding; Ensemble learning; Classifier update; Correct classification
   rate; Occlusion identification
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; VISUAL TRACKING;
   OBJECT TRACKING; REGRESSION; DECISION
AB We describes a novel ensemble learning framework for tracking single visual object that, unlike existing ensemble approaches, relies on the modified nonnegative coding to select the optimal subset of classifiers and determinate the corresponding weights. The obtained ensemble classifier makes the tracker to be more robust. The iteration update and the proof of convergence for solving the objective function of the nonnegative coding based ensemble learning are provided. For object tracking, we use the predicted labels generated by each selected individual classifier to compute the correct classification rate, and thence use it to identify occlusion, which is critical to minimize tracking drift. Evaluation is performed on fifty challenging benchmark sequences, and shows our approach achieving or exceeding the state of the art. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tian, Xiaolin; Zhao, Sujie; Jiao, Licheng; Gan, Zhipeng] Xidian Univ, Int Res Ctr Intelligent Percept & Computat, Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian, Peoples R China.
C3 Xidian University
RP Tian, XL (corresponding author), Xidian Univ, Inst Intelligent Informat Proc, POB 224, Xian 710071, Peoples R China.
EM xltian@mail.xidian.edu.cn
RI Jiao, Licheng/JOZ-0842-2023
OI Jiao, Licheng/0000-0003-3354-9617
FU National Natural Science Foundation of China [61571342, 61203303,
   61202176]; National Basic Research Program of China [2013CB329402]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61571342, 61203303, and 61202176; by the National
   Basic Research Program of China under Grant 2013CB329402.
CR [Anonymous], 2005, Proc._Neural_Information_Processing_System
   [Anonymous], 2001, THESIS
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen HH, 2009, IEEE T KNOWL DATA EN, V21, P999, DOI 10.1109/TKDE.2009.62
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hachour S, 2014, INFORM FUSION, V20, P174, DOI 10.1016/j.inffus.2014.01.007
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He X., 2003, ADV NEURAL INFORM PR, P153
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   KIM T.-K., 2010, 2010 IEEE COMPUTER S, P1
   LeBlanc M, 1996, J AM STAT ASSOC, V91, P1641, DOI 10.2307/2291591
   Lee D D, 2000, Adv. Neural Inf. Process., P535, DOI DOI 10.1186/GB-2013-14-4-R39
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Leistner C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1362, DOI 10.1109/ICCVW.2009.5457451
   Li L, 2014, PATTERN RECOGN, V47, P3451, DOI 10.1016/j.patcog.2014.04.015
   Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Oza Nikunj C, 2001, INT WORKSH ART INT S, P229
   Qian C, 2014, NEUROCOMPUTING, V136, P327, DOI 10.1016/j.neucom.2013.12.025
   Schapire RE, 1998, ANN STAT, V26, P1651
   SHAPLEY L, 1984, PUBLIC CHOICE, V43, P329, DOI 10.1007/BF00118940
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yuan HN, 2013, IEEE T KNOWL DATA EN, V25, P2900, DOI 10.1109/TKDE.2012.245
   Zhang HL, 2015, IEEE SIGNAL PROC LET, V22, P1350, DOI 10.1109/LSP.2015.2404856
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 44
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 166
EP 175
DI 10.1016/j.jvcir.2016.09.014
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000015
DA 2024-07-18
ER

PT J
AU Yagoubi, MR
   Serir, A
   Beghdadi, A
AF Yagoubi, Mohamed Riad
   Serir, Amina
   Beghdadi, Azeddine
TI Joint enhancement-compression of handwritten document images through
   DjVu encoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Document image enhancement; Historical document; Image restoration;
   Image compression; Image segmentation; Joint enhancement-compression;
   Waveatoms; Directional filter; DjVu; JPEG2000
ID WAVE ATOMS; BINARIZATION; RESTORATION; DIFFUSION
AB Despite all the technological developments in image acquisition and processing, preserving old documents and other data of historical interest is still a very challenging issue. Indeed, these documents are often proned to several types of artifacts affecting their readability. Furthermore, due to the considerable information considered in such media, reducing the size of the digitized documents is another challenging problem since their entropy is often high due to the presence of artifacts. Thus, we believe that directing the lost of information onto artifacts could bring an elegant solution to this issue. In this paper, we propose the first approach joining enhancement-compression for handwritten document images. This approach presents a novel foreground/background segmentation algorithm, using both directional and contrast features to highlight the original information. This pre-treatment step is embedded into DjVu encoder, which is commonly used in National Archives and libraries frameworks, to drive the compression rate. Both objective evaluation and perceptual judgment demonstrate the efficiency of the proposed scheme on the whole DIBCO datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yagoubi, Mohamed Riad; Serir, Amina] USTHB, Dept Telecommun, LTIR, Algiers, Algeria.
   [Beghdadi, Azeddine] Inst Galile, L2TI, Paris, France.
C3 University Science & Technology Houari Boumediene
RP Yagoubi, MR (corresponding author), USTHB, Dept Telecommun, LTIR, Algiers, Algeria.
EM myagoubi@usthb.dz
RI SERIR, Amina/AIE-7078-2022; Beghdadi, Azeddine/ABF-9801-2022
OI SERIR, Amina/0000-0001-7716-1273; Beghdadi, Azeddine/0000-0002-5595-0615
CR [Anonymous], 2001, P 18 INT C MACH LEAR
   Beghdadi A., 2007, 9 INT S SIGN PROC IT, P1
   Bottou L, 1998, J ELECTRON IMAGING, V7, P410, DOI 10.1117/1.482609
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   de Queiroz R, 1998, P SOC PHOTO-OPT INS, V3653, P1106, DOI 10.1117/12.334618
   Demanet L, 2007, APPL COMPUT HARMON A, V23, P368, DOI 10.1016/j.acha.2007.03.003
   Drira Fadoua, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P321, DOI 10.1109/ICDAR.2009.109
   Drira F, 2012, INT J DOC ANAL RECOG, V15, P183, DOI 10.1007/s10032-011-0165-5
   Dubois E, 2005, ARCHIVING 2005, FINAL PROGRAM AND PROCEEDINGS, P170
   Haddad Z, 2013, PATTERN RECOGN, V46, P2450, DOI 10.1016/j.patcog.2013.02.004
   Haffner P., 2002, ISMM, V2
   Haneda E, 2011, IEEE T IMAGE PROCESS, V20, P1611, DOI 10.1109/TIP.2010.2101611
   Hedjam R, 2013, PATTERN RECOGN, V46, P2297, DOI 10.1016/j.patcog.2012.12.015
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Kim SJ, 2011, PATTERN RECOGN, V44, P1461, DOI 10.1016/j.patcog.2010.12.019
   Lee WL, 2000, SIGNAL PROCESS, V80, P45, DOI 10.1016/S0165-1684(99)00110-3
   LENEGRATE A, 1992, CVGIP-GRAPH MODEL IM, V54, P13, DOI 10.1016/1049-9652(92)90030-2
   Liu F, 2012, OPT COMMUN, V285, P5008, DOI 10.1016/j.optcom.2012.08.007
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Mitchell J., 1992, ITU-Rec. T. 81
   Moghaddam RF, 2009, PATTERN RECOGN, V42, P3355, DOI 10.1016/j.patcog.2008.10.021
   Moghaddam RF, 2009, INT J DOC ANAL RECOG, V11, P183, DOI 10.1007/s10032-008-0076-2
   Monteil J, 1999, IEEE T PATTERN ANAL, V21, P940, DOI 10.1109/34.790435
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panchapakesan K, 1998, INT CONF ACOUST SPEE, P2649, DOI 10.1109/ICASSP.1998.678067
   Pratikakis I, 2012, INT CONF FRONT HAND, P817, DOI 10.1109/ICFHR.2012.216
   RAMPONI G, 1993, SIGNAL PROCESS, V33, P23, DOI 10.1016/0165-1684(93)90075-L
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shafait F, 2008, IEEE T PATTERN ANAL, V30, P941, DOI 10.1109/TPAMI.2007.70837
   Sharma G, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P609, DOI 10.1109/ICIP.2000.899508
   Su BL, 2013, IEEE T IMAGE PROCESS, V22, P1408, DOI 10.1109/TIP.2012.2231089
   Su Bolan, 2010, P INT WORKSH DOC AN, P159
   Tan CL, 2002, IEEE T PATTERN ANAL, V24, P1399, DOI 10.1109/TPAMI.2002.1039211
   Tsai CM, 2002, IEEE T IMAGE PROCESS, V11, P434, DOI 10.1109/TIP.2002.999677
   Villemoes LF, 2002, CR MATH, V335, P793, DOI 10.1016/S1631-073X(02)02570-0
   Wang Q, 2003, PROC INT CONF DOC, P736
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   Yagoubi M., 2014, VIS INF PROC EUVIP 2, P1
   Yagoubi MR, 2015, PROC INT CONF DOC, P1126, DOI 10.1109/ICDAR.2015.7333936
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zheng YF, 2004, IEEE T PATTERN ANAL, V26, P337, DOI 10.1109/TPAMI.2004.1262324
NR 43
TC 3
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 324
EP 338
DI 10.1016/j.jvcir.2016.10.012
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000029
DA 2024-07-18
ER

PT J
AU Wang, Z
   Zhu, SQ
   Li, YH
   Cui, ZZ
AF Wang, Zhi
   Zhu, Shiqiang
   Li, Yuehua
   Cui, Zhengzhe
TI Convolutional neural network based deep conditional random fields for
   stereo matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Conditional random fields; Convolutional neural network
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; BELIEF PROPAGATION;
   SEGMENTATION; PATCHMATCH
AB Stereo matching has been studied for many years and is still a challenge problem. The Markov Random Fields (MRF) model and the Conditional Random Fields (CRF) model based methods have achieved good performance recently. Based on these pioneer works, a deep conditional random fields based stereo matching algorithm is proposed in this paper, which draws a connection between the Convolutional Neural Network (CNN) and CRF. The object knowledge is used as a soft constraint, which can effectively improve the depth estimation accuracy. Moreover, we proposed a CNN potential function that learns the potentials of CRF in a CNN framework. The inference of the CRF model is formulated as a Recurrent Neural Network (RNN). A variety of experiments have been conducted on KITTI and Middlebury benchmark. The results show that the proposed algorithm can produce state-of-the-art results and outperform other MRF-based or CRF-based methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Zhi; Zhu, Shiqiang; Li, Yuehua; Cui, Zhengzhe] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, Z (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM 11325067@zju.edu.cn
RI LI, Yue/GRS-8071-2022; li, yue/HSF-7296-2023; li, yueyue/IVH-9846-2023;
   li, yue/IXD-9935-2023
FU National Natural Science Foundation of China [51521064]; Hangzhou Civic
   Significant Technological Innovation Project of China [20131110A04,
   20142013A56]
FX The authors would like to thank the National Natural Science Foundation
   of China (Grant No: 51521064), the Hangzhou Civic Significant
   Technological Innovation Project of China (No: 20131110A04), Hangzhou
   Civic Significant Technological Innovation Project of China (No:
   20142013A56) for supporting this work.
CR [Anonymous], LOW LEVEL VISION CON
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 2009, P TWELTH INT C ARTIF
   [Anonymous], SCHOLARPEDIA
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2015, J MACHINE LEARNING R
   [Anonymous], BRIT MACH VIS C 2008
   [Anonymous], INT VEH S
   [Anonymous], PROC CVPR IEEE
   [Anonymous], J ELECT IMAGING
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], INT VEH S
   [Anonymous], 2014, IEEE T PATTERN ANAL
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2014, P ADV NEUR INF PROC
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261
   Bleyer M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3081, DOI 10.1109/CVPR.2011.5995581
   Bleyer M, 2010, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2010.5539783
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117
   Donglai Wei, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P277, DOI 10.1109/3DV.2014.97
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gurrieri LE, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.011004
   Hazan T, 2010, IEEE T INFORM THEORY, V56, P6294, DOI 10.1109/TIT.2010.2079014
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Klaus A, 2006, INT C PATT RECOG, P15
   Kohli P., 2008, C COMPUTER VISION PA, P1
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Ladicky L, 2014, IEEE T PATTERN ANAL, V36, P1056, DOI 10.1109/TPAMI.2013.165
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lee S, 2015, IMAGE VISION COMPUT, V37, P1, DOI 10.1016/j.imavis.2015.01.003
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mozerov MG, 2015, IEEE T IMAGE PROCESS, V24, P1153, DOI 10.1109/TIP.2015.2395820
   Pal CJ, 2012, INT J COMPUT VISION, V99, P319, DOI 10.1007/s11263-010-0385-z
   Spangenberg R, 2014, IEEE INT VEH SYM, P190
   Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Taguchi Y., 2008, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1
   Wei Zeng, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563053
   Xu SB, 2015, IEEE T IMAGE PROCESS, V24, P2182, DOI 10.1109/TIP.2015.2416654
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yamaguchi K, 2013, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2013.243
   Yamaguchi K, 2012, LECT NOTES COMPUT SC, V7576, P45, DOI 10.1007/978-3-642-33715-4_4
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yao ZT, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ARTIFICIAL INTELLIGENCE (CAAI 2015), P1, DOI 10.1109/PESGM.2015.7285696
   Yedidia J.S., 2003, Exploring Artificial Intelligence in the New Millennium, V54, P276
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhang L, 2005, PROC CVPR IEEE, P288
NR 61
TC 12
Z9 15
U1 1
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 739
EP 750
DI 10.1016/j.jvcir.2016.08.022
PN B
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600028
DA 2024-07-18
ER

PT J
AU Liu, M
   Müller, K
   Raake, A
AF Liu, Mohan
   Mueller, Karsten
   Raake, Alexander
TI Efficient no-reference metric for sharpness mismatch artifact between
   stereoscopic views
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sharpness mismatch; Stereo 3D videos; No-reference; Quality assessment;
   Asymmetric blurriness
ID IMAGE QUALITY ASSESSMENT; VIDEO QUALITY; DISPARITY; BLUR
AB This paper analyzes sharpness mismatch between stereoscopic views. Sharpness mismatch is a special binocular mismatch and can occur through e.g. focus mismatch between stereoscopic cameras, errors in post-processing or asymmetric coding for low-bandwidth transmission, where one view is subsampled or transmitted at a much lower rate. Although blurred edges in one view can be suppressed by the corresponding sharper edges in the other view according to the binocular suppression phenomenon, sharpness mismatch can still be perceived and cause eye strain for viewers. Subjective studies were carried out with a test video dataset, in which the stereoscopic views are asymmetrically blurred by Gaussian low-pass filters since defocus-based effects of lens aberrations can be modeled as Gaussian blur. Also, an efficient novel automatic no-reference approach to measure the probability of sharpness mismatch is presented in this paper. The sharpness mismatch score is estimated by measuring width deviations of edge pairs in each "edge-significant" depth plane based on depth edges in both views. The probability of sharpness mismatch (PSM) is then calculated considering the perceptibility of edge width deviations considering absolute depth at which the edges occur. This PSM metric is evaluated using the test video dataset and blurriness dataset of LIVE 3D Phase II database. The experimental results show that the proposed metric outperforms the state-of-the-art stereo 3D quality metrics on analyzing sharpness mismatch between stereoscopic views. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liu, Mohan; Mueller, Karsten] Heirich Hertz Inst, Fraunhofer Inst Telecommun, Visual Commun & Analyt Dept, D-10587 Berlin, Germany.
   [Liu, Mohan] Tech Univ Berlin, Dept Teclecommun Syst, D-10623 Berlin, Germany.
   [Raake, Alexander] Ilmenau Univ Technol, Dept Audio Visual Technol, D-98693 Ilmenau, Germany.
C3 Fraunhofer Gesellschaft; Technical University of Berlin; Technische
   Universitat Ilmenau
RP Liu, M (corresponding author), Heirich Hertz Inst, Fraunhofer Inst Telecommun, Visual Commun & Analyt Dept, D-10587 Berlin, Germany.
EM mohan.liu@hhi.fraunhofer.com; karsten.mueller@hhi.fraunhofer.com;
   alexander.raake@tu-ilmenau.de
RI Raake, Alexander/R-7050-2017
OI Raake, Alexander/0000-0002-9357-1763
CR [Anonymous], SUBJ METH ASS STER 3
   [Anonymous], SUBJ VID QUAL ASS ME
   [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], GEN VIEW COND SUBJ A
   [Anonymous], 2010, P INT WORKSH VID PRO
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   BLAKE R, 1980, PERCEPTION, V9, P223, DOI 10.1068/p090223
   Bokov A, 2014, PROC SPIE, V9011, DOI 10.1117/12.2054330
   Breese BB, 1909, PSYCHOL REV, V16, P410, DOI 10.1037/h0075805
   Carnec M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P185
   Chen JY, 2014, IEEE INT CON MULTI
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Cheng M., 2012, 2012 8th International Symposium on Communication Systems, Networks Digital Signal Processing (CSNDSP), P1
   Craparo R., 2007, ENCY MEASUREMENT STA, V3, P889
   De Silva V, 2011, IEEE T MULTIMEDIA, V13, P498, DOI 10.1109/TMM.2011.2129500
   Delis S., 2013, P 20 IEEE INT C IM P, P15
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Fezza SA, 2014, IEEE IMAGE PROC, P2002, DOI 10.1109/ICIP.2014.7025401
   Georgeson MA, 2014, OPHTHAL PHYSL OPT, V34, P163, DOI 10.1111/opo.12108
   Gottschalk PG, 2005, ANAL BIOCHEM, V343, P54, DOI 10.1016/j.ab.2005.04.035
   Held RT, 2012, CURR BIOL, V22, P426, DOI 10.1016/j.cub.2012.01.033
   Howard Ian P, 1995, Binocular Vision and Stereopsis
   Kauff P., 2008, DELIVERABLE D 2 1 2
   Kim D, 2011, IEEE T CIRC SYST VID, V21, P231, DOI 10.1109/TCSVT.2011.2106275
   Kim T, 2014, IEEE T MULTIMEDIA, V16, P387, DOI 10.1109/TMM.2013.2292592
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Lee YY, 2008, J VISION, V8, DOI 10.1167/8.12.5
   Li ZY, 2014, INT CONF INFO SCI, P1, DOI 10.1109/ICIST.2014.6920318
   Md SK, 2015, IEEE SIGNAL PROC LET, V22, P1985, DOI 10.1109/LSP.2015.2449878
   Mendiburu Bernard., 2009, 3D Movie Making: Stereoscopic Digital Cinema From Scrip to Screen
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   PERKINS MG, 1992, IEEE T COMMUN, V40, P684, DOI 10.1109/26.141424
   Quan H., 2013, P SPIE HUMAN VISION, V8651, P1
   REICHELT S, 2010, P SPIE 3D DISPLAYS, P1
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   SAKAMOTO T, 1984, APPL OPTICS, V23, P1707, DOI 10.1364/AO.23.001707
   Shao F, 2015, IEEE T BROADCAST, V61, P154, DOI 10.1109/TBC.2015.2402491
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shimizu S., JCT3VK0071
   Tam WJ, 2011, IEEE T BROADCAST, V57, P335, DOI 10.1109/TBC.2011.2125070
   Tam WJ, 1998, P SOC PHOTO-OPT INS, V3295, P226, DOI 10.1117/12.307169
   TechNavio, 2014, GLOB 3D EN DEV MARK
   Thomas G., 2011, VISUAL ANAL HUMANS L
   Voronov A., 2012, 3D Imaging (IC3D), 2012 International Conference on, P1
   VQEG, OBJ PERC ASS VID QUA
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Werner M, 2014, IEEE T CONSUM ELECTR, V60, P66, DOI 10.1109/TCE.2014.6780927
   Yaqub M., 2013, COMMUN EYE HLTH J, V25, P1
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   You JY, 2010, SIGNALS COMMUN TECHN, P51, DOI 10.1007/978-3-642-12802-8_3
NR 56
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 132
EP 141
DI 10.1016/j.jvcir.2016.05.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900013
DA 2024-07-18
ER

PT J
AU Pun, CM
   Lin, C
AF Pun, Chi-Man
   Lin, Cong
TI A real-time detector for parked vehicles based on hybrid background
   modeling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive threshold; Background subtraction; Hybrid background model;
   Parked vehicle
ID FRAMEWORK; ALGORITHM
AB In this paper, a real-time detection system based on hybrid background modeling is proposed for detecting parked vehicles along the side of a road. The hybrid background model consists of three components: (1) a scene background model, (2) a computed restricted area map, and (3) a dynamic threshold curve for vehicles. By exploiting the motion information of normal activity in the scene, we propose a hybrid background model that determines the location of the road, estimates the roadside and generates the adaptive threshold of the vehicle size. The system triggers a notification when a large vehicle-like foreground object has been stationary for more than a pre-set number of video frames (or time). The proposed method is tested on the AVSS 2007 PV dataset. The results are satisfactory compared to other state-of-the-art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pun, Chi-Man; Lin, Cong] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo; yb17403@umac.mo
RI Pun, Chi Man/GRJ-3703-2022
OI Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX This research was supported in part by the Research Committee of the
   University of Macau (MYRG2015-00011-FST, MYRG2015-00012-FST) and the
   Science and Technology Development Fund of Macau SAR (008/2013/A1,
   093-2014-A2).
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Boragno S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P260, DOI 10.1109/AVSS.2007.4425320
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Brox T, 2009, PROC CVPR IEEE, P41, DOI 10.1109/CVPRW.2009.5206697
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Greenhalgh J, 2015, IEEE T INTELL TRANSP, V16, P1360, DOI 10.1109/TITS.2014.2363167
   Guler S, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P248, DOI 10.1109/AVSS.2007.4425318
   Horn B. K. P., 1981, Proceedings of the SPIE - The International Society for Optical Engineering, V281, P319, DOI 10.1117/12.965761
   Huwer S, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P37, DOI 10.1109/VS.2000.856856
   Kumar P, 2005, IEEE T INTELL TRANSP, V6, P43, DOI 10.1109/TITS.2004.838219
   Lee JT, 2009, IEEE T CIRC SYST VID, V19, P1014, DOI 10.1109/TCSVT.2009.2020249
   Lee JT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P254, DOI 10.1109/NEMS.2007.352020
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lin Z., 2009, AUGMENTED LAGRANGE M
   Liu Ce, 2009, THESIS
   Miles J. C., 2006, IET Proceedings Intelligent Transport Systems, V153, P183, DOI 10.1049/ip-its:20060014
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Quanfu F., 2014 11 IEEE INT C A, P223
   Raghavan A, 2012, IEEE INT C INTELL TR, P963, DOI 10.1109/ITSC.2012.6338742
   Shawe-Taylor J., 2006, IET Proceedings Intelligent Transport Systems, V153, P221, DOI 10.1049/ip-its:20060006
   Song L, 2014, IEEE T INTELL TRANSP, V15, P1273, DOI 10.1109/TITS.2014.2299403
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tian YL, 2005, PROC CVPR IEEE, P1182
   Töpfer D, 2015, IEEE T INTELL TRANSP, V16, P441, DOI 10.1109/TITS.2014.2354243
   Toh K.-C., 2009, PAC J OPTIM, V6, P15
   Venetianer PL, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P242, DOI 10.1109/AVSS.2007.4425317
   Xu JL, 2014, IEEE T INTELL TRANSP, V15, P2121, DOI 10.1109/TITS.2014.2310138
   Yuan X., 2009, OPT ONL
   Zhang W, 2012, IEEE T INTELL TRANSP, V13, P140, DOI 10.1109/TITS.2011.2165338
   Zhou HL, 2015, IEEE T INTELL TRANSP, V16, P297, DOI 10.1109/TITS.2014.2331353
NR 34
TC 7
Z9 7
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 82
EP 92
DI 10.1016/j.jvcir.2016.05.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900008
DA 2024-07-18
ER

PT J
AU Ou, B
   Li, XL
   Wang, JW
AF Ou, Bo
   Li, Xiaolong
   Wang, Jinwei
TI Improved PVO-based reversible data hiding: A new implementation based on
   multiple histograms modification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Pixel-value-ordering; Multiple histograms
   modification
ID IMAGE WATERMARKING; EXPANSION; PREDICTOR; FRAMEWORK
AB Pixel-value-ordering (PVO) technique is based on ranking the pixels within a block and often employed in reversible data hiding (RDH) to preserve the image fidelity. In this paper, an improved PVO-based algorithm is proposed to achieve a high-performance RDH. We formulate the PVO embedding as a problem of multiple histograms modification (MHM) and make two contributions. Firstly, the existing PVO-based algorithms are generalized in an MHM form and the systematic analysis of performance is offered by considering the parameter determination. Secondly, based on the new framework, an improved implementation of PVO embedding is proposed to adaptively determine the MHM manner by solving the distortion minimization of multiple histograms, which can handle different characteristics in image areas. Experimental results show the superiority of the new algorithm over the state-of-the-art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ou, Bo] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Xiaolong] Peking Univ, Inst Comp Sci & Technol, Beijing 100871, Peoples R China.
   [Wang, Jinwei] Nanjing Univ Informat Sci & Technol, Sch Comp Sci & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Peking University; Nanjing University of Information
   Science & Technology
RP Ou, B (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM oubo@hnu.edu.cn; lixiaolong@pku.edu.cn; wjwei@nuist.edu.cn
RI jinwei, wang/AAG-5700-2019; li, xiao/GSN-6181-2022; OU, BO/L-2212-2013;
   Li, xiaolong/GRS-9148-2022
OI Ou, Bo/0000-0001-6936-9955
FU National Science Foundation of China [61502160, 61232016, U1405254,
   61272421]; PAPD fund
FX This work is supported by the National Science Foundation of China (Nos.
   61502160, 61232016, U1405254, and 61272421) and the PAPD fund.
CR Caciula I., 2014, P IEEE ICASSP
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chung KL, 2010, IEEE T CIRC SYST VID, V20, P1643, DOI 10.1109/TCSVT.2010.2077577
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li X., IEEE T IMAGE PROCESS, V20
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B., SIGNAL PROCESS IMAGE, V29
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang J., J VIS COMMUN IMAGE R, V25
   Wang JX, 2013, IEEE INT WORKS INFOR, P203, DOI 10.1109/WIFS.2013.6707819
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 48
TC 72
Z9 75
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 328
EP 339
DI 10.1016/j.jvcir.2016.03.011
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100028
OA hybrid
DA 2024-07-18
ER

PT J
AU Shimada, A
   Nagahara, H
   Taniguchi, RI
AF Shimada, Atsushi
   Nagahara, Hajime
   Taniguchi, Rin-ichiro
TI Background light ray modeling for change detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Change detection; Light field; Background modeling; Spatio-temporal
   consistency
AB This paper is an extension of the work that was originally reported in Shimada et al. (2013). This paper proposes a change detection method based on spatio-temporal light ray consistency. The proposed method introduces light field sensing, which is used to generate an arbitrary in-focus plane. Change detection is performed in a surveillance scene, where the background region can be filtered out by an out-focusing process. This approach resolves a longstanding issue in background modeling-based object detection, which often suffers from false positives in the background regions. To realize this new change detection method, a new feature representation, called the local ray pattern (LRP), is introduced. The LRP evaluates the spatial consistency of the light rays, and this plays an important role in distinguishing whether the light rays come from the in-focus plane or elsewhere. A combination of the LRP and Gaussian mixture model (GMM)-based background modeling realizes change detection in the in-focus plane. Experimental results demonstrate the proposed method's effectiveness and its applicability to video surveillance. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Shimada, Atsushi] Kyushu Univ, Fac Arts & Sci, Fukuoka 8190395, Japan.
   [Nagahara, Hajime; Taniguchi, Rin-ichiro] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka 8190395, Japan.
C3 Kyushu University; Kyushu University
RP Shimada, A (corresponding author), Kyushu Univ, Fac Arts & Sci, Fukuoka 8190395, Japan.
EM atsushi@ait.kyushu-u.ac.jp
OI Shimada, Atsushi/0000-0002-3635-9336
FU JSPS [25540072]; Grants-in-Aid for Scientific Research [25540072]
   Funding Source: KAKEN
FX This work was partially supported by JSPS KAKENHI Grant-in-Aid for
   Challenging Exploratory Research No. 25540072.
CR Aizawa K, 2000, IEEE T CIRC SYST VID, V10, P323, DOI 10.1109/76.825731
   [Anonymous], INT C QUAL CONTR ART
   [Anonymous], IPSJ T COMPUT VISION
   [Anonymous], 2011, J SIGNAL INFOR PROCE, DOI DOI 10.4236/JSIP.2011.22010)
   Bouwmans T., 2011, RECENT PATENTS COMPU, V4
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Fernandez-Sanchez EJ, 2013, SENSORS-BASEL, V13, P8895, DOI 10.3390/s130708895
   Joshi N., 2007, P IEEE INT C COMP VI
   Kaneko S, 2002, PATTERN RECOGN, V35, P2223, DOI 10.1016/S0031-3203(01)00177-7
   Kawabata S, 2007, LECT NOTES COMPUT SC, V4843, P149
   Lim SN, 2005, PROC CVPR IEEE, P1071
   Lumsdaine A., 2008, Full resolution lightfield rendering
   Maeno K., 2013, INT C COMP PHOT
   Ng R., 2005, 2 CSTR, V2
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Shimada A., P IEEE INT C ADV VID
   Umeda K., 2009, P SPIE 3D IMAGING ME, V7239
   Wilburn B, 2002, PROC SPIE, V4674, P29
   Yoshinaga S, 2011, LECT NOTES COMPUT SC, V6495, P216, DOI 10.1007/978-3-642-19282-1_18
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 21
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 55
EP 64
DI 10.1016/j.jvcir.2016.02.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100006
DA 2024-07-18
ER

PT J
AU Zhao, N
   Xia, YJ
   Xu, C
   Shi, XM
   Liu, YC
AF Zhao, Na
   Xia, Yingjie
   Xu, Chao
   Shi, Xingmin
   Liu, Yuncai
TI APPOS: An adaptive partial occlusion segmentation method for multiple
   vehicles tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple vehicles tracking; Partial occlusion; Segmentation; Optical
   flow; Mean square error; Location; Foreground extraction; Occlusion
   detection
AB In traffic surveillance videos, it is common that the vehicles are occluded partially by each other. Such kind of occlusion situation is a challengeable task in multiple vehicles tracking. Various solutions in dealing with the occlusion for vehicles tracking have been proposed in many literatures. However, most of them are specialized on one tracking method and cannot flexibly adapt to the others. In this paper, we propose an adaptive partial occlusion segmentation method (APPOS) for multiple vehicles tracking. In this method, the occlusion detection process is firstly conducted to discover the occlusion. After that, the candidate regions of the respective occluded vehicles are roughly evaluated by the contour's optical flow. Finally, the line scanning which uses color contrast among regions is adopted to accurately locate the vehicles. We evaluate the effectiveness and accuracy of APPOS by the experiments on practical and simulating videos. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhao, Na; Xia, Yingjie; Xu, Chao; Shi, Xingmin; Liu, Yuncai] Hangzhou Normal Univ, Intelligent Transportat & Informat Secur Lab, Hangzhou, Zhejiang, Peoples R China.
   [Xia, Yingjie] Zhejiang Univ, Coll Comp Sci, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Hangzhou Normal University; Zhejiang University
RP Xia, YJ (corresponding author), Hangzhou Normal Univ, Intelligent Transportat & Informat Secur Lab, Hangzhou, Zhejiang, Peoples R China.
EM xiayingjie@zju.edu.cn
FU National Natural Science Foundation of China [61472113, 61304188];
   Zhejiang Provincial Natural Science Foundation of China [LZ13F020004,
   LR14F020003]
FX This research is supported in part by the following funds: National
   Natural Science Foundation of China under Grant Nos. 61472113 and
   61304188, and Zhejiang Provincial Natural Science Foundation of China
   under Grant Nos. LZ13F020004 and LR14F020003.
CR Ali A, 2006, SECOND INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGIES 2006, PROCEEDINGS, P174, DOI 10.1109/ICET.2006.335916
   [Anonymous], SIGNAL PROCESS
   Comaniciu D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P70, DOI 10.1109/ICIP.2000.899297
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Guha P., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P191, DOI 10.1109/AVSS.2011.6027318
   Harville M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P90, DOI 10.1109/ICIP.2001.958058
   Huang Y, 2005, PROC CVPR IEEE, P1051
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Khan A, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, P243
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Parrilla E, 2008, COMPUT MATH APPL, V56, P733, DOI 10.1016/j.camwa.2008.02.008
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Serby D, 2004, INT C PATT RECOG, P184, DOI 10.1109/ICPR.2004.1334091
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu MJ, 2010, COMPUT ELECTR ENG, V36, P927, DOI 10.1016/j.compeleceng.2009.12.013
   Xia Y., 2014, MULTIMEDIA SYST
   Xia YJ, 2015, NEUROCOMPUTING, V151, P700, DOI 10.1016/j.neucom.2014.05.091
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yan Zhou, 2006, Advances in Image and Video Technology. First Pacific Rim Symposium, PSIVT 2006. Proceedings (Lecture Notes in Computer Science Vol.4319), P474
   Zhang L, 2014, IEEE T CYBERN T CYB
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang Y., 2014, IEEE T IND ELECT T I
NR 25
TC 11
Z9 11
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2016
VL 37
SI SI
BP 25
EP 31
DI 10.1016/j.jvcir.2015.04.011
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DG0JS
UT WOS:000371751700004
DA 2024-07-18
ER

PT J
AU Azzam, R
   Kemouche, MS
   Aouf, N
   Richardson, M
AF Azzam, R.
   Kemouche, M. S.
   Aouf, N.
   Richardson, M.
TI Efficient visual object detection with spatially global Gaussian mixture
   models and uncertainties
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; SGGMM; RGB colour; Pixel uncertainty;
   Classification; Gaussian mixture; Modelling Real time
ID ROBUST; TRACKING; HUMANS
AB In this paper, we deal with the problem of visual detection of moving objects using innovative Gaussian mixture models (GMM). The proposed method, the Spatially Global Gaussian Mixture Model (SGGMM) uses RGB and pixel uncertainty for background modelling. The SGGMM with colours only is used for scenes with moderate illumination changes. When combined with pixel uncertainty statistics, the method can deal efficiently with dynamic backgrounds and scene backgrounds with fast change in luminosity. Experimental evaluation in indoor and outdoor environments shows the performance of the foreground segmentation with the proposed SGGMM model using solely RGB colour or in combination with pixel uncertainties. These experimental scenarios take into account changes in the background within the scene. They are also used to compare the proposed technique with other state-of-the-art segmentation approaches in terms of accuracy and execution time performance. Further, our solution is implemented and tested in embedded camera sensor network nodes. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Azzam, R.; Aouf, N.; Richardson, M.] Cranfield Univ, Ctr Elect Warfare, Swindon SN6 8LA, Wilts, England.
   [Kemouche, M. S.] Mil Polytech Sch, Dept Elect, Bordj El Bahri, Algeria.
C3 Cranfield University; Ecole Military Polytechnic
RP Azzam, R (corresponding author), Cranfield Univ, Ctr Elect Warfare, Swindon SN6 8LA, Wilts, England.
RI Sadek, Kemmouche Mohamed/AAY-6557-2020
OI Aouf, Nabil/0000-0001-9291-4077; Richardson, Mark/0000-0003-2694-5486;
   Kemmouche, Mohamed Sadek/0000-0003-0933-1028
CR [Anonymous], IEEE WORKSH MOT VID
   [Anonymous], 2011, P IEEE 11 INT C DAT
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Chen P., 2008, ACM IEEE C DISTR SMA
   Cheng FC, 2011, IEEE T SYST MAN CY C, V41, P589, DOI 10.1109/TSMCC.2010.2092425
   DICKINSON P, 2005, P IEEE WORKSH ADV VI, P64
   Durucan E, 2001, P IEEE, V89, P1368, DOI 10.1109/5.959336
   Elgammal A., 2000, COMPUTER VISION
   Finlayson G. D., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P13
   FRIEDMAN N, 1997, P 13 C UNC ART INT U
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Gutchesst D., 2001, IEEE INT C COMP VIS
   Han B., 2004, P AS C COMP VIS
   Hayman E, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P67
   Huang SC, 2014, IEEE T CYBERNETICS, V44, P114, DOI 10.1109/TCYB.2013.2248057
   Huang SC, 2013, IEEE T NEUR NET LEAR, V24, P1920, DOI 10.1109/TNNLS.2013.2270314
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   *INT CORP, 2004, INT PXA270 PROC EL M
   Javed O, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P22, DOI 10.1109/MOTION.2002.1182209
   Palorno EJ, 2009, LECT NOTES COMPUT SC, V5863, P743, DOI 10.1007/978-3-642-10677-4_85
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Kanazawa Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCV.2001.937640
   Kemouche M., 2010, 13 C INF FUS FUSION, P1
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Li LY, 2002, IEEE T IMAGE PROCESS, V11, P105, DOI 10.1109/83.982818
   Liu SC, 1998, IEEE T IMAGE PROCESS, V7, P1258, DOI 10.1109/83.709658
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Marchant JA, 2000, J OPT SOC AM A, V17, P1952, DOI 10.1364/JOSAA.17.001952
   Mittal A., 2004, COMP VIS PATT REC C
   Nickels K, 2002, IMAGE VISION COMPUT, V20, P47, DOI 10.1016/S0262-8856(01)00076-2
   O.T. Inc, 2006, OV9655 COL CMOS SXGA
   Ohta N, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P481, DOI 10.1109/ICCV.2001.937664
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   PORIKLI F, 2005, P 3 ACM INT WORKSH V, P55, DOI DOI 10.1145/1099396.1099407
   Raja Y., 1998, P ASIAN CONFERENECE, P607, DOI DOI 10.1007/3-540-63930-6_173
   Rowe S., 1995, P BRIT MACH VIS C, P421
   Sedky M, 2014, IEEE COMPUT SOC CONF, P405, DOI 10.1109/CVPRW.2014.65
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Shoaib M, 2009, INT CONF ACOUST SPEE, P773, DOI 10.1109/ICASSP.2009.4959698
   Singh A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P168, DOI 10.1109/ICCV.1990.139516
   Skifstad K., 1989, COMPUT VIS GRAPH IMA, V45, P400
   St-Charles PL, 2014, IEEE WINT CONF APPL, P509, DOI 10.1109/WACV.2014.6836059
   Statella T., 2008, WT PEC MEM REM SENS, P1
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Wang NY, 2012, LECT NOTES COMPUT SC, V7578, P126, DOI 10.1007/978-3-642-33786-4_10
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xie BL, 2004, IMAGE VISION COMPUT, V22, P117, DOI 10.1016/j.imavis.2003.07.003
   Xu M., 2001, P BRIT MACHINE VISIO, P163
   Zang Q, 2004, INT C PATT RECOG, P90, DOI 10.1109/ICPR.2004.1334047
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 56
TC 15
Z9 16
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 90
EP 106
DI 10.1016/j.jvcir.2015.11.009
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200008
DA 2024-07-18
ER

PT J
AU Karygianni, S
   Frossard, P
AF Karygianni, Sofia
   Frossard, Pascal
TI Sparse molecular image representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparsity; Structure; Linear combinations; Molecules; Prototypes;
   Deformations; Pools; Structural similarity
ID SELECTION; RECOVERY; SIGNALS
AB Sparsity-based models have proven to be very effective in most image processing applications. The notion of sparsity has recently been extended to structured sparsity models where not only the number of components but also their support is important. This paper goes one step further and proposes a new model where signals are composed of a small number of molecules, which are each linear combinations of a few elementary functions in a dictionary. Our model takes into account the energy on the signal components in addition to their support. We study our prior in detail and propose a novel algorithm for sparse coding that permits the appearance of signal dependent versions of the molecules. Our experiments prove the benefits of the new image model in various restoration tasks and confirm the effectiveness of priors that extend sparsity in flexible ways especially in case of inverse problems with low quality data. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Karygianni, Sofia; Frossard, Pascal] Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Karygianni, S (corresponding author), Ecole Polytech Fed Lausanne, Signal Proc Lab LTS4, CH-1015 Lausanne, Switzerland.
EM sofia.karygianni@epfl.ch; pascal.frossard@epfl.ch
RI Frossard, Pascal/AAF-2268-2019
FU Swiss National Science Foundation (SNSF) [200021_143999]; Swiss National
   Science Foundation (SNF) [200021_143999] Funding Source: Swiss National
   Science Foundation (SNF)
FX We would like to thank Prof. Christine Guillemot for the fruitful
   discussions and comments. This work was been partially funded by the
   Swiss National Science Foundation (SNSF) under Grant 200021_143999.
CR [Anonymous], MNIST DATABASE HANDW
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Cai TT, 2010, IEEE T INFORM THEORY, V56, P3516, DOI 10.1109/TIT.2010.2048506
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Cevher V., 2008, NIPS, P257
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Daudet L, 2006, IEEE T AUDIO SPEECH, V14, P1808, DOI 10.1109/TSA.2005.858540
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Garrigues P., 2008, Advances in Neural Information Processing Systems, P505
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Jacob L., 2009, P 26 ANN INT C MACH, P433, DOI DOI 10.1145/1553374.1553431
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jenatton R, 2011, J MACH LEARN RES, V12, P2777
   Karygianni Sofia, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3533, DOI 10.1109/ICASSP.2014.6854258
   Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605, DOI 10.1109/CVPRW.2009.5206545
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   Lee H., 2009, P 26 ANN INT C MACHI, V382, P609, DOI 10.1145/1553374.1553453
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Peleg T, 2012, IEEE T SIGNAL PROCES, V60, P2286, DOI 10.1109/TSP.2012.2188520
   Rolfe J. T., DISCRIMINATIVE RECUR
   Rubinstein R, 2010, IEEE T SIGNAL PROCES, V58, P1553, DOI 10.1109/TSP.2009.2036477
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhao P, 2009, ANN STAT, V37, P3468, DOI 10.1214/07-AOS584
NR 31
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 213
EP 228
DI 10.1016/j.jvcir.2016.01.013
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200018
OA Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, QP
   Shao, F
   Jiang, GY
   Yu, M
   Peng, ZJ
AF Jiang, Qiuping
   Shao, Feng
   Jiang, Gangyi
   Yu, Mei
   Peng, Zongju
TI Supervised dictionary learning for blind image quality assessment using
   quality-constraint sparse coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image quality assessment (BIQA); Supervised dictionary learning;
   Sparse coding; Sparse representation; Quality-constraint; Opinion free;
   Gabor; Histogram of Oriented Gradient (HOG)
ID NO-REFERENCE IMAGE; K-SVD; REPRESENTATION; RECOGNITION; STATISTICS
AB Blind image quality assessment (BIQA) involves predicting the perceptual quality of distorted images without using their corresponding reference images as benchmark. Especially, it is desirable and meaningful to design effective opinion-free BIQA (OF-BIQA) model to predict image quality without depending on human subjective score. Toward this end, we propose a supervised dictionary learning framework for OF-BIQA using quality-constraint sparse coding. The prominent advantage of the proposed model is that "ground truth" quality scores derived from existing full-reference IQA (FR-IQA) metrics are incorporated into the traditional dictionary learning framework so that a quality-aware sparse model can be learnt. Since the goal of BIQA is to predict the quality score, the introduction of quality information into dictionary learning can be regard as a supervised dictionary learning framework. In the detailed implementation, a quality-aware regularization term is added to the traditional dictionary learning formulation, such that a feature-aware dictionary and a quality-aware dictionary can be learned jointly. Especially, these two dictionaries share the same sparse coefficients, so that the reconstruction errors from the image feature vectors and quality score vectors are both minimized. Once the feature-aware and quality-aware dictionaries are jointly learned, given a testing sample, we first abstract its feature vector and then compute the corresponding sparse coefficients w.r.t. the learnt feature-aware dictionary, finally its quality score can be directly reconstructed based on the learnt quality-aware dictionary and the estimated sparse coefficients w.r.t. the learnt feature-aware dictionary. The reconstructed quality score is expected to well approximate to the "ground truth" quality score. Thorough validation experiments on three publicly available IQA benchmark databases demonstrate the promising performance of the proposed OF-BIQA model both on the prediction accuracy and generalization capability. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jiang, Qiuping; Shao, Feng; Jiang, Gangyi; Yu, Mei; Peng, Zongju] Ningbo Univ, Fac Informat Sci & Engn, 818 Fenghua Rd, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, 818 Fenghua Rd, Ningbo 315211, Zhejiang, Peoples R China.
EM shaofeng@nbu.edu.cn
RI jiang, gang/KII-8233-2024; Jiang, Qiuping/AAL-8273-2020; Peng,
   Zongju/AAA-2914-2020
OI Peng, Zongju/0000-0001-8286-538X
FU Natural Science Foundation of China [61271021, 61271270, U1301257]; K.C.
   Wong Magna Fund in Ningbo University
FX This work was supported by the Natural Science Foundation of China
   (Grant nos. 61271021, 61271270, U1301257). It was also sponsored by K.C.
   Wong Magna Fund in Ningbo University.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], ADV NEUR INF PROC SY
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chang HW, 2013, IEEE T IMAGE PROCESS, V22, P4007, DOI 10.1109/TIP.2013.2266579
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   Gao F, 2015, IEEE T NEUR NET LEAR, V26, P2275, DOI 10.1109/TNNLS.2014.2377181
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Guha T, 2014, SIGNAL PROCESS-IMAGE, V29, P1138, DOI 10.1016/j.image.2014.09.010
   Gunasekar S, 2014, IEEE T INF FOREN SEC, V9, P2119, DOI 10.1109/TIFS.2014.2360579
   He LH, 2012, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2012.6247795
   Hemami SS, 2010, SIGNAL PROCESS-IMAGE, V25, P469, DOI 10.1016/j.image.2010.05.009
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kruizinga P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P142, DOI 10.1109/ICIAP.1999.797585
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HT, 2010, IEEE T CIRC SYST VID, V20, P529, DOI 10.1109/TCSVT.2009.2035848
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Marial J., 2009, P IEEE INT C MACH LE
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2012, IEEE SIGNAL PROC LET, V19, P75, DOI 10.1109/LSP.2011.2179293
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N., 2013, P EUR WORKSH VIS INF
   Ren Z., 2012, P IEEE INT C MULT EX
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2015, IEEE T BROADCAST, V61, P154, DOI 10.1109/TBC.2015.2402491
   Sheikh H., 2005, P IEEE INT C IM PROC
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xue W., 2013, P IEEE INT C COMP VI
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Ye P., 2012, P IEEE INT C COMP VI
   Ye P., 2014, P IEEE INT C COMP VI
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 50
TC 25
Z9 28
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 123
EP 133
DI 10.1016/j.jvcir.2015.09.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700013
DA 2024-07-18
ER

PT J
AU Wu, JS
   Tai, KH
   Li, GL
   Chen, MJ
   Tang, YH
AF Wu, Jian-Sheng
   Tai, Kuang-Han
   Li, Gwo-Long
   Chen, Mei-Juan
   Tang, Yung-Hsiang
TI Effective computation-aware algorithm by inter-layer motion analysis for
   scalable video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable video coding; Computation-aware; Mode decision; Motion vector;
   Rate-distortion cost; Base layer; Enhancement layer; Inter-layer; Search
   range
ID MODE DECISION ALGORITHM; STANDARD
AB Scalable video coding incorporated with computation-aware ability achieves quality as well as being computation scalable. This paper presents a computation-aware algorithm for scalable video coding with spatial/quality scalability aiming for the best trade-off between rate distortion performance and computational consumption. We first observe and analyze and then establish a model for the motion vector difference relationship between the scalable base and enhancement layers. By using the modeling results, a linear algorithm for computation distribution is thus proposed to allocate the computation for each macroblock in the enhancement layer. In addition, the rate distortion costs of the base layer are also taken into account for the computation allocation process in order to further improve the coding performance. The simulation results demonstrate that our proposed computation-aware algorithm not only accomplishes better rate distortion performance than other works under the same computational constraints, but also achieves less computation necessities. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wu, Jian-Sheng; Tai, Kuang-Han; Chen, Mei-Juan; Tang, Yung-Hsiang] Natl Dong Hwa Univ, Dept Elect Engn, Hualien 97401, Taiwan.
   [Li, Gwo-Long] Novatek Microelect Corp, Hsinchu, Taiwan.
C3 National Dong Hwa University
RP Chen, MJ (corresponding author), Natl Dong Hwa Univ, Dept Elect Engn, Hualien 97401, Taiwan.
EM cmj@mail.ndhu.edu.tw
RI Wu, Jian/AAU-5221-2020; Tai, Kuang-Han/G-6768-2015; Wu,
   Jian/AAU-5221-2020
OI Wu, Jian/0000-0001-9933-7364; Tai, Kuang-Han/0000-0002-6214-0813; Wu,
   Jian/0000-0002-3394-1507; Chen, Mei-Juan/0000-0003-3382-8296
FU Ministry of Science and Technology, Taiwan, R.O.C. [NSC
   99-2221-E-259-019-MY3, NSC 102-2221-E-259-022-MY3]
FX This work was supported by Ministry of Science and Technology, Taiwan,
   R.O.C. under Grant NSC 99-2221-E-259-019-MY3 and Grant NSC
   102-2221-E-259-022-MY3.
CR [Anonymous], 2001, Q6SG16 ITUT
   Bjontegaard G., 2008, SG16Q6 ITUT
   Chen CY, 2006, IEEE T MULTIMEDIA, V8, P698, DOI 10.1109/TMM.2006.876296
   Kim TJ, 2011, IEEE T CONSUM ELECTR, V57, P247, DOI 10.1109/TCE.2011.5735509
   Lee B, 2011, IEEE T CIRC SYST VID, V21, P88, DOI 10.1109/TCSVT.2011.2106273
   Leuvun S.V., 2011, IEEE T CONSUM ELECTR, V57, P827
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1533, DOI 10.1109/TCSVT.2010.2077773
   Park CS, 2009, IEEE T CONSUM ELECTR, V55, P235, DOI 10.1109/TCE.2009.4814440
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sun X., 2011, P 7 INT C INT INF HI, P278
   Tai PL, 2003, IEEE T CIRC SYST VID, V13, P901, DOI 10.1109/TCSVT.2003.816510
   Tang X.L., 2010, P INT C GREEN CIRC S, P516
   Tsai CY, 2010, J VIS COMMUN IMAGE R, V21, P917, DOI 10.1016/j.jvcir.2010.09.001
   Wang PC, 2010, ETRI J, V32, P577, DOI 10.4218/etrij.10.0109.0622
   Wang TH, 2011, IEEE T CONSUM ELECTR, V57, P1194, DOI 10.1109/TCE.2011.6018874
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu J.S., 2012, P IEEE INT C SIGN PR, P78
   Yeh CH, 2012, J VIS COMMUN IMAGE R, V23, P1167, DOI 10.1016/j.jvcir.2012.08.001
   Yeh CH, 2010, IEEE T CIRC SYST VID, V20, P563, DOI 10.1109/TCSVT.2010.2041825
   Zheng LW, 2013, ETRI J, V35, P469, DOI 10.4218/etrij.13.0112.0421
NR 21
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 107
EP 119
DI 10.1016/j.jvcir.2015.07.015
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300009
DA 2024-07-18
ER

PT J
AU Peter, P
   Schmaltz, C
   Mach, N
   Mainberger, M
   Weickert, J
AF Peter, Pascal
   Schmaltz, Christian
   Mach, Nicolas
   Mainberger, Markus
   Weickert, Joachim
TI Beyond pure quality: Progressive modes, region of interest coding, and
   real time video decoding for PDE-based image compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Partial differential equation; Diffusion; EED; Progressive mode; Region
   of interest coding; Image compression; Real time; Video decoding
AB Compared to transform-based image compression methods such as JPEG2000, approaches based on partial-differential equations (PDEs) are in a proof-of-concept stage. Nevertheless, R-EED, a codec employing edge-enhancing anisotropic diffusion (EED) and rectangular subdivision, can surpass JPEG2000 quality-wise. However, today's requirements for compression algorithms go beyond pure compression performance. Codecs must also fulfil the feature requirements of specific applications such as online media or medical imaging. We propose three such features for the R-EED codec. By reordering grey values and exploiting the subdivision scheme, we incorporate a progressive mode into R-EED that can outperform JPEG and JPEG2000. Additionally, we show that rectangular subdivision is well-suited for region of interest coding and adapt the quality of image parts according to their importance. Finally, we propose a real-time video player that demonstrates how R-EED-based decoding can be performed efficiently. All of these extensions are compatible with each other and can be used simultaneously. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Peter, Pascal; Schmaltz, Christian; Mach, Nicolas; Mainberger, Markus; Weickert, Joachim] Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, D-66041 Saarbrucken, Germany.
C3 Saarland University
RP Peter, P (corresponding author), Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, Campus E1-7, D-66041 Saarbrucken, Germany.
EM peter@mia.uni-saarland.de; schmaltz@mia.uni-saarland.de;
   mach@mia.uni-saarland.de; mainberger@mia.uni-saarland.de;
   weickert@mia.uni-saarland.de
RI mach, nicolas/AAZ-5302-2021
CR [Anonymous], 2000, JPEG 2000 IMAGE COMP
   [Anonymous], 1985, Multi-grid methods and applications
   [Anonymous], 1997, RFC 2083
   Bae E, 2010, LECT NOTES COMPUT SC, V5862, P1, DOI 10.1007/978-3-642-11620-9_1
   Baum K., 2013, THESIS SAARLAND U SA
   Bornemann FA, 1996, NUMER MATH, V75, P135, DOI 10.1007/s002110050234
   BRANDT A, 1977, MATH COMPUT, V31, P333, DOI 10.1090/S0025-5718-1977-0431719-X
   CARLSSON S, 1988, SIGNAL PROCESS, V15, P57, DOI 10.1016/0165-1684(88)90028-X
   Chan TF, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICIP.2000.899404
   CompuServe Incorporated Graphics Interchange Format (tm), 1987, GRAPH INT FORM TM ST
   Desai U. Y., 1996, 1584 MIT ART INT LAB
   Elder JH, 1999, INT J COMPUT VISION, V34, P97, DOI 10.1023/A:1008183703117
   Galic I, 2005, LECT NOTES COMPUT SC, V3752, P37
   Galíc I, 2008, J MATH IMAGING VIS, V31, P255, DOI 10.1007/s10851-008-0087-0
   Gao Q., 2008, THESIS SAARLAND U SA
   Gautier J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P81, DOI 10.1109/PCS.2012.6213291
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Grewenig S, 2010, LECT NOTES COMPUT SC, V6376, P533
   Hoffmann S., 2013, LECT NOTES COMPUTER, P319, DOI [10.1007/978-3-642-38267-3_27, DOI 10.1007/978-3-642-38267-3]
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   HUMMEL R, 1989, IEEE T ACOUST SPEECH, V37, P2111, DOI 10.1109/29.45555
   Kaur N., 2011, IJCA SPEC ISSUE COMP, V1, P35
   Kostler H., 2007, 0711 U ERL NURNB LEH, V10
   Li Y., 2012, ENV SYST RES, V1, P1, DOI DOI 10.1186/2193-2697-1-7
   Lillholm M, 2003, INT J COMPUT VISION, V52, P73, DOI 10.1023/A:1022995822531
   Liu D, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1443
   Mahoney M. V, 2005, Tech. Rep. CS-2005-16
   Mainberger M, 2012, LECT NOTES COMPUT SC, V6667, P26, DOI 10.1007/978-3-642-24785-9_3
   Murnau F. W., 1922, NOSFERATU SYMPHONE G
   Pawadshetty J. S., 2013, INT J ENG RES APPL, V3, P1184
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Peter P, 2014, IEEE IMAGE PROC, P4822, DOI 10.1109/ICIP.2014.7025977
   RISSANEN JJ, 1976, IBM J RES DEV, V20, P198, DOI 10.1147/rd.203.0198
   Schmaltz C, 2014, INT J COMPUT VISION, V108, P222, DOI 10.1007/s11263-014-0702-z
   Schmaltz C, 2013, PICT COD SYMP, P233, DOI 10.1109/PCS.2013.6737726
   Schmaltz C, 2009, LECT NOTES COMPUT SC, V5748, P452, DOI 10.1007/978-3-642-03798-6_46
   Solé A, 2004, IEEE T IMAGE PROCESS, V13, P1245, DOI 10.1109/TIP.2004.832864
   Varga RS., 1962, Matrix Iterative Analysis
   Weickert J, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P315, DOI 10.1007/3-540-31272-2_19
   Weickert J., 1996, COMPUTING WIEN SUPPL, V11, P221, DOI [DOI 10.1007/978-3-7091-6586-713, 10.1007/978-3-7091-6586-7_13, DOI 10.1007/978-3-7091-6586-7_13]
   Weickert J., 2013, LECT NOTES COMPUTER, V7893, P390, DOI [10.1007/978-3-642-38267-3_32, DOI 10.1007/978-3-642-38267-3_32]
NR 41
TC 15
Z9 15
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 253
EP 265
DI 10.1016/j.jvcir.2015.06.017
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600023
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
AF Al-Otum, Hazem Munawer
TI A novel set of image morphological operators using a modified vector
   distance measure with color pixel classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mathematical morphology; Multivariate ordering; Color image
   segmentation; Color image morphology; Color distance classification; HSV
   color space; Color skeleton
ID MULTIVARIATE MATHEMATICAL MORPHOLOGY
AB A novel set of color image morphological operators is proposed and is based on using a modified vector distance measure with an efficient preprocessing color pixel classification procedure. The input color pixels are classified into different categories based on the characteristics of the human color perception properties. Next, the color distance is calculated for each input color pixel based on its category, and, a combined technique is used to obtain color morphological operators. The main contributions of this work can be summarized in the following: (a) designing of novel vector-based morphological operators that can be used with color images and (b) the designed operators were extended to be implemented for developing vector-based tools for noise suppression, texture analysis, shape analysis, edge detection and skeletonization. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Al-Otum, Hazem Munawer] Jordan Univ Sci & Technol, Fac Engn, EE Dept, Amman, Jordan.
   [Al-Otum, Hazem Munawer] Al Imam Muhammad Bin Saud Islamic Univ, Coll Engn, EE Dept, Riyadh, Saudi Arabia.
C3 Jordan University of Science & Technology; Imam Mohammad Ibn Saud
   Islamic University (IMSIU)
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, Fac Engn, EE Dept, Amman, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Adreadis I., 2000, P EUSIPCO 2000 TAMP, VIV, P2389
   Al-Otum HM, 2004, OPT ENG, V43, P1280, DOI 10.1117/1.1689974
   Al-Otum HM, 2003, OPT ENG, V42, P2595, DOI 10.1117/1.1594727
   Angulo J, 2007, COMPUT VIS IMAGE UND, V107, P56, DOI 10.1016/j.cviu.2006.11.008
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], INT C PATT REC
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   Aptoula E, 2009, IEEE T IMAGE PROCESS, V18, P2505, DOI 10.1109/TIP.2009.2027363
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   Caliman A, 2014, PATTERN RECOGN, V47, P721, DOI 10.1016/j.patcog.2013.08.021
   CHANUSSOT J, 1998, THESIS U SAVOIE
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O
   Herodotou N., 1998, VIS COMM IM PROC 98, V3309
   Ledoux A, 2012, TRAIT SIGNAL, V29, P65, DOI 10.3166/TS.29.65-82
   Lei T, 2013, IEEE IMAGE PROC, P3031, DOI 10.1109/ICIP.2013.6738624
   Louverdis G, 2002, PATTERN RECOGN, V35, P1733, DOI 10.1016/S0031-3203(01)00166-2
   Matheron G., 1975, Random sets and integral geometry
   Sartor LJ, 2001, J ELECTRON IMAGING, V10, P548, DOI 10.1117/1.1353199
   Sternberg S.R., 1986, GRAPHICS IMAGE PROCE, V35, P333, DOI DOI 10.1016/0734-189X(86)90004-6
   Velasco-Forero S, 2012, IEEE J-STSP, V6, P753, DOI 10.1109/JSTSP.2012.2211336
NR 21
TC 6
Z9 6
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 46
EP 63
DI 10.1016/j.jvcir.2015.02.010
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900005
DA 2024-07-18
ER

PT J
AU Zhang, LB
   Chen, J
   Zhu, T
AF Zhang, Libao
   Chen, Jie
   Zhu, Tong
TI Image denoising based on iterative generalized cross-validation and fast
   translation invariant
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Image denoising; Wavelet shrinkage; Integer wavelet
   transform; Generalized cross-validation; Translation invariant;
   Pseudo-Gibbs phenomena; Recursion strategy
ID TRANSFORM
AB Wavelet shrinkage is a promising method in image denoising, the key factor of which lies in the threshold selection. A fast and effective wavelet denoising method, called Iterative Generalized Cross-Validation and Fast Translation Invariant (IGCV-FTI) is proposed, which reduces the computation cost of the standard Generalized Cross-Validation (GCV) method and efficiently suppresses the Pseudo-Gibbs phenomena with an extra gain of 1-1.87 dB in PSNR compared with GCV. In the proposed approach, we establish a novel functional relation between the GCV results of two neighboring thresholds based on integer wavelet transform, and combine it with threshold-search interval optimization. As a result, the proposed IGCV reduces the time complexity of original GCV algorithm by two orders of magnitude. In addition, a recursion strategy is applied to expedite the translation invariant. The high efficiency and proficient capacity to remove noise make IGCV-FTI a good choice for image denoising. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Libao; Chen, Jie; Zhu, Tong] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Zhang, LB (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
EM libaozhang@bnu.edu.cn
FU National Natural Science Foundation of China [60602035, 61071103];
   Fundamental Research Funds for the Central Universities [2012LYB50]
FX This work was sponsored by the National Natural Science Foundation of
   China (Nos. 60602035 and 61071103) and Fundamental Research Funds for
   the Central Universities (2012LYB50).
CR [Anonymous], J IMAGE GRAPH
   [Anonymous], WAVELETS STAT
   [Anonymous], IEEE CROSS STRAIT QU
   [Anonymous], PREPRINT
   [Anonymous], TRANLATION INVARIANT
   [Anonymous], 2012 24 INT C MICR I
   [Anonymous], INT S MULT IM PROC P
   [Anonymous], WAVELET TRANSFORM GR
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   Choi H, 2004, IEEE SIGNAL PROC LET, V11, P717, DOI 10.1109/LSP.2004.833493
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dobe M, 2013, FAM COMMUNITY HEALTH, V36, P172, DOI 10.1097/FCH.0b013e318282ac42
   Hancock PA, 2006, COMPUT GEOSCI-UK, V32, P834, DOI 10.1016/j.cageo.2005.10.010
   Jansen M, 1997, SIGNAL PROCESS, V56, P33, DOI 10.1016/S0165-1684(97)83621-3
   Li W, 2011, SIGNAL PROCESS-IMAGE, V26, P250, DOI 10.1016/j.image.2011.04.005
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Sun J., 2008, CVPR 2008 IEEE C COM, P1
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Weiss Y., 2007, CVPR 07 IEEE C COMPU, P1
NR 24
TC 9
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 1
EP 14
DI 10.1016/j.jvcir.2015.01.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000001
DA 2024-07-18
ER

PT J
AU Li, MD
   Chen, ZZ
   Tan, PH
   Sun, SM
   Tan, YP
AF Li, Maodong
   Chen, Zhenzhong
   Tan, Peng Hui
   Sun, Sumei
   Tan, Yap-Peng
TI QoE-aware video streaming for SVC over multiuser MIMO-OFDM systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE QoE; Video quality assessment; SVC; Scalability; Video streaming; Rate
   adaptation; Resource allocation; MU MIMO-OFDM systems
ID PERCEPTUAL QUALITY ASSESSMENT; RESOURCE-ALLOCATION; PERFORMANCE
   ANALYSIS; WIRELESS SYSTEMS; EXPERIENCE; TRANSMISSION; SELECTION
AB We propose a QoE-aware video streaming solution to maximize multiuser QoE for Scalable Video Coding (SVC) streaming over multiuser (MU) Multiple-Input Multiple-Output (MIMO)-Orthogonal Frequency Division Multiplexing (OFDM) systems. We achieve it by integrating novel QoE-aware video adaptation (QoEVA) and QoE-aware resource allocation (QoERA) schemes. We first study QoEVA of SVC via a subjective video quality assessment database and derive QoE-optimized scalability adaptation tracks. A rate-QoE model is then constructed to approximate the track and is employed to design QoERA. By proving the NP-hardness of the QoERA problem, we propose an adaptive solution where resource block assignment, power allocation and modulation selection are jointly optimized to enhance multiuser QoE. Experimental results show that the proposed QoEVA significantly performs better than the conventional video adaptation schemes and the proposed QoERA achieves much better user experience when compared to state-of-the-art solutions. Our solution can be employed for both pre-coded and live video streaming. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Li, Maodong; Tan, Peng Hui; Sun, Sumei] Agcy Sci Technol & Res, Inst Infocomm Res, Singapore, Singapore.
   [Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan, Peoples R China.
   [Tan, Yap-Peng] Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Wuhan University; Nanyang Technological
   University
RP Li, MD (corresponding author), Agcy Sci Technol & Res, Inst Infocomm Res, Singapore, Singapore.
EM limd@i2r.a-star.edu.sg; zzchen@whu.edu.cn; phtan@i2r.a-star.edu.sg;
   sunsm@i2r.a-star.edu.sg; eyptan@ntu.edu.sg
RI Chen, Zhenzhong/C-2529-2015; Tan, Peng/HGD-6812-2022; Tan,
   Yap-Peng/A-5158-2011; Sun, Sumei/F-5376-2018; Tan, Peng/HJI-1411-2023
OI Tan, Peng/0000-0001-9563-9744
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   [Anonymous], 2007, NEW APPENDIX 1 DEFIN
   [Anonymous], 2006, MEAN OP SCOR MOS TER
   [Anonymous], 2011, JSVM SOFTWARE MANUAL
   Bartolomé D, 2007, IEEE T COMMUN, V55, P1577, DOI 10.1109/TCOMM.2007.902567
   Brandt J, 2010, IEEE 14 INT S CONS E, P1
   Brooks P, 2010, IEEE NETWORK, V24, P8, DOI 10.1109/MNET.2010.5430138
   Dimic G, 2005, IEEE T SIGNAL PROCES, V53, P3857, DOI 10.1109/TSP.2005.855401
   Fasano A, 2002, ISIT: 2002 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P243, DOI 10.1109/ISIT.2002.1023515
   Fiedler M, 2010, IEEE NETWORK, V24, P36, DOI 10.1109/MNET.2010.5430142
   Hayashi S, 2009, IEEE T INFORM THEORY, V55, P1153, DOI 10.1109/TIT.2008.2011433
   Institute of Electrical and Electronics Engineers, 802162004 IEEE
   International Telecommunication Union, 2002, METH SUBJ ASS QUAL T
   International Telecommunication Union, 1994, QUAL TEL SERV CONC M
   JAIN R, TR301 DEC
   Ji X, 2009, IEEE T CIRC SYST VID, V19, P1549, DOI 10.1109/TCSVT.2009.2026812
   Jiang M, 2007, P IEEE, V95, P1430, DOI 10.1109/JPROC.2007.898869
   Joseph V, 2012, IEEE INFOCOM SER, P567, DOI 10.1109/INFCOM.2012.6195799
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Lee J, 2006, IEEE T COMMUN, V54, P1170, DOI 10.1109/TCOMM.2006.877955
   Li M., 2012, IEEE VISUAL COMMUN I
   Li M., 2011, P IEEE RAD FREQ INT, P1, DOI DOI 10.1109/RFIC.2011.5940608
   Li MD, 2013, J VIS COMMUN IMAGE R, V24, P509, DOI 10.1016/j.jvcir.2013.03.006
   Liu YW, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348821
   Mansour H, 2009, IEEE T MULTIMEDIA, V11, P1478, DOI 10.1109/TMM.2009.2032682
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   P ITU-T RECOMMENDATION, 1999, SUBJ VID QUAL ASS ME
   ParandehGheibi A, 2011, IEEE J SEL AREA COMM, V29, P1064, DOI 10.1109/JSAC.2011.110516
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Schwarz Heike., 2007, IEEE Transactions on Circuits and Systems for Video Technology, V17
   Song D, 2007, IEEE T CIRC SYST VID, V17, P1218, DOI 10.1109/TCSVT.2007.905531
   Staelens N., IEEE T BROADCAST, V56
   Staelens N, 2009, INT WORK QUAL MULTIM, P29, DOI 10.1109/QOMEX.2009.5246982
   Stankiewicz R, 2011, IEEE COMMUN MAG, V49, P148, DOI 10.1109/MCOM.2011.5741159
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Thakolsri Srisakul, 2009, Journal of Communications, V4, P669, DOI 10.4304/jcm.4.9.669-680
   Thakolsri S., 2010, P 18 ACM INT C MULT, P783
   Tsai CF, 2008, IEEE T WIREL COMMUN, V7, P1734, DOI 10.1109/TWC.2008.060994
   Venkataraman M, 2011, IEEE NETWORK, V25, P4, DOI 10.1109/MNET.2011.5687947
   Volk M, 2010, IEEE COMMUN MAG, V48, P126, DOI 10.1109/MCOM.2010.5534597
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Xu J, 2010, IEEE J SEL AREA COMM, V28, P456, DOI 10.1109/JSAC.2010.100416
   Yaghoobi H., 2004, INTEL TECHNOLOGY J, V8, P201
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Zhang YJ, 2005, IEEE T COMMUN, V53, P107, DOI 10.1109/TCOMM.2004.840666
   Zhu HL, 2009, IEEE T COMMUN, V57, P2734, DOI 10.1109/TCOMM.2009.09.080067
   Zinner Thomas, 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P29, DOI 10.1109/QOMEX.2010.5518277
NR 49
TC 3
Z9 4
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 24
EP 36
DI 10.1016/j.jvcir.2014.10.011
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000004
DA 2024-07-18
ER

PT J
AU Yaman, M
   Kalkan, S
AF Yaman, Mustafa
   Kalkan, Sinan
TI An iterative adaptive multi-modal stereo-vision method using mutual
   information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-modal stereo-vision; Mutual information; Adaptive windowing;
   Adaptive cost aggregation; Iterative stereo; Plane fitting; RGB-D;
   Middleburry dataset
ID BELIEF PROPAGATION; REGISTRATION
AB We propose a method for computing disparity maps from a multi-modal stereo-vision system composed of an infrared-visible camera pair. The method uses mutual information (MI) as the basic similarity measure where a segment-based adaptive windowing mechanism is proposed along with a novel MI computation surface with joint prior probabilities incorporated. The computed cost confidences are aggregated using a novel adaptive cost aggregation method, and the resultant minimum cost disparities in segments are plane-fitted in their respective segments which are iteratively refined by merging and splitting segments reducing dependency to initial segmentation. Finally, the estimated disparities are iteratively refined by repeating all the steps. On an artificially-modified version of the Middlebury dataset and a Kinect dataset that we created in this study, we show that (i) our proposal improves the quality of existing MI formulation, and (ii) our method can provide depth comparable to the quality of Kinect depth data. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yaman, Mustafa; Kalkan, Sinan] Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey.
C3 Middle East Technical University
RP Yaman, M (corresponding author), Middle E Tech Univ, Dept Comp Engn, TR-06531 Ankara, Turkey.
EM mustafa.yaman@ceng.metu.edu.tr; skalkan@ceng.metu.edu.tr
RI KALKAN, Sinan/AAC-3625-2019; Kalkan, Sinan/A-4843-2016
OI Kalkan, Sinan/0000-0003-0915-5917
CR Ambrosch K, 2008, EURASIP J EMBED SYST, DOI 10.1155/2008/386059
   [Anonymous], 2006, P 2006 IEEE INT TRAN
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], INT C COMP GRAPH IM
   [Anonymous], 13 IAPR INT C MACH V
   [Anonymous], MSCIS0020 U PENNS
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], IEEE INT C VID SIGN
   Campo FB, 2012, IEEE J-STSP, V6, P437, DOI 10.1109/JSTSP.2012.2204036
   Bilodeau GA, 2014, INFRARED PHYS TECHN, V64, P79, DOI 10.1016/j.infrared.2014.02.005
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fookes C, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P961, DOI 10.1109/TDPVT.2004.1335420
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Krotosky SJ, 2007, COMPUT VIS IMAGE UND, V106, P270, DOI 10.1016/j.cviu.2006.10.008
   Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R., 2011, COMPUTER VISION ALGO
   Taguchi Y., 2008, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1
   Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562
   Tippetts B, 2016, J REAL-TIME IMAGE PR, V11, P5, DOI 10.1007/s11554-012-0313-2
   Torabi A., 2011, 2011 IEEE International Symposium on Robotic and Sensors Environments (ROSE 2011), P143, DOI 10.1109/ROSE.2011.6058540
   Torabi A, 2013, COMPUT VIS IMAGE UND, V117, P1736, DOI 10.1016/j.cviu.2013.01.016
   VENKATESWAR V, 1995, INT J COMPUT VISION, V15, P245, DOI 10.1007/BF01451743
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wang Z., 2008, IEEE C COMPUTER VISI
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Zhu Z., 2007, MULTIMODAL SURVEILLA
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 37
TC 14
Z9 15
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 115
EP 131
DI 10.1016/j.jvcir.2014.11.010
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000011
DA 2024-07-18
ER

PT J
AU Huang, LK
   Lu, JW
   Tan, YP
AF Huang, Likun
   Lu, Jiwen
   Tan, Yap-Peng
TI Multi-manifold metric learning for face recognition based on image sets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Face recognition; Face image sets; Metric learning;
   Set-based distance metric; Manifold-to-manifold distance; Person
   specific; Pattern recognition
ID SUBSPACE DISTANCE; EIGENFACES; SAMPLE
AB In this paper, we propose a new multi-manifold metric learning (MMML) method for the task of face recognition based on image sets. Different from most existing metric learning algorithms that learn the distance metric for measuring single images, our method aims to learn distance metrics to measure the similarity between manifold pairs. In our method, each image set is modeled as a manifold and then multiple distance metrics among different manifolds are learned. With these distance metrics, the intra-class manifold variations are minimized and inter-class manifold variations are maximized simultaneously. For each person, we learn a distance metric by using such a criterion that all the learned distance metrics are person-specific and thus more discriminative. Our method is extensively evaluated on three widely studied face databases, i.e., Honda/UCSD database, CMU MoBo database and YouTube Celebrities database, and compared to the state-of-the-arts. Experimental results are presented to show the effectiveness of the proposed method. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Huang, Likun; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Lu, Jiwen] Adv Digital Sci Ctr, Singapore 138632, Singapore.
C3 Nanyang Technological University
RP Huang, LK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM huan0181@e.ntu.edu.sg; jiwen.lu@adsc.com.sg; eyptan@ntu.edu.sg
RI Tan, Yap-Peng/A-5158-2011; Lu, Jiwen/C-5291-2009
OI Lu, Jiwen/0000-0002-6121-5529
CR [Anonymous], 2013, 10 INT C ASIC
   [Anonymous], 2012, CVPR
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], 2001, Cmu Ri Tr 01-18
   [Anonymous], ARXIV11034896
   [Anonymous], 2005, NIPS
   [Anonymous], 2012, CVPR
   [Anonymous], 2007, ICML
   Arandjelovic O, 2005, PROC CVPR IEEE, P581
   Arandjelovic O, 2006, IMAGE VISION COMPUT, V24, P639, DOI 10.1016/j.imavis.2005.08.002
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Chen YC, 2012, LECT NOTES COMPUT SC, V7577, P766, DOI 10.1007/978-3-642-33783-3_55
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fukui K, 2005, SPRINGER TRAC ADV RO, V15, P192
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kozakaya T., 2004, Transactions of the Information Processing Society of Japan, V45, P951
   Lee KC, 2003, PROC CVPR IEEE, P313
   Li F, 2009, IEEE SIGNAL PROC LET, V16, P227, DOI 10.1109/LSP.2008.2010819
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Ng A. Y., 2002, Advances in Neural Information Processing Systems, P1473
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ortiz EG, 2013, PROC CVPR IEEE, P3531, DOI 10.1109/CVPR.2013.453
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Satoh S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P163, DOI 10.1109/AFGR.2000.840629
   Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang LW, 2006, PATTERN RECOGN, V39, P456, DOI 10.1016/j.patcog.2005.08.015
   Wang RP, 2008, PROC CVPR IEEE, P2940
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wolf L, 2004, J MACH LEARN RES, V4, P913, DOI 10.1162/1532443041827934
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xia Ning, 2008, 2008 IEEE International Conference on Data Mining Workshops, P720, DOI 10.1109/ICDMW.2008.113
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120
NR 49
TC 15
Z9 17
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1774
EP 1783
DI 10.1016/j.jvcir.2014.08.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100026
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chu, WT
   Chen, CH
   Hsu, HN
AF Chu, Wei-Ta
   Chen, Chih-Hao
   Hsu, Han-Nung
TI Color CENTRIST: Embedding color information in scene categorization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Census transform histogram; Color index; Scene categorization; Color
   descriptor; Color quantization; Image classification; Place recognition;
   Holistic representation
ID IMAGE; CLASSIFICATION; RECOGNITION; MODEL
AB A new color descriptor has now been proposed to embed color information into the framework of CENsus TRansform hISTogram (CENTRIST), so that such a state-of-the-art visual descriptor can be further improved to categorize image scenes. In the proposed color CENTRIST descriptor, global structure characteristics are described by both gradients derived from intensity values and color variations between image pixels. The spatial pyramid scheme has also been adopted to convey information in different scales. Comprehensive studies based on various datasets were conducted to verify the effectiveness of the color CENTRIST from different aspects, including the way to quantize the color space, selection of color space, and categorization performance on various datasets. We demonstrated that the color CENTRIST descriptor was not only easy to implement, but also reliably achieved superior performance over CENTRIST. An application was also proposed to demonstrate the possibility of applying the color CENTRIST in various domains. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chu, Wei-Ta; Chen, Chih-Hao; Hsu, Han-Nung] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
EM wtchu@cs.ccu.edu.tw; w7376ms46@hotmail.com; h3607912@hotmail.com
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU National Science Council of Taiwan [NSC101-2221-E-194-055-MY2]
FX The work was partially supported by the National Science Council of
   Taiwan under the grants NSC101-2221-E-194-055-MY2.
CR Agarwala A, 2006, ACM T GRAPHIC, V25, P853, DOI 10.1145/1141911.1141966
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], 2007, P IEEE INT C COMP VI
   [Anonymous], P ACM INT C MULT RET
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Chang C.-C., 2009, ACM T INTEL SYST TEC, V2, P32
   Chao Zhu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3065, DOI 10.1109/ICPR.2010.751
   Devore J.L., 2011, Probability and statistics for engineering the science, P768
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fornoni M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.98
   Jiang YN, 2012, LECT NOTES COMPUT SC, V7573, P730, DOI 10.1007/978-3-642-33709-3_52
   Krapac J, 2011, IEEE I CONF COMP VIS, P1487, DOI 10.1109/ICCV.2011.6126406
   Kwitt Roland, 2012, Computer Vision - ECCV 2012. Proceedings of the 12th European Conference on Computer Vision, P359, DOI 10.1007/978-3-642-33765-9_26
   Lampert CH, 2009, IEEE I CONF COMP VIS, P987, DOI 10.1109/ICCV.2009.5459359
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lian XC, 2010, LECT NOTES COMPUT SC, V6314, P157, DOI 10.1007/978-3-642-15561-1_12
   Liu W., 2011, J INF COMPUT SCI, V8, P412
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUO J, 2006, CVAP304 CAS KUNGL TH
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pandey M, 2011, IEEE I CONF COMP VIS, P1307, DOI 10.1109/ICCV.2011.6126383
   Parizi SN, 2012, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2012.6248001
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Pronobis A., 2005, CVAP297 KUNGL TH
   Pronobis A., 2006, P IEEE RSJ INT C INT
   Rasiwasia N., 2008, P IEEE COMP SOC C CO
   Shabou A, 2012, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2012.6248107
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu XD, 2011, IEEE I CONF COMP VIS, P810, DOI 10.1109/ICCV.2011.6126320
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zheng YB, 2012, LECT NOTES COMPUT SC, V7576, P172, DOI 10.1007/978-3-642-33715-4_13
NR 42
TC 4
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 840
EP 854
DI 10.1016/j.jvcir.2014.01.013
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200013
DA 2024-07-18
ER

PT J
AU Su, HL
   Yang, FZ
AF Su, Honglei
   Yang, Fuzheng
TI Content-adaptive bitstream-layer model for coding distortion assessment
   of H.264/AVC networked video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No reference; Video quality assessment; Bitstream-layer model; Coding
   distortion; H.264/AVC; Networked video; Spatial complexity; Temporal
   complexity
ID QUALITY ASSESSMENT; QOE ASSESSMENT; PSNR; QUANTIZATION
AB Bitstream-layer models are designed to use the information extracted from both packet headers and payload for real-time and non-intrusive quality monitoring of networked video. This paper proposes a content-adaptive bitstream-layer (CABL) model for coding distortion assessment of H.264/AVC networked video. Firstly, the fundamental relationship between perceived coding distortion and quantization parameter (QP) is established. Then, considering the fact that the perceived coding distortion of a networked video significantly relies on both the spatial and temporal characteristics of video content, spatial and temporal complexities are incorporated in the proposed model. Assuming that the residuals before Discrete Cosine Transform (DCT) keep to the Laplace distribution, the scale parameters of the Laplace distribution are estimated utilizing QP and quantized coefficients on the basis of the Parseval theorem firstly. Then the spatial complexity is evaluated using QP and the scale parameters. Meanwhile, the temporal complexity is obtained using the weighted motion vectors (MV) considering the variations in temporal masking extent for high motion regions and low motion regions, respectively. Both the two characteristics of video content are extracted from the compressed bitstream without resorting to a complete decoding. Using content related information, the proposed model is able to adapt to different video contents. Experimental results show that the overall performance of CABL model significantly outperforms that of the P.1202.1 model and other coding distortion assessment models in terms of widely used performance criteria, including the Pearson Correlation Coefficient (PCC), the Spearman Rank Order Correlation Coefficient (SROCC), the Root-Mean-Squared Error (RMSE) and the Outlier Ratio (OR). (c) 2014 Elsevier Inc. All rights reserved.
C1 [Su, Honglei; Yang, Fuzheng] Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China.
C3 Xidian University
RP Su, HL (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian, Peoples R China.
EM hlsu@mail.xidian.edu.cn
RI Su, Honglei/KQV-0892-2024
FU National Science Foundation of China [61371089, 61170253]; Fundamental
   Research Funds for the Central Universities [72115612, K5051301020]; 111
   Project [B08038]
FX This work was supported by the National Science Foundation of China
   (61371089, 61170253), the Fundamental Research Funds for the Central
   Universities (72115612, K5051301020), and the 111 Project under Grant
   No. B08038.
CR [Anonymous], X264 A FREE H264 AVC
   [Anonymous], J VISUAL COMMUNICATI
   [Anonymous], P 2009 IEEE INT S BR
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], 2010, TD379 ITUT SG12
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], 2006, Digital Video Image Quality and Perceptual Coding
   Brandao T, 2008, SIGNAL PROCESS, V88, P822, DOI 10.1016/j.sigpro.2007.09.017
   BURR DC, 1982, VISION RES, V22, P479, DOI 10.1016/0042-6989(82)90196-1
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Chin M., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P312
   Clarke R.J., 1985, TRANSFORM CODING IMA
   de la Cruz Ramos Pedro, 2010, Proceedings of the Fifth International Conference on Digital Telecommunications (ICDT 2010), P128, DOI 10.1109/ICDT.2010.31
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   Eden Arnd, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P298, DOI 10.1109/ISCE.2009.5156922
   Eden A, 2008, IEEE T BROADCAST, V54, P691, DOI 10.1109/TBC.2008.2001718
   Feghali R, 2007, IEEE T BROADCAST, V53, P441, DOI 10.1109/TBC.2007.891700
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Ichigaya A, 2006, IEEE T CIRC SYST VID, V16, P251, DOI 10.1109/TCSVT.2005.858745
   Ichigaya A, 2008, IEEE T CIRC SYST VID, V18, P817, DOI 10.1109/TCSVT.2008.920658
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Karam LJ, 2009, IEEE J-STSP, V3, P189, DOI 10.1109/JSTSP.2009.2015485
   KARUNASEKERA SA, 1995, IEEE T IMAGE PROCESS, V4, P713, DOI 10.1109/83.388074
   Knee M., 2000, SINGLE ENDED PICTURE, P95
   Lu ZK, 2005, PROC SPIE, V5666, P554, DOI 10.1117/12.596845
   Muntean GM, 2008, IEEE T BROADCAST, V54, P494, DOI 10.1109/TBC.2008.2004258
   Ou YF, 2011, IEEE T CIRC SYST VID, V21, P286, DOI 10.1109/TCSVT.2010.2087833
   RIES M., 2007, P IEEE INT S WIR PER
   Rimac-Drlje S., 2009, P 16 INT C SYST SIGN, P1
   Rohaly AM, 2000, P SOC PHOTO-OPT INS, V4067, P742, DOI 10.1117/12.386632
   Su H, 2012, INT J COMPUT COMMUN, V7, P565
   Sugimoto O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3333, DOI 10.1109/ICIP.2011.6116385
   Sugimoto O, 2009, IEEE IMAGE PROC, P2237, DOI 10.1109/ICIP.2009.5413957
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Watanabe K, 2008, IEEE IMAGE PROC, P2060, DOI 10.1109/ICIP.2008.4712191
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Yamawaki K, 2009, PROG THEOR PHYS SUPP, P1, DOI 10.1143/PTPS.180.1
   Yang FZ, 2012, IEEE COMMUN MAG, V50, P203, DOI 10.1109/MCOM.2012.6353702
   Yang FZ, 2012, IEEE J-STSP, V6, P672, DOI 10.1109/JSTSP.2012.2207705
   Yang FZ, 2010, IEEE T CIRC SYST VID, V20, P1544, DOI 10.1109/TCSVT.2010.2087433
   Yang KC, 2007, IEEE T MULTIMEDIA, V9, P1528, DOI 10.1109/TMM.2007.906576
   Yang Y., 2011, GLOBAL TELECOMMUN C, P1
NR 45
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1199
EP 1208
DI 10.1016/j.jvcir.2014.04.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200045
DA 2024-07-18
ER

PT J
AU Lin, YH
   Tsai, MH
   Wu, JL
AF Lin, Yu-Hsun
   Tsai, Ming-Hung
   Wu, Ja-Ling
TI Depth sculpturing for 2D paintings: A progressive depth map completion
   framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 2D painting; Color plus depth 3D; Bilateral filter; Depth map;
   Interactive system; Picture composition; Picture animation; Depth of
   field
ID IMAGE; RECONSTRUCTION; FILTER
AB In real word, the depth of objects can be directly acquired by existing depth cameras; however, the depth information of 2D paintings can only be generated by users. A novel and low complexity interactive depth generation approach for 2D paintings is devised. In contrast to traditional approaches which addressed this problem through a time-consuming optimization framework, we formulate the problem as a filter-based scheme to achieve reasonable interactive response time. Inspired by sculpturing, we address the depth information generation as an iterative stroking-and-viewing process. Our work achieves instant response for interactive generating of depth information in which immediate visualization of the generated depth information is possible. Users can, therefore, rapidly and directly rectify the current depth generation results. Finally, we illustrate that the newly added depth information for 2D paintings can not only be applied to view 3D effects but also support interesting applications like editing, enhancing, and user-controlled animating of 2D paintings. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Lin, Yu-Hsun] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei, Taiwan.
   [Tsai, Ming-Hung; Wu, Ja-Ling] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Lin, YH (corresponding author), R503,CSIE Bldg 1,Sec 4,Roosevelt Rd, Taipei 106, Taiwan.
EM lymanblue@cmlab.csie.ntu.edu.tw
RI Li, Mengqi/AAG-6804-2021; Lin, Yu-Hsun/HTN-0354-2023
OI Lin, Yu-Hsun/0000-0002-6177-8639; WU, JA-LING/0000-0002-3631-1551
CR [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI [10.1109/CVPR.2008.4587843, DOI 10.1109/CVPR.2008.4587843]
   [Anonymous], EUR 07
   [Anonymous], 2011, P ICME, DOI DOI 10.1109/ICME.2011.6012006
   [Anonymous], HIGH QUALITY SCANNIN
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ICCV 01
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cao X, 2011, IEEE T BROADCAST, V57, P491, DOI 10.1109/TBC.2011.2127650
   Chen WC, 2010, J VIS COMMUN IMAGE R, V21, P427, DOI 10.1016/j.jvcir.2010.03.004
   Chenglei Wu, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P65
   Chuang YY, 2005, ACM T GRAPHIC, V24, P853, DOI 10.1145/1073204.1073273
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Han B, 2011, J VIS COMMUN IMAGE R, V22, P421, DOI 10.1016/j.jvcir.2011.03.006
   Lee EK, 2011, J VIS COMMUN IMAGE R, V22, P73, DOI 10.1016/j.jvcir.2010.10.006
   Lee S, 2008, I3D 2008: SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P123
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   MEYER F, 1992, IEE CONF PUBL, V354, P303
   Mueller M., 2010, 3DTV C TRUE VISION C, P1
   Oh JD, 2010, J VIS COMMUN IMAGE R, V21, P404, DOI 10.1016/j.jvcir.2010.03.003
   Oh KJ, 2009, IEEE SIGNAL PROC LET, V16, P747, DOI 10.1109/LSP.2009.2024112
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Russell Bryan C., 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2711, DOI 10.1109/CVPRW.2009.5206643
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shaaban KM, 2012, J VIS COMMUN IMAGE R, V23, P397, DOI 10.1016/j.jvcir.2011.12.001
   Sykora D, 2010, COMPUT GRAPH FORUM, V29, P615, DOI 10.1111/j.1467-8659.2009.01631.x
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Wang DL, 2011, J VIS COMMUN IMAGE R, V22, P325, DOI 10.1016/j.jvcir.2011.02.001
   Wu TP, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409072
   Yang Q., 2007, IEEE CVPR 07, P1
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611
NR 32
TC 3
Z9 3
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 670
EP 678
DI 10.1016/j.jvcir.2013.12.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science
GA AD2NN
UT WOS:000333072500007
DA 2024-07-18
ER

PT J
AU Liu, HW
   Philipose, M
   Sun, MT
AF Liu, Haowei
   Philipose, Matthai
   Sun, Ming-Ting
TI Automatic objects segmentation with RGB-D cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Boundary detection; Object segmentation; Trilateral filter; Graph Cuts
AB Automatic object segmentation is a fundamentally difficult problem due to issues such as shadow, lighting, and semantic gaps. Edges play a critical role in object segmentation; however, it is almost impossible for the computer to know which edges correspond to object boundaries and which are caused by internal texture discontinuities. Active 3-D cameras, which provide streams of depth and RGB frames, are poised to become inexpensive and widespread. The depth discontinuities provide useful information for identifying object boundaries, which makes automatic object segmentation possible. However, the depth frames are extremely noisy. Also, the depth and RGB information often lose synchronization when the object is moving fast, due to different response time of the RGB and depth sensors. We show how to use the combined depth and RGB information to mitigate these problems and produce an accurate silhouette of the object. On a large dataset (24 objects with 1500 images), we provide both qualitative and quantitative evidences that our proposed techniques are effective. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Liu, Haowei; Philipose, Matthai; Sun, Ming-Ting] Univ Washington, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle
RP Liu, HW (corresponding author), Univ Washington, Seattle, WA 98195 USA.
EM hwliu@uw.edu
CR Abramov Alexey, 2012, WORKSH APPL COMP VIS
   Adams Andrew, 2009, ACM ANN C COMP GRAPH
   [Anonymous], 2005, IEEE INT C COMP VIS
   [Anonymous], COMP VIS WINT WORKSH
   [Anonymous], 2011, ICCV WORKSH
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Dolson J, 2010, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2010.5540086
   Du Hao, 2011, UBICOMP
   Fei Qi, 2012, PATTERN RECOGNITION, V34
   Gupta A., 2009, INT C COMP PHOT
   Lai K, 2010, INT J ROBOT RES, V29, P1019, DOI 10.1177/0278364910369190
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Martin D, 2004, WORLD POULTRY SCI J, V60, P1
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Raskar Ramesh, 2004, INT S NONPH AN REND
   Richardt Christian, 2012, EUROGRAPHICS, V31
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Schiller Ingo, 2012, P SCAND C IM AN
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Vaiapury Karthikeyan, 2010, P 2010 ACM WORKSH SU
   Wu JX, 2007, IEEE I CONF COMP VIS, P290, DOI 10.1109/ICCV.2007.4408865
   Yang Qingxiong, 2007, IEEE INT C COMP VIS
   Yang YL, 2011, PROC IEEE MICR ELECT, P79, DOI 10.1109/MEMSYS.2011.5734366
NR 23
TC 9
Z9 9
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2014
VL 25
IS 4
SI SI
BP 709
EP 718
DI 10.1016/j.jvcir.2013.03.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD2NN
UT WOS:000333072500011
DA 2024-07-18
ER

PT J
AU Tokuda, E
   Pedrini, H
   Rocha, A
AF Tokuda, Eric
   Pedrini, Helio
   Rocha, Anderson
TI Computer generated images vs. digital photographs: A synergetic feature
   and classifier combination approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital forensics; Feature fusion; Photorealism; Classifier combination;
   Image descriptors; Synthetic images; Voting method; Feature extraction
ID STATISTICS; PATTERNS
AB The development of powerful and low-cost hardware devices allied with great advances on content editing and authoring tools have promoted the creation of computer generated images (CG) to a degree of unrivaled realism. Differentiating a photo-realistic computer generated image from a real photograph (PG) can be a difficult task to naked eyes. Digital forensics techniques can play a significant role in this task. As a matter of fact, important research has been made by the scientific community in this regard. Most of the approaches focus on single image features aiming at detecting differences between real and computer generated images. However, with the current technology advances, there is no universal image characterization technique that completely solves this problem. In our work, we (1) present a complete study of several CG versus PG approaches; (2) create a large and heterogeneous dataset to be used as a training and validation database; (3) implement representative methods of the literature; and (4) devise automatic ways for combining the best approaches. We compared the implemented methods using the same validation environment showing their pros and cons with a common benchmark protocol. We collected approximately 4850 photographs and 4850 CGs with large diversity of image content and quality. We implemented a total of 13 methods. Results show that this set of methods can achieve up to 93% of accuracy when used without any form of machine learning fusion. The same methods, when combined through the implemented fusion schemes, can achieve an accuracy rate of 97%, representing a reduction of 57% of the classification error over the best individual result. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Tokuda, Eric; Pedrini, Helio; Rocha, Anderson] Univ Estadual Campinas, UNICAMP, Inst Comp, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Pedrini, H (corresponding author), Univ Estadual Campinas, UNICAMP, Inst Comp, Av Albert Einstein 1251, BR-13083852 Campinas, SP, Brazil.
EM helio@ic.unicamp.br
RI Pedrini, Helio/A-7556-2012; Rocha, Anderson/KHU-9621-2024; SILVA,
   EDUARDO/IQS-1403-2023
FU Sao Paulo Research Foundation - FAPESP [2010/05647-4, 2010/13745-6,
   2011/22749-8]; National Counsel of Technological and Scientific
   Development - CNPq [304352/2012-8, 307113/2012-4]; Microsoft; Fundacao
   de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP) [10/05647-4]
   Funding Source: FAPESP
FX This work was partially supported by Sao Paulo Research Foundation -
   FAPESP (Grants 2010/05647-4, 2010/13745-6, and 2011/22749-8), National
   Counsel of Technological and Scientific Development - CNPq (Grants
   304352/2012-8 and 307113/2012-4) and Microsoft.
CR [Anonymous], 2013, ADV PATTERN RECOGNIT, DOI DOI 10.1007/3-540-44732-6-41
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616
   Candes E.J., 2000, CURVE SURFACE FITTIN, P105
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chakravarti R, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1323, DOI 10.1109/ITNG.2009.126
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen W, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1123
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   da Silva Pinto A., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P221, DOI 10.1109/SIBGRAPI.2012.38
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   De Silva GC, 2009, IEEE T MULTIMEDIA, V11, P1240, DOI 10.1109/TMM.2009.2030603
   Dehnie S, 2006, IEEE IMAGE PROC, P2313, DOI 10.1109/ICIP.2006.312849
   Dirik AE, 2007, IEEE IMAGE PROC, P2129
   Dirik AE, 2007, 2007 IEEE WORKSHOP ON SIGNAL PROCESSING APPLICATIONS FOR PUBLIC SECURITY AND FORENSICS, P1
   Do M.N., 2002, IEEE INT C IM PROC I, VI
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Dang-Nguyen DT, 2012, EUR SIGNAL PR CONF, P1234
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elkharraz G, 2009, IEEE IMAGE PROC, P1341, DOI 10.1109/ICIP.2009.5413570
   Equitz W., 1994, 9805 RJ IBM RES
   Fan S., 2012, SIGGRAPH ASIA, P17
   Farid H., 2010, TR2010669 DARTM COLL
   Farid H., 2004, 2004518 DARTM COLL
   Farid H., 2010, SPIE S EL IM SEI CA
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gallagher AC, 2008, PROC CVPR IEEE, P253
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Isenberg T., 2013, Image and Video-Based Artistic Stylisation, V42, P311
   Johnson Micah K., 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P19
   Kutyniok G, 2011, J APPROX THEORY, V163, P1564, DOI 10.1016/j.jat.2011.06.005
   Larsen Richard J., 2000, An Introduction to Mathematical Statistics and Its Applications, V3rd
   Lee AB, 2003, INT J COMPUT VISION, V54, P83, DOI 10.1023/A:1023705401078
   LIEBOVITCH LS, 1989, PHYS LETT A, V141, P386, DOI 10.1016/0375-9601(89)90854-2
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Ludwig O, 2009, 2009 12TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC 2009), P432
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Mäenpää T, 2003, LECT NOTES COMPUT SC, V2749, P885
   Mallat S., 1999, WAVELET TOUR SIGNAL, DOI [10.1016/B978-012466606-1/50004-0, DOI 10.1016/B978-012466606-1/50004-0]
   MANDELBROT B, 1967, SCIENCE, V156, P636, DOI 10.1126/science.156.3775.636
   Ng TT, 2009, IEEE SIGNAL PROC MAG, V26, P49, DOI 10.1109/MSP.2008.931077
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng F, 2012, INT J DIGIT CRIME FO, V4, P1, DOI 10.4018/jdcf.2012010101
   PHOONG SM, 1995, IEEE T SIGNAL PROCES, V43, P649, DOI 10.1109/78.370620
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Pouli T., 2010, IMAGE STATE THEIR AP
   Rocha A., 2008, Patent, Patent No. [PCT/BR2007/000156, 2007000156]
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rocha A, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412610010
   Rocha A, 2010, COMPUT VIS IMAGE UND, V114, P349, DOI 10.1016/j.cviu.2009.10.002
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Scheirer W, 2010, LECT NOTES COMPUT SC, V6313, P481
   Schwartz W.R., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117592
   Schwartz WR, 2011, IEEE IMAGE PROC, P1033, DOI 10.1109/ICIP.2011.6115600
   Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181
   Tian-Tsong Ng, 2005, 13th Annual ACM International Conference on Multimedia, P239
   Vaidyanathan P. P., 1987, IEEE ASSP Magazine, V4, P4, DOI 10.1109/MASSP.1987.1165589
   Wang Y., 2006, IEEE International Conference on Acoustics, Speech, and Signal Processing, V2, pII
   Wenxiang Li, 2010, Proceedings of the 2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2010), P2316, DOI 10.1109/FSKD.2010.5569821
NR 65
TC 35
Z9 36
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1276
EP 1292
DI 10.1016/j.jvcir.2013.08.009
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700006
DA 2024-07-18
ER

PT J
AU Arróspide, J
   Salgado, L
   Camplani, M
AF Arrospide, Jon
   Salgado, Luis
   Camplani, Massimo
TI Image-based on-road vehicle detection using cost-effective Histograms of
   Oriented Gradients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image analysis; Intelligent transportation systems; Intelligent
   vehicles; Vehicle detection; Histograms of Oriented Gradients
AB Image-based vehicle detection has received increasing attention in recent years in the framework of advanced driver assistance systems. However, the variability of vehicles in size, color, shape, etc. poses an enormous challenge, especially for the vehicle verification task. Histograms of Oriented Gradients (HOGs) have successfully been applied to image-based verification of objects. However, these descriptors are computationally demanding and are not affordable for real-time on-road vehicle detection. In this paper, less-demanding HOG descriptors are proposed and evaluated that significantly lighten the computation by exploiting the a priori known vehicle appearance. The proposed descriptors are evaluated on a large, public database and the experiments disclose that the computation times are reduced in a factor of more than 5, thus rendering HOG-based real-time vehicle detection affordable, while achieving detection rates of over 96%. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Arrospide, Jon; Salgado, Luis; Camplani, Massimo] Univ Politecn Madrid, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
   [Arrospide, Jon] Altran Spain, Methods & Tools, Madrid 28022, Spain.
   [Salgado, Luis] Univ Autonoma Madrid, Video Proc & Understanding Lab, E-28049 Madrid, Spain.
C3 Universidad Politecnica de Madrid; Autonomous University of Madrid
RP Arróspide, J (corresponding author), Univ Politecn Madrid, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
EM jal@gti.ssr.upm.es; L.Salgado@gti.ssr.upm.es; mac@gti.ssr.upm.es
RI Salgado, Luis/AAA-9871-2019; Camplani, Massimo/J-2549-2012
OI Salgado, Luis/0000-0002-5364-9837; Camplani, Massimo/0000-0002-6101-5324
FU Ministerio de Economa y Competitividad of the Spanish Government
   [TEC2010-20412]; European Union; Universidad Politcnica de Madrid (UPM)
FX This work was partially supported by the Ministerio de Economa y
   Competitividad of the Spanish Government under project TEC2010-20412
   (Enhanced 3DTV). M. Camplani would like to acknowledge the European
   Union and the Universidad Politcnica de Madrid (UPM) for supporting his
   activities through the Marie Curie Cofund research grant.
CR [Anonymous], MYSVM MANUAL
   [Anonymous], 2001, IEEE INT C COMP VIS, DOI DOI 10.1023/B:VISL00000
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Dalai N., 2005, P IEEE C COMP VIS PA, V1
   Gandhi Tarak, 2007, Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, P1067
   GTI Vehicle Image Database, 2011, GTI VEH IM DAT
   Gwang Yul Song, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P428, DOI 10.1109/IVS.2008.4621139
   Huang DY, 2012, J VIS COMMUN IMAGE R, V23, P648, DOI 10.1016/j.jvcir.2012.03.002
   Hwang J, 2009, OPT ENG, V48, DOI 10.1117/1.3269685
   Kembhavi A, 2011, IEEE T PATTERN ANAL, V33, P1250, DOI 10.1109/TPAMI.2010.182
   Ling Mao, 2010, 2010 International Conference on Communications, Circuits and Systems (ICCCAS), P354, DOI 10.1109/ICCCAS.2010.5581983
   Lu SY, 2013, J VIS COMMUN IMAGE R, V24, P127, DOI 10.1016/j.jvcir.2012.07.008
   Ma LY, 2013, J VIS COMMUN IMAGE R, V24, P708, DOI 10.1016/j.jvcir.2012.04.005
   Monzo D., 2011, MACH VISION APPL, V23, P471
   Negri P, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/782432
   Oniga F, 2010, IEEE T VEH TECHNOL, V59, P1172, DOI 10.1109/TVT.2009.2039718
   Palazzi CE, 2010, IEEE T INTELL TRANSP, V11, P90, DOI 10.1109/TITS.2009.2029078
   Rybicki J, 2007, MOBICOM'07: PROCEEDINGS OF THE THIRTEENTH ACM INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P215
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Southall B, 2009, PROC CVPR IEEE, P541, DOI 10.1109/CVPRW.2009.5206597
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Wei Liu, 2007, Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, P252
   Yang Y, 2009, SIXTH ACM INTERNATIONAL WORKSHOP ON VEHICULAR INTER-NETWORKING - VANET 2009, P3
   Zhou J, 2007, IEEE T VEH TECHNOL, V56, P51, DOI 10.1109/TVT.2006.883735
NR 24
TC 37
Z9 39
U1 1
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1182
EP 1190
DI 10.1016/j.jvcir.2013.08.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700041
DA 2024-07-18
ER

PT J
AU Dias, Z
   Goldenstein, S
   Rocha, A
AF Dias, Zanoni
   Goldenstein, Siome
   Rocha, Anderson
TI Exploring heuristic and optimum branching algorithms for image phylogeny
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image phylogeny tree; Image phylogeny; Image dependencies; Image's
   ancestry relationships; Near-duplicate detection and recognition;
   Near-duplicates kinship; Oriented prim algorithm; Chu-Liu, Bock and
   Edmonds algorithm
ID REGISTRATION
AB Currently, multimedia objects can be easily created, stored, (re)-transmitted, and edited for good or bad. In this sense, there has been an increasing interest in finding the structure of temporal evolution within a set of documents and how documents are related to one another overtime. This process, also known in the literature as Multimedia Phylogeny, aims at finding the phylogeny tree(s) that best explains the creation process of a set of near-duplicate documents (e.g., images/videos) and their ancestry relationships. Solutions to this problem have direct applications in forensics, security, copyright enforcement, news tracking services and other areas. In this paper, we explore one heuristic and one optimum branching algorithm for reconstructing the evolutionary tree associated with a set of image documents. This can be useful for aiding experts to track the source of child pornography image broadcasting or the chain of image distribution in time, for instance. We compare the algorithms with the state-of-the-art solution considering 350,000 test cases and discuss advantages and disadvantages of each one in a real scenario. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Dias, Zanoni; Goldenstein, Siome; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, BR-13083970 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Rocha, A (corresponding author), Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1251, BR-13083970 Campinas, SP, Brazil.
EM zanoni@ic.unicamp.br; siome@ic.unicamp.br; anderson@ic.unicamp.br
RI Goldenstein, Siome K/A-4468-2013; UNICAMP, CCES -/J-7787-2015; Rocha,
   Anderson/KHU-9621-2024
FU Sao Paulo Research Foundation - FAPESP [2010/05647-4]; National Counsel
   of Technological and Scientific Development - CNPq [307018/2010-5,
   304352/2012-8, 306730/2012-0, 477692/2012-5]; Microsoft; European Union;
   European Commission [268478]; Fundacao de Amparo a Pesquisa do Estado de
   Sao Paulo (FAPESP) [10/05647-4] Funding Source: FAPESP
FX This work was partially supported by Sao Paulo Research Foundation -
   FAPESP (grant 2010/05647-4), National Counsel of Technological and
   Scientific Development - CNPq (grants 307018/2010-5, 304352/2012-8,
   306730/2012-0, and 477692/2012-5), Microsoft, and the European Union
   through the Rewind project. The Rewind project acknowledges the
   financial support of the Future and Emerging Technologies (FET) program
   within the Seventh Framework Program for Research of the European
   Commission (under FETOpen grant 268478).
CR [Anonymous], THESIS U CERGY PONTO
   [Anonymous], INT C MULT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bock F., 1971, Developments in operations research, P29
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   CHU YJ, 1965, SCI SINICA, V14, P1396
   Dias Z., 2011, IEEE INT WORKSH INF, P1
   Dias Z, 2012, IEEE T INF FOREN SEC, V7, P774, DOI 10.1109/TIFS.2011.2169959
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goldfinch SF, 2009, INTERNATIONAL HANDBOOK OF PUBLIC MANAGEMENT REFORM, P1
   Hartley R., 2003, Multiple view geomerty in computer vision, VSecond
   Joly A, 2007, IEEE T MULTIMEDIA, V9, P293, DOI 10.1109/TMM.2006.886278
   Kennedy L., 2008, ACM International Conference on Multimedia (MM), P349
   Kim HS, 2010, LECT NOTES COMPUT SC, V5993, P229
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Mao JW, 2009, IEEE IMAGE PROC, P1501, DOI 10.1109/ICIP.2009.5414612
   Maret Y., 2007, THESIS ECOLE POLYTEC
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   PRIM RC, 1957, AT&T TECH J, V36, P1389, DOI 10.1002/j.1538-7305.1957.tb01515.x
   Rocha A, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978805
   Rosa A.D., 2010, Media Forensics and Security II, SPIE, pX1
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shelton D., 2011, FORENSIC SCI COURT C
   Shen H., 2013, ACM COMPUT SURV CSUR, V45
   TARJAN RE, 1977, NETWORKS, V7, P25, DOI 10.1002/net.3230070103
   Valle Eduardo., 2008, Proceeding of the 17th ACM conference on Information and knowledge management, P739, DOI DOI 10.1145/1458082.1458181
   Xiao C, 2011, ACM T DATABASE SYST, V36, DOI 10.1145/2000824.2000825
NR 29
TC 23
Z9 26
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1124
EP 1134
DI 10.1016/j.jvcir.2013.07.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700036
DA 2024-07-18
ER

PT J
AU Dong, WS
   Shi, GM
   Wu, XL
   Zhang, L
AF Dong, Weisheng
   Shi, Guangming
   Wu, Xiaolin
   Zhang, Lei
TI A learning-based method for compressive image recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Image recovery; Prior model learning; Non-local;
   Sparse auto-regressive model; Image reconstruction; Regularization;
   Sparse representation
ID SIGNAL RECOVERY; NONLOCAL REGULARIZATION; SPARSITY
AB Compressive sensing (CS) theory dictates that a sparse signal can be reconstructed from a few random measurements. An important issue of compressive image recovery (CIR) is that the optimal sparse space is usually unknown and/or it often varies spatially for non-stationary signals (e.g., natural images). In this paper, apart from fixed sparse spaces, prior models, specifically a set of piecewise autoregressive (AR) models that encode the common statistics of image micro-structures, are learned from example image patches, and they are then used to construct adaptive sparsity regularizers for CIR. Furthermore, a complementary non-local structural sparsity regularizer is also incorporated into the CIR process to improve the robustness. The regularization by local AR model and non-local redundancy makes the proposed CIR very effective. Experimental results on benchmark images validate that the proposed algorithm can outperform significantly previous CIR methods in terms of both PSNR and visual quality. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Dong, Weisheng; Shi, Guangming] Xidian Univ, Sch Elect Engn, Chinese Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian, Shaanxi, Peoples R China.
   [Wu, Xiaolin] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
   [Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
C3 Xidian University; McMaster University; Hong Kong Polytechnic University
RP Dong, WS (corresponding author), Xidian Univ, Sch Elect Engn, Chinese Minist Educ, Key Lab Intelligent Percept & Image Understanding, Xian, Shaanxi, Peoples R China.
EM wsdong@mail.xidian.edu.cn
RI Zhang, Lei/A-1412-2014
FU Major State Basic Research Development Program of China (973 Program)
   [2013CB329402]; Natural Science Foundation of China [61100154, 61227004,
   61033004, 61070138]
FX This work was supported in part by Major State Basic Research
   Development Program of China (973 Program) (No. 2013CB329402) and in
   part by the Natural Science Foundation of China under (Grants 61100154,
   61227004, 61033004, 61070138).
CR [Anonymous], 2008, P NEUR INF PROC SYST
   Baraniuk RG, 2010, IEEE T INFORM THEORY, V56, P1982, DOI 10.1109/TIT.2010.2040894
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Candès E, 2005, PROC SPIE, V5674, P76, DOI 10.1117/12.600722
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong WS, 2010, PROC SPIE, V7744, DOI 10.1117/12.863368
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoval D, 2006, TRANSISTOR LEVEL MODELING FOR ANALOG/ RF IC DESIGN, P1, DOI 10.1007/1-4020-4556-5_1
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Galatsanos NP, 1992, IEEE T IMAGE PROCESS, V1, P322, DOI 10.1109/83.148606
   Hale E. T., 2007, TR0707 CAAM RIC U
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Ji SH, 2008, IEEE T SIGNAL PROCES, V56, P2346, DOI 10.1109/TSP.2007.914345
   Peyre G, 2008, LECT NOTES COMPUT SC, V5304, P57, DOI 10.1007/978-3-540-88690-7_5
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wu X., 2012, IEEE T IMAGE PROCESS, V21
   Wu XL, 2008, IEEE DATA COMPR CONF, P123, DOI 10.1109/DCC.2009.69
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 30
TC 15
Z9 18
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1055
EP 1063
DI 10.1016/j.jvcir.2013.06.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700029
DA 2024-07-18
ER

PT J
AU Razlighi, QR
   Kehtarnavaz, N
   Yousefi, S
AF Razlighi, Q. R.
   Kehtarnavaz, N.
   Yousefi, S.
TI Evaluating similarity measures for brain image registration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Brain image registration; Similarity measures; Spatial mutual
   information; Normalized spatial mutual information; Comparison of
   similarity measures
ID MUTUAL-INFORMATION; NONRIGID REGISTRATION; MAXIMIZATION; PET; MR;
   COMPUTATION; ALIGNMENT; PROTOCOL; CT
AB Evaluation of similarity measures for image registration is a challenging problem due to its complex interaction with the underlying optimization, regularization, image type and modality. We propose a single performance metric, named robustness, as part of a new evaluation method which quantifies the effectiveness of similarity measures for brain image registration while eliminating the effects of the other parts of the registration process. We show empirically that similarity measures with higher robustness are more effective in registering degraded images and are also more successful in performing intermodal image registration. Further, we introduce a new similarity measure, called normalized spatial mutual information, for 3D brain image registration whose robustness is shown to be much higher than the existing ones. Consequently, it tolerates greater image degradation and provides more consistent outcomes for intermodal brain image registration. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Razlighi, Q. R.; Kehtarnavaz, N.] Columbia Univ, Dept Neurol, New York, NY 10032 USA.
   [Yousefi, S.] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
C3 Columbia University; University of Texas System; University of Texas
   Dallas
RP Razlighi, QR (corresponding author), Columbia Univ, Dept Neurol, New York, NY 10032 USA.
EM qr2108@columbia.edu
RI Razlighi, Qolamreza/HLP-7646-2023
FU National Institute of Health - National Institute of Aging [AG000261-12]
FX This work was partially supported by National Institute of Health -
   National Institute of Aging through a T32 federal grant number
   AG000261-12.
CR [Anonymous], 2001, P 4 INT C MEDICAL IM, DOI DOI 10.1007/3-540-45468-3_31
   Avants BB, 2011, NEUROIMAGE, V54, P2033, DOI 10.1016/j.neuroimage.2010.09.025
   Bardinet E, 1998, COMPUT VIS IMAGE UND, V71, P39, DOI 10.1006/cviu.1997.0595
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   Bovik A.C., 2005, SOCIETY, V3, P256
   Chen Bei_Jing, 2007, 2007 1st International Conference on Bioinformatics and Biomedical Engineering, P956
   Chung A.C. S., 2002, International Conference on Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science, V2, P525
   COLLIGNON A, 1995, COMP IMAG VIS, V3, P263
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Declerck J, 1997, IEEE T MED IMAGING, V16, P727, DOI 10.1109/42.650870
   Dutton R.A., 2003, 3 IEEE INT S BIOM IM, V2, P193
   Friston KJ, 1995, HUM BRAIN MAPP, V3, P165, DOI 10.1002/hbm.460030303
   Gallier J., 2000, Curves and Surfaces in Geometric Modeling
   Gholipour A, 2008, IEEE T BIO-MED ENG, V55, P563, DOI 10.1109/TBME.2007.912641
   Gholipour A, 2007, IEEE T MED IMAGING, V26, P427, DOI 10.1109/TMI.2007.892508
   Hellier P., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P590
   Hellier P, 2003, IEEE T MED IMAGING, V22, P1120, DOI 10.1109/TMI.2003.816961
   Holden M, 2008, IEEE T MED IMAGING, V27, P111, DOI 10.1109/TMI.2007.904691
   HSU WM, 1992, COMP GRAPH, V26, P177, DOI 10.1145/142920.134036
   Klein A, 2010, NEUROIMAGE, V51, P214, DOI 10.1016/j.neuroimage.2010.01.091
   Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037
   Klein S., 2010, Medical Imaging, IEEE Transactions on, V29, p196,205
   LEVIN DN, 1988, RADIOLOGY, V169, P817, DOI 10.1148/radiology.169.3.3263666
   Lin JR, 2004, P ANN INT IEEE EMBS, V26, P1747
   MA Y, 1993, COMPUT MED IMAG GRAP, V17, P365, DOI 10.1016/0895-6111(93)90030-Q
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   PELIZZARI CA, 1989, J COMPUT ASSIST TOMO, V13, P20, DOI 10.1097/00004728-198901000-00004
   Pluim JPW, 2000, IEEE T MED IMAGING, V19, P809, DOI 10.1109/42.876307
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872
   Razlighi QR, 2011, J REAL-TIME IMAGE PR, V6, P137, DOI 10.1007/s11554-009-0144-y
   Razlighi QR, 2009, IEEE T IMAGE PROCESS, V18, P2629, DOI 10.1109/TIP.2009.2029988
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Rueckert D, 2000, PROC SPIE, V3979, P438, DOI 10.1117/12.804801
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Skerl D, 2008, MED IMAGE ANAL, V12, P42, DOI 10.1016/j.media.2007.06.001
   Skerl D, 2006, IEEE T MED IMAGING, V25, P779, DOI 10.1109/TMI.2006.874963
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Studholme C, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P23, DOI 10.1109/MMBIA.1996.534054
   Thévenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Zagorchev L, 2006, IEEE T IMAGE PROCESS, V15, P529, DOI 10.1109/TIP.2005.863114
NR 44
TC 34
Z9 39
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 977
EP 987
DI 10.1016/j.jvcir.2013.06.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700022
PM 24039378
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Wu, QX
   Wang, ZY
   Deng, FQ
   Yong, X
   Kang, WX
   Feng, DD
AF Wu, Qiuxia
   Wang, Zhiyong
   Deng, Feiqi
   Yong, Xia
   Kang, Wenxiong
   Feng, David Dagan
TI Discriminative two-level feature selection for realistic human action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Realistic human action recognition; Visual saliency; Space-time interest
   points; Unsupervised codeword selection; Maximal information compression
   index; Bag-of-features model; Saliency map; Support vector machine
ID VISUAL-ATTENTION; MODEL; CONTEXT
AB Constructing the bag-of-features model from Space-time interest points (STIPs) has been successfully utilized for human action recognition. However, how to eliminate a large number of irrelevant STIPs for representing a specific action in realistic scenarios as well as how to select discriminative codewords for effective bag-of-features model still need to be further investigated. In this paper, we propose to select more representative codewords based on our pruned interest points algorithm so as to reduce computational cost as well as improve recognition performance. By taking human perception into account, attention based saliency map is employed to choose salient interest points which fall into salient regions, since visual saliency can provide strong evidence for the location of acting subjects. After salient interest points are identified, each human action is represented with the bag-of-features model. In order to obtain more discriminative codewords, an unsupervised codeword selection algorithm is utilized. Finally, the Support Vector Machine (SVM) method is employed to perform human action recognition. Comprehensive experimental results on the widely used and challenging Hollywood-2 Human Action (HOHA-2) dataset and YouTube dataset demonstrate that our proposed method is computationally efficient while achieving improved performance in recognizing realistic human actions. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wu, Qiuxia; Deng, Feiqi; Kang, Wenxiong] S China Univ Technol, Guangzhou 510640, Guangdong, Peoples R China.
   [Wu, Qiuxia; Wang, Zhiyong; Yong, Xia; Feng, David Dagan] Univ Sydney, Sydney, NSW 2006, Australia.
C3 South China University of Technology; University of Sydney
RP Wu, QX (corresponding author), S China Univ Technol, Guangzhou 510640, Guangdong, Peoples R China.
EM wutong_924@163.com
RI Cataldi, Antonio/AAM-7411-2021
OI Feng, Dagan/0000-0002-3381-214X; Wang, Zhiyong/0000-0002-8043-0312;
   Deng, Feiqi/0000-0002-0257-5647
FU National Natural Science Foundation of China [61273126, 61105019];
   Guangdong Natural Science Foundation [10251064101000008,
   S2011040002474]; Science and Technology Planning Project of Guangdong
   Province [2012B010100021]; Fundamental Research Funds for the Central
   Universities [2012ZZ0108]; China Scholarship Council (CSC); Australian
   Research Council (ARC)
FX The authors thank Ivan Laptev for his valuable help. The work presented
   in this paper is partially supported by grants from National Natural
   Science Foundation of China (No. 61273126 and No. 61105019), Guangdong
   Natural Science Foundation (No. 10251064101000008 and No.
   S2011040002474), Science and Technology Planning Project of Guangdong
   Province (No. 2012B010100021), the Fundamental Research Funds for the
   Central Universities (No. 2012ZZ0108) and China Scholarship Council
   (CSC), Australian Research Council (ARC).
CR [Anonymous], PROC ACM INT CONF MU
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], COMPUT VIS PATT RECO, DOI DOI 10.1109/CVPR.2009.5206557
   [Anonymous], 2007, MIR
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chi MC, 2009, IEEE T CIRC SYST VID, V19, P1025, DOI 10.1109/TCSVT.2009.2022822
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gokalp D., 2007, Computer Vision and Pattern Recognition, CVPR, IEEE Conference on, P1
   Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Junejo IN, 2012, J VIS COMMUN IMAGE R, V23, P853, DOI 10.1016/j.jvcir.2012.05.001
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kim S, 2006, INT C PATT RECOG, P650
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Liu CX, 2009, COMPUT VIS IMAGE UND, V113, P415, DOI 10.1016/j.cviu.2008.08.002
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Lu SY, 2013, J VIS COMMUN IMAGE R, V24, P127, DOI 10.1016/j.jvcir.2012.07.008
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Mallapragada PK, 2010, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2010.5540062
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mitra P., IEEE T PATTERN ANAL, V24
   Moosmann F., 2006, ECCV INT WORKSH REPR
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rahman SA, 2013, J VIS COMMUN IMAGE R, V24, P217, DOI 10.1016/j.jvcir.2012.12.001
   Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Schindler G., 2007, P IEEE C COMP VIS PA, V2007, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shih HC, 2009, IEEE T MULTIMEDIA, V11, P244, DOI 10.1109/TMM.2008.2009682
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Tsotsos John K., 2005, pXXIII, DOI 10.1016/B978-012375731-9/50003-3
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Udrea RM, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2713739
   Vizireanu DN, 2001, J DIGIT IMAGING, V14, P241, DOI 10.1007/BF03190354
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Zhang Shiliang., 2009, MM 09 P 17 ACM INT C, P75, DOI DOI 10.1145/1631272.1631285
   Zhu Guan, 2009, P165, DOI 10.1007/978-3-540-74042-1_5
NR 46
TC 7
Z9 7
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1064
EP 1074
DI 10.1016/j.jvcir.2013.07.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700030
DA 2024-07-18
ER

PT J
AU Chan, CC
   Tang, CW
AF Chan, Chia-Chi
   Tang, Chih-Wei
TI Coding statistics based fast mode decision for multi-view video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view video coding; Fast mode decision; RD cost; Motion cost;
   Motion vector difference; DIRECT mode; Inter mode; Intra mode
ID ALGORITHM
AB Reduction of high computational complexity of multi-view video coding (MVC) is necessary for realization in consumer electronics. Since mode decision is one of the key computational bottlenecks of multiview video encoders, this paper proposes a coding statistics based fast mode decision algorithm. First of all, a rate-distortion cost based fast DIRECT mode decision algorithm early terminates the mode decision process if possible. Next, the candidates for Inter modes are reduced by taking the advantage of the correlation between an optimal mode and motion cost. The proper thresholds to reduce the candidates for the above two fast algorithms can be easily derived from exponential functions at run time. Finally, motion vector difference based motion characteristics is referred to further speed up the mode decision process of Inter modes. The experimental results show that the proposed scheme reduces up to 70.82% of encoding time with negligible degradation of RD performance. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Chan, Chia-Chi; Tang, Chih-Wei] Natl Cent Univ, Dept Commun Engn, Visual Commun Lab, Jhongli 32001, Taiwan.
C3 National Central University
RP Tang, CW (corresponding author), Natl Cent Univ, Dept Commun Engn, Visual Commun Lab, Jhongli 32001, Taiwan.
EM cwtang@ce.ncu.edu.tw
CR [Anonymous], 2008, JVTAA212 ISOIEC JTC1
   [Anonymous], VCEGM33 ITUT Q6SG16
   Chan Grace Chia-Chi, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P478, DOI 10.1109/PCS.2010.5702541
   Chiang JC, 2011, IEEE J-STSP, V5, P309, DOI 10.1109/JSTSP.2010.2066956
   Huang YW, 2006, IEEE T CIRC SYST VID, V16, P507, DOI 10.1109/TCSVT.2006.872783
   ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 Q.6, 2006, JVTT207 ISOIEC JTC1S
   Kim JH, 2008, J VIS COMMUN IMAGE R, V19, P175, DOI 10.1016/j.jvcir.2007.09.001
   Liu XG, 2010, J VIS COMMUN IMAGE R, V21, P155, DOI 10.1016/j.jvcir.2009.05.002
   Ma WP, 2009, IEEE INT CON MULTI, P17, DOI 10.1109/ICME.2009.5202425
   Martinez-Enriquez E., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P325
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Micallef B. W., 2011, P IEEE INT C 3DTV, P1
   Onural L., 2004, P EUR WORKSH INT KNO, P25
   Peng ZJ, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/393727
   Shen LQ, 2011, IEEE T CIRC SYST VID, V21, P837, DOI 10.1109/TCSVT.2011.2130310
   Shen LQ, 2009, IEEE T BROADCAST, V55, P761, DOI 10.1109/TBC.2009.2030453
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yo-Sung Ho, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P5
   Zatt B., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P42, DOI 10.1109/PCS.2010.5702527
   Zeng HQ, 2010, IEEE IMAGE PROC, P3405, DOI 10.1109/ICIP.2010.5653326
   Zhu W, 2010, IEEE T CONSUM ELECTR, V56, P1696, DOI 10.1109/TCE.2010.5606315
NR 22
TC 4
Z9 7
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 686
EP 699
DI 10.1016/j.jvcir.2012.01.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900006
DA 2024-07-18
ER

PT J
AU Elshoura, SM
   Megherbi, DB
AF Elshoura, S. M.
   Megherbi, D. B.
TI Analysis of noise sensitivity of Tchebichef and Zernike moments with
   application to image watermarking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sensitivity; Noise sensitivity; Tchebichef moments; Zernike moments;
   Image watermarking; Tampering detection; Image reconstruction; Error
   measurement
ID SCHEME; ROBUST
AB In this paper we show that, contrary to the common belief found in some of the literature, Tchebichef moments are more sensitive to image additive noise than Zernike moments. We examine the problem of noisy image reconstruction by the method of orthogonal moments. We comparatively show this by imposing different types and levels of noise on various images and by measuring the error due to the added noise alone after image reconstruction. Here the error due to the added noise alone is defined, quantified and calculated by subtracting the noise-free image reconstruction error from the total noisy reconstructed error, which includes both reconstruction and added noise errors. The reconstruction error is with respect to a given original non-noisy image. A reconstruction measure metric for better evaluating the sensitivity of orthogonal moments towards noise added to images, namely accumulative relative error, is also introduced and proposed. As a result of this noise analysis study, we also present an empirical comparative study of Tchebichef and Zernike moments in image watermarking applications. In particular, we consider the case of moment-based watermarking schemes involving moment watermarks being embedded in a given carrier image moments. We show that the Tchebichef moments of a given image are more sensitive to image malicious and intended manipulations than Zernike moments, and hence are more capable of detecting tampering performed on watermarked images during transmission. However, this suggests and will most likely make Zernike orthogonal moments more suitable as moment descriptors employed as pattern features in scene registration, recognition, modeling, and data compression in noisy scenes, than Tchebitchef moments. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Elshoura, S. M.; Megherbi, D. B.] Univ Massachusetts, Dept Elect & Comp Engn, CMINDS Res Ctr, Lowell, MA USA.
C3 University of Massachusetts System; University of Massachusetts Lowell
RP Megherbi, DB (corresponding author), Univ Massachusetts, Dept Elect & Comp Engn, CMINDS Res Ctr, Lowell, MA USA.
EM suzan_elshoua@student.uml.edu; Dalila_me-gherbi@uml.edu
CR Abdelwahab SAS, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P269, DOI 10.1109/ICCES.2009.5383269
   Chang C., 2007, IEEE T INF FOREN SEC, V2, P493
   Cheng SC, 2005, IEEE T MULTIMEDIA, V7, P189, DOI 10.1109/TMM.2005.843358
   Cox I. J., 2002, Digital Watermarking
   Elshoura S., 2010, P INT S COMP COMM CO
   Elshoura SM, 2008, PROCEEDINGS IEEE SOUTHEASTCON 2008, VOLS 1 AND 2, P521, DOI 10.1109/SECON.2008.4494350
   Elshoura SM, 2008, 2008 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, VOLS 1 AND 2, P615, DOI 10.1109/THS.2008.4534524
   Elshoura S.M., 2010, IEEE P 2 INT C FUT C
   Emre Celebi M., 2005, P INT C INF TECHN CO
   Eyadat M., 2004, P INT C INF TECHN CO
   FARZAM M, 2003, P IEEE 4 WORKSH MULT, P529
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Gope C, 2005, PATTERN RECOGN, V38, P125, DOI 10.1016/j.patcog.2004.06.005
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kang HI, 2004, IEEE IMAGE PROC, P1553
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kotoulas L, 2006, IEEE T CIRC SYST VID, V16, P884, DOI 10.1109/TCSVT.2006.877403
   Kotoulas L, 2007, IEEE T IMAGE PROCESS, V16, P2028, DOI 10.1109/TIP.2007.899621
   Li CT, 2002, INT CONF ACOUST SPEE, P3445
   Lin CY, 2006, J INF SCI ENG, V22, P163
   Lv W., 2008, P IEEE INT C NEUR NE, P146
   Megherbi D.B., ANAL ANAL RECONSTRUC
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 2001, P CISST01 INT C
   Mukundan R, 2004, P 6 IASTED INT C SIG
   Nikolaidis A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P991, DOI 10.1109/ICIP.2001.958292
   Paschos G, 2003, IEEE T KNOWL DATA EN, V15, P1069, DOI 10.1109/TKDE.2003.1232264
   Patra JC, 2008, IEEE SYS MAN CYBERN, P512, DOI 10.1109/ICSMC.2008.4811328
   PAWLAK M, 2002, P IEEE CAN C EL COMP
   Sharma RK, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P237, DOI 10.1109/MMSP.2001.962740
   Singhal N, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P401, DOI 10.1109/MMSP.2007.4412901
   Solanki K, 2004, IEEE T IMAGE PROCESS, V13, P1627, DOI 10.1109/TIP.2004.837557
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tzouveli P, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY (ISSPIT), VOLS 1 AND 2, P399
   Xie J., 2008, INT S EL COMM SEC
   Yang Cheng-Hsing, 2008, IEEE T INFORM FORENS, V3
   Yang HJ, 2006, IEEE SIGNAL PROC LET, V13, P741, DOI 10.1109/LSP.2006.879829
   Yap P., 2005, PROC IEEE REGION 10, P1
   Yap PT, 2002, APCCAS 2002: ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P525, DOI 10.1109/APCCAS.2002.1115328
   Yap PT, 2001, IEEE IJCNN, P2856, DOI 10.1109/IJCNN.2001.938829
   Yasein Mohamed S., 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P116, DOI 10.1109/ISSPIT.2007.4458129
   Zhang L, 2007, OPT EXPRESS, V15, P2251, DOI 10.1364/OE.15.002251
NR 44
TC 24
Z9 26
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2013
VL 24
IS 5
BP 567
EP 578
DI 10.1016/j.jvcir.2013.03.021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 162VU
UT WOS:000320294900006
DA 2024-07-18
ER

PT J
AU Zhu, YX
   Cheng, S
   Stankovic, V
   Stankovic, L
AF Zhu, Yingxuan
   Cheng, Samuel
   Stankovic, Vladimir
   Stankovic, Lina
TI Image registration using BP-SIFT
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image registration; Belief propagation; SIFT; RANSAC; Min-sum algorithm;
   Keypoint matching; Descriptors matching; Image processing
ID BELIEF PROPAGATION; DESCRIPTORS
AB Scale Invariant Feature Transform (SIFT) is a powerful technique for image registration. Although SIFT descriptors accurately extract invariant image characteristics around keypoints, the commonly used matching approaches of registration loosely represent the geometric information among descriptors. In this paper, we propose an image registration algorithm named BP-SIFT, where we formulate keypoint matching of SIFT descriptors as a global optimization problem and provide a suboptimum solution using belief propagation (BP). Experimental results show significant improvement over conventional SIFT-based matching with reasonable computation complexity. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Zhu, Yingxuan] Syracuse Univ, Dept Elect Engn & Comp Sci, Syracuse, NY 13244 USA.
   [Cheng, Samuel] Univ Oklahoma, Sch Elect & Comp Engn, Tulsa, OK 74135 USA.
   [Stankovic, Vladimir; Stankovic, Lina] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow G1 1XW, Lanark, Scotland.
C3 Syracuse University; University of Oklahoma System; University of
   Oklahoma - Tulsa; University of Strathclyde
RP Zhu, YX (corresponding author), Syracuse Univ, Dept Elect Engn & Comp Sci, Syracuse, NY 13244 USA.
EM zhuyingxuan@gmail.com
RI ; Stankovic, Vladimir/L-6584-2016
OI Cheng, Samuel/0000-0002-5439-1137; Stankovic,
   Vladimir/0000-0002-1075-2420; Stankovic, Lina/0000-0002-8112-1976
CR [Anonymous], P NATL ACAD SCI US
   [Anonymous], IEEE CONFERENCE ON C
   [Anonymous], PROCEEDINGS OF INFOR
   [Anonymous], TOWARD CATEGORY LEVE
   [Anonymous], TECH REP 070012
   [Anonymous], WORKSHOP ON ARTIFICI
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], SCIENCE AND TECHNOLO
   [Anonymous], PROCEEDINGS OF THE I
   [Anonymous], IEEE INTERNATIONAL C
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Bustard J., 2008, IEEERSJ INT C BIOMET, P1
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Grabner M, 2006, LECT NOTES COMPUT SC, V3851, P918
   Hopfield JJ, 2001, P NATL ACAD SCI USA, V98, P1282, DOI 10.1073/pnas.031567098
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Lhuillier M, 2000, INT C PATT RECOG, P968, DOI 10.1109/ICPR.2000.905620
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacKay D., 2003, INFORM THEORY INFERE
   MacKay DJC, 1999, IEEE T INFORM THEORY, V45, P399, DOI 10.1109/18.748992
   McEliece RJ, 1998, IEEE J SEL AREA COMM, V16, P140, DOI 10.1109/49.661103
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Pearl J., 1988, PROBABILISTIC REASON
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tang CM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL I, PROCEEDINGS, P580, DOI 10.1109/IITA.2008.586
   Wainwright M. J., 2008, GRAPHICAL MODELS EXP
   Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 35
TC 28
Z9 31
U1 4
U2 52
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 448
EP 457
DI 10.1016/j.jvcir.2013.02.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400002
DA 2024-07-18
ER

PT J
AU Shafei, B
   Steidl, G
AF Shafei, B.
   Steidl, G.
TI Segmentation of images with separating layers by fuzzy <i>c</i>-means
   and convex optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Segmentation; Fuzzy-c means; TV-functional; ADMM; Convex optimization;
   Materials with layers
AB This paper is concerned with the segmentation of two- and three-dimensional images containing separated layers. We tackle this problem by combining the fuzzy c-means algorithm with recently developed convex multi-class segmentation algorithms, where we modify the data term of the corresponding functional to involve the information of the layer structure. We solve the optimization problem numerically by applying an alternating direction method of multipliers in conjunction with the fast discrete cosine transform to solve the involved linear system of equations. We demonstrate the performance of our method on synthetic and real-world images. In particular we deal with the segmentation of three-dimensional images arising from micro-computed tomography of C/SiC-ceramics by synchrotron radiation. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Steidl, G.] Univ Kaiserslautern, Dept Math, Felix Klein Zentrum, D-67663 Kaiserslautern, Germany.
   [Shafei, B.] Fraunhofer ITWM, D-67663 Kaiserslautern, Germany.
C3 University of Kaiserslautern
RP Steidl, G (corresponding author), Univ Kaiserslautern, Dept Math, Felix Klein Zentrum, Paul Ehrlich Str 31, D-67663 Kaiserslautern, Germany.
EM steidl@mathematik.uni-kl.de
CR [Anonymous], 2008, CONVEX APPROACH COMP
   Bae E., 2010, STUDY CONTINUOUS M 2
   Bae E., 2011, DAGST SEM P
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Bae E, 2009, LECT NOTES COMPUT SC, V5567, P1, DOI 10.1007/978-3-642-02256-2_1
   Bezdek J.C., 1981, FATTERN RECOGNITION
   BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan T, 2008, CAM REPORTS
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chaux C, 2011, J MATH IMAGING VIS, V41, P23, DOI 10.1007/s10851-010-0241-3
   Delong A, 2009, IEEE I CONF COMP VIS, P285, DOI 10.1109/ICCV.2009.5459263
   Duchi J., 2008, P INT C MACH LEARN
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Esser E, 2009, 0931 CAM UCLA
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Gabay D., 1983, AUGMENTED LAGRANGIAN, V15, P299, DOI DOI 10.1016/S0168-2024(08)70034-1
   Gersho A., 2003, Vector Quantization and Signal Compression
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hathaway RJ, 2000, IEEE T FUZZY SYST, V8, P576, DOI 10.1109/91.873580
   HATHAWAY RJ, 1988, J CLASSIF, V5, P237, DOI 10.1007/BF01897166
   He Y., 2011, FUZZY C MEANS METHOD
   Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908
   Kersten PR, 1999, IEEE T FUZZY SYST, V7, P708, DOI 10.1109/91.811239
   Lellmann J., 2010, CONTINUOUS MULTICLAS
   Lellmann J, 2010, LECT NOTES COMPUT SC, V6312, P494, DOI 10.1007/978-3-642-15552-9_36
   Lellmann J, 2009, LECT NOTES COMPUT SC, V5567, P150, DOI 10.1007/978-3-642-02256-2_13
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Miyamoto S., 1996, P 4 INT WORKSH ROUGH, P255
   Overstreet D.D., 1998, THESIS GEORGIA SO U
   Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604
   Potts D, 1998, LINEAR ALGEBRA APPL, V281, P265, DOI 10.1016/S0024-3795(98)10042-3
   Rack A, 2008, NUCL INSTRUM METH A, V586, P327, DOI 10.1016/j.nima.2007.11.020
   Rao K.R, 2014, DISCRETE COSINE TRAN
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2012, J COMPUT APPL MATH, V236, P2200, DOI 10.1016/j.cam.2011.09.042
   Setzer S., 2011, CYCLIC GRADIENT DESC
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Yuan J, 2010, LECT NOTES COMPUT SC, V6316, P379, DOI 10.1007/978-3-642-15567-3_28
   Zach C., 2008, VIS MOD VIS WORKSH
NR 42
TC 20
Z9 20
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 611
EP 621
DI 10.1016/j.jvcir.2012.02.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500003
DA 2024-07-18
ER

PT J
AU Liu, F
   Liu, JB
AF Liu, Feng
   Liu, Jingbo
TI Anisotropic diffusion for image denoising based on diffusion tensors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Anisotropic diffusion; Nonlinear diffusion; Diffusion
   tensor; Diffusion filter; Diffusion direction; Diffusion amount;
   Multi-scale method
ID EDGE-DETECTION; BACKWARD DIFFUSION; ENHANCEMENT; SPACE
AB In this paper, the anisotropic diffusion for image denoising is considered. A new method to construct diffusion tensors is proposed. The tensors obtained by our approach depend on four directional derivatives of the intensity of an image, and hence they are adaptively determined by local image structure. It is shown that the proposed diffusion filter is isotropic in the interior of a region, whereas it is anisotropic at edges. This property of tensors allows us to efficiently remove noise in an image, particularly noise at edges. Several numerical experiments are conducted on both synthetic and real images. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Liu, Feng] Xi An Jiao Tong Univ, Dept Informat Sci, Sch Sci, Xian 710049, Peoples R China.
   [Liu, Jingbo] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Xi'an Jiaotong University; Tsinghua University
RP Liu, F (corresponding author), Xi An Jiao Tong Univ, Dept Informat Sci, Sch Sci, Xian 710049, Peoples R China.
EM liuf@mail.xjtu.edu.cn
RI Wang, Xin/AAN-8435-2021
OI Wang, Xin/0000-0002-4457-7376
FU National Natural Science Foundation of China [11171270]
FX This research was supported by the National Natural Science Foundation
   of China under Grant No. 11171270.
CR ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   [Anonymous], COMP SUPPL
   Aubert G., 2002, MATH PROBLEMS IMAGE
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan TF, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICIP.2000.899404
   Clarenz U, 2004, IEEE T IMAGE PROCESS, V13, P248, DOI 10.1109/TIP.2003.819863
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Malgouyres F, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P57, DOI 10.1109/VLSM.2001.938882
   Mrázek P, 2003, LECT NOTES COMPUT SC, V2695, P101
   NITZBERG M, 1992, IEEE T PATTERN ANAL, V14, P826, DOI 10.1109/34.149593
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Wang Y, 2007, IEEE T IMAGE PROCESS, V16, P1854, DOI 10.1109/TIP.2007.899002
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   WEICKERT J, 1996, P ICAOS 96 IMAGES WA, V219, P111
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   Yue Y, 2006, IEEE T MED IMAGING, V25, P297, DOI 10.1109/TMI.2005.862737
NR 25
TC 19
Z9 26
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 516
EP 521
DI 10.1016/j.jvcir.2012.01.012
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800010
DA 2024-07-18
ER

PT J
AU Chiang, KC
   Wu, MF
   Shann, JJJ
AF Chiang, Kuen-Cheng
   Wu, Ming Feng
   Shann, Jean Jyh-Jiun
TI Modification and implementation of an edge-based fast intra prediction
   mode decision algorithm for H.264/AVC high resolution real-time systems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mode decision; Direction decision; Vector calculation; Intra prediction;
   H.264/AVC; Five-value MB sorting; Butterfly architecture; Histogram
   strength accumulation
AB In this paper, we propose an architecture for H.264/AVC fast intra-prediction-mode decision making in high resolution real-time applications. Intra-prediction-mode decision making requires many computations of H.264/AVC video coding, and also extra time for mode generation for intra prediction mode decisions. Hence, there exists a bottleneck in the execution of high resolution real-time applications. To improve the operation of intra prediction mode decision, we use an algorithm which, based on the edge information of an object, will reduce estimations of mode predictions by 66%; with negligible loss of video quality and a small increase in bit-rate of video stream. We propose a low cost architecture, with gate counts reduced by 50% compared with former design. The total gate count is 86,671 and the maximum operating frequency is 250 MHz using TSMC 0.18 mu m cell-based technology. The experimental results show our design is a strong competitor with most modern high resolution, real-time video processing. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chiang, Kuen-Cheng; Wu, Ming Feng; Shann, Jean Jyh-Jiun] Natl Chiao Tung Univ, Coll Elect Engn & Comp Sci, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chiang, KC (corresponding author), Natl Chiao Tung Univ, Coll Elect Engn & Comp Sci, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
EM kcc.chiang@msa.hinet.net
CR [Anonymous], H264 ITUT
   Changsung Kim, 2005, P J VISUAL COMMUNICA, V17, P291
   Chen TC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P273
   Huang YW, 2005, IEEE T CIRC SYST VID, V15, P378, DOI 10.1109/TCSVT.2004.842620
   Jin G H, 2006, 6 IEEE INT C COMP IN, P246
   Kim C, 2004, IEEE IMAGE PROC, P769
   Li S, 2007, IEICE T INF SYST, VE90D, P90, DOI 10.1093/ietisy/e90-d.1.90
   Li S, 2007, GLSVLSI'07: PROCEEDINGS OF THE 2007 ACM GREAT LAKES SYMPOSIUM ON VLSI, P20
   Liu Qiong, 2006, Journal of Zhejiang University (Science), V7, P101, DOI 10.1631/jzus.2006.AS0101
   Pan Feng, 2005, P IEEE T CIRCUITS SY, P7
   Park Jun Sung, 2006, P WORLD ACAD SCI ENG, V13
   Richardson G., H 264 MPEG 4 VIDEO C
   Tsukuba T., P EUR SIGN PROC C EU
   Wang Jia-Ching, 2007, P IEEE T CIRCUITS SY, V17
NR 14
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 245
EP 253
DI 10.1016/j.jvcir.2011.10.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900002
DA 2024-07-18
ER

PT J
AU Penatti, OAB
   Valle, E
   Torres, RD
AF Penatti, Otavio A. B.
   Valle, Eduardo
   Torres, Ricardo da S.
TI Comparative study of global color and texture descriptors for web image
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Comparative study; Color descriptors; Texture descriptors; Web;
   Content-based image retrieval; Efficiency and effectiveness; Asymptotic
   complexity; Correlation analysis
ID ROTATION-INVARIANT; FEATURES; SCALE; CLASSIFICATION; REPRESENTATION;
   HISTOGRAMS
AB This paper presents a comparative study of color and texture descriptors considering the Web as the environment of use. We take into account the diversity and large-scale aspects of the Web considering a large number of descriptors (24 color and 28 texture descriptors, including both traditional and recently proposed ones). The evaluation is made on two levels: a theoretical analysis in terms of algorithms complexities and an experimental comparison considering efficiency and effectiveness aspects. The experimental comparison contrasts the performances of the descriptors in small-scale datasets and in a large heterogeneous database containing more than 230 thousand images. Although there is a significant correlation between descriptors performances in the two settings, there are notable deviations, which must be taken into account when selecting the descriptors for large-scale tasks. An analysis of the correlation is provided for the best descriptors, which hints at the best opportunities of their use in combination. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Penatti, Otavio A. B.; Valle, Eduardo; Torres, Ricardo da S.] Univ Campinas Unicamp, RECOD Lab, Inst Comp IC, Campinas, SP, Brazil.
   [Valle, Eduardo] Univ Campinas Unicamp, Sch Elect & Comp Engn FEEC, Dept Comp Engn & Ind Automat DCA, Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas; Universidade Estadual de Campinas
RP Penatti, OAB (corresponding author), Univ Campinas Unicamp, RECOD Lab, Inst Comp IC, Campinas, SP, Brazil.
EM penatti@ic.unicamp.br; dovalle@dca.fee.unicamp.br; rtorres@ic.unicamp.br
RI Torres, Ricardo da S./C-4526-2012
OI Torres, Ricardo/0000-0001-9772-263X; Alves do Valle Jr,
   Eduardo/0000-0001-5396-9868
FU Fapesp [2006/59525-1, 2007/52015-0, 2009/10554-8, 2009/18438-7,
   2009/05951-8]; CNPq; Capes; Microsoft Research; Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [09/18438-7] Funding Source:
   FAPESP
FX We would like to thank Fapesp (Grant Nos. 2006/59525-1, 2007/52015-0,
   2009/10554-8, 2009/18438-7, and 2009/05951-8), CNPq, Capes, and
   Microsoft Research for infrastructure and financial support. We thank
   the colleagues who have helped with the descriptors implementations. We
   also thank the researchers from Federal University of Amazonas (UFAM),
   Federal University of Minas Gerais (UFMG) and University of Campinas
   (Unicamp) who have given us the pool of queries to be used in our
   experiments.
CR Ahmad UA, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P67
   Annesley J., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P105
   [Anonymous], 1999, Visual Information Retrieval
   [Anonymous], J INFORM DATA MANAGE
   Barton S., 2010, ADAPTIVITY PERSONALI, P84
   Penatti OAB, 2008, SIBGRAPI, P163, DOI 10.1109/SIBGRAPI.2008.20
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Çarkacioglu A, 2003, PATTERN RECOGN, V36, P2615, DOI 10.1016/S0031-3203(03)00171-7
   Çarkacioglu A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P137, DOI 10.1109/ICIP.2001.958443
   Chaira T, 2005, FUZZY SET SYST, V150, P545, DOI 10.1016/j.fss.2004.09.003
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dengsheng Zhang, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P646
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Howarth P, 2004, LECT NOTES COMPUT SC, V3115, P326
   Huang CB, 2007, INT C COMMUN CIRCUIT, P772
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang PW, 2006, J VIS COMMUN IMAGE R, V17, P947, DOI 10.1016/j.jvcir.2005.08.005
   Janney P., 2007, P IEEE C COMP VIS PA, P1
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   Kiranyaz S, 2008, IEEE T IMAGE PROCESS, V17, P377, DOI 10.1109/TIP.2007.915562
   Kokare M, 2004, PATTERN RECOGN LETT, V25, P391, DOI 10.1016/j.patrec.2003.11.008
   Kovalev V, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P32, DOI 10.1109/MULMM.1998.722972
   Lee HY, 2003, IEEE T MULTIMEDIA, V5, P358, DOI 10.1109/TMM.2003.814792
   Lee KL, 2005, IMAGE VISION COMPUT, V23, P479, DOI 10.1016/j.imavis.2004.12.002
   Lei Zhang, 2007, 2007 8th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing, P798
   Lejsek H., 2006, ACM MULTIMEDIA '06, P589
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moghaddam HA, 2005, PATTERN RECOGN, V38, P2506, DOI 10.1016/j.patcog.2005.05.010
   Zegarra JAM, 2009, J COMPUT APPL MATH, V227, P294, DOI 10.1016/j.cam.2008.03.017
   Montoya-Zegarra JA, 2007, SIBGRAPI, P121, DOI 10.1109/SIBGRAPI.2007.42
   Montoya-Zegarra JA, 2008, IEEE INT SYM MULTIM, P148, DOI 10.1109/ISM.2008.113
   Nallaperumal K, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P185, DOI 10.1109/ICCIMA.2007.72
   Nevatia R., 1982, MACHINE PERCEPTION
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P1021, DOI 10.1109/ICPR.2002.1048479
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paschos G, 2003, IEEE T KNOWL DATA EN, V15, P1069, DOI 10.1109/TKDE.2003.1232264
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Penatti O. A., 2010, INT C MULT INF RETR, P413
   Ro YM, 2000, ELECTRON LETT, V36, P1268, DOI 10.1049/el:20000949
   Rubner Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1018, DOI 10.1109/ICCV.1999.790380
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Safar M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P141, DOI 10.1109/ICME.2000.869564
   Sim DG, 2004, IMAGE VISION COMPUT, V22, P331, DOI 10.1016/j.imavis.2003.11.003
   Sim DG, 2001, ELECTRON LETT, V37, P18, DOI 10.1049/el:20010035
   Stehling R. O., 2003, Knowledge and Information Systems, V5, P315, DOI 10.1007/s10115-003-0084-y
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   Stehling RO, 2001, 2001 INTERNATIONAL DATABASE ENGINEERING & APPLICATIONS SYMPOSIUM, PROCEEDINGS, P356, DOI 10.1109/IDEAS.2001.938104
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Sun JD, 2006, PATTERN RECOGN LETT, V27, P1122, DOI 10.1016/j.patrec.2005.12.014
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Torres R. S. D., 2006, RITA, V13, P161
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   Utenpattanant A., 2006, INT C ADV COMM TECHN, V1, P818
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang Q, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P462, DOI 10.1109/ISIMP.2004.1434100
   Wang Y., 2003, Proceedings of the eleventh ACM international conference on Multimedia, P323
   Williams A, 2007, MULTIMED TOOLS APPL, V34, P239, DOI 10.1007/s11042-006-0087-2
   Wong KM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P611
   Wu P, 2000, SIGNAL PROCESS-IMAGE, V16, P33, DOI 10.1016/S0923-5965(00)00016-3
   Xu F, 2006, J VIS COMMUN IMAGE R, V17, P701, DOI 10.1016/j.jvcir.2005.10.002
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Yang XY, 2002, PATTERN RECOGN LETT, V23, P93, DOI 10.1016/S0167-8655(01)00092-7
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhou J, 2003, PATTERN RECOGN, V36, P1061, DOI 10.1016/S0031-3203(02)00264-9
NR 80
TC 120
Z9 126
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 359
EP 380
DI 10.1016/j.jvcir.2011.11.002
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900013
DA 2024-07-18
ER

PT J
AU Pai, YS
   Shen, YC
   Wu, JL
AF Pai, Yu-Shan
   Shen, Yun-Chung
   Wu, Ja-Ling
TI High efficient distributed video coding with parallelized design for
   LDPCA decoding on CUDA based GPGPU
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding (DVC); Ladder Step Size Request (LSSR); LDPC
   Accumulate (LDPCA); General Purpose Graphics Processing Unit (GPGPU);
   CUDA; Wyner-Ziv; Slepian-Wolf; Accumulated parity check matrix
ID SIDE INFORMATION
AB Distributed video coding (DVC) is a new coding paradigm targeting on applications with the need of low-complexity and/or low-power encoding at the cost of a high-complexity decoding. In the DVC architectures based on Error Control Codes (ECCs) with a feedback channel, the high decoding complexity comes from the decode-check-request iterations between the ECC encoder and the ECC decoder. In this paper, a parallel message-passing decoding algorithm for computing low density parity check (LDPC) syndromes is applied through the Compute Unified Device Architecture (CUDA) based on General Purpose Graphics Processing Unit (GPGPU). Furthermore, we proposed a novel rate control mechanism, dubbed as the Ladder Step Size Request (LSSR), to reduce the number of requests which leads to much speedup gain. Experimental results show that, through our work, the overall DVC decoding speedup gain can reach 46.52 with only 0.2 dB rate distortion performance loss. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Pai, Yu-Shan; Wu, Ja-Ling] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
   [Shen, Yun-Chung; Wu, Ja-Ling] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Pai, YS (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
EM shockeita@cmlab.csie.ntu.edu.tw; cazindo@cmlab.csie.ntu.edu.tw;
   wjl@cmlab.csie.ntu.edu.tw
OI WU, JA-LING/0000-0002-3631-1551
CR Aaron A, 2002, CONF REC ASILOMAR C, P240
   ARTIGAS X, 2007, PICT COD S
   Ascenso J, 2007, IEEE IMAGE PROC, P1157
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   DUFAUX F, 2010, EURASIP J IMAGE VIDE, V2009
   Dufaux F., 2009, EURASIP J IMAGE VIDE
   Falcao G, 2008, PPOPP'08: PROCEEDINGS OF THE 2008 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P83, DOI 10.1145/1345206.1345221
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   IVKOVIC M, 2007, INF THEOR 2007 ISIT, P2266
   Liveris AD, 2002, IEEE COMMUN LETT, V6, P440, DOI 10.1109/LCOMM.2002.804244
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tonomura Y, 2009, IEICE T FUND ELECTR, VE92A, P2463, DOI 10.1587/transfun.E92.A.2463
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   DISCOVER TEST MAT
NR 15
TC 7
Z9 8
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 63
EP 74
DI 10.1016/j.jvcir.2011.08.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100007
DA 2024-07-18
ER

PT J
AU Deng, CW
   Lin, WS
   Lee, BS
   Lau, CT
   Sun, MT
AF Deng, Chenwei
   Lin, Weisi
   Lee, Bu-sung
   Lau, Chiew Tong
   Sun, Ming-Ting
TI Performance analysis, parameter selection and extensions to H.264/AVC
   FRExt for high resolution video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC FRExt; Motion JPEG 2000; Video coding; Inter-frame coding;
   Intra-frame coding; High resolution; Digital cinema; Residual entropy
ID TRANSFORM
AB H.264/AVC FRExt (Fidelity Range Extensions) and Motion JPEG 2000 are the current respective inter-frame and intra-frame coding standards for high resolution (HR) (e.g., 4096 x 2160) visual signals. It is commonly believed that an inter-frame method could achieve higher coding efficiency compared with an intra-frame one, due to the exploitation of video temporal redundancy. However, Motion JPEG 2000 has been selected as the digital cinema compression standard, and some existing work has demonstrated that JPEG 2000 is more suitable at HR situations. In this paper, we compare the rate-distortion (R-D) performance of these two different schemes and give more insight from both theoretical and experimental point of view. We derive an entropy-based R-D model to analyze the test results and the impact of residual entropy and quantization for inter-frame coding. Several extensions are introduced into H.264/AVC FRExt for HR video content for better performance. Experimental results show that these extensions lead to significantly higher coding efficiency and make our extended version more suitable for HR video coding (C) 2011 Elsevier inc. All rights reserved.
C1 [Deng, Chenwei; Lin, Weisi; Lee, Bu-sung; Lau, Chiew Tong] Nanyang Technol Univ, Singapore 639798, Singapore.
   [Sun, Ming-Ting] Univ Washington, Seattle, WA 98195 USA.
C3 Nanyang Technological University; University of Washington; University
   of Washington Seattle
RP Lin, WS (corresponding author), Nanyang Technol Univ, Singapore 639798, Singapore.
EM wslin@ntu.edu.sg
RI Lee, Francis BS/G-9323-2014; Lin, Weisi/A-3696-2011; Liu,
   Kai/IST-6808-2023; Liu, Anmin/A-4730-2012; Lin, Weisi/A-8011-2012
OI Lee, Francis BS/0000-0001-7828-7900; Lin, Weisi/0000-0001-9866-1947; 
FU MoE AcRF Tire 2, Singapore [T208B1218]
FX This work is supported by MoE AcRF Tire 2, Singapore, Grant No.
   T208B1218.
CR Al A, 2004, IEEE IMAGE PROC, P525, DOI 10.1109/ICIP.2004.1418806
   [Anonymous], 1997, Gabor Analysis and Algorithms: Theory and Applications
   [Anonymous], 2004, 154441 ISOIEC
   [Anonymous], 2002, OV MPEG 4 STAND
   [Anonymous], TEST MEDIA
   Baruffa G., 2009, IEEE INT C DSP JUL, P11
   Bjontegaard G., 2001, VCEG CONTRIBUTION VC
   Bojkovic Z, 2009, TELSIKS 2009, VOLS 1 AND 2, P273, DOI 10.1109/TELSKS.2009.5339537
   Camperi G., H 264 AVC INTRACODIN
   Chang CL, 2010, IEEE T IMAGE PROCESS, V19, P1740, DOI 10.1109/TIP.2010.2044964
   Dai Y.Y., 2007, IEEE INT C IM PROC I, V1, P421
   DCI, 2008, DCI DIG CIN SYST SPE
   Dettmer R, 2003, IEE REVIEW, V49, P46, DOI 10.1049/ir:20031008
   Dong J, 2009, IEEE T CIRC SYST VID, V19, P1462, DOI 10.1109/TCSVT.2009.2026792
   International Telecommunication Union Telecommunication Standardization Sector (ITU-T) and International Organization for Standardization/International Electrotechnical Commission (ISO/IEC) JTC 1, 2005, ADV VID COD GEN AUD
   Jayant N.S, 2007, DIGITAL CODING WAVEF
   Kamisli F, 2010, INT CONF ACOUST SPEE, P738, DOI 10.1109/ICASSP.2010.5495034
   Kamisli F, 2009, INT CONF ACOUST SPEE, P789, DOI 10.1109/ICASSP.2009.4959702
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   Mame D., 2005, IEEE INT C IM PROC I, V1, P5936
   Marpe D, 2003, PROC SPIE, V5266, P129
   Pinson MH, 2010, IEEE T BROADCAST, V56, P86, DOI 10.1109/TBC.2009.2034511
   Shi BX, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P725, DOI 10.1109/ICME.2008.4607537
   Smith M., 2004, SMPTE TECHN C EXH 20, P1
   Suehring K., H 264 AVC REFERENCE
   Sullivan G., 2004, SPIE C APPL DIGITAL, V5558, P53
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   Sullivan GJ, 1996, IEEE T INFORM THEORY, V42, P1365, DOI 10.1109/18.532878
   Sun MT, 1998, J VIS COMMUN IMAGE R, V9, P163, DOI 10.1006/jvci.1998.0381
   Taubman D., KAKADU REFERENCE SOF
   Zeng B, 2008, IEEE T CIRC SYST VID, V18, P305, DOI 10.1109/TCSVT.2008.918455
   Zeng JF, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P415, DOI 10.1109/ICME.2004.1394217
NR 32
TC 10
Z9 13
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 749
EP 759
DI 10.1016/j.jvcir.2011.01.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200008
DA 2024-07-18
ER

PT J
AU Wang, H
   Xiao, S
   Kuo, CCJ
AF Wang, Hui
   Xiao, Song
   Kuo, C. -C. Jay
TI Random linear network coding with ladder-shaped global coding matrix for
   robust video transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Network coding; H.264/SVC; Unequal erasure protection (UEP); Random
   linear network coding (RLNC); Video multicast; Ladder-shaped global
   coding matrix (LGCM); Video quality; Robust video transmission
AB Robust video multicast in erasure networks using network coding (NC) to reduce the impact of packet loss is studied in this paper. In our proposed solution, random linear network coding (RLNC) is adopted at intermediate nodes of the network. RLNC linearly combines a group of packets by randomly selecting weighting coefficients on a finite field, and the loss of an RLNC-coded packet is equivalent to the loss of one constraint in a linear system of equations required for RLNC decoding. Unless the global coding coefficient matrix, or simply called the global coding matrix (GCM), is of full rank, a receive node cannot reconstruct all source packets. To address this rank deficiency problem, we propose to construct a special-structured GCM, called the ladder-shaped GCM (LGCM), for layered H.264/SVC (scalable video coding) video multicast. The ladder shape of the sparse coding matrix is maintained throughout the RLNC process to achieve two objectives: (1) to enable partial decoding of a block; and (2) to provide unequal erasure protection for H.264/SVC priority layers. Furthermore, quality degradation is minimized by optimizing the amount of redundancy assigned to each layer, and graceful quality degradation is achieved by error concealment (EC). Simulation results are given to demonstrate the superior performance of the proposed RLNC-LGCM scheme over the traditional RLNC with a general GCM. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Wang, Hui; Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Wang, Hui; Kuo, C. -C. Jay] Univ So Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
   [Xiao, Song] Xidian Univ, ISN Key Lab, Xian 710071, Shanxi, Peoples R China.
C3 University of Southern California; University of Southern California;
   Xidian University
RP Wang, H (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM wanghui@usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU National Natural Science Foundation of China [60702058, 60532060,
   60832001]; 111 project [B08038]
FX This work is supported by the National Natural Science Foundation of
   China under Grant Nos. 60702058, 60532060 and 60832001 and the 111
   project under Grand No. B08038.
CR Acedanski S., 2005, NETCOD
   Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   [Anonymous], 2007, IEEE T CIRCUITS SYST
   [Anonymous], P 5 INT C MOB UB MUL
   [Anonymous], 2003, P ANN ALL C COMM CON
   CAI N, 2006, COMMUNICATIONS INFOR
   Chou P. A., 2003, 51 ALL C COMM CONTR
   DEB S, 2005, IEEE INFOCOM 2005 MA
   Gkantsidis C, 2005, IEEE INFOCOM SER, P2235
   GOMEZBARQUERO D, 2007, IEEE 65 VEH TECHN C
   HO T, 2005, IEEE T INFORM TH MAR
   *JVSM SOFTW, 2006, JOINT SCAL VID MOD J
   KAI X, 2006, J ZHEJIANG U SCI A, V5
   KIM JG, 2001, C VID TECHN MULT APP
   LIMA L, 2007, IEEE INT S INF THEOR
   Luby M, 2006, CONSUM COMM NETWORK, P192
   LUN D, 2004, P 42 ANN ALL C COMM
   Lun DS, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY (ISIT), VOLS 1 AND 2, P1848
   LUN DS, 2006, P 4 INT S MOD OPT MO
   NYBOM K, 2007, SURVEY APPL LAYER FO
   PAKZAD P, 2005, ISIT AUG
   SHIN J, 2001, IEEE T MULTIMEDI JUN
   WU Y, 2005, IEEE T COMMUNICA NOV
   WU Y, 2005, IEEE J SELECTED AREA
   WU Y, 2007, IEEE SIGNAL PROCESSI
   WU YN, 2005, THESIS PRINCETON U
   Yeung R. W., 2006, COMMUNICATIONS INFOR
   ZHANG Z, 2008, IEEE T INFORM THEORY, P54
NR 28
TC 10
Z9 13
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 203
EP 212
DI 10.1016/j.jvcir.2010.08.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300001
DA 2024-07-18
ER

PT J
AU Qi, XJ
   Xin, X
AF Qi, Xiaojun
   Xin, Xing
TI A quantization-based semi-fragile watermarking scheme for image content
   authentication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Authentication measures; Error map; Quantization; Semi-fragile
   watermarking; Wavelet transform; Tampered error pixels; Tampering
   detection sensitivity; Localization capability
AB This paper presents a novel semi-fragile watermarking scheme for image content authentication with tampering localization. The proposed scheme uses a non-traditional quantization method to modify one chosen approximation coefficient of each non-overlapping block to ensure its robustness against incidental attacks and fragileness against malicious attacks. The image content authentication starts with extracting watermark using the parity of quantization results from the probe image, where the round operation is used to ensure the semi-fragile property. It then constructs a binary error map and computes two authentication measures with M-1 measuring the overall similarity between extracted and embedded watermarks and M-2 measuring the overall clustering level of tampered error pixels. These two measures are further integrated to confirm the image content and localize the possible tampered areas. Our experimental results show that our scheme outperforms four peer schemes and is capable of identifying intentional tampering and incidental modification, and localizing tampered regions. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Qi, Xiaojun; Xin, Xing] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
C3 Utah System of Higher Education; Utah State University
RP Qi, XJ (corresponding author), Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
EM Xiaojun.Qi@usu.edu
CR [Anonymous], P 3 INT S INF ASS SE
   Che SB, 2007, INT C WAVEL ANAL PAT, P382
   Cruz C, 2008, MIDWEST SYMP CIRCUIT, P306, DOI 10.1109/MWSCAS.2008.4616797
   Eggers JJ, 2001, INT CONF ACOUST SPEE, P1977, DOI 10.1109/ICASSP.2001.941335
   Ekici Ö, 2004, J ELECTRON IMAGING, V13, P209, DOI 10.1117/1.1633285
   FRIDRICH J, 1999, P 5 INT S SIGN PROC, V1, P301
   Ho CK, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P7
   HSIEH M, 2004, ELECTRON COMMER RES, P157
   Hu YP, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5484
   Kang H., 2003, Proc. of STEG, P127
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   LAN T, 2001, P IEEE INT C AC SPEE, P581
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   Liu HM, 2005, IEEE INT SYMP CIRC S, P4014
   Liu T, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1556, DOI 10.1109/ICOSP.2002.1180093
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Qi XJ, 2007, SIGNAL PROCESS, V87, P1264, DOI 10.1016/j.sigpro.2006.11.002
   UHL A, 2004, ADV INFORM SECURITY, P103
   Yang HF, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P1112
   Yu GJ, 2001, OPT ENG, V40, P1396, DOI 10.1117/1.1384885
   Zhou X, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P374
NR 24
TC 71
Z9 77
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 187
EP 200
DI 10.1016/j.jvcir.2010.12.005
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600008
DA 2024-07-18
ER

PT J
AU Chu, WT
   Li, CJ
   Tseng, SC
AF Chu, Wei-Ta
   Li, Cheng-Jung
   Tseng, Sheng-Chun
TI Travelmedia: An intelligent management system for media captured in
   travel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Travel media management; Representative selection; Region of interest;
   Face clustering; Video scene detection; Photo browsing; Vector space
   model; Visual words
ID VISUAL-ATTENTION; FACE RECOGNITION; VIDEO-RETRIEVAL; SEGMENTATION; TEXT
AB A media management system exploiting characteristics of travel media is designed to facilitate efficient management and browsing. According to travel schedules, travel media often have implicit thematic structure. Correlation between different modalities also provides implicit cues to media analysis. In this system, we exploit techniques of near-duplicate detection to select representative photos, and determine region-of-interest in photos to enhance browsing experience. For face-name association, a face clustering module based on visual language models is constructed. To systematically segment travel videos of bad visual quality and significant motion, we explore correlation between photos and videos based on approximate visual word histogram matching. Experimental results demonstrate the effectiveness of the proposed approaches and show that they are practical functions. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Chu, Wei-Ta; Li, Cheng-Jung; Tseng, Sheng-Chun] Natl Chung Cheng Univ, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, 168 Univ Rd, Chiayi 621, Taiwan.
EM wtchu@cs.ccu.edu.tw; zoneli1987@gmail.com; bittertea0503@gmail.com
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU National Science Council of Taiwan, Republic of China [NSC
   99-2221-E-194-036, NSC 98-2221-E-194-056]
FX The authors would like to thank Chia-Hung Lin, Ya-Lin Lee, and Che-Cheng
   Lin for their efforts on preliminary results of this work. The authors
   would also like to thank anonymous reviewers for giving valuable
   comments. The work was partially supported by the National Science
   Council of Taiwan, Republic of China under research contract NSC
   99-2221-E-194-036 and NSC 98-2221-E-194-056.
CR Ahern S, 2007, ACM-IEEE J CONF DIG, P1, DOI 10.1145/1255175.1255177
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], The color feret database
   [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], TREC VIDEO RETRIEVAL
   [Anonymous], 2007, P INT WORKSHOP WORKS
   [Anonymous], P 17 ACM INT C MULT
   BERG TL, 2004, P IEEE COMP SOC C CO
   Chasanis V, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P187, DOI 10.1109/MMSP.2007.4412849
   Chen JJ, 2008, IEEE INT SYM MULTIM, P23, DOI 10.1109/ISM.2008.104
   Cheng WH, 2008, IEEE T CIRC SYST VID, V18, P1639, DOI 10.1109/TCSVT.2008.2005608
   Cheng WH, 2005, IEICE T INF SYST, VE88D, P1578, DOI 10.1093/ietisy/e88-d.7.1578
   Chu W.T., 2009, P ACM INT C IM VID R
   Chu WT, 2010, J VIS COMMUN IMAGE R, V21, P256, DOI 10.1016/j.jvcir.2010.01.006
   CHU WT, 2009, P ACM MULT C, P625
   Cooper M, 2005, ACM T MULTIM COMPUT, V1
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Girgensohn A, 2000, MULTIMED TOOLS APPL, V11, P347, DOI 10.1023/A:1009630817712
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang W, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P313, DOI 10.1109/ICME.2008.4607434
   Jing Yushi., 2007, P 6 ACM INT C IMAGE, P280
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Liu H., 2010, P IEEE C COMP VIS PA
   Lopez Jose., 2000, SOCIAL STRUCTURE
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Ozkan D, 2010, PATTERN RECOGN, V43, P1717, DOI 10.1016/j.patcog.2009.10.015
   Pham PT, 2010, IEEE T MULTIMEDIA, V12, P13, DOI 10.1109/TMM.2009.2036232
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Stone Z, 2010, P IEEE, V98, P1408, DOI 10.1109/JPROC.2010.2044551
   Sundaram H., 2000, Proceedings ACM Multimedia 2000, P95, DOI 10.1145/354384.354440
   Vendrig J, 2002, IEEE T MULTIMEDIA, V4, P492, DOI 10.1109/TMM.2002.802021
   Vinciarelli Alessandro., 2007, Proceedings of the 15th international conference on Multimedia, MULTIMEDIA '07, P261, DOI DOI 10.1145/1291233.1291287
   Wang J., 2002, P ACM MULT, P243
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Yuan JS, 2007, IEEE I CONF COMP VIS, P321
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
NR 50
TC 5
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 93
EP 104
DI 10.1016/j.jvcir.2010.10.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300009
DA 2024-07-18
ER

PT J
AU Wang, YF
   Mao, XN
   He, Y
AF Wang, Yunfei
   Mao, Xunan
   He, Yun
TI A dual quad-tree based variable block-size coding method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding structure; Hybrid coding; Variable block-size coding; Dual
   quad-tree; DQTC; Transform; Prediction; Low complexity
ID DISCRETE COSINE TRANSFORM; H.264/AVC; COMPLEXITY; VIDEO
AB Recent video coding standards with hybrid structure adopt variable block-size processing techniques including variable block-size motion estimation and compensation, variable block-size intra prediction, and variable block-size transform. This paper gives analysis on the variable block-size techniques based on software simulations, and variable block-size transform is specially studied. As a result of the analysis, a generalized dual quad-tree based variable block-size coding (DQTC) structure is proposed. This structure also shows good flexibility and expansibility, in which the prediction block-size set and the transform block-size set can be configured according to requirements and the implementation complexity constraints. Simulation results show a considerable performance improvement for the proposed structure with low implementation complexity while the coding block-size sets and parameters are optimized. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Wang, Yunfei; Mao, Xunan; He, Yun] Tsinghua Univ, State Key Lab Microwave & Digital Commun, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, YF (corresponding author), Tsinghua Univ, State Key Lab Microwave & Digital Commun, Tsinghua Natl Lab Informat Sci & Technol, Dept Elect Engn, Beijing 100084, Peoples R China.
EM wangyf03@mails.tsinghua.edu.cn; mxn03@mails.tsinghua.edu.cn;
   hey@tsinghua.edu.cn
RI he, yun/JMB-6362-2023
FU Chinese 973 project [2009CB320903]
FX This work is supported by the Chinese 973 project 2009CB320903.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   AN D, AVS 29 M 2009
   [Anonymous], 2003, ADV VID COD GEN AUD
   *AVS VID EXP GROUP, 2009, AVS REF SOFTW RM6 2K
   *AVS VID EXP GROUP, 2009, AVS 29 M JUN
   *AVS VID EXP GROUP, 2007, AVS 22 M SEPT
   Bjontegaard G., 2001, VCEG 13 M AUST TX US
   CHAM WK, 1989, DEVELOPMENT, V136, P276
   Chen C.-T., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1854, DOI 10.1109/ICASSP.1989.266814
   CHEN T, 2004, JVT 11 M MUN DE MARC
   CHEN TC, 2006, P 2006 C AS S PAC DE, P570
   CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   GORDON S, 2004, JVT 11 M MUN MARCH
   GUICHARD J, 1987, PCS 87 JUN, P23
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   *JVT, 2007, JM JOINT MOD JOINT V
   Li Y, 2008, J SIGNAL PROCESS SYS, V50, P19, DOI 10.1007/s11265-007-0111-4
   Malvar H., 2003, IEEE Trans. Circuits and Systems for Video Technology, V13
   MAO X, 2008, P INT VID COD VID PR
   MAO X, 2008, AVS 25 M JUN
   PURI A, 1987, P IEEE GLOB TEL C GL, P65
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   SULLIVAN GJ, 1991, P GLOBECOM 91 PHOEN, P85
   TAN TK, 2008, VCEG 35 M BERL GERM
   Vaisey D, 1987, IEEE INT C AC SPEECH, V12, P1051
   VAISEY D, 1992, IEEE T SIGNAL PROCES, V40, P2040
   Wien M, 2003, IEEE T CIRC SYST VID, V13, P604, DOI 10.1109/TCSVT.2003.815380
   WIEN M, 2002, JVT 5 M GEN DEC
   WIEN M, 2002, JVT 3 M FAIRF VA MAY
   WOODS LW, 1969, S PICT BANDW COMPR M
   Yu L, 2005, P SOC PHOTO-OPT INS, V5960, P679, DOI 10.1117/12.632515
   ZHENG X, 2008, P INT VID COD VID PR
NR 32
TC 3
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 889
EP 899
DI 10.1016/j.jvcir.2010.08.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500013
DA 2024-07-18
ER

PT J
AU Chao, GC
   Tsai, YP
   Jeng, SK
AF Chao, Gwo-Cheng
   Tsai, Yu-Pao
   Jeng, Shyh-Kang
TI Augmented keyframe
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Keyframe; Video abstraction; Video summarization; Surveillance video;
   Object tracking; Content extraction; Content synthesis; Motion analysis
ID KEY-FRAME-EXTRACTION; VIDEO
AB In surveillance applications, keyframes are usually used to summarize important video contents. However, most traditional keyframe extraction approaches just select some video frames from the input video, while the information in these selected video frames are insufficient and cannot let the users perceive the events happened in the original video easily. In this paper, we propose a novel keyframe generating technique to condense the contents of a surveillance video clip captured by a static camera into a still picture (augmented keyframe). The augmented keyframe is a more meaningful keyframe augmented with representative objects, important contents (human faces, license plate, etc.), motion status (represented as icons) and some marks of the moving objects in a still picture. This new technique consists of two major phases: content extraction and content synthesis. Some testing results of the proposed augmented keyframe are also presented and compared with results obtained by the traditional keyframe approach. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Chao, Gwo-Cheng; Jeng, Shyh-Kang] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 106, Taiwan.
   [Tsai, Yu-Pao] MediaTek Inc, Adv Technol Dev Div, Hsinchu, Taiwan.
   [Jeng, Shyh-Kang] Natl Taiwan Univ, Dept Elect Engn, Taipei 106, Taiwan.
C3 National Taiwan University; Mediatek Incorporated; National Taiwan
   University
RP Chao, GC (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, 1,Sec 4,Roosevelt Rd, Taipei 106, Taiwan.
EM d93944003@ntu.edu.tw
OI Jeng, Shyh-Kang/0000-0001-8960-9995
CR [Anonymous], P INT WORKSH REAL TI
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   CHANG IC, 2007, P IEEE INT C CONS EL, P1
   Chiu P, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2059, DOI 10.1109/ICME.2004.1394670
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Fielding Raymond., 1972, The Technique of Special Effects Cinematography
   Girgensohn A, 2001, COMPUTER, V34, P61, DOI 10.1109/2.947093
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   KANG HW, 2006, P IEEE C COMP VIS PA, P1331
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Liu LJ, 2005, IEEE T CIRC SYST VID, V15, P869, DOI 10.1109/TCSVT.2005.848347
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Pritch Y, 2007, IEEE I CONF COMP VIS, P833
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun J, 2006, LECT NOTES COMPUT SC, V3952, P628
   Sze KW, 2005, IEEE T CIRC SYST VID, V15, P1148, DOI 10.1109/TCSVT.2005.852623
   Taniguchi Y., 1995, MULTIMEDIA 95 P 3 AC, P25
   TONOMURA Y, 1993, P INTERCHI 93, P131
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   VLAHOS J., 2008, Popular Mechanics, V185, P64
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
NR 33
TC 8
Z9 9
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 682
EP 692
DI 10.1016/j.jvcir.2010.05.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400008
DA 2024-07-18
ER

PT J
AU Khan, US
   Al-Nuaimy, W
   Abd El-Samie, FE
AF Khan, Umar S.
   Al-Nuaimy, Waleed
   Abd El-Samie, Fathi E.
TI Detection of landmines and underground utilities from acoustic and GPR
   images with a cepstral approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Landmine detection; GPR; Acoustic images; MFCCs; Polynomial
   coefficients; Discrete cosine transform (DCT); Discrete sine transform
   (DST); Discrete wavelet transform (DWT)
ID GROUND-PENETRATING RADAR; LAND MINE DETECTION; FEATURE-SELECTION;
   SPEECH; COEFFICIENTS
AB This paper introduces a cepstral approach for the automatic detection of landmines and underground utilities from acoustic and ground penetrating radar (GPR) images. This approach is based on treating the problem as a pattern recognition problem. Cepstral features are extracted from a group of images, which are transformed first to 1-D signals by lexicographic ordering. Mel-frequency cepstral coefficients (MFCCs) and polynomial shape coefficients are extracted from these 1-D signals to form a database of features, which can be used to train a neural network with these features. The target detection can be performed by extracting features from any new image with the same method used in the training phase. These features are tested with the neural network to decide whether a target exists or not. The different domains are tested and compared for efficient feature extraction from the lexicographically ordered 1-D signals. Experimental results show the success of the proposed cepstral approach for landmine detection from both acoustic and GPR images at low as well as high signal to noise ratios (SNRs). Results also show that the discrete cosine transform (DCT) is the most appropriate domain for feature extraction. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Abd El-Samie, Fathi E.] Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
   [Khan, Umar S.; Al-Nuaimy, Waleed] Univ Liverpool, Dept Elect Engn & Elect, Liverpool L69 3BX, Merseyside, England.
C3 Egyptian Knowledge Bank (EKB); Menofia University; University of
   Liverpool
RP Abd El-Samie, FE (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Elect & Elect Commun, Menoufia 32952, Egypt.
EM fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Shahbaz Khan, Umar/0000-0002-5263-1408
CR Abujarad F, 2004, PROCEEDINGS OF THE TENTH INTERNATIONAL CONFERENCE ON GROUND PENETRATING RADAR, VOLS 1 AND 2, P697
   Al-Nuaimy W, 2000, J APPL GEOPHYS, V43, P157, DOI 10.1016/S0926-9851(99)00055-5
   Al-Nuaimy W, 2000, APPL PHYS LETT, V77, P1230, DOI 10.1063/1.1289267
   ALNUAIMY W, 1999, THESIS U LIVERPOOL
   [Anonymous], 2007, Neural networks theory
   BROOKES JW, 2000, THESIS U ALABAMA HUN
   BRUNZELL H, 1997, IEEE RADAR, V97, P688
   Bruschini C, 1998, J APPL GEOPHYS, V40, P59, DOI 10.1016/S0926-9851(97)00038-4
   Chengalvarayan R, 1998, IEEE T SPEECH AUDI P, V6, P505, DOI 10.1109/89.725317
   Clark GA, 2000, IEEE T GEOSCI REMOTE, V38, P304, DOI 10.1109/36.823923
   Daniels D., 2004, Ground Penetrating Radar
   Dharanipragada S, 2007, IEEE T AUDIO SPEECH, V15, P224, DOI 10.1109/TASL.2006.876776
   Dreyfus G., 2005, NEURAL NETWORKS METH, DOI DOI 10.1007/3-540-28847-3
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   Gandhiraj R, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P666, DOI 10.1109/ADCOM.2007.104
   GODRDON A, 1999, CLASSIFICATION
   Groenenboom J., 2002, SUBSURFACE SENSING T, V3, P387
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kasban H., 2009, Progress In Electromagnetics Research C, V6, P79, DOI 10.2528/PIERC08112002
   Kasban H, 2008, IEEE INT C COMP ENG
   Katsamanis A, 2009, IEEE T AUDIO SPEECH, V17, P411, DOI 10.1109/TASL.2008.2008740
   Kinnunen T., 2003, THESIS U JOENSUU FIN
   PAOLA JD, 1995, IEEE T GEOSCI REMOTE, V33, P981, DOI 10.1109/36.406684
   Polur PD, 2005, IEEE T NEUR SYS REH, V13, P558, DOI 10.1109/TNSRE.2005.856074
   SARIKAYA R, 2001, THESIS DUKE U
   SHIHAB S, 2005, THESIS U LIVERPOOL
   Su Z, 2000, OPT ENG, V39, P2472, DOI 10.1117/1.1288364
   Tufekci Z., 2001, THESIS CLEMSON U
   Vergin R, 1999, IEEE T SPEECH AUDI P, V7, P525, DOI 10.1109/89.784104
   Wang TP, 2007, IEEE T GEOSCI REMOTE, V45, P718, DOI 10.1109/TGRS.2006.888142
   Xiang N, 2000, P SOC PHOTO-OPT INS, V4038, P645, DOI 10.1117/12.396292
   XIANG N, 2003, J ACOUSTICAL SOC AM, V113
   ZHENGOU Z, 2008, ICMMT P
NR 33
TC 26
Z9 32
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 731
EP 740
DI 10.1016/j.jvcir.2010.05.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400012
DA 2024-07-18
ER

PT J
AU Du, SY
   Zheng, NN
   Xiong, L
   Ying, SH
   Xue, JR
AF Du, Shaoyi
   Zheng, Nanning
   Xiong, Lei
   Ying, Shihui
   Xue, Jianru
TI Scaling iterative closest point algorithm for registration of
   <i>m</i>-<i>D</i> point sets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Iterative closest point (ICP); Singular value decomposition (SVD);
   Properties of parabola; Scaling registration; Point set registration;
   Iterative algorithm; Local convergence; Covariance matrix
ID FORM SOLUTION; 3D; MATRIX
AB Point set registration is important for calibration of multiple cameras, 3D reconstruction and recognition, etc. The iterative closest point (ICP) algorithm is accurate and fast for point set registration in a same scale, but it does not handle the case with different scales. This paper instead introduces a novel approach named the scaling iterative closest point (SICP) algorithm which integrates a scale matrix with boundaries into the original ICP algorithm for scaling registration. At each iterative step of this algorithm, we set up correspondence between two m-D point sets, and then use a simple and fast iterative algorithm with the singular value decomposition (SVD) method and the properties of parabola incorporated to compute scale, rotation and translation transformations. The SICP algorithm has been proved to converge monotonically to a local minimum from any given parameters. Hence, to reach desired global minimum, good initial parameters are required which are successfully estimated in this paper by analyzing covariance matrices of point sets. The SICP algorithm is independent of shape representation and feature extraction, and thereby it is general for scaling registration of m-D point sets. Experimental results demonstrate its efficiency and accuracy compared with the standard ICP algorithm. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Du, Shaoyi; Zheng, Nanning; Xue, Jianru] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
   [Xiong, Lei] AF Engn Univ, Sch Engn, Xian 710049, Peoples R China.
   [Ying, Shihui] Shanghai Univ, Sch Sci, Dept Math, Shanghai 200444, Peoples R China.
C3 Xi'an Jiaotong University; Air Force Engineering University; Shanghai
   University
RP Du, SY (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Peoples R China.
EM dushaoyi@gmail.com; nnzheng@aiar.xjtu.edu.cn; lei.xiong12@gmail.com;
   yingshihui@gmail.com; jrxuester@gmail.com
RI Ying, Shihui/G-6411-2011; Xue, Jianru/N-3923-2014
CR Almhdie A, 2007, PATTERN RECOGN LETT, V28, P1523, DOI 10.1016/j.patrec.2007.03.005
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Fitzgibbon AW, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P662, DOI 10.1109/ICCV.2001.937584
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Jost T, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427, DOI 10.1109/IM.2003.1240278
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lee BU, 2000, IEEE T PATTERN ANAL, V22, P1205, DOI 10.1109/34.879805
   Lorusso A, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P237
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Minguez J, 2006, IEEE T ROBOT, V22, P1047, DOI 10.1109/TRO.2006.878961
   Shaoyi Du, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P193
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   WALKER MW, 1991, CVGIP-IMAG UNDERSTAN, V54, P358, DOI 10.1016/1049-9660(91)90036-O
   Zha HB, 2000, IEEE SYS MAN CYBERN, P1495, DOI 10.1109/ICSMC.2000.886066
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zinsser T., 2005, INT C PATT REC IM PR, P116
NR 23
TC 77
Z9 99
U1 0
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 442
EP 452
DI 10.1016/j.jvcir.2010.02.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600007
DA 2024-07-18
ER

PT J
AU Muñoz-Salinas, R
   Medina-Carnicer, R
   Madrid-Cuevas, FJ
   Carmona-Poyato, A
AF Munoz-Salinas, Rafael
   Medina-Carnicer, R.
   Madrid-Cuevas, F. J.
   Carmona-Poyato, A.
TI People detection and tracking with multiple stereo cameras using
   particle filters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Plan-view maps; Stereo vision; Person tracking; Particle filtering;
   Colour processing; Condensation algorithm; Person detection; Gesture
   recognition
ID INTEGRATED PERSON TRACKING
AB In this work, a novel approach for people detection and tracking using multiple stereo cameras is proposed. Our proposal consists in combining information from all the available cameras using three different plan-view maps. Occupancy and height maps register the volume and height of the objects that are visible in the stereo cameras, respectively. We also propose the use of a novel map, named confidence map, which registers the confidence of the information projected in each cell. The proposed confidence map is employed to fuse the information captured by each camera so that the most reliable information is kept in each cell. We then propose a particle filter algorithm for tracking people in the fused plan-view maps. The observation model employed considers height, occupancy and confidence information so that information from the most reliable camera is employed at each time instant. The experiments conducted show the validity of our proposal. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Munoz-Salinas, Rafael; Medina-Carnicer, R.; Madrid-Cuevas, F. J.; Carmona-Poyato, A.] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
EM rmsalinas@uco.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Medina-Carnicer, Rafael/G-3401-2015;
   Carmona-Poyato, Angel/G-1593-2015; Madrid-Cuevas, Francisco
   Jose/H-1396-2015
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Medina-Carnicer,
   Rafael/0000-0003-4481-0614; Carmona-Poyato, Angel/0000-0002-8820-8396;
   Madrid-Cuevas, Francisco Jose/0000-0001-6557-7431
FU Spanish Ministry of Science and Technology [DPI2006-02608,
   TIN2007-66367]; FEDER
FX This work has been carried out with the support of the Research Projects
   DPI2006-02608 and TIN2007-66367 funded by the Spanish Ministry of
   Science and Technology and FEDER.
CR [Anonymous], OPENCV OP SOURC COMP
   Beymer D, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P127, DOI 10.1109/HUMO.2000.897382
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   CHECKA N, 2003, C COMP VIS PATT REC, P100
   CIPOLLA R, 1990, IMAGE VISION COMPUT, V8, P85, DOI 10.1016/0262-8856(90)90061-9
   Darrell T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P628, DOI 10.1109/ICCV.2001.937685
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   Du W, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P165
   Eklundh Janolof., 1996, BMVC, P1
   FRANKLIN D, 1996, INT C AUT FAC GEST R, P14
   GORDON N, 1995, J GUID CONTROL DYNAM, V18, P1434, DOI 10.2514/3.21565
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Harville M, 2004, PROC CVPR IEEE, P398
   Harville M, 2004, IMAGE VISION COMPUT, V22, P127, DOI 10.1016/j.imavis.2003.07.009
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Hayashi K, 2006, LECT NOTES COMPUT SC, V3851, P359
   Hayashi K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P681, DOI 10.1109/AFGR.2004.1301613
   Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1996, ECCV, P343
   Kahn RE, 1996, PROC CVPR IEEE, P734, DOI 10.1109/CVPR.1996.517154
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   LUNGH R, 2007, P IEEE RSJ INT C INT, P3403
   MITTAL A, 2001, INT J COMPUT VISION, V53, P189
   Muñoz-Salinas R, 2008, PATTERN RECOGN, V41, P3665, DOI 10.1016/j.patcog.2008.06.013
   Muñoz-Salinas R, 2008, J VIS COMMUN IMAGE R, V19, P75, DOI 10.1016/j.jvcir.2007.07.004
   Muñoz-Salinas R, 2008, PATTERN RECOGN LETT, V29, P319, DOI 10.1016/j.patrec.2007.10.011
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   SALINAS RM, 2007, IMAGE VISION COMPUT, P995
   Vermaak J, 2005, IEEE T AERO ELEC SYS, V41, P309, DOI 10.1109/TAES.2005.1413764
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   ZHAO T, 2005, COMPUTER VISION PATT, P976
NR 34
TC 17
Z9 18
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2009
VL 20
IS 5
BP 339
EP 350
DI 10.1016/j.jvcir.2009.03.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 547LX
UT WOS:000273891500004
DA 2024-07-18
ER

PT J
AU Song, K
   Chung, T
   Oh, Y
   Kim, CS
AF Song, Kwanwoong
   Chung, Taeyoung
   Oh, Yunje
   Kim, Chang-Su
TI Error concealment of multi-view video sequences using inter-view and
   intra-view correlations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view video; Error concealment; Hierarchical B prediction;
   Bilateral motion estimation; Multi-hypothesis prediction; Robust video
   transmission; Error propagation; Mode selection
ID IMAGE
AB An efficient error concealment algorithm for multi-view video sequences is proposed in this work. First, we develop three concealment modes: temporal bilateral error concealment (TBEC), inter-view bilateral error concealment (IBEC), and multi-hypothesis error concealment (MHEC). TBEC and IBEC, respectively, exploit intra-view and inter-view correlations in multi-view video sequences to reconstruct an erroneous block. MHEC finds a few candidate blocks based on the block matching principle and combines them for the concealment. We then propose a mode selection scheme, which chooses one of the three modes adaptively to provide reliable and accurate concealment results. Simulation results demonstrate that the proposed algorithm can protect the quality of reconstructed videos effectively even in severe error conditions. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Song, Kwanwoong; Chung, Taeyoung; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Oh, Yunje] Samsung Elect, Suwon, South Korea.
C3 Korea University; Samsung; Samsung Electronics
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM kwsong71@korea.ac.kr; lovelool17@korea.ac.kr; yunjeoh@samsung.com;
   changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU Korea Research Foundation; Korean Government [KRF-2008-331-D00420];
   Ministry of Knowledge Economy, Korea; Institute of Information
   Technology Advancement [IITA-2008-C1090-0801-0017]; Samsung Electronics
FX This work was supported partly by the Korea Research Foundation Grant
   funded by the Korean Government (KRF-2008-331-D00420), partly by the
   Ministry of Knowledge Economy, Korea, under the Information Technology
   Research Center support program supervised by the Institute of
   Information Technology Advancement (grant number
   IITA-2008-C1090-0801-0017), and partly by the Samsung Electronics.
CR BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   CLEMEMS C, 2004, P INT WORKSH IM AN M
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Gao J, 2007, PROCEEDINGS OF 2007 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES, VOLS 1 AND 2, P1014
   GUENTHER KAM, 2004, P PCS 2004
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   *ISO IEC JTC1 SC29, 2007, MULT VID COD US VIEW
   *ISO IEC JTC1 SC29, 2006, COMM TEST COND MULT
   *ISO IEC JTC1 SC29, 2006, DISP VECT PRED METH
   *ISO IEC JTC1 SC29, 2007, JOINT MULT VID MOD J
   KANAL LN, 1978, P IEEE, V66, P724, DOI 10.1109/PROC.1978.11013
   KANG LW, 2007, P INT C IM P SEPT, V3, P13
   Kim JH, 2007, IEEE T CIRC SYST VID, V17, P1519, DOI 10.1109/TCSVT.2007.909976
   Knorr S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P820
   Kumar S, 2006, J VIS COMMUN IMAGE R, V17, P425, DOI 10.1016/j.jvcir.2005.04.006
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   Merkle P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1717, DOI 10.1109/ICME.2006.262881
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   PANG L, 2006, P INT C SIGN PROC, V2, P16
   Park YO, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P465
   Pereira F, 1997, IEEE T CIRC SYST VID, V7, P32, DOI 10.1109/76.554416
   Puri R, 2006, IEEE SIGNAL PROC MAG, V23, P94, DOI 10.1109/MSP.2006.1657820
   SCHAFER R, 2006, P PCS 2006
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   SONG K, 2007, P ISCAS, P973
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   Wang RS, 2000, IEEE T CIRC SYST VID, V10, P397, DOI 10.1109/76.836284
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   YEO C, 2007, P SPIE VCIP SAN JOS
NR 33
TC 24
Z9 40
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2009
VL 20
IS 4
BP 281
EP 292
DI 10.1016/j.jvcir.2009.02.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 447EV
UT WOS:000266175300005
DA 2024-07-18
ER

PT J
AU Poppe, C
   Martens, G
   Mannens, E
   Van de Walle, R
AF Poppe, Chris
   Martens, Gaetan
   Mannens, Erik
   Van de Walle, Rik
TI Personal content management system: A semantic approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Personal content management; Semantic web; Multimedia standards;
   Metadata; Annotation; Ontology; Interoperability; Reasoning
AB The amount of multimedia resources that is created and needs to be managed is increasing considerably.Additionally, a significant increase of metadata, either structured (metadata fields of standardized metadata formats) or unstructured (free tagging or annotations) is noticed. This increasing amount of data and metadata, combined with the substantial diversity in terms of used metadata fields and constructs, results in severe problems to manage and retrieve these multimedia resources. Standardized metadata schemes can be used but the plethora of these schemes results in interoperability issues. In this paper, we propose a metadata model suited for personal content management systems. We create a layered metadata service that implements the presented model as an upper layer and combines different metadata schemes in the lower layers. Semantic web technologies are used to define and link formal representations of these schemes. Specifically, we create an ontology for the DIG35 metadata standard and elaborate on how it is used within this metadata service. To illustrate the service, we present a representative use case scenario consisting of the upload, annotation, and retrieval of multimedia content within a personal content management system. (C) 2008 Elsevier Inc. All rights reserved
C1 [Poppe, Chris; Martens, Gaetan; Mannens, Erik; Van de Walle, Rik] Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP Poppe, C (corresponding author), Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, Gaston Crommenlaan 8 Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM Chris.Poppe@UGent.be
OI Mannens, Erik/0000-0001-7946-4884
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT-Flanders); Fund for Scientific
   Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, the Interdisciplinary Institute for
   Broadband Technology (IBBT), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT-Flanders), the
   Fund for Scientific Research-Flanders (FWO-Flanders), and the European
   Union.
CR AMANN B, 2008, P 1 INT SEM WEB C SE, P117
   [Anonymous], P 4 INT C AUT SOL CR
   [Anonymous], 2004, W3C MEMB SUBMISS
   [Anonymous], 2006, P JENA USER C BRIST
   [Anonymous], MULTIMEDIA VOCABULAR
   Arndt R, 2007, LECT NOTES COMPUT SC, V4825, P30
   ASIRELLI P, 2006, P SEM WEB APPL PERSP, P255
   *BRICKS, 2007, BRICKS BUILD RES INT
   Cruz IF, 2004, INTERNATIONAL DATABASE ENGINEERING AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P217, DOI 10.1109/IDEAS.2004.1319794
   Dönderler ME, 2005, MULTIMED TOOLS APPL, V27, P79, DOI 10.1007/s11042-005-2715-7
   Ferdinand M, 2004, LECT NOTES COMPUT SC, V3140, P354
   Garcia R., 2006, Proc 5th Knowledge Markup and Semantic Annotation Workshop CEUR Workshop Proceeding, P69
   GUSSOW D, 2004, NEW LENS WAR
   HARE JS, 2006, P 3 EUR SEM WEB C WO
   Hunter J., 2005, International Journal of Web Engineering and Technology, V2, P264, DOI 10.1504/IJWET.2005.008487
   Hunter J., 2001, First International Semantic Web Working Symposium (SWWS'01), P261
   *INT ORG STAND, 2006, JTC1SC29WG11 INT ORG
   *INT ORG STAND, 2002, 7 MPEG INT ORG STAND
   *IPTC, 2007, PHOT MET WHIT PAP
   *ISO IEC, 2001, 159383 ISO IEC FCD I
   Klein M, 2002, 13TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P889
   LAGOZE C, 2001, J DIGITAL INFORM, V2
   MASOLO C, 2002, TECHNICAL REPORT WON, P17
   Patel-Schneider P.F., 2004, OWL Web Ontology Lan-guage semantics and abstract syntax
   Petridis K, 2006, IEE P-VIS IMAGE SIGN, V153, P255, DOI 10.1049/ip-vis:20050059
   POPPE C, 2006, P INT C WWW INT, P315
   POPPE C, 2007, P PAC RIM C MULT PCM, P549
   Salembier P, 2001, IEEE T CIRC SYST VID, V11, P748, DOI 10.1109/76.927435
   SCHALLAUER P, 2006, J UNIVESAL KNOWLEDGE, V1, P26
   SIMOU N, 2005, P WORKSH IM AN MULT
   SLUIJS N, 2007, P INT C PAR DISTR PR, P396
   Troncy R, 2006, LECT NOTES COMPUT SC, V4306, P41
   TZOUVARAS V, 2007, MULTIMEDIA ANNOTATIO
   Vallet D, 2007, IEEE T CIRC SYST VID, V17, P336, DOI 10.1109/TCSVT.2007.890633
   *W3C, 2002, DESCR RETR PHOT US R
   *W3C REC, 2008, SPARQL QUER LANG RDF
   Wang X, 2005, IEEE T MULTIMEDIA, V7, P408, DOI 10.1109/TMM.2005.846788
   WILKINSON R, 2004, P 3 WORKSH EMP EV AD, P221
NR 38
TC 5
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 131
EP 144
DI 10.1016/j.jvcir.2008.12.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800007
OA Green Published
DA 2024-07-18
ER

PT J
AU Bribiesca, E
AF Bribiesca, Ernesto
TI A method for representing 3D tree objects using chain coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D tree objects; 3D tree structures; unique tree descriptor; 3D discrete
   branches; chain coding; 3D tree representation
ID CURVES
AB We describe a method for representing 3D (three-dimensional) tree objects by means of a chain code. These 3D tree objects correspond to natural existing 3D tree structures, such as: blood vessels, plants, live trees, and so on. Thus, trees are digitalized and represented by a notation called the unique tree descriptor. The unique tree descriptor is invariant under translation and rotation. Furthermore, this descriptor is starting vertex normalized via the unique path in the tree. Also, it is possible to obtain the mirror image of any tree with ease. This unique tree descriptor preserves the shape of trees (and the shape of their branches), allows us to know their geometrical and topological properties. To determine if two 3D tree objects have the same shape, it is only necessary to see if their descriptors are equal. In this manner, graph comparisons and tree searches are eliminated. Also, the proposed tree descriptor is a good tool for storing of 3D tree objects. Finally, in order to prove our method for representing 3D tree objects, we obtain some tree descriptors of objects on real images. (c) 2008 Published by Elsevier Inc.
C1 Univ Nacl Autonoma Mexico, Inst Invest Matemat Aplicadas & Sistemas, Mexico City 01000, DF, Mexico.
C3 Universidad Nacional Autonoma de Mexico
RP Bribiesca, E (corresponding author), Univ Nacl Autonoma Mexico, Inst Invest Matemat Aplicadas & Sistemas, Apdo 20-726, Mexico City 01000, DF, Mexico.
EM ernesto@leibniz.iimas.unam.mx
RI Bribiesca, Ernesto/AAH-6842-2021
OI Bribiesca, Ernesto/0000-0001-6663-9438
CR [Anonymous], ACM COMPUTING SURVEY
   Ballard D.H., 1982, Computer Vision
   Bird R., 1987, INTRO FUNCTIONAL PRO
   Bondy J. A., 1976, GRAPH THEORY APPL, V290
   Bribiesca E, 2000, PATTERN RECOGN, V33, P755, DOI 10.1016/S0031-3203(99)00093-X
   Bribiesca E, 2001, COMPUT MATH APPL, V42, P1571, DOI 10.1016/S0898-1221(01)00263-2
   Cayley A., 1889, A theorem of trees, V23, P376
   CLOSSON M, 2000, J GRAPH ALGORITHMS A, V5, P1
   Di Battista G., 2000, Journal of Graph Algorithms and Applications, V4, DOI 10.7155/jgaa.00027
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GUZMAN A, 1987, ACA25487 MCC
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   HUDAK P, 1992, ACM SIGPLAN NOTICES, V27, pT1
   Jonas A, 1997, PATTERN RECOGN, V30, P1803, DOI 10.1016/S0031-3203(97)00011-3
   O'Gorman L., 1992, PROGR COMPUTER VISIO, P167
   Zhao CS, 1997, PATTERN RECOGN, V30, P1817, DOI 10.1016/S0031-3203(97)00007-1
NR 17
TC 16
Z9 18
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2008
VL 19
IS 3
BP 184
EP 198
DI 10.1016/j.jvcir.2008.01.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 290FT
UT WOS:000255109400004
OA Bronze
DA 2024-07-18
ER

PT J
AU Ellinas, JN
   Sangriotis, MS
AF Ellinas, J. N.
   Sangriotis, M. S.
TI Morphological wavelet-based stereo image coders
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE stereo image compression; wavelet transform; morphology; disparity
ID COMPRESSION
AB In this paper, we propose a family of novel stereoscopic image coders based on morphological coding and a block-based disparity compensation algorithm. The proposed schemes employ discrete wavelet transform decomposition and a morphological coder that lowers total entropy by exploiting the intra-band and inter-band statistical properties of the wavelet coefficients. This ensures high coding efficiency, embedded bit streams, fast execution, and simple implementation. Disparity compensation procedure is implemented on blocks of fixed or variable size employing the block-matching algorithm. The blocks of variable size are formed as a result of Right image's quad-tree decomposition with a simplified rate-distortion criterion. This technique adapts block size to regions of almost constant binocular disparity in contradiction with fixed block size based disparity estimation that divides these regions into smaller blocks, thus requiring more disparity vectors. The Left and the resulting predictive error images are subsequently transformed, quantized, and coded. The wavelet nature of the algorithm and the proposed disparity compensation provide reconstructed images without blocking artifacts and fewer annoying ringing effects. The extensive experimental evaluation shows that the proposed coders demonstrate very good performance as far as PSNR measures and visual quality are concerned, as well as low complexity. (C) 2005 Elsevier Inc. All rights reserved.
C1 Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.
C3 National & Kapodistrian University of Athens
RP Ellinas, JN (corresponding author), Natl & Kapodistrian Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.
EM iellinas@di.uoa.gr
CR ADAMS MD, 2000, ISOIECJTC1SC29WG1N17
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Boulgouris NV, 2002, IEEE T CIRC SYST VID, V12, P898, DOI 10.1109/TCSVT.2002.804895
   Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Ellinas JN, 2004, IMAGE VISION COMPUT, V22, P281, DOI 10.1016/j.imavis.2003.09.017
   Frajka T, 2003, OPT ENG, V42, P182, DOI 10.1117/1.1526492
   PERKINS MG, 1992, IEEE T COMMUN, V40, P684, DOI 10.1109/26.141424
   Ramchandran K, 1993, IEEE T IMAGE PROCESS, V2, P160, DOI 10.1109/83.217221
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Servetto SD, 1999, IEEE T IMAGE PROCESS, V8, P1161, DOI 10.1109/83.784429
   SETHURAMAN S, 1996, THESIS CARNEGIE MELL
   SETHURAMAN S, 1995, P IS T SPIE
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Stelmach LB, 2000, IEEE IMAGE PROC, P5, DOI 10.1109/ICIP.2000.900878
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Woo O, 2000, IEEE T CIRC SYST VID, V10, P194, DOI 10.1109/76.825718
   Woo W, 1999, IEEE T CIRC SYST VID, V9, P861, DOI 10.1109/76.785724
   WOO W, 1998, THESIS U SO CALIFORN
   WOO W, 1999, P ICIP, V99, P467
NR 21
TC 8
Z9 9
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 686
EP 700
DI 10.1016/j.jvcir.2005.10.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500002
DA 2024-07-18
ER

PT J
AU Ong, EP
   Yang, XK
   Lin, WS
   Lu, ZK
   Yao, SS
   Lin, X
   Rahardja, S
   Seng, BC
AF Ong, Ee Ping
   Yang, Xiaokang
   Lin, Weisi
   Lu, Zhongkang
   Yao, Susu
   Lin, Xiao
   Rahardja, Susanto
   Seng, Boon Choong
TI Perceptual quality and objective quality measurements of compressed
   videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; MPEG-4; video coding; perceptual quality; objective video quality
   measurement; full-reference; subjective quality ratings
ID BLOCKING ARTIFACTS; CONTRAST; VISION; MODEL; MASKING; MECHANISMS;
   IMAGES; MOTION
AB This paper firstly presents a study of video quality for H.264 compressed videos compared to MPEG-4 (simple profile) from a perceptual point of view. Traditionally, peak signal-to-noise ratio (PSNR) has been used to represent the quality of a compressed video sequence. However, PSNR has been found to correlate poorly with subjective quality ratings, particularly at much lower bitrates and low frame rates. Thus, an alternative that has been commonly used is to perform subjective test where a large number of human subjects are used to gauge the quality of a video. However, this process is not only time-consuming but also tedious and expensive to perform. Hence, this paper further proposes an objective video quality measurement method to automatically measure the perceptual quality of a stream of video images. The proposed method has been tested on multimedia videos, consisting of CIF and QCIF video sequences compressed at various bitrates (24-384 kbps) and frame rates (7.5-30 fps) using the H.264 and MPEG-4 video codecs and it is shown to give significantly better correlations to the human perception than PSNR and the video structural similarity method. (C) 2005 Elsevier Inc. All rights reserved.
C1 Inst Infocomm Res, Singapore 119613, Singapore.
   NTT DoCoMo Inc, Multimedia Signal Proc Lab, Kanagawa 2398536, Japan.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); NTT Docomo
RP Ong, EP (corresponding author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM epong@i2r.a-star.edu.sg
RI Lin, Weisi/A-8011-2012; Liu, Anmin/A-4730-2012; Yang,
   Xiaokang/C-6137-2009; Lin, Wei/D-3353-2012; Lin, Weisi/A-3696-2011
OI Yang, Xiaokang/0000-0003-4029-3322; Lin, Weisi/0000-0001-9866-1947; Lu,
   Zhongkang/0000-0001-7379-3193; Ong, Ee Ping/0000-0002-9239-8399
CR [Anonymous], 2002, IEEE INT C AC SPEECH
   BARONCINI V, 2001, ISOIECJTC1SC29WG11, P4240
   CAMPBELL FW, 1968, J PHYSIOL-LONDON, V197, P551, DOI 10.1113/jphysiol.1968.sp008574
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   CHOU CH, 1966, IEEE T CIRCUITS SYST, V6, P143
   FOLEY JM, 1994, J OPT SOC AM A, V11, P1710, DOI 10.1364/JOSAA.11.001710
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   GIROD B, 1989, P SOC PHOTO-OPT INS, V1077, P178
   Girod Bernd, 1993, P207
   HOOKE R, 1961, J ACM, V8, P212, DOI 10.1145/321062.321069
   *ISO IEC, 2001, JTC1SC29WG11N3908 IS
   *ISO IEC, 2001, JTC1SC29WG11N4507 IS
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Kamaci N., 2003, IEEE INT C MULT EXP
   KARUNASEKERA SA, 1995, IEEE T IMAGE PROCESS, V4, P713, DOI 10.1109/83.388074
   KELLY DH, 1983, J OPT SOC AM, V73, P742, DOI 10.1364/JOSA.73.000742
   KELLY DH, 1979, J OPT SOC AM, V69, P1340, DOI 10.1364/JOSA.69.001340
   KELLY DH, 1979, J OPT SOC AM, V69, P1266, DOI 10.1364/JOSA.69.001266
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   LINDH P, 1996, IEEE INT C IM PROC
   Lu LG, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P61, DOI 10.1109/ICME.2002.1035718
   LUBIN J, 2000, Patent No. 6075884
   Marr D., 1982, Visual perception
   MASRY M, 2004, SIGNAL PROCESSING IM, V19
   Miyahara M, 1998, IEEE T COMMUN, V46, P1215, DOI 10.1109/26.718563
   MOON P, 1945, J OPT SOC AM, V35, P233, DOI 10.1364/JOSA.35.000233
   NETRAVALI AN, 1998, DIGITAL PICTURES REP
   Nothdurft HC, 2000, VISION RES, V40, P1183, DOI 10.1016/S0042-6989(00)00031-6
   Ong EP, 2004, IEEE T CIRC SYST VID, V14, P559, DOI 10.1109/TCSVT.2004.825574
   ONG EP, 2003, IEEE INT C IM PROC B, V3, P189
   RAN XN, 1995, IEEE T IMAGE PROCESS, V4, P401, DOI 10.1109/83.370671
   ROBSON JG, 1966, J OPT SOC AM, V56, P1141, DOI 10.1364/JOSA.56.001141
   SCHADE OH, 1956, J OPT SOC AM, V46, P721, DOI 10.1364/JOSA.46.000721
   SEYLER AJ, 1959, NATURE, V184, P1215, DOI 10.1038/1841215a0
   SEYLER AJ, 1965, IEEE T INFORM THEORY, V11, P31, DOI 10.1109/TIT.1965.1053735
   SWITKES E, 1988, J OPT SOC AM A, V5, P1149, DOI 10.1364/JOSAA.5.001149
   Tan KT, 2000, IEEE T CIRC SYST VID, V10, P1208, DOI 10.1109/76.875525
   TEO PC, 1994, IEEE IMAGE PROC, P982, DOI 10.1109/ICIP.1994.413502
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   *VQEG, 2003, REP REP VID QUAL EXP
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Watson AB, 1997, J OPT SOC AM A, V14, P2379, DOI 10.1364/JOSAA.14.002379
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Yao S, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P688
   YAO S, 2003, IEEE INT C AC SPEECH
   Yu ZH, 2002, P IEEE, V90, P154, DOI 10.1109/5.982412
NR 50
TC 17
Z9 20
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 717
EP 737
DI 10.1016/j.jvcir.2005.11.002
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500004
DA 2024-07-18
ER

PT J
AU Yoon, K
   Harwood, D
   Davis, L
AF Yoon, Kyongil
   Harwood, David
   Davis, Larry
TI Appearance-based person recognition using color/path-length profile
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE person recognition; color/path-length; appearance; kernel density
   estimation; Kullback-Leibler distance
ID TRACKING; BODY
AB Recognizing a person is a basic process of video understanding. In this paper, we present a method for recognizing (matching) persons based on their overall extrinsic appearance, regardless of their (upright) pose. Appearance is that of their visible clothing and bodies seen in silhouette obtained by background subtraction. The method of appearance recognition uses kernel estimation of probabilities associated with color/path-length profiles and uses Kullback-Leibler distance to compare such profiles with possible models. We show that with suitable normalization of color variables our method appears to be robust under conditions varying viewpoints, complex illumination, and multiple cameras. Our method is also useful to detect changes in appearance, for instance caused by carried packages. When there are more than one profiles to match in one frame, we adopt multiple matching algorithm enforcing 1 to 1 constraint to improve the performance. (C) 2006 Elsevier Inc. All rights reserved.
C1 Univ Maryland, Dept Comp Sci, Comp Vis Lab, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Yoon, K (corresponding author), Univ Maryland, Dept Comp Sci, Comp Vis Lab, College Pk, MD 20742 USA.
EM kiyoon@cs.umd.edu
CR ABDELKADER C, 2002, P 5 FGR
   Alexander DC, 2001, INT J COMPUT VISION, V44, P87, DOI 10.1023/A:1011870913626
   [Anonymous], MONOGRAPHS STAT APPL
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], P IEEE ICCV 99 FRAME
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   COMANICIU D, 2000, IEEE C COMP VIS PAT
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   HARITAOGLU I, 1998, INT C PATT REC
   HARWOOD D, IM UND WORKSH 87, P507
   KAPUR JN, 1992, ENTROPY OPTIMIZATIO
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LING H, 2005, INT C COMP VIS PATT
   MARTIN J, 1998, IEEE 3 INT C AUT FAC
   MCKENNA SJ, 1998, P ACCV 98, P615
   Nakajima C, 2003, PATTERN RECOGN, V36, P1997, DOI 10.1016/S0031-3203(03)00061-X
   Press W. H., 1988, Numerical Recipes
   Scott D.W., 2015, Multivariate Density Estimation: Theory, Practice and Visualization, DOI 10.1002/9780470316849
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhou S., 2002, P ECCV
NR 21
TC 17
Z9 20
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 605
EP 622
DI 10.1016/j.jvcir.2005.09.003
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300007
DA 2024-07-18
ER

PT J
AU Kang, LW
   Leou, JJ
AF Kang, LW
   Leou, JJ
TI A hybrid error concealment scheme for MPEG-2 video transmission based on
   best neighborhood matching algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error concealment; transmission error; MPEG-2 video transmission; best
   neighborhood matching algorithm
ID CODED IMAGES; EREC
AB For entropy-coded MPEG-2 video frames, a transmission error will not only affect the underlying codeword but also may affect subsequent codewords, resulting in a great degradation of the received video frames. In this study, a hybrid error concealment scheme for MPEG-2 video transmission is proposed. The objective is to recover high-quality MPEG-2 video frames from the corresponding corrupted video frames, without increasing the transmission bit rate. In this study, transmission errors or equivalently corrupted/lost video packets in MPEG-2 video frames are detected and located by the error detection scheme proposed by Shyu and Leou [IEEE Trans. Circuits Syst. Video Technol. 10 (4) (2000) 659], and then the corrupted blocks are concealed by the proposed hybrid error concealment scheme. Based on the fitness function for evaluating the candidate concealed blocks of a corrupted block, a corrupted block in an intra-coded I frame is concealed by either the spatial error concealment algorithm in H.264 or the proposed fast best neighborhood matching (BNM) algorithm. A corrupted block in an inter-coded P or B frame is concealed by the proposed fast motion-compensated BNM algorithm. Based on the simulation results obtained in this study, the proposed scheme can recover high-quality MPEG-2 video frames from the corresponding corrupted video frames up to a packet loss rate of 20%. The performance of the proposed scheme is better than those of four existing approaches for comparison. (C) 2004 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM jjleou@cs.ccu.edu.tw
CR [Anonymous], JTC1SC29WG11602 ISOI
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Chu WJ, 1998, IEEE T CIRC SYST VID, V8, P74, DOI 10.1109/76.660830
   Chung KL, 2003, IEEE T IMAGE PROCESS, V12, P648, DOI 10.1109/TIP.2003.812756
   Cosman PC, 2000, IEEE T IMAGE PROCESS, V9, P982, DOI 10.1109/83.846241
   GHANBARI M, 1998, IEEE T CIRCUITS SYST, V3, P238
   Han YH, 1998, IEEE T CIRC SYST VID, V8, P221, DOI 10.1109/76.664106
   Haskell B.G., 1997, DIGITAL VIDEO INTRO
   Hong MC, 1999, SIGNAL PROCESS-IMAGE, V14, P473, DOI 10.1016/S0923-5965(98)00061-7
   Jung HS, 2000, IEEE T CIRC SYST VID, V10, P433, DOI 10.1109/76.836289
   Lee YC, 2002, IEEE T IMAGE PROCESS, V11, P1314, DOI 10.1109/TIR2002.804275
   OHTA H, 1991, IEEE J SEL AREA COMM, V9, P1471, DOI 10.1109/49.108684
   Poli A., 1992, ERROR CORRECTING COD
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   Shirani S, 2000, IEEE T IMAGE PROCESS, V9, P1292, DOI 10.1109/83.847842
   Shyu HC, 1999, IEEE T CIRC SYST VID, V9, P937, DOI 10.1109/76.785732
   Shyu WL, 1996, IEEE T COMMUN, V44, P938, DOI 10.1109/26.535434
   SUN HF, 1995, IEEE T IMAGE PROCESS, V4, P470, DOI 10.1109/83.370675
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   Valente S, 2001, IEEE T CONSUM ELECTR, V47, P568, DOI 10.1109/30.964147
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y., 2002, VIDEO PROCESSING COM
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wang Z, 1998, IEEE T IMAGE PROCESS, V7, P1056, DOI 10.1109/83.701166
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
NR 27
TC 13
Z9 13
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2005
VL 16
IS 3
BP 288
EP 310
DI 10.1016/j.jvcir.2004.11.004
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 932YU
UT WOS:000229591500004
DA 2024-07-18
ER

PT J
AU Han, I
   Yun, ID
   Lee, SU
AF Han, I
   Yun, ID
   Lee, SU
TI Modified Hausdorff distance for model-based 3-D object recognition from
   a single view
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3-D model; object recognition; Hausdorff distance; single view
ID IMAGES
AB In this paper, we consider the problem of recognizing 3-D object from a single 2-D intensity image, obtained from unknown position and orientation. We propose the feature set based correspondence algorithm between 3-D model features and 2-D image features, in contrast to the conventional approaches which use a single local feature or fixed number of local features. We describe the model and the image as the set of the feature sets, which are then used as a basic unit to compare the similarity. As a measure of the similarity between features, the Hausdorff distance with explicit paring (HDEP) is proposed and extended to the partial HDEP, using the notion of the partial distance to cope with the problems which occur when there are backgrounds and some of image features are missing or severely deviated from the original. The proposed correspondence algorithm employing the partial HDEP is the generalized form which is able to vary the number of local relations to be considered flexibly from a single local relation to set of local relations. The probabilistic measure which reflects the view variation of the projected features is used to measure the similarity between the elements of the feature set. The 3-D object recognition system with hypothesis-verification scheme is implemented and tested on real images with backgrounds and occlusion. (C) 2003 Elsevier Inc. All rights reserved.
C1 Hankuk Univ Foreign Studies, Sch Elect & Informat Engn, Yongin 449791, South Korea.
   Samsung Elect, Wireless Terminal Div, Yongin 449900, South Korea.
   Seoul Natl Univ, Sch Elect Engn, Seoul 151742, South Korea.
C3 Hankuk University Foreign Studies; Samsung; Seoul National University
   (SNU)
RP Hankuk Univ Foreign Studies, Sch Elect & Informat Engn, Yongin 449791, South Korea.
EM inseo@samsung.co.kr; yun@computer.org; sanguk@spl.snu.ac.kr
CR BEIS JS, 1994, P COMP VIS PATT REC
   BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667
   BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774
   DHOME M, 1987, IEEE T PATTERN ANAL, V9, P429, DOI 10.1109/TPAMI.1987.4767924
   GRIMSON WEL, 1990, IEEE T PATTERN ANAL, V12, P255, DOI 10.1109/34.49052
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921
   Lamdan Y., 1988, PROC 2 INT C COMPUTE, P238
   LILIEN RH, 1996, P EUR C COMP VIS, P536
   LINNAINMAA S, 1988, IEEE T PATTERN ANAL, V10, P634, DOI 10.1109/34.6772
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Malik R, 1997, IEEE T PATTERN ANAL, V19, P52, DOI 10.1109/34.566810
   Mundy J., 1992, GEOMETRIC INVARIANCE
   NEVATIA R, 1980, COMPUT VISION GRAPH, V13, P257, DOI 10.1016/0146-664X(80)90049-0
   Olson C. F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P387, DOI 10.1109/CVPR.1993.341101
   OLSON CF, 1995, IEEE T PATTERN ANAL, V17, P518, DOI 10.1109/34.391391
   Thompson D. W., 1987, Proceedings of the 1987 IEEE International Conference on Robotics and Automation (Cat. No.87CH2413-3), P208
NR 17
TC 4
Z9 5
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2004
VL 15
IS 1
BP 27
EP 43
DI 10.1016/j.jvcir.2003.06.003
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 772PV
UT WOS:000188851200002
DA 2024-07-18
ER

EF