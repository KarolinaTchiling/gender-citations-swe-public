FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Liu, CY
   Chiou, LJ
   Li, CC
   Ye, XW
AF Liu, Cheng-yong
   Chiou, Ling-Jan
   Li, Cheng-chung
   Ye, Xiu-Wen
TI Analysis of Beijing Tianjin Hebei regional credit system from the
   perspective of big data credit reporting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SVM; Information asymmetry; Convolution neural network; Decision tree;
   Credit investigation
ID OBJECT DETECTION; DEEP
AB With the wide application of big data technology and the continuous innovation of the financial industry, the development of Internet finance has become irreversible. The new financial model has improved the efficiency of financial services and formed new ways of payment and transaction. The traditional credit information system has been unable to meet the needs of the development of the financial industry. The research methods adopted in this paper mainly include literature research, case analysis and comparative analysis. The development process, current situation and characteristics of China's personal credit system, as well as the development process and current situation of China's personal credit system under Internet finance are analyzed. It also points out the main problems faced by China's personal credit reporting system under the Internet finance. Then, aiming at the specific problems faced by China's personal credit reporting system under Internet finance, this paper makes case studies of representative market-oriented credit reporting institutions such as Beijing, Tianjin and Hebei, and uses convolutional neural network to analyze the specific practices of these individual credit reporting institutions and achieves results. At the same time, it compares how different credit agencies make up for the shortcomings of personal credit reporting system. Finally, it draws the conclusion of perfecting the personal credit system of our country under the Internet finance, points out the new problems that may be brought by the superposition of various solutions, and puts forward the countermeasures and suggestions of perfecting the personal credit system of our country under the Internet finance. (C) 2019 Published by Elsevier Inc.
C1 [Liu, Cheng-yong] Beijing Inst Technol, Zhuhai, Guangdong, Peoples R China.
   [Chiou, Ling-Jan] Meiho Univ, Dept Hlth Business Adm, Pingtung, Taiwan.
   [Li, Cheng-chung] Coretron Intelligence Cloud Serv, Hsinchu, Taiwan.
   [Ye, Xiu-Wen] Yulin Normal Univ, Yulin, Guangxi, Peoples R China.
C3 Beijing Institute of Technology; Yulin Normal University
RP Ye, XW (corresponding author), Yulin Normal Univ, Yulin, Guangxi, Peoples R China.
EM 18677588510@qq.com
RI liu, cheng-yong/GWV-7228-2022
FU Beijing Institute of Technology, Zhuhai [XK-2018-19]
FX This work was supported by the 2018 scientific research program of
   Beijing Institute of Technology, Zhuhai (No. XK-2018-19).
CR Agarap AFM, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P26, DOI 10.1145/3195106.3195117
   Aiqin M. A., 2018, J YIBIN U
   Cai J. X., 2018, J TECH EC MANAGE
   Chen ZH, 2018, TRANSL BIOINFORM, V12, P1, DOI 10.1007/978-981-10-8764-6_1
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Fan  Y., 2018, MOD ELECT TECH
   Fu YG, 2018, ELECTRON COMMER RES, V18, P605, DOI 10.1007/s10660-017-9260-0
   Gan  X., 2018, POWER SYST PROTECT C
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Jia T., 2018, STUDY EFFECT BIG DAT
   Jiang  L., 2018, OPT INSTRUM
   Jide J. I. A., 2018, J MILITARY TRANSPORT
   Kelly R, 2018, J HOUS ECON, V41, P153, DOI 10.1016/j.jhe.2018.05.005
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Lan  Hong, 2018, W FORUM EC MANAGEMEN
   Li  H., 2018, J LANZHOU U
   Li  L., 2018, J HEIHE U
   Liang  W., 2018, SAF ENV ENG
   Lin  K., 2018, PROCESS AUTOMATION I
   Liu  Cheng-yong, 2018, COMP LAW RES
   Liu MZ, 2018, INT J AUDIOL, V57, P875, DOI 10.1080/14992027.2018.1498982
   Liu  W., 2018, TELECOMMUN SCI
   Liu Y. H., 2018, ELECT POWER INF COMM
   Liu Y, 2018, PATTERN RECOGN, V78, P307, DOI 10.1016/j.patcog.2018.01.022
   Men H, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010285
   Peng YanKun Peng YanKun, 2018, Transactions of the Chinese Society of Agricultural Engineering, V34, P159
   Rodrigues, 2018, INFORM TECHNOLOGY NE, P443
   Rong  J., 2018, J GEODESY GEODYN
   Song  D., 2018, CHIN INT COMBUST ENG
   Wang Y D, 2018, J CHINA RAILWAY SOC
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P5738, DOI 10.1109/TIE.2015.2410766
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang  W., 2018, P CSEE
   Zhang WP, 2017, SAUDI J BIOL SCI, V24, P563, DOI 10.1016/j.sjbs.2017.01.027
   Zhu  J., 2018, J ELECT MEASUR INSTR
NR 44
TC 9
Z9 9
U1 5
U2 86
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 300
EP 308
DI 10.1016/j.jvcir.2019.01.018
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600031
DA 2024-07-18
ER

PT J
AU Rehman, YAU
   Po, LM
   Liu, MY
   Zou, ZJ
   Ou, WF
   Zhao, YZ
AF Rehman, Yasar Abbas Ur
   Po, Lai-Man
   Liu, Mengyang
   Zou, Zijie
   Ou, Weifeng
   Zhao, Yuzhi
TI Face liveness detection using convolutional-features fusion of real and
   deep network generated face images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolution neural networks; Face anti-spoofing; Face liveness
   detection; Adaptive fusion; Auto-encoder; DNG face images
ID SPOOFING DETECTION; TEXTURE
AB Conventionally, classifiers designed for face liveness detection are trained on real-world images, where real-face images and corresponding face presentation attacks (PA) are very much overlapped. However, a little research has been carried out in utilization of the combination of real-world face images and face images generated by deep convolutional neural networks (CNN) for face liveness detection. In this paper, we evaluate the adaptive fusion of convolutional-features learned by convolutional layers from real-world face images and deep CNN generated face images for face liveness detection. Additionally, we propose an adaptive convolutional-features fusion layer that adaptively balance the fusion of convolutional-features of real-world face images and face images generated by deep CNN during training. Our extensive experiments on the state-of-the-art face anti-spoofing databases, i.e., CASIA, OULU and Replay-Attack face anti-spoofing databases with both intra-database and cross-database scenarios indicate promising performance of the proposed method on face liveness detection compared to state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Rehman, Yasar Abbas Ur; Po, Lai-Man; Liu, Mengyang; Zou, Zijie; Ou, Weifeng; Zhao, Yuzhi] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Rehman, YAU (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM yaurehman2-c@my.cityu.edu.hk; eelmpo@-cityu.edu.hk;
   mengyaliu7-c@my.cityu.edu.hk; zijiezou2-c@my.cityu.edu.hk;
   weifengou2-c@my.cityu.edu.hk; yzzhao2-c@my.cityu.edu.hk
RI /ADN-5973-2022
OI /0000-0002-8908-3863; Liu, Mengyang/0000-0003-3527-6907; rehman,
   yasar/0000-0002-2945-7181; Zhao, Yuzhi/0000-0001-8561-2206
FU City University of Hong Kong [7004430]
FX The work in this paper is supported by City University of Hong Kong
   under the research project with grant number 7004430.
CR Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   [Anonymous], 2017, IEEE T INF FORENSICS
   [Anonymous], FACE ANTISPOOFING BA
   [Anonymous], 2014, ABS14085601 CORR
   [Anonymous], IEEE T INF FORENSICS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2018, LEARNING DEEP MODELS
   [Anonymous], FAKE FACE DETECTION
   [Anonymous], FACE DE SPOOFING ANT
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   [Anonymous], ARXIV181013170V1
   [Anonymous], PROC CVPR IEEE
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chingovska Ivana, 2012, BIOSIG
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030699
   de Souza GB, 2017, IEEE T CIRCUITS-II, V64, P1397, DOI 10.1109/TCSII.2017.2764460
   Dong JX, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P377, DOI 10.1109/SPAC.2017.8304308
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Feng LT, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043014
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Gan J., 2017, INT C TRANSPARENT OP, P1, DOI [DOI 10.1109/ICTON.2017.8024849, 10.1109/ICTON.2017.8024849]
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Hadid A, 2014, IEEE COMPUT SOC CONF, P113, DOI 10.1109/CVPRW.2014.22
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Lakshminarayana N.N., 2017, IEEE ISBA, P1
   Li HX, 2018, ANN HUM BIOL, V45, P359, DOI 10.1080/03014460.2018.1480731
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li L, 2018, J VIS COMMUN IMAGE R, V54, P182, DOI 10.1016/j.jvcir.2018.05.009
   Li LF, 2016, CRYSTALS, V6, DOI 10.3390/cryst6040045
   Liu H, 2018, IEEE T PATTERN ANAL, V40, P2546, DOI 10.1109/TPAMI.2017.2734779
   Lu JW, 2017, IEEE SIGNAL PROC MAG, V34, P76, DOI 10.1109/MSP.2017.2732900
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Menotti David, 2015, IEEE Transactions on Information Forensics and Security, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Rehman YAU, 2018, EXPERT SYST APPL, V108, P159, DOI 10.1016/j.eswa.2018.05.004
   Rehman YAU, 2017, SIG P ALGO ARCH ARR, P195, DOI 10.23919/SPA.2017.8166863
   Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772
   Simonyan K., 2014, 14091556 ARXIV
   Tu XK, 2017, LECT NOTES COMPUT SC, V10635, P686, DOI 10.1007/978-3-319-70096-0_70
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang Y, 2017, J VIS COMMUN IMAGE R, V49, P332, DOI 10.1016/j.jvcir.2017.09.002
   Xu ZQ, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P141, DOI 10.1109/ACPR.2015.7486482
   Zhang LB, 2018, J VIS COMMUN IMAGE R, V51, P56, DOI 10.1016/j.jvcir.2018.01.001
   Zhang Z, 2012, J NANOMATER, V2012, DOI 10.1155/2012/238605
   Zheng YT, 2018, PROC CVPR IEEE, P5089, DOI 10.1109/CVPR.2018.00534
NR 51
TC 14
Z9 14
U1 3
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 574
EP 582
DI 10.1016/j.jvcir.2019.02.014
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600059
DA 2024-07-18
ER

PT J
AU Wang, YF
   Wang, ZP
AF Wang, Yafei
   Wang, Zepeng
TI A survey of recent work on fine-grained image classification techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; Deep learning; Convolutional neural networks
AB Image classification is a hot topic in image processing. Image classification aims to automatically classify large numbers of images. Many methods have been proposed for solving this task. Traditional methods usually leverage low-level features. Clustering is the most commonly used method of image classification. In recent years, convolutional neural networks (CNNs) is widely used in extracting deep features. Many network architectures are proposed for image classification, such as ResNeXt, Cifar10. These deep learning methods aims at fusing features of texture, color and segmentation. In this paper, we discuss the different methods and techniques of image classification, and made a detailed summary of their performance. We believe that our work plays an important role in the field of image classification. (C) 2018 Published by Elsevier Inc.
C1 [Wang, Yafei] Pingdingshan Univ, Coll Informat Engn, Pingdingshan 467000, Henan, Peoples R China.
   [Wang, Zepeng] Hefei Univ Technol, Dept CSIE, Hefei, Anhui, Peoples R China.
C3 Pingdingshan University; Hefei University of Technology
RP Wang, YF (corresponding author), Pingdingshan Univ, Coll Informat Engn, Pingdingshan 467000, Henan, Peoples R China.
EM wang_yaafei@sohu.com
CR [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Gong C, 2016, IEEE T IMAGE PROCESS, V25, P3249, DOI 10.1109/TIP.2016.2563981
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Korytkowski M, 2016, INFORM SCIENCES, V327, P175, DOI 10.1016/j.ins.2015.08.030
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Viola Paul, J INT J COMPUT VISON, P137
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Yang HD, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8030383
   Zhang D, 2018, WATER RESOUR MANAG, V32, P2079, DOI 10.1007/s11269-018-1919-3
   Zhang L, 2018, J VISUAL COMMUN IMAG
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
NR 21
TC 32
Z9 34
U1 1
U2 56
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 210
EP 214
DI 10.1016/j.jvcir.2018.12.049
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600022
DA 2024-07-18
ER

PT J
AU Xu, HB
   Zhang, G
   Zhang, QM
AF Xu, Haibo
   Zhang, Ge
   Zhang, Qingming
TI RETRACTED: An iterative propagation based co-saliency framework for RGBD
   images (Retracted article. See vol. 77, 2021)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE RGBD images; Co-saliency; Iterative optimization; Saliency propagation;
   Depth information; Saliency detection
ID OBJECT DETECTION; DEEP
AB As an important topic which is emerging in the field of computer vision, co-saliency detection is aimed at finding the salient target among several related images. The existent methods are usually to formulate co-saliency map by designed clues or initialized and direct forward pipeline. However, these models are in lack of an improved scheme for loop scheme. At the meantime, lots of methods only focus on RGB images while ignore depth cues of RGBD images. In this paper, an iterative RGBD co-saliency method will be introduced. It utilizes the existing single saliency maps as initialization and another kind of refinement-cycle model to generate a final RGBD co-saliency map. The proposed model adopted three schemes, including addition scheme, deletion scheme and iterative scheme. Besides, this paper also proposed a new descriptor in addition scheme: Depth Shape Prior (DSP). Putting introduced depth cues into DSP can enhance recognition ability for co-saliency target, which will eventually achieve the transformation from two-dimension saliency detection to co-saliency detection based on RGBD images. Experiments show the effectiveness of described in this paper. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xu, Haibo; Zhang, Qingming] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Zhang, Ge] Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
   [Zhang, Ge] Henan Univ, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
C3 South China University of Technology; Henan University; Henan University
RP Zhang, G (corresponding author), Henan Univ, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
EM 18011880631@189.cn; zhangge@henu.edu.cn
FU Guangzhou Science Technology and Innovation Commission [201707010068];
   NSFC [61802114, 61802113]; Scientific Research Foundation of the Higher
   Education Institutions of Henan Province [18A520021]
FX This work was supported by Guangzhou Science Technology and Innovation
   Commission (No. 201707010068), NSFC (No. 61802114, 61802113), Scientific
   Research Foundation of the Higher Education Institutions of Henan
   Province (18A520021).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, DOI DOI 10.1109/CVPR.2016.257
   Chen B. J., 2017, NEUROCOMPUTING, P266
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Ge CJ, 2016, SIGNAL PROCESS-IMAGE, V44, P69, DOI 10.1016/j.image.2016.03.005
   Guo X, 2013, PROC CVPR IEEE, P3206, DOI 10.1109/CVPR.2013.412
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang R, 2015, IEEE INT CON MULTI
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Lei JJ, 2016, IEEE T MULTIMEDIA, V18, P1783, DOI 10.1109/TMM.2016.2592325
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Montilla M. S., 2014, COSALIENCY DETECTION
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Song HK, 2016, IEEE SIGNAL PROC LET, V23, P1722, DOI 10.1109/LSP.2016.2615293
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang S, 2015, IEEE T KNOWL DATA EN, V27, P1356, DOI 10.1109/TKDE.2014.2345380
   Xu HB, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/8738316
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang YX, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3125645
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
NR 40
TC 4
Z9 5
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 186
EP 194
DI 10.1016/j.jvcir.2019.01.016
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600019
DA 2024-07-18
ER

PT J
AU Chen, KM
   Chang, CC
AF Chen, Kaimeng
   Chang, Chin-Chen
TI High-capacity reversible data hiding in encrypted images based on
   extended run-length coding and block-based MSB plane rearrangement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Run-length coding; Image encryption
ID DIFFERENCE
AB In this paper, we propose a novel reversible data hiding method in encrypted images. The proposed method takes full advantage of the spatial correlation in the original images to vacate room for embedding data before image encryption. By jointly using an extended run-length coding and a block-based most significant bit (MSB) plane rearrangement mechanism, the MSB planes of images can be compressed efficiently to generate room for high-capacity embedding. The receiver can extract data directly from encrypted images with only the data hiding key, and the original image or the high-quality plain image that contains secret data can be recovered with only the encryption key. The experimental results prove that the proposed method can reach a high embedding rate and a high PSNR. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chen, Kaimeng] JiMei Univ, Comp Engn Coll, Xiamen 361021, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Jimei University; Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Natural Science Foundation of Fujian Province, China [2017J05104];
   National Natural Science Foundation of China [61701191]
FX This paper is supported by the Natural Science Foundation of Fujian
   Province, China (2017J05104), and the National Natural Science
   Foundation of China (61701191).
CR [Anonymous], 2011, P 13 INF HID C PRAG
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chandra A, 2001, IEEE VLSI TEST SYMP, P42, DOI 10.1109/VTS.2001.923416
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Puech W., 2008, P SOC PHOTO-OPT INS, V6819, P68
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2018, INFORM SCIENCES, V465, P285, DOI 10.1016/j.ins.2018.07.021
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Nguyen TS, 2015, J VIS COMMUN IMAGE R, V33, P389, DOI 10.1016/j.jvcir.2015.10.008
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 29
TC 89
Z9 102
U1 6
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 334
EP 344
DI 10.1016/j.jvcir.2018.12.023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100033
DA 2024-07-18
ER

PT J
AU Lu, XL
   Lü, XB
   Zuo, YS
AF Lu, Xiaolei
   Lu, Xuebin
   Zuo, Yongsheng
TI Spherically contoured exponential scale mixture prior based nonlocal
   image restoration with ADMM framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Nonlocal self-similarity; Spherically contoured
   exponential scale mixture; Weighted group-based simultaneous sparse
   coding; ADMM
ID SPARSE REPRESENTATION; INVERSE PROBLEMS; NOISE REMOVAL; REGULARIZATION;
   TRANSFORM; SUPERRESOLUTION; ALGORITHMS
AB According to the nonlocal self-similarity property of natural images, group-based simultaneous sparse coding (GSSC) model assumes that nonlocal similar patches have similar sparse representations in a given dictionary and have been widely used in various image inverse problems. Inspired by the success of the GSSC mode in image restoration problems, this paper proposes a weighted group-based simultaneous sparse coding (WGSSC) model based on the spherically contoured exponential scale mixture (SCESM) prior for image restoration. Compared with traditional GSSC models, which often characterize the similar sparse coefficients by a common set of zero supports and lack spatial adaption and principled fashion, the proposed model considers the dependent relation and adaptivity of similar sparse coefficient, so it is more rational than the GSSC model. The similar sparse coefficients and scale variables can be jointly estimated by the alternating minimization algorithm with the SCESM prior. Based on the estimated sparse coefficients, we can reconstruct the clear patch group and obtain the global denoised image by averaging these patch groups. We refer this denoised method as WGSSC-SCESM based denoiser prior, which can be effectively plugged into general image restoration problems by the alternating direction method of multipliers (ADMM) techniques. Extensive experiments on various types of image restoration problems, e.g., image denoising, inpainting, deblurring and single image super-resolution, demonstrate that the proposed method outperforms many state-of-the-art restored methods in term of the objective and subjective metrics.
C1 [Lu, Xiaolei; Lu, Xuebin; Zuo, Yongsheng] Nanjing Tech Univ, Sch Phys & Math Sci, Dept Math, Nanjing 210009, Jiangsu, Peoples R China.
C3 Nanjing Tech University
RP Lu, XL (corresponding author), Nanjing Tech Univ, Sch Phys & Math Sci, Dept Math, Nanjing 210009, Jiangsu, Peoples R China.
EM math_lu@126.com
CR [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P IEEE INT C IM PROC
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cho D, 2005, SIGNAL PROCESS-IMAGE, V20, P77, DOI 10.1016/j.image.2004.10.003
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Deledalle CA, 2014, IEEE SIGNAL PROC MAG, V31, P69, DOI 10.1109/MSP.2014.2311305
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong WS, 2015, IEEE I CONF COMP VIS, P442, DOI 10.1109/ICCV.2015.58
   Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Egiazarian K, 2015, EUR SIGNAL PR CONF, P2849, DOI 10.1109/EUSIPCO.2015.7362905
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Elmoataz A, 2008, IEEE T IMAGE PROCESS, V17, P1047, DOI 10.1109/TIP.2008.924284
   Eslami R, 2006, IEEE T IMAGE PROCESS, V15, P3362, DOI 10.1109/TIP.2006.881992
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   HAGER WW, 1989, SIAM REV, V31, P221, DOI 10.1137/1031049
   Huang YM, 2012, IEEE T IMAGE PROCESS, V21, P4534, DOI 10.1109/TIP.2012.2205007
   Ji H, 2011, SIAM J IMAGING SCI, V4, P1122, DOI 10.1137/100817206
   Ji H, 2010, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2010.5539849
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Li F, 2014, IEEE T IMAGE PROCESS, V23, P4242, DOI 10.1109/TIP.2014.2346030
   Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P829, DOI 10.1109/TIP.2015.2511584
   Lucas A, 2018, IEEE SIGNAL PROC MAG, V35, P20, DOI 10.1109/MSP.2017.2760358
   Ma LY, 2017, J SCI COMPUT, V70, P1336, DOI 10.1007/s10915-016-0282-x
   Ma LY, 2013, SIAM J IMAGING SCI, V6, P2258, DOI 10.1137/120866452
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2012, FOUND TRENDS COMPUT, V8, DOI 10.1561/0600000058
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Metzler CA, 2016, IEEE T INFORM THEORY, V62, P5117, DOI 10.1109/TIT.2016.2556683
   Pang JH, 2017, IEEE T IMAGE PROCESS, V26, P1770, DOI 10.1109/TIP.2017.2651400
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Romano Y, 2014, IEEE T IMAGE PROCESS, V23, P3085, DOI 10.1109/TIP.2014.2325774
   Rond A, 2016, J VIS COMMUN IMAGE R, V41, P96, DOI 10.1016/j.jvcir.2016.09.009
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Shi F, 2007, APPL COMPUT HARMON A, V23, P131, DOI 10.1016/j.acha.2007.01.007
   Sreehari S, 2016, IEEE T COMPUT IMAG, V2, P408, DOI 10.1109/TCI.2016.2599778
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Talebi H, 2014, IEEE T IMAGE PROCESS, V23, P755, DOI 10.1109/TIP.2013.2293425
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang XR, 2017, INT CONF ACOUST SPEE, P1323, DOI 10.1109/ICASSP.2017.7952371
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen YW, 2008, SIAM J SCI COMPUT, V30, P2655, DOI 10.1137/070683374
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xiong RQ, 2016, IEEE T IMAGE PROCESS, V25, P5793, DOI 10.1109/TIP.2016.2614160
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zha ZY, 2017, IEEE INT CON MULTI, P883, DOI 10.1109/ICME.2017.8019334
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
   Zuo WM, 2013, IEEE I CONF COMP VIS, P217, DOI 10.1109/ICCV.2013.34
NR 78
TC 3
Z9 3
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 374
EP 392
DI 10.1016/j.jvcir.2018.05.021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100031
DA 2024-07-18
ER

PT J
AU Izadyyazdanabadi, M
   Belykh, E
   Mooney, M
   Martirosyan, N
   Eschbacher, J
   Nakaji, P
   Preul, MC
   Yang, YZ
AF Izadyyazdanabadi, Mohammadhassan
   Belykh, Evgenii
   Mooney, Michael
   Martirosyan, Nikolay
   Eschbacher, Jennifer
   Nakaji, Peter
   Preul, Mark C.
   Yang, Yezhou
TI Convolutional neural networks: Ensemble modeling, fine-tuning and
   unsupervised semantic localization for neurosurgical CLE images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neural network; Unsupervised localization; Ensemble modeling; Brain
   tumor; Confocal laser endomicroscopy; Surgical vision
ID PARALLEL FRAMEWORK
AB Confocal laser endomicroscopy (CLE) is an advanced optical fluorescence technology undergoing assessment for applications in brain tumor surgery. Many of the CLE images can be distorted and interpreted as nondiagnostic. However, just one neat CLE image might suffice for intraoperative diagnosis of the tumor. While manual examination of thousands of nondiagnostic images during surgery would be impractical, this creates an opportunity for a model to select diagnostic images for the pathologists or surgeons review. In this study, we sought to develop a deep learning model to automatically detect the diagnostic images. We explored the effect of training regimes and ensemble modeling and localized histological features from diagnostic CLE images. The developed model could achieve promising agreement with the ground truth. With the speed and precision of the proposed method, it has potential to be integrated into the operative workflow in the brain tumor surgery.
C1 [Izadyyazdanabadi, Mohammadhassan; Belykh, Evgenii; Yang, Yezhou] Arizona State Univ, Tempe, AZ 85281 USA.
   [Izadyyazdanabadi, Mohammadhassan; Belykh, Evgenii; Mooney, Michael; Martirosyan, Nikolay; Eschbacher, Jennifer; Nakaji, Peter; Preul, Mark C.] St Josephs Hosp, Barrow Neurol Inst, Dept Neurosurg, Phoenix, AZ 85013 USA.
   [Belykh, Evgenii] Irkutsk State Med Univ, Krassnogo Vosstaniya 1, Irkutsk 664003, Russia.
C3 Arizona State University; Arizona State University-Tempe; Barrow
   Neurological Institute; St. Joseph's Hospital and Medical Center;
   Irkutsk State Medical University
RP Izadyyazdanabadi, M (corresponding author), Arizona State Univ, Tempe, AZ 85281 USA.
EM mizadyya@asu.edu
RI Belykh, Evgenii/O-8279-2017; Yazdanabadi, Mohammadhassan
   Izady/AAD-4373-2020
OI Belykh, Evgenii/0000-0003-2060-5739; 
FU Newsome Family Endowed Chair of Neurosurgery Research at the Barrow
   Neurological Institute; Barrow Neurological Foundation; NSF [1750802]
FX This work was supported by the Newsome Family Endowed Chair of
   Neurosurgery Research at the Barrow Neurological Institute held by Dr.
   Preul and by funds from the Barrow Neurological Foundation. Dr. Yezhou
   Yang is partially supported by NSF grant #1750802.
CR [Anonymous], J NEUROSURG
   [Anonymous], IEEE T INTELL TRANSP
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], MED BIOL ENG COMPUT
   [Anonymous], 2017, IEEE J BIOMED HLTH I
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ARXIV14085093
   [Anonymous], COMPUT MATH METHODS
   [Anonymous], IEEE T MED IMAGING
   [Anonymous], SPIE MED IMAGING
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], ARXIV170205747
   Belykh E, 2016, FRONT SURG, V3, DOI 10.3389/fsurg.2016.00055
   Bengio Yann Le Cunand Yoshua, 1998, HDB BRAIN THEORY NEU, P255
   Charalampaki Patra, 2015, Neurosurgery, V62 Suppl 1, P171, DOI 10.1227/NEU.0000000000000805
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   Foersch S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0041760
   Gao Y, 2016, I S BIOMED IMAGING, P787, DOI 10.1109/ISBI.2016.7493384
   Ghafoorian M, 2017, NEUROIMAGE-CLIN, V14, P391, DOI 10.1016/j.nicl.2017.01.033
   Greenspan H, 2016, IEEE T MED IMAGING, V35, P1153, DOI 10.1109/TMI.2016.2553401
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krogh A., 1995, Advances in Neural Information Processing Systems 7, P231
   Kumar A, 2017, IEEE J BIOMED HEALTH, V21, P31, DOI 10.1109/JBHI.2016.2635663
   Kumar A, 2016, I S BIOMED IMAGING, P791, DOI 10.1109/ISBI.2016.7493385
   Mahapatra D, 2016, LECT NOTES COMPUT SC, V10019, P172, DOI 10.1007/978-3-319-47157-0_21
   Martirosyan NL, 2016, NEUROSURG FOCUS, V40, DOI 10.3171/2016.1.FOCUS15559
   METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Salehi S.S. M., 2017, IEEE Transactions on Medical Imaging
   Sanai N, 2011, NEUROSURGERY, V68, P282, DOI 10.1227/NEU.0b013e318212464e
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suk HI, 2016, LECT NOTES COMPUT SC, V10019, P113, DOI 10.1007/978-3-319-47157-0_14
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102
   Zehri Aqib H, 2014, Surg Neurol Int, V5, P60, DOI 10.4103/2152-7806.131638
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P3025, DOI 10.1109/TIP.2014.2326010
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
   Zhou ZH, 2002, ARTIF INTELL, V137, P239, DOI 10.1016/S0004-3702(02)00190-X
NR 46
TC 26
Z9 27
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 10
EP 20
DI 10.1016/j.jvcir.2018.04.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vazquez-Corral, J
   Bertalmío, M
AF Vazquez-Corral, Javier
   Bertalmio, Marcelo
TI Spatial gamut mapping among non-inclusive gamuts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gamut mapping; Gamut extension; Gamut reduction; Color coherence
ID COLOR; EXTENSION
AB Gamut mapping transforms the color gamut of an image to that of a target device. UTwo cases are usually considered: gamut reduction (target gamut smaller than source gamut), and gamut extension (target gamut larger than the source gamut). Less attention is devoted to the more general case, when neither gamut is fully included in the other. In this work we unify and expand two recent methods for gamut extension and reduction, so as to simultaneously perform both forms of gamut mapping in different regions of the same image without introducing color artifacts or halos. We demonstrate the usefulness of this approach for the traditional gamut mapping problem, and also how the proposed method can be used to adapt the color palette of an image so that it is closer to that of a given reference image. Results are compared with the state-of-the-art and validated through user tests and objective metrics.
C1 [Vazquez-Corral, Javier; Bertalmio, Marcelo] Univ Pompeu Fabra, E-08018 Barcelona, Spain.
C3 Pompeu Fabra University
RP Vazquez-Corral, J (corresponding author), Univ Pompeu Fabra, E-08018 Barcelona, Spain.
EM javier.vazquez@upf.edu; marcelo.bertalmio@upf.edu
RI Bertalmío, Marcelo/A-4341-2012; Vazquez-Corral, Javier/A-5655-2011
OI Vazquez-Corral, Javier/0000-0003-0414-7096; Bertalmio,
   Marcelo/0000-0002-1023-8325
FU European Research Council, Starting Grant [306337]; European Union's
   Horizon 2020 research and innovation programme [761544, 780470]; Spanish
   government; FEDER Fund [TIN2015-71537-P]; Icrea Academia Award; Spanish
   government [IJCI-2014-19516]; H2020 - Industrial Leadership [761544]
   Funding Source: H2020 - Industrial Leadership; European Research Council
   (ERC) [306337] Funding Source: European Research Council (ERC)
FX This work is supported by the European Research Council, Starting Grant
   Ref. 306337; by the European Union's Horizon 2020 research and
   innovation programme under grant agreements Ref. 761544 and Ref. 780470;
   by the Spanish government and FEDER Fund, grant Ref.
   TIN2015-71537-P(MINECO/FEDER,UE); and by the Icrea Academia Award. The
   work of J. Vazquez-Corral was supported by the Spanish government, grant
   IJCI-2014-19516.
CR Alsam A, 2012, LECT NOTES COMPUT SC, V7431, P556, DOI 10.1007/978-3-642-33179-4_53
   Alsam A, 2009, LECT NOTES COMPUT SC, V5575, P109, DOI 10.1007/978-3-642-02230-2_12
   Anderson H, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P188, DOI 10.1109/ICIAPW.2007.27
   [Anonymous], 2002, THESIS
   Bertalmío M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777
   Bertalmío M, 2009, INT J COMPUT VISION, V83, P101, DOI 10.1007/s11263-009-0221-5
   Casella S. E., 2008, 16 COLOR IMAGING C C, P106
   Dain SJ, 2016, J OPT SOC AM A, V33, pA300, DOI 10.1364/JOSAA.33.00A300
   Farup I, 2007, IEEE T IMAGE PROCESS, V16, P2423, DOI 10.1109/TIP.2007.904946
   Frigo O, 2016, IEEE T IMAGE PROCESS, V25, P5455, DOI 10.1109/TIP.2016.2601267
   GENTILE RS, 1990, J IMAGING TECHNOL, V16, P176
   HaCohen Y, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461997
   HaCohen Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964965
   Heckaman R.L., 2011, SID Symposium Digest of Technical Papers, V42, P225, DOI DOI 10.1889/1.3621279
   Jang K., 2013, P INT C FUT INF COMM, P559
   Kang BH, 2003, ETRI J, V25, P156, DOI 10.4218/etrij.03.0102.3315
   Kotera H, 2005, IEEE IMAGE PROC, P2549
   Laird J, 2009, COLOR RES APPL, V34, P443, DOI 10.1002/col.20537
   Li Y., 2011, 2011 INT C ELECT INF, P1035
   Lindner A., IEEE TMM T MULTIMED
   McCann J. J., 2002, CATASTROPHE CULTURE, P213
   Meng X., 2013, 2012 INT C INFORM TE, P705
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moroviˇc Jan., 2008, Color gamut mapping, V10
   Murch G. M., 1989, EUROGRAPHICS SEMINAR, P41
   Pan H, 2008, SID INT SYMP DIG TEC, V39, P1363, DOI 10.1889/1.3069398
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Pytlarz J., IET C P
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Schweiger F., 2016, P SMPTE ANN TECH C E, P1
   Thurstone L. L., 1927, PSYCHOL REV, V34
   Vazquez-Corral J, 2016, IEEE IMAGE PROC, P3349, DOI 10.1109/ICIP.2016.7532980
   Vazquez-Corral J, 2014, IEEE T IMAGE PROCESS, V23, P4564, DOI 10.1109/TIP.2014.2344312
   Zamir SW, 2017, IEEE T IMAGE PROCESS, V26, P1595, DOI 10.1109/TIP.2017.2661404
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Zamir S. W., 2015, P IS T SPIE HUM VIS
   Zamir SW, 2014, IEEE J-STSP, V8, P490, DOI 10.1109/JSTSP.2014.2313182
NR 37
TC 4
Z9 4
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 204
EP 212
DI 10.1016/j.jvcir.2018.05.012
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800018
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Atta, R
   Ghanbari, M
AF Atta, Randa
   Ghanbari, Mohammad
TI A high payload steganography mechanism based on wavelet packet
   transformation and neutrosophic set
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image steganography; Wavelet packet transformation; Neutrosophic set;
   Edge detection
ID DIGITAL IMAGES; STEGANALYSIS
AB In this paper a steganographic method is proposed to improve the capacity of the hidden secret data and to provide an imperceptible stego-image quality. The proposed steganography algorithm is based on the wavelet packet decomposition (WPD) and neutrosophic set. First, an original image is decomposed into wavelet packet coefficients. Second, the generalized parent child relationships of spatial orientation trees for wavelet packet decomposition are established among the wavelet packet subbands. An edge detector based on the neutrosophic set named (NSED) is then introduced and applied on a number of subbands. This leads to classify each wavelet packet tree into edge/non-edge tree to embed more secret bits into the coefficients in the edge tree than those in the non-edge tree. The embedding is done based on the least significant bit substitution scheme. Experimental results demonstrate that the proposed method achieves higher embedding capacity with better imperceptibility compared to the published steganographic methods.
C1 [Atta, Randa] Port Said Univ, Dept Elect Engn, Port Said 42523, Egypt.
   [Ghanbari, Mohammad] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 Egyptian Knowledge Bank (EKB); Port Said University; University of
   Tehran; University of Essex
RP Atta, R (corresponding author), Port Said Univ, Dept Elect Engn, Port Said 42523, Egypt.
EM r.atta@eng.psu.edu.eg; ghan@ut.ac.ir
RI Atta, Randa/I-8824-2019; Ghanbari, Mohammad/L-4053-2019
OI Atta, Randa/0000-0001-8294-7780; Ghanbari, Mohammad/0000-0002-5482-8378
CR Amarunnishad T. M., 2006, ADCOM 2006: Autonomic Computing Fourteenth International Conference on Advanced Computing and Communications, P344
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], WORLD ACAD SCI ENG T
   [Anonymous], 2011, P 13 INF HID C PRAG
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Chu R., 2004, P INT C AC SPEECH SI
   Chutani S., 2012, INT J COMPUTERS TECH, V3, P153
   Cogranne R., 2015, IEEE INT WORKSH INF, P16
   El Safy R. O., 2009, 2009 International Conference on Networking and Media Convergence (ICNM'09), P111, DOI 10.1109/ICNM.2009.4907200
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Guo YH, 2014, COMPUT ELECTR ENG, V40, P3, DOI 10.1016/j.compeleceng.2014.04.020
   Guo YH, 2009, PATTERN RECOGN, V42, P587, DOI 10.1016/j.patcog.2008.10.002
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Hussain M, 2017, SIGNAL PROCESS-IMAGE, V50, P44, DOI 10.1016/j.image.2016.10.005
   Hussain M, 2016, SYMMETRY-BASEL, V8, DOI 10.3390/sym8060041
   Kaur K., 2010, INT J COMPUT APPL, V1, P57, DOI [10.5120/442-675, DOI 10.5120/442-675]
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Lai BL, 2006, LECT NOTES COMPUT SC, V4319, P1085
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Liang L.R., 2003, APPL SOFT COMPUT, V3, P123, DOI DOI 10.1016/S1568-4946(03)00008-5
   Liao X, 2011, J VIS COMMUN IMAGE R, V22, P1, DOI 10.1016/j.jvcir.2010.08.007
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Provos N., 2001, P 10 C USENIX SEC S, V10
   Seyyedi SA, 2014, INT J SECUR APPL, V8, P183, DOI 10.14257/ijsia.2014.8.4.17
   Smarandache F., 2003, A Unifying Field in Logics: Neutrosophic Logic, V3rd
   Suryakant N. K., 2012, Int. J. Adv. Res. Comput. Sci. Software Eng., V2, P38
   Tseng H.-W., 2014, IET IMAGE P, V8
   Tseng HW, 2013, J APPL MATH, DOI 10.1155/2013/189706
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Xuan GR, 2002, ELECTRON LETT, V38, P1646, DOI 10.1049/el:20021131
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 40
TC 39
Z9 39
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 42
EP 54
DI 10.1016/j.jvcir.2018.03.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800005
DA 2024-07-18
ER

PT J
AU Zhang, JH
   Zhao, YZ
   Chen, SY
AF Zhang, Jianhua
   Zhao, Yanzhu
   Chen, Shengyong
TI Object-level saliency: Fusing objectness estimation and saliency
   detection into a uniform framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object-level; Salient object detection; Saliency; Objectness; Background
   prior; Peeling
AB Most existing saliency detection algorithms concentrate on obtaining good results for images with single salient object, while it produces poor generalization power when tested on more realistic images. In this paper, we present a novel framework to detect saliency in object-level through fusing objectness estimation into the process of salient object detection. Different from most existing methods that evaluate saliency via aggregation of adjacent pixels or regions, our approach peels background regions step by step via evaluating each region's saliency, objectness and background, until all the independent foreground objects are left. Instead of extracting from saliency map, the proposed method can obtain salient objects directly, and different salient scores can be assigned to different salient objects. Experimental results show that the proposed method is effective and achieves state-of-the-art performance in several benchmark datasets, especially on PASCAL_S and SED2 that offer salient objects in more complicated scenes.
C1 [Zhang, Jianhua; Zhao, Yanzhu; Chen, Shengyong] Zhejiang Univ Technol, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Zhao, YZ (corresponding author), Zhejiang Univ Technol, Sch Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM yanzhu.zhao@hotmail.com
RI Chen, S./H-3083-2011
OI Zhang, Jianhua/0000-0001-7844-6035; Chen, S.Y./0000-0002-6705-3831
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CARREIRA J, 2010, PROC CVPR IEEE, P3241, DOI DOI 10.1109/CVPR.2010.5540063
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen XJ, 2017, IEEE I CONF COMP VIS, P2080, DOI 10.1109/ICCV.2017.227
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Donoser M, 2014, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2014.404
   Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Humayun A, 2014, PROC CVPR IEEE, P336, DOI 10.1109/CVPR.2014.50
   Itti, 2007, Scholarpedia, V2, P3327, DOI DOI 10.4249/SCHOLARPEDIA.3327
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Peng H., 2014, RGBD SALIENT OBJECT
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351
   Ren TW, 2016, MULTIMED TOOLS APPL, V75, P2543, DOI 10.1007/s11042-015-2875-z
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xia C., 2017, PROC CVPR IEEE, P4142, DOI DOI 10.1109/CVPR.2017.468
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang JM, 2016, PROC CVPR IEEE, P5733, DOI 10.1109/CVPR.2016.618
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang LH, 2015, NEUROCOMPUTING, V155, P1, DOI 10.1016/j.neucom.2014.12.080
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 49
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 102
EP 112
DI 10.1016/j.jvcir.2018.03.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800010
DA 2024-07-18
ER

PT J
AU Hong, SH
   Wang, L
   Truong, TK
AF Hong, Shao-Hua
   Wang, Lin
   Trieu-Kien Truong
TI Low-complexity direct computation algorithm for cubic-spline
   interpolation scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cubic-spline interpolation; Direct computation algorithm; Fast Fourier
   transform; Low-complexity direct computation algorithm
ID CONVOLUTION
AB Cubic-spline interpolation (CSI) scheme is known to be designed to resample the discrete image data based on the least-square method in conjunction with the cubic convolution interpolation (CCI) function. It is superior in performance and can be used together with the discrete cosine transform (DCT)-based image or video codec to improve the coding performance for a variety of high compression ratios. In this paper, we firstly make some comments on the direct computation algorithm for CSI scheme developed by Lin et al. Moreover, a low-complexity direct computation algorithm for CSI scheme is developed to further improve the computational efficiency. The mathematical derivations and simulation results indicate that such simplified CSI scheme using the proposed low-complexity direct computation algorithm can achieve almost the same objective and subjective performance with much fewer arithmetic operations in comparison with the CSI scheme using the direct computation algorithm.
C1 [Hong, Shao-Hua; Wang, Lin] Xiamen Univ, Dept Commun Engn, Xiamen 361005, Fujian, Peoples R China.
   [Trieu-Kien Truong] I Shou Univ, Dept Informat Engn, Kaohsiung 840, Kaohsiung Cty, Taiwan.
   [Trieu-Kien Truong] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung 804, Kaohsiung Cty, Taiwan.
C3 Xiamen University; I Shou University; National Sun Yat Sen University
RP Hong, SH (corresponding author), Xiamen Univ, Dept Commun Engn, Xiamen 361005, Fujian, Peoples R China.
EM hongsh@xmu.edu.cn
RI wang, lin/GSE-3040-2022; LIN, WANG/JWA-3182-2024; wang,
   lin/HZK-4145-2023; wang, lili/HDL-7210-2022; wang, lin/HHM-2225-2022
FU National Natural Science Foundation of China [61271241, 61671395];
   National Science Foundation of Fujian Province of China [2014J01248]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61271241 and No. 61671395, and the National
   Science Foundation of Fujian Province of China (No. 2014J01248).
CR Blahut R.E., 1984, FAST ALGORITHM DIGIT
   Choi JS, 2016, IEEE T IMAGE PROCESS, V25, P469, DOI 10.1109/TIP.2015.2507402
   Guven O, 2016, HEALTHC TECHNOL LETT, V3, P105, DOI 10.1049/htl.2015.0031
   Hong SH, 2013, IEEE T IMAGE PROCESS, V22, P1233, DOI 10.1109/TIP.2012.2230009
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   KOLBA DP, 1977, IEEE T ACOUST SPEECH, V25, P281, DOI 10.1109/TASSP.1977.1162973
   Lee SJ, 2016, IEEE T CONSUM ELECTR, V62, P159, DOI 10.1109/TCE.2016.7514715
   Lin TC, 2010, IEEE T IMAGE PROCESS, V19, P2913, DOI 10.1109/TIP.2010.2050723
   McCann MT, 2017, IEEE T IMAGE PROCESS, V26, P4639, DOI 10.1109/TIP.2017.2706521
   MEAD C., 1980, INTRO VLSI SYSTEM
   Truong TK, 2000, IEEE T IMAGE PROCESS, V9, P1988, DOI 10.1109/83.877222
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221
   Wang LJ, 2004, IEEE SIGNAL PROC LET, V11, P768, DOI 10.1109/LSP.2004.833479
   Wang LJ, 2001, IEEE T SIGNAL PROCES, V49, P1189
   Wu JJ, 2016, IEEE T IMAGE PROCESS, V25, P5369, DOI 10.1109/TIP.2016.2604489
   Zhu SY, 2016, IEEE T MULTIMEDIA, V18, P1707, DOI 10.1109/TMM.2016.2593039
NR 17
TC 8
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 159
EP 166
DI 10.1016/j.jvcir.2017.11.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700016
OA Bronze
DA 2024-07-18
ER

PT J
AU Lin, JL
   Chen, YW
   Chang, YL
   An, JC
   Zhang, K
   Huang, YW
   Lei, SM
AF Lin, Jian-Liang
   Chen, Yi-Wen
   Chang, Yu -Lin
   An, Jicheng
   Zhang, Kai
   Huang, Yu-Wen
   Lei, Shawmin
TI Advanced texture and depth coding in 3D-HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; Inter-view motion prediction; Disparity derivation; Depth
   coding
ID HEVC
AB The 3D extension of High Efficiency Video Coding (3D-HEVC) is a new international video coding standard developed by the Joint Collaborative Team on 3D Video Coding Extensions (JCT-3V) in order to support coding of multiple views and its associated depth data. 3D-HEVC aims at improving the coding efficiency of 3D and multi-view videos by introducing new coding tools to utilize the correlations between views and between texture and depth components. In this paper, an inter-view motion prediction (inter-view merge candidate) and an inter component motion prediction (texture merge candidate) are proposed to explore the inter-view and the inter component redundancies for texture and depth components, respectively. Moreover, a new coding mode termed as single depth mode which simply reconstructs a coding block with a single depth value based on block merging scheme under the HEVC quad-tree based block partitioning is also introduced. All the proposed schemes are adopted in 3D-HEVC. The experimental results evaluated under the common test conditions (CTC) for developing 3D-HEVC show that the proposed inter-view merge candidate, texture merge candidate, and single depth mode achieve significant BD-rate reductions of 19.5% for dependent texture views and 8.3% for the synthesized texture views.
C1 [Lin, Jian-Liang; Chen, Yi-Wen; Chang, Yu -Lin; An, Jicheng; Zhang, Kai; Huang, Yu-Wen; Lei, Shawmin] MediaTek, Hsinchu, Taiwan.
C3 Mediatek Incorporated
RP Chen, YW (corresponding author), MediaTek, Hsinchu, Taiwan.
EM ywchen0711@gmail.com
OI Huang, Yu-Wen/0000-0003-3045-1104
CR An J., 2013, JCT3VF0110
   An J., 2012, JCT3VA0049
   [Anonymous], JCT3VF1002
   [Anonymous], 2015, JCT3VK0033
   [Anonymous], 2008, JTC1SC29WG11 ISOIEC
   [Anonymous], JCT3VJ1001
   [Anonymous], 2008, VCEG-AI11
   Chang Y.-L., 2013, JCT3VD0138
   Chen Y., 2014, JCT3VG0119
   Chen Y.W., 2014, JCT3VI0095
   Chen Y.-W., 2013, JCT3VC0137
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Jager F., 2012, JCT3VA0010
   Kim Il-Koo, 2012, IEEE T CIRCUITS SYST, V22
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li Zhang, 2014, 2014 IEEE International Symposium on Circuits and Systems (ISCAS), P17, DOI 10.1109/ISCAS.2014.6865054
   Lin J.-L., 2013, JCT3VD0109
   Rusanovskyy D., 2013, JCT3VD1100
   Stefanoski N., 2011, JTC1SC29WG11 ISOIEC
   Tech G., 2016, JCT3VN1012
   Tian D., 2013, JCT3V00152
   Zhang K., 2014, JCT3VG0063
   Zhang L, 2013, IEEE INT SYMP CIRC S, P1632, DOI 10.1109/ISCAS.2013.6572175
NR 23
TC 4
Z9 6
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 83
EP 92
DI 10.1016/j.jvcir.2017.11.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700009
DA 2024-07-18
ER

PT J
AU Li, XT
   Ng, MK
   Ye, YM
   Wang, EK
   Xu, XF
AF Li, Xutao
   Ng, Michael K.
   Ye, Yunming
   Wang, Eric Ke
   Xu, Xiaofei
TI Block linear discriminant analysis for visual tensor objects with
   frequency or time information
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tensors; Discriminant analysis; Hyperspectral face recognition;
   Gait recognition; Between-class scatter; Within-class scatter
ID PRINCIPAL; PCA
AB Recently, due to the advancement of acquisition techniques, visual tensor data have been accumulated in a great variety of engineering fields, e.g., biometrics, neuroscience, surveillance and remote sensing. How to analyze and learn with such tensor objects thus becomes an important and growing interest in machine learning community. In this paper, we propose a block linear discriminant analysis (BLDA) algorithm to extract features for visual tensor objects such as multichannel/hyperspectral face images or human gait videos. Taking the inherent characteristic of such tensor data into account, we unfold tensor objects according to their spatial information and frequency/time information, and represent them in a block matrix form. As a result, the block form between-class and within-class scatter matrices are constructed, and a related block eigen-decomposition is solved to extract features for classification. Comprehensive experiments have been carried out to test the effectiveness of the proposed method, and the results show that BLDA outperforms existing algorithms like DATER, 2DLDA, GTDA, UMLDA, STDA and MPCA for visual tensor object analysis. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Li, Xutao; Ye, Yunming; Wang, Eric Ke; Xu, Xiaofei] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen Key Lab Internet Informat Collaborat, Harbin, Heilongjiang, Peoples R China.
   [Ng, Michael K.] Hong Kong Baptist Univ, Dept Math, Kowloon Tong, Hong Kong, Peoples R China.
C3 Harbin Institute of Technology; Hong Kong Baptist University
RP Li, XT (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen Key Lab Internet Informat Collaborat, Harbin, Heilongjiang, Peoples R China.
EM lixutao@hit.edu.cn; mng@math.hkbu.edu.hk; yeyunming@hitsz.edu.cn;
   wk_hit@hitsz.edu.cn; xiaofei@hit.edu.cn
RI Xu, Xiaofei/IQS-7571-2023; Ng, Michael/B-7189-2009; NG,
   Michael/AAG-9117-2020
OI Ng, Michael/0000-0001-6833-5227; 
FU NSFC [61602132, 61572158]; Shenzhen Science and Technology Program
   [JCYJ20160330163900579, JSGG20150512145714247]; HKRGC GRF Grant [202013,
   12302715, HKBUFRG2/14-15/087, HKBU12306616, HKBU12302715]
FX The research was supported in part by NSFC under Grant Nos. 61602132and
   61572158, and Shenzhen Science and Technology Program under Grant Nos.
   JCYJ20160330163900579 and JSGG20150512145714247, and by HKRGC GRF Grant
   Nos. 202013 and 12302715, HKBUFRG2/14-15/087, HKBU12306616 and
   HKBU12302715.
CR [Anonymous], 2004, ADV NEURAL INF PROCE
   [Anonymous], ELECT IMAGING 2007
   [Anonymous], 31 AAAI C ART INT
   [Anonymous], 2015, IEEE T IMAGE PROCESS
   Denes L, 2002, CMURITR0225
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   Duda R. O., 2012, PATTERN CLASSIFICATI, DOI DOI 10.1007/978-3-319-57027-3_4
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li XB, 2012, PRZ ELEKTROTECHNICZN, V88, P141
   Li XT, 2014, IEEE T KNOWL DATA EN, V26, P929, DOI 10.1109/TKDE.2013.48
   Lin YR, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P527
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P1820, DOI 10.1109/TNN.2009.2031144
   Lu HP, 2009, IEEE T NEURAL NETWOR, V20, P103, DOI 10.1109/TNN.2008.2004625
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Miwakeichi F, 2004, NEUROIMAGE, V22, P1035, DOI 10.1016/j.neuroimage.2004.03.039
   Morup M, 2006, NEUROIMAGE, V29, P938, DOI 10.1016/j.neuroimage.2005.08.005
   Ng M. K.-P., 2011, P 17 ACM SIGKDD INT, P1217
   Oh SM, 2011, PROC CVPR IEEE
   Ryoo MS, 2010, LECT NOTES COMPUT SC, V6388, P270, DOI 10.1007/978-3-642-17711-8_28
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Uzair M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.57
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang Z, 2015, NEUROCOMPUTING, V149, P1058, DOI 10.1016/j.neucom.2014.07.028
   Zhang Z, 2011, IEEE SIGNAL PROC LET, V18, P643, DOI 10.1109/LSP.2011.2165538
NR 29
TC 2
Z9 2
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 38
EP 46
DI 10.1016/j.jvcir.2017.08.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800004
DA 2024-07-18
ER

PT J
AU Magri, L
   Fusiello, A
AF Magri, Luca
   Fusiello, Andrea
TI Multiple structure recovery with T-linkage
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Multi-model fitting; Grouping; Segmentation
ID ROBUST ESTIMATION; FRAMEWORK; CONSENSUS; REPRESENTATIONS;
   CLASSIFICATION; SEGMENTATION; MOTION
AB This work addresses the problem of robust fitting of geometric structures to noisy data corrupted by outliers. An extension of J-linkage (called T-linkage) is presented and elaborated. T-linkage improves the preference analysis implemented by J-linkage in term of performances and robustness, considering both the representation and the segmentation steps. A strategy to reject outliers and to estimate the inlier threshold is proposed, resulting in a versatile tool, suitable for multi-model fitting "in the wild". Experiments demonstrate that our methods perform better than J-linkage on simulated data, and compare favorably with state-of-the-art methods on public domain real datasets. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Magri, Luca] Univ Verona, Dip Informat, Str Le Grazie 15, Verona, Italy.
   [Fusiello, Andrea] Univ Udine, DPIA, Via Sci 208, Udine, Italy.
C3 University of Verona; University of Udine
RP Magri, L (corresponding author), Univ Verona, Dip Informat, Str Le Grazie 15, Verona, Italy.
EM magri.luca.1@gmail.com
RI Fusiello, Andrea/GOJ-9893-2022; Magri, Luca/AAU-2569-2021
OI Fusiello, Andrea/0000-0003-2963-0316; Magri, Luca/0000-0002-0598-8279
CR Agarwal S, 2005, PROC CVPR IEEE, P838
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   [Anonymous], BRIT MACH VIS C
   [Anonymous], LECT NOTES COMPUT 1
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], THESIS
   [Anonymous], 2011, HELMHOLTZ PRINCIPLE
   [Anonymous], PAMI
   [Anonymous], LNCS
   [Anonymous], P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P EUR C COMP VISION
   [Anonymous], P INT C COMP VIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2011, P 24 INT C NEUR INF
   [Anonymous], THESIS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2005, P IEEE INT C IM PROC
   Atkinson Anthony., 2013, Exploring multivariate data with the forward search
   Bab-Hadiashar A, 1999, ROBOTICA, V17, P649, DOI 10.1017/S0263574799001812
   Bicego M, 2004, PATTERN RECOGN, V37, P2281, DOI 10.1016/j.patcog.2004.04.005
   Chauve AL, 2010, PROC CVPR IEEE, P1261, DOI 10.1109/CVPR.2010.5539824
   Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Delong A, 2012, LECT NOTES COMPUT SC, V7572, P370, DOI 10.1007/978-3-642-33718-5_27
   Desolneux A., 2007, GESTALT THEORY IMAGE, V34
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fan LX, 2008, LECT NOTES COMPUT SC, V5304, P182
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fitzgibbon AW, 2000, LECT NOTES COMPUT SC, V1842, P891
   Govindu VM, 2005, PROC CVPR IEEE, P1150
   Häne C, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P563, DOI 10.1109/3DIMPVT.2012.55
   Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7
   Jaccard P., 1901, B SOCIT VAUDOISE SCI, V37, P547, DOI [10.5169/seals-266440, DOI 10.5169/SEALS-266440]
   Lai C, 2004, INT J PATTERN RECOGN, V18, P867, DOI 10.1142/S0218001404003459
   Lai TT, 2016, MULTIMED TOOLS APPL, V75, P7445, DOI 10.1007/s11042-016-3365-7
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Lee KM, 1998, IEEE T PATTERN ANAL, V20, P200, DOI 10.1109/34.659940
   Lipkus AH, 1999, J MATH CHEM, V26, P263, DOI 10.1023/A:1019154432472
   Magri L, 2015, LECT NOTES COMPUT SC, V9279, P73, DOI 10.1007/978-3-319-23231-7_7
   Miller JV, 1996, PROC CVPR IEEE, P300, DOI 10.1109/CVPR.1996.517089
   Moisan L, 2012, IMAGE PROCESS ON LIN, V2, P56, DOI 10.5201/ipol.2012.mmm-oh
   Monti S, 2003, MACH LEARN, V52, P91, DOI 10.1023/A:1023949509487
   Orozco-Alzate M, 2009, PATTERN RECOGN LETT, V30, P242, DOI 10.1016/j.patrec.2008.09.010
   Ozden KE, 2010, IEEE T PATTERN ANAL, V32, P1134, DOI 10.1109/TPAMI.2010.23
   Pekalska E., 2005, The Dissimilarity Representation for Pattern Recognition
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Raguram R, 2011, IEEE I CONF COMP VIS, P1299, DOI 10.1109/ICCV.2011.6126382
   Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191
   Schindler K, 2008, INT J COMPUT VISION, V79, P159, DOI 10.1007/s11263-007-0111-7
   STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558
   Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280
   Subbarao R., 2006, CVPR, V1, P1168
   Tanimoto T. T., 1958, ELEMENTARY MATH THEO
   Tepper M, 2014, SIAM J IMAGING SCI, V7, P2488, DOI 10.1137/140967325
   Tiwari L, 2016, IEEE IMAGE PROC, P3728, DOI 10.1109/ICIP.2016.7533056
   Toldo R, 2013, IMAGE VISION COMPUT, V31, P756, DOI 10.1016/j.imavis.2013.07.007
   Toldo R, 2009, LECT NOTES COMPUT SC, V5716, P123, DOI 10.1007/978-3-642-04146-4_15
   TORR PHS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1037, DOI 10.1109/ICCV.1995.466820
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296
   Tron R., 2007, P IEEE C COMPUTER VI
   Wang Hanzi, 2015, P INT C COMP VIS
   Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109
   Xiao GB, 2016, PATTERN RECOGN, V60, P748, DOI 10.1016/j.patcog.2016.06.026
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang A.Y., 2006, CVPRW 06 P 2006 C CO, P99
   Zass R, 2005, IEEE I CONF COMP VIS, P294
NR 71
TC 4
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 57
EP 77
DI 10.1016/j.jvcir.2017.08.005
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Alilou, VK
   Yaghmaee, F
AF Alilou, Vahid K.
   Yaghmaee, Farzin
TI Non-texture image inpainting using histogram of oriented gradients
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Histogram of oriented gradients; Dominant orientation;
   Local gradients
ID ERROR CONCEALMENT; NONLOCAL-MEANS; NOISE REMOVAL
AB This paper presents a novel and efficient algorithm for non-texture inpainting of images based on using the dominant orientation of local gradients. It first introduces the concept of a new matrix called orientation matrix and then uses it for faster and better inpainting. The process of propagating information is carried out by using a new formulation which leads to much more efficient computations than the previous methods. The gain is both in terms of computational complexity and visual quality. The promising results in contexts of text, scratch, and block loss inpainting demonstrate the effectiveness of the proposed method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Alilou, Vahid K.] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
   [Yaghmaee, Farzin] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University; Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM f_yaghmaee@semnan.ac.ir
RI Yaghmaee, Farzin/AAZ-6590-2021; K. Alilou, Vahid/AAQ-6281-2020
OI Yaghmaee, Farzin/0000-0001-7430-542X; K. Alilou,
   Vahid/0000-0002-9230-8277
CR Alilou V. K., 2016, MULTIMED TOOLS APPL, P1
   Alilou VK, 2015, PATTERN RECOGN LETT, V62, P24, DOI 10.1016/j.patrec.2015.04.020
   [Anonymous], 4 INT WORKSH VID PRO
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Benzarti F., ABS13052221 CORR
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bertalmio M., 2001, Computer Vision and Pattern Recognition, V1, P1
   Bornemann F, 2007, J MATH IMAGING VIS, V28, P259, DOI 10.1007/s10851-007-0017-6
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Chalmers A., IMAGE QUALITY METRIC
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2006, J MATH IMAGING VIS, V25, P107, DOI 10.1007/s10851-006-5257-3
   Chen Wang, 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C)
   Chung B, 2014, SIGNAL PROCESS-IMAGE, V29, P1121, DOI 10.1016/j.image.2014.09.009
   Collins Matthew, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1235, DOI 10.1109/ICCVW.2009.5457467
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dahl J., NUMER ALGORITHMS, P53
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fornasier M, 2006, J MATH IMAGING VIS, V24, P359, DOI 10.1007/s10851-006-4242-1
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Huan XL, 2010, COMPUT VIS IMAGE UND, V114, P847, DOI 10.1016/j.cviu.2010.04.007
   Igehy H, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P186, DOI 10.1109/ICIP.1997.632049
   JUNG KH, 1994, P SOC PHOTO-OPT INS, V2308, P1466, DOI 10.1117/12.185905
   Kobayashi T, 2008, LECT NOTES COMPUT SC, V4985, P598
   Komodakis N., IEEE T IMAGE PROCESS, P16
   Kumar Veepin, 2015, Combinatorial Image Analysis. 17th International Workshop, IWCIA 2015. Proceedings, P284, DOI 10.1007/978-3-319-26145-4_21
   Kumar Veepin, 2015, Pattern Recognition and Machine Intelligence. 6th International Conference, PReMI 2015. Proceedings: LNCS 9124, P116, DOI 10.1007/978-3-319-19941-2_12
   Kumar V, 2016, IEEE T IMAGE PROCESS, V25, P5212, DOI 10.1109/TIP.2016.2605919
   Li X., IEEE T CIRC SYST VID, P12
   Liu D, 2012, J VIS COMMUN IMAGE R, V23, P100, DOI 10.1016/j.jvcir.2011.09.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Malgouyres F, 2001, SIAM J NUMER ANAL, V39, P1, DOI 10.1137/S0036142999362286
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   Melgosa M, 2000, COLOR RES APPL, V25, P49, DOI 10.1002/(SICI)1520-6378(200002)25:1<49::AID-COL7>3.0.CO;2-4
   Mosleh A, 2014, J VIS COMMUN IMAGE R, V25, P855, DOI 10.1016/j.jvcir.2014.01.007
   Mosleh A, 2013, IEEE T IMAGE PROCESS, V22, P4460, DOI 10.1109/TIP.2013.2273672
   Nanni L, 2009, EXPERT SYST APPL, V36, P12414, DOI 10.1016/j.eswa.2009.04.041
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343
   Phadikar A, 2010, IEEE T CONSUM ELECTR, V56, P971, DOI 10.1109/TCE.2010.5506028
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Venkatesh MV, 2009, PATTERN RECOGN LETT, V30, P168, DOI 10.1016/j.patrec.2008.03.011
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wikipedia Ycbcr Wikipedia, 2017, YCBCR WIK FREE ENC
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Wong BY, 2012, IEEE T MULTIMEDIA, V14, P760, DOI 10.1109/TMM.2012.2188997
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P1651, DOI 10.1109/TIP.2010.2044960
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang XQ, 2015, AEU-INT J ELECTRON C, V69, P307, DOI 10.1016/j.aeue.2014.09.018
NR 56
TC 12
Z9 15
U1 0
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 43
EP 53
DI 10.1016/j.jvcir.2017.06.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700004
DA 2024-07-18
ER

PT J
AU Garduño-Ramón, MA
   Terol-Villalobos, IR
   Osornio-Rios, RA
   Morales-Hernandez, LA
AF Antonio Garduno-Ramon, Marco
   Ramon Terol-Villalobos, Ivan
   Alfredo Osornio-Rios, Roque
   Alberto Morales-Hernandez, Luis
TI A new method for inpainting of depth maps from time-of-flight sensors
   based on a modified closing by reconstruction algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Time-of-flight; Depth maps; Mathematical morphology; Morphological
   reconstruction; Modified closing by reconstruction
ID IMAGE; CAMERAS; CALIBRATION; INDOOR; COLOR; ENHANCEMENT; CONFIDENCE;
   RECOVERY; FILTER
AB Time-of-Flight (ToF) sensors are popular devices that extract 3D information from a scene but result to be susceptible to noise and loss of data creating holes and gaps in the boundaries of the objects. The most common approaches to tackling this problem are supported by color images with good results, however, not all ToF devices produce color information. Mathematical morphology provides operators that can manage the problem of noise in single depth frames. In this paper, a new method for the filtering of single depth maps, when no color image is available, is presented, based on a modification to the morphological closing by reconstruction algorithm. The proposed method eliminates noise, emphasizing a high contour preservation, and it is compared, both qualitative and quantitatively, with other state-of-the-art filters. The proposed method represents an improvement to the closing by reconstruction algorithm that can be applied for filter depth maps of ToF devices. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Antonio Garduno-Ramon, Marco; Alfredo Osornio-Rios, Roque; Alberto Morales-Hernandez, Luis] Univ Autonoma Queretaro, Fac Ingn, Rio Moctezuma 249, San Juan Del Rio 76807, Queretaro, Mexico.
   [Ramon Terol-Villalobos, Ivan] CIDETEQ SC, Parque Tecnol Queretaro S-N, Pedro Escobedo 76700, Queretaro, Mexico.
C3 Universidad Autonoma de Queretaro; CIDETEQ - Centro de Investigacion &
   Desarrollo Tecnologico en Electroquimica S.C.
RP Morales-Hernandez, LA (corresponding author), Univ Autonoma Queretaro, Fac Ingn, Rio Moctezuma 249, San Juan Del Rio 76807, Queretaro, Mexico.
EM luis.morales@uaq.mx
RI ; Osornio-Rios, Roque A/B-1970-2015; Morales-Hernandez, Luis
   Alberto/K-5446-2017
OI Garduno Ramon, Marco Antonio/0000-0002-7184-277X; Osornio-Rios, Roque
   A/0000-0003-0868-2918; Morales-Hernandez, Luis
   Alberto/0000-0002-6483-0543
FU Mexican National Council for Science and Technology (CONACYT)
   [487601/278034]
FX Garduilo-Ramon expresses his gratitude to the Mexican National Council
   for Science and Technology (CONACYT) for financing this work through the
   Ph.D. scholarship 487601/278034.
CR Acosta D, 2013, J MATH IMAGING VIS, V47, P3, DOI 10.1007/s10851-012-0366-7
   Amamra A., 2014, J REAL TIME IMAGE PR
   Le AV, 2014, SENSORS-BASEL, V14, P11362, DOI 10.3390/s140711362
   Bhavsar AV, 2012, COMPUT VIS IMAGE UND, V116, P572, DOI 10.1016/j.cviu.2011.12.005
   Burger W., 2009, Principles of Digital Image Processing
   Chan D., 2008, NOISE AWARE FILTER R
   Chiabrando F, 2009, SENSORS-BASEL, V9, P10080, DOI 10.3390/s91210080
   Choo B, 2014, SENSORS-BASEL, V14, P17430, DOI 10.3390/s140917430
   Fernandez-Sanchez EJ, 2013, SENSORS-BASEL, V13, P8895, DOI 10.3390/s130708895
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Garcia F, 2015, IMAGE VISION COMPUT, V41, P26, DOI 10.1016/j.imavis.2015.06.008
   Garrido-Jurado S, 2016, J VIS COMMUN IMAGE R, V39, P120, DOI 10.1016/j.jvcir.2016.05.014
   Gasparrini S, 2014, SENSORS-BASEL, V14, P2756, DOI 10.3390/s140202756
   Gong XJ, 2013, IMAGE VISION COMPUT, V31, P695, DOI 10.1016/j.imavis.2013.07.006
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Jung CK, 2015, J VIS COMMUN IMAGE R, V33, P1, DOI 10.1016/j.jvcir.2015.08.010
   Jung SW, 2013, IEEE T CIRC SYST VID, V23, P269, DOI 10.1109/TCSVT.2012.2203734
   Kazmi W, 2014, ISPRS J PHOTOGRAMM, V88, P128, DOI 10.1016/j.isprsjprs.2013.11.012
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Lasang P, 2016, J VIS COMMUN IMAGE R, V39, P24, DOI 10.1016/j.jvcir.2016.05.006
   Liu J., 2013, GUIDED DEPTH ENHANCE, P408, DOI 10.1007/978-3-319-03731-8_38
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Martull S., REALISTIC CG STERIO
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Najman L., 2013, Mathematical Morphology: from Theory to Applications
   Paulus S, 2014, SENSORS-BASEL, V14, P3001, DOI 10.3390/s140203001
   Peregrina-Barreto H, 2011, J OPT SOC AM A, V28, P455, DOI 10.1364/JOSAA.28.000455
   Peris M., SIMULATION DRIVEN ST
   Petschnigg G., 2004, DIGITAL PHOTOGRAPHY
   Piatti D, 2012, REMOTE SENS-BASEL, V4, P1069, DOI 10.3390/rs4041069
   PoLin Lai, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P9, DOI 10.1109/PCS.2010.5702589
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Schmeing M, 2014, PATTERN RECOGN LETT, V50, P63, DOI 10.1016/j.patrec.2014.03.026
   Serra J., 1983, IMAGE ANAL MATH MORP
   Shahbazi M, 2011, SENSORS-BASEL, V11, P8721, DOI 10.3390/s110908721
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Song XB, 2014, VISUAL COMPUT, V30, P855, DOI 10.1007/s00371-014-0965-y
   Stoyanov T, 2013, ROBOT AUTON SYST, V61, P1094, DOI 10.1016/j.robot.2012.08.011
   Sun SW, 2016, J VIS COMMUN IMAGE R, V35, P36, DOI 10.1016/j.jvcir.2015.11.012
   Tan X, 2016, PATTERN RECOGN, V50, P210, DOI 10.1016/j.patcog.2015.08.003
   Terol-Villalobos IR, 2006, J VIS COMMUN IMAGE R, V17, P107, DOI 10.1016/j.jvcir.2005.01.001
   Calderita LV, 2013, SENSORS-BASEL, V13, P8835, DOI 10.3390/s130708835
   Vijayanagar KR, 2014, MOBILE NETW APPL, V19, P414, DOI 10.1007/s11036-013-0458-7
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Wang C, 2015, J SIGNAL PROCESS SYS, V79, P1, DOI [10.1007/s11265-013-0819-2, 10.1155/2013/390534]
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Xue ZX, 2012, ROBOT AUTON SYST, V60, P387, DOI 10.1016/j.robot.2011.07.012
   Yaman M, 2015, J VIS COMMUN IMAGE R, V26, P115, DOI 10.1016/j.jvcir.2014.11.010
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang QX, 2013, IEEE T IMAGE PROCESS, V22, P4841, DOI 10.1109/TIP.2013.2278917
   Yang YX, 2015, NEUROCOMPUTING, V149, P1396, DOI 10.1016/j.neucom.2014.08.056
   Yu HS, 2014, SENSORS-BASEL, V14, P10753, DOI 10.3390/s140610753
   Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362
NR 55
TC 9
Z9 11
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2017
VL 47
BP 36
EP 47
DI 10.1016/j.jvcir.2017.05.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX8TD
UT WOS:000403522200004
DA 2024-07-18
ER

PT J
AU Rad, R
   Jamzad, M
AF Rad, Roya
   Jamzad, Mansour
TI Image annotation using multi-view non-negative matrix factorization with
   different number of basis vectors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Automatic image annotation; Non-negative matrix factorization (NMF);
   Multi-view NMF
ID MODEL; RETRIEVAL
AB Automatic Image Annotation (AIA) helps image retrieval systems by predicting tags for images. In this paper, we propose an AIA system using Non-negative Matrix Factorization (NMF) framework. The NMF framework discovers a latent space, by factorizing data into a set of non-negative basis and coefficients. To model the images, multiple features are extracted, each one represents images from a specific view. We use multi-view graph regularization NMF and allow NMF to choose a different number of basis vectors for each view. For tag prediction, each test image is mapped onto the multiple latent spaces. The distances of images in these spaces are used to form a unified distance matrix. The weights of distances are learned automatically. Then a search-based method is used to predict tags based on tags of nearest neighbors'. We evaluate our method on three datasets and show that it is competitive with the current stateof-the-art methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Rad, Roya; Jamzad, Mansour] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Rad, R (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM raad@ce.sharif.edu; jamzad@sharif.edu
RI rad, roya/AAN-4434-2021; Rahmani, Maryam/R-3333-2016
CR Alkhawlani M., 2015, INT J COMPUT INFORM, V4
   Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 1998, ENCY BIOSTATISTICS
   BenAbdallah Jaafar, 2010, Proceedings 2010 IEEE/ACM International Conference on Web Intelligence-Intelligent Agent Technology (WI-IAT), P128, DOI 10.1109/WI-IAT.2010.293
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Caicedo J C, 2012, P 2 ACM INT C MULT R, P1
   Caicedo JC, 2012, NEUROCOMPUTING, V76, P50, DOI 10.1016/j.neucom.2011.04.037
   Chen A., 2013, ICML, P1274
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Cooper M, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P25
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Driesen J., 2012, THESIS
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Eweiwi A, 2013, LECT NOTES COMPUT SC, V8142, P61, DOI 10.1007/978-3-642-40602-7_7
   Feng XD, 2016, ENG APPL ARTIF INTEL, V52, P161, DOI 10.1016/j.engappai.2016.02.016
   Grubinger M., 2007, ANAL EVALUATION VISU
   Guan XH, 2009, J NETW COMPUT APPL, V32, P31, DOI 10.1016/j.jnca.2008.04.006
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hidru D., 2014, EQUINMF GRAPH REGULA
   Hong RC, 2014, IEEE T CYBERNETICS, V44, P669, DOI 10.1109/TCYB.2013.2265601
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kim J, 2008, IEEE DATA MINING, P353, DOI 10.1109/ICDM.2008.149
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Li ZC, 2013, NEUROCOMPUTING, V105, P38, DOI 10.1016/j.neucom.2012.02.046
   Li ZX, 2013, ENG APPL ARTIF INTEL, V26, P2143, DOI 10.1016/j.engappai.2013.07.004
   Lienhart R., 2009, Proceeding of the ACM International Conference on Image and Video Retrieval, P1, DOI DOI 10.1145/1646396.1646408
   Liu J., 2013, P 2013 SIAM INT C DA, P252, DOI DOI 10.1137/1.9781611972832.28
   Lo W, 2015, ENG APPL ARTIF INTEL, V38, P14, DOI 10.1016/j.engappai.2014.10.010
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu Z., 2012, P 20 ACM INT C MULT, P499, DOI DOI 10.1145/2393347.2393418
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Moran S, 2014, INT J MULTIMED INF R, V3, P209, DOI 10.1007/s13735-014-0063-y
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Rad R., 2015, IET COMPUT VISION
   Sinhal A., 2013, INT J ENG RES TECHNO, P35
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Tian DP, 2013, IEEE IMAGE PROC, P3996, DOI 10.1109/ICIP.2013.6738823
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Xiang Y, 2009, PROC CVPR IEEE, P1153, DOI 10.1109/CVPRW.2009.5206518
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Y, 2015, J VIS COMMUN IMAGE R, V33, P368, DOI 10.1016/j.jvcir.2015.10.006
NR 48
TC 23
Z9 25
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 1
EP 12
DI 10.1016/j.jvcir.2017.03.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500001
DA 2024-07-18
ER

PT J
AU Fei, MJ
   Jiang, W
   Mao, WJ
AF Fei, Mengjuan
   Jiang, Wei
   Mao, Weijie
TI Memorable and rich video summarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Key frame; Video summary; Memorability; Entropy
ID PARALLEL FRAMEWORK; HEVC; ABSTRACTION; IMAGES
AB Video summarization can facilitate rapid browsing and efficient video indexing in many applications. A good summary should maintain the semantic interestingness and diversity of the original video. While many previous methods extracted key frames based on low-level features, this study proposes Memorability-Entropy-based video summarization. The proposed method focuses on creating semantically interesting summaries based on image memorability. Further, image entropy is introduced to maintain the diversity of the summary. In the proposed framework, perceptual hashing-based mutual information (MI) is used for shot segmentation. Then, we use a large annotated image memorability data set to fine-tune Hybrid-AlexNet. We predict the memorability score by using the fine-tuned deep network and calculate the entropy value of the images. The frame with the maximum memorability score and entropy value in each shot is selected to constitute the video summary. Finally, our method is evaluated on a benchmark dataset, which comes with five human-created summaries. When evaluating our method, we find it generates high-quality results, comparable to human-created summaries and conventional methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Fei, Mengjuan; Jiang, Wei; Mao, Weijie] Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Jiang, W (corresponding author), Zhejiang Univ, Inst Cyber Syst & Control, Hangzhou 310027, Peoples R China.
EM jiangwei_zju@zju.edu.cn
RI jiang, wei/J-6317-2018
OI jiang, wei/0000-0002-9240-5851; Mao, Weijie/0000-0001-5791-1823
FU National Natural Science Foundation of China [61375049]; Autonomous
   Research Project of the State Key Laboratory of Industrial Control
   Technology, China [ICT1601]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61375049) and the Autonomous Research Project of the State
   Key Laboratory of Industrial Control Technology, China (Grant No.
   ICT1601).
CR Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], VIS COMMUN IMAGE REP
   [Anonymous], IEEE MULTIMEDIA
   [Anonymous], P CVPR
   Bylinskii Z, 2015, VISION RES, V116, P165, DOI 10.1016/j.visres.2015.03.005
   Carreira J, 2010, PROC CVPR IEEE, P3241, DOI 10.1109/CVPR.2010.5540063
   Celikkale B, 2015, IMAGE VISION COMPUT, V42, P35, DOI 10.1016/j.imavis.2015.07.001
   Celikkale B, 2013, IEEE COMPUT SOC CONF, P976, DOI 10.1109/CVPRW.2013.142
   Charles ST, 2003, J EXP PSYCHOL GEN, V132, P310, DOI 10.1037/0096-3445.132.2.310
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Fei MJ, 2016, IET COMPUT VIS, V10, P280, DOI 10.1049/iet-cvi.2015.0237
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Khosla A, 2013, PROC CVPR IEEE, P2698, DOI 10.1109/CVPR.2013.348
   Konkle T, 2010, PSYCHOL SCI, V21, P1551, DOI 10.1177/0956797610385359
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Lee Y.J., 2015, IJCV
   Li L., 2011, Proc. 20th Int. Conf. World Wide Web, P287
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Liu TC, 2002, LECT NOTES COMPUT SC, V2353, P403
   Liu YL, 2013, RADIOENGINEERING, V22, P1072
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mancas M, 2013, IEEE IMAGE PROC, P196, DOI 10.1109/ICIP.2013.6738041
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   PAL SK, 1995, J INTELL FUZZY SYST, V3, P247
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Wang F, 2009, IEEE INT CON MULTI, P1326, DOI 10.1109/ICME.2009.5202747
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   You JY, 2007, IEEE T CIRC SYST VID, V17, P273, DOI 10.1109/TCSVT.2007.890857
   Zhang Q, 2013, J HUM KINET, V39, P5, DOI 10.2478/hukin-2013-0063
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 46
TC 33
Z9 34
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 207
EP 217
DI 10.1016/j.jvcir.2016.12.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200017
DA 2024-07-18
ER

PT J
AU Tew, YQ
   Wong, K
   Phan, RCW
   Ngan, KN
AF Tew, Yiqi
   Wong, KokSheik
   Phan, Raphael C. -W.
   Ngan, King Ngi
TI Multi-layer authentication scheme for HEVC video based on embedded
   statistics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Authentication Multi-layer; Information hiding; Compressed video; HEVC;
   Statistical properties
ID SEMI-FRAGILE WATERMARKING; IMAGE
AB A multi-layer authentication scheme for HEVC compressed video is proposed. The combination of CU sizes, which is unique to HEVC and sensitive to video manipulation, is considered along with other elements in the HEVC coding standard to generate the authentication tag. Temporal dependency was enforced, where the authentication tag generated in one slice is embedded into its subsequent slice. By design, the authentication tag is repeatedly but selectively embedded into various elements in a HEVC video, including nonzero DCT coefficients, QP parameter values, and prediction modes, depending on the bit segment in the generated tag. Our scheme offers three layers of authentication to detect and localize the tampered regions in a HEVC video, as well as verifying the source/sender of the video using a shared secret key. Video sequences from various classes (resolutions) are considered to verify the performance of the proposed multi-layer authentication scheme. Results show that, at the expense of slight degradation in perceptual quality, the proposed scheme is robust against several common attacks. A functional comparison is performed between the proposed multi-layer authentication scheme and the conventional schemes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tew, Yiqi; Wong, KokSheik] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
   [Phan, Raphael C. -W.] Univ Multimedia, Cyberjaya, Malaysia.
   [Ngan, King Ngi] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
C3 Universiti Malaya; Multimedia University; Chinese University of Hong
   Kong
RP Wong, K (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Comp Syst & Technol, Kuala Lumpur 50603, Malaysia.
EM koksheik@um.edu.my
RI Phan, Raphael C.-W./I-7266-2013; Ngan, N/E-8240-2014; Tew,
   Yiqi/AAR-1026-2020; Wong, KokSheik/B-9796-2011
OI Ngan, N/0000-0003-1946-3235; Tew, Yiqi/0000-0002-9395-2937; Wong,
   KokSheik/0000-0002-4893-2291
FU Fundamental Research Grant Scheme (FRGS) MoHE Grant [FP063-2014A];
   Telekom Malaysia (TM) [RDTC/150879]
FX This research is supported by the Fundamental Research Grant Scheme
   (FRGS) MoHE Grant under project - Background/foreground separation in
   compressed domain (Grant No. FP063-2014A). R. Phan is supported by
   Telekom Malaysia (TM) under project - 2beAware (Grant No. RDTC/150879).
CR Ababneh S, 2009, J VIS COMMUN IMAGE R, V20, P303, DOI 10.1016/j.jvcir.2009.03.010
   Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   [Anonymous], 2012, DOCUMENTATION EVALUA
   [Anonymous], 2013, 2300822013 ISOIEC
   Atrey P K., 2009, Digital video authentication
   Baek J, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC 2013), P358, DOI 10.1109/3PGCIC.2013.61
   Caciula Ion, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7425, DOI 10.1109/ICASSP.2014.6855043
   Casey E., 2011, Digital evidence and computer crime: Forensic science, computers, and the internet
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Furht B., 2006, MULTIMEDIA ENCRYPTIO
   ISO/IEC, 2003, 14496102003 ISOIEC
   Liu JK, 2010, INT J INF SECUR, V9, P287, DOI 10.1007/s10207-010-0109-y
   Lo S.-W., 2014, IEEE INT C MULT EXP, P1
   Maillard J., 2009, 2 EMMY AWARD ISO IEC
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   *NIST, 2002, FIPS PUB, V1802
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Ren YJ, 2013, IEEE T INF FOREN SEC, V8, P1678, DOI 10.1109/TIFS.2013.2279542
   Ren YJ, 2012, INT C PATT RECOG, P1088
   Roy SD, 2013, IEEE T CIRC SYST VID, V23, P300, DOI 10.1109/TCSVT.2012.2203738
   Sharma A., 2010, LSE Research Paper, P1
   Song L., 2013, P 2013 IEEE 4 INT C, P422
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tartary C, 2011, IEEE T INFORM THEORY, V57, P6285, DOI 10.1109/TIT.2011.2161960
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Upadhyay Saurabh., 2011, International Conference on Image Information Processing (ICIIP), P1
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Waddilove R, 2015, BEST FREE VIDEO EDIT
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Z, 2014, IEEE T INF FOREN SEC, V9, P543, DOI 10.1109/TIFS.2014.2301916
   Zhang J, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P46
NR 32
TC 16
Z9 17
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 502
EP 515
DI 10.1016/j.jvcir.2016.07.017
PN B
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600009
DA 2024-07-18
ER

PT J
AU Zhan, K
   Guan, JP
   Yang, Y
   Wu, Q
AF Zhan, Kun
   Guan, Junpeng
   Yang, Yi
   Wu, Qun
TI Unsupervised discriminative hashing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised discriminative hashing; Out-of-sample extrapolation;
   Manifold learning
AB Hashing is one of the popular solutions for approximate nearest neighbor search because of its low storage cost and fast retrieval speed, and many machine learning algorithms are adapted to learn effective hash function. As hash codes of the same cluster are similar to each other while the hash codes in different clusters are dissimilar, we propose an unsupervised discriminative hashing learning method (UDH) to improve discrimination among hash codes in different clusters. UDH shares a similar objective function with spectral hashing algorithm, and uses a modified graph Laplacian matrix to exploit local discriminant information. In addition, UDH is designed to enable efficient out-of-sample extension. Experiments on real world image datasets demonstrate the effectiveness of our novel approach for image retrieval. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhan, Kun; Guan, Junpeng; Yang, Yi] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Peoples R China.
   [Wu, Qun] Zhejiang Sci Tech Univ, Sch Art & Design, Hangzhou, Zhejiang, Peoples R China.
C3 Lanzhou University; Zhejiang Sci-Tech University
RP Zhan, K (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Peoples R China.
EM kzhan@lzu.edu.cn
RI Liu, Yangyang/IST-5125-2023; Zhan, Kun/D-1741-2017
OI Liu, Yangyang/0000-0001-5118-4901; Zhan, Kun/0000-0002-8000-5682
FU National Science Foundation of China [61201422, 61300230]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20120211120013]; Fundamental Research Funds for the Central
   Universities [lzujbky-2016-239, lzujbky-2016-139]
FX This work has been supported by the National Science Foundation of China
   under the Grant Nos. 61201422 and 61300230, the Specialized Research
   Fund for the Doctoral Program of Higher Education under the Grant No.
   20120211120013, and the Fundamental Research Funds for the Central
   Universities under the Grant No. lzujbky-2016-239 and lzujbky-2016-139.
CR [Anonymous], 2009, NEURIPS
   Charikar Moses S., 2002, P 34 ANN ACM S THEOR, P380, DOI DOI 10.1145/509907.509965
   Chung F. R., 1997, Spectral Graph Theory, V92, DOI DOI 10.1090/CBMS/092
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du XZ, 2016, SIGNAL PROCESS, V120, P754, DOI 10.1016/j.sigpro.2014.12.027
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Globerson A, 2006, ADV NEURAL INFORM PR, P451
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   He J., 2010, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P1129
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Liu Y, 2013, NEUROCOMPUTING, V119, P49, DOI 10.1016/j.neucom.2012.02.051
   Lv Q., 2007, P 33 INT C VER LARG, P950
   Monadjemi A., 2002, REP
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Salakhutdinov R., 2007, PMLR, P412
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shao J, 2012, PATTERN RECOGN LETT, V33, P271, DOI 10.1016/j.patrec.2011.10.018
   Song JK, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P827, DOI 10.1145/2733373.2806341
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Yang Y., 2010, P AAAI, V24
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Yang Yi., 2009, Proceedings of the 17th ACM international conference on Multimedia, P175
   Zhuang Yueting., 2011, ACM MM, P1457
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 30
TC 3
Z9 3
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 847
EP 851
DI 10.1016/j.jvcir.2016.08.016
PN B
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600038
OA Bronze
DA 2024-07-18
ER

PT J
AU Chung, KL
   Huang, YH
AF Chung, Kuo-Liang
   Huang, Yong-Huai
TI Efficient multiple-example based super-resolution for symmetric mixed
   resolution stereoscopic video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Asymmetric resolution stereoscopic video coding (ARSVC); Bitrate
   reduction; Multiple-example; Stereoscopic quality; Super-resolution;
   Symmetric mixed resolution stereoscopic video coding (SMRSVC); 3D TV
ID MOTION COMPENSATION; INTERPOLATION
AB In this paper, we first propose a new symmetric mixed resolution stereoscopic video coding (SMRSVC) model which can provide clear bitrate-reduction and visual merits. Based on the newly proposed SMRSVC model, we then propose a quality-efficient multiple-example based super-resolution method. In the proposed super-resolution method, the four block examples selected from the forward and backward key-frames, the reference super-resolved frame, and the interview super-resolved frame are referred so as to effectively fuse the high frequency component of the super-resolved current block of the downsampled non-key-frame, and then an enhanced super-resolved non-key-frame is followed. Based on six test stereoscopic video sequences, the experimental results demonstrate that besides the bitrate-saving effect, the proposed super-resolution method for the proposed SMRSVC model also has better quality performance in terms of six well-known quality metrics when compared with several state-of-the-art methods for the previous asymmetric resolution stereoscopic video coding model and the SMRSVC model. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chung, Kuo-Liang] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
   [Huang, Yong-Huai] Jinwen Univ Sci & Technol, Dept Elect Engn, 99 AnChung Rd, New Taipei 23154, Taiwan.
C3 National Taiwan University of Science & Technology
RP Huang, YH (corresponding author), Jinwen Univ Sci & Technol, Dept Elect Engn, 99 AnChung Rd, New Taipei 23154, Taiwan.
EM klchung01@gmail.com; yonghuai@ms28.hinet.net
FU Ministry of Science and Technology of ROC [MOST 102-2221-E-011-055-MY3,
   MOST 104-2221-E228-006]
FX Supported by the Ministry of Science and Technology of ROC under the
   Contract MOST 102-2221-E-011-055-MY3.; Supported by the Ministry of
   Science and Technology of ROC under the Contract MOST 104-2221-E228-006.
CR Aflaki P, 2011, INT SYMP IMAGE SIG, P396
   Aflaki P, 2010, IEEE IMAGE PROC, P4021, DOI 10.1109/ICIP.2010.5650661
   Aksay A., 2009, P TRUE VIS CAP TRANS, P1
   [Anonymous], VCEG CONTRIBUTION
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2003, JVTO013 ISOIEC JTC1S
   Chen Y, 2009, IEEE INT SYMP CIRC S, P2585, DOI 10.1109/ISCAS.2009.5118330
   Chen Y, 2008, IEEE IMAGE PROC, P1944, DOI 10.1109/ICIP.2008.4712162
   Chung KL, 2014, IEEE T CIRC SYST VID, V24, P430, DOI 10.1109/TCSVT.2013.2276877
   De Silva V, 2013, IEEE T IMAGE PROCESS, V22, P3392, DOI 10.1109/TIP.2013.2268422
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Fehn Christoph, 2007, 3DTV Conference, 2007, P1
   Feng Shao, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P186, DOI 10.1109/CISP.2011.6099913
   Fezza SA, 2014, IEEE IMAGE PROC, P5656, DOI 10.1109/ICIP.2014.7026144
   Hsu CC, 2015, IEEE T IMAGE PROCESS, V24, P919, DOI 10.1109/TIP.2014.2387416
   Hung EM, 2012, IEEE T CIRC SYST VID, V22, P1321, DOI 10.1109/TCSVT.2012.2201669
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Kang LW, 2013, IEEE INT WORKSH MULT, P224, DOI 10.1109/MMSP.2013.6659292
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Park SN, 2009, OPT ENG, V48, DOI 10.1117/1.3156016
   PERKINS MG, 1992, IEEE T COMMUN, V40, P684, DOI 10.1109/26.141424
   Saygili G, 2011, IEEE T BROADCAST, V57, P593, DOI 10.1109/TBC.2011.2131450
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Shao F, 2010, IEEE T CONSUM ELECTR, V56, P2460, DOI 10.1109/TCE.2010.5681128
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Song BC, 2011, IEEE T CIRC SYST VID, V21, P274, DOI 10.1109/TCSVT.2010.2087454
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Tam W. J., 2007, JVTW094
   Yu MC, 2012, INT J SYST SCI, V43, P163, DOI 10.1080/00207721.2010.481367
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang YB, 2011, IEEE T IMAGE PROCESS, V20, P3291, DOI 10.1109/TIP.2011.2158226
NR 32
TC 4
Z9 4
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 65
EP 81
DI 10.1016/j.jvcir.2016.05.007
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900007
DA 2024-07-18
ER

PT J
AU Dong, M
   Zeng, HQ
   Chen, J
   Cai, CH
   Ma, KK
AF Dong, Meng
   Zeng, Huanqiang
   Chen, Jing
   Cai, Canhui
   Ma, Kai-Kuang
TI Multiple description video coding based on adaptive data reuse
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple description video coding; Adaptive data reuse; Error resilient;
   Inter prediction; Intra prediction
ID MACRO BLOCK LEVEL; H.264/AVC; ALLOCATION
AB In this paper, an efficient multiple description coding (MDC) method, called the adaptive data reuse MDC (ADR-MDC), is proposed for robust video transmission. The proposed ADR-MDC first groups four sub-sequences, which are generated by performing spatial down-sample operation on each frame of input video sequence, into two descriptions. In each description, one sub-sequence is directly encoded and decoded by applying the H.264/AVC encoder and decoder, while the other is encoded and decoded at each macro block (MB) based on the adaptive data reuse criterion, which are developed by making full use of the spatial and temporal correlations among the sub-sequences. Experimental results have shown that the proposed ADR-MDC scheme possesses higher error resilient ability and obtains better reconstructed video than the existing state-of-the-art MDC method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Dong, Meng; Zeng, Huanqiang; Chen, Jing; Cai, Canhui] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
   [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Huaqiao University; Nanyang Technological University
RP Zeng, HQ (corresponding author), Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
EM mengyingyidai@163.com; zeng0043@hqu.edu.cn; jingzi@hqu.edu.cn;
   chcai@hqu.edu.cn; ekkma@ntu.edu.sg
RI Ma, Kai-Kuang/KBA-9411-2024; Zeng, Huanqiang/U-2017-2018
FU National Natural Science Foundation of China [61372107, 61401167];
   Natural Science Foundation of Fujian Province [2016J01308]; Opening
   Project of Sate Key Laboratory of Digital Publishing Technology
   [FZDP2015-B-001]; Zhejiang Open Foundation of the Most Important
   Subjects; High-Level Talent Project Foundation of Huaqiao University
   [14BS201, 14BS204]
FX This work was support in part by the National Natural Science Foundation
   of China under the Grants 61372107 and 61401167, in part by the Natural
   Science Foundation of Fujian Province under the Grant 2016J01308, in
   part by the Opening Project of Sate Key Laboratory of Digital Publishing
   Technology under the Grant FZDP2015-B-001, in part by the Zhejiang Open
   Foundation of the Most Important Subjects, in part by the High-Level
   Talent Project Foundation of Huaqiao University under the Grants 14BS201
   and 14BS204.
CR Bai HH, 2012, IEEE DATA COMPR CONF, P389, DOI 10.1109/DCC.2012.45
   Bernardini R, 2004, IEEE IMAGE PROC, P3213
   Chen JY, 2010, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2010.5653336
   Dong M, 2013, IEEE IMAGE PROC, P1928, DOI 10.1109/ICIP.2013.6738397
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   Greco C., 2010, IEEE INT WORKSH MULT, P239
   Hsiao CW, 2010, IEEE T CIRC SYST VID, V20, P76, DOI 10.1109/TCSVT.2009.2026973
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Lin CY, 2011, IEEE T CIRC SYST VID, V21, P589, DOI 10.1109/TCSVT.2011.2129270
   Tillo T, 2008, IEEE T CIRC SYST VID, V18, P59, DOI 10.1109/TCSVT.2007.913751
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wei Z., 2006, INT S INT SIGN PROC, P151
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Wei Z, 2012, IEEE T CIRC SYST VID, V22, P465, DOI 10.1109/TCSVT.2011.2168131
   Wen X, 2009, IEEE INT SYMP CIRC S, P1237, DOI 10.1109/ISCAS.2009.5117986
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yang J., 2007, PICT COD S PCS, P12
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
   Zeng HQ, 2009, IEEE T CIRC SYST VID, V19, P491, DOI 10.1109/TCSVT.2009.2014014
NR 19
TC 3
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 378
EP 385
DI 10.1016/j.jvcir.2016.03.016
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100032
DA 2024-07-18
ER

PT J
AU Du, SY
   Liu, J
   Bi, B
   Zhu, JH
   Xue, JR
AF Du, Shaoyi
   Liu, Juan
   Bi, Bo
   Zhu, Jihua
   Xue, Jianru
TI New iterative closest point algorithm for isotropic scaling registration
   of point sets with noise
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Iterative closest point; Bounded scale; Point set registration; Noise;
   Gaussian model
ID RECOGNITION; RETRIEVAL
AB This paper proposes a new probability iterative closest point (ICP) approach with bounded scale based on expectation maximization (EM) estimation for isotropic scaling registration of point sets with noise. The bounded-scale ICP algorithm can handle the case with different scales, but it could not effectively yield the alignment of point sets with noise. Aiming at improving registration precision, a Gaussian probability model is integrated into the bounded-scale registration problem, which is solved by the proposed method. This new method can be solved by the E-step and M-step. In the E-step, the one-to-one correspondence is built up between two point sets. In the M-step, the scale transformation including the rotation matrix, translation vector and scale factor is computed by singular value decomposition (SVD) method and the properties of parabola. Then, the Gaussian model is updated via the distance and variance between transformed point sets. Experimental results demonstrate the proposed method improves the performance significantly with high precision and fast speed. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Du, Shaoyi; Liu, Juan; Bi, Bo; Zhu, Jihua; Xue, Jianru] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Du, SY (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
EM dushaoyi@gmail.com
OI Du, Shaoyi/0000-0002-7092-0596
FU National Natural Science Foundation of China [61573274, 91320301]; 973
   Program [2015CB351703]; Program of Introducing Talents of Discipline to
   University [B13043]
FX This work was supported by the National Natural Science Foundation of
   China under Grant Nos. 61573274 and 91320301, 973 Program under Grant
   No. 2015CB351703, and the Program of Introducing Talents of Discipline
   to University under Grant No. B13043.
CR [Anonymous], IEEE SIGNAL PROCESS
   Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chetverikov D, 2002, INT C PATT RECOG, P545, DOI 10.1109/ICPR.2002.1047997
   Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986
   Du SY, 2011, ELECTRON LETT, V47, P799, DOI 10.1049/el.2011.1071
   Du SY, 2015, MED IMAGE ANAL, V26, P256, DOI 10.1016/j.media.2015.10.001
   Du SY, 2015, NEUROCOMPUTING, V157, P187, DOI 10.1016/j.neucom.2015.01.019
   Du SY, 2010, J VIS COMMUN IMAGE R, V21, P442, DOI 10.1016/j.jvcir.2010.02.005
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Guan T, 2014, IEEE MULTIMEDIA, V21, P32, DOI 10.1109/MMUL.2013.31
   Guan T, 2013, IEEE T MULTIMEDIA, V15, P1688, DOI 10.1109/TMM.2013.2265674
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lei Zhang, 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P80, DOI 10.1109/3DIMPVT.2011.18
   Levoy M, 2005, The Stanford 3D scanning repository
   Li C, 2011, IEEE IMAGE PROC, P1485, DOI 10.1109/ICIP.2011.6115724
   Liu YH, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P2519, DOI 10.1109/ROBOT.2002.1013610
   Luo YW, 2015, NEUROCOMPUTING, V156, P105, DOI 10.1016/j.neucom.2014.12.079
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nüchter A, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P419
   Phillips JM, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P427
   Ridene T, 2009, IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P375, DOI 10.1109/CIRA.2009.5423176
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   Wei BC, 2014, IEEE MULTIMEDIA, V21, P41, DOI 10.1109/MMUL.2013.65
   Wei LJ, 2011, IEEE INT C INTELL TR, P1923, DOI 10.1109/ITSC.2011.6082990
   Yan P, 2007, COMPUT VIS IMAGE UND, V107, P195, DOI 10.1016/j.cviu.2006.11.001
   Ying SH, 2009, IEEE T AUTOM SCI ENG, V6, P559, DOI 10.1109/TASE.2009.2021337
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zinsser T., 2005, INT C PATT REC IM PR, P116
NR 35
TC 26
Z9 29
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 207
EP 216
DI 10.1016/j.jvcir.2016.02.019
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100018
DA 2024-07-18
ER

PT J
AU Wu, WC
   Lin, ZW
AF Wu, Wen-Chuan
   Lin, Zi-Wei
TI SVD-based self-embedding image authentication scheme using quick
   response code features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image authentication; Fragile watermarking; Tamper detection;
   Self-embedding; Quick response code; Singular value decomposition;
   Differential prediction; Data recovery
ID TAMPER DETECTION; FRAGILE WATERMARKING
AB Image authentication is a type of technique for the content protection of digital images. This technique is able to detect and locate tampered regions on a digital image. In this paper, two self-embedding image authentication approaches are proposed to involve distinctive singular values. Both of them extract self-characteristics of an image as the crucial authentication information for that image. Subsequently, this information is converted into the two dimensional code format and that codes are then embedded into digital image pixels. With the capability of error correction in two dimensional codes, the extracted authentication data, even being detected with a tamper, still can be completely restored and errorless. As well, it can be utilized to detect whether an image has been tampered with or not. According to experimental results, the proposed approaches are superior to other schemes for images that have been modified to a certain attack extent because the authentication data could be completely extracted in more effective way, and the tampered regions could be identified more accurately. In addition, the proposed approaches utilize these complete self-characteristics to restore tampered regions into their original states. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wu, Wen-Chuan; Lin, Zi-Wei] Aletheia Univ, Dept Comp Sci & Informat Engn, 32 Zhenli St, Taipei 25103, Taiwan.
C3 Aletheia University
RP Wu, WC (corresponding author), Aletheia Univ, Dept Comp Sci & Informat Engn, 32 Zhenli St, Taipei 25103, Taiwan.
EM au4387@au.edu.tw; freelifetw29@gmail.com
RI Wu, Wenchuan/H-6751-2019
OI Wu, Wenchuan/0000-0002-5020-5165
CR Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Biham E, 1997, J CRYPTOL, V10, P195, DOI 10.1007/s001459900027
   Chan CS, 2011, PATTERN RECOGN LETT, V32, P1679, DOI 10.1016/j.patrec.2011.07.023
   Chen JH, 2014, APPL MATH INFORM SCI, V8, P585, DOI 10.12785/amis/080216
   Chen Ji-Hong, 2012, INT J COMPUTER CONSU, V1, P61
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Chiou Y. S., 2012, COMPUTER SCI ITS APP, P655
   Chuang JC, 2013, INT J SECUR APPL, V7, P209, DOI 10.14257/ijsia.2013.7.6.22
   Cruz-Ramos C, 2009, LECT NOTES COMPUT SC, V5856, P1005, DOI 10.1007/978-3-642-10268-4_117
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Gunalan G. F., 2013, INT J ELECT COMMUN C, V4, P15
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Tareef A, 2015, EXPERT SYST APPL, V42, P2224, DOI 10.1016/j.eswa.2014.09.055
   WALTON S, 1995, DR DOBBS J, V20, P18
   Wen-Chuan Wu, 2011, 2011 Fifth International Conference on Genetic and Evolutionary Computing, P188, DOI 10.1109/ICGEC.2011.52
   Wen-Chuan Wu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P628, DOI 10.1109/IIH-MSP.2009.279
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu CM., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P13, DOI [10.14257/ijsip.2014.7.5.02, DOI 10.14257/IJSIP.2014.7.5.02]
   Wu W. C., 2015, P 3 INT SCI C ENG AP, P238
NR 20
TC 20
Z9 21
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 18
EP 28
DI 10.1016/j.jvcir.2016.02.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100003
DA 2024-07-18
ER

PT J
AU Chen, Y
   Hua, CJ
   Bai, RL
AF Chen, Ying
   Hua, Chunjian
   Bai, Ruilin
TI Sequentially adaptive active appearance model with regression -based
   online reference appearance template
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active appearance model; Model fitting; Incremental learning; Kernel
   regression; Facial features tracking; Individual generalization; Fitting
   context sensitivity; Tracking drifts
AB Statistically motivated approaches, such as the active appearance model (AAM), have been widely used for non-rigid objects registration and tracking. As an extension of AAM, sequential MM (SAAM) was proposed, in which both an incremental updated component and a reference component were employed simultaneously in the fitting scheme. To make SAAM more adaptive to facial context variations during tracking, a regression-based online reference appearance model (ORAM) is presented to update the subject-specific appearance of the SAAM. The spatial map between scattered local feature correspondences and structured landmark correspondences is learned via Kernel Ridge Regression (KRR). Additionally, a shape deformation and appearance model evaluation strategies help to improve the accuracy and efficiency of the algorithm. The approach is experimentally validated by tracking face videos with improved fitting accuracy. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Ying; Bai, Ruilin] Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
   [Hua, Chunjian] Jiangnan Univ, Sch Mech Engn, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Chen, Y (corresponding author), Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Jiangsu, Peoples R China.
EM chenying@jiangnan.edu.cn
RI Ying, Chen/GRX-5695-2022; Chen, Ying/AAA-2911-2022
OI Chen, Ying/0000-0002-1674-0869
FU National Natural Science Foundation of China [61104213, 61573168];
   Natural Science Foundation of Jiangsu Province [BK2011146]
FX This work was supported by the National Natural Science Foundation of
   China (61104213, 61573168), Natural Science Foundation of Jiangsu
   Province (BK2011146).
CR Arandjelovic O., 2007, Proceedings of ICCP, P1, DOI DOI 10.1109/SIU.2007.4298708
   Asthana A., 2013, CVPR 2013
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Chen Y, 2013, IEEE SIGNAL PROC LET, V20, P567, DOI 10.1109/LSP.2013.2257753
   Cootes T.F., 2006, BRIT MACHINE VISION, P919
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Crowley J. L., 2004, P WORKSH VIS OBS DEI
   [邓朝省 Deng Chaosheng], 2014, [计算机工程与应用, Computer Engineering and Application], V50, P189
   Ghose S., 2011, SPIE C MED IM LAK BU, V7962, P181
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hastie T., 2009, The Elements of Statistical Learning
   Ionita Mircea C., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P453, DOI 10.1109/ICCVW.2011.6130276
   Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051
   Liu XM, 2010, IMAGE VISION COMPUT, V28, P1162, DOI 10.1016/j.imavis.2009.09.016
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Nguyen M., 2008, IEEE C COMP VIS PATT
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saragih J, 2009, PATTERN RECOGN, V42, P2628, DOI 10.1016/j.patcog.2009.04.014
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Schreiber D, 2007, PATTERN RECOGN LETT, V28, P1483, DOI 10.1016/j.patrec.2007.03.007
   Shin J, 2011, PATTERN RECOGN, V44, P559, DOI 10.1016/j.patcog.2010.09.011
   Sung J, 2009, PATTERN RECOGN LETT, V30, P359, DOI 10.1016/j.patrec.2008.11.006
NR 27
TC 5
Z9 5
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 198
EP 208
DI 10.1016/j.jvcir.2015.12.012
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600018
DA 2024-07-18
ER

PT J
AU Wang, Y
   Zhao, YS
   Cai, Q
   Li, HS
   Yan, HX
AF Wang, Yu
   Zhao, Yongsheng
   Cai, Qiang
   Li, Haisheng
   Yan, Huaixin
TI A varied local edge pattern descriptor and its application to texture
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Varied local edge pattern; Texture classification; Local binary pattern;
   Zernike moments; Fusion; Multi-scale; Multi-direction; Multi-resolution
ID IMAGE; EXTRACTION; RETRIEVAL; FEATURES; DETECTOR
AB Similar images can be classified by the aid of texture cues among which edge is widely considered as one of the most valuable features. In this paper, we firstly proposed a flexible edge descriptor, called varied local edge pattern (VLEP). Then we apply VLEP to similar texture classification. The proposed VLEP descriptor has multi-scale, multi-direction (or multi-resolution) properties. Because VLEP uses histogram spectrum to describe image information, it is very easy to fuse local binary pattern (LBP) and Zernike moments histogram spectrum features due to their excellent properties and supplementary roles. The fused histogram spectrum features representing the images are classified via the nearest neighbor classifier. Experimental results show that the VLEP-based method can be remarkably superior to other state-of-the-art texture classification methods on the large and comprehensive CUReT and Outex texture database. (c) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Yu; Cai, Qiang; Li, Haisheng; Yan, Huaixin] Beijing Technol & Business Univ, Sch Comp & Informat Engn, Beijing 100048, Peoples R China.
   [Zhao, Yongsheng] Yanshan Univ, Sch Mech Engn, Qinhuangdao 066004, Hebei Province, Peoples R China.
C3 Beijing Technology & Business University; Yanshan University
RP Wang, Y (corresponding author), Beijing Technol & Business Univ, Sch Comp & Informat Engn, Beijing 100048, Peoples R China.
EM wangyu@btbu.edu.cn
RI LI, Haisheng/AAM-5232-2020
OI LI, Haisheng/0000-0003-4861-0513
FU national Natural Science Foundation of China [61171068]; Beijing Talents
   Fund [2014000026833ZK14]; Importation and Development of High-Caliber
   Talents Project of Beijing Municipal Institutions [CITTCD201504010]
FX The authors sincerely thank Professor Zhenhua Guo for sharing the source
   codes of adaptive LBP method. This work is supported by the national
   Natural Science Foundation of China (No. 61171068), Beijing Talents Fund
   (No. 2014000026833ZK14), and the Importation and Development of
   High-Caliber Talents Project of Beijing Municipal Institutions (No.
   CIT&TCD201504010).
CR Ahonen Timo, 2009, IMAGE ANAL
   Ali M, 2001, INT GEOSCI REMOTE SE, P2298, DOI 10.1109/IGARSS.2001.977981
   [Anonymous], PATTERN CLASSIFICATI
   Bergholm T., 1986, Eighth International Conference on Pattern Recognition. Proceedings (Cat. No.86CH2342-4), P597
   BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   El Maliani AD, 2014, J VIS COMMUN IMAGE R, V25, P1717, DOI 10.1016/j.jvcir.2014.06.004
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Guo ZH, 2010, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2010.5652209
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7
   Kaya Metin, 2005, INT J SIGNAL PROCESS, P80
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kiranjeet K., 2013, INT J APPL INNOVATIO, V2, P496
   LEVINE DM, 1985, VISION MAN MACHINE
   Maani R, 2013, IEEE T IMAGE PROCESS, V22, P2409, DOI 10.1109/TIP.2013.2249081
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Tao D.P., 2015, IEEE T CYBERNET
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang Y., 2012, J ELECTRON IMAGING, V21
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zand M, 2015, J VIS COMMUN IMAGE R, V26, P305, DOI 10.1016/j.jvcir.2014.10.005
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 30
TC 6
Z9 11
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 108
EP 117
DI 10.1016/j.jvcir.2015.11.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400010
DA 2024-07-18
ER

PT J
AU Zhao, HQ
   Xiang, K
   Cao, SX
   Wang, XY
AF Zhao, Houqiang
   Xiang, Ke
   Cao, Songxiao
   Wang, Xuanyin
TI Robust visual tracking via CAMShift and structural local sparse
   appearance model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Sparse representation; Background suppression; Target
   model update; CAMShift; Similar color distributed background;
   Illumination changes; Motion blur
AB This paper addresses issues in visual tracking where videos contain object intersections, pose changes, occlusions, illumination changes, motion blur, and similar color distributed background. We apply the structural local sparse representation method to analyze the background region around the target. After that, we reduce the probability of prominent features in the background and add new information to the target model. In addition, a weighted search method is proposed to search the best candidate target region. To a certain extent, the weighted search method solves the local optimization problem. The proposed scheme, designed to track single human through complex scenarios from videos, has been tested on some video sequences. Several existing tracking methods are applied to the same videos and the corresponding results are compared. Experimental results show that the proposed tracking scheme demonstrates a very promising performance in terms of robustness to occlusions, appearance changes, and similar color distributed background. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhao, Houqiang; Xiang, Ke; Cao, Songxiao; Wang, Xuanyin] Zhejiang Univ, State Key Lab Fluid Power Transmiss & Control, Hangzhou 310003, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Zhao, HQ (corresponding author), Zhejiang Univ, State Key Lab Fluid Power Transmiss & Control, Hangzhou 310003, Zhejiang, Peoples R China.
EM zhaohouqiang0220@163.com
RI Cao, Songxiao/HKE-6408-2023; wang, xuan/JBJ-6948-2023; wang,
   xuan/GXF-3679-2022
FU National Natural Science Foundation of China [51175459]; Science Fund
   for Creative Research Groups of National Natural Science Foundation of
   China [51221004]
FX This research is supported by Project 51175459 supported by National
   Natural Science Foundation of China and 51221004 Science Fund for
   Creative Research Groups of National Natural Science Foundation of
   China.
CR An X, 2014, IET COMPUT VIS, V8, P235, DOI 10.1049/iet-cvi.2013.0004
   [Anonymous], 2015, ARXIV150206796
   [Anonymous], ARXIV150104587
   Collins R., 2005, PROC IEEE INT WORKSH, V2, P35
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fang JX, 2011, AEU-INT J ELECTRON C, V65, P915, DOI 10.1016/j.aeue.2011.02.013
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khan ZH, 2011, IEEE T CIRC SYST VID, V21, P74, DOI 10.1109/TCSVT.2011.2106253
   Kim DH, 2012, ETRI J, V34, P399, DOI [10.4218/etrij.11.0111.0383, 10.4218/etrij.12.0111.0383]
   Levey A., 2000, IMAGE, V9, P456
   Liu HP, 2012, INFORM SCIENCES, V195, P141, DOI 10.1016/j.ins.2012.01.033
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mohammadi S. A., 2011, 2011 IEEE 3rd International Conference on Communication Software and Networks (ICCSN 2011), P494, DOI 10.1109/ICCSN.2011.6014773
   Ning J, 2012, IET COMPUT VIS, V6, P62, DOI 10.1049/iet-cvi.2009.0075
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Rao G. Mallikarjuna, 2013, International Journal of Image, Graphics and Signal Processing, V5, P57, DOI 10.5815/ijigsp.2013.06.08
   Raziperchikolaei R, 2012, IEEE INT SYMP SIGNAL, P230, DOI 10.1109/ISSPIT.2012.6621292
   Tao D., 2015, MANIFOLD
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang YR, 2012, PATTERN RECOGN, V45, P4510, DOI 10.1016/j.patcog.2012.05.010
   Yu J, 2014, PATTERN RECOGN, V47, P3512, DOI 10.1016/j.patcog.2014.05.002
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
NR 29
TC 14
Z9 15
U1 1
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 176
EP 186
DI 10.1016/j.jvcir.2015.11.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400016
DA 2024-07-18
ER

PT J
AU Ciecholewski, M
AF Ciecholewski, Marcin
TI Automated coronal hole segmentation from Solar EUV Images using the
   watershed transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Solar image; Coronal hole; Image segmentation; Average contrast
   maximization; Region merging; Watershed by immersion; Oversegmentation
   reduction; Mathematical morphology
ID EXTRACTION; FILAMENTS; OBJECTS
AB Region of interest segmentation in solar images is the subject of frequent research in solar physics. This study outlines watershed by immersion segmentation to identify coronal hole areas in solar images acquired using the Extreme UV Imaging Telescope (EIT). Solutions presented here produce highly accurate segmentation results of coronal holes of irregular shape, and what is more, they do so for images representing varied solar activity, recorded in different years and months. In addition, the solutions presented here make all the methods used operate very quickly. These methods include: the preprocessing step before the watershed segmentation, the watershed segmentation itself, and also the postprocessing of solar images after the watershed segmentation. The mean duration of the entire segmentation process of solar images amounts to 342 ms for a single coronal hole, without the parallel implementation of the methods used. The experiments were carried out on a computer with an Intel Core i7 CPU @ 2 GHz and 4 GB RAM. After the seed point is identified inside the coronal hole, the segmentation runs automatically. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ciecholewski, Marcin] Jagiellonian Univ, Fac Math & Comp Sci, Chair Optimizat & Control, PL-30348 Krakow, Poland.
C3 Jagiellonian University
RP Ciecholewski, M (corresponding author), Jagiellonian Univ, Fac Math & Comp Sci, Chair Optimizat & Control, Ul Prof Stanislawa Lojasiewicza 6, PL-30348 Krakow, Poland.
EM marcin.ciecholewski@uj.edu.pl
RI Ciecholewski, Marcin/H-5789-2019
OI Ciecholewski, Marcin/0000-0001-5636-6819
CR Aboudarham J, 2008, ANN GEOPHYS-GERMANY, V26, P243, DOI 10.5194/angeo-26-243-2008
   ALVAREZ L, 2010, PROC CVPR IEEE, P2197, DOI DOI 10.1109/CVPR.2010.5539900
   Anbeek P, 2004, NEUROIMAGE, V21, P1037, DOI 10.1016/j.neuroimage.2003.10.012
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2003, Geometric Level Set Methods in Imaging, Vision, and Graphics
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Barra V, 2009, ASTRON ASTROPHYS, V505, P361, DOI 10.1051/0004-6361/200811416
   Barra V, 2008, ADV SPACE RES, V42, P917, DOI 10.1016/j.asr.2007.10.021
   Bradski G, 2000, DR DOBBS J, V25, P120
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chiang CC, 2009, J VIS COMMUN IMAGE R, V20, P167, DOI 10.1016/j.jvcir.2009.01.001
   Ciecholewski M, 2013, COMPUT BIOL MED, V43, P2238, DOI 10.1016/j.compbiomed.2013.10.009
   Colak T, 2008, SOL PHYS, V248, P277, DOI 10.1007/s11207-007-9094-3
   Cormen T.H., 2009, INTRO ALGORITHMS
   Couprie M, 2005, J MATH IMAGING VIS, V22, P231, DOI 10.1007/s10851-005-4892-4
   Cousty J, 2010, IMAGE VISION COMPUT, V28, P1229, DOI 10.1016/j.imavis.2010.01.001
   Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173
   Cousty J, 2010, IEEE T PATTERN ANAL, V32, P925, DOI 10.1109/TPAMI.2009.71
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Forcadel N, 2008, NUMER ALGORITHMS, V48, P189, DOI 10.1007/s11075-008-9183-x
   Freedman D, 2005, IEEE T MED IMAGING, V24, P281, DOI 10.1109/TMI.2004.841228
   Fuller N, 2005, SOL PHYS, V227, P61, DOI 10.1007/s11207-005-8364-1
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P469, DOI 10.1109/TPAMI.2006.57
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Joshi AD, 2010, SOL PHYS, V262, P425, DOI 10.1007/s11207-010-9528-1
   Krista LD, 2009, SOL PHYS, V256, P87, DOI 10.1007/s11207-009-9357-2
   Mobahi H, 2011, INT J COMPUT VISION, V95, P86, DOI 10.1007/s11263-011-0444-0
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nieniewski M, 2004, IEEE T SYST MAN CY B, V34, P796, DOI 10.1109/TSMCB.2003.816991
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Rao SR, 2010, LECT NOTES COMPUT SC, V5994, P135
   Robbrecht E, 2006, ADV SPACE RES, V38, P475, DOI 10.1016/j.asr.2005.02.005
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Shapiro L. G., 2001, COMPUTER VISION
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soille P., 2004, MORPHOLOGICAL IMAGE, DOI [10.1007/978-3-662-05088-0, DOI 10.1007/978-3-662-05088-0]
   Tarabalka Y, 2010, PATTERN RECOGN, V43, P2367, DOI 10.1016/j.patcog.2010.01.016
   Veronig A., 2000, Hvar Observatory Bulletin, V24, P195
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Yang HG, 2014, PATTERN RECOGN, V47, P2266, DOI 10.1016/j.patcog.2013.11.004
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
   Young CA, 2008, SOL PHYS, V248, P457, DOI 10.1007/s11207-008-9177-9
   Zhang Y.J., 2006, Advances in image and video segmentation
   Zharkov S, 2004, LECT NOTES ARTIF INT, V3215, P446
NR 47
TC 23
Z9 24
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 203
EP 218
DI 10.1016/j.jvcir.2015.09.015
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700019
DA 2024-07-18
ER

PT J
AU Lie, WN
   Lin, GH
AF Lie, Wen-Nung
   Lin, Guan-Hua
TI Error concealment for the transmission of H.264/AVC-compressed 3D video
   in color plus depth format
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error concealment; Frame loss; 3DTV; 3D video transmission; Color plus
   depth; H.264/AVC; Motion vector extrapolation; Boundary matching
   algorithm
ID FRAME CONCEALMENT; ALGORITHM
AB An error concealment method for the transmission of 3D video in color/depth dual stream format (i.e., separately encoded) is proposed. We consider frame losses of color or depth along error-prone channels. Based on motion vector extrapolation from previous decoded frames, lost frames can be reconstructed. Specifically, the received information of one kind (color or depth) is intensively used when recovering a lost frame of the other kind. Our contributions come from classification of blocks into different kinds for different processing, joint color/depth matching, and shape-adaptive motion compensation. According to experiments, our proposed method, against traditional MV extrapolation (for color) and MV sharing (for depth) schemes, has shown distinctive gains in both color and depth. Our algorithm is effective in retaining integrity and smoothness of object boundaries, which is important to view synthesis for 3D display. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lie, Wen-Nung; Lin, Guan-Hua] Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
   [Lie, Wen-Nung] Natl Chung Cheng Univ, Adv Inst Mfg High Tech Innovat AIM HI, Chiayi 621, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University
RP Lie, WN (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
EM ieewnl@ccu.edu.tw
RI Lin, Guanhua/B-5261-2012; Lie, Wen-Nung/AFP-1266-2022
FU National Science Council, Republic of China [NSC 102-2221-E-194-042-MY2]
FX This work was supported by the National Science Council, Republic of
   China, under contract NSC 102-2221-E-194-042-MY2.
CR [Anonymous], P IEEE INT C VEH TEC
   Chen Y., 2004, P IEEE INT C PICT CO
   Chiang JC, 2011, IEEE J-STSP, V5, P309, DOI 10.1109/JSTSP.2010.2066956
   Daribo I, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/258920
   Hewage C. T. E. R., 2008, P IEEE INT C MULT EX
   Hong Chien-Shiang, 2011, P IEEE INT C GEN EV
   Lam W. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P417, DOI 10.1109/ICASSP.1993.319836
   Lie WN, 2011, ELECTRON LETT, V47, P319, DOI 10.1049/el.2010.2912
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P982, DOI 10.1109/TCSVT.2006.879119
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Liu XM, 2011, PROCEEDINGS OF CHINA DISPLAY/ASIA DISPLAY 2011, P208, DOI 10.1109/ISCE.2011.5973815
   Liu YQ, 2010, IEEE T CIRC SYST VID, V20, P600, DOI 10.1109/TCSVT.2009.2035838
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P10, DOI 10.1109/ICCCAS.2002.1180560
   Rusanovskyy Dmytro, 2012, ISOIECJTC1SC29WG11
   Doan VH, 2013, IEEE INT SYMP CIRC S, P2900, DOI 10.1109/ISCAS.2013.6572485
   Xiang XG, 2010, J VIS COMMUN IMAGE R, V21, P975, DOI 10.1016/j.jvcir.2010.07.002
   Yan B, 2012, IEEE T MULTIMEDIA, V14, P936, DOI 10.1109/TMM.2012.2184743
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yang M, 2014, IEEE T BROADCAST, V60, P385, DOI 10.1109/TBC.2014.2321676
   Yang M, 2012, IEEE IMAGE PROC, P1281, DOI 10.1109/ICIP.2012.6467101
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 23
TC 6
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 237
EP 245
DI 10.1016/j.jvcir.2015.08.012
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300020
DA 2024-07-18
ER

PT J
AU Miao, RH
   Tang, JL
   Chen, XQ
AF Miao, Rong-Hui
   Tang, Jing-Lei
   Chen, Xiao-Qian
TI Classification of farmland images based on color features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color features; Farmland images; Non equal interval quantification; PCA;
   RBF; Color spaces; Color feature curves; Classification
AB Farmland images recognition and classification are of great significance in farmland environmental perception. Since the open and unstructured farmland environment has complex scenes, and is easily affected by various factors, furthermore, environmental information is uncertain and hard to predict. Based on hue saturation value (HSV), hue saturation lightness (HSL) and hue saturation intensity (HSI) color space models, taking use of image analysis and classification technology, this paper realizes the classification of farmland images in different environments. On the basis of color space, eight color features of the images are extracted. First, we conducted non equal interval quantification and drew the color feature curves, after that, we selected five eigenvectors which can correctly classify the images. Then, principal component analysis (PCA) was used for dimension reduction. Finally, radial basis function (RBF) neural network was joined for the extraction of images in the same scenes and different ones. The performance of the use of multiple color spaces combining with PCA and RBF shows that the average recognition rates of sunny days and cloudy days in the same scenes and different scenes are 100%, 87.36% and 84.58%, 68.11% respectively. Therefore, this method has higher recognition rate than BP neural network. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Miao, Rong-Hui; Tang, Jing-Lei; Chen, Xiao-Qian] Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Peoples R China.
C3 Northwest A&F University - China
RP Tang, JL (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling 712100, Peoples R China.
EM tangjinglei@nwsuaf.edu.cn
RI 苗, 荣慧/HHS-7990-2022
FU National High Technology Research and Development Program of China (863
   Program) [2013AA10230402]; National Natural Science Foundation of China
   [31101075]; Northwest AAMP;F University Special Innovation Foundation
   [QN2011069]; Northwest AAMP;F University Ph.D. Scientific Research
   Foundation [2011BSJJ095]
FX This work is supported by the National High Technology Research and
   Development Program of China (863 Program) under Grant No.
   2013AA10230402, National Natural Science Foundation of China under Grant
   No. 31101075, Northwest A&F University Special Innovation Foundation
   under Grant No. QN2011069 and Northwest A&F University Ph.D. Scientific
   Research Foundation under Grant No. 2011BSJJ095.
CR Cheng J., 2009, THESIS
   Deng J.Z., T CSAE, V28
   Guo X Y, 2011, J AGR MECH RES, V33, P190
   Li Ping-ting, 2011, Computer Engineering, V37, P224, DOI 10.3969/j.issn.1000-3428.2011.16.076
   [李志臣 LI Zhichen], 2008, [东北农业大学学报, Journal of Northeast Agricultural University], V39, P117
   Li Zhuo, 2007, Chinese Journal of Electron Devices, V30, P2137
   Ling L., 2004, 11 INT C GEOM GRAPH, P113
   Liu J., 2013, AGR ENG, V3, P116
   [刘亮 LIU Liang], 2006, [中国科学院研究生院学报, Journal of the Graduate School of the Academy of Sciences], V23, P484
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lv C.H., 2001, T CSAE, V17, P146
   [乔玉良 Qiao Yuliang], 2002, [遥感学报, Journal of Remote Sensing], V6, P70
   SUN JX, 2001, FEATURE EXTRACTION C
   Wang Y.L, 2013, COMPUT PROGRAMM SKIL, P86
   WU FN, 2003, REV CHINA AGR SCI TE, V5, P76
   Xie W.L, 2012, J HUMAN I ENG, V22, P46
   Xu GF, 2009, THESIS
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   [张汝波 Zhang Rubo], 2013, [计算机研究与发展, Journal of Computer Research and Development], V50, P1981
   Zhu Jiang, 2010, Chinese Journal of Scientific Instrument, V31, P1916
NR 23
TC 25
Z9 27
U1 1
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 138
EP 146
DI 10.1016/j.jvcir.2015.02.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100013
DA 2024-07-18
ER

PT J
AU Ma, XX
   Pan, ZB
   Hu, S
   Wang, LF
AF Ma, Xiaoxiao
   Pan, Zhibin
   Hu, Sen
   Wang, Lingfei
TI Reversible data hiding scheme for VQ indices based on modified locally
   adaptive coding and double-layer embedding strategy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Steganography; Reversible data hiding; Vector quantzation
   (VQ); Side match vector quantization (SMVQ); Locally adaptive coding;
   Modified locally adaptive coding; Double-layer embedding
ID VECTOR QUANTIZATION; SIDE MATCH; DESIGN; TABLE
AB In this paper, a new reversible data hiding scheme for vector quantization (VQ) compressed images is proposed. The proposed scheme utilizes the modified locally adaptive coding scheme which is initially made up with the codebook indices to guarantee that all VQ indices can be coded using the self-organized list L. Then the side match vector quantization (SMVQ) approach is used to improve the performance of locally adaptive coding scheme and a lossless coding method is brought into encode the positions at which the VQ indices appear in the list L. Finally a double-layer embedding strategy, which embeds the secret message into two layers that are the block type descriptor and the encoded position value, is proposed to obtain a better embedding ability. The experimental results demonstrate that our proposed scheme has a better performance in terms of compression rate, embedding payload and embedding efficiency compared with the related schemes. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ma, Xiaoxiao; Pan, Zhibin] Nanchang Hangkong Univ, Key Lab Jiangxi Prov Image Proc & Pattern Recogni, Nanchang 330063, Peoples R China.
   [Ma, Xiaoxiao; Pan, Zhibin; Hu, Sen; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
C3 Nanchang Hangkong University; Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of the National Laboratory of Pattern
   Recognition [201407370]; Open Project Program of Key Laboratory of
   Jiangxi Province for Image Processing and Pattern Recognition, Nanchang
   Hangkong University [TX2014001]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30), Open Project Program of the National Laboratory
   of Pattern Recognition (Grant No. 201407370) and Open Project Program of
   Key Laboratory of Jiangxi Province for Image Processing and Pattern
   Recognition, Nanchang Hangkong University (Grant No. TX2014001).
CR BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Ghonge M., 2014, INT J ADVENT RES COM, V1, P35
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang CT, 2013, IMAGING SCI J, V61, P195, DOI 10.1179/1743131X11Y.0000000031
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Laha A, 2004, IEEE T IMAGE PROCESS, V13, P1291, DOI 10.1109/TIP.2004.833107
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
NR 27
TC 16
Z9 16
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 60
EP 70
DI 10.1016/j.jvcir.2015.01.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000008
DA 2024-07-18
ER

PT J
AU Torkamani-Azar, F
   Imani, H
   Fathollahian, H
AF Torkamani-Azar, Farah
   Imani, Hassan
   Fathollahian, Hossein
TI Video quality measurement based on 3-D. Singular value decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image Quality assessment; Video Quality Assessment; Tensor
   decomposition; Higher Order Singular Value Decomposition; Human Visual
   Systems; Structural Information; Objective Evaluation; Video Quality
   Experts Group (VQEG)
AB This paper presents a new full reference Video Quality Assessment (VQA) method based on using 3 Dimensional Singular Value Decomposition (3-D SVD). The method compares the structural properties and the luminance characteristics between the reference and the distorted videos. This aim is obtained by applying 3-D SVD that is singular value decomposition in a 3-D space. In principal, the distorted and the original videos are projected on the singular vectors of the original video. The weighted difference between the reflections coefficients could be considered to quantify the quality of videos. For our experiments, we have used the LIVE and EPFL-PoliMI video quality databases to evaluate the performance of our metric. The results show a great correlation between the measure scores and the subjective scores. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Torkamani-Azar, Farah; Imani, Hassan; Fathollahian, Hossein] Shahid Beheshti Univ, Fac Elect & Comp Engn, Cognit Commun Res Grp, Tehran, Iran.
C3 Shahid Beheshti University
RP Torkamani-Azar, F (corresponding author), Shahid Beheshti Univ, Fac Elect & Comp Engn, Cognit Commun Res Grp, Tehran, Iran.
EM f-torkamani@sbu.ac.ir
RI Imani, Hassan/KSL-4309-2024
OI Imani, Hassan/0000-0003-1566-3897
CR Amirshahi SA, 2011, INT WORK QUAL MULTIM, P84, DOI 10.1109/QoMEX.2011.6065718
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   De Simone F., 2010, 35 INT C AC SPEECH S
   De Simone F., 2009, 1 INT WORKSH QUAL MU
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kolda TG, 2001, SIAM J MATRIX ANAL A, V23, P243, DOI 10.1137/S0895479800368354
   Lin DCC, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P320, DOI 10.1109/MMSP.2006.285322
   LU ZK, 2003, P ICASSP 2003 HONG K, V3, P617
   Mahmoudi-Aznaveh A, 2009, OPT REV, V16, P30, DOI 10.1007/s10043-009-0007-6
   Mansouri A, 2009, OPT REV, V16, P49, DOI 10.1007/s10043-009-0010-y
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Rohaly A. M, 2000, VIDEO QUALITY EXPERT
   Seshadrinathan K., 2009, P SPIE HUM VIS EL IM
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sheikh H.R., 2005, 1 INT WORKSH VID PRO, V7
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Tao P., 2007, VIDEO QUALITY ASSESS
   Tucker L., 1963, PROBLEMS MEASURING C, V15, P122
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Xin F, 2008, IEEE IMAGE PROC, P2560, DOI 10.1109/ICIP.2008.4712316
NR 25
TC 7
Z9 8
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2015
VL 27
BP 1
EP 6
DI 10.1016/j.jvcir.2014.12.004
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CA5SI
UT WOS:000348967700001
DA 2024-07-18
ER

PT J
AU Zhu, J
   Yu, J
   Wang, C
   Li, FZ
AF Zhu, Jie
   Yu, Jian
   Wang, Chaomurilige
   Li, Fan-Zhang
TI Object recognition via contextual color attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object recognition; Color attention; Discriminative color; Strong patch;
   Weak patch; False weak patch; Contextual color attention; Optimal
   threshold of contextual color attention
ID CO-SEGMENTATION METHOD; TOP-DOWN; BOTTOM-UP; SALIENCY; INFORMATION
AB Visual attention is effective in differentiating an object from its surroundings. Color is used to guide attention via a top-down category-specific attention map in the top-down color attention (CA) method. To uniformly highlight the entire object, our color attention map is reconstructed based on the estimated object patches. The object patches consist of strong patches and false weak patches whose contextual color attention values are beyond the optimal threshold of class-specific contextual color attention. The color attention map constructed by the object color histogram is then used to weight the local shape for object recognition. Extensive experiments are conducted to show that our method can provide stateof-the-art results on several challenging datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhu, Jie; Yu, Jian; Wang, Chaomurilige] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
   [Zhu, Jie] Cent Inst Correct Police, Dept Informat Management, Baoding, Peoples R China.
   [Li, Fan-Zhang] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Peoples R China.
C3 Beijing Jiaotong University; Soochow University - China
RP Yu, J (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
EM arthurzhujie@gmail.com; jianyu@bjtu.edu.cn
RI Yu, Jian/HJY-2670-2023; Li, Fan/GRX-7461-2022
FU NSFC [61033013, 61370129, 61375062, 61300072, 61105056, 61402462]; PhD
   Programs Foundation of the Ministry of Education of China
   [20120009110006]; PCSIRT [IRT 201206]; Fundamental Research Funds for
   the Central Universities, Beijing Committee of Science and Technology,
   China [Z131110002813118]; PTPCPA [2014YL41]
FX This work was supported by the NSFC Grants (61033013, 61370129,
   61375062, 61300072, 61105056, 61402462), the PhD Programs Foundation of
   the Ministry of Education of China (20120009110006), PCSIRT (IRT 201206)
   and the Fundamental Research Funds for the Central Universities, Beijing
   Committee of Science and Technology, China (No. Z131110002813118).
   PTPCPA (2014YL41).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   Awh E, 2012, TRENDS COGN SCI, V16, P437, DOI 10.1016/j.tics.2012.06.010
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Fan JL, 2010, LECT NOTES COMPUT SC, V6311, P411
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fernando B, 2012, PROC CVPR IEEE, P3434, DOI 10.1109/CVPR.2012.6248084
   Fu ZY, 2011, IEEE T PATTERN ANAL, V33, P958, DOI 10.1109/TPAMI.2010.155
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Khan FS, 2009, IEEE I CONF COMP VIS, P979, DOI 10.1109/ICCV.2009.5459362
   Khan FS., 2011, Advances in Neural Information Processing Systems 24 (NIPS-2011), P1323
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Koffka K., 1955, ROUTLEDGE KEGAN PAUL, V2, P4
   Koniusz P, 2011, IEEE IMAGE PROC, P661
   Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mahadevan V, 2009, PROC CVPR IEEE, P1007, DOI 10.1109/CVPRW.2009.5206573
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Nilsback M.-E., 2006, IEEE C COMP VIS PATT, V2, P1447, DOI [DOI 10.1109/CVPR.2006.42, 10.1109/CVPR.2006.42]
   Nilsback M-E., 2009, AUTOMATIC VISUAL FLO
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Parikh D, 2008, LECT NOTES COMPUT SC, V5303, P446, DOI 10.1007/978-3-540-88688-4_33
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Perko R, 2010, COMPUT VIS IMAGE UND, V114, P700, DOI 10.1016/j.cviu.2010.03.005
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   van de Weijer J, 2007, IEEE IMAGE PROC, P1621
   van de Weijer J, 2006, LECT NOTES COMPUT SC, V3952, P334
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang M, 2011, PROC CVPR IEEE, P417, DOI 10.1109/CVPR.2011.5995743
   Yan F, 2010, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2010.5539916
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Yuan XT, 2012, IEEE T IMAGE PROCESS, V21, P4349, DOI 10.1109/TIP.2012.2205006
   Zhu GK, 2014, COMPUT VIS IMAGE UND, V118, P40, DOI 10.1016/j.cviu.2013.07.011
   Zhu J., IET IMAGE PROCESS
NR 52
TC 13
Z9 15
U1 3
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2015
VL 27
BP 44
EP 56
DI 10.1016/j.jvcir.2015.01.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CA5SI
UT WOS:000348967700004
DA 2024-07-18
ER

PT J
AU Wang, CP
   Zhang, JS
   Chang, GD
   Ke, Q
AF Wang, Changpeng
   Zhang, Jiangshe
   Chang, Guodong
   Ke, Qiao
TI Singular Value Decomposition Projection for solving the small sample
   size problem in face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Dimensionality reduction; Singular Value
   Decomposition; Small sample size problem; Sparse Representation based
   Classification; Transformation matrix; Row-orthonormal; Recognition
   accuracy
AB Numerous dimensionality reduction methods have achieved impressive performance in face recognition field due to their potential to exploit the intrinsic structure of images and to enhance the computational efficiency. However, the FR methods based on the existing dimensionality reduction often suffer from small sample size (SSS) problems, where the sample dimensionality is larger than the number of training samples per subject. In recent years, Sparse Representation based Classification (SRC) has been demonstrated to be a powerful framework for robust FR. In this paper, a novel unsupervised dimensionality reduction algorithm, called Singular Value Decomposition Projection (SVDP), is proposed to better fit SRC for handling the SSS problems in FR. In SVDP, a weighted linear transformation matrix is derived from the original data matrix via Singular Value Decomposition. The projection obtained in this way is row-orthonormal and it has some good properties. It makes the solution be robust to small perturbations contained in the data and has better ability to represent various signals. Thus, SVDP could better preserve the discriminant information of the data. Based on SVDP, a novel face recognition method SVDP-SRC is designed to enable SRC to achieve better performance via low-dimensional representation of faces. The experiments carried out with some simulated data show that SVDP achieves higher recovery accuracy than several other dimensionality reduction methods. Moreover, the results obtained on three standard face databases demonstrate that SVDP-SRC is quite effective to handle the SSS problems in terms of recognition accuracy. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Changpeng; Zhang, Jiangshe; Chang, Guodong; Ke, Qiao] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Zhang, JS (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
EM jszhang@mail.xjtu.edu.cn
RI Ke, Qiao/ABB-8750-2021
OI Ke, Qiao/0000-0002-0672-4734
FU National Basic Research Program of China (973 Program) [2013CB329404];
   Major Research Project of the National Natural Science Foundation of
   China [91230101]; National Natural Science Foundation of China
   [61075006, 11201367]; Key Project of the National Natural Science
   Foundation of China [11131006]
FX This work was supported by the National Basic Research Program of China
   (973 Program) under Grant No. 2013CB329404, the Major Research Project
   of the National Natural Science Foundation of China under Grant No.
   91230101, the National Natural Science Foundation of China under Grant
   No. 61075006 and 11201367, and the Key Project of the National Natural
   Science Foundation of China under Grant No. 11131006.
CR [Anonymous], 1987, MATRIX ANAL
   [Anonymous], 2007, IJCAI
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Candes E., 2005, LI MAGIC RECOVERY SP
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Goel N, 2005, PROC SPIE, V5779, P426, DOI 10.1117/12.605553
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HIGHAM DJ, 1995, LINEAR ALGEBRA APPL, V214, P193, DOI 10.1016/0024-3795(93)00066-9
   Higham N. J., 1994, Mathematics of Computation 1943-1993: A Half-Century of Computational Mathematics, V48, P49, DOI [10.1090/psapm/048/1314843, DOI 10.1090/PSAPM/048/1314843]
   Hua G, 2011, IEEE T PATTERN ANAL, V33, P1921, DOI 10.1109/TPAMI.2011.182
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   Li J, 2013, NEUROCOMPUTING, V116, P265, DOI 10.1016/j.neucom.2012.04.034
   Liao SC, 2013, IEEE T PATTERN ANAL, V35, P1193, DOI 10.1109/TPAMI.2012.191
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Martinez A. M., 1998, THE AR FACE DATABASE
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wipf D.P., 2011, P ADV NEUR INF PROC, V24, P2016
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang AY, 2013, IEEE T IMAGE PROCESS, V22, P3234, DOI 10.1109/TIP.2013.2262292
   Yong Xu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.234
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 32
TC 7
Z9 7
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 265
EP 274
DI 10.1016/j.jvcir.2014.09.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000024
DA 2024-07-18
ER

PT J
AU El Maliani, AD
   El Hassouni, M
   Berthoumieu, Y
   Aboutajdine, D
AF El Maliani, Ahmed Drissi
   El Hassouni, Mohammed
   Berthoumieu, Yannick
   Aboutajdine, Driss
TI Color texture classification method based on a statistical multi-model
   and geodesic distance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color texture; Wavelet representation; Multivariate copula model; Rao
   geodesic distance; Bayesian classification; Lab and HSV color spaces;
   Dependence structure; Joint linear-circular model
AB In this paper, we propose a novel color texture classification method based on statistical characterization. The approach consists in modeling complex wavelet coefficients of both luminance and chrominance components separately leading to a multi-modeling approach. The copula theory allows to take into account the spatial dependencies which exist within the intra-luminance sub-bands via the luminance model M-L, and also between the inter-chrominance subband coefficients via the chrominance model M-CT The multi-model, i.e. M-L and M-CT, is used to develop a Bayesian classifier based on the softmax principal. To derive the classifier, we propose a closed-form expression for the Rao geodesic distance between two copulas. Experiments on two sub-families of luminance-chrominance color spaces namely Lab and HSV have been carried out for a wide range of color texture databases. The combination of different statistical sub-models show that the multi-modeling performs better than some existing methods in term of classification rates. (C) 2014 Elsevier Inc. All rights reserved.
C1 [El Maliani, Ahmed Drissi] USMBA, LIM Fac Sci Dhar El Mahraz, Fas, Morocco.
   [El Hassouni, Mohammed] Univ Mohammed V Agdal, FLSHR, DESTEC, Rabat, Morocco.
   [Berthoumieu, Yannick] Inst Polytech Bordeaux, ENSEIRB MATMECA, Lab IMS CNRS UMR 5218, Grp Signal & Image, Bordeaux, France.
   [El Hassouni, Mohammed; Aboutajdine, Driss] Univ Mohammed V Agdal, LRIT URAC 29, Rabat, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed V University in
   Rabat; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute for Engineering & Systems Sciences (INSIS); Mohammed V
   University in Rabat
RP El Hassouni, M (corresponding author), Univ Mohammed V Agdal, LRIT URAC 29, Rabat, Morocco.
EM maliani.ahmed@gmail.com; mohamed.elhassouni@gmail.com
RI El Hassouni, Mohammed/AAL-8452-2020; aboutajdine, driss/AAP-9051-2020;
   Drissi el maliani, Ahmed/ITU-2063-2023; Berthoumieu,
   Yannick/AAL-8245-2020
OI El Hassouni, Mohammed/0000-0002-6741-4799; Berthoumieu,
   Yannick/0000-0002-7559-0602
CR [Anonymous], P IEEE DIG SIGN PROC
   Atkinson C., 1981, Sankhya Ser. A, V43, P345
   Berthoumieu Y., 2011, LECT NOTES COMPUT SC, V7340, P36
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boubchir L, 2010, IEEE IMAGE PROC, P1877, DOI 10.1109/ICIP.2010.5652329
   Ceolin S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4308, DOI 10.1109/ICPR.2010.1047
   DeYoe E., 1996, TRENDS NEUROSCI, V11
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Durrleman V., 2000, WHICH COPULA RIGHT O
   El Maliani AD, 2011, LECT NOTES COMPUT SC, V6855, P498, DOI 10.1007/978-3-642-23678-5_59
   Joe H., 1997, MONOGRAPHS STAT APPL, V37
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Kwitt R, 2009, IEEE IMAGE PROC, P1877, DOI 10.1109/ICIP.2009.5413656
   Lasmar NE, 2014, IEEE T IMAGE PROCESS, V23, P2246, DOI 10.1109/TIP.2014.2313232
   Lasmar NE, 2010, INT CONF ACOUST SPEE, P790, DOI 10.1109/ICASSP.2010.5494963
   Mallat S. G., 1999, WAVELT TOUR SIGNAL P
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Nelsen RB., 2006, INTRO COPULAS, DOI DOI 10.1007/0-387-28678-0
   Ojala T., 2002, 16 INT C PATT REC QU
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Qazi IUH, 2011, PATTERN RECOGN, V44, P16, DOI 10.1016/j.patcog.2010.07.007
   Qazi IUH, 2010, PATTERN RECOGN, V43, P663, DOI 10.1016/j.patcog.2009.07.008
   Rakvongthai Y, 2013, SIGNAL PROCESS-IMAGE, V28, P1494, DOI 10.1016/j.image.2013.06.005
   RANGASWAMY M, 1993, IEEE T AERO ELEC SYS, V29, P111, DOI 10.1109/7.249117
   Reverter F, 2003, J COMPUT APPL MATH, V157, P155, DOI 10.1016/S0377-0427(03)00387-X
   Sakji-Nsibi S, 2010, IEEE IMAGE PROC, P2333, DOI 10.1109/ICIP.2010.5653932
   Sarifuddin M., 2005, Proc. of ACM SIGIR 2005 Workshop on Multimedia Information Retrieval (MMIR 2005), P1
   Seetharaman K, 2014, J VIS COMMUN IMAGE R, V25, P727, DOI 10.1016/j.jvcir.2014.01.004
   Simoncelli EP, 1998, CONF REC ASILOMAR C, P673, DOI 10.1109/ACSSC.1997.680530
   Sklar M., 1959, Publ. Inst. Statist. Univ. Paris, V8, P229, DOI DOI 10.1007/978-3-642-33590-7
   Verdoolaege G, 2012, J MATH IMAGING VIS, V43, P180, DOI 10.1007/s10851-011-0297-8
NR 31
TC 15
Z9 15
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1717
EP 1725
DI 10.1016/j.jvcir.2014.06.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100020
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gong, YC
   Wan, S
   Yang, KF
   Yang, FZ
   Cui, L
AF Gong, Yanchao
   Wan, Shuai
   Yang, Kaifang
   Yang, Fuzheng
   Cui, Li
TI An efficient algorithm to eliminate temporal pumping artifact in video
   coding with hierarchical prediction structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Just noticeable temporal pumping artifact; Spatial-temporal masking
   effect; Hierarchical prediction structure; Hierarchical B-pictures
   structure; Quantization parameter cascading; Temporal noise; H.264/AVC;
   Video coding
ID MOSQUITO NOISE; REDUCTION; QUALITY; IMAGES
AB At low bit-rates, hierarchical prediction structure using quantization parameter cascading strategy will introduce a new temporal distortion, i.e., the temporal pumping artifact (TPA) presenting itself as a stumbling effect which seriously affect the subjective video reconstructive quality. This paper analyzes one important key factor which greatly influence the critical perceptual of the TPA and proposes a metric for just noticeable temporal pumping artifact (JNTPA) based on spatial-temporal masking effects in human visual system (HVS). Finally, an efficient TPA eliminating algorithm in video coding based on the JNTPA has been proposed. The subsequent experiments demonstrate that the estimated JNTPA values using the proposed metric are in line with the HVS perception and comparable with JVT-P104, the proposed TPA eliminating algorithm achieves a more smooth subjective video quality and improves the observe comfort of the human eye. At the same bit-rate, better subjective video quality can be observed using the eliminating algorithm. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Gong, Yanchao; Wan, Shuai; Yang, Kaifang; Cui, Li] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
   [Yang, Fuzheng] Xidian Univ, State Key Lab ISN, Xian, Peoples R China.
C3 Northwestern Polytechnical University; Xidian University
RP Gong, YC (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM ycgong@mail.nwpu.edu.cn
RI Wan, Shuai/AAA-8777-2022
OI Wan, Shuai/0000-0001-8617-149X
FU National Natural Science Foundation Research Program of China [61371089]
FX This work was supported by the National Natural Science Foundation
   Research Program of China (No. 61371089).
CR Abbas H, 2007, INT CONF ACOUST SPEE, P773
   [Anonymous], 2002, RECBT50011 ITUR
   [Anonymous], 2008, RECP910 ITUT
   Borer S., 2010, Proceedings of the 2010 Second International Workshop on Quality of Multimedia Experience (QoMEX 2010), P218, DOI 10.1109/QOMEX.2010.5516155
   Chono K, 2006, IEEE IMAGE PROC, P1713, DOI 10.1109/ICIP.2006.312711
   Chun SS, 2006, IEEE T CONSUM ELECTR, V52, P1303, DOI 10.1109/TCE.2006.273149
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   Iacovoni G., 2005, Proc. IEEE International Conference on Multimedia and Expo, P1452
   JVT, 2009, H2641449610 JVT AVC
   KARUNASEKERA SA, 1995, IEEE T IMAGE PROCESS, V4, P713, DOI 10.1109/83.388074
   Kim I. K., 2013, JCTVCL1002
   Li XA, 2009, IEEE IMAGE PROC, P3765, DOI 10.1109/ICIP.2009.5414354
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Mantel C, 2009, INT WORK QUAL MULTIM, P244, DOI 10.1109/QOMEX.2009.5246943
   Ninassi A, 2009, IEEE J-STSP, V3, P253, DOI 10.1109/JSTSP.2009.2014806
   Ong EP, 2006, J VIS COMMUN IMAGE R, V17, P717, DOI 10.1016/j.jvcir.2005.11.002
   Schwarz H., 2005, JVTP104
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   Vo DT, 2009, IEEE T IMAGE PROCESS, V18, P1166, DOI 10.1109/TIP.2009.2017341
   VQEG, 2007, HYBR PERC BITSTR GRO
   Wan S., 2012, P IEEE INT C MULT EX, P503
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Winkler S, 1999, SIGNAL PROCESS, V78, P231, DOI 10.1016/S0165-1684(99)00062-6
   Xiang Li, 2010, 2010 IEEE International Symposium on Circuits and Systems. ISCAS 2010, P4197, DOI 10.1109/ISCAS.2010.5537584
   Yang Fu-zheng, 2006, Journal of Zhejiang University (Science), V7, P95, DOI 10.1631/jzus.2006.AS0095
   Yang JX, 2010, IEEE T CIRC SYST VID, V20, P458, DOI 10.1109/TCSVT.2009.2035850
NR 28
TC 2
Z9 3
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1528
EP 1542
DI 10.1016/j.jvcir.2014.06.015
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100004
DA 2024-07-18
ER

PT J
AU Liao, L
   Zhang, YN
   Maybank, SJ
   Liu, ZF
   Liu, X
AF Liao, Liang
   Zhang, Yanning
   Maybank, Stephen John
   Liu, Zhoufeng
   Liu, Xin
TI Image recognition via two-dimensional random projection and nearest
   constrained subspace
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Supervised image classification; Two-dimensional random projection;
   Compressive sampling; l(1)-normminimization; l(0)-norm sparse
   presentation; Constrained subspace; Affine hull; Intrinsic dimension
   estimation
ID FACE RECOGNITION; SIGNAL RECOVERY; INTRINSIC DIMENSION; REPRESENTATION;
   REDUCTION; EIGENMAPS; MANIFOLDS; PCA
AB We consider the problem of image recognition via two-dimensional random projection and nearest constrained subspace. First, image features are extracted by a two-dimensional random projection. The two-dimensional random projection for feature extraction is an extension of the 1D compressive sampling technique to 2D and is computationally more efficient than its 1D counterpart and 2D reconstruction is guaranteed. Second, we design a new classifier called NCSC (Nearest Constrained Subspace Classifier) and apply it to image recognition with the 2D features. The proposed classifier is a generalized version of NN (Nearest Neighbor) and NFL (Nearest Feature Line), and it has a close relationship to NS (Nearest Subspace). For large datasets, a fast NCSC, called NCSC-II, is proposed. Experiments on several publicly available image sets show that when well-tuned, NCSC/NCSC-II outperforms its rivals including NN, NFL NS and the orthonormal l(2)-norm classifier. NCSC/NCSC-II with the 2D random features also shows good classification performance in noisy environment. (c) 2014 Published by Elsevier Inc.
C1 [Liao, Liang; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Shaanxi, Peoples R China.
   [Liao, Liang; Liu, Zhoufeng] Zhongyuan Univ Technol, Sch Elect & Informat, Zhengzhou 450007, Henan, Peoples R China.
   [Maybank, Stephen John] Univ London Birkbeck Coll, Dept Comp Sci & Informat Syst, London WC1E 7HX, England.
   [Liu, Xin] Yellow River Conservancy Commiss, Informat Ctr, Zhengzhou 450003, Henan, Peoples R China.
C3 Northwestern Polytechnical University; Zhongyuan University of
   Technology; University of London; Birkbeck University London
RP Zhang, YN (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710129, Shaanxi, Peoples R China.
EM liaoliangis@126.com; ynzhang@nwpu.edu.cn; sjmaybank@dcs.bbk.ac.uk;
   lzhoufeng@hotmail.com; liuxinis@126.com
FU National Natural Science Foundation of China [61152004, 61379113]; China
   Postdoctoral Science Foundation [20110490173]; Key Science and
   Technology Research Project of Henan Province [12A510028]; Foundational
   Frontier Technology Research Project of Henan Province [132300410163];
   High-end Foreign Experts Recruitment Program [GDW20134100119]
FX This work was supported in part by the National Natural Science
   Foundation of China (Nos. 61152004 and 61379113), China Postdoctoral
   Science Foundation (No. 20110490173), Key Science and Technology
   Research Project of Henan Province (No. 12A510028), Foundational
   Frontier Technology Research Project of Henan Province (No.
   132300410163) and High-end Foreign Experts Recruitment Program (No.
   GDW20134100119).
CR [Anonymous], 2004, ADV NEURAL INF PROCE
   [Anonymous], 1981, Practical Optimization
   [Anonymous], MNIST DATABASE HANDW
   [Anonymous], 2004, SIAM J SCI COMPUTING
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Baraniuk RG, 2009, FOUND COMPUT MATH, V9, P51, DOI 10.1007/s10208-007-9011-z
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Broomhead DS, 2001, NEURAL COMPUT, V13, P2595, DOI 10.1162/089976601753196049
   Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189
   Calderbank R., 2009, PREPRINT
   Camastra F, 2002, IEEE T PATTERN ANAL, V24, P1404, DOI 10.1109/TPAMI.2002.1039212
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Carter KM, 2010, IEEE T SIGNAL PROCES, V58, P650, DOI 10.1109/TSP.2009.2031722
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P1040, DOI 10.1137/S1052623494240456
   Davenport M., 2007, Proceedings of SPIE Symposium on Electronic Imaging: Computational Imaging, P6498
   Davenport MA, 2010, IEEE J-STSP, V4, P445, DOI 10.1109/JSTSP.2009.2039178
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P2197, DOI 10.1073/pnas.0437847100
   Duarte MF, 2007, IEEE IMAGE PROC, P2957
   Eftekhari A, 2011, SIGNAL PROCESS, V91, P1589, DOI 10.1016/j.sigpro.2011.01.002
   Farahmand A. M., 2007, P 24 INT C MACH LEAR, P265, DOI [10.1145/1273496.1273530, DOI 10.1145/1273496.1273530]
   Fu Y, 2008, IEEE T IMAGE PROCESS, V17, P226, DOI 10.1109/TIP.2007.914203
   FUKUNAGA K, 1971, IEEE T COMPUT, VC 20, P176, DOI 10.1109/T-C.1971.223208
   GRASSBERGER P, 1983, PHYSICA D, V9, P189, DOI 10.1016/0167-2789(83)90298-1
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hinton GE, 1997, IEEE T NEURAL NETWOR, V8, P65, DOI 10.1109/72.554192
   Huang J., 2008, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1
   Kegl B, 2002, Advances in neural information processing systems, V15
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Levina Elizaveta, 2004, Advances in neural information processing systems, V17
   Li C., TVAL 3 TV MINIMIZATI
   Li SZ, 1999, IEEE T NEURAL NETWOR, V10, P439, DOI 10.1109/72.750575
   Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536
   Li XL, 2010, IEEE T SYST MAN CY B, V40, P1170, DOI 10.1109/TSMCB.2009.2035629
   Liang Liao, 2011, 2011 International Conference on Multimedia Technology, P1
   Majumdar A, 2010, IEEE T SYST MAN CY B, V40, P1359, DOI 10.1109/TSMCB.2009.2038493
   Mathworks, SOLV CONSTR LIN LEAS
   Pang YW, 2008, IEEE T SYST MAN CY B, V38, P1176, DOI 10.1109/TSMCB.2008.923151
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Weinberger KQ, 2004, PROC CVPR IEEE, P988
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu D, 2007, IEEE T SYST MAN CY B, V37, P1226, DOI 10.1109/TSMCB.2006.888925
   Xu D, 2009, IEEE T IMAGE PROCESS, V18, P1671, DOI 10.1109/TIP.2009.2018015
   Xu D, 2009, IEEE T PATTERN ANAL, V31, P1913, DOI 10.1109/TPAMI.2009.51
   Yang A. Y., 2007, Tech. Rep. UCB/EECS-2007-99
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
NR 63
TC 5
Z9 6
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1187
EP 1198
DI 10.1016/j.jvcir.2014.03.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200044
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Buys, K
   Cagniart, C
   Baksheev, A
   De Laet, T
   De Schutter, J
   Pantofaru, C
AF Buys, Koen
   Cagniart, Cedric
   Baksheev, Anatoly
   De Laet, Tinne
   De Schutter, Joris
   Pantofaru, Caroline
TI An adaptable system for RGB-D based human body detection and pose.
   estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Real-time; Body part recognition; Joint locations; Pose detection; RGB-D
   data; Person detection; Random decision forest; Open source; Motion
   capture
AB Human body detection and pose estimation is useful for a wide variety of applications and environments. Therefore a human body detection and pose estimation system must be adaptable and customizable. This paper presents such a system that extracts skeletons from RGB-D sensor data. The system adapts on-line to difficult unstructured scenes taken from a moving camera (since it does not require background subtraction) and benefits from using both color and depth data. It is customizable by virtue of requiring less training data, having a clearly described training method, and a customizable human kinematic model. Results show successful application to data from a moving camera in cluttered indoor environments. This system is open-source, encouraging reuse, comparison, and future research. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Buys, Koen; De Laet, Tinne; De Schutter, Joris] Katholieke Univ Leuven, Dept Mech Eng, B-3001 Heverlee, Belgium.
   [Cagniart, Cedric] Tech Univ Munich, D-85748 Garching, Germany.
   [Baksheev, Anatoly] Itseez, Nizhnii Novgorod 603000, Russia.
   [Pantofaru, Caroline] Willow Garage, Menlo Pk, CA USA.
C3 KU Leuven; Technical University of Munich
RP Buys, K (corresponding author), Katholieke Univ Leuven, Dept Mech Eng, Celestijnenlaan 300, B-3001 Heverlee, Belgium.
EM buys.koen@gmail.com
RI De Laet, Tinne/AAK-8612-2020
OI De Laet, Tinne/0000-0003-0624-3305; De Schutter,
   Joris/0000-0001-9619-5815
FU Flemish; German government; KU Leuven's Concerted Research Action
   [GOA/2010/011]; PCL-Nvidia Code Sprint grant; Amazon Web Services
   education and research grant; Nvidia
FX The authors would like to acknowledge Willow Garage for their open
   contribution to the community with the PR2 Beta Program, Nvidia for
   their financial contributions and technical support for this project.
   The Flemish and the German government for financially supporting the
   authors.; Koen Buys is funded by KU Leuven's Concerted Research Action
   GOA/2010/011 Global real-time optimal control of autonomous robots and
   mechatronic systems, a PCL-Nvidia Code Sprint grant, an Amazon Web
   Services education and research grant, this work was partially performed
   during an intern stay at Willow Garage.; Anatoly Basheev is funded by
   Nvidia as support for the Point-Cloud Library.
CR Agarwal A., 2004, CVPR
   [Anonymous], ICCV
   [Anonymous], 2010, ICRA
   [Anonymous], P IEEE RSJ INT C INT
   [Anonymous], 2005, CVPR
   [Anonymous], CONS DEPTH CAM COMP
   [Anonymous], 2009, ICCV
   [Anonymous], 2010, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], ECCV
   [Anonymous], 2011, CVPR
   [Anonymous], CS201105 U VIRG
   [Anonymous], 2003, CVPR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MICROSOFT XBOX KINEC
   [Anonymous], COME OUR COMMUNITY I
   [Anonymous], P INT C ROB AUT ICRA
   [Anonymous], 2004, OSDI
   [Anonymous], CVCG CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], 2011, UIST
   [Anonymous], 2005, IJCV
   [Anonymous], 2011, ICCV
   [Anonymous], 2008, ECCV
   [Anonymous], INT S DIG HUM MOD
   [Anonymous], CMU GRAPHICS LAB MOT
   [Anonymous], CVPR
   [Anonymous], INT S DIG HUM MOD
   [Anonymous], 2011, ICCV
   Borthakur D., 2007, TECH REP
   Ioffe S., 2001, IJCV, P43
   Kalogerakis E, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778839
   Lepetit V., 2005, CVPR
   Moeslund T.B., 2001, CVIU
   Moeslund T.B., 2006, CVIU
   Ning H., 2008, CVPR, P1
   Poppe R., 2007, CVIU
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Sigal L., 2004, CVPR
   Tu Z.W., 2008, CVPR
   White T., 2012, HADOOP DEFINITIVE GU
   Ye M, 2011, 2011 INT C COMP VIS
   Zhu Y., 2007, ACCV
NR 43
TC 89
Z9 96
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 39
EP 52
DI 10.1016/j.jvcir.2013.03.011
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900005
DA 2024-07-18
ER

PT J
AU Wang, HJ
   Fu, JJ
   Lu, Y
   Chen, XL
   Li, SP
AF Wang, Hanjie
   Fu, Jingjing
   Lu, Yan
   Chen, Xilin
   Li, Shipeng
TI Depth sensor assisted real-time gesture recognition for interactive
   presentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gesture recognition; Real-time interaction; Motion History Image; Depth
   sensor; Background subtraction; Hand tracking; Feature pooling;
   Discriminative model
ID MOVEMENT
AB In this paper, we present a gesture recognition approach to enable real-time manipulating projection content through detecting and recognizing speakers gestures from the depth maps captured by a depth sensor. To overcome the limited measurement accuracy of depth sensor, a robust background subtraction method is proposed for effective human body segmentation and a distance map is adopted to detect human hands. Potential Active Region (PAR) is utilized to ensure the generation of valid hand trajectory to avoid extra computational cost on the recognition of meaningless gestures and three different detection modes are designed for complexity reduction. The detected hand trajectory is temporally segmented into a series of movements, which are represented as Motion History Images. A set-based soft discriminative model is proposed to recognize gestures from these movements. The proposed approach is evaluated on our dataset and performs efficiently and robustly with 90% accuracy. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Hanjie; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Fu, Jingjing; Lu, Yan; Li, Shipeng] Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Microsoft Research Asia; Microsoft
RP Fu, JJ (corresponding author), Tower 2,5 Danling St, Beijing 100080, Peoples R China.
EM jifu@microsoft.com
RI Li, Shipeng/AAA-3374-2020; fu, jingjing/HLW-1028-2023
OI Li, Shipeng/0000-0001-5368-4256
FU NSFC [61025010, 61001193]; FiDiPro program of Tekes
FX Hanjie Wang and Xilin Chen was partially supported by the NSFC under
   contract Nos. 61025010 and 61001193, and the FiDiPro program of Tekes.
CR [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bobick AF, 1997, PHILOS T ROY SOC B, V352, P1257, DOI 10.1098/rstb.1997.0108
   Feng XL, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P717, DOI 10.1109/TDPVT.2002.1024148
   Fujimura K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P381
   Jia YQ, 2012, PROC CVPR IEEE, P3370, DOI 10.1109/CVPR.2012.6248076
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Sadeghipour A., 2012, BMVC
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P500, DOI 10.1109/FG.2011.5771448
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang Q., 2010, BMVC
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
NR 22
TC 5
Z9 10
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1458
EP 1468
DI 10.1016/j.jvcir.2013.10.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700020
DA 2024-07-18
ER

PT J
AU Cho, SG
   Cha, BH
   Gawecki, M
   Kuo, CCJ
AF Cho, Seongho
   Cha, Byung-Ho
   Gawecki, Martin
   Kuo, C. -C. Jay
TI Block-based image steganalysis: Algorithm and performance evaluation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganalysis; Steganography; Block-based image steganalysis; Decision
   fusion; Stego image; Block decomposition; Fisher linear discriminant
   classifier; Dempster-Shafer theory
ID CLASSIFIER
AB Traditional image steganalysis is conducted with respect to the entire image frame. In this work, we differentiate a stego image from its cover image based on steganalysis of decomposed image blocks. After image decomposition into smaller blocks, we classify image blocks into multiple classes and find a classifier for each class. Then, steganalysis of the whole image can be obtained by integrating results of all image blocks via decision fusion. Extensive performance evaluation of block-based image steganalysis is conducted. For a given test image, there exists a trade-off between the block size and the block number. We propose to use overlapping blocks to improve the steganalysis performance. Additional performance improvement can be achieved using different decision fusion schemes and different classifiers. Besides the block-decomposition framework, we point out that the choice of a proper classifier plays an important role in improving detection accuracy, and show that both the logistic classifier and the Fisher linear discriminant classifier outperforms the linear Bayes classifier by a significant margin. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Cho, Seongho; Gawecki, Martin; Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Cho, Seongho; Gawecki, Martin; Kuo, C. -C. Jay] Univ So Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
   [Cha, Byung-Ho] Samsung Elect Co LTD, Convergence S W Lab, Suwon 443742, Gyeonggi Do, South Korea.
C3 University of Southern California; University of Southern California;
   Samsung; Samsung Electronics
RP Cha, BH (corresponding author), Samsung Elect Co LTD, Convergence S W Lab, Suwon 443742, Gyeonggi Do, South Korea.
EM seonghoc@usc.edu; bhpaul.cha@samsung.com; gawecki@usc.edu;
   cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR [Anonymous], 2006, Handbook of Multibiometrics
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   CHEN C, 2008, P IEEE INT S CIRC SY
   Cho S., 2010, P IEEE INT S CIRC SY
   Cho S., 2011, P IEEE INT S CIRC SY
   Cho S., 2010, P IEEE INT C MULT EX
   Cox IJ., 2007, DIGITAL WATERMARKING
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Fridrich J, 2004, P INT WORKSH INF HID
   Jegou H., 2008, EUR C COMP VIS MARS
   KODOVSKY J, 2009, P ACM MULT SEC WORKS
   Kodovsky J., 2010, P SPIE C EL IM MED F
   Kraetzer C., 2009, P MED FOR SEC 11 IS
   Kuncheva LI, 2001, FUZZY SET SYST, V122, P401, DOI 10.1016/S0165-0114(99)00161-X
   PEVNY T, 2007, P SPIE C SEC WAT STE
   Pevny T., 2009, P ACM MULT SEC WORKS
   Rodriguez B, 2006, P IEEE INT C SYST MA
   ROGOVA G, 1994, NEURAL NETWORKS, V7, P777, DOI 10.1016/0893-6080(94)90099-X
   SALLEE P, 2003, P INT WORKSH DIG WAT
   Schaefer G., 2004, P SPIE C STOR RETR M
   Shi Y, 2006, P INT WORKSH INF HID
   Solanki K., 2007, INFORM HIDING
   Wang Y., 2004, P SPIE C SEC WAT STE
NR 24
TC 19
Z9 23
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 846
EP 856
DI 10.1016/j.jvcir.2013.05.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700011
DA 2024-07-18
ER

PT J
AU Petit, J
   Mantiuk, RK
AF Petit, Josselin
   Mantiuk, Rafal K.
TI Assessment of video tone-mapping: Are cameras' S-shaped tone-curves good
   enough?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range; HDR video; Tone mapping; Tone mapping evaluation;
   Quality assessment; Camera response curve; Fidelity; Preference
ID APPEARANCE; OPERATORS; DISPLAY; MODEL
AB The performance of video tone-mapping operators is investigated in a rating experiment using two criteria: overall quality and fidelity to real-world experience. The study includes a tone-curve used in commercial cameras, rarely considered in tone-mapping evaluation studies. The quality is measured for a range of parameter settings, revealing the importance of parameter fine-tuning and often unsatisfactory results of the default operator parameters. In order to explain what makes best performing operators better, the results are analysed in relation to image statistics and the characteristics of the tone-mapping function. Our observations are: state-of-the-art tone mapping produces measurably better results than camera's S-shaped curve for high dynamic range scenes with important content spanned across a wide dynamic range; differences in colour reproduction strongly affect the results; fidelity and quality criteria produce similar results when no reference is present; and state-of-the-art operators produce the results of comparable quality when their parameters are well selected. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Petit, Josselin; Mantiuk, Rafal K.] Bangor Univ, Sch Comp Sci, Bangor LL57 1UT, Gwynedd, Wales.
C3 Bangor University
RP Mantiuk, RK (corresponding author), Bangor Univ, Sch Comp Sci, Dean St, Bangor LL57 1UT, Gwynedd, Wales.
EM josselin.petit@gmail.com; mantiuk@bangor.ac.uk
RI Mantiuk, Rafał K./AAP-9514-2020; Mantiuk, Rafał K. K/I-4209-2016
OI Mantiuk, Rafał K./0000-0003-2353-0349; Mantiuk, Rafał K.
   K/0000-0003-2353-0349
FU EPSRC [EP/I006575/1] Funding Source: UKRI
CR Akyüz AG, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276425
   Akyüz AO, 2008, ACM T APPL PERCEPT, V4, DOI 10.1145/1278760.1278761
   [Anonymous], 1994, Graph. Gems, DOI DOI 10.1016/B978-0-12-336156-1.50054-9
   Ashikhmin M., 2006, ACM T APPL PERCEPT, V3, P399
   Aydin TO, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866187
   Aydin TO, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360668
   Bodrogi P., 2007, THESIS U PANNONIA
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   Celine V., 2010, C COL GRAPH IM VIS C, P189
   Delahunt PB, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1900134
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   Durand F, 2000, SPRING COMP SCI, P219
   Ferwerda J. A., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P249, DOI 10.1145/237170.237262
   Irawan P., 2005, Rendering Techniques, P231
   Johnson GM, 2005, PROC SPIE, V5668, P148, DOI 10.1117/12.602120
   Kuang J., 2006, P INT C IM SCI MILW, P461
   Kuang J., 2007, ACM T APPL PERCEPT, V3, P286
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Kuang JT, 2010, J SOC INF DISPLAY, V18, P461, DOI 10.1889/JSID18.7.461
   Kuang JT, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P315
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   Ledda P., 2004, Proceedings of the 3rd international conference on Com- puter graphics, virtual reality, visualisation and interaction in Africa, P151
   Mantiuk R, 2008, COMPUT GRAPH FORUM, V27, P699, DOI 10.1111/j.1467-8659.2008.01168.x
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Moroney N., 2002, P COL IM C, P23
   Myszkowski K., 2008, HIGH DYNAMIC RANGE V
   Pattanaik SN, 2000, COMP GRAPH, P47, DOI 10.1145/344779.344810
   Petit J, 2010, VISUAL COMPUT, V26, P533, DOI 10.1007/s00371-010-0430-5
   Philips Philirama, 1998, PHIL 1998 99, P1999
   Reinhard E, 2010, M KAUFMANN SERIES CO
   Reinhard E, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366220
   Rensink RA, 2000, VISION RES, V40, P1469, DOI 10.1016/S0042-6989(00)00003-1
   Robertson M. A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P159, DOI 10.1109/ICIP.1999.817091
   Smith K, 2006, COMPUT GRAPH FORUM, V25, P427, DOI 10.1111/j.1467-8659.2006.00962.x
   Van Hateren JH, 2006, ACM T GRAPHIC, V25, P1380, DOI 10.1145/1183287.1183293
   Yoshida A, 2005, PROC SPIE, V5666, P192, DOI 10.1117/12.587782
   Yoshida A, 2006, COMPUT GRAPH FORUM, V25, P415, DOI 10.1111/j.1467-8659.2006.00961.x
   [No title captured]
NR 40
TC 20
Z9 22
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1020
EP 1030
DI 10.1016/j.jvcir.2013.06.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700026
DA 2024-07-18
ER

PT J
AU Hu, Y
   Pearlman, WA
AF Hu, Yang
   Pearlman, William A.
TI Distributed video coding with progressive significance map
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding; Set partition coding; SPIHT coding;
   Significance map; Wavelet transform; Slepian-Wolf coding; LDPCA codes;
   Error resilience
ID COMPRESSION; EFFICIENT; INFORMATION; CODES
AB A distributed video coding (DVC) system based on wavelet transform and set partition coding (SPC) is presented in this paper. Conventionally the significance map (sig-map) of SPC is not conducive to Slepian-Wolf (SW) coding, because of the difficulty of generating a side information sig-map and the sensitivity to decoding errors. The proposed DVC system utilizes a higher structured significance map, named progressive significance map (prog-sig-map), which structures the significance information into two parts: a high-level summation significance map (sum-sig-map) and a low-level complementary significance map (comp-sig-map). This prog-sig-map alleviates the above difficulties and thus makes part of the prog-sig-map (specifically, the fixed-length-coded comp-sig-map) suitable for SW coding. Simulation results are provided showing the improved rate-distortion performance of the DVC system even with a simple system configuration. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Hu, Yang; Pearlman, William A.] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Rensselaer Polytechnic Institute
RP Pearlman, WA (corresponding author), Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
EM yanghuyh@gmail.com; pearlw@ecse.rpi.edu
OI Pearlman, William/0000-0002-4978-6812
CR Andrew J, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P658, DOI 10.1109/ICIP.1997.632207
   [Anonymous], 2011, LDPCA PROGRAM CODE
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   ARTIGAS X, 2007, PICT COD S
   CCSDS, CCSDS1220B1
   Cheung NM, 2006, SIGNAL PROCESS, V86, P3180, DOI 10.1016/j.sigpro.2006.03.016
   Chrysafis C, 2000, INT CONF ACOUST SPEE, P2035, DOI 10.1109/ICASSP.2000.859233
   Guo X, 2006, IEEE INT SYMP CIRC S, P5427
   Hsiang S.- T., 2002, THESIS RENSSELAER PO
   Hu Y, 2012, IEEE T IMAGE PROCESS, V21, P3229, DOI 10.1109/TIP.2012.2190084
   *ISO IEC, 154441 ISOIEC
   ISO/IEC, 154442 ISOIEC
   Li X., 2008, Proceedings of SPIE on Visual Communications and Image Processing, V6822
   Liveris AD, 2002, IEEE COMMUN LETT, V6, P440, DOI 10.1109/LCOMM.2002.804244
   Martin SA, 1996, NOISE CON P, P533, DOI 10.1109/ICIP.1996.560909
   Pearlman W., 2011, Digital Signal Compression: Principles and Practice
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Pearlman WA, 2008, FOUND TRENDS SIGNAL, V2, P181, DOI 10.1561/2000000014
   Pearlman WA, 2008, FOUND TRENDS SIGNAL, V2, P95, DOI 10.1561/2000000013
   PETERSON WW, 1961, P IRE, V49, P228, DOI 10.1109/JRPROC.1961.287814
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Thirumalai V, 2008, PROC SPIE, V6822, DOI 10.1117/12.766295
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wang AH, 2007, CHIN OPT LETT, V5, P336
   Wang YG, 2011, IEEE IMAGE PROC, P1821, DOI 10.1109/ICIP.2011.6115819
   WYNER AD, 1974, IEEE T INFORM THEORY, V20, P2, DOI 10.1109/TIT.1974.1055171
   Yeh PS, 2005, AEROSP CONF PROC, P4138
   Yi Zheng, 2009, 2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC 2009), P361, DOI 10.1109/ICICIC.2009.384
   Zong X., 2009, INT C WIR COMM NETW
NR 30
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 458
EP 464
DI 10.1016/j.jvcir.2013.02.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400003
DA 2024-07-18
ER

PT J
AU Zhou, YY
   Ye, ZF
   Xiao, Y
AF Zhou, Yingyue
   Ye, Zhongfu
   Xiao, Yao
TI A restoration algorithm for images contaminated by mixed Gaussian plus
   random-valued impulse noise
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Mixed noise; Sparse representation; Masked K-SVD;
   Overcomplete dictionary; Noise classification; Bayesian decision rule;
   Variational denoising model
ID SPARSE REPRESENTATION; REMOVAL; DICTIONARIES
AB In this paper, we study the problem of restoring the image corrupted by additive Gaussian noise plus random-valued impulse noise. A novel noise classifier is firstly created to identify different noise in the corrupted image. Then, we use the remaining effective information to train an adaptive overcomplete dictionary for sparse representation of image patches with the help of masked K-SVD algorithm. Because of the adaptive nature of the learned dictionary, it can represent the image patches in concern more efficiently. Then, we minimize a variational model containing an optional data-fidelity term and a smooth regularization term respecting sparse representation of every image patch to get the final restored image. Extensive experimental results prove that our method cannot only remove noise from the corrupted image well, but also preserve more details and textures. It surpasses some state-of-the-art methods. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Zhou, Yingyue; Ye, Zhongfu; Xiao, Yao] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Inst Stat Signal Proc, Hefei 230027, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ye, ZF (corresponding author), Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Inst Stat Signal Proc, Hefei 230027, Peoples R China.
EM zyyzhou@mail.ustc.edu.cn; yezf@ustc.edu.cn; xiao1988@mail.ustc.edu.cn
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 1993, 27 AS C SIGN SYST CO
   [Anonymous], 2009, P IEEE INT C COMP VI
   Awad AS, 2011, IEEE SIGNAL PROC LET, V18, P407, DOI 10.1109/LSP.2011.2154330
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A., 2005, P IEEE C COMPUTER VI
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chan RH, 2004, IEEE SIGNAL PROC LET, V11, P921, DOI 10.1109/LSP.2004.838190
   Chen T, 2001, IEEE SIGNAL PROC LET, V8, P1, DOI 10.1109/97.889633
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dong YQ, 2007, IEEE T IMAGE PROCESS, V16, P1112, DOI 10.1109/TIP.2006.891348
   Dong YQ, 2007, IEEE SIGNAL PROC LET, V14, P193, DOI 10.1109/LSP.2006.884014
   Duda R.O., 2001, Pattern Classification, V2nd, P20
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES, P220
   Li B, 2011, SCI CHINA INFORM SCI, V54, P51, DOI 10.1007/s11432-010-4128-0
   Li R., 2003, P 4 IEEE PCM
   Liu QG, 2012, J VIS COMMUN IMAGE R, V23, P753, DOI 10.1016/j.jvcir.2012.04.003
   Luo WB, 2005, IEICE T FUND ELECTR, VE88A, P2579, DOI 10.1093/ietfec/e88-a.10.2579
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Petrou M., 2000, IMAGE PROCESSING FUN, P193
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Srebro N., 2003, P ICML
   Tomasi C., 1998, 6 INT C COMP VIS IEE, P839
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Zhou YY, 2012, IET IMAGE PROCESS, V6, P976, DOI 10.1049/iet-ipr.2011.0312
NR 34
TC 17
Z9 19
U1 0
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 283
EP 294
DI 10.1016/j.jvcir.2013.01.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200007
DA 2024-07-18
ER

PT J
AU Cao, WF
   Sun, J
   Xu, ZB
AF Cao, Wenfei
   Sun, Jian
   Xu, Zongben
TI Fast image deconvolution using closed-form thresholding formulas of
   <i>L<sub>q</sub></i>(<i>q</i>=1/2, 2/3) regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparsity; L-1/2 regularization; L-2/3 regularization; Variable
   splitting; Image deconvolution; L-0 regularization; L-1 regularization;
   Thresholding formula
ID SPARSE; REPRESENTATION; ALGORITHM
AB In this paper, we focus on the research of fast deconvolution algorithm based on the non-convex L-q(q = 1/2, 2/3) sparse regularization. Recently, we have deduced the closed-form thresholding formula for L-1/2 regularization model (Xu (2010) [1]). In this work, we further deduce the closed-form thresholding formula for the L-2/3 non-convex regularization problem. Based on the closed-form formulas for L-q(q = 1/2, 2/3) regularization, we propose a fast algorithm to solve the image deconvolution problem using half-quadratic splitting method. Extensive experiments for image deconvolution demonstrate that our algorithm has a significant acceleration over Krishnan et al.'s algorithm (Krishnan et al. (2009) [3]). Moreover, the simulated experiments further indicate that L-2/3 regularization is more effective than L-0, L-1/2 or L-1 regularization in image deconvolution, and L-1/2 regularization is competitive to L-1 regularization and better than L-0 regularization. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Cao, Wenfei; Sun, Jian; Xu, Zongben] Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
C3 Xi'an Jiaotong University
RP Xu, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Math & Stat, Xian 710049, Peoples R China.
EM caowenf2006@163.com; jiansun@mail.xjtu.edu.cn; zbxu@mail.xjtu.edu.cn
FU National 973 Programming [2013CB329404]; National Natural Science
   Foundation of China [11131006]; National Natural Science Foundations of
   China [61075054]
FX We would like to thank Doctor J. X. Jia and Q Zhao for many helpful
   suggestions. This work was supported by the National 973 Programming
   (2013CB329404), the Key Program of National Natural Science Foundation
   of China (Grant No. 11131006), and the National Natural Science
   Foundations of China (Grant No. 61075054).
CR [Anonymous], 3 INT WORKSH STAT CO
   [Anonymous], P 2010 INT C POW SYS
   [Anonymous], MATH MODELS COMPUT V
   Blumensath T., 2007, IEEE T ACOUST SPEECH, V3
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Chartrand R, 2008, INVERSE PROBL, V24, DOI 10.1088/0266-5611/24/3/035020
   Chartrand R, 2009, I S BIOMED IMAGING, P262, DOI 10.1109/ISBI.2009.5193034
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Krishnan D., 2009, ADV NEURAL INF PROCE
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Xing F. C., 2003, J. Central Univ. Nation., V12, P207
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yuan L, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360673
NR 25
TC 101
Z9 114
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 31
EP 41
DI 10.1016/j.jvcir.2012.10.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600004
DA 2024-07-18
ER

PT J
AU Lee, JY
   Wey, HC
   Park, DS
AF Lee, Jin Young
   Wey, Ho-Cheon
   Park, Du-Sik
TI A high performance and low complexity sampling-based intra coding method
   for H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Sampling-based intra coding; Sampled sub-image; Prediction
   error sub-image; Intra prediction mode; Rate-distortion (RD)
   optimization; Intra mode decision; Video coding
ID PREDICTION; IMAGE
AB The H.264/AVC video coding standard can achieves higher compression performance than previous video coding standards, such as MPEG-2, MPEG-4, and H.263. Especially, in order to obtain the high coding performance in intra pictures, the H.264/AVC encoder employs various directional spatial prediction modes and the rate-distortion (RD) optimization technique inducing high computational complexity. For further improvement in the coding performance with the low computational complexity, we introduce a sampling-based intra coding method. The proposed method generates two sub-images, which are defined as a sampled sub-image and a prediction error sub-image in this paper, from an original image through horizontal or vertical sampling and prediction processes, and then each sub-image is encoded with different intra prediction modes, quantization parameters, and scanning patterns. Experimental results demonstrate that the proposed method significantly improves the intra coding performance and reduces the encoding complexity with the smaller number of the RD cost calculation process. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Lee, Jin Young; Wey, Ho-Cheon; Park, Du-Sik] Samsung Elect Co Ltd, Samsung Adv Inst Technol, Yongin 449712, Gyeonggi Do, South Korea.
C3 Samsung
RP Lee, JY (corresponding author), Samsung Elect Co Ltd, Samsung Adv Inst Technol, San 14-1, Yongin 449712, Gyeonggi Do, South Korea.
EM jinyoung79.lee@gmail.com
CR [Anonymous], VCEGAH11
   [Anonymous], 2020, INT TELECOMMUNICATIO
   Bjontegaard G., 2001, Document VCEG-M33
   Chujoh T., 2009, COM16C181E
   HILLERY AD, 1991, IEEE T SIGNAL PROCES, V39, P1892, DOI 10.1109/78.91161
   Kim D.-Y., 2008, VCEGA123
   Kim DY, 2010, IEEE T CIRC SYST VID, V20, P610, DOI 10.1109/TCSVT.2010.2041822
   Lee J. Y., 2010, P PICT COD S DEC, P62
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Piao Y., 2009, P 2009 IEEE INT C IM, P3421
   Piao Y, 2010, IEEE T CIRC SYST VID, V20, P1915, DOI 10.1109/TCSVT.2010.2090423
   Shiodera T., 2007, VCEGAE14
   Suehring K., KTA SOFTWARE COORDIN
   Tan TK, 2006, IEEE IMAGE PROC, P1693, DOI 10.1109/ICIP.2006.312685
   Tao P., 2010, P DAT COMPR C MAR
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu W., 2010, P IEEE INT C IM PROC
   Yamamoto T., 2007, VCEGAE12
   Ye Y., 2007, ITUTQ6SG16
   Yoshino T., 2008, VCEGAH23
NR 21
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1179
EP 1188
DI 10.1016/j.jvcir.2012.07.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300002
DA 2024-07-18
ER

PT J
AU Liu, J
   Ku, YB
   Leung, SY
AF Liu, Jun
   Ku, Yin-Bon
   Leung, Shingyu
TI Expectation-maximization algorithm with total variation regularization
   for vector-valued image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gaussian mixture model; Expectation-maximization; Total variation;
   Unified cost functional; Image segmentation; Vector-valued images; Fast
   algorithm; Alternative minimization
ID GAUSSIAN MIXTURE-MODELS; ANISOTROPIC DIFFUSION; BREGMAN ITERATION;
   ACTIVE CONTOURS; FIELD MODEL; COLOR; TEXTURE; FRAMEWORK; CLASSIFICATION;
   MINIMIZATION
AB We integrate the total variation (TV) minimization into the expectation-maximization (EM) algorithm to perform the task of image segmentation for general vector-valued images. We first propose a unified variational method to bring together the EM and the TV regularization and to take advantages from both approaches. The idea is based on operator interchange and constraint optimization. In the second part of the paper we propose a simple two-phase approach by splitting the above functional into two steps. In the first phase, a typical EM method can classify pixels into different classes based on the similarity in their measurements. However, since no local geometric information of the image has yet been incorporated into the process, such classification in practice gives unsatisfactory segmentation results. In the second phase, the TV-step obtains the segmentation of the image by applying a TV regularization directly to the clustering result from EM. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Ku, Yin-Bon; Leung, Shingyu] Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Hong Kong, Peoples R China.
   [Liu, Jun] Beijing Normal Univ, Lab Math & Complex Syst, Sch Math Sci, Beijing 100875, Peoples R China.
C3 Hong Kong University of Science & Technology; Beijing Normal University
RP Leung, SY (corresponding author), Hong Kong Univ Sci & Technol, Dept Math, Hong Kong, Hong Kong, Peoples R China.
EM jliu@bnu.edu.cn; maybku@ust.hk; masyleun-g@ust.hk
RI Chan, Tony/IQW-1869-2023; Leung, Shingyu/E-3100-2013
OI Leung, Shingyu/0000-0002-4549-2761; Ku, Yin Bon/0000-0002-3273-3335
FU National Natural Science Foundation of China [11201032, 11071023]; HKUST
   Grant [RPC11SC06]
FX Liu is partially supported by the National Natural Science Foundation of
   China (Nos. 11201032 and 11071023). Leung is partially supported by the
   HKUST Grant RPC11SC06.
CR Allard WK, 2007, SIAM J MATH ANAL, V39, P1150, DOI 10.1137/060662617
   ALLINEY S, 1992, IEEE T SIGNAL PROCES, V40, P1548, DOI 10.1109/78.139258
   Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179
   [Anonymous], GEOMETRY DRIVEN DIFF
   Aujol JF, 2006, J VIS COMMUN IMAGE R, V17, P916, DOI 10.1016/j.jvcir.2005.02.001
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Bresson X, 2008, INVERSE PROBL IMAG, V2, P455, DOI 10.3934/ipi.2008.2.455
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Brune C., 2009, FORWARD BACKWARD EM
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Christiansen O, 2007, INT J BIOMED IMAGING, V2007, DOI 10.1155/2007/27432
   CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F
   Duarte-Carvajalino J., 2011, ONLINE ADAPTIVE STAT
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   Duval V, 2009, MULTISCALE MODEL SIM, V8, P154, DOI 10.1137/090757083
   Duval V, 2009, LECT NOTES COMPUT SC, V5567, P295, DOI 10.1007/978-3-642-02256-2_25
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gupta L, 1998, PATTERN RECOGN, V31, P315, DOI 10.1016/S0031-3203(97)00045-9
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kay DA, 2009, IEEE T IMAGE PROCESS, V18, P2330, DOI 10.1109/TIP.2009.2026678
   Keren D, 1998, J VIS COMMUN IMAGE R, V9, P352, DOI 10.1006/jvci.1998.0392
   Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419
   LEE HC, 1991, IEEE T SIGNAL PROCES, V39, P1181, DOI 10.1109/78.80971
   Leung SY, 2009, SIAM J IMAGING SCI, V2, P834, DOI 10.1137/080731530
   Liu J., 2012, IEEE T IMAGE P UNPUB
   Liu J., 2012, J MATH IMAGING VIS, DOI DOI 10.1007/S108S1-012-0376-5
   Liu J, 2012, LECT NOTES COMPUT SC, V6667, P218, DOI 10.1007/978-3-642-24785-9_19
   Luenberger D. G., 1997, Optimization by Vector Space Methods
   MCLACHLAN BG, 2000, FINITE MIXTURE MODEL
   McLachlan G., 1996, WILEY SERIES PROBABI
   MUMFORD D, 1998, COMMUN PURE APPL MAT, V42, P577
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Osher S, 2010, COMMUN MATH SCI, V8, P93
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   PRIEBE CE, 1994, J AM STAT ASSOC, V89, P796
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Roussos A, 2007, LECT NOTES COMPUT SC, V4485, P104
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   Teboulle M, 2007, J MACH LEARN RES, V8, P65
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   Yan M., 2011, 1156 CAM UCLA
   Yin W, 2007, MULTISCALE MODEL SIM, V6, P190, DOI 10.1137/060663027
   Yin WT, 2010, SIAM J IMAGING SCI, V3, P856, DOI 10.1137/090760350
   Yu G., 2011, P IEEE ICASSP
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 64
TC 14
Z9 15
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1234
EP 1244
DI 10.1016/j.jvcir.2012.09.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300007
DA 2024-07-18
ER

PT J
AU Keskinarkaus, A
   Pramila, A
   Seppänen, T
AF Keskinarkaus, A.
   Pramila, A.
   Seppanen, T.
TI Image watermarking with feature point based synchronization robust to
   print-scan attack
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature points; Second generation watermarking; Multibit watermarking;
   Periodic patterns; Geometrical attacks; Print-scan attack; Compound
   attacks; Synchronization
ID RESILIENT
AB In this paper we propose a content based multibit watermarking method robust to print-scan attack. A method to extract feature points, robust in terms of watermarking, is proposed. The location of the watermark is tied to a coordinate system defined by robust feature points. A message sequence is mapped to a directional angle of periodic patterns, which are scattered and embedded into triangles in permuted locations. In watermark extraction, an interplay between feature extraction and watermarking ensures reliability and a multibit message can be decoded blindly from the locations pointed by the key. By detecting the alignment of the autocorrelations peaks and using a coding table, a multibit message can be extracted. Experiments show that the method provides robust and blind extraction of watermark information after a print-scan attack and a set of compound attacks. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Keskinarkaus, A.; Pramila, A.; Seppanen, T.] Univ Oulu, Dept Comp Sci & Engn, FI-90014 Oulu, Finland.
C3 University of Oulu
RP Keskinarkaus, A (corresponding author), Univ Oulu, Dept Comp Sci & Engn, POB 4500, FI-90014 Oulu, Finland.
EM anja.keskinarkaus@ee.oulu.fi; anu.prami-la@ee.oulu.fi;
   tapio.seppanen@ee.oulu.fi
CR Alghoniemy M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1291, DOI 10.1109/ICME.2000.871003
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Dong P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P489, DOI 10.1109/ICIP.2002.1039014
   Gevrekci M, 2009, COMPUT VIS IMAGE UND, V113, P565, DOI 10.1016/j.cviu.2008.11.006
   Harris C., 1988, ALVEY VISION C, P147151
   Herrigel A, 2001, P SOC PHOTO-OPT INS, V4314, P394, DOI 10.1117/12.435423
   Hu S, 2008, INFORM-J COMPUT INFO, V32, P169
   Keskinarkaus A, 2010, J SYST SOFTWARE, V83, P1715, DOI 10.1016/j.jss.2010.04.073
   Kim BS, 2002, LECT NOTES COMPUT SC, V2613, P202
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   Kutter M., 1998, Proceedings of SPIE, V3628, P423
   Lee HY, 2005, LECT NOTES COMPUT SC, V3710, P418
   Lin C., 1999, INT S MULT INF PROC
   Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lu W, 2010, COMPUT ELECTR ENG, V36, P2, DOI 10.1016/j.compeleceng.2009.04.002
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   O'Ruanaidh J., 1998, Signal Processing, V66, P303, DOI DOI 10.1016/S0165-1684(98)00012-7
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Seo JS, 2004, PATTERN RECOGN, V37, P1365, DOI 10.1016/j.patcog.2003.12.013
   Solanki K, 2006, IEEE T INF FOREN SEC, V1, P464, DOI 10.1109/TIFS.2006.885032
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   Wang XY, 2007, IEEE T INF FOREN SEC, V2, P655, DOI 10.1109/TIFS.2007.908233
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
NR 25
TC 16
Z9 18
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 507
EP 515
DI 10.1016/j.jvcir.2012.01.010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800009
DA 2024-07-18
ER

PT J
AU Chen, DY
   Huang, PC
AF Chen, Duan-Yu
   Huang, Po-Chung
TI Motion-based unusual event detection in human crowds
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human crowd analysis; Unusual event detection; Video surveillance;
   Optical flows; Unsupervised clustering; Force field model; Adjacency
   matrix; Spatial-temporal analysis
AB Analyzing human crowds is an important issue in video surveillance and is a challenging task due to their nature of non-rigid shapes. In this paper, optical flows are first estimated and then used for a clue to cluster human crowds into groups in unsupervised manner using our proposed method of adjacency-matrix based clustering (AMC). While the clusters of human crowds are obtained, their behaviors with attributes, orientation, position and crowd size, are characterized by a model of force field. Finally, we can predict the behaviors of human crowds based on the model and then detect if any anomalies of human crowd(s) present in the scene. Experimental results obtained by using extensive dataset show that our system is effective in detecting anomalous events for uncontrolled environment of surveillance videos. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Chen, Duan-Yu; Huang, Po-Chung] Yuan Ze Univ, Dept Elect Engn, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Chen, DY (corresponding author), Yuan Ze Univ, Dept Elect Engn, Tao Yuan, Taiwan.
EM dychen@saturn.yzu.edu.tw; pochunghun-g26@hotmail.com
CR ANDRADE EL, 2006, P WORKSH ROB VIS SUR, P427
   Andrade EL, 2006, INT C PATT RECOG, P460
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], COMPUTER VISION PATT
   Cheriyadat AM, 2008, IEEE J-STSP, V2, P568, DOI 10.1109/JSTSP.2008.2001306
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hu M, 2008, INT C PATT RECOG, P9
   Ihaddadene N, 2008, INT C PATT RECOG, P217
   JIANG F, 2009, P IEEE ICIP
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   MA YQ, 2009, 2009 IEEE COMP SOC C, P38
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   RYAN D, 2008, P IEEE ICSPCS
   *U MINN, CROWD ACT DAT
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Wu XY, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-3, P214, DOI 10.1109/ROBIO.2006.340379
   Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083
NR 18
TC 64
Z9 67
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 178
EP 186
DI 10.1016/j.jvcir.2010.12.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600007
DA 2024-07-18
ER

PT J
AU Kumwilaisak, W
   Kuo, CCJ
AF Kumwilaisak, Wuttipong
   Kuo, C-C Jay
TI Spatial error concealment with sequence-aligned texture modeling and
   adaptive directional recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatial error concealment; Global pixel alignment; Local pixel
   alignment; Correspondence association; Directional recovery; Geometric
   interpolation; Texture pattern mode; Peak-signal-to-noise ratio
ID PACKET VIDEO; ATM NETWORKS; IMAGE DATA; INTERPOLATION; CODECS
AB A spatial error concealment technique based on the sequence-aligned texture modeling and the adaptive directional recovery is proposed in this work. The sequence alignment technique captures the local variation and the global trend of image textures with surrounding uncorrupted pixels, and provides the best texture model under a given cost function. With the derived texture model, geometric interpolation is used to recover lost pixels adaptively based on pixel locations. There are four candidate modes of pixel sequences to recover lost pixels, and one of them is selected for the concealment purpose. The selection criterion is based on the texture pattern modes of surrounding uncorrupted blocks. The pixel sequences used for error concealment can be obtained from the computation of the decoder or the side information from the encoder. Extensive experimental results are given to demonstrate that our error concealment technique outperforms several benchmark methods in both objective and subjective tests. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Kumwilaisak, Wuttipong] King Mongkuts Univ Technol Thonburi, Commun & Multimedia Lab, Dept Elect & Telecommun, Bangkok 10140, Thailand.
   [Kuo, C-C Jay] Univ So Calif, Signal Proc & Image Proc Inst, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
C3 King Mongkuts University of Technology Thonburi; University of Southern
   California
RP Kumwilaisak, W (corresponding author), King Mongkuts Univ Technol Thonburi, Commun & Multimedia Lab, Dept Elect & Telecommun, Bangkok 10140, Thailand.
EM wuttipong.kum@kmutt.ac.th; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU Ministry of Science and Technology of Thailand [F-31-204-20-03];
   National Research University Fund of Thailand via King Mongkut's
   University of Technology Thonburi
FX This research is supported by the research Grant No. F-31-204-20-03 from
   the Ministry of Science and Technology of Thailand and is partly
   supported by National Research University Fund of Thailand via King
   Mongkut's University of Technology Thonburi. The authors also would like
   to thank Mr. Prateep Nangam for providing some simulation results.
CR Alkachouh Z, 2000, IEEE T IMAGE PROCESS, V9, P729, DOI 10.1109/83.841948
   [Anonymous], 1995, Introduction to computational biology: maps, sequences and genomes
   AYANOGLU E, 1996, ACM BALTZER MOBILE N, V1, P245
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Fadili MJ, 2009, COMPUT J, V52, P64, DOI 10.1093/comjnl/bxm055
   *ITU T, 1995, MULT PROT LOW BITR M
   JUNG KH, 1994, P SOC PHOTO-OPT INS, V2308, P1466, DOI 10.1117/12.185905
   KIEU LH, 1994, IEEE T IMAGE PROCESS, V3, P666, DOI 10.1109/83.334978
   KUMWILAISAK W, 2004, IEEE INT C IM PROC S
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   KWOK W, 1993, IEEE T CONSUM ELECTR, V39, P455, DOI 10.1109/30.234620
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Meisinger K, 2004, IEEE IMAGE PROC, P813
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   OHTA N, 1994, PACKET VIDEO MODELIN
   Park JW, 1997, IEEE T CIRC SYST VID, V7, P845, DOI 10.1109/76.644064
   Park JW, 1999, IEEE T CIRC SYST VID, V9, P1003, DOI 10.1109/76.795052
   Parthasarathy V, 1997, IEEE T CIRC SYST VID, V7, P358, DOI 10.1109/76.564113
   Salama P, 2000, IEEE J SEL AREA COMM, V18, P1129, DOI 10.1109/49.848263
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   SUN H, 1992, IEEE T CONSUM ELECTR, V38, P108, DOI 10.1109/30.156671
   SUN HF, 1995, IEEE T IMAGE PROCESS, V4, P470, DOI 10.1109/83.370675
   SUN J, 1997, IEEE T CONSUM ELECTR, V43, P295
   Sun M.-T., 2001, COMPRESSED VIDEO NET
   WADA M, 1989, IEEE J SEL AREA COMM, V7, P807, DOI 10.1109/49.32344
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wen JT, 1998, IEEE DATA COMPR CONF, P471, DOI 10.1109/DCC.1998.672209
   Wenger S, 1998, IEEE T CIRC SYST VID, V8, P867, DOI 10.1109/76.735382
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yu GS, 1998, IEEE T CIRC SYST VID, V8, P422, DOI 10.1109/76.709409
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 35
TC 8
Z9 12
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 164
EP 177
DI 10.1016/j.jvcir.2010.12.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600006
DA 2024-07-18
ER

PT J
AU Kim, SH
   Ay, SA
   Zimmermann, R
AF Kim, Seon Ho
   Ay, Sakire Arslan
   Zimmermann, Roger
TI Design and implementation of geo-tagged video search framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video search; Geo-tagging; Meta-data; Scalability; Mobile video; Video
   ranking; GPS; Sensor
ID RETRIEVAL
AB User generated video content is experiencing significant growth which is expected to continue and further accelerate. As an example, users are currently uploading 20 h of video per minute to YouTube. Making such video archives effectively searchable is one of the most critical challenges of multimedia management. Current search techniques that utilize signal-level content extraction from video struggle to scale.
   Here we present a framework based on the complementary idea of acquiring sensor streams automatically in conjunction with video content. Of special interest are geographic properties of mobile videos. The meta-data from sensors can be used to model the coverage area of scenes as spatial objects such that videos can effectively, and on a large scale, be organized, indexed and searched based on their field-of-views. We present an overall framework that is augmented with our design and implementation ideas to illustrate the feasibility of this concept of managing geo-tagged video. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Kim, Seon Ho; Ay, Sakire Arslan] Univ So Calif, Los Angeles, CA 90089 USA.
   [Zimmermann, Roger] Natl Univ Singapore, Singapore 117417, Singapore.
C3 University of Southern California; National University of Singapore
RP Kim, SH (corresponding author), Univ So Calif, Los Angeles, CA 90089 USA.
EM seonkim@usc.edu; arslan@usc.edu; rogerz@comp.nus.edu.sg
RI Zimmermann, Roger/D-7944-2015; Ay, Sakire Arslan/AAD-5353-2020
OI Zimmermann, Roger/0000-0002-7410-2590; 
FU Centre of Social Media Innovations for Communities (CoSMIC); Media
   Development Authority (MDA) of Singapore
FX We would like to acknowledge the support of the Centre of Social Media
   Innovations for Communities (CoSMIC), sponsored by the Media Development
   Authority (MDA) of Singapore.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], CISC VIS NETW IND FO
   ARSLAN AS, 2008, ACM INT C MULT, P309
   ARSLAN AS, 2009, ACM INT C MULT, P977
   Ay SA, 2010, MULTIMEDIA SYST, V16, P105, DOI 10.1007/s00530-009-0177-x
   BECKMANN N, 1990, ACM SIGMOD INT C MAN
   BRINKHOFF T, 1994, ACM SIGMOD INT C MAN
   Christel M.G., 2009, SYNTHESIS LECT INFOR, V1, P1
   EPSHTEIN B, 2007, 15 ACM INT S ADV GEO, P1
   Graham C., 1965, Vision and Visual Perception
   HWANG TH, 2003, GEOSC REM SENS S, V6, P3641
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   KIM KH, 2003, GEOSC REM SENS S, V1, P59
   KIM SH, 2010, ACM MULT SYST C, P235
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   LIU XT, 2005, ACM INT C MULT, P618
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Luo J., 2008, ACM International Conference on Multimedia, P1071, DOI DOI 10.1145/1459359.1459574MULTIMEDIA-MM'PLACE
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   ORENSTEIN A, 1986, ACM SIGMOD INT C MAN
   Pavlidis T, 2009, IEEE INT CON MULTI, P1432, DOI 10.1109/ICME.2009.5202771
   PIGEAU A, 2005, ACM INT C MULT
   Simon I., 2008, P ECCV
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Torniai C., 2006, Sharing, Discovering and Browsing Photo Collections through RDF geo-metadata
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Ueda T., 2002, Database and Expert Systems Applications. 13th International Conference, DEXA 2002. Proceedings (Lecture Notes in Computer Science Vol.2453), P768
   WRAY R, 2008, ONLINE VIDEO ADS PUT
   Zhang H., 2009, 2009 ASIA PACIFIC PO, P1
   Zheng YT, 2009, PROC CVPR IEEE, P1085, DOI 10.1109/CVPRW.2009.5206749
NR 32
TC 10
Z9 26
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 773
EP 786
DI 10.1016/j.jvcir.2010.07.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500002
DA 2024-07-18
ER

PT J
AU Tsai, CY
   Hang, HM
AF Tsai, Chia-Yang
   Hang, Hsueh-Ming
TI A rate-distortion analysis on motion prediction efficiency and mode
   decision for scalable wavelet video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interframe wavelet coding; Scalable wavelet video; Motion prediction
   efficiency; Motion information gain; Rate-distortion optimization;
   Prediction mode decision; Video coding bit allocation; Video coding rate
   control
AB A rate-distortion model for describing the motion prediction efficiency in interframe wavelet video coding is proposed in this paper. Different from the non-scalable video coding, the scalable wavelet video coding needs to operate under multiple bitrate conditions and it has an open-loop structure. The conventional Lagrangian multiplier, which is widely used to solve the rate-distortion optimization problems in video coding, does not fit well into the scalable wavelet structure. In order to find the rate-distortion trade-off due to different bits allocated to motion and textual information, we suggest a motion information gain (MIG) metric to measure the motion prediction efficiency. Based on this metric, a new cost function for mode decision is proposed. Compared with the conventional Lagrangian method, our experiments show that the proposed method is less extraction-bitrate dependent and generally improves both the PSNR performance and the visual quality for the scalability cases. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Tsai, Chia-Yang; Hang, Hsueh-Ming] Natl Chiao Tung Univ, Dept Elect Engn, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Hang, HM (corresponding author), Natl Chiao Tung Univ, Dept Elect Engn, Hsinchu, Taiwan.
EM cytsai.ee94g@nctu.edu.tw; hmhang@mail.nctu.e-du.tw
RI Hang, Hsueh-Ming/K-7848-2012
CR [Anonymous], 1449610 ISOIEC
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   BERGER T, 1984, RATE DISTORTION THEO
   Chen MC, 1998, IEEE T CIRC SYST VID, V8, P147, DOI 10.1109/76.664100
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   GIROD B, 1987, IEEE J SEL AREA COMM, V5, P1140, DOI 10.1109/JSAC.1987.1146632
   GIROD B, 1994, P SOC PHOTO-OPT INS, V2308, P1026, DOI 10.1117/12.185863
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   Hsiang ST, 2001, SIGNAL PROCESS-IMAGE, V16, P705, DOI 10.1016/S0923-5965(01)00002-9
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   LEONARDI R, 2006, JTC1SC29WG11 ISOIEC
   OHM JR, 1994, IEEE T IMAGE PROCESS, V3, P559, DOI 10.1109/83.334985
   Peng WH, 2005, LECT NOTES ARTIF INT, V3684, P889
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Rusert T, 2003, PROC SPIE, V5150, P682, DOI 10.1117/12.509881
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Secker A, 2003, IEEE T IMAGE PROCESS, V12, P1530, DOI 10.1109/TIP.2003.819433
   Secker A, 2004, IEEE T IMAGE PROCESS, V13, P1029, DOI 10.1109/TIP.2004.826089
   Shapiro J. M., 1992, P IEEE INT C AC SPEE, P657
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Tsai CY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P601, DOI 10.1109/ICME.2008.4607506
   TSAI CY, 2009, PACK VID WORKSH
   Tsai SS, 2004, SIGNAL PROCESS-IMAGE, V19, P675, DOI 10.1016/j.image.2004.05.008
   Wang MS, 2006, IEEE T SIGNAL PROCES, V54, P3505, DOI 10.1109/TSP.2006.879273
   WIEGAND T, 2003, SYST VIDEO TECHNOL, V13, P688
   WIEGAND T, 2001, P ICIP 2001 THESS GR
   XIONG R, 2005, JTC1SC29WG11 ISOIEC
   XU J, 2004, JTC1SC29WG11 ISOIEC
   Xu JZ, 2001, APPL COMPUT HARMON A, V10, P290, DOI 10.1006/acha.2000.0345
NR 30
TC 6
Z9 7
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 917
EP 929
DI 10.1016/j.jvcir.2010.09.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500015
DA 2024-07-18
ER

PT J
AU Fan, XP
   Au, OC
   Chen, Y
   Zhou, JT
   Ma, MY
   Wong, PHW
AF Fan, Xiaopeng
   Au, Oscar C.
   Chen, Yan
   Zhou, Jiantao
   Ma, Mengyao
   Wong, Peter H. W.
TI Wyner-Ziv-based bidirectionally decodable video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video streaming; Reverse playback; Error resilience; Wyner-Ziv; M-frame
ID SIDE INFORMATION; MPEG VIDEO; BINARY SOURCES; ERROR CONTROL; COMPRESSION
AB In this paper, we propose a novel Wyner-Ziv-based video compression scheme which supports encoding a new type of inter frame called 'M-frame'. Different from traditional multi-hypothesis inter frames, the M-frame is specially compressed with its two neighbor frames as reference at the encoder, but can be identically reconstructed by using any one of them as prediction at the decoder. Based on this, the proposed Wyner-Ziv-based bidirectionally decodable video compression scheme supports decoding the frames in a video stream in both temporal order and reverse order. Unlike the other schemes which support reverse playback, our scheme achieves the reversibility with low extra cost of storage and bandwidth. In error-resilient test, our scheme outperforms H.264 based schemes up to 3.5 dB at same bit rate. The proposed scheme also provides more flexibility for stream switching. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Fan, Xiaopeng; Au, Oscar C.; Zhou, Jiantao; Wong, Peter H. W.] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Hong Kong, Peoples R China.
   [Ma, Mengyao] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
   [Chen, Yan] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
C3 Hong Kong University of Science & Technology; Hong Kong University of
   Science & Technology; University System of Maryland; University of
   Maryland College Park
RP Fan, XP (corresponding author), Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Hong Kong, Peoples R China.
EM eexp@ust.hk; eeau@ust.hk; yan@umd.edu; eejtzhou@ust.hk; myma@ust.hk;
   eepeter@ust.hk
RI Chen, Yan/P-5344-2019; Chen, Yan/P-8901-2017; Chen, Yan/H-5483-2012;
   chen, gang/JRX-1197-2023; Wong, Peter/AAA-3481-2022
OI Chen, Yan/0000-0002-3227-4562; Chen, Yan/0000-0002-3227-4562; Wong,
   Peter/0000-0003-0373-933X
FU Hong Kong Special Administrative Region, China [GHP/048/08]
FX This work has been supported in part by the Innovation and Technology
   Commission of the Hong Kong Special Administrative Region, China
   (project no. GHP/048/08).
CR ARTIGAS X, 2007, COMPLEXITY PERFORMAN
   Chen JH, 2002, IEEE T COMMUN, V50, P406, DOI 10.1109/26.990903
   Chen M.S., 1995, PROC 2 INT IEEE C MU, P73
   CHEUNG NM, 2007, P WORKSH MULT SIGN P
   Fan XP, 2008, IEEE INT SYMP CIRC S, P1404, DOI 10.1109/ISCAS.2008.4541690
   Fang T, 2005, IEEE T MULTIMEDIA, V7, P1131, DOI 10.1109/TMM.2005.858399
   Fu CH, 2006, IEEE T CIRC SYST VID, V16, P19, DOI 10.1109/TCSVT.2005.856901
   Fu CH, 2007, IEEE T IMAGE PROCESS, V16, P2169, DOI 10.1109/TIP.2007.902330
   Garcia-Frias J, 2001, IEEE COMMUN LETT, V5, P417, DOI 10.1109/4234.957380
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   Guo M, 2008, IEEE T CIRC SYST VID, V18, P569, DOI 10.1109/TCSVT.2008.918845
   Guo X, 2008, IEEE T CIRC SYST VID, V18, P713, DOI 10.1109/TCSVT.2008.920970
   HUANG SY, 2003, P IEEE INT C AC SPEE, V5, pV760
   Ip TP, 2005, IEEE INT SYMP CIRC S, P2671
   IP TP, 2006, P IEEE INT C AC SPEE, V2
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   Khansari M, 1996, IEEE T CIRC SYST VID, V6, P1, DOI 10.1109/76.486415
   Lin CW, 2001, IEEE T CIRC SYST VID, V11, P415, DOI 10.1109/76.911165
   Liveris AD, 2002, IEEE COMMUN LETT, V6, P379, DOI 10.1109/LCOMM.2002.803479
   Liveris AD, 2002, IEEE COMMUN LETT, V6, P440, DOI 10.1109/LCOMM.2002.804244
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Pradhan SS, 1999, IEEE DATA COMPR CONF, P158, DOI 10.1109/DCC.1999.755665
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P1181, DOI 10.1109/TIT.2003.810622
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Sehgal A, 2004, IEEE T MULTIMEDIA, V6, P249, DOI 10.1109/TMM.2003.822995
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Tan WT, 2001, IEEE T CIRC SYST VID, V11, P373, DOI 10.1109/76.911162
   Tan YP, 2002, IEEE IMAGE PROC, P713
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wang Y, 2005, P IEEE, V93, P57, DOI 10.1109/JPROC.2004.839618
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WEE S, 1998, P IEEE INT C IM PROC, V2, P209
   WEE SJ, 1998, P SPIE C MULT SYST A, P237
   WENGER S, 1999, 16 ITUT SG
   Wiegand T, 1999, IEEE T CIRC SYST VID, V9, P70, DOI 10.1109/76.744276
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Xu Q, 2006, IEEE T IMAGE PROCESS, V15, P3791, DOI 10.1109/TIP.2006.884925
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   ZHU C, 2006, P IEEE INT C IM PROC
NR 42
TC 2
Z9 3
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 365
EP 376
DI 10.1016/j.jvcir.2009.03.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900001
DA 2024-07-18
ER

PT J
AU Lee, S
   Chung, K
AF Lee, Sunhun
   Chung, Kwangsue
TI Combining the rate adaptation and quality adaptation schemes for
   wireless video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rate adaptation; Quality adaptation; Cross-layer design; Wireless video
   streaming
AB Video streaming service over wireless networks is a challenging task because of the changes in the wire less channel conditions that can occur due to interference, fading, and station mobility. Moreover, the IEEE 802.11 WLAN standard does not contain any specifications for the rate adaptation scheme which are useful for improving the wireless link utilization. To provide efficient wireless video streaming service, the rate adaptation scheme should be applied at the low layer and the quality adaptation scheme should be considered at the high layer. To meet this requirement of wireless video streaming. we propose a new cross-layer design for video streaming over wireless networks. This design includes the rate adaptation scheme in the data link and physical layers and the quality adaptation scheme in the application layer. The rate adaptation scheme adjusts the data transmission rate based on the measured RSSI at the sender-side and informs the quality adaptation scheme about the rate limits. Then the quality adaptation scheme utilizes this rate limits to adjust the quality of the video stream. Through performance evaluations, we prove that our cross-layer design improves the wireless link utilization and the quality of the video stream simultaneously. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Lee, Sunhun; Chung, Kwangsue] Kwangwoon Univ, Sch Elect Engn, Seoul 139701, South Korea.
C3 Kwangwoon University
RP Lee, S (corresponding author), Kwangwoon Univ, Sch Elect Engn, Chamvitkwan 809,447-1 Wo1gye Dong, Seoul 139701, South Korea.
EM sunlee@adams.kw.ac.kr; kchung@kw.ac.kr
FU Ministry of Knowledge Economy (MKE); Korea Industrial Technology
   Foundation (KOTEF); Kwangwoon University in 2008
FX This research was financially supported by the Ministry of Knowledge
   Economy (MKE) and Korea Industrial Technology Foundation (KOTEF) through
   the Human Resource Training Project for Strategic Technology. This
   research also has been conducted by the Research Grant of Kwangwoon
   University in 2008.
CR [Anonymous], 1999, 80211 IEEE WG 11
   [Anonymous], 2016, IEEE Standard 802.11-2020
   Bansal D, 2001, IEEE INFOCOM SER, P631, DOI 10.1109/INFCOM.2001.916251
   Bardwell J., 2002, Converting signal strength percentage to dBm values
   FEAMSTER N, 2001, PV WORKSH
   FLOYD S, 2000, EQUATION BASED CONGE, P43
   Haratcherev I, 2005, WIREL COMMUN MOB COM, V5, P421, DOI 10.1002/wcm.301
   Holland G., 2001, P 7 ANN INT C MOBILE, P236, DOI DOI 10.1145/381677.381700
   HOLLIDAY T, 2002, IEEE INT C COMM, V2, P831
   Kamerman A, 1997, BELL LABS TECH J, V2, P118, DOI 10.1002/bltj.2069
   Kim J., 2006, IEEE INFOCOM
   Kim T, 2003, IEEE INFOCOM SER, P641
   LEE J, 1998, ITC CSCC, V1, P245
   LEE S, 2007, INT C INF NETW
   Lee S, 2006, LECT NOTES COMPUT SC, V3961, P660
   Pang QX, 2005, 2ND INTERNATIONAL CONFERENCE ON BROADBAND NETWORKS (BROADNETS 2005), P709
   PAVON JD, 2003, IEEE INT C COMM ICC, V2, P1108
   Rejaie R, 2000, IEEE J SEL AREA COMM, V18, P2530, DOI 10.1109/49.898735
   Shakkottai S, 2002, 5TH INTERNATIONAL SYMPOSIUM ON WIRELESS PERSONAL MULTIMEDIA COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P12, DOI 10.1109/WPMC.2002.1088125
   Wong SHY, 2006, MOBICOM 2006, P146
NR 20
TC 7
Z9 9
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 508
EP 519
DI 10.1016/j.jvcir.2008.08.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300005
DA 2024-07-18
ER

PT J
AU Ma, MY
   Au, OC
   Guo, LW
   Chan, SHG
   Fan, XP
   Hou, L
AF Ma, Mengyao
   Au, Oscar C.
   Guo, Liwei
   Chan, S. -H. Gary
   Fan, Xiaopeng
   Hou, Ling
TI Alternate motion-compensated prediction for error resilient video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error resilience; Error concealment; Two-hypothesis motion-compensated
   prediction; Alternate motion-compensated prediction; Error ratio; Error
   energy; Temporal interpolation
ID CONCEALMENT
AB Since the quality of compressed video is vulnerable to errors, video transmission over unreliable Internet is very challenging today. Two-Hypothesis Motion-Compensated Prediction (THMCP) has been shown to have Error Resilience (ER) capability for video transmission, where each macroblock is predicted from its previous two frames. In this paper, we propose a novel ER approach named Alternate Motion-Compensated Prediction (AMCP). In addition to two-hypothesis prediction, one-hypothesis prediction is alternately used. We use some schemes to determine which kind of prediction should be used, so that in some cases of loss, the propagated error can be first decreased to some extent before it spreads to the subsequent frames. As a result, the expected converged error is less than that obtained from THMCP with fixed weights (THMCPF). Both analysis and simulation results are given to show that AMCP performs better than THMCPF, in terms of both compression efficiency and ER capability. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Ma, Mengyao; Chan, S. -H. Gary] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.
   [Au, Oscar C.; Guo, Liwei; Fan, Xiaopeng; Hou, Ling] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology; Hong Kong University of
   Science & Technology
RP Ma, MY (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.
EM myma@ust.hk; eeau@ust.hk; eeglw@ust.hk; gchan@ust.hk; eexp@ust.hk;
   eileenzb@ust.hk
OI Chan, Gary Shueng Han/0000-0003-4207-764X
FU Innovation and Technology Commission of the Hong Kong Special
   Administrative Region, China [GHP/033/05]
FX This work has been supported in part by the Innovation and Technology
   Commission (project no. GHP/033/05) of the Hong Kong Special
   Administrative Region, China.
CR Akyol E, 2007, IEEE J-STSP, V1, P231, DOI 10.1109/JSTSP.2007.901527
   [Anonymous], JVT REFERENCE SOFTWA
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Aravind R, 1996, IEEE T CIRC SYST VID, V6, P426, DOI 10.1109/76.538925
   Baccichet Pierpaolo, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P93
   Côté G, 2000, IEEE J SEL AREA COMM, V18, P952, DOI 10.1109/49.848249
   Farber N., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P550, DOI 10.1109/ICIP.1999.822956
   Flierl M, 2003, IEEE T CIRC SYST VID, V13, P587, DOI 10.1109/TCSVT.2003.814963
   Flierl M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P150, DOI 10.1109/ICIP.2000.899317
   Fu CM, 2005, INT CONF ACOUST SPEE, P305
   GHANDI M, 2006, P IEEE INT C AC SPEE, P529
   Girod B, 2000, IEEE T IMAGE PROCESS, V9, P173, DOI 10.1109/83.821595
   Girod B., 2000, COMPRESSED VIDEO NET
   Guo Y, 2006, IEEE IMAGE PROC, P2225, DOI 10.1109/ICIP.2006.313012
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P146, DOI 10.1109/TCSVT.2005.857817
   Kung WY, 2004, IEEE IMAGE PROC, P821
   Lee YC, 2005, IEEE T CIRC SYST VID, V15, P457, DOI 10.1109/TCSVT.2005.844446
   Lin SA, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P545, DOI 10.1109/ICIP.2002.1039028
   MA M, 2005, P IEEE ICIP SEP, P773
   Setton E, 2008, P IEEE, V96, P25, DOI 10.1109/JPROC.2007.909925
   Stockhammer T., 2002, P INT PACK VID WORKS
   Stoufs M., 2007, Proc. IEEE Int. Conf. Image Process, V6, P517
   Tang CW, 1997, ISCAS '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I - IV, P1444, DOI 10.1109/ISCAS.1997.622187
   Tsai Y. - C., 2005, P IEEE INT C MULT EX, P952
   Verdicchio F, 2006, IEEE T IMAGE PROCESS, V15, P3114, DOI 10.1109/TIP.2006.877495
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   WANG YK, 2005, ITU T SG 16
   WENGER S, 1999, ITU T SG 16
   WONG CK, 1995, P SOC PHOTO-OPT INS, V2501, P1108, DOI 10.1117/12.206643
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 32
TC 1
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2008
VL 19
IS 7
BP 437
EP 449
DI 10.1016/j.jvcir.2008.07.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 363NU
UT WOS:000260274800003
DA 2024-07-18
ER

PT J
AU Castrillón, M
   Déniz, O
   Guerra, C
   Hernández, M
AF Castrillon, M.
   Deniz, O.
   Guerra, C.
   Hernandez, M.
TI ENCARA2:: Real-time detection of multiple faces at different resolutions
   in video streams
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE face detection; real-time; human-computer interaction
ID TRACKING
AB This paper describes a face detection system which goes beyond traditional face detection approaches normally designed for still images. The system described in this paper has been designed taking into account the temporal coherence contained in a video stream in order to build a robust detector. Multiple and real-time detection is achieved by means of cue combination. The resulting system builds a feature based model for each detected face, and searches them using the various model information in the next frame. The experiments have been focused on video streams, where our system can actually exploit the benefits of the temporal coherence integration. The results achieved for video stream processing outperform Rowley-Kanade's and Viola-Jones' solutions providing eye and face data in real-time with a notable correct detection rate, approx. 99.9% faces and 87.5% eye pairs on 26338 images. (C) 2006 Elsevier Inc. All rights reserved.
C1 Univ Las Palmas Gran Canaria, IUSIANI, Las Palmas Gran Canaria 35017, Spain.
C3 Universidad de Las Palmas de Gran Canaria
RP Castrillón, M (corresponding author), Univ Las Palmas Gran Canaria, IUSIANI, Las Palmas Gran Canaria 35017, Spain.
EM mcastrillon@iusiani.ulpgc.es
RI Castrillón-Santana, Modesto/C-6662-2008; Deniz, Oscar/AAA-3245-2020
OI Castrillón-Santana, Modesto/0000-0002-8673-2725; Deniz,
   Oscar/0000-0002-0841-4131
CR [Anonymous], 9811 CRL
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], DAGM 25 PATT REC S
   ARTAL CG, 2002, THESIS U LAS PALMAS
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Feyrer S., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P864, DOI 10.1109/IROS.1999.812788
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   KIRBY Y, IEEE T PATT AN MACH, V12
   KIRCHBERG KJ, 2002, GENETIC MODEL OPTIMI, V2359, P103
   Kruppa H., 2003, Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS), P157
   LI SZ, 2002, EUR C COMP VIS, P67
   LISETTI CL, 2000, MULTIDISCIPLINARY PE, V8, P185
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SANTANA MC, 2003, INT C IM PROC BARC
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   SOBOTTKA K, NOVEL METHOD AUTOMAT, V12
   STORRING M, PHYS BAS MOD HUM SKI
   SUNG KK, IEEE T PATT AN MACH, V20
   Turk M, 2004, COMMUN ACM, V47, P61, DOI 10.1145/962081.962107
   VAPNIK V, 2001, NATURE STAT LEARNING, V2091, P65
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   VIOLA P, 2004, J COMPUTER VISION, V57, P151
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
NR 27
TC 124
Z9 139
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 130
EP 140
DI 10.1016/j.jvcir.2006.11.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mrázek, P
   Weickert, J
AF Mrazek, Pavel
   Weickert, Joachim
TI From two-dimensional nonlinear diffusion to coupled Haar wavelet
   shrinkage
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE nonlinear diffusion; wavelet shrinkage; rotation invariance; colour;
   vector- and tensor-valued data
ID TRANSLATION-INVARIANT; SPACE; RECONSTRUCTION; TRANSFORM
AB This paper studies the connections between discrete two-dimensional schemes for shift-invariant Haar wavelet shrinkage on one hand, and nonlinear diffusion on the other. We show that using a single iteration on a single scale, the two methods can be made equivalent by the choice of the nonlinearity which controls each method: the shrinkage function, or the diffusivity function, respectively. In the two-dimensional setting, this diffusion-wavelet connection shows an important novelty compared to the one-dimensional framework or compared to classical 2-D wavelet shrinkage: The structure of two-dimensional diffusion filters suggests to use a coupled, synchronised shrinkage of the individual wavelet coefficient channels. This coupling enables to design Haar wavelet filters with good rotation invariance at a low computational cost. Furthermore, by transferring the channel coupling of vector- and matrix-valued nonlinear diffusion filters to the Haar wavelet setting, we obtain well-synchronised shrinkage methods for colour and tensor images. Our experiments show that these filters perform significantly better than conventional shrinkage methods that process all wavelets independently. (C) 2007 Elsevier Inc. All rights reserved.
C1 UPEK, Prague 13000 3, Czech Republic.
   Univ Saarland, Fac Math & Comp Sci, Math Image Anal Grp, D-66123 Saarbrucken, Germany.
C3 Saarland University
RP Mrázek, P (corresponding author), UPEK, Husinecka 7, Prague 13000 3, Czech Republic.
EM pavel.mrazek@upek.com; weickert@mia.uni-saarland.de
CR ALDROUBI A, 1999, CONT MATH, V247, P1
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   BAO Y, 2001, WAVELETS SIGNAL IMAG, V19, pCH6
   Candès EJ, 2002, SIGNAL PROCESS, V82, P1519, DOI 10.1016/S0165-1684(02)00300-6
   Chambolle A, 2001, IEEE T IMAGE PROCESS, V10, P993, DOI 10.1109/83.931093
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   Chan TF, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICIP.2000.899404
   Cohen A, 1999, AM J MATH, V121, P587
   Cohen A, 2003, REV MAT IBEROAM, V19, P235
   Coifman RR, 2000, APPL COMPUT HARMON A, V9, P1, DOI 10.1006/acha.2000.0299
   Coifman RR, 2001, SIAM J NUMER ANAL, V39, P480, DOI 10.1137/S0036142999362031
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Durand S, 2003, SIAM J SCI COMPUT, V24, P1754, DOI 10.1137/S1064827501397792
   Fletcher AK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P873
   Frangakis AS, 2001, IEEE T BIO-MED ENG, V48, P213, DOI 10.1109/10.909642
   Gao HY, 1997, STAT SINICA, V7, P855
   Gao HY, 1998, J COMPUT GRAPH STAT, V7, P469
   Holschneider M, 1990, Wavelets, P286, DOI DOI 10.1007/978-3-642-75988-828
   Keeling SL, 2002, INVERSE PROBL, V18, P175, DOI 10.1088/0266-5611/18/1/312
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   KRIVA Z., 2000, P ALGORITMY 2000 C S, P174
   Malgouyres F, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P57, DOI 10.1109/VLSM.2001.938882
   MALGOUYRES F, 2002, INVERSE PROBL, V2, P1
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Meyer Y., 2001, OSCILLATING PATTERNS, V22
   Mrázek P, 2005, INT J COMPUT VISION, V64, P171, DOI 10.1007/s11263-005-1842-y
   Mrázek P, 2003, LECT NOTES COMPUT SC, V2781, P156
   Mrázek P, 2003, LECT NOTES COMPUT SC, V2695, P101
   MRAZEK P, 2003, P 8 COMP VIS WINT WO, P61
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pierpaoli C, 1996, RADIOLOGY, V201, P637, DOI 10.1148/radiology.201.3.8939209
   Shen J, 2003, J COMPUT ANAL APPL, V5, P147, DOI 10.1023/A:1021486307819
   Shen JH, 2000, J DIFFER EQUATIONS, V161, P403, DOI 10.1006/jdeq.1999.3707
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Steidl G, 2004, SIAM J NUMER ANAL, V42, P686, DOI 10.1137/S0036142903422429
   Strang G., 1996, Wavelets and Filter Banks
   Tschumperlé D, 2001, PROC CVPR IEEE, P948
   Weickert J, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P3
   Weickert J, 1999, IMAGE VISION COMPUT, V17, P201, DOI 10.1016/S0262-8856(98)00102-4
   Welk M, 2006, LECT NOTES COMPUT SC, V3951, P391
   Whitaker Ross., 1994, Guido Gerig Vector-Valued Diffusion, Geometry-Driven Diffusion in Computer Vision, V1, P93
   Yu TPY, 1996, P SOC PHOTO-OPT INS, V2825, P608, DOI 10.1117/12.255272
NR 46
TC 16
Z9 19
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 162
EP 175
DI 10.1016/j.jvcir.2007.01.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700007
DA 2024-07-18
ER

PT J
AU Abadpour, A
   Kasaei, S
AF Abadpour, Arash
   Kasaei, Shohreh
TI An efficient PCA-based color transfer method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE color image processing; colorizing; color transfer; principle component
   analysis
ID COLORIZATION ALGORITHM; IMAGE; SEGMENTATION
AB Color information of natural images can be considered as a highly correlated vector space. Many different color spaces have been proposed in the literature with different motivations toward modeling and analysis of this stochastic field. Recently, color transfer among different images has been under investigation. Color transferring consists of two major categories: colorizing grayscale images and recoloring colored images. The literature contains a few color transfer methods that rely on some standard color spaces. In this paper, taking advantages of the principal component analysis (PCA), we propose a unifying framework for both mentioned problems. The experimental results show the efficiency of the proposed method. The performance comparison of the proposed method is also given. (c) 2006 Elsevier Inc. All rights reserved.
C1 Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   Sharif Univ Technol, Dept Math Sci, Tehran, Iran.
C3 Sharif University of Technology; Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM abadpour@math.sharif.edu; skasaei@sharif.edu
RI Kasaei, Shohreh/AAD-5618-2019
OI Kasaei, Shohreh/0000-0002-3831-0878
CR ABADPOUR, 2004, IPM WORKSH COMP VIS
   ABADPOUR A, 2004, 9 ANN CSI COMP C CSI, P125
   ABADPOUR A, 2004, 2 IEEE C ADV TECHN G
   ABADPOUR A, 2004, P 12 IR C EL ENG ICE
   ABADPOUR A, 2004, 4 IEEE INT S SIGN PR
   [Anonymous], ACM T GRAPHICS
   Benson K.B., 1992, Television engineering handbook
   Berlin Brent, 1969, Basic Color Terms: Their Universality and Evolution
   BRUCE J, 2000, P IROS 2000 JAP
   Chaira T, 2003, PATTERN RECOGN LETT, V24, P1943, DOI 10.1016/S0167-8655(03)00033-3
   CHANG Y, 2003, P COMP GRAPH INT CGI
   Chen Tongbo., 2004, P ASIAN C COMPUTER V, P1164
   Cheng HD, 2003, PATTERN RECOGN, V36, P1545, DOI 10.1016/S0031-3203(02)00293-5
   Cheng SC, 2003, J VIS COMMUN IMAGE R, V14, P184, DOI 10.1016/S1047-3203(03)00024-5
   FOLEY J, 1982, SYSTEM PROGRAMMING S
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   GREENFIELD GR, 2003, J WSCG 03, V11, P3
   Horiuchi T, 2004, IMAGE VISION COMPUT, V22, P197, DOI 10.1016/j.imavis.2003.08.004
   Horiuchi T, 2003, IEEE IMAGE PROC, P457
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   JAYARAM S, 2004, 2004 IEEE COMP SOC C
   KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441
   KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279
   Lucchese L, 2001, IEE P-VIS IMAGE SIGN, V148, P141, DOI 10.1049/ip-vis:20010229
   Nikolaev DP, 2004, COMPUT VIS IMAGE UND, V94, P115, DOI 10.1016/j.cviu.2003.10.012
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Papamarkos N, 2000, IMAGE VISION COMPUT, V18, P213, DOI 10.1016/S0262-8856(99)00015-3
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Shin MC, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P275, DOI 10.1109/ACV.2002.1182194
   Slater J., 1991, MODERN TELEVISION SY
   SYKORA D, 2004, NPAR 04
   SYKORA D, 2003, THESIS CZECH REPUBLI
   TENENBAUM J, 1974, 87 STANF RES I AI CT
   Tschumperle D, 2002, THESIS U NICE SOPHIA
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vieira LFM, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P151, DOI 10.1109/SIBGRA.2003.1241003
   WELSH T, 2002, P 29 ANN C COMP GRAP, P277, DOI DOI 10.1145/566570.566576
   YAN WQ, 2003, P IEEE INT C MULT EX
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YIN L, 2003, P 6 IEEE INT C AUT F
NR 41
TC 40
Z9 45
U1 3
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 15
EP 34
DI 10.1016/j.jvcir.2006.08.001
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, J
   Shao, HR
   Sun, MT
AF Zhou, Jian
   Shao, Huai-Rong
   Sun, Ming-Ting
TI FGS enhancement layer truncation with reduced intra-frame quality
   variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE fine granularity scalability; enhancement-layer truncation;
   rate-distortion optimization; intra-frame quality variation
ID CONSTRAINED RATE ALLOCATION; VIDEO COMPRESSION
AB This paper presents a rate-distortion optimized MPEG-4 FGS enhancement-layer truncation scheme. Our objective is to minimize the quality variation within each frame when the last transmitted enhancement layer is truncated according to the available network bandwidth. By properly redistributing the bit-budget to the enhancement layer that will be truncated, we can raise the quality of the whole frame uniformly. To achieve this goal, we use a trellis-search approach to decide which "1" bits will be truncated from the enhancement layer for each block. An operational rate-distortion optimization scheme based on the Lagrange Multiplier algorithm is adopted to decide the truncation criteria. Our proposed method can improve the visual quality and reduce the intra-frame quality variation both subjectively and objectively. Compared to previously reported straightforward truncation methods, our approach reduces the intra-frame quality variation significantly, and the decoded visual quality in terms of PSNR is also improved. (C) 2005 Elsevier Inc. All rights reserved.
C1 Motorola Inc, San Diego, CA 92121 USA.
   Samsung Informat Syst Amer, San Jose, CA 95134 USA.
   Univ Washington, Dept Elect Engn, Seattle, WA 98040 USA.
C3 Samsung; University of Washington; University of Washington Seattle
RP Sun, MT (corresponding author), Univ Washington, M418 EE-CSE,Box 352500, Seattle, WA 98195 USA.
EM sun@ee.washington.edu
CR CHENG H, 2003, IEEE INT C MULT EXP
   CHEONG WS, 2001, JTC1SC29WG11 ISOIEC
   *ISO IEC, 2002, 1449622001AMD22002 I
   Li W, 1998, JTC1SC29WG11 ISOIEC
   LIM C, 2000, JTC1SC29WG11 ISOIEC
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Ramchandran K, 1993, IEEE T IMAGE PROCESS, V2, P160, DOI 10.1109/83.217221
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   van der Schaar M, 2001, IEEE T CIRC SYST VID, V11, P318, DOI 10.1109/76.911158
   Wang Q, 2002, IEEE SIGNAL PROC LET, V9, P33, DOI 10.1109/97.991132
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang XM, 2003, IEEE T CIRC SYST VID, V13, P121, DOI 10.1109/TCSVT.2002.808437
   Zhang XM, 2002, P SOC PHOTO-OPT INS, V4671, P817, DOI 10.1117/12.453125
   Zhao L, 2002, PROC SPIE, V4671, P242, DOI 10.1117/12.453063
   ZHAO L, 2002, P SPIE, V4671
   ZHAO L, 2000, NEW CONTENT BASED SH
   ZHOU J, 2003, IEEE INT C MULT EXP
NR 18
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 830
EP 841
DI 10.1016/j.jvcir.2005.06.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500009
DA 2024-07-18
ER

PT J
AU Pan, F
   Lin, ZP
   Lin, X
   Rahardja, S
   Juwono, W
   Slamet, F
AF Pan, F.
   Lin, Z. P.
   Lin, X.
   Rahardja, S.
   Juwono, W.
   Slamet, F.
TI Adaptive frame skipping based on spatio-temporal complexity for low
   bit-rate video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID MPEG-4 RATE CONTROL
AB Conventional rate control schemes focus on the adjustment of quantization values to retain a certain buffer level, and buffer adaptive frame skippings are used to avoid buffer overflow at low bit-rates. In this paper, an adaptive frame-skipping scheme is proposed to achieve the balance between spatial and temporal quality, and to maintain the buffer level. The occurrence of frame skipping is jointly dependent on the temporal and spatial complexity of the video, and on the fullness of the buffer. This helps to achieve a balanced spatial and temporal quality and to enhance the overall perceptual quality. Experimental results show that the new scheme is simple but very effective, with large average PSNR gains and consistently improved visual quality, and the improvement in perceptual quality is much significant than that in average PSNRs. (C) 2005 Elsevier Inc. All rights reserved.
C1 Inst Infocomm Res, Singapore 119613, Singapore.
   Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 637722, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Nanyang Technological University
RP Pan, F (corresponding author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM efpan@i2r.a-star.edu.sg
RI Lin, Zhiping/A-5153-2011; Lin, Zhiping/AAF-2719-2020
OI Lin, Zhiping/0000-0002-1587-1226
CR HANG HM, 1997, IEEE T CIRCUITS SYST, V7, P299
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   LEE JW, 1994, IEEE T IMAGE PROCESS, V3, P513, DOI 10.1109/83.334989
   Pan F, 2003, IEEE T CIRC SYST VID, V13, P440, DOI 10.1109/TCSVT.2003.811603
   Reed EC, 2001, IEEE T CIRC SYST VID, V11, P882, DOI 10.1109/76.931115
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Song HJ, 2001, IEEE T CIRC SYST VID, V11, P512, DOI 10.1109/76.915357
   Vetro A, 1999, IEEE T CIRC SYST VID, V9, P186, DOI 10.1109/76.744285
   *VID GROUP, 2001, ISOIECJTC1SC29WG11 V
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
NR 10
TC 2
Z9 3
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 554
EP 563
DI 10.1016/j.jvcir.2005.07.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300002
DA 2024-07-18
ER

PT J
AU Banerji, AK
   Panchapakesan, K
   Swaminathan, K
AF Banerji, Ashish K.
   Panchapakesan, Kannan
   Swaminathan, Kumar
TI Stitching of H.264 video streams for continuous presence multipoint
   videoconferencing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE videoconferencing; continuous presence multipoint; video stitching;
   video combining; H.264; H.263; compressed-domain; pixel-domain;
   drift-free; intra prediction; inter prediction
ID LOW-COMPLEXITY
AB This paper proposes a video stitching method applicable to continuous presence multipoint videoconferencing. The proposed approach is universally applicable yet computationally simpler than a pixel-domain approach which is computationally expensive due to the need for full re-encoding. A compressed-domain approach is far simpler but its applicability is limited to H.261. The proposed method employs a blend of compressed-domain and pixel-domain tools to eliminate the drift that results when a compressed-domain approach is attempted for H.263 and H.264. Coding parameters from incoming streams are reused on the outgoing side, thereby avoiding the computational bottleneck of re-estimating them. Essential details for implementing the proposed method are presented for H.264, along with simulation results for validating it. Application of the drift-free stitching method to H.263 is provided as an Appendix A. (c) 2005 Elsevier Inc. All rights reserved.
C1 Hughes Network Syst, Germantown, MD 20876 USA.
RP Swaminathan, K (corresponding author), Hughes Network Syst, 11717 Explorat Lane, Germantown, MD 20876 USA.
EM kswami@hns.com
CR CHEN TC, 1994, P SPIE VIS COMM IM P, P850
   Fung KT, 2004, IEEE T MULTIMEDIA, V6, P31, DOI 10.1109/TMM.2003.819761
   *JOINT VID TEAM, JM REF SOFTW VERS 8
   LEI SM, 1994, IEEE T CIRCUITS SYST, V4, P148
   Shiu DJ, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P77, DOI 10.1109/MMCS.1999.778143
   Sun MT, 1997, IEEE T CIRC SYST VID, V7, P855, DOI 10.1109/76.644065
   Zhu QF, 1999, IEEE T CIRC SYST VID, V9, P666, DOI 10.1109/76.767130
NR 7
TC 4
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 490
EP 508
DI 10.1016/j.jvcir.2005.05.007
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000016
DA 2024-07-18
ER

PT J
AU Luo, JB
   Chen, CW
AF Luo, JB
   Chen, CW
TI Modeling of subband coefficients for clustering-based adaptive
   quantization with spatial constraints
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE wavelet transform; adaptive quantization; Laplacian distribution; Gibbs
   random fields
ID IMAGE; DISTRIBUTIONS; COMPRESSION; VIDEO
AB Discrete wavelet transform provides an advantageous framework of multiresolution space-frequency representation with promising applications in image processing. An efficient modeling of the spatial and frequency characteristics of the wavelet transform coefficients has been recognized as a key to designing efficient quantization for wavelet-based image coding. We have proposed a Bayesian estimation framework to provide a unified, simultaneous modeling of both the spatial distribution and the intensity distribution of the wavelet transform coefficients [IEEE Trans. Circuit Syst. Video Technol. 7 (1997) 343], where the spatially localized characteristics of a given subband are modeled by Gibbs random fields (GRF). In this study, we investigate the modeling of individual cluster intensity distribution of the subband coefficients, within the context of a joint scene and signal modeling. This joint modeling decomposes the overall distribution of the coefficients into the superposition of individual cluster distributions. Among Gaussian, Laplacian, and generalized Gaussian, distributions, we conclude that the composite of multiple generalized Gaussian distributions is most consistent with the overall distribution of the coefficients for any given high frequency subband. Meanwhile, modeling by Laplacian distributions has its advantage in terms of low computational complexity. The joint modeling enables us to devise a novel scene adaptive and signal adaptive quantization that fully exploits the coding redundancies resulting from wavelet transform. The concept and the mechanism of the proposed Bayesian estimation framework are applicable and tunable to other wavelet-based image processing tasks. (C) 2003 Elsevier Science (USA). All rights reserved.
C1 Eastman Kodak Co, Div Imaging Sci, Rochester, NY 14650 USA.
   Univ Missouri, Dept Elect Engn, Columbia, MO 65211 USA.
C3 Eastman Kodak; University of Missouri System; University of Missouri
   Columbia
RP Florida Inst Technol, Dept Elect & Comp Engn, 150 W Univ Blvd, Melbourne, FL 32901 USA.
EM cchen@fit.edu
RI Luo, Jiebo/AAI-7549-2020
OI Luo, Jiebo/0000-0002-4516-9729
CR ANTONINI M, 1990, P INT C AC SPEECH SI, V7, P2297
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   BIRNEY KA, 1995, IEEE T IMAGE PROCESS, V4, P186, DOI 10.1109/83.342184
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   FARVARDIN N, 1987, IEEE T INFORM THEORY, V33, P827, DOI 10.1109/TIT.1987.1057373
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   LUO J, 1995, INT C IM PROC 95 WAS, P583
   Luo JB, 1997, IEEE T CIRC SYST VID, V7, P343, DOI 10.1109/76.564112
   LUO JB, 1994, P SOC PHOTO-OPT INS, V2308, P1289, DOI 10.1117/12.185954
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Netravali A.N., 1988, DIGITAL PICTURES REP
   Raffy P, 1997, P SOC PHOTO-OPT INS, V3024, P1067, DOI 10.1117/12.263186
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   WESTERINK PH, 1988, IEEE T COMMUN, V36, P713, DOI 10.1109/26.2791
   Xiong ZX, 1997, IEEE T IMAGE PROCESS, V6, P677, DOI 10.1109/83.568925
NR 15
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2003
VL 14
IS 3
BP 205
EP 216
DI 10.1016/S1047-3203(03)00038-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 713ZE
UT WOS:000184887200001
DA 2024-07-18
ER

PT J
AU Wang, R
   Yang, GZ
   Yan, XH
   Luo, SY
   Han, Q
AF Wang, Rui
   Yang, Guozheng
   Yan, Xuehu
   Luo, Shengyang
   Han, Qiang
TI Secret image sharing in the encrypted domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Image encrypted domain; Formal definition;
   Evaluation metrics
ID SCHEME
AB Nowadays, digital images have a greatly widespread and profound influence on human life, and its security protection problem is increasingly prominent. Image encryption is one of the most effective solutions for image protection but may result in secret concentration or single point of failure. Secret image sharing (SIS) with loss tolerance provides a feasible method to protect secret images in a distributed way. However, existing SIS schemes are most utilized in natural images, and the application of SIS to encrypted images which are widely used in practical scenarios is rarely discussed. Thus, this paper proposes a novel concept of SIS in the encrypted domain (SIS-ED) for the first time on the basis of synthesizing the merits of SIS and image encryption. SIS-ED integrating the encryption and SIS means applying general or user-defined encryption algorithms to encrypt the secret image in the plaintext domain, and in the encrypted domain using appropriate SIS schemes on the encrypted image to share secrets. SIS-ED can prevent secret images from being reconstructed illegally and enhance security against malicious attacks such as differential attacks, which can be widely applied in practical scenarios with high-security requirements such as authentication, blockchain, and cloud systems. In addition, we present a concrete SIS-ED scheme to instantiate the SIS-ED model. The proposed SIS-ED scheme with high security can realize lossless recovery without pixel expansion, and reduced-size shares. Theoretical analysis, experiments, and comparisons are conducted to show the effectiveness and advantages of SIS-ED.
C1 [Wang, Rui; Yang, Guozheng; Yan, Xuehu; Luo, Shengyang; Han, Qiang] Natl Univ Def Technol, Hefei 230037, Peoples R China.
   Anhui Prov Key Lab Cyberspace Secur Situat Awarene, Hefei 230037, Peoples R China.
C3 National University of Defense Technology - China
RP Yan, XH (corresponding author), Natl Univ Def Technol, Hefei 230037, Peoples R China.
EM yangguozheng17@nudt.edu.cn; yanxh17@nudt.edu.cn
FU Program of the National Natural Science Foundation of China [62271496]
FX This work is funded by the Program of the National Natural Science
   Foundation of China (Number: 62271496) .
CR Bensikaddour EH, 2020, J KING SAUD UNIV-COM, V32, P50, DOI 10.1016/j.jksuci.2018.05.002
   Bhowmik S, 2023, J INF SECUR APPL, V72, DOI 10.1016/j.jisa.2022.103391
   Bishoy K. S., 2022, 2022 27 INT C AUTOMA, P1
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Boussif M, 2020, IET IMAGE PROCESS, V14, P1209, DOI 10.1049/iet-ipr.2019.0042
   Chen TH, 2021, MULTIMED TOOLS APPL, V80, P1901, DOI 10.1007/s11042-020-09484-3
   Ghebleh M, 2018, MULTIMED TOOLS APPL, V77, P11903, DOI 10.1007/s11042-017-4841-4
   Hu WT, 2021, MULTIMED TOOLS APPL, V80, P28731, DOI 10.1007/s11042-021-11104-7
   Li L, 2012, SIGNAL PROCESS, V92, P1069, DOI 10.1016/j.sigpro.2011.10.020
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu XB, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-020-02952-7
   Luo SY, 2023, SIGNAL PROCESS, V206, DOI 10.1016/j.sigpro.2023.108931
   Ping P, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501929
   Roy S, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102919
   Sahoo SK, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107924
   Sangavi V, 2023, J INF SECUR APPL, V72, DOI 10.1016/j.jisa.2022.103408
   Sha YW, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422501863
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sharobim Bishoy K., 2022, 2022 International Conference on Microelectronics (ICM), P254, DOI 10.1109/ICM56065.2022.10005395
   Tang JN, 2023, IET IMAGE PROCESS, V17, P518, DOI 10.1049/ipr2.12651
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wu H.-L., 2015, J. Inf. Hiding Multim. Signal Process., V6, P288
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XT, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107768
   Xing FY, 2022, J VIS COMMUN IMAGE R, V86, DOI 10.1016/j.jvcir.2022.103520
   Xiong LZ, 2021, IEEE T INF FOREN SEC, V16, P2912, DOI 10.1109/TIFS.2021.3065794
   Yan XH, 2023, FRONT INFORM TECH EL, V24, P88, DOI 10.1631/FITEE.2200118
   Yan XH, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3419750
   Yan XH, 2020, IET IMAGE PROCESS, V14, P530, DOI 10.1049/iet-ipr.2018.5648
   Yan XH, 2019, J INF SECUR APPL, V47, P208, DOI 10.1016/j.jisa.2019.05.008
   Zhou X, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070249
NR 31
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104013
DI 10.1016/j.jvcir.2023.104013
EA DEC 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EP1U3
UT WOS:001140045000001
DA 2024-07-18
ER

PT J
AU Arshad, MS
   Beksi, WJ
AF Arshad, Mohammad Samiul
   Beksi, William J.
TI IPVNet: Learning implicit point-voxel features for open-surface 3D
   reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D reconstruction; Open surfaces; Implicit functions
AB Reconstruction of 3D open surfaces (e.g., non-watertight meshes) is an underexplored area of computer vision. Recent learning-based implicit techniques have removed previous barriers by enabling reconstruction in arbitrary resolutions. Yet, such approaches often rely on distinguishing between the inside and outside of a surface in order to extract a zero level set when reconstructing the target. In the case of open surfaces, this distinction often leads to artifacts such as the artificial closing of surface gaps. However, real-world data may contain intricate details defined by salient surface gaps. Implicit functions that regress an unsigned distance field have shown promise in reconstructing such open surfaces. Nonetheless, current unsigned implicit methods rely on a discretized representation of the raw data. This not only bounds the learning process to the representation's resolution, but it also introduces outliers in the reconstruction. To enable accurate reconstruction of open surfaces without introducing outliers, we propose a learning-based implicit point-voxel model (IPVNet). IPVNet predicts the unsigned distance between a surface and a query point in 3D space by leveraging both raw point cloud data and its discretized voxel counterpart. Experiments on synthetic and real-world public datasets demonstrates that IPVNet outperforms the state of the art while producing far fewer outliers in the resulting reconstruction.
C1 [Arshad, Mohammad Samiul; Beksi, William J.] Univ Texas Arlington, 701 S Nedderman Dr, Arlington, TX 76019 USA.
C3 University of Texas System; University of Texas Arlington
RP Beksi, WJ (corresponding author), Univ Texas Arlington, 701 S Nedderman Dr, Arlington, TX 76019 USA.
EM william.beksi@uta.edu
OI Beksi, William/0000-0001-5377-2627
CR Arshad MS, 2020, INT CONF 3D VISION, P712, DOI 10.1109/3DV50981.2020.00081
   Atzmon M, 2020, Arxiv, DOI arXiv:2006.05400
   Atzmon M, 2020, PROC CVPR IEEE, P2562, DOI 10.1109/CVPR42600.2020.00264
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Bhatnagar Bharat Lal, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P311, DOI 10.1007/978-3-030-58536-5_19
   Bhatnagar BL, 2019, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2019.00552
   Chen WK, 2022, PROC CVPR IEEE, P18501, DOI 10.1109/CVPR52688.2022.01797
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Cheng Chun You, 2020, 2020 IEEE Conference on Open Systems (ICOS), P37, DOI 10.1109/ICOS50156.2020.9293685
   Cherenkova K, 2020, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP40778.2020.9191095
   Chibane J, 2020, Arxiv, DOI arXiv:2010.13938
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Cui ZH, 2020, 2020 17TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2020), P125, DOI 10.1109/CRV50864.2020.00025
   Duggal S, 2021, Arxiv, DOI arXiv:2101.06860
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   github, 2023, ipvnet
   Gropp A, 2020, Arxiv, DOI [arXiv:2002.10099, 10.48550/arXiv.2002.10099, DOI 10.48550/ARXIV.2002.10099]
   Huang JH, 2021, PROC CVPR IEEE, P8928, DOI 10.1109/CVPR46437.2021.00882
   Huang WL, 2019, AAAI CONF ARTIF INTE, P8481
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Kim Jaeyeon, 2023, 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), P592, DOI 10.1109/WACV56688.2023.00066
   Kingma D. P., 2014, arXiv
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Li Y, 2019, IEEE ACCESS, V7, P46522, DOI 10.1109/ACCESS.2019.2908983
   Li YJ, 2022, IEEE T INTELL TRANSP, V23, P9311, DOI 10.1109/TITS.2021.3071790
   Littwin G, 2019, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2019.00191
   Liu SL, 2021, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR46437.2021.00183
   Liu Z., 2019, arXiv
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Mi ZX, 2020, PROC CVPR IEEE, P967, DOI 10.1109/CVPR42600.2020.00105
   Michalkiewicz M, 2019, Arxiv, DOI arXiv:1901.06802
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Noh J, 2021, PROC CVPR IEEE, P14600, DOI 10.1109/CVPR46437.2021.01437
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Peng Songyou, 2020, Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part III 16, P523
   Pepe M, 2022, DATA BRIEF, V42, DOI 10.1016/j.dib.2022.108250
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2022, Arxiv, DOI arXiv:2102.00463
   Sitzmann V., 2020, ADV NEURAL INF PROCE, V33, P7462
   Sitzmann V, 2020, Arxiv, DOI arXiv:2006.09662
   Son H., 2021, P BRIT MACHINE VISIO, P1
   Tang Haotian, 2020, EUR C COMP VIS, P685, DOI DOI 10.1007/978-3-030-58604-1_41
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tretschk Edgar, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P293, DOI 10.1007/978-3-030-58517-4_18
   Venkatesh R, 2021, P IEEE INT C COMP VI, P12653
   Wei Y, 2021, PROC CVPR IEEE, P6950, DOI 10.1109/CVPR46437.2021.00688
   Wolter F.-E., 1993, Design Laboratory Memorandum 92-2
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xia F, 2018, PROC CVPR IEEE, P9068, DOI 10.1109/CVPR.2018.00945
   Xie JW, 2018, PROC CVPR IEEE, P8629, DOI 10.1109/CVPR.2018.00900
   Xu JY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16004, DOI 10.1109/ICCV48922.2021.01572
   Ye JL, 2022, PROC CVPR IEEE, P12819, DOI 10.1109/CVPR52688.2022.01249
   Zhang C., 2021, arXiv
   Zhao F, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12654, DOI 10.1109/ICCV48922.2021.01244
   Zhao WB, 2021, PROC CVPR IEEE, P10251, DOI 10.1109/CVPR46437.2021.01012
NR 57
TC 0
Z9 0
U1 7
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103970
DI 10.1016/j.jvcir.2023.103970
EA NOV 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z2CM1
UT WOS:001110209700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, GW
   He, ZY
   Huang, JT
   Luo, T
   Xu, HY
   Jin, CC
AF Jiang, Guowei
   He, Zhouyan
   Huang, Jiangtao
   Luo, Ting
   Xu, Haiyong
   Jin, Chongchong
TI RDD-net: Robust duplicated-diffusion watermarking based on deep network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Watermarking; Deep network; Robustness; RGB channels; Channel connection
ID IMAGE WATERMARKING; CLASSIFICATION; OPTIMIZATION; SVM; ALGORITHM
AB This paper proposes a novel robust duplicated-diffusion watermarking model based on deep network (RDD-net). RDD-net employs the encoder-noise-decoder structure for end-to-end training to obtain high image watermarking invisibility and robustness. Firstly, a duplicated-diffusion strategy is employed in the encoder to replicate the original watermark iteratively until all copies are diffused to the whole image so that the generalized ability in resisting various noises is obtained. Then, a channel connection technique is designed to extract inherent image features for fusing watermark for robustness by mining correlations of RGB three channels of the color image. Meanwhile, each channel is fused with watermark to increase robustness. Another attempt to improve the watermarking performance is the optimizer, which optimizes the watermark distribution by evaluating the similarities between the encoded image and the original image, as well as between the encoded image and the noised image. Our extensive experimental results demonstrate that the proposed RDD-net not only resists different noises, but also obtains better image quality and higher robustness than the existing watermarking models.
C1 [Jiang, Guowei; He, Zhouyan; Huang, Jiangtao; Luo, Ting; Jin, Chongchong] Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Peoples R China.
   [Jiang, Guowei; Huang, Jiangtao; Luo, Ting; Xu, Haiyong; Jin, Chongchong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
C3 Ningbo University; Ningbo University
RP He, ZY (corresponding author), Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Peoples R China.
EM hezhouyan@nbu.edu.cn
RI Huang, Jiangtao/GQR-1976-2022; zhouyan, he/GXM-4974-2022
FU Natural Science Foundation of China [61971247, 62171243]; Zhejiang
   Provincial Natural Science Foundation of China [LY22F020020,
   LQ23F010011]; Zhejiang Provincial Postdoctoral Research Excellence
   Fundation [ZJ2022130]; K. C. Wong Magna Fund in Ningbo University
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61971247 and 62171243, Zhejiang Provincial Natural Science
   Foundation of China under Grant No. LY22F020020 and LQ23F010011,
   Zhejiang Provincial Postdoctoral Research Excellence Fundation under
   Grant No. ZJ2022130. It was also sponsored by the K. C. Wong Magna Fund
   in Ningbo University.
CR Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Zhang KA, 2019, Arxiv, DOI arXiv:1901.03892
   Dhanalakshmi P, 2009, EXPERT SYST APPL, V36, P6069, DOI 10.1016/j.eswa.2008.06.126
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Fernandez P, 2022, INT CONF ACOUST SPEE, P3054, DOI 10.1109/ICASSP43922.2022.9746058
   Findik O, 2010, OPT COMMUN, V283, P4916, DOI 10.1016/j.optcom.2010.07.020
   Goodfellow I., 2014, arXiv, DOI 10.48550/arXiv.1406.2661
   Haribabu K., 2015, 2015 IEEE WORKSH COM, P1
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jia J, 2022, IEEE T CYBERNETICS, V52, P7094, DOI 10.1109/TCYB.2020.3037208
   Kahlessenane F, 2021, J AMB INTEL HUM COMP, V12, P2931, DOI 10.1007/s12652-020-02450-9
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu QL, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110066
   Lu J., 2022, 2022 IEEE INT C MULT, P1
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Mun SM, 2017, Arxiv, DOI arXiv:1704.03248
   Namba R, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P228, DOI 10.1145/3321705.3329808
   Pexaras K, 2019, IEEE T CIRCUITS-I, V66, P2088, DOI 10.1109/TCSI.2019.2907191
   Poonam, 2018, Procedia Computer Science, V132, P1441, DOI 10.1016/j.procs.2018.05.076
   Qiao T, 2023, COMPUT SECUR, V127, DOI 10.1016/j.cose.2023.103102
   Rai A, 2017, MULTIMED TOOLS APPL, V76, P18605, DOI 10.1007/s11042-016-4215-3
   Su GD, 2020, IEEE ACCESS, V8, P160840, DOI 10.1109/ACCESS.2020.3019832
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   Vaishnavi D, 2015, PROCEDIA COMPUT SCI, V46, P1770, DOI 10.1016/j.procs.2015.02.130
   Wang CP, 2023, J VIS COMMUN IMAGE R, V95, DOI 10.1016/j.jvcir.2023.103875
   Wang XY, 2009, EXPERT SYST APPL, V36, P9056, DOI 10.1016/j.eswa.2008.12.040
   Wu LL, 2019, IEEE SIGNAL PROC LET, V26, P642, DOI 10.1109/LSP.2019.2901641
   Xiyang Luo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13545, DOI 10.1109/CVPR42600.2020.01356
   Yang X, 2023, SIGNAL PROCESS, V203, DOI 10.1016/j.sigpro.2022.108791
   Zhang LN, 2019, MULTIMED TOOLS APPL, V78, P28003, DOI 10.1007/s11042-019-07902-9
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang ZM, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P1517
   Zheng Y, 2022, IEEE T INF FOREN SEC, V17, P2977, DOI 10.1109/TIFS.2022.3198267
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
   Zong TR, 2016, IEEE ACCESS, V4, P1689, DOI 10.1109/ACCESS.2016.2556723
NR 39
TC 0
Z9 0
U1 3
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103934
DI 10.1016/j.jvcir.2023.103934
EA SEP 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T2LV6
UT WOS:001076358000001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Yang, F
   Ginhac, D
AF Liu, Yu
   Yang, Fan
   Ginhac, Dominique
TI Accumulated micro-motion representations for lightweight online action
   detection in real-time
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion representation; Spatiotemporal action localization; Online action
   detection; Real-time computing; Embedded system
ID NETWORK
AB In the last decade, the explosive growth of vision sensors and video content has driven numerous application demands for automating human action detection in space and time. Aside from reliable precision, vast real -world scenarios also mandate continuous and instantaneous processing of actions under limited computational budgets. However, existing studies often rely on heavy operations such as 3D convolution and fine-grained optical flow, therefore are hindered in practical deployment. Aiming strictly at a better mixture of detection accuracy, speed, and complexity for online detection, we customize a cost-effective 2D-CNN-based tubelet detection framework coined Accumulated Micro-Motion Action detector (AMMA). It sparsely extracts and fuses visual-dynamic cues of actions spanning a longer temporal window. To lift reliance on expensive optical flow estimation, AMMA efficiently encodes actions' short-term dynamics as accumulated micro-motion from RGB frames on-the-fly. On top of AMMA's motion-aware 2D backbone, we adopt an anchor-free detector to cooperatively model action instances as moving points in the time span. The proposed action detector achieves highly competitive accuracy as state-of-the-arts while substantially reducing model size, computational cost, and processing time (6 million parameters, 1 GMACs, and 100 FPS respectively), making it much more appealing under stringent speed and computational constraints. Codes are available on https://github.com/ alphadadajuju/AMMA.
C1 [Liu, Yu; Yang, Fan; Ginhac, Dominique] Univ Burgundy, ImVIA REA7535, F-21078 Dijon, France.
C3 Universite de Bourgogne
RP Liu, Y (corresponding author), Univ Burgundy, ImVIA REA7535, F-21078 Dijon, France.
EM yu_liu@etu.u-bourgogne.fr; fanyang@u-bourgogne.fr;
   dominique.ginhac@ubfc.fr
FU H2020 ITN project ACHIEVE (H2020-MSCA-ITN-2017) [765866]
FX & nbsp;This work was supported by the H2020 ITN project ACHIEVE
   (H2020-MSCA-ITN-2017: agreement no. 765866) .
CR Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Dai JF, 2016, ADV NEUR IN, V29
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Hu XJ, 2022, NEUROCOMPUTING, V491, P395, DOI 10.1016/j.neucom.2022.03.069
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472
   Köpüklü O, 2021, Arxiv, DOI arXiv:1911.06644
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2022, IEEE ACCESS, V10, P37870, DOI 10.1109/ACCESS.2022.3164730
   Liu ZL, 2020, AAAI CONF ARTIF INTE, V34, P11685
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Orsic M, 2019, PROC CVPR IEEE, P12599, DOI 10.1109/CVPR.2019.01289
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Qiu ZF, 2019, PROC CVPR IEEE, P12048, DOI 10.1109/CVPR.2019.01233
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saha S, 2020, Arxiv, DOI arXiv:2004.01494
   Saha S, 2016, Arxiv, DOI arXiv:1608.01529
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sevilla-Lara Laura, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P281, DOI 10.1007/978-3-030-12939-2_20
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Song L, 2019, PROC CVPR IEEE, P11979, DOI 10.1109/CVPR.2019.01226
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Su R, 2019, PROC CVPR IEEE, P12008, DOI 10.1109/CVPR.2019.01229
   Sun C, 2018, LECT NOTES COMPUT SC, V11215, P335, DOI 10.1007/978-3-030-01252-6_20
   Suneetha M, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103161
   Tian Z, 2022, IEEE T PATTERN ANAL, V44, P1922, DOI 10.1109/TPAMI.2020.3032166
   Vaswani A, 2017, ADV NEUR IN, V30
   Xie YF, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103195
   Yang JY, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103263
   Yang XT, 2019, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2019.00035
   Yixuan Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P68, DOI 10.1007/978-3-030-58517-4_5
   Yuxi Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P510, DOI 10.1007/978-3-030-58517-4_30
   Zhang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P500, DOI 10.1145/3343031.3350876
   Zhang DJ, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107312
   Zhao JJ, 2022, Arxiv, DOI arXiv:2104.00969
   Zhao JJ, 2019, PROC CVPR IEEE, P9927, DOI 10.1109/CVPR.2019.01017
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 45
TC 1
Z9 1
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103879
DI 10.1016/j.jvcir.2023.103879
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N7IN5
UT WOS:001038705100001
OA Green Published
DA 2024-07-18
ER

PT J
AU Cai, WX
   Du, SL
   Yang, WK
AF Cai, Wenxiao
   Du, Songlin
   Yang, Wankou
TI UAV image stitching by estimating orthograph with RGB cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Natural image stitching; Image alignment; Orthographic projection;
   Parallax tolerant; Unified perspective
ID FEATURES
AB In the field of image stitching, cases with large camera optical center movement and large parallax have been the virgin territory of research. The goal of image stitching is to overcome the parallax and stitch a natural image. We look into this problem in the context of ultra-low altitude flight of a UAV. We model the 3D world in this scenario and quickly estimate orthographic projection by pairs of homography matrices. Our stitching method can achieve precise alignment since it takes parallax well into consideration. The stitching results are natural and the extra time consumed is short.
C1 [Cai, Wenxiao; Du, Songlin; Yang, Wankou] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Du, SL; Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM wkyang@seu.edu.cn
RI Cai, Wenxiao/JSL-0496-2023
OI Cai, Wenxiao/0009-0000-0522-9654; Yang, Wankou/0000-0002-6385-6776
FU National Natural Science Founda-tion of China [62276061]
FX Acknowledgment This work was supported by the National Natural Science
   Founda-tion of China under Nos. 62276061.
CR Adobe Systems Incorporated, AD LIGHTR
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Chang CH, 2014, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2014.422
   Chen J, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14051068
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Y, 2018, LECT NOTES COMPUT SC, V11256, P347, DOI 10.1007/978-3-030-03398-9_30
   Chen YS, 2016, LECT NOTES COMPUT SC, V9909, P186, DOI 10.1007/978-3-319-46454-1_12
   Cui JG, 2021, IEEE J-STARS, V14, P270, DOI 10.1109/JSTARS.2020.3032011
   Djerida A, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103258
   Du P, 2022, PROC CVPR IEEE, P3678, DOI 10.1109/CVPR52688.2022.00367
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao J., 2013, Eurographics (Short Papers), P45, DOI DOI 10.2312/CONF/EG2013/SHORT/045-048
   Gao JH, 2011, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2011.5995433
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Jing Y., 2022, EUROPEAN C COMPUTER
   Jing YC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5281, DOI 10.1109/ICCV48922.2021.00525
   Jing YC, 2021, PROC CVPR IEEE, P7768, DOI 10.1109/CVPR46437.2021.00768
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Kirillov A, 2023, Arxiv, DOI arXiv:2304.02643
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin KM, 2016, LECT NOTES COMPUT SC, V9907, P370, DOI 10.1007/978-3-319-46487-9_23
   Liu S., 2022, arXiv
   Liu S., 2022, EUROPEAN C COMPUTER
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nie L, 2021, IEEE T IMAGE PROCESS, V30, P6184, DOI 10.1109/TIP.2021.3092828
   Nie L, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102950
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wenxiao C., VDD VARIED DRONE DAT
   Williams C.K.I., PASCAL VISUAL OBJECT
   Xu Q, 2021, IEEE J-STARS, V14, P4465, DOI 10.1109/JSTARS.2021.3061505
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Yang XY, 2022, Arxiv, DOI arXiv:2210.17409
   Zaragoza J, 2013, PROC CVPR IEEE, P2339, DOI 10.1109/CVPR.2013.303
   Zhang F, 2015, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2015.7298811
   Zuliani M, 2005, IEEE IMAGE PROC, P2969
NR 35
TC 3
Z9 3
U1 5
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103835
DI 10.1016/j.jvcir.2023.103835
EA MAY 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H7OQ8
UT WOS:000997816900001
DA 2024-07-18
ER

PT J
AU Hu, XB
   Zhu, SN
   Peng, TL
AF Hu, Xiaobin
   Zhu, Shining
   Peng, Taile
TI Hierarchical attention vision transformer for fine-grained visual
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained visual classification; Vision transformer; Hierarchical
   attention selection; Attention -guided data augmentation
AB Recently, vision transformer has gained a breakthrough in image recognition. Its self-attention mechanism (MSA) can extract discriminative tokens information from different patches to improve image classification accuracy. However, the classification token in its deep layer ignore the local features between layers. In addition, the patch embedding layer feeds fixed-size patches into the network, which inevitably introduces additional image noise. Therefore, we propose a hierarchical attention vision transformer (HAVT) based on the transformer framework. We present a data augmentation method for attention cropping to crop and drop image noise and force the network to learn key features. Second, the hierarchical attention selection (HAS) module is proposed, which improves the network's ability to learn discriminative tokens between layers by filtering and fusing tokens be-tween layers. Experimental results show that the proposed HAVT outperforms state-of-the-art approaches and significantly improves the accuracy to 91.8% and 91.0% on CUB-200-2011 and Stanford Dogs, respectively. We have released our source code on GitHub https://github.com/OhJackHu/HAVT.git.
C1 [Hu, Xiaobin; Zhu, Shining; Peng, Taile] Huaibei Normal Univ, Coll Comp Sci & Technol, Huaibei, Peoples R China.
C3 Huaibei Normal University
RP Peng, TL (corresponding author), Huaibei Normal Univ, Coll Comp Sci & Technol, Huaibei, Peoples R China.
EM 17862008285@163.com; 1365347172@qq.com; 11908110443@chnu.edu.cn
CR Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Dai ZH, 2019, Arxiv, DOI [arXiv:1901.02860, DOI 10.48550/ARXIV.1901.02860]
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ding Y, 2019, IEEE I CONF COMP VIS, P6598, DOI 10.1109/ICCV.2019.00670
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Dubey A., 2018, ADV NEUR IN, V31
   El-Nouby A, 2021, Arxiv, DOI [arXiv:2102.05644, DOI 10.48550/ARXIV.2102.05644]
   Gao Y, 2020, AAAI CONF ARTIF INTE, V34, P10818
   Ge W., 2019, CVPR, P3034
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   He J, 2021, Arxiv, DOI arXiv:2103.07976
   He XT, 2017, AAAI CONF ARTIF INTE, P4075
   Hu T, 2019, Arxiv, DOI [arXiv:1901.09891, DOI 10.48550/ARXIV.1901.09891]
   Hu YQ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4239, DOI 10.1145/3474085.3475561
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Khosla A., 2011, CVPR
   Liu CB, 2020, AAAI CONF ARTIF INTE, V34, P11555
   Liu X., 2021, ARXIV PREPRINT ARXIV
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luo W, 2019, IEEE I CONF COMP VIS, P8241, DOI 10.1109/ICCV.2019.00833
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Ruoyi Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P153, DOI 10.1007/978-3-030-58565-5_10
   Ruyi Ji, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10465, DOI 10.1109/CVPR42600.2020.01048
   Song JW, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534004
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wah Catherine, 2011, Technical report
   Wang J, 2022, Arxiv, DOI arXiv:2107.02341
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wei X, 2018, LECT NOTES COMPUT SC, V11207, P365, DOI 10.1007/978-3-030-01219-9_22
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Yang S., 2021, arXiv
   Yang Z, 2018, LECT NOTES COMPUT SC, V11218, P438, DOI 10.1007/978-3-030-01264-9_26
   Yang ZL, 2019, ADV NEUR IN, V32
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zheng WZ, 2021, PROC CVPR IEEE, P9316, DOI 10.1109/CVPR46437.2021.00920
   Zheng WZ, 2021, IEEE T PATTERN ANAL, V43, P3214, DOI 10.1109/TPAMI.2020.2980231
   Zhuang PQ, 2020, AAAI CONF ARTIF INTE, V34, P13130
NR 40
TC 3
Z9 3
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103755
DI 10.1016/j.jvcir.2023.103755
EA JAN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C6ZX5
UT WOS:000963386800001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Huang, BQ
   Yue, GH
   Wu, JK
   Wang, XX
   Zheng, Z
AF Liu, Yun
   Huang, Baoqing
   Yue, Guanghui
   Wu, Jingkai
   Wang, Xiaoxu
   Zheng, Zhi
TI Two-stream interactive network based on local and global information for
   No-Reference Stereoscopic Image Quality Assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic image quality evaluation; Binocular fusion; Asymmetric
   convolution kernel; CNN; Summation and difference channels
ID PREDICTION; SALIENCY
AB Nowadays, stereoscopic image quality assessment (SIQA) based on convolutional neural network (CNN) has become the mainstream model of image quality assessment (IQA). Compared with the two-dimensional quality evaluation model, stereoscopic image quality evaluation is more challenging due to the effects of depth and parallax information. In this paper, we propose a two-stream interactive network model to perform quality evaluation, which can well simulate the process of human stereo visual perception. Meanwhile, we enhance the extraction of local and global features of images by asymmetric convolution kernel and interactive subnetworks of inter-layers, respectively, which can further optimize our network model. Our proposed algorithm was evaluated on four public databases. The final experimental results show that our proposed algorithm exhibits good performance not only on the whole database but also on each single distortion type.
C1 [Liu, Yun; Huang, Baoqing; Wang, Xiaoxu] Liaoning Univ, Coll Informat, Shenyang 110036, Liaoning, Peoples R China.
   [Yue, Guanghui] Shenzhen Univ, Sch Biomed Engn, Shenzhen 518060, Peoples R China.
   [Wu, Jingkai] Chinese Acad Sci, Shenyang Inst Comp Technol, Shenyang 110168, Liaoning, Peoples R China.
   [Zheng, Zhi] Beijing Jiaotong Univ, Dept Elect & Informat Engn, Beijing 100044, Peoples R China.
   [Liu, Yun] Univ Calif Berkeley, Visual Spatial Perceived Lab, Berkeley, CA 94720 USA.
C3 Liaoning University; Shenzhen University; Chinese Academy of Sciences;
   Beijing Jiaotong University; University of California System; University
   of California Berkeley
RP Liu, Y (corresponding author), Liaoning Univ, Coll Informat, Shenyang 110036, Liaoning, Peoples R China.; Yue, GH (corresponding author), Shenzhen Univ, Sch Biomed Engn, Shenzhen 518060, Peoples R China.; Wu, JK (corresponding author), Chinese Acad Sci, Shenyang Inst Comp Technol, Shenyang 110168, Liaoning, Peoples R China.
EM yunliu@tju.edu.cn; yueguanghui@szu.edu.cn; wujk@chinatowercom.cn
RI li, xiaomin/KCX-9845-2024
OI Huang, Baoqing/0000-0003-2750-0753; Liu, Yun/0000-0003-4115-1617
FU National Natural Science Foundation of China [61901205, 62001302];
   Guangdong Basic and Applied Basic Research Foundation [2019A1515111205];
   Open Project Program of State Key Laboratory of Virtual Reality
   Technology and Systems, Beihang University, China [VRLAB2021C05]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61901205 and 62001302, and Guangdong Basic and Applied
   Basic Research Foundation under Grant 2019A1515111205, and Open Project
   Program of State Key Laboratory of Virtual Reality Technology and
   Systems, Beihang University, China (No. VRLAB2021C05). The authors would
   like to thank Prof. A. C. Bovik for providing the LIVE 3D IQA Databases
   and Prof. Jiheng Wang for providing the IVC 3D IQA Database.
CR [Anonymous], 2010, P INT WORKSH VID PRO
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bhandari U, 2019, INFORM MANAGE-AMSTER, V56, P85, DOI 10.1016/j.im.2018.07.003
   Chen L, 2019, SIGNAL PROCESS-IMAGE, V76, P1, DOI 10.1016/j.image.2019.03.011
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Chen PF, 2021, IEEE T IMAGE PROCESS, V30, P3279, DOI 10.1109/TIP.2021.3060255
   Chen Y, 2020, IEEE ACCESS, V8, P85760, DOI 10.1109/ACCESS.2020.2992746
   De Silva HR, 1930, B J PSYCHOL-GEN SECT, V20, P241
   Ding Y, 2018, APPL OPTICS, V57, P2610, DOI 10.1364/AO.57.002610
   Ding Y, 2019, J VIS COMMUN IMAGE R, V61, P1, DOI 10.1016/j.jvcir.2019.03.019
   Geng XQ, 2017, SIGNAL PROCESS-IMAGE, V52, P54, DOI 10.1016/j.image.2016.12.004
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Hachicha W, 2017, SIGNAL PROCESS-IMAGE, V54, P107, DOI 10.1016/j.image.2017.03.005
   Ji WP, 2019, J VIS COMMUN IMAGE R, V58, P195, DOI 10.1016/j.jvcir.2018.11.038
   Jiang QP, 2018, PATTERN RECOGN, V76, P242, DOI 10.1016/j.patcog.2017.11.001
   Jiang QP, 2015, SIGNAL PROCESS-IMAGE, V38, P57, DOI 10.1016/j.image.2015.04.007
   Jung YJ, 2016, IEEE T CIRC SYST VID, V26, P1201, DOI 10.1109/TCSVT.2015.2430632
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Khan S, 2018, IEEE T IMAGE PROCESS, V27, P5892, DOI 10.1109/TIP.2018.2860279
   Li F., 2021, IEEE T CIRCUITS SYST
   Li LD, 2021, IEEE T MULTIMEDIA, V23, P2757, DOI 10.1109/TMM.2020.3016124
   Li SM, 2020, IEEE I C VI COM I PR, P318, DOI 10.1109/vcip49819.2020.9301854
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu LX, 2017, SIGNAL PROCESS-IMAGE, V58, P287, DOI 10.1016/j.image.2017.08.011
   Liu Y, 2020, NEUROCOMPUTING, V405, P126, DOI 10.1016/j.neucom.2020.04.049
   Lv YQ, 2016, SIGNAL PROCESS-IMAGE, V47, P346, DOI 10.1016/j.image.2016.07.003
   Ma L, 2016, NEUROCOMPUTING, V215, P21, DOI 10.1016/j.neucom.2015.06.116
   Messai O, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115772
   Messai O, 2018, 2018 INTERNATIONAL CONFERENCE ON SIGNAL, IMAGE, VISION AND THEIR APPLICATIONS (SIVA)
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Niu YZ, 2019, IEEE ACCESS, V7, P101583, DOI 10.1109/ACCESS.2019.2930707
   Park H, 2014, IEEE T MULTIMEDIA, V16, P326, DOI 10.1109/TMM.2013.2286567
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Shao F, 2018, IEEE T CIRC SYST VID, V28, P573, DOI 10.1109/TCSVT.2016.2628082
   Shen LL, 2021, NEUROCOMPUTING, V424, P132, DOI 10.1016/j.neucom.2020.10.024
   Shi YQ, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107168
   Su CC, 2015, IEEE T IMAGE PROCESS, V24, P1685, DOI 10.1109/TIP.2015.2409558
   Tang C, 2022, IEEE T KNOWL DATA EN, V34, P4705, DOI 10.1109/TKDE.2020.3048678
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tang C, 2020, IEEE T KNOWL DATA EN, V32, P1747, DOI 10.1109/TKDE.2019.2911946
   Tang C, 2019, IEEE T MULTIMEDIA, V21, P1724, DOI 10.1109/TMM.2018.2889560
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang K., 2016, 2016 VIS COMM IM PRO, P1
   Wang K, 2020, PATTERN RECOGN LETT, V140, P135, DOI 10.1016/j.patrec.2020.09.016
   Wang X, 2018, SIGNAL PROCESS, V145, P202, DOI 10.1016/j.sigpro.2017.12.002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan JL, 2019, IEEE ACCESS, V7, P173657, DOI 10.1109/ACCESS.2019.2902659
   Yang JC, 2019, PATTERN RECOGN LETT, V127, P48, DOI 10.1016/j.patrec.2018.10.012
   Yang JC, 2019, IEEE T MULTIMEDIA, V21, P1750, DOI 10.1109/TMM.2018.2889562
   Yang JC, 2018, INFORM SCIENCES, V430, P1, DOI 10.1016/j.ins.2017.10.053
   Yang XH, 2020, NEUROCOMPUTING, V401, P209, DOI 10.1016/j.neucom.2020.03.072
   Yao Y, 2018, SIGNAL PROCESS-IMAGE, V65, P128, DOI 10.1016/j.image.2018.02.014
   Yue GH, 2018, SIGNAL PROCESS, V150, P204, DOI 10.1016/j.sigpro.2018.04.019
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhou W, 2019, IEEE T IMAGE PROCESS, V28, P3946, DOI 10.1109/TIP.2019.2902831
   Zhou WJ, 2021, SIGNAL PROCESS-IMAGE, V91, DOI 10.1016/j.image.2020.116095
   Zhou WJ, 2020, IEEE T COMPUT IMAG, V6, P883, DOI 10.1109/TCI.2020.2993640
   Zhou WJ, 2017, IEEE T BROADCAST, V63, P404, DOI 10.1109/TBC.2016.2638620
   Zhu HC, 2022, IEEE T CYBERNETICS, V52, P1798, DOI 10.1109/TCYB.2020.2984670
   Zhu HC, 2022, IEEE T CIRC SYST VID, V32, P1048, DOI 10.1109/TCSVT.2021.3073410
NR 61
TC 1
Z9 1
U1 7
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103586
DI 10.1016/j.jvcir.2022.103586
EA AUG 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4U2UR
UT WOS:000858655700002
DA 2024-07-18
ER

PT J
AU Wang, ZF
   Jiang, AW
   Zhang, CJ
   Li, HX
   Liu, B
AF Wang, Zhifeng
   Jiang, Aiwen
   Zhang, Chunjie
   Li, Hanxi
   Liu, Bo
TI Self-supervised multi-scale pyramid fusion networks for realistic bokeh
   effect rendering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bokehrendering; Circleofconfusion; Self-supervised; Multi-scalefusion;
   Structureconsistency
AB Images with visual pleasing bokeh effect are often unattainable for mobile cameras with compact optics and tiny sensors. To balance the aesthetic requirements on photo quality and expensive high-end SLR cameras, syn-thetic bokeh effect rendering has emerged as an attractive machine learning topic for engineering applications on imaging systems. However, most of bokeh rendering models either heavily relied on prior knowledge such as scene depth or were topic-irrelevant data-driven networks without task-specific knowledge, which restricted models' training efficiency and testing accuracy. Since bokeh is closely related to a phenomenon called "circle of confusion", therefore, in this paper, following the principle of bokeh generation, a novel self-supervised multi-scale pyramid fusion network has been proposed for bokeh rendering. During the pyramid fusion process, structure consistencies are employed to emphasize the importance of respective bokeh components. Task-specific knowledge which mimics the "circle of confusion" phenomenon through disk blur convolutions is utilized as self-supervised information for network training. The proposed network has been evaluated and compared with several state-of-the-art methods on a public large-scale bokeh dataset-the "EBB!" Dataset. The experiment performance demonstrates that the proposed network has much better processing efficiency and can achieve better realistic bokeh effect with much less parameters size and running time. Related source codes and pre-trained models of the proposed model will be available soon on https://github.com/zfw-cv/MPFNet.
C1 [Wang, Zhifeng; Jiang, Aiwen; Li, Hanxi] Jiangxi Normal Univ, Sch Comp & Informat Engn, 99 Ziyang Ave, Nanchang 330022, Jiangxi, Peoples R China.
   [Zhang, Chunjie] Beijing Jiaotong Univ, Sch Comp & Informat Technol, 3 Shangyuancun, Beijing 100044, Peoples R China.
   [Liu, Bo] Auburn Univ, Shelby Ctr Engn Technol 3101P, Dept Comp Sci & Software Engn, Auburn, AL 36849 USA.
C3 Jiangxi Normal University; Beijing Jiaotong University; Auburn
   University System; Auburn University
RP Jiang, AW (corresponding author), Jiangxi Normal Univ, Sch Comp & Informat Engn, 99 Ziyang Ave, Nanchang 330022, Jiangxi, Peoples R China.
EM jiangaiwen@jxnu.edu.cn
OI zhang, chunjie/0000-0002-1161-8995; Jiang, Aiwen/0000-0002-5979-7590
FU National Natural Science Foundation of China [61966018]; State Key
   Laboratory for Management and Control of Complex Systems [20220103];
   Beijing Natural Science Foundation [JQ20022]
FX This work is supported by National Natural Science Foundation of China
   under Grand No. 61966018, The open research fund of the State Key
   Laboratory for Management and Control of Complex Systems under Grant NO.
   20220103, and Beijing Natural Science Foundation under Grand No.
   JQ20022.
CR Bigler E., 2002, DEPTH FIELD SCHEIMPF
   Busam B., 2019, P IEEE CVF INT C COM
   Chen HG, 2020, INFORM SCIENCES, V524, P298, DOI 10.1016/j.ins.2020.03.042
   Dutta S, 2021, IEEE COMPUT SOC CONF, P2398, DOI 10.1109/CVPRW53098.2021.00272
   Dutta S, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103089
   Fu XP, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103609
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Ignatov A, 2020, IEEE COMPUT SOC CONF, P1676, DOI 10.1109/CVPRW50498.2020.00217
   Ignatov A, 2019, IEEE INT CONF COMP V, P3591, DOI 10.1109/ICCVW.2019.00444
   Ignatov Andrey, 2020, ADV IMAGE MANIPULATI
   Jeong Y, 2022, IEEE T VIS COMPUT GR, V28, P1373, DOI 10.1109/TVCG.2020.3014474
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Kingma Diederik P., 2015, P 3 INT C LEARN
   Kosara R, 2001, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2001, PROCEEDINGS, P97, DOI 10.1109/INFVIS.2001.963286
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Li J, 2020, INFORM SCIENCES, V536, P317, DOI 10.1016/j.ins.2020.05.072
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu DW, 2016, MACH VISION APPL, V27, P1325, DOI 10.1007/s00138-016-0775-5
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Liu ZY, 2021, ENG APPL ARTIF INTEL, V106, DOI 10.1016/j.engappai.2021.104473
   Luo CC, 2020, PROC CVPR IEEE, P2404, DOI 10.1109/CVPR42600.2020.00248
   Ming Qian, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P229, DOI 10.1007/978-3-030-67070-2_14
   Nakamura ATM, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104205
   Noori M, 2020, ENG APPL ARTIF INTEL, V89, DOI 10.1016/j.engappai.2019.103419
   Purohit K, 2019, IEEE INT CONF COMP V, P3417, DOI 10.1109/ICCVW.2019.00424
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Song WF, 2020, IEEE T MULTIMEDIA, V22, P1220, DOI 10.1109/TMM.2019.2941776
   Wadhwa N, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201329
   Wang WC, 2019, INFORM SCIENCES, V496, P25, DOI 10.1016/j.ins.2019.05.015
   Wang YQ, 2019, IEEE SIGNAL PROC LET, V26, P204, DOI 10.1109/LSP.2018.2885213
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xianrui Luo, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P245, DOI 10.1007/978-3-030-67070-2_15
   Xu XY, 2018, LECT NOTES COMPUT SC, V11213, P36, DOI 10.1007/978-3-030-01240-3_3
   Xu YD, 2021, INFORM SCIENCES, V548, P378, DOI 10.1016/j.ins.2020.09.066
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang TL, 2020, INFORM SCIENCES, V541, P16, DOI 10.1016/j.ins.2020.05.105
   Zhao JM, 2019, ENG APPL ARTIF INTEL, V82, P263, DOI 10.1016/j.engappai.2019.04.003
   Zhu XB, 2020, INFORM SCIENCES, V515, P233, DOI 10.1016/j.ins.2019.12.013
   Zuo YF, 2019, INFORM SCIENCES, V495, P52, DOI 10.1016/j.ins.2019.05.003
NR 42
TC 2
Z9 2
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103580
DI 10.1016/j.jvcir.2022.103580
EA JUL 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Y9YP
UT WOS:000826243200001
DA 2024-07-18
ER

PT J
AU Jin, Y
   Jiang, ZW
   Xue, ZZ
   Hu, YB
AF Jin, Yan
   Jiang, Zhiwei
   Xue, Zhizhong
   Hu, Yibiao
TI Image blind restoration based on degradation representation network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Contrastive learning; Image restoration; Convolution
   neural network
AB Most deep learning (DL)-based image restoration methods have exploited excellent performance by learning a non-linear mapping function from low quality images to high quality images. However, two major problems restrict the development of the image restoration methods. First, most existing methods based on fixed degra-dation suffer from significant performance drop when facing the unknown degradation, because of the huge gap between the fixed degradation and the unknown degradation. Second, the unknown-degradation estimation may lead to restoration task failure due to uncertain estimation errors. To handle the unknown degradation in the real application, we introduce a degradation representation network for single image blind restoration (DRN). Different from the methods of estimating pixel space, we use an encoder network to learn abstract representa-tions for estimating different degradation kernels in the representation space. Furthermore, a degradation perception module with flexible adaptability to different degradation kernels is used to restore more structural details. In our experiments, we compare our DRN with several state-of-the-art methods for two image restoration tasks, including image super-resolution (SR) and image denoising. Quantitative results show that our degradation representation network is accurate and efficient for single image restoration.
C1 [Jin, Yan; Jiang, Zhiwei; Xue, Zhizhong; Hu, Yibiao] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Jin, Y (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
OI zhiwei, jiang/0000-0001-7314-2083
CR Abu Hussein S, 2020, PROC CVPR IEEE, P1425, DOI 10.1109/CVPR42600.2020.00150
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Agustsson E, 2016, INT C PATT RECOG, P3850, DOI 10.1109/ICPR.2016.7900235
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Arora S., 2019, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.1904.11955
   Chen H, 2017, IEEE T MED IMAGING, V36, P2524, DOI 10.1109/TMI.2017.2715284
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen YH, 2018, LECT NOTES COMPUT SC, V11070, P91, DOI 10.1007/978-3-030-00928-1_11
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   He Z., 2021, IEEE T MULTIMEDIA
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Jiang XB, 2021, VISUAL COMPUT, V37, P2419, DOI 10.1007/s00371-020-01996-1
   Jin Y, 2019, IET IMAGE PROCESS, V13, P1970, DOI 10.1049/iet-ipr.2019.0241
   Jingwen He, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P53, DOI 10.1007/978-3-030-58565-5_4
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma DP, 2015, ADV NEUR IN, V28
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Pérez-Pellitero E, 2016, IEEE T IMAGE PROCESS, V25, P2456, DOI 10.1109/TIP.2016.2549362
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   vandenOord Aaron, 2018, ARXIV180703748
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Yang QS, 2018, IEEE T MED IMAGING, V37, P1348, DOI 10.1109/TMI.2018.2827462
   You CY, 2020, IEEE T MED IMAGING, V39, P188, DOI 10.1109/TMI.2019.2922960
   Yu-Syuan Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12493, DOI 10.1109/CVPR42600.2020.01251
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2020, PROC CVPR IEEE, P3214, DOI 10.1109/CVPR42600.2020.00328
   Zhang K, 2019, PROC CVPR IEEE, P1671, DOI 10.1109/CVPR.2019.00177
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zongsheng Yue, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P41, DOI 10.1007/978-3-030-58607-2_3
NR 47
TC 1
Z9 1
U1 3
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103564
DI 10.1016/j.jvcir.2022.103564
EA JUN 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100002
DA 2024-07-18
ER

PT J
AU Chen, Q
   Shen, ZW
   Chen, Z
AF Chen, Qian
   Shen, Zhengwei
   Chen, Zhe
TI A penalty function semi-continuous thresholding methods for constraints
   of hashing problems
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hash coding; Large-scale data retrieval; Orthogonality constraint;
   Quantization error reduction
ID OPTIMIZATION PROBLEMS; ALGORITHMS; CODES
AB The Hashing process is an effective tool for handling large-scale data (for example, images, videos, or multi-model data) retrieval problems. To get better retrieval accuracy, hashing models usually are imposed with three rigorous constraints, i.e., discrete binary constraint, uncorrelated condition, and the balanced constraint, which will lead to being 'NP-hard'. In this study, we divide the whole constraints set into the uncorrelated (orthogonality) constraint and the binary discrete balance constraint and propose a fast and accurate penalty function semi-continuous thresholding (PFSCT) hash coding algorithm based on forward- backward algorithms. In addition, we theoretically analyze the equivalence between the relaxed model and the original problems. Extensive numerical experiments on diverse large-scale benchmark datasets demonstrate comparable performance and effectiveness of the proposed method.
C1 [Chen, Qian; Shen, Zhengwei; Chen, Zhe] Univ Sci & Technol Beijing, Sch Math & Phys, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Shen, ZW (corresponding author), Univ Sci & Technol Beijing, Sch Math & Phys, Beijing 100083, Peoples R China.
EM ijwmip@ustb.edu.cn
OI Shen, Zhengwei/0000-0001-5472-2242
FU Fundamental Re-search Funds for Central Universities [FRF-BR-20-02B]
FX Acknowledgement The author would like to thank the support of
   Fundamental Re-search Funds for Central Universities (FRF-BR-20-02B) and
   would like to thank anonymous reviewers for their careful work and
   thoughtful suggestions that have helped improve this paper
   substantially.
CR [Anonymous], 2013, DISSERTATIONS THESES
   [Anonymous], 2009, P 26 INT C MACH LEAR
   Attouch H, 2013, MATH PROGRAM, V137, P91, DOI 10.1007/s10107-011-0484-9
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Chen Y, 2020, IEEE T IMAGE PROCESS, V29, P3596, DOI 10.1109/TIP.2020.2963952
   Dean T, 2013, PROC CVPR IEEE, P1814, DOI 10.1109/CVPR.2013.237
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Gao B, 2019, SIAM J SCI COMPUT, V41, pA1949, DOI 10.1137/18M1221679
   Gao B, 2018, SIAM J OPTIMIZ, V28, P302, DOI 10.1137/16M1098759
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Havrlant L, 2017, INT J GEN SYST, V46, P27, DOI 10.1080/03081079.2017.1291635
   Hu J, 2020, J OPER RES SOC CHINA, V8, P199, DOI 10.1007/s40305-020-00295-9
   Hu J, 2018, SIAM J MATRIX ANAL A, V39, P1181, DOI 10.1137/17M1142478
   Hu R, 2021, IEEE ACCESS, V9, P63729, DOI 10.1109/ACCESS.2021.3074947
   Jin ZM, 2014, IEEE T CYBERNETICS, V44, P1362, DOI 10.1109/TCYB.2013.2283497
   Lai RJ, 2014, J SCI COMPUT, V58, P431, DOI 10.1007/s10915-013-9740-x
   Lin GS, 2014, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2014.253
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2014, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2014.275
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163
   Luo X, 2019, IEEE T IMAGE PROCESS, V28, P2962, DOI 10.1109/TIP.2019.2892703
   Luo X, 2018, ACM/SIGIR PROCEEDINGS 2018, P735, DOI 10.1145/3209978.3210035
   Manton JH, 2002, IEEE T SIGNAL PROCES, V50, P635, DOI 10.1109/78.984753
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Talmon R, 2013, IEEE SIGNAL PROC MAG, V30, P75, DOI 10.1109/MSP.2013.2250353
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang SN, 2021, IEEE T CYBERNETICS, V51, P4089, DOI 10.1109/TCYB.2019.2894020
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Wen ZW, 2016, J SCI COMPUT, V66, P1175, DOI 10.1007/s10915-015-0061-0
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wu BY, 2019, IEEE T PATTERN ANAL, V41, P1695, DOI 10.1109/TPAMI.2018.2845842
   Xiao NC, 2022, OPTIM METHOD SOFTW, V37, P1205, DOI 10.1080/10556788.2020.1852236
   Xu Y, 2023, IEEE T KNOWL DATA EN, V35, P741, DOI 10.1109/TKDE.2021.3079581
   Yang Y, 2014, IEEE T MULTIMEDIA, V16, P1677, DOI 10.1109/TMM.2014.2323014
   Yuan L, 2020, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR42600.2020.00315
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang SF, 2018, IEEE T CIRC SYST VID, V28, P2716, DOI 10.1109/TCSVT.2017.2710345
   Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335
   Zhang Z, 2019, IEEE T IMAGE PROCESS, V28, P4803, DOI 10.1109/TIP.2019.2912290
   Zhao K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1089, DOI 10.1145/2647868.2654971
   Zheng XT, 2020, NEUROCOMPUTING, V403, P224, DOI 10.1016/j.neucom.2020.04.037
NR 48
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103552
DI 10.1016/j.jvcir.2022.103552
EA JUN 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H5UY
UT WOS:000814360600003
DA 2024-07-18
ER

PT J
AU Baraha, S
   Sahoo, AK
AF Baraha, Satyakam
   Sahoo, Ajit Kumar
TI Restoration of speckle noise corrupted SAR images using regularization
   by denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Denoiser; Despeckling; PnP priors; Rayleigh noise; RED; Synthetic
   aperture radar
ID ULTRASOUND IMAGES; RECONSTRUCTION; SPARSE; REDUCTION; FRAMEWORK; ADMM
AB Speckle noise removal is a well-established problem in synthetic aperture radar (SAR) image processing. Among different methods focused on the reconstruction of SAR images, variational models have achieved state-of-the -art performance. In this paper, a Rayleigh based speckle reduction algorithm is developed using the variational framework. The forward model is combined with recently proposed regularization by denoising (RED) prior. However, RED has been proposed in literature for the additive noise model. Multiplicative noise in SAR images prevents the direct application of RED to variational models. Hence, logarithm transformation is applied to change the multiplicative noise model to additive model, and the forward model from Rayleigh to Fisher-Tippett distribution. The resulting optimization problem is solved using the alternating direction method of multipliers. Further, the proof of the convergence analysis is carried out for the above framework. Simulations convey that the proposed method has better despeckling performance compared to that of state-of-the-art methods.
C1 [Baraha, Satyakam; Sahoo, Ajit Kumar] Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Baraha, S (corresponding author), Natl Inst Technol Rourkela, Dept Elect & Commun Engn, Odisha, India.
EM 517ec1014@nitrkl.ac.in; ajitsahoo@nitrkl.ac.in
RI Sahoo, Ajit Kumar/O-6153-2017; Baraha, Satyakam/AEY-1038-2022
OI Baraha, Satyakam/0000-0002-7770-4335
CR Afonso M, 2015, NEUROCOMPUTING, V150, P200, DOI 10.1016/j.neucom.2014.08.073
   Afonso MV, 2015, DIGIT SIGNAL PROCESS, V40, P101, DOI 10.1016/j.dsp.2015.02.002
   Afonso MV, 2015, IEEE T IMAGE PROCESS, V24, P2239, DOI 10.1109/TIP.2015.2417505
   [Anonymous], 2021, ALASKA SATELLITE FAC
   Baraha S., 2020, 2020 IEEE 17 IND COU
   Baraha S, 2022, SIGNAL PROCESS, V196, DOI 10.1016/j.sigpro.2022.108521
   Baraha S, 2020, IET RADAR SONAR NAV, V14, P1297, DOI 10.1049/iet-rsn.2019.0609
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buzzard GT, 2018, SIAM J IMAGING SCI, V11, P2001, DOI 10.1137/17M1122451
   Chan SH, 2019, IEEE T COMPUT IMAG, V5, P274, DOI 10.1109/TCI.2019.2892123
   Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286
   Chi YH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1708, DOI 10.1109/ICASSP.2018.8461887
   Cozzolino D, 2014, IEEE GEOSCI REMOTE S, V11, P524, DOI 10.1109/LGRS.2013.2271650
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dalsasso E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162636
   Deledalle CA, 2015, IEEE T GEOSCI REMOTE, V53, P2021, DOI 10.1109/TGRS.2014.2352555
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Dellepiane SG, 2011, INT GEOSCI REMOTE SE, P3803, DOI 10.1109/JSTARS.2013.2279501
   Di Martino G, 2014, IEEE T GEOSCI REMOTE, V52, P1596, DOI 10.1109/TGRS.2013.2252907
   Döring BJ, 2013, IEEE T GEOSCI REMOTE, V51, P5307, DOI 10.1109/TGRS.2012.2234128
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   KAPLAN D, 1993, ULTRASON, P961, DOI 10.1109/ULTSYM.1993.339648
   Li RZ, 2021, IEEE SENS J, V21, P3437, DOI 10.1109/JSEN.2020.3025053
   Li XZ, 2018, COMPUT GRAPH FORUM, V37, P155, DOI 10.1111/cgf.13556
   Li Y, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107706
   Liu SQ, 2021, IEEE T GEOSCI REMOTE, V59, P3956, DOI 10.1109/TGRS.2020.3014130
   Liu SQ, 2019, IEEE T GEOSCI REMOTE, V57, P2700, DOI 10.1109/TGRS.2018.2876339
   Mullissa AG, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2020.3042694
   Nobre R., 2017, **DATA OBJECT**, DOI 10.21227/H28W2J
   Pang JH, 2017, IEEE T IMAGE PROCESS, V26, P1770, DOI 10.1109/TIP.2017.2651400
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Reehorst ET, 2019, IEEE T COMPUT IMAG, V5, P52, DOI 10.1109/TCI.2018.2880326
   Romano Y, 2017, SIAM J IMAGING SCI, V10, P1804, DOI 10.1137/16M1102884
   Seabra J, 2008, IEEE ENG MED BIO, P435, DOI 10.1109/IEMBS.2008.4649183
   Sun YL, 2021, IEEE T GEOSCI REMOTE, V59, P1231, DOI 10.1109/TGRS.2020.3002561
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Teodoro AM, 2019, IEEE T IMAGE PROCESS, V28, P451, DOI 10.1109/TIP.2018.2869727
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Wang S, 2018, NUMER ALGORITHMS, V78, P513, DOI 10.1007/s11075-017-0386-x
   Xie H, 2002, IEEE T GEOSCI REMOTE, V40, P721, DOI 10.1109/TGRS.2002.1000333
   Yun S, 2012, IEEE T IMAGE PROCESS, V21, P2523, DOI 10.1109/TIP.2012.2185942
   Zhu L, 2020, IEEE T VIS COMPUT GR, V26, P2471, DOI 10.1109/TVCG.2018.2889055
   Zhu L, 2018, NEUROCOMPUTING, V294, P48, DOI 10.1016/j.neucom.2018.03.009
   Zhu L, 2017, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2017.60
   Zhu L, 2017, SIGNAL PROCESS, V134, P275, DOI 10.1016/j.sigpro.2016.12.011
   Zhu L, 2016, COMPUT GRAPH FORUM, V35, P217, DOI 10.1111/cgf.13019
NR 48
TC 9
Z9 9
U1 3
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103546
DI 10.1016/j.jvcir.2022.103546
EA MAY 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H3MB
UT WOS:000814201400001
DA 2024-07-18
ER

PT J
AU Shao, ZP
   Hu, ZY
   Yang, JY
   Li, YF
AF Shao, Zhanpeng
   Hu, Zhongyan
   Yang, Jianyu
   Li, Youfu
TI Multi-stream feature refinement network for human object interaction
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human object interaction; Action recognition; Feature refinement and
   learning; Multi-stream neural network; Human pose; Object semantic
   information
AB Human-Object Interaction (HOI) detection is a crucial problem for comprehensive visual understanding, which aims to detect < human, action, object > triplets within an image. Many existing methods often exploit to integrate the human and object visual features , the spatial layout of human-object pairs, human poses, contextual information, and even object semantic information into a framework to infer the interactions, proving that all these components can contribute to improve the HOI detection. However, most methods simply concatenate these components that are not explicitly embedded in the feature learning for HOI detection. In this paper, we are trying to fuse these components explicitly using a multi-stream feature refinement network. The network extracts the visual features of humans, contexts, and objects, which receives the attentions from human poses, spatial configurations, and semantic prior knowledge of objects to refine these visual features, respectively. In addition, an additional graph neural network is employed here to learn the structural features of human-object pairs. We verify our method on V-COCO and HICO-DET datasets with extensive experiments. The experimental results demonstrate that our method is a simple yet effective for HOI detection, achieving superior performance to those state-of-the-art methods.
C1 [Shao, Zhanpeng; Hu, Zhongyan] Zhejiang Univ Technol, Sch Comp Sci & Technol, 288 Liuhe Rd, Hangzhou 310023, Peoples R China.
   [Yang, Jianyu] Soochow Univ, Sch Rail Transportat, 8 Jixue Rd, Suzhou 215000, Peoples R China.
   [Li, Youfu] City Univ Hong Kong, Dept Mech Engn, Tat Chee Ave, Hong Kong, Peoples R China.
C3 Zhejiang University of Technology; Soochow University - China; City
   University of Hong Kong
RP Yang, JY (corresponding author), Soochow Univ, Sch Rail Transportat, 8 Jixue Rd, Suzhou 215000, Peoples R China.
EM zpshao@zjut.edu.cn; 2111912031@zjut.edu.cn; jyyang@suda.edu.cn;
   meyfli@cityu.edu.hk
RI LU, CX/KFB-9510-2024; XIE, WANYING/JNR-9259-2023; wen,
   liang/JNR-7720-2023
OI Shao, Zhanpeng/0000-0002-8130-5230; LI, You Fu/0000-0002-5227-1326
FU National Natural Science Foundation of China (NSFC) [61976191, 61773272,
   61873220]; Zhejiang Provincial Natural Science Foundation, China
   [LY19F030 015]; Six Talent Peaks Project of Jiangsu Province, China
   [XYDXX-053]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC No. 61976191, 61773272, 61873220,) and
   Zhejiang Provincial Natural Science Foundation, China (No. LY19F030 015)
   , and the Six Talent Peaks Project of Jiangsu Province, China (No.
   XYDXX-053) .
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bansal A, 2020, AAAI CONF ARTIF INTE, V34, P10460
   Bingjie Xu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P2019, DOI 10.1109/CVPR.2019.00212
   Bochkovskiy A., 2020, PREPRINT
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dong-Jin Kim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P718, DOI 10.1007/978-3-030-58589-1_43
   Fang HS, 2018, LECT NOTES COMPUT SC, V11214, P52, DOI 10.1007/978-3-030-01249-6_4
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gao C., 2018, BRIT MACH VIS C
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R., 2019, DETECTRON2
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gupta S., 2015, PREPRINT
   Gupta T, 2019, IEEE I CONF COMP VIS, P9676, DOI 10.1109/ICCV.2019.00977
   He K., 2016, P IEEE C COMP VIS PA, P770, DOI DOI 10.48550/ARXIV.1512.03385
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Kato K, 2018, LECT NOTES COMPUT SC, V11218, P247, DOI 10.1007/978-3-030-01264-9_15
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li YL, 2020, PROC CVPR IEEE, P379, DOI [10.1109/CVPR42600.2020.00046, 10.1109/ICEMME51517.2020.00080]
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056
   Lin T.-Y., 2014, CoRR, P740
   Lin X, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1104
   Liu HC, 2021, COMPUT VIS MEDIA, V7, P229, DOI 10.1007/s41095-020-0188-2
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Naveed H, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103135
   Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Redmon J., 2018, P IEEE C COMP VIS PA
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shao ZP, 2021, IEEE T CIRC SYST VID, V31, P160, DOI 10.1109/TCSVT.2020.2965574
   Ulutan O., 2020, CVPR, P13617
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang TC, 2020, PROC CVPR IEEE, P4115, DOI 10.1109/CVPR42600.2020.00417
   Wang ZH, 2021, IEEE T IMAGE PROCESS, V30, P6240, DOI 10.1109/TIP.2021.3093383
   Wu HP, 2019, IEEE I CONF COMP VIS, P9216, DOI 10.1109/ICCV.2019.00931
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yang DM, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1111
   Yang JY, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103263
   Zhao ZC, 2017, IEEE I CONF COMP VIS, P3411, DOI 10.1109/ICCV.2017.367
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou PH, 2019, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2019.00093
NR 52
TC 7
Z9 7
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103529
DI 10.1016/j.jvcir.2022.103529
EA MAY 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1V1LX
UT WOS:000805861200004
DA 2024-07-18
ER

PT J
AU Chen, YB
   Ke, W
   Lin, H
   Lam, CT
   Lv, K
   Sheng, H
   Xiong, Z
AF Chen, Yanbing
   Ke, Wei
   Lin, Hong
   Lam, Chan-Tong
   Lv, Kai
   Sheng, Hao
   Xiong, Zhang
TI Local perspective based synthesis for vehicle re-identification: A
   transformation state adversarial method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vehicle re-identification; Data synthesis; Local-region perspective
   transformation; Transformation state adversarial; Candidate pool;
   Parameter generator network
AB Vehicle re-identification (V-ReID) aims at discovering an image of a specific vehicle from a set of images typically captured by different cameras. Vehicles are one of the most important objects in cross-camera target recognition systems, and recognizing them is one of the most difficult tasks due to the subtle differences in the visible characteristics of vehicle rigid objects. Compared to various methods that can improve re-identification accuracy, data augmentation is a more straightforward and effective technique. In this paper, we propose a novel data synthesis method for V-ReID based on local-region perspective transformation, transformation state adversarial learning and a candidate pool. Specifically, we first propose a parameter generator network, which is a lightweight convolutional neural network, to generate the transformation states. Secondly, an adversarial module is designed in our work, it ensures that noise information is added as much as possible while keeping the labeling and structure of the dataset intact. With this adversarial module, we are able to promote the performance of the network and generate more proper and harder training samples. Furthermore, we use a candidate pool to store harder samples for further selection to improve the performance of the model. Our system pays more balanced attention to the features of vehicles. Extensive experiments show that our method significantly boosts the performance of V-ReID on the VeRi-776, VehicleID and VERI-Wild datasets.
C1 [Chen, Yanbing; Lin, Hong; Lam, Chan-Tong] Macao Polytech Inst, Sch Appl Sci, Macau, Peoples R China.
   [Ke, Wei] Macao Polytech Inst, Minist Educ, Engn Res Ctr Appl Technol Machine Translat & Arti, Macau, Peoples R China.
   [Lv, Kai; Sheng, Hao; Xiong, Zhang] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Sheng, Hao; Xiong, Zhang] Beihang Univ, Beihang Hangzhou Innovat Inst Yuhang, Hangzhou 310023, Peoples R China.
   [Chen, Yanbing] Zhejiang Sci Tech Univ, Sch Informat Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Macao Polytechnic University; Macao Polytechnic University; Beihang
   University; Beihang University; Zhejiang Sci-Tech University
RP Ke, W (corresponding author), Macao Polytech Inst, Minist Educ, Engn Res Ctr Appl Technol Machine Translat & Arti, Macau, Peoples R China.
EM wke@ipm.edu.mo
OI Lam, Chan-Tong/0000-0002-8022-7744; chen, yanbing/0000-0002-6818-0437;
   Ke, Wei/0000-0003-0952-0961
FU National Key Research and Development Program of China [2018YFB2101100];
   National Natural Science Foundation of China [61861166002]; Science and
   Technology Development Fund, Macau SAR [0001/2018/AFJ]; Open Fund of the
   State Key Laboratory of Software Development Environment, China
   [SKLSDE-2021ZX-03]; HAWKEYE Group
FX This study is partially supported by the National Key Research and
   Development Program of China (No. 2018YFB2101100) , the Na-tional
   Natural Science Foundation of China (No. 61861166002) , and the Science
   and Technology Development Fund, Macau SAR (File no. 0001/2018/AFJ) and
   the Open Fund of the State Key Laboratory of Software Development
   Environment, China (No. SKLSDE-2021ZX-03) . Thanks for the support from
   HAWKEYE Group.
CR Alfasly S, 2019, IEEE ACCESS, V7, P162605, DOI 10.1109/ACCESS.2019.2948965
   Anthopoulos LG, 2017, PUB ADMIN INF TECH, V22, P47, DOI 10.1007/978-3-319-57015-0_3
   Bengio Y., 2014, TECHNICAL REPORT
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He B, 2019, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2019.00412
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S., 2020, P IEEECVF C COMPUTER, P582
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Jung H, 2017, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2017.129
   Khan SD, 2019, COMPUT VIS IMAGE UND, V182, P50, DOI 10.1016/j.cviu.2019.03.001
   Khorramshahi P, 2019, IEEE I CONF COMP VIS, P6131, DOI 10.1109/ICCV.2019.00623
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuma R., 2019, 2019 INT JOINT C NEU, P1
   Li YQ, 2017, IEEE IMAGE PROC, P395, DOI 10.1109/ICIP.2017.8296310
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu XC, 2016, IEEE INT CON MULTI
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Lou YH, 2019, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2019.00335
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Lv K, 2020, IEEE T IMAGE PROCESS, V29, P5163, DOI 10.1109/TIP.2020.2980130
   Odena A, 2017, PR MACH LEARN RES, V70
   Peng J., 2020, MULTIMEDIA TOOLS APP, P1
   Radford A., 2015, ARXIV151106434
   Ruder S., ARXIV160904747
   Rueckert, 2018, CoRR
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shen YT, 2017, IEEE I CONF COMP VIS, P1918, DOI 10.1109/ICCV.2017.210
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Stevenson JA, 2010, GEOMORPHOLOGY, V114, P238, DOI 10.1016/j.geomorph.2009.07.006
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Tang Z, 2019, IEEE I CONF COMP VIS, P211, DOI 10.1109/ICCV.2019.00030
   Tramer Florian, 2017, Ensemble adversarial training: Attacks and defenses
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Xinyue Zhu, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10939, P349, DOI 10.1007/978-3-319-93040-4_28
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yao Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P764
   Yuan Y, 2020, IEEE COMPUT SOC CONF, P1454, DOI 10.1109/CVPRW50498.2020.00185
   ZHANG S., 2014, ARXIV PREPRINT ARXIV
   Zheng A., 2019, ARXIV190508997
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou TH, 2016, LECT NOTES COMPUT SC, V9908, P286, DOI 10.1007/978-3-319-46493-0_18
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhou Yi, 2018, IEEE Trans Image Process, V27, P3275, DOI 10.1109/TIP.2018.2819820
NR 54
TC 7
Z9 8
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103432
DI 10.1016/j.jvcir.2021.103432
EA JAN 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200005
DA 2024-07-18
ER

PT J
AU Liao, JW
   Qi, C
   Cao, JZ
   Wang, XF
   Ren, L
   Zhang, CN
AF Liao, Jiawen
   Qi, Chun
   Cao, Jianzhong
   Wang, Xiaofang
   Ren, Long
   Zhang, Chaoning
TI Rotation-aware correlation filters for robust visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Correlation filter; Visual tracking; Rotation; Phase correlation; Kalman
   filter
AB Recent years have witnessed several modified discriminative correlation filter (DCF) models exhibiting excellent performance in visual tracking. A fundamental drawback to these methods is that rotation of the target is not well addressed which leads to model deterioration. In this paper, we propose a novel rotation-aware correlation filter to address the issue. Specifically, samples used for training of the modified DCF model are rectified when rotation occurs, rotation angle is effectively calculated using phase correlation after transforming the search patch from Cartesian coordinates to the Log-polar coordinates, and an adaptive selection mechanism is further adopted to choose between a rectified target patch and a rectangular patch. Moreover, we extend the proposed approach for robust tracking by introducing a simple yet effective Kalman filter prediction strategy. Extensive experiments on five standard benchmarks show that the proposed method achieves superior performance against state-of-the-art methods while running in real-time on single CPU.
C1 [Liao, Jiawen; Cao, Jianzhong; Ren, Long] Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.
   [Liao, Jiawen; Qi, Chun; Ren, Long] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Liao, Jiawen; Ren, Long] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Wang, Xiaofang] Qilu Univ Technol, Shandong Acad Sci, Jinan 250353, Peoples R China.
   [Zhang, Chaoning] Korea Adv Inst Sci & Technol KAIST, Daejeon 34141, South Korea.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; Xi'an Jiaotong University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; Qilu University of
   Technology; Korea Advanced Institute of Science & Technology (KAIST)
RP Liao, JW (corresponding author), Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.; Qi, C (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM liaojiawen@stu.xjtu.edu.cn; qichun@mail.xjtu.edu.cn
OI Zhang, Chaoning/0000-0001-6007-6099
FU National Natural Science Foundation of China [61572395, 61675161]
FX Acknowledgment This work was supported in part by the National Natural
   Science Foundation of China [61572395, 61675161] .
CR [Anonymous], 2018, IEEE T CIRC SYST VID
   [Anonymous], 2015, INT J COMPUT VISION
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fan H, 2018, IEEE T IMAGE PROCESS
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li Y, 2016, IEEE IMAGE PROC, P454, DOI 10.1109/ICIP.2016.7532398
   Li Y, 2019, AAAI CONF ARTIF INTE, P8666
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liao J., 2020, IEEE T MULTIMED, V1
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Simonyan K., 2014, CORR
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q., 2017, ARXIV PREPRINT ARXIV
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang M.-H., 2018, NEURAL INFORM PROCES
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang MD, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P595, DOI 10.1109/ICCVW.2015.81
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 52
TC 3
Z9 3
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103422
DI 10.1016/j.jvcir.2021.103422
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200001
DA 2024-07-18
ER

PT J
AU Dhamija, A
   Dubey, RB
AF Dhamija, Ashutosh
   Dubey, R. B.
TI A novel active shape model-based DeepNeural network for age invariance
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Age invariance face recognition; CNN architecture; Improved Active shape
   model; Handcrafted and deep features; Principal component analysis; The
   features reduction
ID NEURAL-NETWORKS; DIMENSIONALITY; ARCHITECTURES; VERIFICATION; SCALE
AB Scientific efforts have expanded in age-invariant face recognition (AIFR). Matching faces of large age difference is, therefore, a problem, mostly because of a substantial disparity in the appearance of both young and old age. Owing to age, both the appearance and shape of the face are impaired, making recognition of the face the most challenging task. In recent years, AIFR has become a very common and demanding task. The set of feature extraction and classification algorithm is of prime importance in this field. As the numbers of features obtained from the datasets are large, there is a need to introduce a dimensionality reduction method to map high dimensionality feature space to low variance filter to form the final integrated face age model to be used in the classification process. In this paper, we introduced a novel concept of an improved Active Shape Model (ASM) in conjunction with a specially designed 7-layered Convolutional Neural Network (CNN) in order to accomplish a combination of feature extraction and classification in a single unit. The study approach involves conducting extensive experiments to evaluate the proposed system's performance using three standard datasets: FG-NET, LAG, and CACD. The results reveal that the proposed method outperforms state-of-the-art approaches and achieves excellent accuracy in face recognition across age. The maximum accuracies achieved by demonstrated ASM-CNN methodology for FG-NET, LAG, and CACD databases are 95.02%, 91.76 % and 99.4 % respectively.
C1 [Dhamija, Ashutosh] SRM Univ, ECE Dept, Sonepat, Haryana, India.
   [Dubey, R. B.] SRM Univ, EEE Dept, Sonepat, Haryana, India.
C3 SRM University Haryana; SRM University Haryana
RP Dubey, RB (corresponding author), SRM Univ, EEE Dept, Sonepat, Haryana, India.
EM rbdubey@srmuniversity.ac.in
OI Dhamija, Ashutosh/0000-0002-0454-3622
CR Abi-Nahed J, 2006, LECT NOTES COMPUT SC, V4191, P1
   Ali ASO, 2015, IET BIOMETRICS, V4, P98, DOI 10.1049/iet-bmt.2014.0018
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2003, Quality control and applied statistics
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bereta M, 2013, PATTERN RECOGN, V46, P2634, DOI 10.1016/j.patcog.2013.03.010
   Bianco S, 2017, PATTERN RECOGN LETT, V90, P36, DOI 10.1016/j.patrec.2017.03.006
   Bijarnia S, 2016, ADV INTELL SYST, V452, P71, DOI 10.1007/978-981-10-1023-1_7
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bouchaffra D, 2015, IEEE T NEUR NET LEAR, V26, P1375, DOI 10.1109/TNNLS.2014.2341634
   Cao Q, 2013, IEEE I CONF COMP VIS, P2408, DOI 10.1109/ICCV.2013.299
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chenjing Yan, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P211, DOI 10.1007/978-3-319-13168-9_22
   Duong CN, 2017, IEEE I CONF COMP VIS, P3755, DOI 10.1109/ICCV.2017.403
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Du LS, 2020, IEEE T INF FOREN SEC, V15, P2241, DOI 10.1109/TIFS.2019.2960585
   El Khiyari H., 2016, Journal of Information Security, V7, P141
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   George K Soumya, 2014, IOSR J. Comput. Eng, V16, P1, DOI DOI 10.9790/0661-16153438
   Gong DH, 2015, PROC CVPR IEEE, P5289, DOI 10.1109/CVPR.2015.7299166
   Gong DH, 2013, IEEE I CONF COMP VIS, P2872, DOI 10.1109/ICCV.2013.357
   GRD P, 2013, RES PAPERS FACULTY M, V21, P24
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hong S, 2010, CONF PROC INT SYMP C, P280, DOI 10.1145/1816038.1815998
   Hu G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P384, DOI 10.1109/ICCVW.2015.58
   Hunter D., 2012, FACIAL AGEING
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jayaraman U, 2020, NEUROCOMPUTING, V408, P231, DOI 10.1016/j.neucom.2019.08.110
   Jing-Ming Guo, 2011, Proceedings of the 2011 International Conference on System Science and Engineering (ICSSE), P55, DOI 10.1109/ICSSE.2011.5961873
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Li HX, 2018, IEEE T INF FOREN SEC, V13, P2383, DOI 10.1109/TIFS.2018.2819124
   Li HX, 2017, IEEE SIGNAL PROC LET, V24, P465, DOI 10.1109/LSP.2017.2661983
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Li Y, 2015, COMM COM INF SC, V546, P296, DOI 10.1007/978-3-662-48558-3_30
   Li ZF, 2005, PROC CVPR IEEE, P961
   Li ZF, 2016, IEEE T IMAGE PROCESS, V25, P2146, DOI 10.1109/TIP.2016.2535284
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751
   Liu JZ, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/8637260
   Liu W, 2004, LECT NOTES COMPUT SC, V3087, P32
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahalingam G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-36
   Medley D, 2018, LECT NOTES COMPUT SC, V11182, P163, DOI 10.1007/978-3-030-01449-0_14
   Medley DO, 2020, IEEE T IMAGE PROCESS, V29, P2380, DOI 10.1109/TIP.2019.2948728
   Messer K., 1999, P INT C AUD VID BAS, P1
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   Newell EW, 2016, NAT IMMUNOL, V17, P890, DOI 10.1038/ni.3485
   Nimbarte Mrudula, 2018, INT J ELECT COMPUT E, V8, ppp2126, DOI [10.11591/ijece:v8i410.11591/ijece:v8i4, DOI 10.11591/IJECE:V8I410.11591/IJECE:V8I4]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Phung SL, 2009, MATLAB LIB CONVOLUTI
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qi X., 2018, ARXIV180105678
   Sajid M, 2016, COMPUT ELECTR ENG, V54, P255, DOI 10.1016/j.compeleceng.2016.01.001
   Sawant MM, 2019, ARTIF INTELL REV, V52, P981, DOI 10.1007/s10462-018-9661-z
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shakeel MS, 2019, PATTERN RECOGN, V93, P442, DOI 10.1016/j.patcog.2019.04.028
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun Y., 2015, ARXIV150200873
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Suo JL, 2012, IEEE T PATTERN ANAL, V34, P2083, DOI 10.1109/TPAMI.2012.22
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tandon Ankit, 2014, International Conference on Software Intelligence Technologies and Applications & International Conference on Frontiers of Internet of Things 2014, P131
   Tanner M., 2012, Tools for statistical inference: observed data and data augmentation methods
   Thai Hoang Le, 2011, Advances in Artificial Neural Systems, DOI 10.1155/2011/673016
   Thukral P, 2012, INT CONF ACOUST SPEE, P1529, DOI 10.1109/ICASSP.2012.6288182
   Vadivel A., 2003, P INT C INF TECHN CI, P159
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H., P IEEE C COMP VIS PA, P3527
   Wang YT, 2018, LECT NOTES COMPUT SC, V11219, P764, DOI 10.1007/978-3-030-01267-0_45
   Wen YD, 2016, PROC CVPR IEEE, P4893, DOI 10.1109/CVPR.2016.529
   Wolf L, 2009, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2009.5459323
   Wu Y, 2021, IEEE INTERNET THINGS, V8, P4906, DOI 10.1109/JIOT.2020.3030240
   Xiao B, 2013, PATTERN RECOGN, V46, P1906, DOI 10.1016/j.patcog.2012.12.009
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xinhua L., 2015, INT J SIGNAL PROCESS, V8, P29
   Xiong YJ, 2013, IEEE I CONF COMP VIS, P585, DOI 10.1109/ICCV.2013.78
   Xu CF, 2017, NEUROCOMPUTING, V222, P62, DOI 10.1016/j.neucom.2016.10.010
   Yadav D, 2013, IEEE COMPUT SOC CONF, P173, DOI 10.1109/CVPRW.2013.33
   Yan YL, 2017, INT J MULTIMED DATA, V8, P1, DOI 10.4018/IJMDEM.2017010101
   Yan YL, 2015, IEEE INT SYM MULTIM, P483, DOI 10.1109/ISM.2015.126
   Yu JB, 2018, IEEE IMAGE PROC, P2411, DOI 10.1109/ICIP.2018.8451632
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhao J, 2022, IEEE T PATTERN ANAL, V44, P474, DOI 10.1109/TPAMI.2020.3011426
   Zhou HL, 2018, PATTERN RECOGN, V76, P191, DOI 10.1016/j.patcog.2017.10.036
NR 105
TC 5
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103393
DI 10.1016/j.jvcir.2021.103393
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0SO
UT WOS:000783933400003
DA 2024-07-18
ER

PT J
AU Song, YA
   Shen, WM
   Lu, P
AF Song, Yanan
   Shen, Weiming
   Lu, Peng
TI A novel partial-to-partial registration method based on sampling
   network*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Point cloud registration; Partial correspondence; Sampling network; Deep
   learning
AB Point cloud registration is mainly to estimate a rigid transformation between point clouds. The traditional optimization-based registration method requires a good initial position, and it is easy to fall into a local optimal solution. Some learning-based methods are introduced to reduce the dependence on the initial transformation, but they cannot handle partial-to-partial registration tasks. This paper proposes a learning-based registration method for partial-to-partial scenario. The local geometry is encoded into the feature representation of each point. A transformer network is used to enhance attention features. A designed sampling network down-sample key matching points and their corresponding features. The rigid transformation is calculated according to virtual correspondence by a singular value decomposition layer. The ModelNet40 dataset and Stanford 3D Scanning models are used to test the registration performance. Experimental results show that the proposed method achieves better registration accuracy than traditional methods, and it is robust to any initial transformation and noise.
C1 [Song, Yanan; Lu, Peng] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China.
   [Song, Yanan; Lu, Peng] Zhejiang Univ, Inst Comp Innovat, Hangzhou, Peoples R China.
   [Shen, Weiming] Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan, Peoples R China.
C3 Zhejiang University; Zhejiang University; Huazhong University of Science
   & Technology
RP Shen, WM (corresponding author), Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan, Peoples R China.
EM shenwm@hust.edu.cn
RI shen, Weiming/HJZ-2337-2023; Shen, Weiming/B-7400-2013; LU,
   Peng/IST-9799-2023
OI Shen, Weiming/0000-0001-5204-7992; 
FU China Postdoctoral Science Foundation [2021 M692778]
FX Acknowledgments This work was supported by China Postdoctoral Science
   Foundation (Grant Number 2021 M692778) . The authors would like to
   thanks AI + High Performance Computing Center of ZJU-ICI.
CR Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Fu K., 2021, ARXIV210304256
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Huang SY, 2021, PROC CVPR IEEE, P4265, DOI 10.1109/CVPR46437.2021.00425
   Karimi M, 2021, IEEE ROBOT AUTOM LET, V6, P2248, DOI 10.1109/LRA.2021.3060721
   Li J., 2019, ARXIV191010328
   Li MY, 2021, ROBOT CIM-INT MANUF, V71, DOI 10.1016/j.rcim.2021.102136
   Qi CR, 2017, ADV NEUR IN, V30
   Rosen DM, 2019, INT J ROBOT RES, V38, P95, DOI 10.1177/0278364918784361
   Rusinkiewicz S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323037
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sarode Vinit, 2019, ARXIV190807906
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YX, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3792
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie J, 2015, J VIS COMMUN IMAGE R, V32, P194, DOI 10.1016/j.jvcir.2015.08.007
   Yang JL, 2016, IEEE T PATTERN ANAL, V38, P2241, DOI 10.1109/TPAMI.2015.2513405
   Yang Y, 2021, IEEE T CYBERNETICS, V51, P1678, DOI 10.1109/TCYB.2019.2944171
   Zhang S, 2019, J VIS COMMUN IMAGE R, V61, P170, DOI 10.1016/j.jvcir.2019.03.005
   Zhou QY, 2016, LECT NOTES COMPUT SC, V9906, P766, DOI 10.1007/978-3-319-46475-6_47
   Zi Jian Yew, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11821, DOI 10.1109/CVPR42600.2020.01184
NR 27
TC 1
Z9 1
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103411
DI 10.1016/j.jvcir.2021.103411
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0SO
UT WOS:000783933400004
DA 2024-07-18
ER

PT J
AU Wei, WY
   Yang, WZ
   Zuo, EG
   Qian, YY
   Wang, LH
AF Wei, Wenyu
   Yang, Wenzhong
   Zuo, Enguang
   Qian, Yunyun
   Wang, Lihua
TI Person re-identification based on deep learning-An overview
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Person re-identification; Deep learning; Convolutional neural networks;
   Attention mechanism
ID GENERATIVE ADVERSARIAL NETWORKS; TRANSFER GAN; ATTENTION; SIMILARITY;
   DESCRIPTOR; ATTRIBUTE; ALIGNMENT; MODEL
AB Person re-identification(ReID) is an intelligent video surveillance technology that retrieves the same person from different cameras. This task is extremely challenging due to changes in person poses, different camera views, and occlusion. In recent years, person ReID based on deep learning technology has received widespread attention due to the rapid development and excellent performance of deep learning. In this paper, we first divide person ReID based on deep learning approaches into seven types, i.e., fused hand-crafted features deep model, representation learning model, metric learning model, part-based deep model, video-based model, GANbased model, unsupervised model. Furthermore, we launched a brief overview of the seven types. Then, we introduce some examples of commonly used datasets, compare the performance of some algorithms on image and video datasets in recent years, and analyze the advantages and disadvantages of various methods. Finally, we summarize the possible future research directions of person ReID technology.
C1 [Wei, Wenyu; Yang, Wenzhong; Zuo, Enguang; Qian, Yunyun] Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
   [Wang, Lihua] Xinjiang Univ, Sch Software, Urumqi 830046, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Yang, WZ (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, Urumqi 830046, Peoples R China.
EM wwyy1801992@163.com; ywz_xy@163.com
RI wei, wenyu/IQW-3145-2023
FU National Natural Science Founda-tion, China [U1603115]
FX Acknowledgment This work was supported by the National Natural Science
   Founda-tion, China under Grant U1603115.
CR Bai S., 2019, COMPUT VIS PATTERN R
   Bedagkar-Gala A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Chai T., 2021, ABS210806946 CORR
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen C, 2019, AAAI CONF ARTIF INTE, P3296
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen H., 2020, LEARNING DISCRIMINAT
   Chen H, 2020, IEEE WINT CONF APPL, P2472, DOI [10.1109/WACV45572.2020.9093541, 10.1109/wacv45572.2020.9093541]
   Chen HR, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Y., 2020, COMPUT VIS PATTERN R
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Davis J. V., 2007, ICML, P209
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Ding W., 2019, COMPUT VIS PATTERN R
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Ehsani K, 2018, PROC CVPR IEEE, P6144, DOI 10.1109/CVPR.2018.00643
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Gong DNT, 2009, LECT NOTES COMPUT SC, V5716, P179, DOI 10.1007/978-3-642-04146-4_21
   Gong S., 2012, PERSON RE IDENTIFICA, P1
   Gong YC, 2020, IEEE ACCESS, V8, P203700, DOI 10.1109/ACCESS.2020.3036985
   Goodfellow I., 2014, GENERATIVE ADVERSARI, P2680
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hafner F.M., 2018, COMPUT VIS PATTERN R
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He Shuting, 2021, P IEEE CVF INT C COM
   Hermans A., 2017, COMPUT VIS PATTERN R
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hsu CC, 2017, INTERSPEECH, P3364, DOI 10.21437/Interspeech.2017-63
   Huang WJ, 2018, AAAI CONF ARTIF INTE, P2273
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Jiao JN, 2018, AAAI CONF ARTIF INTE, P6967
   Kingma D.P., 2013, Machine Learning
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li D., 2016, COMPUT VIS PATTERN R
   Li J., 2017, ARXIV171207286
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li S, 2017, IEEE I CONF COMP VIS, P1908, DOI 10.1109/ICCV.2017.209
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li YJ, 2016, PR IEEE I C PROGR IN, P224, DOI 10.1109/PIC.2016.7949499
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Li YJ, 2018, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2018.00054
   Liang WQ, 2021, IEEE T IMAGE PROCESS, V30, P6392, DOI 10.1109/TIP.2021.3092578
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Lin K., 2017, NEURIPS 2017, P3158
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu H, 2017, CAAI T INTELL TECHNO, V2, P48, DOI 10.1016/j.trit.2017.04.001
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu Y., 2021, NEUROCOMPUTING, V435
   Liu YH, 2019, AAAI CONF ARTIF INTE, P8786
   Liu YX, 2021, NEUROCOMPUTING, V435, P1, DOI 10.1016/j.neucom.2021.01.010
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Long MS, 2017, PR MACH LEARN RES, V70
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Meng JK, 2019, PROC CVPR IEEE, P760, DOI 10.1109/CVPR.2019.00085
   Meng JK, 2019, PATTERN RECOGN, V93, P430, DOI 10.1016/j.patcog.2019.04.008
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Munaro M, 2014, ADV COMPUT VIS PATT, P161, DOI 10.1007/978-1-4471-6296-4_8
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Pang L, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P609, DOI 10.1145/3240508.3240606
   Peng CL, 2019, PATTERN RECOGN, V90, P161, DOI 10.1016/j.patcog.2019.01.041
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Radford A., 2015, ARXIV
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen YH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3397
   Shu Rui, 2018, A dirt-t approach to unsupervised domain adaptation
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu D., 2019, COMPUT VIS PATTERN R
   Wu JL, 2019, IEEE I CONF COMP VIS, P8320, DOI 10.1109/ICCV.2019.00841
   Wu JL, 2019, IEEE INT CON MULTI, P886, DOI 10.1109/ICME.2019.00157
   Wu L, 2017, PATTERN RECOGN, V65, P238, DOI 10.1016/j.patcog.2016.12.022
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Wu Y, 2018, AAAI CONF ARTIF INTE, P7412
   Xia B, 2019, IEEE I CONF COMP VIS, P3759, DOI 10.1109/ICCV.2019.00386
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang L., 2018, OBJECT DETECTION REC
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zang JL, 2018, IFIP ADV INF COMM TE, V519, P97, DOI 10.1007/978-3-319-92007-8_9
   Zhang CY, 2019, NEUROCOMPUTING, V340, P259, DOI 10.1016/j.neucom.2019.01.093
   Zhang S, 2019, IEEE ACCESS, V7, P126116, DOI 10.1109/ACCESS.2019.2939071
   Zhang X., 2017, COMPUT VIS PATTERN R
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zhang Z., ARXIV200312224
   Zhang ZZ, 2020, INT CONF CONDIT MON, P404, DOI 10.1109/CVPR42600.2020.01042
   Zhang Z, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1101-x
   Zhang ZF, 2018, NEUROCOMPUTING, V275, P1407, DOI 10.1016/j.neucom.2017.09.080
   Zhao G., 2019, COMPUT VIS PATTERN R
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng Liang., 2016, Person re-identification: Past, present and future
   Zheng M., 2019, RE IDENTIFICATION CO, P5735
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng Z., 2018, OPEN SET ADVERSARIAL
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong WL, 2019, J VIS COMMUN IMAGE R, V62, P267, DOI 10.1016/j.jvcir.2019.06.001
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou SR, 2019, J VIS COMMUN IMAGE R, V59, P393, DOI 10.1016/j.jvcir.2019.01.029
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu X., 2019, COMPUT VIS PATTERN R
   Zhu Xiaoke., 2016, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, P3552
   Zhuang Z., 2018, P ASIAN C COMPUTER V, DOI [10.1007/978-3-030-20893-6_15, DOI 10.1007/978-3-030-20893-6_15]
NR 168
TC 7
Z9 7
U1 13
U2 89
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103418
DI 10.1016/j.jvcir.2021.103418
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I8FF
UT WOS:000779649200006
DA 2024-07-18
ER

PT J
AU Mansouri, S
   Bizaki, HK
   Fakhredanesh, M
AF Mansouri, Saeideh
   Bizaki, Hossein Khaleghi
   Fakhredanesh, Mohammad
TI Reversible data hiding with automatic contrast enhancement using
   two-sided histogram expansion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Reversible contrast enhancement; Two-sided
   histogram shifting; Embedding capacity
ID IMAGE QUALITY ASSESSMENT
AB Recently, reversible data hiding (RDH) has emerged into a new class of data hiding methods that enables exact retrieving of both embedded data and cover medium. In the present study, a novel automatic RDH method with contrast enhancement is proposed, in which the data is embedded through two-sided histogram expansion. Twosided histogram shifting doubles the number of bits embedded at each iteration. Moreover, it preserves the mean brightness of the cover image and prevents it from over enhancement with less calculation. Experimental results on two sets of images show that the proposed method enhances the image contrast at an appropriate level without using a mean brightness controller during data embedding and provides higher information security compared to the existing RDH approaches.
C1 [Mansouri, Saeideh; Bizaki, Hossein Khaleghi; Fakhredanesh, Mohammad] Malek Ashtar Univ Technol, Dept Elect & Comp Engn, Tehran, Iran.
C3 Malek Ashtar University of Technology
RP Bizaki, HK (corresponding author), Malek Ashtar Univ Technol, Dept Elect & Comp Engn, Tehran, Iran.
EM saeideh.mansouri92@gmail.com; bizaki@gmail.com; m-fakhredanesh@aut.ac.ir
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Chen H., 2016, INT C CLOUD COMP SEC
   Chen HS, 2020, COMPUT J, V63, P1584, DOI 10.1093/comjnl/bxaa072
   Chen HS, 2016, SIGNAL PROCESS-IMAGE, V46, P1, DOI 10.1016/j.image.2016.04.006
   Franzen R, 1999, Kodak lossless true color image suite, P4
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gao GY, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107817
   Gao GY, 2017, INFORM SCIENCES, V385, P250, DOI 10.1016/j.ins.2017.01.009
   Gao GY, 2015, IEEE SIGNAL PROC LET, V22, P2078, DOI 10.1109/LSP.2015.2459055
   Gao M.-Z., 2013, Adv. Intell. Syst. Appl., V2, P331, DOI [10.1007/978-3-642-35473-133, DOI 10.1007/978-3-642-35473-133]
   Kim S., 2019, 2019 IEEE 4 INT C IM
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P2271, DOI 10.1109/TCSVT.2018.2869935
   Kim S, 2015, IEEE INT WORKS INFOR
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Ri Y., 2017, INT C INT INF HID MU
   Ri YW, 2017, COMM COM INF SC, V772, P284, DOI 10.1007/978-981-10-7302-1_24
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tohl D, 2019, SIGNAL PROCESS-IMAGE, V71, P45, DOI 10.1016/j.image.2018.10.011
   Wang YM, 2020, IEEE ACCESS, V8, P227036, DOI 10.1109/ACCESS.2020.3044568
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2019, IEEE ACCESS, V7, P83332, DOI 10.1109/ACCESS.2019.2921407
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Xia Y., 2016, 2016 12 INT C COMP I
   Yang Y, 2016, DIGIT SIGNAL PROCESS, V52, P13, DOI 10.1016/j.dsp.2016.02.006
   Ying QC, 2019, IEEE ACCESS, V7, P46506, DOI 10.1109/ACCESS.2019.2909560
   Zhang S.W. Tiancong, J COMPUT SECURITY DA, V1, P60
NR 29
TC 12
Z9 12
U1 3
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103359
DI 10.1016/j.jvcir.2021.103359
EA NOV 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700006
DA 2024-07-18
ER

PT J
AU Kaplan, NH
   Erer, I
AF Kaplan, N. H.
   Erer, I
TI Scale aware remote sensing image enhancement using rolling guidance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image enhancement; Remote sensing images; Rolling guidance filter; Edge
   preserving filters; Multiscale decomposition
ID CONTRAST ENHANCEMENT; HISTOGRAM EQUALIZATION
AB Enhancement of remotely sensed images is a challenging problem, since the enhanced image has to have an improved contrast and edge information while preserving the original radiance values as much as possible. In this paper, a scale aware enhancement method based on rolling guidance is proposed for remotely sensed images. For each scale, a guidance image is defined and the approximation image is provided by an iterative joint filtering of the approximation and guidance images. Then the extracted details are amplified through an adaptive scheme and added to the final level approximation layer to provide the resulting enhanced image. A comparative study between the proposed methods with classical edge preserving filters and traditional methods have been carried out by using several criteria. The proposed methods have an average of 12% improvement for contrast gain (CG) metric and 81% improvement for enhancement measurement (EME) metric compared to the closest comparison method.
C1 [Kaplan, N. H.] Erzurum Tech Univ, Elect & Elect Engn Dept, TR-25050 Erzurum, Turkey.
   [Erer, I] Istanbul Tech Univ, Elect & Commun Engn Dept, TR-34469 Istanbul, Turkey.
C3 Erzurum Technical University; Istanbul Technical University
RP Kaplan, NH (corresponding author), Erzurum Tech Univ, Elect & Elect Engn Dept, TR-25050 Erzurum, Turkey.
EM huseyin.kaplan@erzurum.edu.tr; ierer@itu.edu.tr
RI Kaplan, Nur Hüseyin/H-1771-2016; Kaplan, Nur Hüseyin/JCO-4465-2023
OI Kaplan, Nur Hüseyin/0000-0002-4740-3259; Kaplan, Nur
   Hüseyin/0000-0002-4740-3259
CR Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   [Anonymous], 2018, The USC-SIPI image database
   Celik T, 2012, PATTERN RECOGN, V45, P3810, DOI 10.1016/j.patcog.2012.03.019
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   DigitalGlobe, 2005, 2A DIGITALGLOBE
   Fischer M., 2020, P 13 INT C ADV COMP, P357
   Fisher Y, 2016, INT C LEARN REPR ICL
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Huang ZH, 2021, OPTIK, V226, DOI 10.1016/j.ijleo.2020.165877
   Kamoona AM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105749
   Kaplan NH, 2018, OPTIK, V155, P139, DOI 10.1016/j.ijleo.2017.10.132
   Kaplan NH, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES (RAST), P447, DOI 10.1109/rast.2019.8767443
   Kaplan NH, 2017, PROCEEDINGS OF 8TH INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN SPACE TECHNOLOGIES (RAST 2017), P139, DOI 10.1109/RAST.2017.8002981
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Mayathevar K, 2020, OPTIK, V216, DOI 10.1016/j.ijleo.2020.164927
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Shin J, 2015, IEEE SIGNAL PROC LET, V22, P1293, DOI 10.1109/LSP.2015.2399612
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Suresh S, 2017, IEEE J-STARS, V10, P3665, DOI 10.1109/JSTARS.2017.2699200
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Vu T, 2019, LECT NOTES COMPUT SC, V11133, P243, DOI 10.1007/978-3-030-11021-5_16
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
NR 30
TC 1
Z9 1
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103315
DI 10.1016/j.jvcir.2021.103315
EA SEP 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900004
DA 2024-07-18
ER

PT J
AU Pilarczyk, J
   Janeczko, W
   Sterna, R
   Kuniecki, M
AF Pilarczyk, Joanna
   Janeczko, Weronika
   Sterna, Radoslaw
   Kuniecki, Michal
TI Are emotional objects visually salient? The Emotional Maps Database
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Meaning maps; Saliency; Emotion; Arousal; Natural scenes; Key objects
ID ATTENTION; SCENE; PERCEPTION; REPRESENTATION; PICTURES; DRIVES; SHIFTS;
   OVERT
AB The visual system prioritizes emotional content in natural scenes, but it is unclear whether emotional objects are systematically more salient. We compare emotional maps - created by averaging multiple manual selections of the most meaningful regions in images of negative, positive, and neutral affective valence - with saliency maps generated by Graph-Based Visual Saliency, Proto-object, and SalGAN models. We found that similarity between emotional and saliency maps is modulated by the scenes' arousal and valence ratings: the more negative and high-arousing content, the less it was salient. Simultaneously, the negative and high-arousing content was the easiest to identify by the participants, as shown by the highest inter-individual agreement in the selections. Our results support the "affective gap" hypothesis, i.e., decoupling of emotional meaning from image's formal features. The Emotional Maps Database created for this study, proven useful in gaze fixation prediction, is available online for scientific use.
C1 [Pilarczyk, Joanna; Janeczko, Weronika; Sterna, Radoslaw; Kuniecki, Michal] Jagiellonian Univ, Inst Psychol, Krakow, Poland.
C3 Jagiellonian University
RP Pilarczyk, J (corresponding author), Jagiellonian Univ, Inst Psychol, Krakow, Poland.
EM joanna.pilarczyk@uj.edu.pl; weronika.janeczko@doctoral.uj.edu.pl;
   radoslaw.sterna@doctoral.uj.edu.pl; michal.kuniecki@uj.edu.pl
OI Pilarczyk, Joanna/0000-0002-2654-7536; Kuniecki,
   Michal/0000-0001-6910-8667; Janeczko, Weronika/0000-0001-5493-2151
FU National Science Center in Poland [2012/07/E/HS6/01046,
   2017/25/B/HS6/00758, DI2018 015848]; Ministry of Education and Science
   of Poland
FX This work was supported by the National Science Center in Poland (grant
   numbers 2012/07/E/HS6/01046 and 2017/25/B/HS6/00758) . During work on
   the paper, Radosaw Sterna was supported by the funding from the budget
   for science in the years 2019-2023, as a research project (project
   number DI2018 015848) under the Diamond Grant program financed by the
   Ministry of Education and Science of Poland. We would like to thank
   Piotr Wojcik for technical support in the development of the computer
   tool for data acquisition. We also thank Patrycja Naskrt, Maciej
   Ostrykiewicz, Anna Piekarz, Emilia Schwert-ner, Konrad Szklarski,
   Krzysztof Waniak, and Kinga Wooszyn-Hohol for their assistance in data
   gathering.
CR Acunzo DJ, 2011, EMOTION, V11, P1134, DOI 10.1037/a0022586
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Calvo MG, 2007, J EXP PSYCHOL GEN, V136, P347, DOI 10.1037/0096-3445.136.3.347
   Carter BT, 2020, INT J PSYCHOPHYSIOL, V155, P49, DOI 10.1016/j.ijpsycho.2020.05.010
   Dan-Glauser ES, 2011, BEHAV RES METHODS, V43, P468, DOI 10.3758/s13428-011-0064-1
   Diano M, 2017, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.02029
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3
   Fan SJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P217, DOI 10.1145/3123266.3123445
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   Ferri J, 2013, NEUROIMAGE, V70, P268, DOI 10.1016/j.neuroimage.2012.12.030
   Grill-Spector K, 2001, VISION RES, V41, P1409, DOI 10.1016/S0042-6989(01)00073-6
   Han JW, 2016, IEEE T CYBERNETICS, V46, P487, DOI 10.1109/TCYB.2015.2404432
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Henderson JM, 2003, PERCEPT PSYCHOPHYS, V65, P58, DOI 10.3758/BF03194783
   Henderson JM, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31894-5
   Henderson JM, 2017, NAT HUM BEHAV, V1, P743, DOI 10.1038/s41562-017-0208-0
   Humphrey K, 2012, J VISION, V12, DOI 10.1167/12.1.22
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Keil A, 2003, COGN AFFECT BEHAV NE, V3, P195, DOI 10.3758/CABN.3.3.195
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kuniecki M, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00429
   Kuniecki M, 2015, FRONT HUM NEUROSCI, V9, DOI 10.3389/fnhum.2015.00212
   Lang PJ, 2010, BIOL PSYCHOL, V84, P437, DOI 10.1016/j.biopsycho.2009.10.007
   Lang PJ, 2008, A8 U FLOR
   LIBBY WL, 1973, PSYCHOPHYSIOLOGY, V10, P270, DOI 10.1111/j.1469-8986.1973.tb00526.x
   Libkuman TM, 2007, BEHAV RES METHODS, V39, P326, DOI 10.3758/BF03193164
   Marchewka A, 2014, BEHAV RES METHODS, V46, P596, DOI 10.3758/s13428-013-0379-1
   Markovic J, 2014, BEHAV BRAIN RES, V259, P229, DOI 10.1016/j.bbr.2013.11.018
   Marsman JBC, 2012, HUM BRAIN MAPP, V33, P307, DOI 10.1002/hbm.21211
   McSorley E, 2013, EMOTION, V13, P769, DOI 10.1037/a0032185
   Niu YQ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00336
   Nummenmaa L, 2006, EMOTION, V6, P257, DOI 10.1037/1528-3542.6.2.257
   Nummenmaa L, 2009, J EXP PSYCHOL HUMAN, V35, P305, DOI 10.1037/a0013626
   Öhman A, 2001, J EXP PSYCHOL GEN, V130, P466, DOI 10.1037/0096-3445.130.3.466
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Onat S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093254
   Orquin Jacob L, 2018, Behav Res Methods, V50, P1645, DOI 10.3758/s13428-017-0998-z
   Pan J., 2017, PROC IEEE C COMPUT V
   Peacock CE, 2019, ATTEN PERCEPT PSYCHO, V81, P20, DOI 10.3758/s13414-018-1607-7
   Pedale T, 2019, BRAIN STRUCT FUNCT, V224, P2009, DOI 10.1007/s00429-019-01873-1
   Peng KC, 2016, IEEE IMAGE PROC, P614, DOI 10.1109/ICIP.2016.7532430
   Peng KC, 2015, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2015.7298687
   Pilarczyk J, 2020, VISION RES, V171, P36, DOI 10.1016/j.visres.2020.04.008
   Pilarczyk J, 2019, PSYCHONEUROENDOCRINO, V104, P25, DOI 10.1016/j.psyneuen.2019.02.009
   Pilarczyk J, 2014, J VISION, V14, DOI 10.1167/14.12.4
   Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2
   Pourtois G, 2013, BIOL PSYCHOL, V92, P492, DOI 10.1016/j.biopsycho.2012.02.007
   Reinders AATS, 2005, EUR J NEUROSCI, V22, P524, DOI 10.1111/j.1460-9568.2005.04212.x
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Russell AF, 2014, VISION RES, V94, P1, DOI 10.1016/j.visres.2013.10.005
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schafe GE, 2000, J NEUROSCI, V20, part. no., DOI 10.1523/JNEUROSCI.20-18-j0003.2000
   Schupp HT, 2004, PSYCHOPHYSIOLOGY, V41, P441, DOI 10.1111/j.1469-8986.2004.00174.x
   Stoll J, 2015, VISION RES, V107, P36, DOI 10.1016/j.visres.2014.11.006
   Todd RM, 2012, J NEUROSCI, V32, P11201, DOI 10.1523/JNEUROSCI.0155-12.2012
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wessa M., 2010, KLIN PSYCHOL PSYCHOT, V1, P11
   Wierzba M, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01336
   Yanulevskaya V, 2013, J VISION, V13, DOI 10.1167/13.13.27
   Zhang D., 2021, ARXIV PREPRINT ARXIV
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao SC, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5534
NR 70
TC 0
Z9 0
U1 4
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103221
DI 10.1016/j.jvcir.2021.103221
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA UF2LR
UT WOS:000688410900008
DA 2024-07-18
ER

PT J
AU Liu, KD
   Liu, YW
   Liu, JX
   Argyriou, A
AF Liu, Kedong
   Liu, Yanwei
   Liu, Jinxia
   Argyriou, Antonios
TI Tile caching for scalable VR video streaming over 5G mobile networks*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE VR video; Caching; Video tile; 5G systems
ID EDGE
AB Currently, VR video delivery over 5G systems is still a very complicated endeavor. One of the major challenges for VR video streaming is the expectations for low latency that current mobile networks can hardly meet. Network caching can reduce the content delivery latency efficiently. However, current caching schemes cannot obtain ideal results for VR video since it requests the viewport interactively. In this paper, we propose a tiled scalable VR video caching scheme over 5G networks. VR chunks are first encoded into multi-granularity quality layers, and are then partitioned into tiles to facilitate viewport data access. By accommodating the 5G network infrastructure, the tiles are cooperatively cached in a three-level hierarchal system to reduce delivery latency. Furthermore, a quality-adaptive request routing algorithm is designed to cater for the 5G bandwidth dynamics. Experimental results show that the proposed scheme can reduce the transmission latency over conventional constant bitrate video caching schemes.
C1 [Liu, Kedong; Liu, Yanwei] Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
   [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Peoples R China.
   [Argyriou, Antonios] Univ Thessaly, Volos, Greece.
   [Liu, Kedong] Coordinat Ctr China, Natl Comp Network Emergency Response Tech Team, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Zhejiang Wanli University; University of Thessaly
RP Liu, YW (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing 100093, Peoples R China.
EM liuyanwei@iie.ac.cn
RI Liu, Jinxia/H-1794-2011; Argyriou, Antonios/AAF-9586-2021
OI Argyriou, Antonios/0000-0002-2510-3124
FU National Natural Science Foun-dation of China [61771469]
FX This work was supported in part by National Natural Science Foun-dation
   of China under Grant 61771469.
CR 3rd Generation Partnership Project (3GPP), 2017, Tech. Rep. 38.901
   Abari O, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P531
   Afzal S, 2017, VR/AR NETWORK '17: PROCEEDINGS OF THE 2017 WORKSHOP ON VIRTUAL REALITY AND AUGMENTED REALITY NETWORK, P1, DOI 10.1145/3097895.3097896
   Ahlehagh H, 2014, IEEE ACM T NETWORK, V22, P1444, DOI 10.1109/TNET.2013.2294111
   [Anonymous], 2019, 21915 3GPP TR
   [Anonymous], 1992, DATA NETWORKS
   Borst S, 2010, IEEE INFOCOM SER, DOI 10.1109/infcom.2010.5461964
   Boyce J., 2016, JVETD1030R1
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Chu P, 1997, THESIS MANAGEMENT SC
   Concolato C, 2018, IEEE T CIRC SYST VID, V28, P1981, DOI 10.1109/TCSVT.2017.2688491
   Dai J, 2012, IEEE INFOCOM SER, P2444, DOI 10.1109/INFCOM.2012.6195634
   Dehghani M., 2015, 2015 IEEE Eindhoven PowerTech, P1
   Franky O.E.A., 2016, 2016 INT SEM INT TEC
   Gaddam VR, 2016, IEEE T MULTIMEDIA, V18, P1819, DOI 10.1109/TMM.2016.2586304
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Golrezaei N, 2012, IEEE INFOCOM SER, P1107, DOI 10.1109/INFCOM.2012.6195469
   Hu NN, 2003, IEEE J SEL AREA COMM, V21, P879, DOI 10.1109/JSAC.2003.814505
   Little JDC, 2008, INT SER OPER RES MAN, V115, P81
   Liu K, 2018, PAC RIM C MULT HEF C
   Liu KD, 2019, LECT NOTES COMPUT SC, V11295, P92, DOI 10.1007/978-3-030-05710-7_8
   Liu YW, 2019, IEEE T MULTIMEDIA, V21, P1302, DOI 10.1109/TMM.2018.2876044
   Mahzari A, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P173, DOI 10.1145/3240508.3240680
   Martello Silvano, 1990, Knapsack Problems: Algorithms and Computer Implementations
   Ohl S, 2015, IEEE T VIS COMPUT GR, V21, P1442, DOI 10.1109/TVCG.2015.2407403
   Papaioannou G, 2019, PROCEEDINGS OF THE 2019 THE TWENTIETH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING (MOBIHOC '19), P171, DOI 10.1145/3323679.3326515
   Paschos GS, 2018, IEEE J SEL AREA COMM, V36, P1111, DOI 10.1109/JSAC.2018.2844939
   Patel Milan, 2014, Mobile edge computing-Introductory technical white paper, V29, P854
   Poderys J, 2018, IEEE ACCESS, V6, P8630, DOI 10.1109/ACCESS.2018.2809490
   Prasad A, 2018, IEEE WIREL COMMUNN, P220, DOI 10.1109/WCNCW.2018.8368976
   Qiao J, 2016, IEEE T WIREL COMMUN, V15, P7187, DOI 10.1109/TWC.2016.2598748
   Raidl GR, 1998, IEEE C EVOL COMPUTAT, P207, DOI 10.1109/ICEC.1998.699502
   Schmoll R., 2018, 2018 15 IEEE ANN CON
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Skupin R., 2017, 14 IEEE ANN CONS COM
   Sukhmani S, 2019, IEEE MULTIMEDIA, V26, P21, DOI 10.1109/MMUL.2018.2879591
   Sun LY, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P162, DOI 10.1145/3204949.3204978
   Sun Y., 2018, P IEEE INT C COMM IC, P1
   Wang XF, 2014, IEEE COMMUN MAG, V52, P131, DOI 10.1109/MCOM.2014.6736753
   Xie GG, 2018, IEEE T CIRC SYST VID, V28, P1183, DOI 10.1109/TCSVT.2017.2652487
   Zhao JB, 2017, P IEEE VIRT REAL ANN, P313, DOI 10.1109/VR.2017.7892302
NR 41
TC 3
Z9 3
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103210
DI 10.1016/j.jvcir.2021.103210
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100013
DA 2024-07-18
ER

PT J
AU Ahmed, IAL
   Jaward, MH
AF Ahmed, Ifham Abdul Latheef
   Jaward, Mohamed Hisham
TI Classifier aided training for semantic segmentation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene understanding; Semantic segmentation; Computer vision; Deep
   learning
AB Semantic segmentation is a prominent problem in scene understanding expressed as a dense labeling task with deep learning models being one of the main methods to solve it. Traditional training algorithms for semantic segmentation models produce less than satisfactory results when not combined with post-processing techniques such as CRFs. In this paper, we propose a method to train segmentation models using an approach which utilizes classification information in the training process of the segmentation network. Our method employs the use of classification network that detects the presence of classes in the segmented output. These class scores are then used to train the segmentation model. This method is motivated by the fact that by conditioning the training of the segmentation model with these scores, higher order features can be captured. Our experiments show significantly improved performance of the segmentation model on the CamVid and CityScapes datasets with no additional post processing.
C1 [Ahmed, Ifham Abdul Latheef; Jaward, Mohamed Hisham] Monash Univ Malaysia, Sch Engn Elect & Comp Syst, Subang Jaya, Malaysia.
C3 Monash University; Monash University Malaysia
RP Ahmed, IAL (corresponding author), Monash Univ Malaysia, Sch Engn Elect & Comp Syst, Subang Jaya, Malaysia.
EM ifhamahmed.ai@gmail.com; mohamed.hisham@monash.edu
RI Jaward, Mohamed Hisham/HNR-0504-2023; Jaward, Mohamed Hisham/P-9259-2018
OI Jaward, Mohamed Hisham/0000-0001-8968-4135
FU Malaysian Ministry of Higher Education Exploratory Research Grant Scheme
   [ERGS/1/2013/TK02/MUSM/03/1]
FX This work was supported by Malaysian Ministry of Higher Education
   Exploratory Research Grant Scheme, ERGS/1/2013/TK02/MUSM/03/1. This work
   was also supported by the MASSIVE HPC facility (www.massive.org.au) .
CR Aarthi S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P191
   [Anonymous], 2016, NIPS Workshop on Adversarial Training
   Arnab A, 2018, IEEE SIGNAL PROC MAG, V35, P37, DOI 10.1109/MSP.2017.2762355
   Arnab A, 2016, LECT NOTES COMPUT SC, V9906, P524, DOI 10.1007/978-3-319-46475-6_33
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bolstad W.M., 2007, INTRO BAYESIAN STAT, P55
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Gonfaus JM, 2010, PROC CVPR IEEE, P3280, DOI 10.1109/CVPR.2010.5540048
   Goodfellow, 2017, ARXIV170100160
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grimmett G. R., 1973, Bull. London Math. Soc., V5, P81, DOI [10.1112/blms/5.1.81, DOI 10.1112/BLMS/5.1.81]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   KENDALL A, 2015, ABS151102680 CORR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu ZW, 2018, IEEE T PATTERN ANAL, V40, P1814, DOI 10.1109/TPAMI.2017.2737535
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mohan Rohit, 2020, ARXIV200402307
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tao A., 2020, Arxiv
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Yuan Y., 2019, ARXIV PREPRINT ARXIV
   Zhao W, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8050837
   Zhu XB, 2019, J VIS COMMUN IMAGE R, V58, P532, DOI 10.1016/j.jvcir.2018.11.020
NR 37
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103177
DI 10.1016/j.jvcir.2021.103177
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500008
DA 2024-07-18
ER

PT J
AU Zhang, J
   Li, KK
   Wang, Z
AF Zhang, Jing
   Li, Kangkang
   Wang, Zhe
TI Parallel-fusion LSTM with synchronous semantic and visual information
   for image captioning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image captioning; Parallel-fusion LSTM; Attention mechanism; Guiding
   LSTM
ID NETWORK
AB For synchronously combining the dynamic semantic and visual information in the decoder part of image captioning, we propose a novel parallel-fusion LSTM (pLSTM) structure in this paper. Two parallel LSTMs with attributes and visual information of image are fused by the hidden states at every time step, which makes the attributes and visual information complementary or enhanced for generating more accurate captions. According to the different ways of integrating semantic information from attribute LSTM to visual LSTM, we propose two models pLSTM with attention (pLSTM-A) and pLSTM with guiding (pLSTM-G). pLSTM-A can automatically capture the crucial semantic and visual information to generate captions, and pLSTM-G directly adjusts the hidden state of visual LSTM by synchronous semantic information to the critical region. For verifying the effectiveness of our proposed pLSTM, we conduct a series of experiments on MSCOCO and Flickr30K datasets, and the experimental results outperform some state-of-the-art image captioning methods.
C1 [Zhang, Jing; Li, Kangkang; Wang, Zhe] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
C3 East China University of Science & Technology
RP Zhang, J; Wang, Z (corresponding author), East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM jingzhang@ecust.edu.cn; wangzhe@ecust.edu.cn
RI zhang, xiaoyu/HJI-4374-2023
OI Li, Kangkang/0000-0002-3052-2665
FU National Nature Science Foundation of China [61806078]
FX This research has been supported by the National Nature Science
   Foundation of China (Grant 61806078).
CR Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Chen H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P606
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen S, 2018, LECT NOTES COMPUT SC, V11215, P72, DOI 10.1007/978-3-030-01252-6_5
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Feng J, 2017, AAAI CONF ARTIF INTE, P1884
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kingma D. P., 2014, arXiv
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Simonyan K., 2014, CORR
   Sutskever I, 2014, ADV NEUR IN, V27
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang JB, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107075
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xiao XY, 2019, IEEE T MULTIMEDIA, V21, P2942, DOI 10.1109/TMM.2019.2915033
   Xiao XY, 2019, PATTERN RECOGN, V90, P285, DOI 10.1016/j.patcog.2019.01.028
   Xu K., IEEE INT C MACH LEAR, P2048
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang ZJ, 2019, IEEE T MULTIMEDIA, V21, P1681, DOI 10.1109/TMM.2018.2888822
NR 42
TC 14
Z9 15
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103044
DI 10.1016/j.jvcir.2021.103044
EA FEB 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600005
DA 2024-07-18
ER

PT J
AU Sridhar, S
   Sudha, GF
AF Sridhar, Srividhya
   Sudha, Gnanou Florence
TI Two in One Image Secret Sharing Scheme (TiOISSS) for extended
   progressive visual cryptography using simple modular arithmetic
   operations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual Cryptography; Progressive; Polynomial; Meaningful shares and
   Modular Arithmetic
ID QUALITY; CONSTRUCTIONS; RECOVERY
AB Existing Extended Progressive Visual Cryptography scheme (EPVCS) suffers from the problem of pixel expansion, poor quality of reconstructed image and residual trace of cover images in the reconstructed image. Hence in this paper, Two in One Image secret sharing scheme for EPVCS is proposed which decodes the encrypted image in two stages. The proposed scheme provides (k, n) threshold construction using meaningful shares without pixel expansion and demonstrates that the reconstructed image has improved quality compared to the existing schemes. To reduce the computational complexity, the proposed scheme uses simple Modular Arithmetic operations instead of Galois field. The proposed scheme has the additional advantages of supporting any value of k and n, no overhead in resizing the secret image and no residual trace of cover image. Simulation results and performance analysis show the effectiveness of proposed scheme with improved contrast, 99% Structural Similarity of the reconstructed image and good progressive reconstruction.
C1 [Sridhar, Srividhya; Sudha, Gnanou Florence] Pondicherry Engn Coll, Dept Elect & Commun Engn, Pondicherry, India.
C3 Pondicherry Engineering College
RP Sridhar, S (corresponding author), Pondicherry Engn Coll, Dept Elect & Commun Engn, Pondicherry, India.
EM srividhya2207@gmail.com; gfsudha@pec.edu
RI Sudha, Gnanou Florence/GLU-3814-2022
OI Sudha, Gnanou Florence/0000-0002-5471-3255
CR Chao HC, 2018, MULTIMED TOOLS APPL, V77, P11867, DOI 10.1007/s11042-017-4836-1
   Chao HC, 2017, DISPLAYS, V49, P6, DOI 10.1016/j.displa.2017.05.004
   Chao HC, 2017, DIGIT SIGNAL PROCESS, V68, P69, DOI 10.1016/j.dsp.2017.05.009
   Chen TH, 2018, MULTIMED TOOLS APPL, V77, P7865, DOI 10.1007/s11042-017-4680-3
   Chiu PL, 2019, SIGNAL PROCESS, V165, P233, DOI 10.1016/j.sigpro.2019.06.038
   Chiu PL, 2015, SIGNAL PROCESS, V108, P476, DOI 10.1016/j.sigpro.2014.09.032
   Fan TY, 2018, IET INFORM SECUR, V12, P398, DOI 10.1049/iet-ifs.2017.0546
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Jeng Fuh-gwo, 2014, Journal of Shanghai Jiaotong University (Science), V19, P455, DOI 10.1007/s12204-014-1525-3
   Lee JS, 2015, DIGIT SIGNAL PROCESS, V40, P131, DOI 10.1016/j.dsp.2015.02.012
   Li P, 2018, J REAL-TIME IMAGE PR, V14, P41, DOI 10.1007/s11554-016-0621-z
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin CH, 2015, J VIS COMMUN IMAGE R, V33, P31, DOI 10.1016/j.jvcir.2015.08.018
   Lin KS, 2014, INFORM SCIENCES, V288, P330, DOI 10.1016/j.ins.2014.07.016
   Liu X, 2018, MULTIMED TOOLS APPL, V77, P20673, DOI 10.1007/s11042-017-5482-3
   Mhala NC, 2019, SIGNAL PROCESS, V162, P253, DOI 10.1016/j.sigpro.2019.04.023
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Srividhya S, 2016, J VIS COMMUN IMAGE R, V38, P284, DOI 10.1016/j.jvcir.2016.03.012
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang S, 2016, MULTIMED TOOLS APPL, V75, P3353, DOI 10.1007/s11042-014-2438-8
   Wu XT, 2019, J VIS COMMUN IMAGE R, V61, P74, DOI 10.1016/j.jvcir.2019.03.020
   Wu XT, 2018, SIGNAL PROCESS-IMAGE, V66, P42, DOI 10.1016/j.image.2018.05.001
   Yan X., 2014, SIVIP, V9, P1659
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2017, DIGIT SIGNAL PROCESS, V71, P36, DOI 10.1016/j.dsp.2017.08.006
   Yan XH, 2016, MULTIMED TOOLS APPL, V75, P8657, DOI 10.1007/s11042-015-2779-y
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yan XH, 2014, SIGNAL PROCESS, V105, P389, DOI 10.1016/j.sigpro.2014.06.011
   Yang CN, 2017, J VIS COMMUN IMAGE R, V42, P121, DOI 10.1016/j.jvcir.2016.10.014
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 33
TC 7
Z9 7
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102996
DI 10.1016/j.jvcir.2020.102996
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900004
DA 2024-07-18
ER

PT J
AU Wang, YH
   Zhao, RZ
   Liang, LQ
   Zheng, XW
   Cen, YG
   Kan, SC
AF Wang, Yanhong
   Zhao, Ruizhen
   Liang, Liequan
   Zheng, Xinwei
   Cen, Yigang
   Kan, Shichao
TI Block-based image matching for image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Composite descriptors; Block index; Vector of locally aggregated
   descriptors; Image matching; Feature fusion; Deep feature; Image
   retrieval
AB Due to the lighting, translation, scaling and rotation, image matching is a challenge task in computer vision area. In the past decades, local descriptors (e.g. SIFT, SURF and HOG, etc.) and global features (e.g. HSV, CNN, etc.) play a vital role for this task. However, most image matching methods are based on the whole image, i.e., matching the entire image directly base on some image representation methods (e.g. BoW, VLAD and deep learning, etc.). In most situations, this idea is simple and effective, but we recognize that a robust image matching can be realized based on sub-images. Thus, a block-based image matching algorithm is proposed in this paper. First, a new local composite descriptor is proposed, which combines the advantages of local gradient and color features with spatial information. Then, VLAD method is used to encode the proposed composite descriptors in one block, and block-CNN feature is extracted at the same time. Second, a block-based similarity metric is proposed for similarity calculation of two images. Finally, the proposed methods are verified on several benchmark datasets. Compared with other methods, experimental results show that our method achieves better performance.
C1 [Wang, Yanhong] Tianjin Foreign Studies Univ, Sch Commun, Tianjin 300204, Peoples R China.
   [Wang, Yanhong; Zhao, Ruizhen; Cen, Yigang; Kan, Shichao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100081, Peoples R China.
   [Zhao, Ruizhen; Cen, Yigang; Kan, Shichao] Key Lab Adv Informat Sci & Network Technol Beijin, Beijing 100081, Peoples R China.
   [Liang, Liequan; Zheng, Xinwei] Guangdong Univ Finance & Econ, Informat Sci Sch, Guangzhou 510320, Guangdong, Peoples R China.
C3 Tianjin Foreign Studies University; Beijing Jiaotong University;
   Guangdong University of Finance & Economics
RP Cen, YG (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100081, Peoples R China.
EM ygcen@bjtu.edu.cn
RI wang, yiran/IAP-0414-2023; Cen, Yigang/AAC-1999-2019; SUN,
   Ye/KBC-8159-2024; Wang, Yanbo/HFZ-8018-2022; wang, yan/GSE-6489-2022;
   Wang, Ying/HJI-2509-2023; wang, yi/GVT-8516-2022; wangwangwang,
   yuanyaunyuan/HHN-6432-2022; wang, yan/JBJ-7462-2023; Wang,
   Yuan/HHC-1520-2022; Wang, Yu/GZL-9655-2022; wang, yi/HOF-6668-2023;
   Wang, Yin/HCI-9352-2022
FU National Natural Science Foundation of China [61872034, 62011530042];
   Beijing Municipal Natural Science Foundation [4202055]; Science and
   Technology Program of Guangzhou [201804010271]; Natural Science
   Foundation of Guizhou Province [[2019]1064]; Key scientific research
   platforms and projects of Guangdong Universities [2018KTSCX071]
FX This work was supported by National Natural Science Foundation of China
   (61872034, 62011530042); The Beijing Municipal Natural Science
   Foundation under Grant (4202055); The Science and Technology Program of
   Guangzhou (201804010271); The Natural Science Foundation of Guizhou
   Province ([2019]1064); Key scientific research platforms and projects of
   Guangdong Universities (2018KTSCX071).
CR Alzu'bi A, 2015, INT CONF SYST SIGNAL, P253, DOI 10.1109/IWSSIP.2015.7314224
   [Anonymous], 2012, IM AN MULT INT SERV
   [Anonymous], 2016, EUR C COMP VIS
   [Anonymous], 2009, IEEE T IMAGE PROCESS
   [Anonymous], 2014, BMVC
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Fan P, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P726, DOI 10.1109/ICNIDC.2009.5360809
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jiang YN, 2012, PROC CVPR IEEE, P3100, DOI 10.1109/CVPR.2012.6248042
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kan S.C., 2017, J VISUAL COMMUN IMAG, V49
   Kan SC, 2020, PATTERN RECOGN, V99, DOI 10.1016/j.patcog.2019.107086
   Kan SC, 2019, IEEE T IMAGE PROCESS, V28, P5809, DOI 10.1109/TIP.2019.2901407
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Z., 2012, P ACM INT C MULTIMED, P199
   Perronnin F., 2007, P IEEE CVPR, P1
   Philbin J., 2008, IM DAT P IEEE C COMP
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2
   Sicre R, 2014, IEEE IMAGE PROC, P3057, DOI 10.1109/ICIP.2014.7025618
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   Vigo David A. Rojas, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1549, DOI 10.1109/ICPR.2010.383
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Yu J., 2019, IEEE T NEUR NET LEAR
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang SL, 2011, IEEE T IMAGE PROCESS, V20, P2664, DOI 10.1109/TIP.2011.2128333
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 37
TC 6
Z9 6
U1 2
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102998
DI 10.1016/j.jvcir.2020.102998
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900002
DA 2024-07-18
ER

PT J
AU Ou, Y
   Luo, JQ
   Li, BL
   Swamy, MNS
AF Ou, Yang
   Luo, Jianqiao
   Li, Bailin
   Swamy, M. N. S.
TI Gray-level image denoising with an improved weighted sparse coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Nonlocal self-similarity; Weight matrix; Weighted
   sparse coding
ID ALGORITHM; FRAMEWORK; REPRESENTATION; MINIMIZATION; RESTORATION
AB The nonlocal self-similarity of images means that groups of similar patches have low-dimensional property. The property has been previously used for image denoising, with particularly notable success via sparse coding. However, only a few studies have focused on the varying statistics of noise in different similar patches during the iterative denoising process. This has motivated us to introduce an improved weighted sparse coding for gray-level image denoising in this paper. On the basis of traditional sparse coding, we introduce a weight matrix to account for the noise variation characteristics of different similar patches, while introduce another weight matrix to make full use of the sparsity priors of natural images. The Maximum A-Posterior estimation (MAP) is used to obtain the closed-form solution of the proposed method. Experimental results demonstrate the competitiveness of the proposed method compared with that of state-of-the-art methods in both the objective and perceptual quality.
C1 [Ou, Yang; Luo, Jianqiao; Li, Bailin] Southwest Jiaotong Univ, Sch Mech Engn, Chengdu 610031, Peoples R China.
   [Swamy, M. N. S.] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Southwest Jiaotong University; Concordia University - Canada
RP Li, BL (corresponding author), Southwest Jiaotong Univ, Sch Mech Engn, Chengdu 610031, Peoples R China.
EM blli62@swjtu.edu.cn
RI Ou, Yang/HNG-6403-2023
OI Jianqiao, Luo/0000-0002-7432-1531
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cai N, 2016, SIGNAL IMAGE VIDEO P, V10, P993, DOI 10.1007/s11760-015-0850-9
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai T, 2015, IEEE IMAGE PROC, P4406, DOI 10.1109/ICIP.2015.7351639
   Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fedorov V, 2017, IEEE T IMAGE PROCESS, V26, P2137, DOI 10.1109/TIP.2017.2681421
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo J, 2019, NEURAL COMPUT APPL, V31, P5097, DOI 10.1007/s00521-018-04001-y
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   Huang YM, 2018, INFORM SCIENCES, V429, P147, DOI 10.1016/j.ins.2017.10.047
   Iqbal A, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922074
   Jia XX, 2016, SIGNAL PROCESS, V129, P1, DOI 10.1016/j.sigpro.2016.05.026
   Kumar A, 2019, IEEE ACCESS, V7, P26200, DOI 10.1109/ACCESS.2019.2901691
   Kumar A, 2019, IEEE T IMAGE PROCESS, V28, P2921, DOI 10.1109/TIP.2019.2892663
   Kumar A, 2019, ISA T, V85, P293, DOI 10.1016/j.isatra.2018.10.030
   Kumar A, 2018, INFORM SCIENCES, V454, P292, DOI 10.1016/j.ins.2018.05.001
   Li J, 2019, CHIN CONT DECIS CONF, P3338, DOI [10.1109/ccdc.2019.8833239, 10.1109/CCDC.2019.8833239]
   Liu XH, 2013, IEEE T IMAGE PROCESS, V22, P5226, DOI 10.1109/TIP.2013.2283400
   Lu CW, 2013, PROC CVPR IEEE, P415, DOI 10.1109/CVPR.2013.60
   Luo EM, 2016, IEEE T IMAGE PROCESS, V25, P4489, DOI 10.1109/TIP.2016.2590318
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Paraineswaran S, 2019, IEEE T IMAGE PROCESS, V28, P687, DOI 10.1109/TIP.2018.2866691
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JF, 2018, INT J MOD PHYS E, V27, DOI 10.1142/S0218301318500064
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Zha ZY, 2018, NEUROCOMPUTING, V275, P2294, DOI 10.1016/j.neucom.2017.11.004
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 39
TC 13
Z9 13
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102895
DI 10.1016/j.jvcir.2020.102895
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400011
DA 2024-07-18
ER

PT J
AU Ameur, S
   Ben Khalifa, A
   Bouhlel, MS
AF Ameur, Safa
   Ben Khalifa, Anouar
   Bouhlel, Med Salim
TI Chronological pattern indexing: An efficient feature extraction method
   for hand gesture recognition with Leap Motion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Leap Motion; Hand gesture recognition; Feature extraction; Time series
   data; Chronological indexing
ID SIGN-LANGUAGE; FUSION; CONTROLLER; SYSTEM; VIDEO; TIME
AB Recently, Hand-Gesture-Recognition (HGR) systems has appreciably change the way of interaction between humans and computers thanks to advanced sensor technologies like the Leap-Motion-Controller (LMC). Despite the success achieved by many state-of-the-art methods, they have not worked on the rich temporal information existing in the sequential hand gesture data and characterizing the discriminative representation of different hand gesture classes. In this paper, we suggest a novel Chronological-Pattern-Indexing (CPI) approach which encodes the temporal orders of patterns for hand gesture time series data acquired by the LMC sensor. We extract a set of temporal patterns from different optimized projections. Then, we compare their temporal order and we encode the whole sequence with the index of the first coming pattern. We repeat these steps until we generate an efficient feature vector modeling the chronological dynamics of the hand gesture. The experiments demonstrate the potential of the proposed CPI approach for HGR systems. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Ben Khalifa, Anouar] Univ Sousse, LATIS Lab Adv Technol & Intelligent Syst, Ecole Natl Ingenieurs Sousse, Sousse 4023, Tunisia.
   [Ameur, Safa] Univ Sousse, Ecole Natl Ingenieurs Sousse, Sousse 4023, Tunisia.
   [Ameur, Safa; Bouhlel, Med Salim] Univ Sfax, Inst Super Biotechnol Sfax, SETIT Res Unit Sci Elect Technol Informat & Telec, Sfax 3038, Tunisia.
C3 Universite de Sousse; Universite de Sousse; Universite de Sfax
RP Ben Khalifa, A (corresponding author), ENISo, Sousse 4023, Tunisia.
EM anouar.benkhalifa@eniso.rnu.tn
RI BOUHLEL, Med Salim/B-6261-2019; BEN KHALIFA, Anouar/AAG-1860-2020
OI BOUHLEL, Med Salim/0000-0003-2952-3967; BEN KHALIFA,
   Anouar/0000-0002-9946-0829; AMEUR, Safa/0000-0003-3343-5388
CR Aliyu S, 2017, INT MULTICONF SYST, P611, DOI 10.1109/SSD.2017.8167010
   Almasre M. A., 2016, IJAEMS OPEN ACCESS I, V2, P514
   Ameur Safa, 2016, 2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), P514, DOI 10.1109/SETIT.2016.7939924
   Atas M, 2017, IEEE ACCESS, V5, P23320, DOI 10.1109/ACCESS.2017.2764471
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Ben Abdallah M, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON SCIENCES OF ELECTRONICS, TECHNOLOGIES OF INFORMATION AND TELECOMMUNICATIONS (SETIT), P20, DOI 10.1109/SETIT.2012.6481883
   Ben Khalifa A, 2020, COGN SYST RES, V60, P77, DOI 10.1016/j.cogsys.2019.12.003
   Berndt DJ, 1994, P 3 INT C KNOWL DISC, P359, DOI DOI 10.5555/3000850.3000887
   Chopade P., 2018, IEEE International Symposium on Technologies for Homeland Security, P1
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Cui J, 2018, COMPUT GRAPH-UK, V74, P1, DOI 10.1016/j.cag.2018.04.004
   Cui J, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P41, DOI 10.1109/CW.2016.14
   Deriche M, 2019, IEEE SENS J, V19, P8067, DOI 10.1109/JSEN.2019.2917525
   Dharmayasa IGA, 2017, 2017 TRON SYMPOSIUM (TRONSHOW)
   Ding I, 2018, COMPUT ELECTR ENG, V69, P815, DOI 10.1016/j.compeleceng.2018.02.041
   Dipietro L, 2008, IEEE T SYST MAN CY C, V38, P461, DOI 10.1109/TSMCC.2008.923862
   ElBadawy M, 2015, ADV INTELL SYST, V323, P721, DOI 10.1007/978-3-319-11310-4_63
   Elons AS, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P368, DOI 10.1109/ICCES.2014.7030987
   Eqab A, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTING TECHNOLOGIES AND APPLICATIONS (ICECTA), P675
   Cardenas EJE, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102772
   Fasihuddin H, 2018, 2018 INTERNATIONAL CONFERENCE ON SMART COMPUTING AND ELECTRONIC ENTERPRISE (ICSCEE)
   Fok KY, 2015, IEEE INT SYMP CIRC S, P1904, DOI 10.1109/ISCAS.2015.7169037
   Fok KY, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY, P411, DOI 10.1109/CyberC.2015.81
   Funasaka M., 2015, Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications (PDPTA), P263
   Ganguly B., 2019, LECT NOTES ELECT ENG, P139, DOI [10.1007/978-981-13-8687-9_13., DOI 10.1007/978-981-13-8687-9_13.]
   Izard SG, 2018, SIXTH INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ECOSYSTEMS FOR ENHANCING MULTICULTURALITY (TEEM'18), P397, DOI 10.1145/3284179.3284247
   Guerra-Segura E, 2017, MEASUREMENT, V105, P87, DOI 10.1016/j.measurement.2017.04.016
   Han J., 2014, P INT C NEW INT MUS
   Harth J, 2018, IEEE CONSUM ELECTR M, V7, P36, DOI 10.1109/MCE.2018.2816218
   Hisham B., 2017, J. Comput. Sci, V13, P337, DOI DOI 10.3844/JCSSP.2017.337.354
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu JT, 2015, INT C CONTR AUTOMAT, P1885, DOI 10.1109/ICCAS.2015.7364671
   Huang XA, 2019, IEEE SENS J, V19, P9504, DOI 10.1109/JSEN.2019.2924797
   Jaouedi Neziha, 2016, 2016 7th International Conference on Sciences of Electronics, Technologies of Information and Telecommunications (SETIT), P263, DOI 10.1109/SETIT.2016.7939877
   Jegham I, 2019, LECT NOTES COMPUT SC, V11678, P518, DOI 10.1007/978-3-030-29888-3_42
   Jegham I, 2020, FORENS SCI INT-DIGIT, V32, DOI 10.1016/j.fsidi.2019.200901
   Jegham I, 2018, INT C MICROELECTRON, P60, DOI 10.1109/ICM.2018.8704009
   Jegham I, 2017, I C COMP SYST APPLIC, P358, DOI 10.1109/AICCSA.2017.35
   Jiang XT, 2018, VIRTUAL REAL-LONDON, V22, P297, DOI 10.1007/s10055-018-0339-2
   Jin HY, 2016, CAAI T INTELL TECHNO, V1, P104, DOI 10.1016/j.trit.2016.03.010
   Kadam Bhushan R., 2016, IJSRD INT J SCI RES, V4
   Khelil B., 2016, P 3 INT C AUT CONTR
   Kincaid CJ, 2019, MED ENG PHYS, V63, P72, DOI 10.1016/j.medengphy.2018.11.001
   Krastev Georgi, 2015, International Journal of Computer Science & Information Technology, V7, P145, DOI 10.5121/ijcsit.2015.7612
   Kumar P, 2017, NEUROCOMPUTING, V259, P21, DOI 10.1016/j.neucom.2016.08.132
   Kumar P, 2017, PATTERN RECOGN LETT, V86, P1, DOI 10.1016/j.patrec.2016.12.004
   Lavy David, 2015, VIRTUAL SHAPE RECOGN
   Lee AR, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105385
   Lejmi W, 2019, LECT NOTES COMPUT SC, V11679, P62, DOI 10.1007/978-3-030-29891-3_6
   Lejmi W, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P682, DOI 10.1109/FSKD.2017.8393354
   Lejmi W, 2017, I C COMP SYST APPLIC, P178, DOI 10.1109/AICCSA.2017.193
   Li Wen-Jeng., 2017, 2017 INT C APPL SYST, P386, DOI [DOI 10.1109/ICASI.2017.7988433, 10.1109/ICASI.2017.7988433]
   Liao B, 2018, INT CONF INFO SCI, P84, DOI 10.1109/ICIST.2018.8426125
   Lu W, 2016, IEEE SIGNAL PROC LET, V23, P1188, DOI 10.1109/LSP.2016.2590470
   Mapari RB, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P323, DOI 10.1109/ICRCICN.2015.7434258
   Mapari Rajesh B., 2016, PROC 2 INT C INFORM, DOI [10.1145/2905055.2905125, DOI 10.1145/2905055.2905125]
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Mimouna A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040560
   Mimouna A, 2018, INT MULTICONF SYST, P491, DOI 10.1109/SSD.2018.8570429
   Mittal A, 2019, IEEE SENS J, V19, P7056, DOI 10.1109/JSEN.2019.2909837
   Mohandes M, 2014, PROC IEEE INT SYMP, P960, DOI 10.1109/ISIE.2014.6864742
   Moharram MA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL ELECTROMAGNETICS (ICCEM), P5, DOI 10.1109/COMPEM.2015.7052535
   Moreira TP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102771
   Mustafa AW, 2018, P INT C VIRTUAL SYST, P1
   Naglot D, 2016, 2016 INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT), VOL 2, P73
   Nigam I, 2014, IEEE IMAGE PROC, P5012, DOI 10.1109/ICIP.2014.7026015
   Nymoen K., 2015, P INT C NEW INTERFAC, P1, DOI [10.5555/2993778.2993834, DOI 10.5555/2993778.2993834]
   Pambudi RA, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P142, DOI 10.1109/ELECSYM.2016.7860991
   Pititeeraphab Y, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING (BME-HUST), P109, DOI 10.1109/BME-HUST.2016.7782091
   Polfreman R., 2018, P INT C NEW INT MUS, P249
   Ponraj G, 2018, IEEE SENS J, V18, P2042, DOI 10.1109/JSEN.2018.2790801
   Potter L.E., 2013, P 25 AUSTR COMPUTER, P175, DOI [10.1145/2541016.2541072, DOI 10.1145/2541016.2541072]
   Quesada L, 2015, LECT NOTES COMPUT SC, V9454, P277, DOI 10.1007/978-3-319-26401-1_26
   Quivira Fernando, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P166, DOI 10.1109/BHI.2018.8333395
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Ricardez G.A. G., 2018, 2018 14th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA), P1, DOI DOI 10.1109/MESA.2018.8449178
   Rossol N, 2016, IEEE T HUM-MACH SYST, V46, P350, DOI 10.1109/THMS.2015.2467212
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Seddik B., 2014, 2014 1 INT IM PROC, DOI 10.1109/ipas.2014.7043295
   Simos M, 2016, 9TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2016), DOI 10.1145/2903220.2903249
   Singla A, 2019, DISPLAYS, V57, P18, DOI 10.1016/j.displa.2019.03.001
   Taranta EM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5850, DOI 10.1145/3025453.3026002
   Vikram S., 2013, P CHI 2013 PAR FRANC
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Xie QC, 2017, IOP CONF SER-MAT SCI, V187, DOI 10.1088/1757-899X/187/1/012015
   Yuan J., 2015, INT C IM PROC COMP V
   Zaiti IA, 2015, PERS UBIQUIT COMPUT, V19, P821, DOI 10.1007/s00779-015-0863-y
   Zhang QX, 2017, J PHYS CONF SER, V910, DOI 10.1088/1742-6596/910/1/012037
   Zhao D, 2018, ADVANCED FUNCTIONAL MATERIALS (CMC 2017), P1, DOI 10.1007/978-981-13-0110-0_1
NR 90
TC 12
Z9 14
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102842
DI 10.1016/j.jvcir.2020.102842
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900026
DA 2024-07-18
ER

PT J
AU Qi, BJ
   Yang, CF
   Tan, L
   Luo, XY
   Liu, FL
AF Qi, Baojun
   Yang, Chunfang
   Tan, Lei
   Luo, Xiangyang
   Liu, Fenlin
TI A novel haze image steganography method via cover-source switching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Haze image; Natural steganography; UNIWARD; Steganalysis
ID FRAMEWORK; WEATHER; VISION
AB In realistic outdoor scenarios, image sensors tend to suffer from various weather conditions (e.g., haze, rain, etc.), which make the images of the same scene taken at different times may be different. Therefore, one should be able to securely embed secret messages into these images by making use of the variations of the weather effects. Inspired by some recent natural steganography algorithms, this paper presents a novel haze image steganography method, which embeds messages through adjusting the weather effects of an input haze image, making it resemble the same image captured under another weather condition. The proposed steganography method consists of three parts: (1) model parameter estimation of the input haze image, (2) haze effects adjustment according to the atmospheric scattering model, (3) message embedding using the floating-point adjusted haze image. 10,000 haze images captured under different haze conditions in various scenarios were used to test the proposed steganography algorithm. The experimental results show that the proposed steganography algorithm is more secure than S-UNIWARD and HILL for steganalyzers who only have raw haze images. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Qi, Baojun; Yang, Chunfang; Tan, Lei; Luo, Xiangyang; Liu, Fenlin] PLA Strateg Support Force Informat Engn Univ, 62 Kexue Rd, Zhengzhou 450001, Peoples R China.
C3 PLA Information Engineering University
RP Yang, CF (corresponding author), PLA Strateg Support Force Informat Engn Univ, 62 Kexue Rd, Zhengzhou 450001, Peoples R China.
EM chunfangyang@126.com
FU National Natural Science Foundation of China [61872448, U1536104,
   61772549, U1736214, 61602508, 61601517]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61872448, U1536104, 61772549, U1736214, 61602508, 61601517).
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti C, 2018, LECT NOTES COMPUT SC, V11182, P620, DOI 10.1007/978-3-030-01449-0_52
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   [Anonymous], 2018, P EL IM MED WAT SEC
   [Anonymous], 2019, IEEE T MULTIMEDIA, DOI DOI 10.1080/09603123.2019.1682528
   Bas P, 2016, IEEE INT WORKS INFOR
   Bas P, 2017, INT CONF ACOUST SPEE, P2127, DOI 10.1109/ICASSP.2017.7952532
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Denemark T, 2017, INT CONF ACOUST SPEE, P2117, DOI 10.1109/ICASSP.2017.7952530
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   Hautiere N, 2007, PROC CVPR IEEE, P2216
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2075239
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yin ZB, 2019, ICBBE 2019: 2019 6TH INTERNATIONAL CONFERENCE ON BIOMEDICAL AND BIOINFORMATICS ENGINEERING, P1, DOI 10.1145/3375923.3375933
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
NR 38
TC 7
Z9 7
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102814
DI 10.1016/j.jvcir.2020.102814
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900020
DA 2024-07-18
ER

PT J
AU Wang, M
   Hou, SY
   Li, HF
   Li, F
AF Wang, Meng
   Hou, Shengyu
   Li, Huafeng
   Li, Fan
TI Generative image deblurring based on multi-scaled residual adversary
   network driven by composed prior-posterior loss
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deblurring; Generative adversarial network; Residual learning;
   Prior distribution; Histogram of gradients
AB Conditional Generative Adversarial Networks (CGANs) have been introduced to generate realistic images from extremely degraded inputs. However, these generative models without prior knowledge of spatial distributions has limited performance to deal with various complex scenes. In this paper, we proposed a image deblurring network based on CGANs to generate ideal images without any blurring assumption. To overcome adversarial insufficiency, an extended classifier with different attribute domains is formulated to replace the original discriminator of CGANs. Inspired by residual learning, a set of skip-connections are cohered to transfer multi-scaled spatial features to the following high-level operations. Furthermore, this adversary architecture is driven by a composite loss that integrates histogram of gradients (HoG) and geodesic distance. In experiments, an uniformed adversarial iteration is circularly applied to improve image degenerations. Extensive results show that the proposed deblurring approach significantly outper-forms state-of-the-art methods on both qualitative and quantitative evaluations. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Meng; Hou, Shengyu; Li, Huafeng; Li, Fan] Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
   [Wang, Meng; Hou, Shengyu; Li, Huafeng; Li, Fan] Kunming Univ Sci & Technol, Yunnan Key Lab Artificial Intelligence, Kunming 650500, Yunnan, Peoples R China.
C3 Kunming University of Science & Technology; Kunming University of
   Science & Technology
RP Wang, M (corresponding author), Kunming Univ Sci & Technol, Fac Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
EM vicong68@qq.com
OI Li, Huafeng/0000-0003-2462-6174
FU National Natural Science Foundation of China [61563025, 61562053,
   61762056]; Yunnan Science and Technology Department of Science and
   Technology Project [2016FB109, 2017FB094]
FX This research was funded by National Natural Science Foundation of China
   (61563025, 61562053, 61762056), Yunnan Science and Technology Department
   of Science and Technology Project (2016FB109, 2017FB094).
CR Almeida MSC, 2008, INT CONF ACOUST SPEE, P1261, DOI 10.1109/ICASSP.2008.4517846
   [Anonymous], 2007, Blind Image Deconvolution: Theory and Applications
   [Anonymous], 2011, TEXTS COMPUT SCI
   [Anonymous], 2016, P ADV NEUR INF PROC
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P1302, DOI 10.1109/TIP.2015.2400217
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cole F, 2017, PROC CVPR IEEE, P3386, DOI 10.1109/CVPR.2017.361
   Emami H, 2018, MED PHYS, V45, P3627, DOI 10.1002/mp.13047
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta R, 2010, PRINCIPLES OF PULMONARY PROTECTION IN HEART SURGERY, P171, DOI 10.1007/978-1-84996-308-4_19
   Harmeling Stefan, 2010, P ADV NEUR INF PROC, P829
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HILLERY AD, 1991, IEEE T SIGNAL PROCES, V39, P1892, DOI 10.1109/78.91161
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Jia JY, 2007, PROC CVPR IEEE, P453
   Joshi N, 2008, PROC CVPR IEEE, P3823
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kovács G, 2017, PATTERN RECOGN LETT, V100, P44, DOI 10.1016/j.patrec.2017.09.023
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kupyn O., 2013, P IEEE C COMP VIS PA, P8183
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li HF, 2020, IEEE T INSTRUM MEAS, V69, P1082, DOI 10.1109/TIM.2019.2912239
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Likas AC, 2004, IEEE T SIGNAL PROCES, V52, P2222, DOI 10.1109/TSP.2004.831119
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mahalakshmi A, 2016, INT CONF COMP COMMUN
   Miskin J, 2000, PERSP NEURAL COMP, P123
   Molina R, 1997, INT CONF ACOUST SPEE, P2809, DOI 10.1109/ICASSP.1997.595373
   Molina R, 2006, IEEE T IMAGE PROCESS, V15, P3715, DOI 10.1109/TIP.2006.881972
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WQ, 2016, IEEE T IMAGE PROCESS, V25, P3426, DOI 10.1109/TIP.2016.2571062
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Sun LX, 2013, PART FIBRE TOXICOL, V10, DOI 10.1186/1743-8977-10-43
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Wang YJ, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P994
   WHITE RL, 1994, P SOC PHOTO-OPT INS, V2198, P1342, DOI 10.1117/12.176819
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Wong HS, 2001, IEEE T NEURAL NETWOR, V12, P516, DOI 10.1109/72.925555
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yan RM, 2016, IEEE T IMAGE PROCESS, V25, P1910, DOI 10.1109/TIP.2016.2535273
   Yao HW, 2018, IEEE ACCESS, V6, P24973, DOI 10.1109/ACCESS.2018.2832066
   Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
NR 54
TC 12
Z9 12
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102648
DI 10.1016/j.jvcir.2019.102648
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700009
DA 2024-07-18
ER

PT J
AU Corcoran, P
   Zunic, J
   Rosin, PL
AF Corcoran, Padraig
   Zunic, Jovisa
   Rosin, Paul L.
TI A multi-scale topological shape model for single and multiple component
   shapes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple component shapes; Topology; Multi-scale; Persistent homology
ID PERSISTENT HOMOLOGY; REPRESENTATION; FEATURES
AB A novel shape model of multi-scale topological features is proposed which considers those features relating to connected components and holes. This is achieved by considering the persistent homology of a pair of sublevel set functions corresponding to a pair of distance functions defined on the ambient space. The model is applicable to both single and multiple component shapes and, to the authors knowledge, is the first shape model to consider multi-scale topological features of multiple component shapes. It is demonstrated, both qualitatively and quantitatively, that the proposed model models useful multi-scale topological features and outperforms a commonly used benchmark models with respect to the task of multiple component shape retrieval. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Corcoran, Padraig; Rosin, Paul L.] Cardiff Univ, Sch Comp Sci & Informat, Cardiff, S Glam, Wales.
   [Zunic, Jovisa] Serbian Acad Sci, Math Inst, Beograd, Serbia.
C3 Cardiff University; Serbian Academy of Sciences & Arts
RP Corcoran, P (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, Cardiff, S Glam, Wales.
EM corcoranp@cardiff.ac.uk
OI Rosin, Paul/0000-0002-4965-3884
CR [Anonymous], [No title captured]
   Aslan C, 2005, IEEE I CONF COMP VIS, P1339
   Baker-LePain JC, 2011, J BONE MINER RES, V26, P468, DOI 10.1002/jbmr.254
   Belongie S, 2001, ADV NEUR IN, V13, P831
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Cerri A, 2012, LECT NOTES COMPUT SC, V7309, P128, DOI 10.1007/978-3-642-30238-1_14
   Chazal F, 2018, J MACH LEARN RES, V18
   Corcoran P, 2017, IEEE ACCESS, V5, P18534, DOI 10.1109/ACCESS.2017.2749319
   Corcoran P, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.81
   Correll N, 2018, IEEE T AUTOM SCI ENG, V15, P172, DOI 10.1109/TASE.2016.2600527
   Curry J., 2012, S APPL MATH
   Di Fabio B, 2015, LECT NOTES COMPUT SC, V9279, P294, DOI 10.1007/978-3-319-23231-7_27
   Di Fabio B, 2012, PATTERN RECOGN LETT, V33, P1445, DOI 10.1016/j.patrec.2011.11.003
   Edelsbrunner H., 2010, AM MATH SOC, DOI DOI 10.1007/978-3-540-33259-6_7
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   Eom KB, 1998, PATTERN RECOGN LETT, V19, P189, DOI 10.1016/S0167-8655(97)00165-7
   Fabbri R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322434
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Kerber M., 2017, Journal of Experimental Algorithmics (JEA), V22, P1, DOI [DOI 10.1145/3064175, 10.1145/3064175]
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   Madsen D, 2018, PROC CVPR IEEE, P5295, DOI 10.1109/CVPR.2018.00555
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Munkres J. R., 1996, ELEMENTS ALGEBRAIC T
   RAUBER TW, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P466, DOI 10.1109/ICPR.1992.201819
   Rosin PL, 2003, MACH VISION APPL, V14, P172, DOI 10.1007/s00138-002-0118-6
   Turner K, 2014, INF INFERENCE, V3, P310, DOI 10.1093/imaiai/iau011
   YOU Z, 1984, COMPUT VISION GRAPH, V28, P185, DOI 10.1016/S0734-189X(84)80021-3
   Zeppelzauer M, 2018, COMPUT VIS IMAGE UND, V167, P74, DOI 10.1016/j.cviu.2017.10.012
   Zhou Z, 2017, PATTERN RECOGN LETT, V87, P177, DOI 10.1016/j.patrec.2016.04.002
   Zomorodian A, 2005, DISCRETE COMPUT GEOM, V33, P249, DOI 10.1007/s00454-004-1146-y
   Zunic J, 2006, IEEE T IMAGE PROCESS, V15, P3478, DOI 10.1109/TIP.2006.877527
   Zunic J, 2018, PATTERN RECOGN, V78, P91, DOI 10.1016/j.patcog.2018.01.010
NR 33
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102617
DI 10.1016/j.jvcir.2019.102617
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600018
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Malawski, F
   Kwolek, B
AF Malawski, Filip
   Kwolek, Bogdan
TI Improving multimodal action representation with joint motion history
   context
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Action descriptors; Depth maps; Feature selection;
   Multimodal representation; Decision-level fusion
ID ACTION RECOGNITION; SELECTION; FEATURES
AB Automatic recognition of actions can be addressed by employing data from multiple sensors, such as RGB cameras, depth sensors or inertial measurement units. Recent studies show that multimodal representations of actions are effective in providing rich information about motion patterns. In this work, we propose a novel action descriptor, called Joint Motion History Context, which is based on depth and skeleton data. It improves action representation when used with previously introduced descriptors that are based on depth, skeleton and inertial data. A feature selection method is proposed as well, which ranks features on the basis of their inter-class discriminative power, while minimizing redundancy in the selected feature subset. Decision-level fusion, based on Support Vector Machines and Multilayer Perceptron is employed to effectively combine motion pattern information from multiple feature sets. Experimental results on two publicly available datasets, FFD and UTD-MHAD, demonstrated that the proposed methods outperform state-of-the-art algorithms. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Malawski, Filip; Kwolek, Bogdan] AGH Univ Sci & Technol, 30 Mickiewicza Av, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Malawski, F (corresponding author), AGH Univ Sci & Technol, Dept Comp Sci, 30 Mickiewicza Av,Bldg D-17, PL-30059 Krakow, Poland.
EM fmal@agh.edu.pl
RI Malawski, Filip/J-3479-2018; Kwolek, Bogdan/M-4552-2013
OI Kwolek, Bogdan/0000-0002-7715-1435
FU Polish National Science Center (NCN) [2014/15/B/ST6/02808]; Polish
   Ministry of Science and Higher Education
FX This work was supported by Polish National Science Center (NCN) under a
   research grant 2014/15/B/ST6/02808 and by the funds of Polish Ministry
   of Science and Higher Education assigned to AGH University of Science
   and Technology.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Annadani Y., 2016, ARXIV161100218
   [Anonymous], 32 AAAI C ART INT
   [Anonymous], 2014, ABS14053531 CORR
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bulbul MF, 2015, INT J MULTIMED DATA, V6, P23, DOI 10.4018/IJMDEM.2015100102
   Chen C, 2017, MULTIMED TOOLS APPL, V76, P4405, DOI 10.1007/s11042-015-3177-1
   Chen C, 2016, IEEE SENS J, V16, P773, DOI 10.1109/JSEN.2015.2487358
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Delachaux B, 2013, LECT NOTES COMPUT SC, V7903, P216
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   El Madany NE, 2016, IEEE IMAGE PROC, P4170, DOI 10.1109/ICIP.2016.7533145
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Elmadany N.E.D., 2016, IEEE INT WORKSH MULT, P1
   Escobedo E, 2016, SIBGRAPI, P209, DOI [10.1109/SIBGRAPI.2016.35, 10.1109/SIBGRAPI.2016.037]
   Fernandez-Cervantes V, 2018, ENTERTAIN COMPUT, V27, P60, DOI 10.1016/j.entcom.2018.04.001
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   González-Ortega D, 2014, COMPUT METH PROG BIO, V113, P620, DOI 10.1016/j.cmpb.2013.10.014
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hamaya M, 2017, PATTERN RECOGN LETT, V99, P67, DOI 10.1016/j.patrec.2017.04.007
   Hanai Y, 2009, 2009 IEEE 13TH DIGITAL SIGNAL PROCESSING WORKSHOP & 5TH IEEE PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, PROCEEDINGS, P675, DOI 10.1109/DSP.2009.4786008
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Kasiri S, 2017, COMPUT VIS IMAGE UND, V159, P143, DOI 10.1016/j.cviu.2017.04.007
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Kepski M, 2014, IEEE ENG MED BIO, P770, DOI 10.1109/EMBC.2014.6943704
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Kwolek B, 2015, NEUROCOMPUTING, V168, P637, DOI 10.1016/j.neucom.2015.05.061
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lin Weiyao, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1489, DOI 10.1109/TPAMI.2016.2608884
   Liu J, 2018, PROC CVPR IEEE, P8349, DOI 10.1109/CVPR.2018.00871
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu GL, 2014, NEUROCOMPUTING, V123, P328, DOI 10.1016/j.neucom.2013.06.042
   Malawski F, 2018, IMAGE VISION COMPUT, V75, P1, DOI 10.1016/j.imavis.2018.04.005
   Malawski F, 2017, 2017 40TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P520, DOI 10.1109/TSP.2017.8076041
   Malawski F, 2016, SIG P ALGO ARCH ARR, P51, DOI 10.1109/SPA.2016.7763586
   Malawski F, 2014, LECT NOTES COMPUT SC, V8610, P395, DOI 10.1007/978-3-319-09912-5_33
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Pan MS, 2016, PERVASIVE MOB COMPUT, V31, P37, DOI 10.1016/j.pmcj.2016.01.011
   Pärkkä J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863
   Rawashdeh M., 2017, FUTURE GENER COMPUT
   Reily B, 2017, COMPUT VIS IMAGE UND, V159, P154, DOI 10.1016/j.cviu.2016.11.006
   Sabatini AM, 2005, IEEE T BIO-MED ENG, V52, P486, DOI 10.1109/TBME.2004.840727
   Sarbolandi H, 2015, COMPUT VIS IMAGE UND, V139, P1, DOI 10.1016/j.cviu.2015.05.006
   Skalski P, 2011, NEW MEDIA SOC, V13, P224, DOI 10.1177/1461444810370949
   Thomas G, 2017, COMPUT VIS IMAGE UND, V159, P3, DOI 10.1016/j.cviu.2017.04.011
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Ngo TT, 2015, PATTERN RECOGN, V48, P1289, DOI 10.1016/j.patcog.2014.10.012
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang ZK, 2018, IEEE IMAGE PROC, P3458, DOI 10.1109/ICIP.2018.8451483
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   2010, PATTERN RECOGN, V43, P3605, DOI DOI 10.1016/J.PATCOG.2010.04.019
   2013, IEEE C COMP VIS PATT, P716, DOI DOI 10.1109/CVPR.2013.98
   2015, IEEE T HUM-MACH SYST, V45, P51, DOI DOI 10.1109/THMS.2014.2362520
NR 65
TC 7
Z9 8
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 198
EP 208
DI 10.1016/j.jvcir.2019.03.026
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100021
DA 2024-07-18
ER

PT J
AU Wen, J
   Zhou, XJ
   Li, MD
   Zhong, P
   Xue, YM
AF Wen, Juan
   Zhou, Xuejing
   Li, Mengdi
   Zhong, Ping
   Xue, Yiming
TI A novel natural language steganographic framework based on image
   description neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Natural language steganography; Image description; Neural network;
   Embedding capacity; BLEU; Perplexity
AB It is a challenge to conduct natural language steganography on Online interactive platforms such as photo-sharing websites since the stego texts should be consistent with the content of the images. In this paper, a novel natural language steganographic framework based on an end-to-end generative network is proposed. A Convolution Neural Network (CNN) combined with Long Short-Term Memory (LSTM) is trained to generate stego descriptions. Word by Word Hiding (WWH) and Sentence by Sentence Hiding (SSH) schemes are proposed to achieve various embedding capacity under the premise of sharing model between the sender and the receiver. Furthermore, a blind extraction scheme called Hash Hiding (HH) is proposed in case that the model is unavailable for data extraction. Comparative experiments show the superiority of the proposed framework. It is verified that the proposed framework is an effective carrier-less steganographic framework with competitive embedding capacity, considerable text quality, and good reversibility. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wen, Juan; Zhou, Xuejing; Li, Mengdi; Xue, Yiming] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Zhong, Ping] China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
C3 China Agricultural University; China Agricultural University
RP Xue, YM (corresponding author), 17 East Tsinghua Rd, Beijing 100083, Peoples R China.
EM xueym@cau.edu.cn
RI Wen, Juan/ADU-0902-2022; Li, Mengdi/HPC-9714-2023
OI Li, Mengdi/0009-0000-2650-2891
FU National Natural Science Foundation of China [61802410, 61872368];
   Chinese Universities Scientific Fund [2017QC003, 2018QC024]
FX We would like to thank Andrej Karpathy for his contribution to the demo
   code of image caption neuraltalk. We would like to appreciate the
   efforts spent by the reviewers. This work is supported by the National
   Natural Science Foundation of China (Nos. 61802410 and 61872368), and
   the Chinese Universities Scientific Fund (2017QC003 and 2018QC024).
CR [Anonymous], 2011, P 24 CVPR
   Atallah M. J., 2001, Information Hiding, P185
   Bhattacharyya S., 2013, INT J COMPUT APPL, V70, P29, DOI [10.5120/12169-8282, DOI 10.5120/12169-8282]
   Brassil JT, 1999, P IEEE, V87, P1181, DOI 10.1109/5.771071
   Chapman M., 2017, NICETEXT
   Chauhan S., 2016, 2016 IEEE International Conference on Plasma Science (ICOPS), DOI 10.1109/PLASMA.2016.7534009
   Chen ZL, 2011, LECT NOTES COMPUT SC, V6526, P251, DOI 10.1007/978-3-642-18405-5_21
   Da-ren Huang, 2002, Journal of Software, V13, P1290
   Dai Zu-xu, 2007, Journal of Communications, V28, P108
   Fallahpour M, 2015, IEEE-ACM T AUDIO SPE, V23, P1273, DOI 10.1109/TASLP.2015.2430818
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jangid S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P589, DOI 10.1109/ICCONS.2017.8250530
   JELINEK F, 1976, P IEEE, V64, P532, DOI 10.1109/PROC.1976.10159
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Khairullah M, 2009, INT C COMP ELEC ENG, P482, DOI 10.1109/ICCEE.2009.127
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luo YB, 2016, KSII T INTERNET INF, V10, P4568
   Maher K., 2007, TEXTO
   Moraldo H. Hernan, 2014, CORR
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pun CM, 2013, IEEE T AUDIO SPEECH, V21, P2412, DOI 10.1109/TASL.2013.2279312
   Qianrong Zhou, 2016, Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data. 15th China National Conference, CCL 2016, and 4th International Symposium, NLP-NABD 2016. Proceedings: LNAI 10035, P324, DOI 10.1007/978-3-319-47674-2_27
   Ramakrishnan BK, 2016, SECUR COMMUN NETW, V9, P6066, DOI 10.1002/sec.1757
   Saniei R, 2013, IRAN CONF MACH, P38, DOI 10.1109/IranianMVIP.2013.6779946
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shi SW, 2016, 2016 INTERNATIONAL COMPUTER SYMPOSIUM (ICS), P227, DOI [10.1109/ICS.2016.0052, 10.1109/ICS.2016.51]
   Singh P., 2012, IOSR J COMPUTER ENG, V3, P11, DOI DOI 10.9790/0661-0341117
   Stutsman R., 2006, P 2006 ACM S APPL CO, P338
   Tian Hui, 2009, P 17 ACM INT C MULT, P777
   Vinyals O., 2014, CORR
   Wang C, 2012, INT CONF ACOUST SPEE, P1785, DOI 10.1109/ICASSP.2012.6288246
   Wayner P., 1992, Cryptologia, V16, P193, DOI 10.1080/0161-119291866883
   Wu Qingqing., 2015, CoRR
   Xiang LY, 2014, MULTIMED TOOLS APPL, V71, P1893, DOI 10.1007/s11042-012-1313-8
   Xianyi Chen, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P133, DOI 10.1007/978-3-319-27051-7_12
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yajam HA, 2014, INT ISC CONF INFO SE, P155, DOI 10.1109/ISCISC.2014.6994040
   2016, MULTIMED TOOLS APPL, V75, P1350, DOI DOI 10.1007/S11042-015-2743-X
   2013, J SYST SOFTW, V86, P604, DOI DOI 10.1016/J.JSS.2012.10.922
NR 43
TC 18
Z9 20
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 157
EP 169
DI 10.1016/j.jvcir.2019.03.016
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100017
DA 2024-07-18
ER

PT J
AU Yang, J
   Li, WJ
   Wang, RG
   Xue, LX
   Hu, M
AF Yang, Juan
   Li, Wenjing
   Wang, Ronggui
   Xue, Lixia
   Hu, Min
TI Enhanced two-phase residual network for single image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Convolutional neural network; Deep residual learning;
   Dilated convolution
AB Recent research on deep residual neural network has made breakthrough in single image super resolution. However, these studies ignore persistent memory of information in the propagation, which fail to infer plausible high-frequency sufficiently. To solve this problem, we propose a novel enhanced two-phase residual network (ETRN). The proposed ETRN progressively generate high-resolution image in two phases so that we can recover accurate texture. We also present dense residual unit to capture hierarchical features in the local residual learning phase. With the help of these high-level representations, we use global residual learning to improve reconstruction quality in the second phase. In order to reduce cumbersome computation, between two phases we introduce dilated convolution which enlarges receptive field without increasing additional parameters. Comprehensive experiments show that ETRN has a significant improvement in both quantitation and visual perception. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yang, Juan; Li, Wenjing; Wang, Ronggui; Xue, Lixia; Hu, Min] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Anhui, Peoples R China.
EM yangjuan@hfut.edu.cn
RI Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]; State Key
   Program of NSFC-Shenzhen Joint Foundation [U1613217]
FX We express our sincere thanks to the anonymous reviewers for their
   helpful comments and suggestions to raise the standard of our paper.
   This work is partly supported by the National Natural Science Foundation
   of China under Grant No. 61672202 and State Key Program of NSFC-Shenzhen
   Joint Foundation under Grant No. U1613217.
CR [Anonymous], 2016, INT C LEARN REPR
   [Anonymous], CVPR
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], P 31 AAAI C ART INT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2015, P 3 INT C LEARNING R
   [Anonymous], 2008, NIPS
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], BMVC
   [Anonymous], IEEE T ACOUSTICS SPE
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], 2016, P ADV NEUR INF PROC
   Atkins C.B., 1999, P C IMAGE PROCESSING, P405
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Chen YJ, 2015, PROC CVPR IEEE, P5261, DOI 10.1109/CVPR.2015.7299163
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A., 2008, SUPERVISED SEQUENCE, P385
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang Y, 2008, CLIN DEV IMMUNOL, DOI 10.1155/2008/790309
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Srivastava RK., 2015, P 28 INT C NEURAL IN, P2377, DOI DOI 10.48550/ARXIV.1507.06228
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhangyang Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301266
NR 47
TC 4
Z9 4
U1 2
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 188
EP 197
DI 10.1016/j.jvcir.2019.04.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100020
DA 2024-07-18
ER

PT J
AU Yin, WB
   Xu, DS
   Wang, Z
   Zhao, ZJ
   Chen, C
   Yao, YY
AF Yin, Weibin
   Xu, Dongsheng
   Wang, Zheng
   Zhao, Zhijun
   Chen, Chao
   Yao, Yiyang
TI Perceptually learning multi-view sparse representation for scene
   categorization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene categorization
AB Utilizing multi-channel visual features to characterize scenery images is standard for state-of-the-art scene recognition systems. However, how to encode human visual perception for scenery image modeling and how to optimally combine visual features from multiple views remains a tough challenge. In this paper, we propose a perceptual multi-view sparse learning (PMSL) framework to distinguish sceneries from different categories. Specifically, we first project regions from each scenery into the so-called perceptual space, which is established by combining human gaze behavior, color and texture. Afterward, a novel PMSL is developed which fuzes the above three visual cues into a sparse representation. PMSL can support absent channel visual features, which is frequently occurred in practical circumstances. Finally, the sparse representation from each scenery image is incorporated into an image kernel, which is further fed into a kernel SVM for scene categorization. Comprehensive experimental results on popular data sets have demonstrated the superiority of our method over well-known shallow/deep recognition models. (C) 2019 Published by Elsevier Inc.
C1 [Yin, Weibin; Xu, Dongsheng; Wang, Zheng; Zhao, Zhijun; Chen, Chao] State Grid Jiaxing Elect Power Supply Co, Jiaxing, Peoples R China.
   [Yao, Yiyang] State Grid Zhejiang Elect Power Co Ltd, Informat & Telecommun Co, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Yao, YY (corresponding author), State Grid Zhejiang Elect Power Co Ltd, Informat & Telecommun Co, Hangzhou, Zhejiang, Peoples R China.
EM yin_weibin@zj.sgcc.com.cn; xu_dongsheng@zj.sgcc.com.cn;
   wang_zheng@zj.sgcc.com.cn; zhao_zhijun@zj.sgcc.com.cn;
   chen_chao@zj.sgcc.com.cn; yao_yiyang@zj.sgcc.com.cn
RI Zhao, Zhi-jun/AAE-9577-2020
CR [Anonymous], P IJCAI
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2018, ARXIV180207938
   [Anonymous], PROC CVPR IEEE
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2008, P WORKSHOP CAUSATION
   [Anonymous], IMAGE CLASSIFICATION
   [Anonymous], 2011, Advances in Neural Information Processing Systems
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu WM, 2016, IEEE T MULTIMEDIA, V18, P76, DOI 10.1109/TMM.2015.2496372
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Li Y, 2015, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2015.7298699
   Ragheb H., 2008, DISTRIBUTED SMART CA, P1, DOI [10.1109/ICDSC.2008.4635730, DOI 10.1109/ICDSC.2008.4635730]
   UDE A, 1994, ADVANCES IN ROBOT KINEMATICS AND COMPUTATIONAL GEOMETRY, P505
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Z, 2014, KNOWL-BASED SYST, V70, P376, DOI 10.1016/j.knosys.2014.07.019
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Wu Y., 2004, ACM INT C MULTIMEDIA, P572, DOI DOI 10.1145/1027527.1027665
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yuan CF, 2016, INT J COMPUT VISION, V118, P151, DOI 10.1007/s11263-015-0867-0
   Zhang J, 2018, IEEE SIGNAL PROC LET, V25, P333, DOI 10.1109/LSP.2017.2748604
   Zhang LM, 2018, IEEE T MULTIMEDIA, V20, P1462, DOI 10.1109/TMM.2017.2769799
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou X, 2008, PATTERN RECOGN, V41, P778, DOI 10.1016/j.patcog.2007.06.019
NR 39
TC 5
Z9 5
U1 2
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 59
EP 63
DI 10.1016/j.jvcir.2019.01.002
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000008
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Li, LD
   Zhu, HC
   Liu, HT
   Wang, SQ
   Zhao, Y
AF Zhou, Yu
   Li, Leida
   Zhu, Hancheng
   Liu, Hantao
   Wang, Shiqi
   Zhao, Yao
TI No-reference quality assessment for contrast-distorted images based on
   multifaceted statistical representation of structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality assessment; No-reference; Contrast-distorted images; Structure
   representation; Back propagation (BP)
ID SHARPNESS ASSESSMENT; BLOCKING ARTIFACTS; ENHANCEMENT; REGULARITY
AB In many real-world applications, images are prone to be degraded by contrast distortions during image acquisition. Quality assessment for contrast-distorted images is vital for benchmarking and optimizing the contrast-enhancement algorithms. To this end, this paper proposes a no-reference quality metric for contrast-distorted images based on Multifaceted Statistical representation of Structure (MSS). The "Multifaceted" has two meanings, namely (1) not only the luminance information, but also the chromatic information is used for structure representation. This is inspired by the fact that the chromatic information on the one hand affects the perception of image quality as well, and on the other hand it changes along with the contrast distortions. Therefore, the chromatic information should be integrated with the luminance information for quality assessment of contrast-distorted images, a fact most existing quality metrics overlook; (2) regarding structure representation, three aspects, i.e. spatial intensity, spatial distribution, and orientation of structures are calculated, which is enlightened by the fact that the human visual system (HVS) is sensitive to the three aspects of structures. Specifically, the image is first transformed from RGB to the S-CIELAB color space to obtain a representation that is more consistent with the characteristics of the HVS, as well as to separate the chromatic information from the luminance. Then the statistical structural features are extracted from both luminance and chromatic channels. Finally, the back propagation (BP) neural network is adopted to train a quality prediction model. Experimental results conducted on four public contrast-distorted image databases demonstrate the superiority of the proposed method to the relevant state-of-the-arts. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhou, Yu; Li, Leida; Zhu, Hancheng] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Liu, Hantao] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 3AA, S Glam, Wales.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 China University of Mining & Technology; Cardiff University; City
   University of Hong Kong; Beijing Jiaotong University
RP Li, LD (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM lileida@cumt.edu.cn
RI Li, Li/AEM-3636-2022; li, li/HII-4157-2022
FU National Natural Science Foundation of China [61771473, 61379143];
   Natural Science Foundation of Jiangsu Province [BK20181354]; Six Talent
   Peaks High-level Talents in Jiangsu Province [XYDXX-063]; Qing Lan
   Project of Jiangsu Province
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771473 and 61379143, Natural Science Foundation of
   Jiangsu Province under Grant BK20181354, Six Talent Peaks High-level
   Talents in Jiangsu Province under Grant XYDXX-063, and the Qing Lan
   Project of Jiangsu Province.
CR Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Bettahar S, 2012, IEEE T IMAGE PROCESS, V21, P2500, DOI 10.1109/TIP.2011.2177844
   Dandawate YH, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P138, DOI 10.1109/ICCIMA.2007.231
   Ding L, 2017, IEEE T IMAGE PROCESS, V26, P1799, DOI 10.1109/TIP.2017.2665972
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Gómez-Verdejo V, 2008, IEEE T NEURAL NETWOR, V19, P3, DOI 10.1109/TNN.2007.902723
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2013, IEEE IMAGE PROC, P383, DOI 10.1109/ICIP.2013.6738079
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Gvozden G, 2018, J VIS COMMUN IMAGE R, V50, P145, DOI 10.1016/j.jvcir.2017.11.017
   He LH, 2011, SIGNAL IMAGE VIDEO P, V5, P283, DOI 10.1007/s11760-010-0200-x
   ITU-R, 2012, ITUR Recommendation BT. 500-13
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Larsson J, 2006, J NEUROPHYSIOL, V95, P862, DOI 10.1152/jn.00668.2005
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Li LD, 2014, IEICE T INF SYST, VE97D, P993, DOI 10.1587/transinf.E97.D.993
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P918, DOI 10.1109/LSP.2014.2320743
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Lin P. T., 2016, 12 IEEE ASME INT C M, P1
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu HT, 2016, IEEE T IMAGE PROCESS, V25, P3087, DOI 10.1109/TIP.2016.2561406
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu SL, 2017, J VIS COMMUN IMAGE R, V48, P169, DOI 10.1016/j.jvcir.2017.05.011
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Roe BP, 2005, NUCL INSTRUM METH A, V543, P577, DOI 10.1016/j.nima.2004.12.018
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Simone F. D., 2009, P 4 INT WORKSH VPQM
   Solomatine DP, 2004, IEEE IJCNN, P1163
   Sun W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1228, DOI 10.1109/ICASSP.2018.8461581
   Tang LJ, 2017, J VIS COMMUN IMAGE R, V49, P204, DOI 10.1016/j.jvcir.2017.09.010
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Yan YP, 2016, IET IMAGE PROCESS, V10, P1017, DOI 10.1049/iet-ipr.2016.0177
   Yang GY, 2017, IEEE ACCESS, V5, P23146, DOI 10.1109/ACCESS.2017.2764126
   Yi Wan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457892
   Yin T, 2015, COMPUT SECUR, V55, P130, DOI 10.1016/j.cose.2015.09.003
   Yue Wang, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P274, DOI 10.1109/PCS.2010.5702485
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang Y., 2012, P IEEE C COMP VIS PA, P16
   Zhou Y, 2018, IEEE T MULTIMEDIA, V20, P3019, DOI 10.1109/TMM.2018.2829607
NR 54
TC 5
Z9 7
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 158
EP 169
DI 10.1016/j.jvcir.2019.02.028
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000019
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Lin, JJ
   Zhuge, JL
   Yuan, WH
AF Zhang, Qing
   Lin, Jiajun
   Zhuge, Jingling
   Yuan, Wenhao
TI Multi-level and multi-scale deep saliency network for salient object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Salient object detection; Fully convolutional neural
   network; Multi-scale features
AB Traditional saliency model usually utilize handcrafted image features and various prior knowledge to pop out salient regions from complex surroundings. In this paper, we propose a novel FCN-like deep convolutional neural network for pixel-wise salient object detection. Our deep network automatically learns multi-level feature from different convolutional layers of a pre-trained convolutional neural network. Moreover, deeper side outputs are connected to the shallower ones, which provides a better feature representation and helps shallow side outputs to accurately locate salient regions. In addition, we adopt a weighted-fusion module to combine different side outputs for utilizing multi-scale and multi-level features. Finally, a fully connected CRF model can be optimally incorporated to improve spatial coherence and contour localization in the fused saliency map. Both qualitative and quantitative evaluations on four publicly available datasets demonstrate the robustness and efficiency of our proposed approach against 17 state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Qing] Shanghai Inst Technol, Coll Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
   [Lin, Jiajun; Zhuge, Jingling] East China Univ Sci & Technol, Coll Informat Sci & Engn, Shanghai 200237, Peoples R China.
   [Yuan, Wenhao] Shandong Univ Technol, Coll Comp Sci & Technol, Zibo 255000, Peoples R China.
C3 Shanghai Institute of Technology; East China University of Science &
   Technology; Shandong University of Technology
RP Zhang, Q (corresponding author), Shanghai Inst Technol, Coll Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM zhangqing0329@gmail.com
OI Yuan, Wenhao/0000-0003-0020-7629
FU National Natural Science Foundation of China [61401281, 61701286];
   Science and Technology Development Foundation of Shanghai Institute of
   Technology [ZQ2018-23]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61401281 and No. 61701286, and Science and
   Technology Development Foundation of Shanghai Institute of Technology
   under Grant No. ZQ2018-23.
CR Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Liang M, 2015, IEEE T IMAGE PROCESS, V24, P1178, DOI 10.1109/TIP.2015.2395713
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Xia CQ, 2017, PROC CVPR IEEE, P4399, DOI 10.1109/CVPR.2017.468
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhang DW, 2017, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2017.436
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang Q, 2018, VISUAL COMPUT, V34, P473, DOI 10.1007/s00371-017-1354-0
   Zhang Q, 2017, NEUROCOMPUTING, V243, P35, DOI 10.1016/j.neucom.2017.02.064
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 46
TC 6
Z9 6
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 415
EP 424
DI 10.1016/j.jvcir.2019.01.034
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600044
DA 2024-07-18
ER

PT J
AU Afiq, AA
   Zakariya, MA
   Saad, MN
   Nurfarzana, AA
   Khir, MHM
   Fadzil, AF
   Jale, A
   Gunawan, W
   Izuddin, ZAA
   Faizari, M
AF Afiq, A. A.
   Zakariya, M. A.
   Saad, M. N.
   Nurfarzana, A. A.
   Khir, M. H. M.
   Fadzil, A. F.
   Jale, A.
   Gunawan, W.
   Izuddin, Z. A. A.
   Faizari, M.
TI A review on classifying abnormal behavior in crowd scene
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Crowd analysis; Abnormal detection; Gaussian Mixture Model (GMM); Hidden
   Markov Model (HMM); Optical Flow (OF); Spatio-Temporal Technique (STT)
ID VIDEO ANOMALY DETECTION; SALIENT OBJECT DETECTION; DEEP NEURAL-NETWORKS;
   HIDDEN MARKOV MODEL; EVENT DETECTION; DENSITY-ESTIMATION; TEXT
   DETECTION; FEATURE FUSION; LOCALIZATION; SURVEILLANCE
AB Crowd behavior analysis has become one of the new areas of interest in the computer vision community due to the increasing demands from surveillance and security industries. It is important to meticulously understand crowd behavior to prevent any disaster and unwanted incidents such as thief, stampede and riots. For this purpose, crowd features such as density, motion and trajectory are analyzed to detect any abnormality in the crowd. Thus, this review is aimed to provide insight on several detection methods including Gaussian Mixture Model (GMM), Hidden Markov Model (HMM), Optical Flow method and Spatio-Temporal Technique (STT). Providing the latest development, the review presented the studies that are published in journals and conferences over the past 5 years. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Afiq, A. A.; Zakariya, M. A.; Saad, M. N.; Nurfarzana, A. A.; Khir, M. H. M.; Fadzil, A. F.; Jale, A.; Gunawan, W.; Izuddin, Z. A. A.; Faizari, M.] Univ Teknol PETRONAS, Ctr Intelligent Signal & Imaging Res, Seri Iskandar 32610, Perak, Malaysia.
C3 Universiti Teknologi Petronas
RP Afiq, AA (corresponding author), Univ Teknol PETRONAS, Block 22, Seri Iskandar 32610, Perak, Malaysia.
EM afiqaizuddin88@gmail.com; mazman_zakariya@utp.edu.my;
   naufal_saad@utp.edu.my; a.a.nurfarzana@gmail.com; harisk@utp.edu.my;
   faizal_ahmadfadzil@utp.edu.my; jale_ahmad@utp.edu.my;
   gunawan.witjaksono@utp.edu.my; izuddin_z@utp.edu.my;
   mfaizari_mnor@utp.edu.my
RI Saad, Naufal m/N-2871-2013; Zainal-Abidin, Izuddin/G-2581-2017
OI Zainal-Abidin, Izuddin/0000-0002-4533-5977
FU Ministry of Higher Education (MOHE) Malaysia under MyPhD Scheme
FX This research is supported by Ministry of Higher Education (MOHE)
   Malaysia under MyPhD Scheme. We would like to show our gratitude to
   University Technology PETRONAS (UTP) especially Electrical & Electronics
   Engineering department for giving the opportunity to work in this
   project and at the same time enhanced the theoretical and practical
   skills regarding the project. We would also like to also acknowledge the
   assistance provided by the Communication Lab Technologists who gave the
   access and guidance for all the equipment.
CR Afonso M, 2015, IEEE IMAGE PROC, P2547, DOI 10.1109/ICIP.2015.7351262
   Akpinar S., 2015, COMPUTER VISION PATT, P331
   Alyammahi S, 2017, KNOWL-BASED SYST, V131, P83, DOI 10.1016/j.knosys.2017.06.001
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2017, INT J MACH LEARN CYB
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Azzam R, 2016, J VIS COMMUN IMAGE R, V36, P90, DOI 10.1016/j.jvcir.2015.11.009
   Biswas S, 2017, NEUROCOMPUTING, V242, P63, DOI 10.1016/j.neucom.2017.02.058
   Cai YF, 2015, IET INTELL TRANSP SY, V9, P810, DOI 10.1049/iet-its.2014.0238
   Chaker R, 2017, PATTERN RECOGN, V61, P266, DOI 10.1016/j.patcog.2016.06.016
   Charte D, 2018, INFORM FUSION, V44, P78, DOI 10.1016/j.inffus.2017.12.007
   Chen HK, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P640, DOI 10.1109/WCICA.2016.7578533
   Chen X, 2016, COMPUT NETW, V108, P108, DOI 10.1016/j.comnet.2016.07.004
   Chen XR, 2015, OPTIK, V126, P2256, DOI 10.1016/j.ijleo.2015.05.122
   Chen YC, 2016, APPL MATH COMPUT, V283, P141, DOI 10.1016/j.amc.2016.02.024
   Cheng KW, 2015, IEEE T IMAGE PROCESS, V24, P5288, DOI 10.1109/TIP.2015.2479561
   Cho SH, 2014, PATTERN RECOGN LETT, V44, P64, DOI 10.1016/j.patrec.2013.11.017
   Colque R. M., 2017, IEEE T CIRCUITS SYST, V27, P10
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   Coniglio C, 2017, PATTERN RECOGN LETT, V93, P182, DOI 10.1016/j.patrec.2016.12.014
   Datondji SRE, 2016, IEEE T INTELL TRANSP, V17, P2681, DOI 10.1109/TITS.2016.2530146
   Denman S, 2015, EXPERT SYST APPL, V42, P9449, DOI 10.1016/j.eswa.2015.08.001
   Dimitriou N, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P200, DOI 10.1109/AVSS.2016.7738057
   Ding WW, 2016, SIGNAL PROCESS-IMAGE, V42, P109, DOI 10.1016/j.image.2016.01.010
   Du J, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/4685187
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Epaillard E, 2016, PATTERN RECOGN, V55, P125, DOI 10.1016/j.patcog.2016.02.004
   Fan XJ, 2015, PATTERN RECOGN, V48, P3407, DOI 10.1016/j.patcog.2015.04.025
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Fortun Denis, 2015, Computer Vision and Image Understanding, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Fradi H, 2015, INFORM FUSION, V24, P3, DOI 10.1016/j.inffus.2014.09.005
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Furui S, 2015, SIGNALS COMMUN TECHN, P13, DOI 10.1007/978-1-4471-5779-3_2
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Gu XX, 2014, OPTIK, V125, P3428, DOI 10.1016/j.ijleo.2014.01.041
   Gunduz AE, 2016, IET COMPUT VIS, V10, P374, DOI 10.1049/iet-cvi.2015.0345
   Güngör E, 2017, EXPERT SYST APPL, V69, P10, DOI 10.1016/j.eswa.2016.10.022
   Guo HW, 2016, NEUROCOMPUTING, V204, P106, DOI 10.1016/j.neucom.2015.07.153
   Han TT, 2016, NEUROCOMPUTING, V171, P347, DOI 10.1016/j.neucom.2015.06.048
   Hao Y, 2016, 2016 22ND INTERNATIONAL CONFERENCE ON AUTOMATION AND COMPUTING (ICAC), P463
   Hariyono J, 2017, NEUROCOMPUTING, V234, P144, DOI 10.1016/j.neucom.2016.12.050
   He PS, 2017, J VIS COMMUN IMAGE R, V48, P149, DOI 10.1016/j.jvcir.2017.06.010
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang SC, 2016, COMPUT VIS IMAGE UND, V153, P77, DOI 10.1016/j.cviu.2016.06.003
   Ji ZX, 2017, NEUROCOMPUTING, V266, P550, DOI 10.1016/j.neucom.2017.05.069
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Khan SS, 2017, APPL SOFT COMPUT, V55, P168, DOI 10.1016/j.asoc.2017.01.034
   Khare V, 2015, EXPERT SYST APPL, V42, P7627, DOI 10.1016/j.eswa.2015.06.002
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Kwon Y, 2017, EXPERT SYST APPL, V78, P386, DOI 10.1016/j.eswa.2017.02.026
   Leyva R, 2017, IEEE T IMAGE PROCESS, V26, P3463, DOI 10.1109/TIP.2017.2695105
   Li A, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/406941
   Li SF, 2018, SIGNAL PROCESS-IMAGE, V60, P6, DOI 10.1016/j.image.2017.09.002
   Li XZ, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P84, DOI 10.1109/ROBIO.2015.7414628
   Li Y, 2018, NEUROCOMPUTING, V301, P11, DOI 10.1016/j.neucom.2018.01.084
   Li Y, 2018, NEUROCOMPUTING, V297, P50, DOI 10.1016/j.neucom.2018.02.037
   Li Y, 2018, SIGNAL PROCESS-IMAGE, V64, P21, DOI 10.1016/j.image.2018.01.012
   Lim K. L., 2016, 12 IEEE INT C CONTR, P887
   Lim MK, 2014, EXPERT SYST APPL, V41, P4704, DOI 10.1016/j.eswa.2014.02.003
   Lin Weiyao, 2017, IEEE Trans Pattern Anal Mach Intell, V39, P1489, DOI 10.1109/TPAMI.2016.2608884
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Liu P, 2017, NEUROCOMPUTING, V269, P3, DOI 10.1016/j.neucom.2016.09.138
   Liu WX, 2016, PATTERN RECOGN, V58, P110, DOI 10.1016/j.patcog.2016.03.031
   Liu YN, 2016, SIGNAL PROCESS, V120, P761, DOI 10.1016/j.sigpro.2015.01.001
   Lloyd K, 2017, MACH VISION APPL, V28, P361, DOI 10.1007/s00138-017-0830-x
   Lu T, 2014, INT C PATT RECOG, P2203, DOI 10.1109/ICPR.2014.383
   Lu W.-L., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P6
   Lung FB, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P471, DOI 10.1109/MVA.2015.7153233
   Luo DW, 2016, I COMP CONF WAVELET, P1, DOI 10.1109/ICCWAMTIP.2016.8079794
   Luo X. M., 2016, SENSORS, V16, P17
   Arceda VEM, 2016, ELECTRON NOTES THEOR, V329, P5, DOI 10.1016/j.entcs.2016.12.002
   Mahapatra A, 2014, AEU-INT J ELECTRON C, V68, P227, DOI 10.1016/j.aeue.2013.08.011
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Manfredi M, 2014, PATTERN RECOGN LETT, V44, P39, DOI 10.1016/j.patrec.2013.11.001
   Marsden M, 2016, IEEE IMAGE PROC, P918, DOI 10.1109/ICIP.2016.7532491
   Meng QX, 2017, IEEE IJCNN, P364, DOI 10.1109/IJCNN.2017.7965877
   Ming YW, 2018, NEUROCOMPUTING, V281, P27, DOI 10.1016/j.neucom.2017.11.044
   Moria K, 2016, 2016 13TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P303, DOI 10.1109/CRV.2016.14
   Mousavi H, 2015, IEEE IMAGE PROC, P2354, DOI 10.1109/ICIP.2015.7351223
   Mousavi H, 2015, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2015.27
   Ng WWY, 2016, PATTERN RECOGN, V60, P875, DOI 10.1016/j.patcog.2016.06.013
   Oiwa D, 2017, PROCEDIA COMPUT SCI, V112, P1479, DOI 10.1016/j.procs.2017.08.029
   Pennisi A, 2016, COMPUT VIS IMAGE UND, V144, P166, DOI 10.1016/j.cviu.2015.09.010
   Pu SL, 2017, PROCEDIA COMPUT SCI, V111, P154, DOI 10.1016/j.procs.2017.06.022
   Qi TQ, 2017, NEUROCOMPUTING, V267, P475, DOI 10.1016/j.neucom.2017.06.041
   Rabbouch H, 2017, NEUROCOMPUTING, V260, P157, DOI 10.1016/j.neucom.2017.04.026
   Rahmani MH, 2018, DIGIT SIGNAL PROCESS, V82, P54, DOI 10.1016/j.dsp.2018.06.004
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Sankaran A, 2017, IMAGE VISION COMPUT, V60, P64, DOI 10.1016/j.imavis.2017.01.005
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Sekii T, 2016, PROC CVPR IEEE, P4275, DOI 10.1109/CVPR.2016.463
   Sengar SS, 2017, OPTIK, V145, P130, DOI 10.1016/j.ijleo.2017.07.040
   Serajeh R, 2014, IRAN CONF ELECTR ENG, P1097, DOI 10.1109/IranianCEE.2014.6999699
   Shao J, 2017, IEEE T CIRC SYST VID, V27, P1290, DOI 10.1109/TCSVT.2016.2539878
   Shao J, 2016, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR.2016.606
   Shao J, 2014, PROC CVPR IEEE, P2227, DOI 10.1109/CVPR.2014.285
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Shivakumara P, 2017, PATTERN RECOGN, V68, P158, DOI 10.1016/j.patcog.2017.03.018
   Singh D, 2017, PATTERN RECOGN, V65, P265, DOI 10.1016/j.patcog.2017.01.001
   Sun SL, 2015, PATTERN RECOGN, V48, P2407, DOI 10.1016/j.patcog.2015.02.028
   Teney D, 2017, LECT NOTES COMPUT SC, V10115, P412, DOI 10.1007/978-3-319-54193-8_26
   Tripathi RK, 2017, ARTIF INTELL, V50, P1
   Varadarajan S, 2015, COMPUT VIS IMAGE UND, V136, P45, DOI 10.1016/j.cviu.2014.12.004
   Vojir T, 2016, COMPUT VIS IMAGE UND, V153, P109, DOI 10.1016/j.cviu.2016.05.007
   Wang C, 2017, MULTIMED TOOLS APPL, V76, P6263, DOI 10.1007/s11042-015-3199-8
   Wang J, 2016, COMPUT VIS IMAGE UND, V144, P177, DOI 10.1016/j.cviu.2015.08.010
   Wang Q, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416550077
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Wang T, 2018, OPTIK, V152, P50, DOI 10.1016/j.ijleo.2017.07.064
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Wang Y., 2015, 2015 IEEE INT C SIGN, P1
   Wu GL, 2017, PATTERN RECOGN, V68, P175, DOI 10.1016/j.patcog.2017.03.015
   Wu S, 2017, J VIS COMMUN IMAGE R, V48, P461, DOI 10.1016/j.jvcir.2017.01.026
   Wu ZY, 2014, PATTERN RECOGN LETT, V44, P152, DOI 10.1016/j.patrec.2013.11.016
   Xie L, 2018, PATTERN RECOGN, V82, P118, DOI 10.1016/j.patcog.2018.04.025
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Xu JX, 2016, EXPERT SYST APPL, V54, P13, DOI 10.1016/j.eswa.2016.01.035
   Ye RZ, 2017, J COMPUT SCI TECH-CH, V32, P470, DOI 10.1007/s11390-017-1737-8
   Yi S, 2016, LECT NOTES COMPUT SC, V9905, P263, DOI 10.1007/978-3-319-46448-0_16
   Yi S, 2016, IEEE T IMAGE PROCESS, V25, P4354, DOI 10.1109/TIP.2016.2590322
   Yu BS, 2017, IEEE T SYST MAN CY-S, V47, P704, DOI 10.1109/TSMC.2016.2638048
   Yu J, 2016, INT CONF CONTR AUTO, P106, DOI 10.1109/ICCAIS.2016.7822444
   Yu WC, 2015, NEUROCOMPUTING, V149, P308, DOI 10.1016/j.neucom.2014.03.077
   Yuan Y., 2017, IEEE T CYBERNETICS, P1
   Yuan Y, 2018, PATTERN RECOGN, V73, P99, DOI 10.1016/j.patcog.2017.08.001
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zang XH, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P113, DOI 10.1109/BigMM.2016.33
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang J, 2017, IEEE WINT CONF APPL, P1, DOI 10.1109/WACV.2017.8
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhang XF, 2016, MULTIMED TOOLS APPL, V75, P8799, DOI 10.1007/s11042-015-3101-8
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YM, 2018, NEUROCOMPUTING, V273, P190, DOI 10.1016/j.neucom.2017.08.018
   Zhao Y, 2015, PHYSICA A, V431, P84, DOI 10.1016/j.physa.2015.02.068
   Zhao Y, 2016, IEEE IMAGE PROC, P3354, DOI 10.1109/ICIP.2016.7532981
   Zheng CH, 2017, NEUROCOMPUTING, V228, P71, DOI 10.1016/j.neucom.2016.09.085
   Zhou BL, 2014, IEEE T PATTERN ANAL, V36, P1586, DOI 10.1109/TPAMI.2014.2300484
   Zhou LJ, 2017, PATTERN RECOGN, V72, P548, DOI 10.1016/j.patcog.2017.06.035
   Zhou SF, 2016, SIGNAL PROCESS-IMAGE, V47, P358, DOI 10.1016/j.image.2016.06.007
   Zhou SF, 2015, INT CONF ACOUST SPEE, P1300, DOI 10.1109/ICASSP.2015.7178180
   Zhou Y., 2017, SENSOR DATA FUSION T, P1
   Zhu F., 2016, IEEE T CIRCUITS SYST, V16
   Zhu GY, 2016, NEUROCOMPUTING, V214, P567, DOI 10.1016/j.neucom.2016.06.044
   Zhu SH, 2016, MULTIMED TOOLS APPL, V75, P9445, DOI 10.1007/s11042-015-3122-3
   Zitouni MS, 2015, IEEE SYS MAN CYBERN, P1827, DOI 10.1109/SMC.2015.320
   Zitouni MS, 2016, NEUROCOMPUTING, V186, P139, DOI 10.1016/j.neucom.2015.12.070
   Zou JL, 2016, NEUROCOMPUTING, V184, P221, DOI 10.1016/j.neucom.2015.08.108
NR 158
TC 32
Z9 36
U1 4
U2 110
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 285
EP 303
DI 10.1016/j.jvcir.2018.11.035
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100029
DA 2024-07-18
ER

PT J
AU Li, X
   Fan, M
   Feng, DZ
   Li, HK
   Wu, JQ
AF Li, Xiao
   Fan, Min
   Feng, Dazheng
   Li, Haikun
   Wu, Jinqiao
TI Zero shot learning by partial transfer from source domain with
   <i>L</i><sub>2,1</sub> norm constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero shot learning; Partial transfer; Visual similarity; Semantic
   similarity; L-2,L-1 norm
AB Current zero shot learning methods mostly focus on applying the knowledge learnt by seen images to the unseen images. However, there is a big distribution difference between seen and unseen data, also called source and target domain. Thus, there are many irrelevant seen samples for unseen samples. We want to partially transfer the seen samples to target domain by selecting relevant seen samples. In this paper, we propose a method, zero shot learning by partial transfer from source domain with L-2,L-1 norm constraint, called ZSLPT which embeds visual similarity and semantic similarity to transfer partial source samples. The relevant source samples are selected, while the irrelevant are eliminated. What's more, we train source classification model used for transferring to target domain with the selected source samples, making the transferred target model more accurate. We have experimented on the state-of-the-art zero shot learning datasets, demonstrating that ZSLPT has good performance. (C) 2018 Published by Elsevier Inc.
C1 [Li, Xiao; Fan, Min; Li, Haikun; Wu, Jinqiao] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Feng, Dazheng] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Xidian University
RP Fan, M (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM mfang@mail.xidian.edu.cn
RI li, haikun/ADY-7816-2022
OI li, haikun/0000-0003-3827-6910
FU National Natural Science Foundation of China [61472305, 61070143,
   61806155]; Science and Technology Project of Shaanxi Province, China
   [2015GY027]; Aeronautical Science Foundation of China [20151981009];
   China Postdoctoral Science Foundation [2018M631125]; Fundamental
   Research Funds for the Central Universities [XJS18037]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 61472305, 61070143, 61806155), Science and Technology
   Project of Shaanxi Province, China (Grant No. 2015GY027), Aeronautical
   Science Foundation of China (Grant No. 20151981009), China Postdoctoral
   Science Foundation funded project under Grant 2018M631125, and
   Fundamental Research Funds for the Central Universities under Grant
   XJS18037.
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], 2014, C TRACK P
   [Anonymous], 2016, PROCEEDINGS OF THE I, DOI DOI 10.1109/CVPR.2016.649
   [Anonymous], 2015, PROC CVPR IEEE
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Cheng YH, 2018, IEEE T NEUR NET LEAR, V29, P1662, DOI 10.1109/TNNLS.2017.2677441
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Fu ZY, 2018, IEEE T PATTERN ANAL, V40, P2009, DOI 10.1109/TPAMI.2017.2737007
   Gan C, 2017, AAAI CONF ARTIF INTE, P4032
   Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17
   Gan M. L. Chuang, 2015, AAAI
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Hoo WL, 2015, EXPERT SYST APPL, V42, P9279, DOI 10.1016/j.eswa.2015.07.049
   Huang RB, 2017, J VIS COMMUN IMAGE R, V47, P10, DOI 10.1016/j.jvcir.2017.05.001
   Jayaraman D, 2014, ADV NEUR IN, V27
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Kodirov E., ARXIV170408345
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li X, 2017, NEUROCOMPUTING, V238, P76, DOI 10.1016/j.neucom.2017.01.038
   Li X, 2016, SIGNAL PROCESS-IMAGE, V44, P92, DOI 10.1016/j.image.2016.03.009
   Luo C., 2017, IEEE T AUTOM SCI ENG, V99, P1
   Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313
   Nie F., 2010, NIPS
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Rifkin R., 2003, Computer and Systems Sciences, V190, P131
   Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627
   Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xian Yongqin, 2018, PAMI
   Xu X., ARXIV151104458
   Yang Y., 2011, PROC INT JOINT C ART, P1589
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
NR 41
TC 8
Z9 8
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 701
EP 711
DI 10.1016/j.jvcir.2018.12.041
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100066
DA 2024-07-18
ER

PT J
AU Ye, YC
   Yang, XD
   Tian, YL
AF Ye, Yuancheng
   Yang, Xiaodong
   Tian, YingLi
TI Discovering spatio-temporal action tubes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatio-temporal action detection; Deep neural networks
AB In this paper, we address the challenging problem of spatial and temporal action detection in videos. We first develop an effective approach to localize frame-level action regions through integrating static and kinematic information by the early- and late-fusion detection scheme. With the intention of exploring important temporal connections among the detected action regions, we propose a tracking-by-point-matching algorithm to stitch the discrete action regions into a continuous spatio-temporal action tube. Recurrent 3D convolutional neural network is used to predict action categories and determine temporal boundaries of the generated tubes. We then introduce an action footprint map to refine the candidate tubes based on the action-specific spatial characteristics preserved in the convolutional layers of R3DCNN. In the extensive experiments, our method achieves superior detection results on the three public benchmark datasets: UCFSports, J-HMDB and UCF101. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Ye, Yuancheng; Tian, YingLi] CUNY, City Coll, New York, NY 10021 USA.
   [Ye, Yuancheng; Tian, YingLi] CUNY, Grad Ctr, New York, NY 10016 USA.
   [Yang, Xiaodong] NVIDIA Res, Santa Clara, CA USA.
C3 City University of New York (CUNY) System; City College of New York
   (CUNY); City University of New York (CUNY) System
RP Tian, YL (corresponding author), CUNY, City Coll, New York, NY 10021 USA.; Tian, YL (corresponding author), CUNY, Grad Ctr, New York, NY 10016 USA.
EM yye@gradcenter.cuny.edu; xiaodongy@nvidia.com; ytian@ccny.cuny.edu
RI TIAN, YI/KHU-9704-2024; Yang, Xiaodong/GSJ-1255-2022
OI Tian, Yingli/0000-0003-4458-360X
FU NSF [EFRI-1137172, IIS-1400802]
FX This work was supported in part by NSF grants EFRI-1137172 and
   IIS-1400802.
CR [Anonymous], INT C COMP VIS ICCV
   [Anonymous], 2014, CVPR
   [Anonymous], 2017, IEEE T PATTERN ANAL
   Delaitre V., 2011, NEURAL INFORM PROCES
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong XW, 2018, IEEE CONF COMPUT
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escorcia V., 2018, IEEE C COMP VIS PATT
   Escorcia V, 2016, LECT NOTES COMPUT SC, V9907, P768, DOI 10.1007/978-3-319-46487-9_47
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahasseni B., 2018, BRIT MACH VIS C BMVC
   Mettes P., 2016, EUR C COMP VIS ECCV
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Revaud J, 2015, PROC CVPR IEEE, P1164, DOI 10.1109/CVPR.2015.7298720
   Richard A, 2016, PROC CVPR IEEE, P3131, DOI 10.1109/CVPR.2016.341
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Shuai W, 2016, PR INT CONGR SOUND V
   Singh G., 2017, INT C COMP VIS ICCV
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341
   van Gemert Jan, 2015, BRIT MACH VIS C BMVC
   Wang P., 2018, IEEE T MULTIMEDIA TM
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Weinzaepfel P., 2015, INT C COMP VIS ICCV
   Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu H., 2017, INT C COMP VIS ICCV
   Yang X., 2014, EUR C COMP VIS ECCV
   Ye Y., 2016, ACM INT C MULT RETR
   Yu G, 2015, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2015.7298735
   Yuan J, 2016, PROC CVPR IEEE, P3093, DOI 10.1109/CVPR.2016.337
   Zhu H., 2017, INT C COMP VIS ICCV
NR 47
TC 9
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 515
EP 524
DI 10.1016/j.jvcir.2018.12.019
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100050
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, ZW
   Chen, GE
   Jin, XQ
   Wang, YQ
AF Jiang, Zhengwei
   Chen, Guoen
   Jin, Xueqi
   Wang, Yueqiang
TI RETRACTED: Analysis of security operation and maintenance system using
   privacy utility in media environment (Retracted article. See vol. 69,
   2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE KVM; Safety; Operation and maintenance control; Intelligent management
AB At present, the power information room mostly adopts the analog KVM matrix, or adopts the digital KVM matrix, but there are various defects in the two methods. In order to solve the problem of traditional mode, this paper developed a new security operation and maintenance management system composed of 5 parts. It also has the advantages of traditional mode and overcomes the shortcomings of the traditional model. First, introduces the advantages and disadvantages of two kinds of traditional model, puts forward the necessity of improving; then, the security operation management system each part of the design, and set out to achieve its function; finally carries on the analysis of security. The results show that the security operation and maintenance management system improves the security of the system and helps the system to operate more intelligently and safely based on the guarantee of the required functions. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Jiang, Zhengwei; Jin, Xueqi] State Grid Zhejiang Elect Power Co LTD, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Guoen; Wang, Yueqiang] State Grid Jiaxing Elect Power Supply Co, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Jiang, ZW (corresponding author), State Grid Zhejiang Elect Power Co LTD, Hangzhou, Zhejiang, Peoples R China.
EM 1668900100@qq.com
CR [敖青云 Ao Qingyun], 2012, [计算机应用与软件, Computer Applications and Software], V29, P217
   Calmon FD, 2012, ANN ALLERTON CONF, P1401, DOI 10.1109/Allerton.2012.6483382
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hattori M., 2016, ANAL SMART METER DAT
   Hattori M., 2016, PRIVACY UTILITY TRAD
   Kolter J Zico, 2011, M ETAGUSED, V25, P59
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Rajagopalan S. R., 2011, 2011 IEEE Second International Conference on Smart Grid Communications (SmartGridComm 2011), P190, DOI 10.1109/SmartGridComm.2011.6102315
   Sankar L, 2013, IEEE T SMART GRID, V4, P837, DOI 10.1109/TSG.2012.2211046
   Wu Qiang, 2010, GUANGDONG ELECT POWE, V23, P53
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhao Kexin, 2010, INSTRUM TECH SENSOR, V9, P90
   张哲, 2008, [电力系统自动化, Automation of Electric Power Systems], V32, P106
NR 17
TC 1
Z9 1
U1 3
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 177
EP 181
DI 10.1016/j.jvcir.2018.09.007
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500017
DA 2024-07-18
ER

PT J
AU Yang, CW
   Feng, HJ
   Xu, ZH
   Li, Q
   Chen, YT
AF Yang, Chenwei
   Feng, Huajun
   Xu, Zhihai
   Li, Qi
   Chen, Yueting
TI The spatial correlation problem of noise in imaging deblurring and its
   solution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatial correlation coefficient; Noise probability distribution model;
   Colour interpolation; Colour space transformation; Correction algorithm;
   Image deblurring
ID KERNEL ESTIMATION; MOTION
AB We describe the spatial correlation problem of noise in colour digital images and analyse its cause. Pixel correlated image processing procedures, such as CFA colour interpolation and colour space transformation, mainly lead to this problem. Considering this problem, we propose a new noise model based on a joint Gaussian probability distribution. Furthermore, we present an algorithm that makes the revised noise model fit the existing image deconvolution well. The parameters of our algorithm depend only on the image processing procedures of the imaging system. Finally, we apply the proposed algorithm to revise two typical image deconvolution methods and perform simulations and real-world experiments. Both the quantitative indicators and visual performance of the image deblurring results show that the revised deconvolution methods based on our noise model behave better in reducing the noise and ringing artefacts, thus improving the image quality compared with the methods that use the original noise model. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yang, Chenwei; Feng, Huajun; Xu, Zhihai; Li, Qi; Chen, Yueting] Zhejiang Univ, State Key Lab Modern Opt Instrumentat, Zheda Rd 38, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Yang, CW (corresponding author), Zhejiang Univ, State Key Lab Modern Opt Instrumentat, Zheda Rd 38, Hangzhou 310027, Zhejiang, Peoples R China.
EM yangchenwei@zju.edu.cn
OI Yang, Chenwei/0000-0001-7201-7205
FU Fundamental Research Funds for the Central Universities; Major Science
   and Technology Projects of Yunnan Province, China
FX This research is supported by the the Fundamental Research Funds for the
   Central Universities and the Major Science and Technology Projects of
   Yunnan Province, China.
CR [Anonymous], 1998, YUV LUMINANCE CONSID
   [Anonymous], MATHEMATICIEN EXTRAP
   [Anonymous], FXSCRIPT REFERENCE R
   [Anonymous], VIDEO RENDERING 8 BI
   Bar L, 2006, INT J COMPUT VISION, V70, P279, DOI 10.1007/s11263-006-6468-1
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho TS, 2011, PROC CVPR IEEE, P241, DOI 10.1109/CVPR.2011.5995479
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fortunato HE, 2014, VISUAL COMPUT, V30, P661, DOI 10.1007/s00371-014-0966-x
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES, V455
   Joshi N, 2009, PROC CVPR IEEE, P1550, DOI 10.1109/CVPRW.2009.5206802
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim JH, 2007, INT GEOSCI REMOTE SE, P111, DOI 10.1109/IGARSS.2007.4422742
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   LUCY LB, 1974, ASTRON J, V79, P745, DOI 10.1086/111605
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Stroebel L.D., 1993, Focal Encyclopedia of Photography, V3
   Tai YW, 2012, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2012.6247653
   Tikhonov A. N, 2013, NUMERICAL METHODS SO
   Whyte O, 2014, INT J COMPUT VISION, V110, P185, DOI 10.1007/s11263-014-0727-3
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zhong L, 2013, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2013.85
NR 29
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 167
EP 176
DI 10.1016/j.jvcir.2018.09.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500016
DA 2024-07-18
ER

PT J
AU Hannane, R
   Elboushaki, A
   Afdel, K
AF Hannane, Rachida
   Elboushaki, Abdessamad
   Afdel, Karim
TI MSKVS: Adaptive mean shift-based keyframe extraction for video
   summarization and a new objective verification approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Keyframe extraction; Video summarization; Mean shift; Features
   extraction; Summarization quality; Objective video summary evaluation
ID KEY-FRAME EXTRACTION; SHOT-BOUNDARY DETECTION; SELECTION; SCHEME
AB Video abstraction is an interesting topic that aims at briefly representing the entire video stream by producing a short summary either statically or dynamically. In this paper, we present an optimal static video summarization method based on keyframe extraction, termed as MSKVS. The proposed MSKVS has three major components: A new feature representation is exploited to describe the visual content of the video, a simple and fast algorithm is proposed to eliminate most similar and redundant frames, and an adaptive mean shift algorithm is used to select the most representative keyframes. We further develop a novel verification technique to measure the amount of information preserved by the produced summary and to make sure that it deserves to present the entire video stream regardless of human opinion impact. We report experimental results on six challenging datasets using different evaluation metrics, showing that MSKVS achieves state-of-the-art performances in a short computation time.
C1 [Hannane, Rachida; Elboushaki, Abdessamad; Afdel, Karim] Ibn Zohr Univ, Fac Sci, Lab Comp Syst & Vis, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Hannane, R (corresponding author), Ibn Zohr Univ, Fac Sci, Lab Comp Syst & Vis, Agadir 80000, Morocco.
EM rachida.hannane@edu.uiz.ac.ma; abdessamad.elboushaki@edu.uiz.ac.ma;
   k.afdel@uiz.ac.ma
RI Karim, AFDEL/AAC-7992-2019
OI Karim, AFDEL/0000-0002-0828-2116
FU Moroccan government through the CNRST funding program [PPR2-2015]
FX This work was supported by the PPR2-2015 project grant, financed by
   Moroccan government through the CNRST funding program.
CR Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 2016, P THE 3 MULT INT SOC, DOI [DOI 10.1145/2955129.2955179, 10.1007/s00438-016-1266-0, DOI 10.1007/S00438-016-1266-0]
   [Anonymous], 2013, Iberoamerican Congress on Pattern Recognition
   Calic J., 2004, WORKSH IM AN MULT IN
   CASELLA G, 1992, AM STAT, V46, P167, DOI 10.2307/2685208
   Chasanis V, 2008, LECT NOTES COMPUT SC, V5163, P847, DOI 10.1007/978-3-540-87536-9_87
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cirne M. V. M., 2017, MULTIMED TOOLS APPL, P1
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demir M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1071, DOI 10.1109/ICCVW.2015.140
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   Elboushaki A, 2017, PATTERN RECOGN, V64, P168, DOI 10.1016/j.patcog.2016.11.004
   Fei MJ, 2016, IET COMPUT VIS, V10, P280, DOI 10.1049/iet-cvi.2015.0237
   Ferreira L, 2015, SIGNAL PROCESS-IMAGE, V39, P98, DOI 10.1016/j.image.2015.09.005
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Guo Z, 2016, NEUROCOMPUTING, V208, P299, DOI 10.1016/j.neucom.2016.03.083
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hammoud R., 2000, International Workshop on Real-Time Image Sequence Analysis (RISA '00), P79
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Hannane R., 2015, 5 INT C INF COMM TEC, P1
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Hannane R, 2016, I C COMP GRAPH IM VI, P312, DOI 10.1109/CGiV.2016.67
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Janvier B, 2006, MULTIMED TOOLS APPL, V30, P273, DOI 10.1007/s11042-006-0026-2
   Jeong DJ, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0122-9
   Jiang RM, 2009, STUD COMPUT INTELL, V231, P27
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Knoche H, 1999, INT WORKSH QUAL SERV, P12, DOI 10.1109/IWQOS.1999.766473
   Kuanar SK, 2013, J VIS COMMUN IMAGE R, V24, P1212, DOI 10.1016/j.jvcir.2013.08.003
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li YS, 2010, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE 2010, VOL 1: CODES AND STANDARDS, P851, DOI 10.1145/1873951.1874095
   Li Z, 2005, IEEE T CIRC SYST VID, V15, P1245, DOI 10.1109/TCSVT.2005.854230
   Liu LJ, 2005, IEEE T CIRC SYST VID, V15, P869, DOI 10.1109/TCSVT.2005.848347
   Liu X, 2012, INT C PATT RECOG, P2565
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luan Q, 2014, IEEE INT CON MULTI
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Marvaniya S, 2016, IEEE IMAGE PROC, P176, DOI 10.1109/ICIP.2016.7532342
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Mentzelopoulos M., 2004, P 6 ACM SIGMM INT WO, P39, DOI DOI 10.1145/1026711.1026719
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Morère O, 2015, IEEE IMAGE PROC, P3165, DOI 10.1109/ICIP.2015.7351387
   Mukherjee DP, 2007, IEEE T CIRC SYST VID, V17, P612, DOI 10.1109/TCSVT.2007.895353
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Cirne MVM, 2014, LECT NOTES COMPUT SC, V8827, P901, DOI 10.1007/978-3-319-12568-8_109
   Nasreen A., 2013, INT J COMPUT SCI COM, V3, P194
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Omidyeganeh M, 2011, IEEE T IMAGE PROCESS, V20, P2730, DOI 10.1109/TIP.2011.2143421
   Pan L., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P385
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Peng J., 2009, IEEE MULTIMEDIA, V2, P64
   Raikwar Suresh C., 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P297, DOI 10.1109/ICCCT.2014.7001508
   Ren HY, 2014, INT C PATT RECOG, P2389, DOI 10.1109/ICPR.2014.414
   Ren TW, 2010, ADV PATTERN RECOGNIT, P243, DOI 10.1007/978-1-84996-507-1_10
   Sabbar W, 2012, 2012 SECOND INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P190, DOI 10.1109/INTECH.2012.6457809
   Sandip M., 2012, INT J SCI RES PUBLIC, V2, P1
   Sheena CV, 2015, PROCEDIA COMPUT SCI, V70, P36, DOI 10.1016/j.procs.2015.10.021
   Shroff N, 2010, IEEE T MULTIMEDIA, V12, P853, DOI 10.1109/TMM.2010.2058795
   Song GH, 2014, AEU-INT J ELECTRON C, V68, P783, DOI 10.1016/j.aeue.2014.03.004
   Sze KW, 2005, IEEE T CIRC SYST VID, V15, P1148, DOI 10.1109/TCSVT.2005.852623
   Taniguchi Y., 1995, MULTIMEDIA 95 P 3 AC, P25
   Thakre KS, 2016, PROCEDIA COMPUT SCI, V78, P790, DOI 10.1016/j.procs.2016.02.058
   Tongwei Ren, 2008, 2008 IEEE International Conference on Data Mining Workshops, P874, DOI 10.1109/ICDMW.2008.55
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Valdes V, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2240136.2240138
   Xu Q, 2012, INT C PATT RECOG, P1892
   Xu Q, 2014, INFORM SCIENCES, V278, P736, DOI 10.1016/j.ins.2014.03.088
   Yang Y, 2011, P AM MATH SOC, V139, P3171, DOI 10.1090/S0002-9939-2011-10735-4
   Yongkang Wong, 2011, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops 2011), P74, DOI 10.1109/CVPRW.2011.5981881
NR 81
TC 13
Z9 13
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 179
EP 200
DI 10.1016/j.jvcir.2018.06.002
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100017
DA 2024-07-18
ER

PT J
AU Wang, GJ
   Chen, XH
   Guo, HK
   Zhang, CR
AF Wang, Guijin
   Chen, Xinghao
   Guo, Hengkai
   Zhang, Cairong
TI Region ensemble network: Towards good practices for deep 3D hand pose
   estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional network; Hand pose estimation; Human pose estimation;
   Fingertip detection; Ensemble learning; Depth imaging
ID CONVOLUTIONAL NETWORKS
AB 3D hand pose estimation is an important and challenging problem for human-computer interaction. Recently convolutional networks (ConvNet) with sophisticated design have been employed to address it, but the improvement is not so significant. To exploit good practice and promote the performance for hand pose estimation, we propose a Region Ensemble Network (REN) for directly 3D coordinate regression. It first partitions the last convolutional outputs of ConvNet into several grid regions. Results from separate fully-connected (FC) regressors on each regions are integrated by another FC layer to perform estimation. By exploitation of several training strategies including data augmentation and smooth L-1 loss, REN significantly improves the performance of ConvNet for hand pose estimation. Experiments demonstrate that our approach achieves strong performance on par or better than state-of-the-art algorithms on three public hand pose datasets. We also experiment our methods on fingertip detection and human pose datasets and obtain state-of-the-art accuracy.
C1 [Wang, Guijin; Chen, Xinghao; Guo, Hengkai; Zhang, Cairong] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, GJ (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM wangguijin@tsinghua.edu.cn; chen-xh13@mails.tsinghua.edu.cn;
   guohengkaighk@gmail.com; zcr17@mails.tsinghua.edu.cn
RI Chen, Xinghao/AAA-6824-2019
OI Chen, Xinghao/0000-0002-2102-8235
FU National High-Tech R&D Program (863 Program) of China [2015AA016304]
FX This work was partially supported by National High-Tech R&D Program (863
   Program) of China (No. 2015AA016304). The authors are grateful to the
   reviewers for their constructive comments.
CR [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46448-0_10
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], COMP VIS WINT WORKSH
   [Anonymous], SPIE PHOTONICS EUROP
   [Anonymous], 2 STREAM CONVOLUTION
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2014, ACM T GRAPHIC, DOI DOI 10.1145/2629500
   [Anonymous], NETWORK EXPERTS LARG
   [Anonymous], RULE THUMB DEEP DERO
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], EUR C COMP VIS
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], LEARNING SEARCH MANI
   [Anonymous], 2016, IEEE C COMP VIS PATT
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chen HZ, 2016, PATTERN RECOGN, V55, P148, DOI 10.1016/j.patcog.2016.01.020
   Chen L.-C., DEEPLAB SEMANTIC IMA
   Chen X., 2016, PROC VIS COMMUN IMAG, P1, DOI DOI 10.1109/VCIP.2016.7805509
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   Choi C, 2015, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2015.269
   De Smedt Q., 2016, P IEEE C COMPUTER VI, P1
   Ge L., 2017, P IEEE C COMP VIS PA, P1991
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Jia Y., Caffe: Convolutional architecture for fast feature embedding
   Jung HY, 2015, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2015.7298861
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Li HX, 2016, COMPUT VIS IMAGE UND, V153, P120, DOI 10.1016/j.cviu.2016.07.002
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seshadri M, 2017, IEEE INT C INTELL TR
   Shi CB, 2015, IEEE T IMAGE PROCESS, V24, P1412, DOI 10.1109/TIP.2015.2393054
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wan C., 2017, CVPR, P680
   Wang GJ, 2013, APPL OPTICS, V52, P516, DOI 10.1364/AO.52.000516
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhou X., 2016, IJCAI
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 47
TC 56
Z9 59
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 404
EP 414
DI 10.1016/j.jvcir.2018.04.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100033
DA 2024-07-18
ER

PT J
AU Wang, L
   Zhu, L
   Dong, X
   Liu, L
   Sun, JD
   Zhang, HX
AF Wang, Li
   Zhu, Lei
   Dong, Xiao
   Liu, Li
   Sun, Jiande
   Zhang, Huaxiang
TI Joint feature selection and graph regularization for modality-dependent
   cross-modal retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-modal retrieval; Feature selection; Subspace learning; Graph
   regularization
AB Most existing cross-modal retrieval methods ignore the discriminative semantics embedded in multi-modal data and the unique characteristics of different sub-retrieval tasks. To address the problem, we propose a novel approach in this paper, which is named Joint Feature selection and Graph regularization for Modality-dependent cross-modal retrieval (JFGM). The key idea of JFGM is learning modality-dependent subspaces for different sub-retrieval tasks while simultaneously preserving the semantic consistency of multi-modal data. Specifically, besides to the shared subspace learning between different modalities, a linear regression term is introduced to further correlate the discovered modality-dependent subspace with the explicit semantic space. Furthermore, a multi-model graph regularization term is formulated to preserve the inter-modality and intra-modality semantic consistency. In order to avoid over-fitting problems and select the discriminative features, l(2,1)-norm is imposed on the projection matrices. Experimental results on several publicly available datasets demonstrate the superiority of the proposed method compared with several state-of-the-art approaches.
C1 [Wang, Li; Zhu, Lei; Dong, Xiao; Liu, Li; Sun, Jiande; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Sun, Jiande; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhu, L; Sun, JD; Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM leizhu0608@gmail.com; jiandesun@hotmail.com; huaxzhang@163.com
RI Zhu, Lei/AAC-6810-2019; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-2993-7142; Zhu, Lei/0000-0002-5348-7532; Dong,
   Xiao/0000-0001-9519-612X
FU National Natural Science Foundation of China [61772322, 61572298,
   61702310, 61402268, 61401260, 61601268]; Technology and Development
   Project of Shandong [2017GGX10117]
FX The work is partially supported by the National Natural Science
   Foundation of China (No. 61772322, 61572298, 61702310, 61402268,
   61401260, 61601268) and the Technology and Development Project of
   Shandong (No. 2017GGX10117).
CR Andrew G., 2013, P ICML, P1247
   Cao Y, 2017, AAAI CONF ARTIF INTE, P3974
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Dong X, 2018, MULTIMED TOOLS APPL, V77, P3579, DOI 10.1007/s11042-017-5164-1
   Gu XL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P190, DOI 10.1145/3123266.3123441
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hu MQ, 2018, IEEE T IMAGE PROCESS, V27, P545, DOI 10.1109/TIP.2017.2749147
   Hwang S. J., 2010, BRIT MACHINE VISION, P1
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   Li K, 2017, IEEE T PATTERN ANAL, V39, P1825, DOI 10.1109/TPAMI.2016.2610969
   Liu AA, 2017, J VIS COMMUN IMAGE R, V48, P353, DOI 10.1016/j.jvcir.2017.04.003
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nikolova M, 2005, SIAM J SCI COMPUT, V27, P937, DOI 10.1137/030600862
   Peng YX, 2016, IEEE T CIRC SYST VID, V26, P583, DOI 10.1109/TCSVT.2015.2400779
   Ranjan V, 2015, IEEE I CONF COMP VIS, P4094, DOI 10.1109/ICCV.2015.466
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Wang J, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P347, DOI 10.1145/2671188.2749341
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wang LQ, 2017, SIGNAL PROCESS, V131, P249, DOI 10.1016/j.sigpro.2016.08.012
   Wang YX, 2017, IETE J RES, V63, P358, DOI 10.1080/03772063.2016.1274240
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Wu JL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P917, DOI 10.1145/3077136.3080678
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yang EK, 2017, AAAI CONF ARTIF INTE, P1618
   Yao T, 2016, NEUROCOMPUTING, V193, P250, DOI 10.1016/j.neucom.2016.02.016
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
   Zhang L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3406
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhou T, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01512
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 44
TC 14
Z9 14
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 213
EP 222
DI 10.1016/j.jvcir.2018.05.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800019
DA 2024-07-18
ER

PT J
AU Chen, CC
AF Chen, Chien-Chang
TI Essential secret image sharing scheme with equal-sized shadows
   generation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Essential; Non-essential; Three-layered structure
ID CELLULAR-AUTOMATA; AUTHENTICATION; STEGANOGRAPHY
AB A (t, s, k, n) essential secret image sharing scheme (ESIS) shares a secret image between s essential and n-s non-essential shadows, where t essential shadows and total k shadows are needed to recover the secret image. This paper presents a three-layered structure for ESIS by generating equal-sized essential and non-essential shadows for security to prevent the discovery of essential shadows using only the size difference. In the first layer, two criteria of t essential shadows and totally k shadows are needed. The second and third layers generate essential and non-essential shadows to fit the requirement of the (t, s, k, n) thresholds. The proposed scheme is proved to fit ESIS and equal-sized requirements with properly chosen parameters. Theoretical analysis and experimental results show that the proposed scheme is superior to other schemes on the smallest shadow sizes among equal-sized ESIS schemes.
C1 [Chen, Chien-Chang] Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
C3 Tamkang University
RP Chen, CC (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM ccchen34@mail.tku.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
FU National Science Council of the Republic of China [NSC
   105-2221-E-032-053]
FX This paper was partially supported by the National Science Council of
   the Republic of China under contract NSC 105-2221-E-032-053.
CR Chang CC, 2011, INFORM SCIENCES, V181, P3073, DOI 10.1016/j.ins.2011.03.002
   Chen CC, 2016, J VIS COMMUN IMAGE R, V38, P595, DOI 10.1016/j.jvcir.2016.04.004
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen SK, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.1.013103
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Le THN, 2011, DIGIT SIGNAL PROCESS, V21, P734, DOI 10.1016/j.dsp.2011.07.004
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu ZJ, 2008, OPT COMMUN, V281, P5322, DOI 10.1016/j.optcom.2008.07.048
   Subba Rao Y. V., 2014, International Journal of Network Security, V16, P249
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tso HK, 2008, OPT ENG, V47, DOI 10.1117/1.2955502
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang RZ, 2010, J VIS COMMUN IMAGE R, V21, P751, DOI 10.1016/j.jvcir.2010.06.001
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
NR 23
TC 18
Z9 19
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 143
EP 150
DI 10.1016/j.jvcir.2018.02.006
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300014
DA 2024-07-18
ER

PT J
AU Chiang, PY
   Lin, CV
   Tseng, CH
AF Chiang, Pei-Ying
   Lin, Chun-Von
   Tseng, Cheng-Hua
TI Generation of Chinese ink portraits by blending face photographs with
   Chinese ink paintings
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Active shape model; Chinese portrait; Facial feature extraction;
   Non-photorealistic rendering
ID PARALLEL FRAMEWORK; HEVC; DECISION
AB In this study, an interactive Chinese portrait rendering system was developed. This portrait rendering system can generate a user-lookalike ink portrait by blending the user's face with a selected Chinese ink painting. It first automatically analyzes the user's facial features and then integrates them into a selected Chinese painting. This system comprises two processes: an offline process and an online process. During the offline process, a collection of Chinese portrait paintings is configured (e.g., the face masks and facial coordinates of the paintings are determined). Subsequently, blending-ready templates (faces without facial features) are prepared for the online process. During the online process, the user integrates their photograph into our rendering system. The system automatically analyzes the face orientation, color, and facial features and adjusts the attributes of the photograph to match the template's configuration. The produced facial image is blended into a selected template, which preserves the textures of the original Chinese painting. The results reveal that our system preserved both the user characteristics and original painting styles. In this study, user-portrait matching was experimentally evaluated, and a questionnaire survey on satisfaction with painting style was conducted.
C1 [Chiang, Pei-Ying; Lin, Chun-Von; Tseng, Cheng-Hua] Natl Taipei Univ Technol, Taipei, Taiwan.
C3 National Taipei University of Technology
RP Chiang, PY (corresponding author), Natl Taipei Univ Technol, Taipei, Taiwan.
EM peiyingc@csie.ntut.edu.tw
RI Li, Mengqi/AAG-6804-2021
FU Taiwan Ministry of Science and Technology [MOST 105-2221-E-027-088, MOST
   104-2221-E-027-057]
FX This research was supported by Taiwan Ministry of Science and Technology
   under Grant Nos. MOST 105-2221-E-027-088 and MOST 104-2221-E-027-057.
CR [Anonymous], 2000, PROC VIS
   [Anonymous], 2001, Encyclopedia of Mathematics
   Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Chen S., 2008, P 16 INT C MULTIMEDI
   Chiang P.-Y., 2004, P AS C COMP VIS 2004
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Geng X, 2014, PROC CVPR IEEE, P1837, DOI 10.1109/CVPR.2014.237
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Lin Min., 2013, Proceedings of the 21st ACM International Conference on Multimedia, MM'13, P183
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milborrow S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P380
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Teodora V., 2007, 7 IEEE RAS INT C HUM
   Xie N., 2010, Proc. NPAR '10, P63
   Xu T.-C., 2012, SIGGRAPH ASIA 2012 T
   Yan C., 2017, EFFECTIVE UYGHUR LAN, P1
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang W, 2014, 2014 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P237, DOI 10.1109/CW.2014.40
   Zhang YJ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/463930
NR 25
TC 2
Z9 2
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 33
EP 44
DI 10.1016/j.jvcir.2018.02.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300004
DA 2024-07-18
ER

PT J
AU Kuncheva, LI
   Yousefi, P
   Almeida, J
AF Kuncheva, Ludmila I.
   Yousefi, Paria
   Almeida, Jurandy
TI Edited nearest neighbour for selecting keyframe summaries of egocentric
   videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Keyframe summary; Nearest neighbour classifier; Instance selection;
   Egocentric video; Feature representations
ID KEY FRAME EXTRACTION
AB A keyframe summary of a video must be concise, comprehensive and diverse. Current video summarisation methods may not be able to enforce diversity of the summary if the events have highly similar visual content, as is the case of egocentric videos. We cast the problem of selecting a keyframe summary as a problem of prototype (instance) selection for the nearest neighbour classifier (1-nn). Assuming that the video is already segmented into events of interest (classes), and represented as a dataset in some feature space, we propose a Greedy Tabu Selector algorithm (GTS) which picks one frame to represent each class. An experiment with the UT (Egocentric) video database and seven feature representations illustrates the proposed keyframe summarisation method. GTS leads to improved match to the user ground truth compared to the closest-to-centroid baseline summarisation method. Best results were obtained with feature spaces obtained from a convolutional neural network (CNN).
C1 [Kuncheva, Ludmila I.; Yousefi, Paria] Bangor Univ, Sch Comp Sci, Dean St, Bangor LL57 1UT, Gwynedd, Wales.
   [Almeida, Jurandy] Fed Univ Sao Paulo UNIFESP, Inst Sci & Technol, BR-12247014 Sao Jose Dos Campos, SP, Brazil.
C3 Bangor University; Universidade Federal de Sao Paulo (UNIFESP)
RP Kuncheva, LI (corresponding author), Bangor Univ, Sch Comp Sci, Dean St, Bangor LL57 1UT, Gwynedd, Wales.
EM l.i.kuncheva@bangor.ac.uk; paria.yousefi@bangor.ac.uk;
   jurandy.almeida@unifesp.br
RI Almeida, Jurandy/I-2177-2012; Kuncheva, Ludmila/J-4357-2014
OI Almeida, Jurandy/0000-0002-4998-6996; Kuncheva,
   Ludmila/0000-0002-0415-6964
FU Leverhulme Trust, UK [RPG-2015-188]; Sao Paulo Research Foundation -
   FAPESP [2016/06441-7]; Fundacao de Amparo a Pesquisa do Estado de Sao
   Paulo (FAPESP) [16/06441-7] Funding Source: FAPESP
FX This work was done under project RPG-2015-188 funded by The Leverhulme
   Trust, UK. Also, we are grateful to the Sao Paulo Research Foundation -
   FAPESP (grant #2016/06441-7).
CR Almeida J, 2013, J VIS COMMUN IMAGE R, V24, P729, DOI 10.1016/j.jvcir.2012.01.009
   Almeida J, 2012, PATTERN RECOGN LETT, V33, P397, DOI 10.1016/j.patrec.2011.08.007
   [Anonymous], 2015, IEEE INT CONF MULTI, DOI DOI 10.1109/ICMEW.2015.7169863
   Apostolidis Evlampios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6583, DOI 10.1109/ICASSP.2014.6854873
   Bambach S., 2015, SURVEY RECENT ADV CO
   Bolaños M, 2017, IEEE T HUM-MACH SYST, V47, P77, DOI 10.1109/THMS.2016.2616296
   Brighton H, 2002, DATA MIN KNOWL DISC, V6, P153, DOI 10.1023/A:1014043630878
   Chao GC, 2010, J VIS COMMUN IMAGE R, V21, P682, DOI 10.1016/j.jvcir.2010.05.002
   Chowdhury S, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P607, DOI 10.1145/2671188.2749393
   Cooper M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P502, DOI 10.1109/ICME.2005.1521470
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dasarathy B. V., 1991, Nearest neighbor (NN) norms, V317
   del Molino AG, 2017, IEEE T HUM-MACH SYST, V47, P65, DOI 10.1109/THMS.2016.2623480
   Doherty AidenR., 2008, INT C CONTENT BASED, P259
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   García S, 2012, IEEE T PATTERN ANAL, V34, P417, DOI 10.1109/TPAMI.2011.142
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Gong YH, 2003, MULTIMEDIA SYST, V9, P157, DOI 10.1007/s00530-003-0086-3
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   Harvey M, 2016, PERVASIVE MOB COMPUT, V27, P14, DOI 10.1016/j.pmcj.2015.12.002
   Le HV, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4793, DOI 10.1145/2858036.2858413
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   Jinda-Apiraksa A., 2013, proceedings of the IAPR conference on Machine Vision Applications (IAPR MVA 2013), P33
   Kim MH, 2012, IEEE INT SYMP CIRC S, P612, DOI 10.1109/ISCAS.2012.6272106
   Kuncheva L. I., 2017, ARXIV171206899
   Kuncheva LI, 2017, INT CONF IMAG PROC
   Lee YJ, 2015, INT J COMPUT VISION, V114, P38, DOI 10.1007/s11263-014-0794-5
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lidon A., 2015, CORR
   Liu GT, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P1126, DOI 10.1109/ICIS.2009.124
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omidyeganeh M, 2011, IEEE T IMAGE PROCESS, V20, P2730, DOI 10.1109/TIP.2011.2143421
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Priya GGL, 2014, ECOL INFORM, V23, P107, DOI 10.1016/j.ecoinf.2013.09.003
   Sidiropoulos P, 2013, IEEE IMAGE PROC, P3991, DOI 10.1109/ICIP.2013.6738822
   Sidiropoulos P, 2011, IEEE T CIRC SYST VID, V21, P1163, DOI 10.1109/TCSVT.2011.2138830
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tapaswi M, 2014, PROC CVPR IEEE, P827, DOI 10.1109/CVPR.2014.111
   Triguero I, 2012, IEEE T SYST MAN CY C, V42, P86, DOI 10.1109/TSMCC.2010.2103939
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Varini P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P539, DOI 10.1145/2671188.2749343
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vermaak J., 2002, P BRIT MACH VIS C 20
   Vila M, 2013, SIGNAL IMAGE VIDEO P, V7, P507, DOI 10.1007/s11760-013-0452-3
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Wilson DR, 2000, MACH LEARN, V38, P257, DOI 10.1023/A:1007626913721
   Xiong B, 2014, LECT NOTES COMPUT SC, V8693, P282, DOI 10.1007/978-3-319-10602-1_19
   Yingbo Li, 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P163, DOI 10.1109/CBMI.2011.5972539
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 61
TC 15
Z9 15
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 118
EP 130
DI 10.1016/j.jvcir.2018.02.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Guo, X
   Tie, Y
   Ye, L
   Yan, JY
AF Guo, Xin
   Tie, Yun
   Ye, Long
   Yan, Jinyao
TI Identifying facial expression using adaptive sub-layer compensation
   based feature extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Marr-Hildreth detector; Adaptive sub-layer compensation; Elastic body
   spline; Discriminative Isomap
ID HUMAN EMOTIONAL STATE; DIMENSIONALITY REDUCTION; FACE RECOGNITION;
   EDGE-DETECTION; TRANSFORMATION
AB In this paper, an automatic facial expression recognition method is proposed to extract feature from video sequences. First, we modified the Marr-Hildreth detector with Wiener filtering, adaptive sub-layer compensation (ASLC) and hysteresis to alleviate the negative effects of traditional one and then, the deformable elastic body spline (EBS) model is extended by using different Poisson's rate to model the facial muscle fiber, which accommodate the fact that different muscle fiber has a different way of deformation. The ASLC feature and the improved EBS feature are fused together to form the facial feature vector. Further, we utilize the Discriminative Isomap (D-Isomap) approach to embed the facial feature into a low dimensional space. The final decision is made by computing the nearest class center of the feature space. RML Emotion database and Cohn-Kanade (CK) database are both used for the experiment and the results demonstrate the effectiveness of the proposed method.
C1 [Guo, Xin; Tie, Yun] Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Henan, Peoples R China.
   [Ye, Long; Yan, Jinyao] Commun Univ China, Minist Educ, Key Lab Media Audio & Video, Beijing, Peoples R China.
C3 Zhengzhou University; Communication University of China
RP Tie, Y (corresponding author), Zhengzhou Univ, Sch Informat Engn, Zhengzhou, Henan, Peoples R China.
EM guoxin19880806@163.com; ieytie@zzu.edu.cn; yelong@cuc.edu.cn;
   jyan@cuc.edu.cn
RI yan, jy/ISS-1790-2023
FU National Natural Science Foundation of China [61640214]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61640214.
CR Ahmad MB, 1999, IEEE T CONSUM ELECTR, V45, P674, DOI 10.1109/30.793567
   Anderson K, 2006, IEEE T SYST MAN CY B, V36, P96, DOI 10.1109/TSMCB.2005.854502
   [Anonymous], INT J COMPUTER VISIO
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Cambria E, 2016, IEEE INTELL SYST, V31, P102, DOI 10.1109/MIS.2016.31
   Cao YY, 2010, 2010 THIRD INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY AND SECURITY INFORMATICS (IITSI 2010), P258, DOI 10.1109/IITSI.2010.11
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Cohen I, 2003, LECT NOTES COMPUT SC, V2728, P184
   Cohn JF, 2010, IEEE SIGNAL PROC MAG, V27, P128, DOI 10.1109/MSP.2010.938102
   Davis MH, 1997, IEEE T MED IMAGING, V16, P317, DOI 10.1109/42.585766
   DAVIS MH, 1995, COMP MED SY, P81, DOI 10.1109/CBMS.1995.465443
   De Silva LC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1310
   Ekman B.P., FACIAL ACTION CODING
   Friedrich T., NONLINEAR DIMENSIONA
   Gao W., 2010, INT C ED TECHN COMP
   Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151
   Harish Kumar J. R., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P281, DOI 10.1109/ICSIP.2010.5697429
   Hassanien AE, 1998, COMP ANIM CONF PROC, P119, DOI 10.1109/CA.1998.681916
   Ho SY, 2001, IEEE T SYST MAN CY B, V31, P706, DOI 10.1109/3477.956032
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kuo CJ, 2005, IEEE T IMAGE PROCESS, V14, P2159, DOI 10.1109/TIP.2005.857279
   Liu QH, 2011, INT ARCH PHOTOGRAMM, V38-8, P151
   Lyons M. J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P202, DOI 10.1109/AFGR.2000.840635
   Marieb E, 2001, HUMAN ANATOMY PHYSL, V3, P82
   Muthukrishnan R., 2012, INT J COMPUTER ENCE, V3, P250, DOI [10.5121/ijcsit.2011.3620, DOI 10.5121/IJCSIT.2011.3620]
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sebe N, 2010, IEEE T MULTIMEDIA, V12, P477, DOI 10.1109/TMM.2010.2052315
   Senthilkumaran N., 2014, INT J SOFT COMPUT EN, V1, P250
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tie Y, 2013, IEEE T CIRC SYST VID, V23, P142, DOI 10.1109/TCSVT.2012.2203210
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P659, DOI 10.1109/TMM.2008.921734
   Wu YM, 2004, INT C PATT RECOG, P171, DOI 10.1109/ICPR.2004.1333731
   Yang M.H., 2002, INT C IM PROC 2002 P, V2
   Yun T, 2013, PATTERN RECOGN, V46, P529, DOI 10.1016/j.patcog.2012.08.002
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang JY, 2010, INT C COMPUT ENG APP, P591, DOI 10.1109/ICCEA.2010.278
   Zhao DF, 2009, IEEE T PATTERN ANAL, V31, P86, DOI 10.1109/TPAMI.2008.34
NR 42
TC 5
Z9 5
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 65
EP 73
DI 10.1016/j.jvcir.2017.11.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700007
DA 2024-07-18
ER

PT J
AU Vitorino, P
   Avila, S
   Perez, M
   Rocha, A
AF Vitorino, Paulo
   Avila, Sandra
   Perez, Mauricio
   Rocha, Anderson
TI Leveraging deep neural networks to fight child pornography in the age of
   social media
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Child pornography; SEIC content; Deep learning; Transfer learning; Fine
   tuning
ID REPRESENTATION
AB Over the past two decades, the nature of child pornography in terms of generation, distribution and possession of images drastically changed, evolving from basically covert and offline exchanges of content to a massive network of contacts and data sharing. Nowadays, the internet has become not only a transmission channel but, probably, a child pornography enabling factor by itself. As a consequence, most countries worldwide consider a crime to take, or permit to be taken, to store or to distribute images or videos depicting any child pornography grammar. But before action can even be taken, we must detect the very existence or presence of sexually exploitative imagery of children when gleaning over vast troves of data. With this backdrop, veering away from virtually all off-the-shelf solutions and existing methods in the literature, in this work, we leverage cutting-edge data-driven concepts and deep convolutional neural networks (CNNs) to harness enough characterization aspects from a wide range of images and point out the presence of child pornography content in an image. We explore different transfer-learning strategies for CNN modeling. CNNs are first trained with problems for which we can gather more training examples and upon which there are no serious concerns regarding collection and storage and then fine-tuned with data from the target problem of interest. The learned networks outperform different existing solutions and seem to represent an important step forward when dealing with child pornography content detection. The proposed solutions are encapsulated in a sandbox virtual machine ready for deployment by experts and practitioners. Experimental results with tens of thousands of real cases show the effectiveness of the proposed methods.
C1 [Vitorino, Paulo] Univ Brasilia, Dept Elect Engn, Brasilia, DF, Brazil.
   [Vitorino, Paulo] Brazilian Fed Police, Brasilia, DF, Brazil.
   [Avila, Sandra; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
   [Perez, Mauricio] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
C3 Universidade de Brasilia; Universidade Estadual de Campinas; Nanyang
   Technological University
RP Avila, S; Rocha, A (corresponding author), Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
EM sandra@ic.unicamp.br; anderson.rocha@ic.unicamp.br
RI Rocha, Anderson/KHU-9621-2024; Pérez, Mauricio/HLW-8190-2023; Avila,
   Sandra/M-2751-2017; Perez, Mauricio Lisboa/AAG-8901-2020; Perez,
   Mauricio Lisboa/HSH-3396-2023; Pérez, Mauricio/IZP-9377-2023
OI Perez, Mauricio Lisboa/0000-0002-4296-9202; Perez, Mauricio
   Lisboa/0000-0002-4296-9202; Avila, Sandra/0000-0001-9068-938X
FU Microsoft Research; Sao Paulo Research Foundation (Fapesp)
   [2017/12646-3]; CAPES DeepEyes project; PNPD/CAPES; Google Research
   Awards for Latin America; Brazil's National Program for Public Security
   with Citizenship (PRONASCI); Fundacao de Amparo a Pesquisa do Estado de
   Sao Paulo (FAPESP) [17/12646-3] Funding Source: FAPESP
FX This work was supported in part by Microsoft Research, Sao Paulo
   Research Foundation (Fapesp) under the grant #2017/12646-3 (DejaVu
   project), CAPES DeepEyes project, PNPD/CAPES, Google Research Awards for
   Latin America 2016, and Brazil's National Program for Public Security
   with Citizenship (PRONASCI). We acknowledge the support of NVIDIA
   Corporation with the donation of two GPUs used in this research.
CR Adler A, 2001, COLUMBIA LAW REV, V101, P209, DOI 10.2307/1123799
   Al Mutawa N, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P293, DOI 10.1109/ARES.2015.49
   [Anonymous], TRANSNATIONAL ORG CR
   [Anonymous], INT J FOREN COMP SCI
   [Anonymous], INT J FOREN COMP SCI
   [Anonymous], DORLANDS ILLUSTRATED
   [Anonymous], FIELD GUIDE DYNAMICA
   [Anonymous], PHOTODNA CLOUD SERV
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], TECH REP
   [Anonymous], ARXIV13125402
   [Anonymous], TECH REP
   [Anonymous], 12 WORKSH VIS COMP
   [Anonymous], 2006, NY TIMES
   [Anonymous], 2006, IADIS International Journal on Computer Science and Information Systems
   [Anonymous], 2006, 2006 CAN C EL COMP E
   [Anonymous], TECH REP
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], NY TIMES
   [Anonymous], 2016, IEEE T NEURAL NETWOR
   [Anonymous], 2009, NY TIMES
   [Anonymous], ARXIV12070580
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2013, CoRR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2016, OPEN SOURCING DEEP L
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bissias G, 2016, CHILD ABUSE NEGLECT, V52, P185, DOI 10.1016/j.chiabu.2015.10.022
   Caetano C, 2016, NEUROCOMPUTING, V213, P102, DOI 10.1016/j.neucom.2016.03.099
   Chatzis V, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P121, DOI 10.1109/DMIAF.2016.7574915
   de Castro Polastro Mateus, 2010, 2010 21st International Conference on Database and Expert Systems Applications, P349, DOI 10.1109/DEXA.2010.74
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Edwards L, 2010, FOURTH INTERNATIONAL CONFERENCE ON DIGITAL SOCIETY: ICDS 2010, PROCEEDINGS, P317, DOI 10.1109/ICDS.2010.72
   Grega M, 2011, COMM COM INF SC, V149, P28
   Grega M, 2014, MULTIMED TOOLS APPL, V68, P95, DOI 10.1007/s11042-012-1164-3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Islam Mofakharul, 2011, Information Security Technical Report, V16, P51, DOI 10.1016/j.istr.2011.09.004
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kelly W, 2008, 2008 INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P151, DOI 10.1109/IMVIP.2008.21
   Kovac J, 2003, IEEE REGION 8 EUROCON 2003, VOL B, PROCEEDINGS, P144
   Krone T., 2004, Trends Issues in Crime and Criminal Justice, V279, P1, DOI DOI 10.3316/AGISPT.20045173
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YZ, 2014, FUTURE GENER COMP SY, V31, P69, DOI 10.1016/j.future.2012.08.012
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Mousavi M.S. R., 2015, VEHICLE POWER PROPUL, P1
   Nian FD, 2016, NEUROCOMPUTING, V210, P283, DOI 10.1016/j.neucom.2015.09.135
   Panchenko Alexander, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P776, DOI 10.1007/978-3-642-36973-5_82
   Peersman C, 2014, IEEE SEC PRIV WORKS, P124, DOI 10.1109/SPW.2014.27
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Polastro MD, 2012, 2012 SEVENTH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES), P604, DOI 10.1109/ARES.2012.71
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ricanek K, 2012, COMPUTER, V45, P95, DOI 10.1109/MC.2012.308
   Sae-Bae N, 2014, IEEE IMAGE PROC, P5332, DOI 10.1109/ICIP.2014.7026079
   Schulze C., 2014, Proceedings of International Conference on Multimedia Retrieval, P353
   Seto MC, 2006, J ABNORM PSYCHOL, V115, P610, DOI 10.1037/0021-843X.115.3.610
   Short MB, 2012, CYBERPSYCH BEH SOC N, V15, P13, DOI 10.1089/cyber.2010.0477
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sorokin A, 2008, IEEE C COMPUTER VISI, P1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taylor M., 2001, CANADIAN J POLICY RE, V2, P94
   Taylor M., 2003, CHILD PORNOGRAPHY IN
   TODD T. WINGATE, 1940, HUMAN BIOL, V12, P1
   Weitzner DJ, 2007, IEEE INTERNET COMPUT, V11, P86, DOI 10.1109/MIC.2007.54
   Yan CC, 2014, J VIS COMMUN IMAGE R, V25, P1130, DOI 10.1016/j.jvcir.2014.03.005
NR 65
TC 44
Z9 46
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 303
EP 313
DI 10.1016/j.jvcir.2017.12.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700030
DA 2024-07-18
ER

PT J
AU Cui, CR
   Lin, PG
   Nie, XS
   Yin, YL
   Zhu, QF
AF Cui, Chaoran
   Lin, Peiguang
   Nie, Xiushan
   Yin, Yilong
   Zhu, Qingfeng
TI Hybrid textual-visual relevance learning for content-based image
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Tag completion; Semantics modeling; Rank
   aggregation; Sparse linear method
ID REPRESENTATIONS
AB Learning effective relevance measures plays a crucial role in improving the performance of content-based image retrieval (CBIR) systems. Despite extensive research efforts for decades, how to discover and incorporate semantic information of images still poses a formidable challenge to real-world CBIR systems. In this paper, we propose a novel hybrid textual-visual relevance learning method, which mines textual relevance from image tags and combines textual relevance and visual relevance for CBIR. To alleviate the sparsity and unreliability of tags, we first perform tag completion to fill the missing tags as well as correct noisy tags of images. Then, we capture users' semantic cognition to images by representing each image as a probability distribution over the permutations of tags. Finally, instead of early fusion, a ranking aggregation strategy is adopted to sew up textual relevance and visual relevance seamlessly. Extensive experiments on two benchmark datasets well verified the promise of our approach. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Cui, Chaoran; Lin, Peiguang; Nie, Xiushan; Zhu, Qingfeng] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
   [Yin, Yilong] Shandong Univ, Sch Comp Sci & Technol, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University of Finance & Economics; Shandong University
RP Lin, PG (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM crcui@sdufe.edu.cn; llpwgh@163.com; niexsh@sdufe.edu.cn;
   ylyin@sdu.edu.cn; zhuqf508@163.com
RI Zhu, Qingfeng/HHZ-6984-2022; Nie, Xiushan/AAZ-6410-2020
OI Zhu, Qingfeng/0000-0002-1262-9688; 
FU Natural Science Foundation of China [61671274, 61602282, 11671229,
   11301298]; Shandong Natural Science Funds for Distinguished Young
   Scholar [JQ201316]; Project of Shandong Province Higher Educational
   Science and Technology Program [J15LN56]; Fostering Project of Dominant
   Discipline and Talent Team of Shandong Province Higher Education
   Institutions
FX This work is supported by the Natural Science Foundation of China
   (61671274, 61602282, 11671229, 11301298), Shandong Natural Science Funds
   for Distinguished Young Scholar (JQ201316), the Project of Shandong
   Province Higher Educational Science and Technology Program (J15LN56),
   and the Fostering Project of Dominant Discipline and Talent Team of
   Shandong Province Higher Education Institutions.
CR Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], IEEE T KNOWL DATA EN
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], NEUROCOMPUTING
   [Anonymous], ADV MULTIMEDIA MODEL
   [Anonymous], 2009, P ACM INT C IM VID R
   [Anonymous], 1997, Information theory and statistics
   Aslam J. A., 2001, SIGIR Forum, P276
   Cao Z., 2007, P 24 INT C MACHINE L, P129, DOI DOI 10.1145/1273496.1273513
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1069, DOI 10.1145/2911451.2914765
   Cui CR, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P895, DOI 10.1145/2733373.2806358
   [崔超然 Cui Chaoran], 2013, [计算机学报, Chinese Journal of Computers], V36, P654
   Cui P, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2590974
   Feng SH, 2013, J VIS COMMUN IMAGE R, V24, P1031, DOI 10.1016/j.jvcir.2013.06.018
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Huang SS, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P343, DOI 10.1145/2766462.2767693
   Huang SS, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2700465
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Karpathy A, 2014, ADV NEUR IN, V27
   Kennedy L.S., 2006, Proc. ACM Multimedia Information Retrieval, P249, DOI DOI 10.1145/1178677.1178712
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Marden John I., 1996, Analyzing and modeling rank data
   Murala S, 2014, J VIS COMMUN IMAGE R, V25, P1324, DOI 10.1016/j.jvcir.2014.05.008
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie XS, 2013, SCI CHINA INFORM SCI, V56, DOI 10.1007/s11432-012-4760-y
   Raveaux R, 2013, J VIS COMMUN IMAGE R, V24, P1252, DOI 10.1016/j.jvcir.2013.08.010
   Shi Y, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2556270
   Sieg Ahu, 2007, P CIKM, P525, DOI DOI 10.1145/1321440.1321515
   Talib A, 2013, J VIS COMMUN IMAGE R, V24, P345, DOI 10.1016/j.jvcir.2013.01.007
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang DX, 2015, IEEE T MULTIMEDIA, V17, P1404, DOI 10.1109/TMM.2015.2455415
   Wang JD, 2012, INFORM RETRIEVAL, V15, P278, DOI 10.1007/s10791-012-9193-0
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang RJ, 2014, J VIS COMMUN IMAGE R, V25, P963, DOI 10.1016/j.jvcir.2014.02.016
   Wu F., 2013, P ACM INT C MULT, P877
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Wu L, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899417
   Wu Pengcheng., 2011, Proceedings of the Fourth 140 ACM International Conference on Web Search and Data Mining, WSDM, P197, DOI DOI 10.1145/1935826.1935865
   Xia Ning, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P497, DOI 10.1109/ICDM.2011.134
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 47
TC 19
Z9 19
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 367
EP 374
DI 10.1016/j.jvcir.2017.03.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700030
DA 2024-07-18
ER

PT J
AU Cao, FL
   Feng, XS
   Zhao, JW
AF Cao, Feilong
   Feng, Xinshan
   Zhao, Jianwei
TI Sparse representation for robust face recognition by dictionary
   decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Face recognition; Dictionary decomposition;
   Projection matrix
ID RANK MATRIX RECOVERY; INCOHERENCE; ALGORITHM
AB Sparse representation-based classification (SRC) method has gained great success in face recognition due to its encouraging and impressive performance. However, in SRC the data used to train or test are usually corrupted, and hence the performance is affected. This paper proposes a robust face recognition approach by means of learning a class-specific dictionary and a projection matrix. Firstly, the training data are decomposed into class-specific dictionary, non-class-specific dictionary, and sparse error matrix. Secondly, in order to correct the corrupted test data, the data are projected onto their corresponding underlying subspace, and a projection matrix between the original training data and the class-specific dictionary is learned. Then, the features of the class-specific dictionary and the corrected test data are extracted by using Eigenface method. Finally, the SRC is performed to classify. Extensive experiments conducted on publicly available data sets show that the proposed algorithm performs better than some state-of-the-art methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Cao, Feilong; Feng, Xinshan; Zhao, Jianwei] China Jiliang Univ, Coll Sci, Dept Appl Math, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Cao, FL (corresponding author), China Jiliang Univ, Coll Sci, Dept Appl Math, Hangzhou 310018, Zhejiang, Peoples R China.
EM feilongcao@gmail.com
FU National Natural Science Foundation of China [61672477, 61571410]
FX This research was supported by the National Natural Science Foundation
   of China under Grants 61672477 and 61571410.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bowyer KW, 2004, IEEE TECHNOL SOC MAG, V23, P9, DOI 10.1109/MTAS.2004.1273467
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chandrasekaran V, 2011, SIAM J OPTIMIZ, V21, P572, DOI 10.1137/090761793
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Chen J, 2014, J VIS COMMUN IMAGE R, V25, P763, DOI 10.1016/j.jvcir.2014.01.015
   De-la-Torre M, 2015, INFORM FUSION, V24, P31, DOI 10.1016/j.inffus.2014.05.006
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jiang XD, 2015, IEEE T PATTERN ANAL, V37, P1067, DOI 10.1109/TPAMI.2014.2359453
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li ZF, 2007, IEEE T INF FOREN SEC, V2, P174, DOI 10.1109/TIFS.2007.897247
   Liu G., 2010, P INT C MACH LEARN, P663
   Lu CY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380155
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   Mairal J., 2008, NIPS, V21, P1033
   Mairal J, 2008, PROC CVPR IEEE, P2415
   Martinez A.M., 1998, AR FACE DATABASE CVC
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Pagano C, 2014, INFORM SCIENCES, V286, P75, DOI 10.1016/j.ins.2014.07.005
   Pagano C., 2012, Neural Networks (IJCNN), The 2012 International Joint Conference on, P1, DOI DOI 10.1109/IJCNN.2012.6252659
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ramirez I., 2010, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2010.5539964, 10.1109/CVPR.2010.5539964]
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Soni A, 2012, INT CONF ACOUST SPEE, P2097, DOI 10.1109/ICASSP.2012.6288324
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang DH, 2010, IEEE PEDG 2010: THE 2ND INTERNATIONAL SYMPOSIUM ON POWER ELECTRONICS FOR DISTRIBUTED GENERATION SYSTEMS, P1, DOI 10.1109/PEDG.2010.5545769
   Wang GJ, 2015, NEUROCOMPUTING, V151, P1500, DOI 10.1016/j.neucom.2014.10.032
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2013, IEEE T IMAGE PROCESS, V22, P1753, DOI 10.1109/TIP.2012.2235849
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zheng ZL, 2014, PATTERN RECOGN, V47, P3502, DOI 10.1016/j.patcog.2014.05.001
NR 49
TC 6
Z9 7
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 260
EP 268
DI 10.1016/j.jvcir.2017.04.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500023
DA 2024-07-18
ER

PT J
AU Hsu, LY
   Hu, HT
AF Hsu, Ling-Yuan
   Hu, Hwai-Tsu
TI Robust blind image watermarking using crisscross inter-block prediction
   in the DCT domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image watermarking; Discrete cosine transform; Partly
   sign-altered; Mixed modulation; Crisscross inter-block prediction
ID DIGITAL WATERMARKING; SCHEME; TRANSFORM; MODULATION; QIM
AB Watermarking has been proposed as a solution to the problem protecting copyrighted multimedia in networked environments. This paper presents a simple but effective blind watermarking scheme capable of satisfying requirements pertaining to imperceptibility as well as robustness, while maintaining a sufficient payload capacity. In the proposed scheme, partly sign-altered mean modulation and mixed modulation are introduced to the crisscross discrete cosine transform (DCT)-based inter-block. Substituting a set of coefficients for a single coefficient enhances robustness against malign attacks. The inclusion of mixed modulation enables control over the parameters required to provide resistance against commonly encountered attacks while maintaining a high peak signal-to-noise ratio. Experiment results demonstrate that the proposed algorithm exceeds the performance of the seven other schemes in providing robust resistance to variety of attacks, particularly those associated with Gaussian noise and speckle noise. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Hsu, Ling-Yuan] St Marys Jr Coll Med Nursing & Management, Dept Informat Management, Ilan, Taiwan.
   [Hu, Hwai-Tsu] Natl Ilan Univ, Dept Elect Engn, Ilan, Taiwan.
C3 National Ilan University
RP Hsu, LY (corresponding author), St Marys Jr Coll Med Nursing & Management, Dept Informat Management, Ilan, Taiwan.
EM hsulingyuan@gmail.com
OI Hsu, Ling-Yuan/0000-0002-9543-6872
FU Ministry of Science and Technology, Taiwan, ROC [MOST
   105-2221-E-562-003, MOST 104-2221-E-197-023]
FX This research work was supported by the Ministry of Science and
   Technology, Taiwan, ROC under Grants MOST 105-2221-E-562-003 and MOST
   104-2221-E-197-023.
CR Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Al-Haj A, 2014, J DIGIT IMAGING, V27, P737, DOI 10.1007/s10278-014-9709-9
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Boyer JP, 2008, IEEE T INF FOREN SEC, V3, P776, DOI 10.1109/TIFS.2008.2004285
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CC, 2007, LECT NOTES COMPUT SC, V4614, P82
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen ST, 2016, MULTIMED TOOLS APPL, V75, P5493, DOI 10.1007/s11042-015-2522-8
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Hsu LY, 2015, J VIS COMMUN IMAGE R, V32, P130, DOI 10.1016/j.jvcir.2015.07.017
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P26723, DOI 10.1007/s11042-016-4202-8
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Jamal SS, 2013, NONLINEAR DYNAM, V73, P1469, DOI 10.1007/s11071-013-0877-9
   Kalantari NK, 2010, IEEE T IMAGE PROCESS, V19, P1504, DOI 10.1109/TIP.2010.2042646
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Liu NS, 2015, NONLINEAR DYNAM, V80, P1329, DOI 10.1007/s11071-015-1946-z
   Moghaddam ME, 2013, FORENSIC SCI INT, V233, P193, DOI 10.1016/j.forsciint.2013.09.005
   Murty PS, 2010, INT J COMPUT SCI NET, V10, P185
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Tao P., 2006, J Multimed, V1, P36, DOI 10.4304/jmm.1.6.36-45
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wang N., 2009, INT C COMP INT SEC 2
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Zhang G., 2004, 7 INT C SIGN PROC IC
   Zhang ML, 2011, LECT NOTES ARTIF INT, V7003, P75, DOI 10.1007/978-3-642-23887-1_10
NR 41
TC 55
Z9 57
U1 3
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 33
EP 47
DI 10.1016/j.jvcir.2017.03.009
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500004
DA 2024-07-18
ER

PT J
AU Karimi, M
   Samavi, S
   Karimi, N
   Soroushmehr, SMR
   Lin, WS
   Najarian, K
AF Karimi, Maryam
   Samavi, Shadrokh
   Karimi, Nader
   Soroushmehr, S. M. Reza
   Lin, Weisi
   Najarian, Kayvan
TI Quality assessment of retargeted images by salient region deformity
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Image retargeting; Geometrical distortions;
   Homogeneity of deformities; Saliency preservation
ID DISTORTION
AB Displaying images on different devices, requires resizing of the media. Traditional image resizing methods result in quality degradation. Content-aware retargeting algorithms aim to resize images for displaying them on a new device with the goal of preserving important contents of the image. Quality assessment of retargeted images can be employed to choose among outputs of different retargeting methods or help the optimization of such methods. In this paper we propose a learning based quality assessment method for retargeted images. An optical flow algorithm is used to find the correspondence between regions in the scaled and retargeted images. Three groups of features are defined to cover different aspects of distortions that are important to human observers. Area related features are used to detect how the areas of salient regions are retained and how much geometrical deformities are produced in the image. Also, to better assess the retargeted image we introduce features to show how well the aspect ratios of objects are retained. More importantly, we introduce the concept of measuring the homogeneity of distribution of deformities throughout the image. Experimental results demonstrate that our quality estimation method has better correlation with subjective scores and outperforms existing methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Karimi, Maryam; Samavi, Shadrokh; Karimi, Nader] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Samavi, Shadrokh] Univ Michigan, Ctr Integrat Res Crit Care, Ann Arbor, MI 48109 USA.
   [Soroushmehr, S. M. Reza; Najarian, Kayvan] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Najarian, Kayvan] Michigan Ctr Integrat Res Crit Care, Ann Arbor, MI USA.
C3 Isfahan University of Technology; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan; Nanyang Technological University
RP Samavi, S (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
EM samavi@mcmaster.ca
RI Karimi, Nader/HWP-4206-2023; Lin, Weisi/A-8011-2012; Lin,
   Weisi/A-3696-2011; karimi, maryam/AAZ-9303-2021
OI Karimi, Nader/0000-0001-8904-1607; Lin, Weisi/0000-0001-9866-1947;
   karimi, maryam/0000-0002-7597-0680
CR Abdi H., 2007, Encyclopedia of measurement and statistics, P508, DOI DOI 10.4135/9781412952644.N239
   [Anonymous], RETARGET ME BENCHMAR
   [Anonymous], TRENDS TOPICS COMPUT
   [Anonymous], SPIE OPTICAL ENG APP
   [Anonymous], VISUAL SIGNAL QUALIT
   [Anonymous], ACM T GRAPH TOG
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Li LD, 2016, J VIS COMMUN IMAGE R, V38, P550, DOI 10.1016/j.jvcir.2016.04.006
   Liang YH, 2016, INT CONF INTEL NETWO, P99, DOI 10.1109/INCoS.2016.38
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2015, SIGNAL PROCESS-IMAGE, V39, P444, DOI 10.1016/j.image.2015.08.001
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Simakov D, 2008, PROC CVPR IEEE, P3887
   Song ML, 2013, NEUROCOMPUTING, V119, P222, DOI 10.1016/j.neucom.2013.03.037
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu L, 2012, IEEE T PATTERN ANAL, V34, P1744, DOI 10.1109/TPAMI.2011.236
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhang XJ, 2013, J VIS COMMUN IMAGE R, V24, P81, DOI 10.1016/j.jvcir.2012.11.002
   Zhang YB, 2016, IEEE T IMAGE PROCESS, V25, P4286, DOI 10.1109/TIP.2016.2585884
NR 30
TC 18
Z9 21
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 108
EP 118
DI 10.1016/j.jvcir.2016.12.011
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400011
DA 2024-07-18
ER

PT J
AU Chen, ZH
   Wang, HZ
   Zhang, LM
   Yan, Y
   Liao, HYM
AF Chen, Zhihui
   Wang, Hanzi
   Zhang, Liming
   Yan, Yan
   Liao, Hong-Yuan Mark
TI Visual saliency detection based on homology similarity and an
   experimental evaluation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Homology similarity; Spatial compactness; Color contrast; Visual
   saliency
ID OBJECT DETECTION; ATTENTION; MODEL
AB In recent years, visual saliency detection has become a popular research topic. It can provide useful prior knowledge for high-level vision tasks, such as object detection and image classification. In this paper, a graph-based superpixel-wise similarity called "homology similarity" is proposed, which describes how likely two superpixels belong to the same object or background region. A saliency detection model is then developed based on the combination of homology distribution and improved color contrast. The homology distribution represents spatial compactness, while the color contrast characterizes color conspicuity. By combining these two saliency cues, the proposed model obtains more uniformly highlighted object level saliency maps with fewer false positive noises. In the experiments, we evaluate our model and 14 competing models (including traditional and state-of-the-art models) on the most popular dataset MSRA-1000 and 4 other publicly available datasets. Experimental results show that, compared with these competing models, our model yields promising results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Zhihui; Wang, Hanzi; Yan, Yan] Xiamen Univ, Sch Informat Sci & Engn, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
   [Chen, Zhihui; Wang, Hanzi; Yan, Yan] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China.
   [Zhang, Liming] Univ Macau, Fac Sci & Technol, Zhuhai, Peoples R China.
   [Liao, Hong-Yuan Mark] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
C3 Xiamen University; Xiamen University; University of Macau; Academia
   Sinica - Taiwan
RP Wang, HZ (corresponding author), Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China.
EM zhihui.qz.chen@gmail.com; hanzi.wang@xmu.edu.cn; lmzhang@umac.mo;
   yanyan@xmu.edu.cn; liao@iis.sinica.edu.tw
RI Zhang, Liming/G-5518-2013; Zhang, Liming/ABG-5996-2020; wang,
   hao/HSE-7975-2023; wang, handong/HLH-5739-2023; Wang, Han/GPW-9809-2022;
   Liao, Hong-Yuan Mark/AAQ-5514-2021
OI Zhang, Liming/0000-0002-2664-8193; Zhang, Liming/0000-0002-2664-8193; 
FU National Natural Science Foundation of China [61472334, 61571379];
   Science and Technology Development Fund of Macao [SAR: FDCT056/2012/A2,
   MYRG144(Y1-L2)-FST11-ZLM]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61472334 and 61571379. It was also supported by the
   Science and Technology Development Fund of Macao SAR: FDCT056/2012/A2
   and MYRG144(Y1-L2)-FST11-ZLM.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S., 2007, IEEE C COMPUTER VISI, P1
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hu WM, 2014, IEEE T IMAGE PROCESS, V23, P1513, DOI 10.1109/TIP.2014.2303639
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Luo Y, 2011, IEEE T CIRC SYST VID, V21, P1822, DOI 10.1109/TCSVT.2011.2147230
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang P, 2012, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2012.6248054
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang WB, 2013, NEUROCOMPUTING, V103, P63, DOI 10.1016/j.neucom.2012.08.029
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhihui Chen, 2013, Intelligence Science and Big Data Engineering. 4th International Conference, IScIDE 2013. Revised Selected Papers: LNCS 8261, P441, DOI 10.1007/978-3-642-42057-3_56
NR 48
TC 14
Z9 14
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 251
EP 264
DI 10.1016/j.jvcir.2016.06.013
PN A
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500023
DA 2024-07-18
ER

PT J
AU He, WG
   Xiong, GQ
   Zhou, K
   Cai, J
AF He, Wenguang
   Xiong, Gangqiang
   Zhou, Ke
   Cai, Jie
TI Reversible data hiding based on multilevel histogram modification and
   pixel value grouping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Multilevel histogram modification; Image
   partition; Pixel value grouping; Virtual reference pixel
ID IMAGE; WATERMARKING; EXPANSION
AB This paper proposes a multilevel histogram modification based reversible data hiding scheme using a new difference generation strategy called pixel value grouping (PVG). It aims to produce shaper difference histogram by exploiting the high correlation among pixels within block. After sorting, pixel values are grouped according to their distribution. For each set of similar pixel values, real or virtual reference pixel will be determined to compute differences in the scope of pixel values group and next secret message is embedded through expansion embedding. By PVG, we success to greatly reduce the number of to-be shifted pixels while producing sufficient EC and hence less distortion can be introduced for embedding the same payload. Moreover, the same grouping can be achieved at the decoder and the real or virtual reference pixel can be determined without any prior knowledge, which guarantees the reversibility. Experimental results demonstrate that our scheme outperforms previous related state-of-the-art schemes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [He, Wenguang; Xiong, Gangqiang; Zhou, Ke; Cai, Jie] Guangdong Med Univ, Sch Informat Engn, Zhanjiang 524023, Guangdong, Peoples R China.
C3 Guangdong Medical University
RP He, WG (corresponding author), Guangdong Med Univ, Sch Informat Engn, Zhanjiang 524023, Guangdong, Peoples R China.
EM 56207403@qq.com
OI he, wenguang/0000-0003-1051-389X
FU National Scientific Fund of China [61170320, 81201763]
FX This work is supported by the National Scientific Fund of China (Nos.
   61170320, 81201763).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Fu DS, 2014, AEU-INT J ELECTRON C, V68, P933, DOI 10.1016/j.aeue.2014.04.015
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Honsinger C., 2001, United States Patent, Patent No. [6278791, 278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Li X., IEEE T IMAGE PROCESS, V20
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li YC, 2010, DIGIT SIGNAL PROCESS, V20, P1116, DOI 10.1016/j.dsp.2009.10.025
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Pei QQ, 2013, J SYST SOFTWARE, V86, P2841, DOI 10.1016/j.jss.2013.06.055
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 31
TC 23
Z9 25
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 459
EP 469
DI 10.1016/j.jvcir.2016.07.014
PN B
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600006
DA 2024-07-18
ER

PT J
AU Ji, ZX
   Huang, YB
   Sun, QS
   Cao, G
AF Ji, Zexuan
   Huang, Yubo
   Sun, Quansen
   Cao, Guo
TI A spatially constrained generative asymmetric Gaussian mixture model for
   image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Asymmetric Gaussian mixture model; Expectation-maximization (EM)
   algorithm; Image segmentation; Markov random fields (MRFs); Spatial
   constraint
ID ALGORITHM; CLASSIFICATION
AB Accurate image segmentation is an essential step in image processing, where Gaussian mixture models with spatial constraint play an important role. Nevertheless, most methods suffer from one or more challenges such as limited robustness to noise, over-smoothness for segmentations, and lack of flexibility to fit the observed data. To address these issues, in this paper, we propose a generative asymmetric Gaussian mixture model with spatial constraint for image segmentation. The asymmetric distribution is modified to be easily incorporated the spatial information. Then our asymmetric model can be constructed based on the posterior and prior probabilities of within-cluster and between-cluster. Based on the Kullback-Leibler divergence, we introduce two pseudo-likelihood quantities which consider the neighboring priors of within-cluster and between-cluster. Finally, we derive an expectation maximization algorithm to maximize the approximation of the data log-likelihood. We compare our algorithm with state-of-the-art segmentation approaches to demonstrate the superior performance of the proposed algorithm. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Ji, Zexuan; Huang, Yubo; Sun, Quansen; Cao, Guo] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Ji, ZX (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM jizexuan@njust.edu.cn
RI , Guo/AAC-1388-2022
OI , Guo/0000-0002-2689-0932
FU National Natural Science Foundation of China [61401209]; Natural Science
   Foundation of Jiangsu Province, China (Youth Fund Project) [BK20140790];
   Fundamental Research Funds for the Central Universities [30916011324];
   China Postdoctoral Science Foundation [2014T70525, 2013M531364]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61401209, the Natural Science Foundation of
   Jiangsu Province, China (Youth Fund Project) under Grant No. BK20140790,
   the Fundamental Research Funds for the Central Universities under Grant
   No. 30916011324, and China Postdoctoral Science Foundation under Grants
   Nos. 2014T70525 & 2013M531364.
CR Allili MS, 2010, IEEE T CIRC SYST VID, V20, P1373, DOI 10.1109/TCSVT.2010.2077483
   Ashburner J, 2005, NEUROIMAGE, V26, P839, DOI 10.1016/j.neuroimage.2005.02.018
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4
   Clifford P., 1990, MARKOV RANDOM FIELDS
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Diplaros A, 2007, IEEE T NEURAL NETWOR, V18, P798, DOI 10.1109/TNN.2007.891190
   Forbes F, 2003, IEEE T PATTERN ANAL, V25, P1089, DOI 10.1109/TPAMI.2003.1227985
   Franczak BC, 2014, IEEE T PATTERN ANAL, V36, P1149, DOI 10.1109/TPAMI.2013.216
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Ji ZX, 2014, IEEE INT FUZZY SYST, P202, DOI 10.1109/FUZZ-IEEE.2014.6891640
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072
   Lindblom J, 2003, IEEE T SPEECH AUDI P, V11, P88, DOI 10.1109/TSA.2002.805639
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Rohlfing T, 2012, IEEE T MED IMAGING, V31, P153, DOI 10.1109/TMI.2011.2163944
   Roweis S, 2002, ADV NEUR IN, V14, P889
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Nguyen TM, 2014, PATTERN RECOGN, V47, P3132, DOI 10.1016/j.patcog.2014.03.030
   Nguyen TM, 2014, IEEE T CYBERNETICS, V44, P857, DOI 10.1109/TCYB.2013.2273714
   Nguyen TM, 2014, IEEE J BIOMED HEALTH, V18, P109, DOI 10.1109/JBHI.2013.2264749
   Nguyen TM, 2013, IEEE T CYBERNETICS, V43, P751, DOI 10.1109/TSMCB.2012.2215849
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Titterington D. M., 1985, Statistical Analysis of Finite Mixture Distributions, V198
   Unnikrishnan R., 2005, IEEE Conference on Computer Vision and Pattern Recognition, CVPR Workshops 2005, San Diego, CA, USA, 21-23 September, 2005, page, P34, DOI 10.1109/CVPR.2005.390
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   Verbeek JJ, 2005, NEUROCOMPUTING, V63, P99, DOI 10.1016/j.neucom.2004.04.008
   Zhang H, 2013, INT CONF ACOUST SPEE, P1478, DOI 10.1109/ICASSP.2013.6637897
   Zhang H, 2013, IEEE SIGNAL PROC LET, V20, P117, DOI 10.1109/LSP.2012.2230626
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
NR 39
TC 15
Z9 18
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 611
EP 626
DI 10.1016/j.jvcir.2016.08.001
PN B
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600018
DA 2024-07-18
ER

PT J
AU Hosseinzadeh, H
   Razzazi, F
   Kabir, E
AF Hosseinzadeh, Hamidreza
   Razzazi, Farbod
   Kabir, Ehsanollah
TI A weakly supervised large margin domain adaptation method for isolated
   handwritten digit recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Writer adaptation; Domain adaptation; Handwriting recognition;
   Transformation learning; Feature learning; Large margin semi-supervised
   learning
ID LIBRARY; STYLE
AB Learning handwriting categories fail to perform well when trained and tested on data from different databases. In this paper, we propose a novel large margin domain adaptation algorithm which is able to learn a transformation between training and test datasets in addition to adapting the parameters of classifier using a few or even no training labeled samples from target handwriting dataset. Additionally, we developed a framework of ensemble projection feature learning for datasets representation as a front end for our algorithm to utilize the abundant unlabeled samples in target domain. Experiments on different handwritten digit datasets adaptations demonstrate that the proposed large margin domain adaptation algorithm achieves superior classification accuracy comparing with the state of the art methods. Quantitative evaluation of the proposed algorithm shows that semi-supervised adaptation utilizing one sample per class of target domain set reduces the error rates by 64.72% comparing with a corresponding SVM classifier. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hosseinzadeh, Hamidreza; Razzazi, Farbod] Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran, Iran.
   [Kabir, Ehsanollah] Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Tarbiat Modares University
RP Hosseinzadeh, H (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Elect & Comp Engn, Tehran, Iran.
EM hr.hosseinzadeh@srbiau.ac.ir; razzazi@srbiau.ac.ir; kabir@modares.ac.ir
RI kabir, ehsanollah/D-1708-2010; Razzazi, Farbod/AAO-8522-2021
OI kabir, ehsanollah/0000-0002-5610-7611; Razzazi,
   Farbod/0000-0003-4970-8117
CR [Anonymous], 2001, Intelligent Signal Processing
   [Anonymous], ELECT LETT COMPUTER
   [Anonymous], 2009, ADV NEURAL INFORM PR
   Ball Gregory R., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P26, DOI 10.1109/ICDAR.2009.249
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Ben-David S., 2007, NIPS, P137
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dai DX, 2013, IEEE I CONF COMP VIS, P2072, DOI 10.1109/ICCV.2013.259
   Daume III Hal, 2007, ACL 2007, P256
   Diem M, 2013, PROC INT CONF DOC, P1422, DOI 10.1109/ICDAR.2013.287
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Frinken Volkmar, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P31, DOI 10.1109/ICDAR.2009.18
   Goldman S., 2000, ICML, P327
   Gong B., 2013, P INT C MACH LEARN, P222
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Guan T, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2795234
   Hastie T., 2003, THE ELEMENTS OF STAT
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Jiang Jing, 2007, ANN M ASS COMP LING, P264, DOI DOI 10.1145/1273496.1273558
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Lin D, 2013, PATTERN RECOGN LETT, V34, P1279, DOI 10.1016/j.patrec.2013.04.012
   Luo YW, 2015, NEUROCOMPUTING, V156, P105, DOI 10.1016/j.neucom.2014.12.079
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sun Qian, 2011, P ADV NEUR INF PROC, P505
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Vajda S, 2011, PROC INT CONF DOC, P259, DOI 10.1109/ICDAR.2011.60
   Veeramachaneni S, 2005, IEEE T PATTERN ANAL, V27, P14, DOI 10.1109/TPAMI.2005.19
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yuan Y, 2013, J VIS COMMUN IMAGE R, V24, P95, DOI 10.1016/j.jvcir.2012.02.007
   Zhang X.-Y., 2011, PROC INT JOINT C ART, V22, P1621, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-272
   Zhang XY, 2013, IEEE T PATTERN ANAL, V35, P1773, DOI 10.1109/TPAMI.2012.239
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X., 2005, PhD thesis
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
NR 40
TC 8
Z9 10
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 307
EP 315
DI 10.1016/j.jvcir.2016.02.018
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100026
DA 2024-07-18
ER

PT J
AU Lin, CY
   Muchtar, K
   Yeh, CH
   Lu, CS
AF Lin, Chih-Yang
   Muchtar, Kahlil
   Yeh, Chia-Hung
   Lu, Chun-Shien
TI Secure multicasting of images via joint privacy-preserving
   fingerprinting, decryption, and authentication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Authentication; Joint fingerprinting and decryption (JFD);
   Privacy-preserving fingerprinting; Secret sharing; Multimedia
   distribution; Content integrity; Data encryption; Image authentication
ID VIDEO; WATERMARKING; SCHEME
AB Joint fingerprinting and decryption (JFD) is useful in securing media transmission and distribution in a multicasting environment. Common drawbacks of the existing JFD methods are the transmitted data may leak the content of data, and a subscriber cannot determine if a received image is modified such that tampering attack can be mounted successfully. Here we focus on security and privacy of image multicasting and introduce a new framework called JFDA (joint privacy-preserving fingerprinting, decryption, and authentication). It has several main characteristics, JFDA: (1) accomplishes fingerprinting in the encryption domain to preserve privacy and prevent encrypted data from being tampered without additional hash code/digest, (2) prevents tampering attack on the decrypted data to ensure the fidelity of the fingerprinted data, (3) makes user subscribing to a visual media be an examiner to authenticate the same visual media over the Internet. The effectiveness of the proposed method is confirmed by experimental results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lin, Chih-Yang] Asia Univ, Dept Bioinformat & Med Engn, Taichung, Taiwan.
   [Lin, Chih-Yang] China Med Univ, China Med Univ Hosp, Dept Med Res, Taichung, Taiwan.
   [Muchtar, Kahlil; Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 80424, Taiwan.
   [Lu, Chun-Shien] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
C3 Asia University Taiwan; China Medical University Taiwan; China Medical
   University Hospital - Taiwan; National Sun Yat Sen University; Academia
   Sinica - Taiwan
RP Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung 80424, Taiwan.
EM yeh@mail.ee.nsysu.edu.tw
RI Muchtar, Kahlil/P-8532-2019; Lin, Chih-Yang/HOF-2583-2023
OI Muchtar, Kahlil/0000-0001-5740-1938; Lin, Chih-Yang/0000-0002-0401-8473
FU National Science Council Taiwan [MOST 103-2221-E-468-007-MY2]
FX This work was supported by National Science Council Taiwan, under Grants
   MOST 103-2221-E-468-007-MY2. We specially thank Prof. Ya-Fen Chang,
   Dept. of Computer Science and Information Engineering, National Taichung
   University of Science and Technology, for giving us precious comments on
   this paper.
CR Adelsbach A, 2006, LECT NOTES COMPUT SC, V4058, P136
   Anderson R, 1997, LECT NOTES COMPUT SC, V1267, P107
   Boneh D, 1998, IEEE T INFORM THEORY, V44, P1897, DOI 10.1109/18.705568
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Brown I, 1999, LECT NOTES COMPUT SC, V1736, P286
   Celik MU, 2008, IEEE T INF FOREN SEC, V3, P475, DOI 10.1109/TIFS.2008.926988
   Celik MU, 2004, IEEE SIGNAL PROC LET, V11, P831, DOI 10.1109/LSP.2004.835475
   Chen TH, 2005, IEEE T IND ELECTRON, V52, P327, DOI 10.1109/TIE.2004.841083
   Chih-Yang Lin, 2010, Proceedings of the 2010 International Conference on Broadband, Wireless Computing, Communication and Applications (BWCCA 2010), P463, DOI 10.1109/BWCCA.2010.115
   Czaplewski B, 2015, SIGNAL PROCESS, V111, P150, DOI 10.1016/j.sigpro.2014.12.026
   Fresia M., 2009, P 32 INT C SARN S IE, V1-6
   Hartung F, 1997, INT CONF ACOUST SPEE, P2621, DOI 10.1109/ICASSP.1997.595326
   Judge P, 2002, COMPUT NETW, V39, P699, DOI 10.1016/S1389-1286(02)00227-X
   Karthik K., 2007, INT J NETWORK SECURI, V4, P254
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Lemma A, 2006, LECT NOTES COMPUT SC, V4283, P433
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lin CY, 2014, SIGNAL PROCESS, V98, P52, DOI 10.1016/j.sigpro.2013.11.011
   Lin CY, 2012, SIGNAL PROCESS, V92, P2159, DOI 10.1016/j.sigpro.2012.02.002
   MACQ BM, 1995, P IEEE, V83, P944, DOI 10.1109/5.387094
   Mao YN, 2005, IEEE IMAGE PROC, P205
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Pfitzmann B., 1997, Advances in Cryptology - EUROCRYPT '97. International Conference on the Theory and Application of Cryptographic Techniques Proceedings, P88
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Stallings W., 2005, CRYPTOGRAPHY NETWORK, V4th
   Strang, 2009, Introduction to linear algebra
   Trappe W, 2003, IEEE T SIGNAL PROCES, V51, P1069, DOI 10.1109/TSP.2003.809378
   Wang ZJ, 2005, IEEE T IMAGE PROCESS, V14, P804, DOI 10.1109/TIP.2005.847284
   Xu YY, 2014, J VIS COMMUN IMAGE R, V25, P805, DOI 10.1016/j.jvcir.2014.01.005
   Zhao HV, 2006, IEEE T IMAGE PROCESS, V15, P12, DOI 10.1109/TIP.2005.860356
   Zhao HV, 2005, IEEE T IMAGE PROCESS, V14, P646, DOI 10.1109/TIP.2005.846035
NR 31
TC 3
Z9 3
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 858
EP 871
DI 10.1016/j.jvcir.2016.02.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100072
DA 2024-07-18
ER

PT J
AU Boukhari, A
   Serir, A
AF Boukhari, Aissa
   Serir, Amina
TI Weber Binarized Statistical Image Features (WBSIF) based video copy
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video copy detection; Video fingerprinting; Content-based copy
   detection; Key-frame; Local binary patterns; Weber local descriptor;
   Binarized statistical image features; Weber binarized statistical image
   features
ID TEXTURE CLASSIFICATION; PATTERNS; ROTATION
AB This paper presents a new video copy detection system based on testing similarities between textural feature vectors which are extracted from videos. Herein, the proposed method is based on Weber Binarized Statistical Image Features (WBSIF) which is an interior improvement of Weber Local Descriptor (WLD). Actually, the orientation gradient in WLD is substituted by a recent Binarized Statistical Image Features (BSIF) as a local textural descriptor. The WBSIF approach is tested on three databases and evaluated through several attacks. Moreover, the proposed method is compared to the recent existing approaches, especially those mostly used in the literature, which are based on the binary pattern descriptors. The obtained results outline the robustness and the effectiveness of the proposed video copy detection system in terms of precision, recall, Fscore, accuracy and collision test. This study shows clearly a noteworthy performance of the proposed scheme against currently existing techniques. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Boukhari, Aissa; Serir, Amina] USTHB, Lab Image Proc & Radiat, Fac Elect & Comp, BP 32 El Alia, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Boukhari, A (corresponding author), USTHB, Lab Image Proc & Radiat, Fac Elect & Comp, BP 32 El Alia, Algiers 16111, Algeria.
EM aboukhari@usthb.dz; aserir@usthb.dz
RI SERIR, Amina/AIE-7078-2022
OI SERIR, Amina/0000-0001-7716-1273
CR [Anonymous], 2013, P IEEE 6 INT C BIOME
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Boukhari A., 2014, 5 EUR WORKSH VIS INF, P1
   Boukhari Aissa, 2013, 2 INT C SIGN IM VIS, P181
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chiu CY, 2010, IEEE T CIRC SYST VID, V20, P1603, DOI 10.1109/TCSVT.2010.2087471
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Douze Matthijs, 2008, TREC VID RETR EV TRE
   Dutta D, 2013, SIGNAL IMAGE VIDEO P, V7, P665, DOI 10.1007/s11760-013-0482-x
   Garboan A., 2011, VISUAL INFORM PROCES
   Hadid Abdenour., 2008, 2008 1 WORKSH IM PRO, P1
   HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P151
   Jiang S., 2013, ERA INTERACTIVE MEDI, P557
   Joly Alexis, 2008, NIST TRECVID NOTEBOO
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kim S, 2014, SIGNAL PROCESS-IMAGE, V29, P788, DOI 10.1016/j.image.2014.05.002
   Kim S, 2014, J VIS COMMUN IMAGE R, V25, P373, DOI 10.1016/j.jvcir.2013.12.003
   Küçüktunç O, 2010, J VIS COMMUN IMAGE R, V21, P838, DOI 10.1016/j.jvcir.2010.07.001
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Law-To J., 2007, Muscle-VCD-2007: a live benchmark for video copy detection
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lian SG, 2010, STUD COMPUT INTELL, V282, P253
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Malekesmaeili M, 2009, EIGHTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P69, DOI 10.1109/ICMLA.2009.32
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Barrios JM, 2013, MULTIMED TOOLS APPL, V62, P75, DOI 10.1007/s11042-011-0915-x
   Marchionini G, 2006, J AM SOC INF SCI TEC, V57, P1629, DOI 10.1002/asi.20336
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Oostveen J, 2001, PROC SPIE, V4472, P121, DOI 10.1117/12.449746
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Poullot S., 2008, Proceedings of the ACM International Conference on Multimedia, P61
   Ren Jennifer, 2012, P 2 ACM ICMR 12
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Tasdemir K, 2014, SIGNAL IMAGE VIDEO P, V8, P1049, DOI 10.1007/s11760-014-0627-6
   Wu ZP, 2014, INT J MULTIMED INF R, V3, P1, DOI 10.1007/s13735-013-0049-1
   Yang X., 2009, P 1 ACM WORKSH LARG, P73, DOI DOI 10.1145/1631058.1631073
   Yeh M.-C., 2009, Proceedings of the 17th ACM international conference on Multimedia, P633
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou Xuebing, 2008, VEHICLE POWER TECHNO, P1
NR 44
TC 11
Z9 11
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 50
EP 64
DI 10.1016/j.jvcir.2015.10.015
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400005
DA 2024-07-18
ER

PT J
AU Kiani, V
   Harati, A
   Mazloum, AV
AF Kiani, Vahid
   Harati, Ahad
   Mazloum, Abedin Vahedian
TI Iterative Wedgelet Transform: An efficient algorithm for computing
   wedgelet representation and approximation of images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiresolution analysis; Wedgelets; Fast wedgelet transform; Non-linear
   least squares; Continuous-domain wedgelet; Wedgelet estimation; Relaxed
   wedgelet; Image approximation; Quad-tree pruning
ID COMPRESSION; MOMENTS
AB The most common method to compute wedgelet transform is based on exhaustive search which requires assessment of all wedgelet atoms and hence is prohibitively slow. In this paper, the discontinuous edge model of the wedgelet is replaced by a continuous differentiable model to make gradient based estimation of the edge parameters possible. The proposed estimation based approach contributes to a surprisingly fast algorithm called Iterative Wedgelet Transform, which leads to a better tradeoff between quality and computation speed compared to the existing approaches.
   Performance of the proposed method is studied in the image approximation task and the results are compared with two other major algorithms, namely classical Wedgelet Transform and Moments-based Wedgelet Transform. The iterative algorithm is shown to be much faster than classical wedgelet transform, O(N(2)log(2)N) given an N x N image; and compared to the moments-based method exhibits higher precision. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kiani, Vahid; Harati, Ahad; Mazloum, Abedin Vahedian] Ferdowsi Univ Mashhad FUM, Fac Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Harati, A (corresponding author), Ferdowsi Univ Mashhad FUM, Fac Engn, Mashhad, Iran.
EM vkiani@stu.um.ac.ir; a.harati@um.ac.ir; vahedian@um.ac.ir
RI Vahedian, Abedin/Q-7812-2019; Kiani, Vahid/AAD-4191-2019; Harati,
   Ahad/P-4468-2015; Kiani, Vahid/AAZ-9719-2020
OI Harati, Ahad/0000-0001-7263-0309; Kiani, Vahid/0000-0002-8248-9262
CR [Anonymous], EL COMP ENG CCECE 20
   Candes E., 1999, CURVES SURFACE FITTI, P105
   Do MN, 2000, PROC SPIE, V4119, P831, DOI 10.1117/12.408673
   Donoho D. L., 2002, Multiscale and Multiresolution Methods, V2002, P149, DOI DOI 10.1007/978-3-642-56205-1
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Kang MK, 2012, IEEE T MULTIMEDIA, V14, P121, DOI 10.1109/TMM.2011.2169238
   Labate D., 2005, P SPIE, V5914
   Le Pennec E, 2000, IEEE IMAGE PROC, P661, DOI 10.1109/ICIP.2000.901045
   Lisowska Agnieszka, 2007, EUROCON 2007. International Conference on "Computer as a Tool", P237, DOI 10.1109/EURCON.2007.4400239
   Lisowska A, 2008, LECT NOTES COMPUT SC, V5112, P182, DOI 10.1007/978-3-540-69812-8_18
   Lisowska A, 2014, STUD COMPUT INTELL, V545, P39, DOI 10.1007/978-3-319-05011-9_4
   Lisowska A, 2011, J MATH IMAGING VIS, V39, P180, DOI 10.1007/s10851-010-0233-3
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Popovici I, 2006, IEEE T PATTERN ANAL, V28, P637, DOI 10.1109/TPAMI.2006.75
   Romberg JK, 2003, IEEE IMAGE PROC, P49
   Romberg JK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P585, DOI 10.1109/ICIP.2002.1039038
   Sebai D., 2012, P SPIE, V8290
   Wakin M, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P237, DOI 10.1109/ICIP.2002.1038949
   Willett RM, 2003, IEEE T MED IMAGING, V22, P332, DOI 10.1109/TMI.2003.809622
NR 20
TC 10
Z9 10
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 65
EP 77
DI 10.1016/j.jvcir.2015.10.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400006
DA 2024-07-18
ER

PT J
AU Fan, H
   Xiang, JH
   Liao, HH
   Du, XP
AF Fan, Heng
   Xiang, Jinhai
   Liao, Honghong
   Du, Xiaoping
TI Robust tracking based on local structural cell graph
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Local structural cell (LSC); Local structural cell
   graph (LSCG); Bayesian framework; Graph matching; Superpixel; Local
   based representation; Appearance model
ID OBJECT TRACKING; VISUAL TRACKING
AB Structure information has been increasingly incorporated into computer vision, however most trackers have ignored the inner spatial structure of the object. In this paper, we develop a simple yet robust tracking algorithm based on local structural cell graph (LSCG). This approach exploits both partial and spatial information of the target via representing the object with local structural cells (LSCs) and constructing a graph to model the spatial structure between the inner parts of the object. The tracking is formulated as matching LSCG, whose nodes are target parts and edges are the interaction between two parts. Within the Bayesian framework, we achieve object tracking by matching graphs between the reference and candidates. Eventually, the candidate with the highest similarity is the target. In addition, an updating strategy is adopted to help our tracker adapt to the fast time-varying object appearance. Experimental results demonstrate that the proposed method outperforms several state-of-the-art trackers. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Fan, Heng] Huazhong Agr Univ, Coll Engn, Wuhan 430070, Peoples R China.
   [Xiang, Jinhai] Huazhong Agr Univ, Coll Informat, Wuhan 430070, Peoples R China.
   [Liao, Honghong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Du, Xiaoping] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Key Lab Digital Earth, Beijing 100094, Peoples R China.
C3 Huazhong Agricultural University; Huazhong Agricultural University;
   Huazhong University of Science & Technology; Chinese Academy of
   Sciences; The Institute of Remote Sensing & Digital Earth, CAS
RP Xiang, JH (corresponding author), Huazhong Agr Univ, Coll Informat, Wuhan 430070, Peoples R China.
EM hfan@webmail.hzau.edu.cn; jimmy_xiang@163.com; hustliaohh@gmail.com;
   duxp@radi.ac.cn
OI Xiang, Jinhai/0000-0002-8923-5302
FU Fundamental Research Funds for the Central Universities [20148Q083]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (Program No. 20148Q083).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2010, PASCAL VISUAL OBJECT
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Choi MJ, 2012, IEEE T PATTERN ANAL, V34, P240, DOI 10.1109/TPAMI.2011.119
   Fan JL, 2010, LECT NOTES COMPUT SC, V6311, P480
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Malik J., 2007, Computer Vision and Pattern Recognition, P1
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Toshev A, 2010, PROC CVPR IEEE, P950, DOI 10.1109/CVPR.2010.5540114
   Wang HZ, 2007, IEEE T PATTERN ANAL, V29, P1661, DOI [10.1109/TPAMI.2007.1112, 10.1109/TPAMl.2007.1112]
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yang F, 2013, IMAGE VISION COMPUT, V31, P992, DOI 10.1016/j.imavis.2013.09.008
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
NR 28
TC 7
Z9 7
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 54
EP 63
DI 10.1016/j.jvcir.2015.05.011
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600005
DA 2024-07-18
ER

PT J
AU Hassanien, AE
   Emary, E
   Zawbaa, HM
AF Hassanien, Aboul Ella
   Emary, E.
   Zawbaa, Hossam M.
TI Retinal blood vessel localization approach based on bee colony swarm
   optimization, fuzzy c-means and pattern search
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Retinal blood vessel; Retinal vessel segmentation; Artificial bee
   colony; Pattern search; Fuzzy c-means; Swarm optimization; Clustering;
   Image enhancement
ID MATCHED-FILTER; SEGMENTATION; IMAGES
AB Accurate segmentation of retinal blood vessels is an important task in computer aided diagnosis and surgery planning of retinopathy. Despite the high resolution of photographs in fundus photography, the contrast between the blood vessels and retinal background tends to be poor. Furthermore, pathological changes of the retinal vessel tree can be observed in a variety of diseases such as diabetes and glaucoma. Vessels with small diameters are much liable to effects of diseases and imaging problems. In this paper, an automated retinal blood vessels segmentation approach based on two levels optimization principles is proposed. The proposed approach makes use of the artificial bee colony optimization in conjunction with fuzzy cluster compactness fitness function with partial belongness in the first level to find coarse vessels. The dependency on the vessel reflectance is problematic as the confusion with background and vessel distortions especially for thin vessels, so we made use of a second level of optimization. In the second level of optimization, pattern search is further used to enhance the segmentation results using shape description as a complementary feature. Thinness ratio is used as a fitness function for the pattern search optimization. The pattern search is a powerful tool for local search while artificial bee colony is a global search with high convergence speed. The proposed retinal blood vessels segmentation approach is tested on two publicly available databases DRIVE and STARE of retinal images. The results demonstrate that the performance of the proposed approach is comparable with state of the art techniques in terms of sensitivity, specificity and accuracy. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hassanien, Aboul Ella; Emary, E.] Cairo Univ, Fac Comp & Informat, Cairo, Egypt.
   [Zawbaa, Hossam M.] Beni Suef Univ, Fac Comp & Informat, Bani Suwayf, Egypt.
   [Zawbaa, Hossam M.] Univ Babes Bolyai, Fac Math & Comp, R-3400 Cluj Napoca, Romania.
C3 Egyptian Knowledge Bank (EKB); Cairo University; Egyptian Knowledge Bank
   (EKB); Beni Suef University; Babes Bolyai University from Cluj
RP Hassanien, AE (corresponding author), Cairo Univ, Fac Comp & Informat, Cairo, Egypt.
RI Hassanien, Aboul ella/O-5672-2014; Emary, Eid M/C-6131-2017; Zawbaa,
   Hossam M./O-6203-2014
OI Hassanien, Aboul ella/0000-0002-9989-6681; Zawbaa, Hossam
   M./0000-0001-6548-2993
FU IPROCOM Marie Curie initial training network, through the People
   Programme (Marie Curie Actions) of the European Union's Seventh
   Framework Programme FP7 under REA [316555]
FX This work was partially supported by the IPROCOM Marie Curie initial
   training network, funded through the People Programme (Marie Curie
   Actions) of the European Union's Seventh Framework Programme
   FP7/2007-2013/ under REA Grant agreement No. 316555. This fund only
   apply for one author (Hossam M. Zawbaa).
CR Ahmed, 2012, INT J SYST BOIL BIOM, V1, P61
   Akbari R, 2010, COMMUN NONLINEAR SCI, V15, P3142, DOI 10.1016/j.cnsns.2009.11.003
   Asad Ahmed. H., 2013, P 2 INT S INT INF IS
   Asad Ahmed. H., 2012, P 7 INT C BIOINSP CO
   Asad Ahmed Hamza, 2013, 13 IEEE INT C HYBR I, P222
   Cinsdikici MG, 2009, COMPUT METH PROG BIO, V96, P85, DOI 10.1016/j.cmpb.2009.04.005
   Foracchia M, 2011, 2 INT WORKSH COMP AS
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Fraz M. M., 2011, COMPUT METHODS PROGR
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Goatman K, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027524
   Grisan E, 2003, P ANN INT IEEE EMBS, V25, P890, DOI 10.1109/IEMBS.2003.1279908
   Haddouche A, 2010, DIGIT SIGNAL PROCESS, V20, P149, DOI 10.1016/j.dsp.2009.06.005
   Heneghan C, 2002, MED IMAGE ANAL, V6, P407, DOI 10.1016/S1361-8415(02)00058-0
   Hooshyar Sina, 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P239, DOI 10.1109/CRV.2010.38
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Kanski J.J., 2007, Clinical Ophthalmology, V6
   LEWIS R.M., 1996, Rank ordering and positive bases in pattern search algorithms
   Lowell J, 2004, IEEE T MED IMAGING, V23, P1196, DOI 10.1109/TMI.2004.830524
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Mendonça AM, 2006, IEEE T MED IMAGING, V25, P1200, DOI 10.1109/TMI.2006.879955
   Mitchell P, 2005, OPHTHALMOLOGY, V112, P245, DOI 10.1016/j.ophtha.2004.08.015
   Moghimirad E, 2012, COMPUT BIOL MED, V42, P50, DOI 10.1016/j.compbiomed.2011.10.008
   Ramakrishnan AG., 2011, IEEE ANN IND C INDIC, P1
   Soares JVB, 2006, IEEE T MED IMAGING, V25, P1214, DOI 10.1109/TMI.2006.879967
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Torczon V, 1997, SIAM J OPTIMIZ, V7, P1, DOI 10.1137/S1052623493250780
   Usman Akram M., 2009, P IASTED INT C SIGN, P260
   Wang JJ, 2006, OBESITY, V14, P206, DOI 10.1038/oby.2006.27
   Wang YF, 2013, PATTERN RECOGN, V46, P2117, DOI 10.1016/j.patcog.2012.12.014
   Yanlam B.S., 2008, IEEE T MED IMAGING, P237
   You XG, 2011, PATTERN RECOGN, V44, P2314, DOI 10.1016/j.patcog.2011.01.007
   Zhang B, 2010, COMPUT BIOL MED, V40, P438, DOI 10.1016/j.compbiomed.2010.02.008
NR 34
TC 34
Z9 35
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 186
EP 196
DI 10.1016/j.jvcir.2015.06.019
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600017
DA 2024-07-18
ER

PT J
AU Huang, LD
   Zhao, W
   Sun, ZB
   Wang, J
AF Huang, Lidong
   Zhao, Wei
   Sun, Zebin
   Wang, Jun
TI An advanced gradient histogram and its application for contrast and
   gradient enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; Gradient enhancement; Gradient histogram; Global
   histogram equalization; Histogram modification; Histogram equalization;
   Image subjective quality; Image gradient
ID EQUALIZATION
AB This paper proposes an image contrast and gradient enhancement method based on advanced gradient histogram equalization (AGHE). We first define a novel advanced gradient histogram (AGH). Unlike the traditional intensity histogram which only contains intensity information, the AGH contains both gradient and intensity information of image. This character enables AGH to alleviate high peaks and thus avoid over enhancement in AGHE. Moreover, it's proved that AGHE can increase the mean of absolute gradients (MAG) which is a measurement of image gradient. Then we present a sine function histogram correction (SHC) to control the enhancement level of AGHE. By modifying AGH using SHC before equalization, both the contrast and gradient enhancement levels can be controlled effectively. Simulation results demonstrate that AGHE with SHC (SAGHE) can improve the image subjective quality effectively by enhancing both the contrast and gradient of image. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Huang, Lidong; Zhao, Wei; Sun, Zebin; Wang, Jun] Beihang Univ, Sch Elect & Informat Engn, Grp 203, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhao, W (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Grp 203, Beijing 100191, Peoples R China.
EM zhaowei203@buaa.edu.cn
CR Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   Celik T, 2012, IEEE T IMAGE PROCESS, V21, P145, DOI 10.1109/TIP.2011.2162419
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Cheng FC, 2010, IEICE T INF SYST, VE93D, P1773, DOI 10.1587/transinf.E93.D.1773
   Cheng HD, 2000, PATTERN RECOGN, V33, P809, DOI 10.1016/S0031-3203(99)00096-5
   DiCarlo JM, 2000, PROC SPIE, V3965, P392, DOI 10.1117/12.385456
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Lee WF, 2009, IEEE IMAGE PROC, P1805, DOI 10.1109/ICIP.2009.5414624
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Miller S. J., 2003, ARITHMETIC GEOMETRIC
   Nercessian SC, 2013, IEEE T IMAGE PROCESS, V22, P3549, DOI 10.1109/TIP.2013.2262287
   Peissig JJ, 2005, PERCEPTION, V34, P1353, DOI 10.1068/p5427
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Toh KKV, 2011, IEEE T CONSUM ELECTR, V57, P1227, DOI 10.1109/TCE.2011.6018878
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang Q, 2007, IEEE T CONSUM ELECTR, V53, P757, DOI 10.1109/TCE.2007.381756
   Wang ZG, 2009, DISPLAYS, V30, P133, DOI 10.1016/j.displa.2009.03.006
   Yang F., 2005, OPT ENG, V44
   Zitnick CL, 2012, PROC CVPR IEEE, P622, DOI 10.1109/CVPR.2012.6247729
NR 29
TC 14
Z9 16
U1 4
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 86
EP 100
DI 10.1016/j.jvcir.2015.06.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600008
DA 2024-07-18
ER

PT J
AU Lee, JC
AF Lee, Jen-Chun
TI Copy-move image forgery detection based on Gabor magnitude
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image forensics; Image splicing; Copy-move forgery; Image
   retouching; Histogram of orientation Gabor magnitude; Gabor filter;
   Duplicate region detection; Lexicographical order
ID EFFICIENT; ALGORITHM
AB With advancement of media editing software, even people who are not image processing experts can easily alter digital images. Various methods of digital image forgery exist, such as image splicing, copy-move forgery, and image retouching. The most common method of tampering with a digital image is copy-move forgery, in which a part of an image is duplicated and used to substitute another part of the same image at a different location. In this paper, we present an efficient and robust method to detect such artifacts. First, the tampered image is segmented into overlapping fixed-size blocks, and the Gabor filter is applied to each block. Thus, the image of Gabor magnitude represents each block. Secondly, statistical features are extracted from the histogram of orientated Gabor magnitude (HOGM) of overlapping blocks, and reduced features are generated for similarity measurement. Finally, feature vectors are sorted lexicographically, and duplicated image blocks are identified by finding similarity block pairs after suitable post-processing. To enhance the algorithm's robustness, a few parameters are proposed for removing the wrong similar blocks. Experiment results demonstrate the ability of the proposed method to detect multiple examples of copy-move forgery and precisely locate the duplicated regions, even when dealing with images distorted by slight rotation and scaling, JPEG compression, blurring, and brightness adjustment. (C) 2015 Elsevier Inc. All rights reserved.
C1 Chinese Naval Acad, Dept Elect Engn, Kaohsiung 813, Taiwan.
RP Lee, JC (corresponding author), Chinese Naval Acad, Dept Elect Engn, Kaohsiung 813, Taiwan.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Chang I-Cheng, 2013, IMAGE VIS COMPUT, V31
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Criminisi A, 2003, PROC CVPR IEEE, P721
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Farid H., 2006, P 8 WORKSH MULT SEC
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fridrich J., 1999, PROC ACM WORKSHOM MU, P19
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gilinsky A, 2013, IEEE I CONF COMP VIS, P777, DOI 10.1109/ICCV.2013.101
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Jae Hyeok Choi, 2013, 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE), P68, DOI 10.1109/GCCE.2013.6664927
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Liang ZS, 2015, J VIS COMMUN IMAGE R, V30, P75, DOI 10.1016/j.jvcir.2015.03.004
   Luo W., 2009, FRONT COMPUT SCI CHI, V1, P308
   Luo WQ, 2006, INT C PATT RECOG, P746
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Ma WY, 1998, J AM SOC INFORM SCI, V49, P633, DOI 10.1002/(SICI)1097-4571(19980515)49:7<633::AID-ASI5>3.0.CO;2-N
   Ma WY, 1996, PROC CVPR IEEE, P425, DOI 10.1109/CVPR.1996.517107
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Yeung N.M., 1998, CACM, V41, P31
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 35
TC 41
Z9 43
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 320
EP 334
DI 10.1016/j.jvcir.2015.07.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600029
DA 2024-07-18
ER

PT J
AU Liu, J
   Zhang, GY
   Liu, Y
   Tian, LC
   Chen, YQ
AF Liu, Jun
   Zhang, Guyue
   Liu, Ye
   Tian, Luchao
   Chen, Yan Qiu
TI An ultra-fast human detection method for color-depth camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human detection; Color-depth image; Depth camera; RGB-D sensor; Kinect;
   Real-time; Cascade-structured; Cluttered and dynamic environments
ID REAL-TIME; TRACKING; PEOPLE; SYSTEM
AB Real-time human detection is important for a wide range of applications. The task is highly challenging due to occlusions, complex backgrounds, and variation of human poses. We propose a cascade-structured approach to real-time human detection in cluttered and dynamic environments with both color and depth data seamlessly incorporated. The first stage efficiently exploits depth data which generates a set of physically plausible yet over-detected candidates. These candidates are then purified by another two filters: a knowledge based human upper portion locator and a data-driven learning based filter. Experimental results show high detection accuracy achieved by the proposed method at 80-140 fps on a single CPU core (without GPU acceleration). (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liu, Jun; Zhang, Guyue; Tian, Luchao; Chen, Yan Qiu] Fudan Univ, Sch Comp Sci, Shanghai 201203, Peoples R China.
   [Liu, Ye] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Jiangsu, Peoples R China.
C3 Fudan University; Nanjing University of Posts & Telecommunications
RP Chen, YQ (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 201203, Peoples R China.
EM ljchangyu@hotmail.com; guyuezhang13@fudan.edu.cn; yeliu@fudan.edu.cn;
   hualitic@163.com; chenyq@fudan.edu.cn
RI Zhang, Guyue/D-7621-2019
OI Zhang, Guyue/0000-0001-9061-1750; Liu, Jun/0000-0002-4365-4165
FU National Natural Science Foundation of China [61175036]
FX This research work is supported by National Natural Science Foundation
   of China, Grant No. 61175036.
CR [Anonymous], 2005, CVPR
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], IROS
   Bevilacqua A., 2006, IEEE INT C VID SIGN
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   Chen Q, 2009, SCI CHINA SER F, V52, P244, DOI 10.1007/s11432-009-0031-y
   Choi W., 2011, ICCVW
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   Chuang CH, 2014, J VIS COMMUN IMAGE R, V25, P1018, DOI 10.1016/j.jvcir.2014.02.014
   Dan BK, 2012, IEEE T CONSUM ELECTR, V58, P1013, DOI 10.1109/TCE.2012.6311350
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Ganotra D., 2003, P SPIE
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Ikemura S., 2010, ACCV
   Levi K., 2004, CVPR
   Li X, 2010, IEEE SIGNAL PROC LET, V17, P308, DOI 10.1109/LSP.2009.2036653
   Liu J, 2013, IEEE IMAGE PROC, P3088, DOI 10.1109/ICIP.2013.6738636
   Liu J, 2015, PATTERN RECOGN LETT, V53, P16, DOI 10.1016/j.patrec.2014.09.013
   Mitzel D., 2012, BMVC
   Mu Y., 2008, CVPR
   Pang YW, 2011, SIGNAL PROCESS, V91, P773, DOI 10.1016/j.sigpro.2010.08.010
   Shuai B, 2012, LECT NOTES COMPUT SC, V7202, P201, DOI 10.1007/978-3-642-31919-8_26
   Wang L., 2012, ACCV
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xia L., 2011, CVPRW
   Xu JS, 2012, IEEE SIGNAL PROC LET, V19, P676, DOI 10.1109/LSP.2012.2210870
   Zhang H, 2013, IEEE T CYBERNETICS, V43, P1429, DOI 10.1109/TCYB.2013.2275291
NR 28
TC 21
Z9 21
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 177
EP 185
DI 10.1016/j.jvcir.2015.06.014
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600016
DA 2024-07-18
ER

PT J
AU Zhang, JG
   Han, YH
   Jiang, JM
AF Zhang, Jianguang
   Han, Yahong
   Jiang, Jianmin
TI Tensor rank selection for multimedia analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tensor rank selection; Tensor decomposition; Tensor BOW; Multimedia
   analysis; Video action recognition; Image classification; Head-pose
   estimation; Regression
ID CLASSIFICATION
AB Tensors representations are widely used in multimedia applications. As a key step of tensor processing, the rank-1 tensor decomposition (i.e., the CANDECOMP/PARAFAC (CP) decomposition) always requires the estimation of the tensor rank. The Pm-norm has been shown to be effective for tensor rank selection. The existing tensor rank selection algorithm force the same columns of the tensor matrices to simultaneously become zero. However, the real sparse columns for different factor matrices may be different. Such strategy does not really uncover the sparse information of each factor matrix. In this paper, we add a separable l(2,1)-norm on multiple factor matrices to obtain real sparse results along to different modes. And then different sparse results are assembled into a joint sparse pattern for tensor rank selection. This added separable regularization term has twofold role in enhancing the effect of regularization for each factor matrix and fully utilizing the knowledge of multiple factor matrices to facilitate decision making. In order to effectively exploit the structure information of multimedia data, we propose a model of tensor bag of words (tBOW) as the direct input of our algorithms. In the experiments, we apply the proposed algorithms to three representative tasks of multimedia analysis, i.e., image classification, video action recognition, and head pose estimation. Experimental results on three open benchmark datasets show that our algorithms are effective to multimedia analysis. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Jianguang; Han, Yahong] Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
   [Jiang, Jianmin] Shenzhen Univ, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Han, Yahong] Tianjin Univ, Tianjin Key Lab Cognit Comp & Applicat, Tianjin, Peoples R China.
   [Zhang, Jianguang] Hengshui Univ, Dept Math & Comp Sci, Hengshui, Peoples R China.
C3 Tianjin University; Shenzhen University; Tianjin University; Hengshui
   University
RP Han, YH (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin, Peoples R China.
EM lynxzjg@tju.edu.cn; yahong@tju.edu.cn; jmjiang@tju.edu.cn
FU NSFC [61202166, 61472276]; Major Project of National Social Science Fund
   [14ZDB153]; Ministry of Education of China [20120032120042]
FX This work was partly supported by the NSFC (under Grant 61202166 and
   61472276), the Major Project of National Social Science Fund (under
   Grant 14ZDB153), and Doctoral Fund of Ministry of Education of China
   (under Grant 20120032120042).
CR [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2572 U ILL URB CHAMP
   [Anonymous], 2009, IEEE T PATTERN ANAL
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Athitsos V., 2007, IEEE 11 INT C COMPUT, P1
   Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   Chen Ming-Yu., MOSIFT RECOGNIZING H
   Cohen I, 2004, IEEE T PATTERN ANAL, V26, P1553, DOI 10.1109/TPAMI.2004.127
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Gourier N., 2004, FG NET WORKSHOP VISU, P1
   Guo G., 2008, International Conference on Pattern Recognition, P1
   Guo WW, 2012, IEEE T IMAGE PROCESS, V21, P816, DOI 10.1109/TIP.2011.2165291
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Kashima H, 2009, IEICE T INF SYST, VE92D, P1338, DOI 10.1587/transinf.E92.D.1338
   Kim D, 2006, LECT NOTES ARTIF INT, V3918, P215
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lu SY, 2013, J VIS COMMUN IMAGE R, V24, P127, DOI 10.1016/j.jvcir.2012.07.008
   Nie F., 2010, ADV NEURAL INFORM PR, V23, P1813, DOI DOI 10.5555/2997046.2997098
   Pele O, 2008, LECT NOTES COMPUT SC, V5304, P495, DOI 10.1007/978-3-540-88690-7_37
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Wang H., 2009, BMVC 2009 BRIT MACH
   Wang P, 2013, INT J COMPUT VISION, V103, P1, DOI 10.1007/s11263-012-0588-6
   Wu QX, 2013, J VIS COMMUN IMAGE R, V24, P1064, DOI 10.1016/j.jvcir.2013.07.001
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Zang D, 2007, J VIS COMMUN IMAGE R, V18, P81, DOI 10.1016/j.jvcir.2006.10.002
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou XM, 2012, IEEE T MULTIMEDIA, V14, P1220, DOI 10.1109/TMM.2012.2194481
NR 32
TC 16
Z9 16
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 376
EP 392
DI 10.1016/j.jvcir.2015.05.004
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900033
DA 2024-07-18
ER

PT J
AU Han, H
   Liu, SJ
   Gan, L
AF Han, Hong
   Liu, Sanjun
   Gan, Lu
TI Non-negativity and dependence constrained sparse coding for image
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-negative Matrix Factorization; Graph Laplacian; Dictionary learning;
   Sparse coding; Spatial pyramid; Image classification; Parameter
   selection; Sparseness
ID NONNEGATIVE MATRIX FACTORIZATION; RECOGNITION
AB Sparse coding method is a powerful tool in many computer vision applications. However, due to the combinatorial optimization of sparse coding involving both additive and subtractive interactions, the features can cancel each other out with subtraction. And also, in the process of independent coding, the locality and the similarity among the instances which be encoded may be lost. To solve these problems, an image classification framework by leveraging the Non-negative Matrix Factorization and graph Laplacian techniques is presented. Firstly, the Non-negative Matrix Factorization is used to constrain both of the codebook and the corresponding coding coefficients non-negativity. To preserve the dependence properties of the locality and the similarity among the instances, the graph Laplacian regularization is utilized. Then, along with max pooling and spatial pyramid matching, we extend our method to Bag-of-Words image representation. Finally, the linear SVM is leveraged for image classification. Experimental results show that the proposed method achieves or outperforms the state-of-the-art results on several benchmarks. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Han, Hong; Liu, Sanjun; Gan, Lu] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Han, H (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM hanh@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61075041, 61105016];
   Fundamental Research Funds for the Central Universities [K5051302026]
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61075041, 61105016), the Fundamental Research Funds for the
   Central Universities (No. K5051302026).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2001, ADV NEURAL INFORM PR
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 2001, IJCV
   [Anonymous], CVPR
   [Anonymous], 2004, Technical report
   [Anonymous], 2011, CVPR
   [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], 2006, P ACM SIGKDD INT C K
   [Anonymous], 2008, CVPR
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], 2010, CVPR
   [Anonymous], 1997, REGIONAL C SERIES MA
   [Anonymous], P ACM SIGIR INT C RE
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], CVPR
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Cho YC, 2005, PATTERN RECOGN LETT, V26, P1327, DOI 10.1016/j.patrec.2004.11.026
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gillis N, 2012, NEURAL COMPUT, V24, P1085, DOI 10.1162/NECO_a_00256
   Gillis N, 2010, PATTERN RECOGN, V43, P1676, DOI 10.1016/j.patcog.2009.11.013
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   He R, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995487
   Hoyer PO, 2004, J MACH LEARN RES, V5, P1457
   Hoyer PO, 2003, NEUROCOMPUTING, V52-4, P547, DOI 10.1016/S0925-2312(02)00782-8
   Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067
   Hoyer PO, 2002, VISION RES, V42, P1593, DOI 10.1016/S0042-6989(02)00017-2
   Kim M, 2006, LECT NOTES COMPUT SC, V3889, P617
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li HL, 2007, J VLSI SIG PROC SYST, V48, P83, DOI 10.1007/s11265-006-0039-0
   Li S.Z., 2001, CVPR
   Liu JL, 2010, AAAI CONF ARTIF INTE, P512
   Mendels F, 2002, INT C PATT RECOG, P326, DOI 10.1109/ICPR.2002.1047462
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Olshausen B.A., The sparsenet software package for MATLAB
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang Y, 2005, INT J PATTERN RECOGN, V19, P495, DOI 10.1142/S0218001405004198
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang Z, 2007, NEUROCOMPUTING, V71, P363, DOI 10.1016/j.neucom.2006.11.023
   Yuan ZJ, 2005, LECT NOTES COMPUT SC, V3540, P333
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou GX, 2011, IEEE T NEURAL NETWOR, V22, P1626, DOI 10.1109/TNN.2011.2164621
NR 48
TC 4
Z9 10
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 247
EP 254
DI 10.1016/j.jvcir.2014.12.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000022
DA 2024-07-18
ER

PT J
AU Hu, HM
   Zhang, XW
   Zhang, W
   Li, B
AF Hu, Hai-Miao
   Zhang, Xiaowei
   Zhang, Wan
   Li, Bo
TI Joint global-local information pedestrian detection algorithm for
   outdoor video surveillance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pedestrian detection; Small-scale pedestrian; Global information; LBP;
   Histogram equalization pre-process; Outdoor video surveillance; Gaussian
   low-pass filtering; Global-local integrated model
ID COLOR; SEQUENCE; FEATURES; FUSION
AB The pedestrian size is usually small in practical outdoor surveillances. The small-scale pedestrian detection for outdoor surveillances is an important but difficult issue due to the limited information and the background interference. According to human cognition, the global information is important for the pedestrian detection. Therefore, a joint global-local information pedestrian detection algorithm is proposed to fully exploit and utilize the global information. The LBP feature is explicitly extracted from the low-frequency component of original images, which are utilized as the global information to suppress the background interference and enrich the description of pedestrian. Moreover, a structure-LBP is proposed to apply the inherent topology structure of human body to LBP. The structure-LBP feature extracted from original images can achieve a more discriminative description of pedestrians compared with the original LBP. The experimental results demonstrate that the proposed algorithm can improve the overall recognition performance for the small-scale pedestrians. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Hu, Hai-Miao; Zhang, Xiaowei; Zhang, Wan; Li, Bo] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Hu, Hai-Miao; Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Hu, HM (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM frank0139@163.com
RI , ulises.gomez-pinedo/C-3414-2016; ZHANG, Xiaowei/AEQ-8255-2022; Li,
   Bo/AAA-8968-2020; Li, bo/IWL-9318-2023
OI , ulises.gomez-pinedo/0000-0003-3097-5557; ZHANG,
   Xiaowei/0000-0003-4854-3736; Li, Bo/0000-0002-7294-6888; 
FU National Science Fund for Distinguished Young Scholars [61125206];
   National Natural Science Foundation of China [61370121]; National
   Hi-Tech Research and Development Program (863 Program) of China
   [2014AA015102]; Outstanding Tutors for doctoral dissertations of S&T
   project in Beijing [20131000602]
FX This work was partially supported by the National Science Fund for
   Distinguished Young Scholars (No. 61125206), the National Natural
   Science Foundation of China (No. 61370121), the National Hi-Tech
   Research and Development Program (863 Program) of China (No.
   2014AA015102), and Outstanding Tutors for doctoral dissertations of S&T
   project in Beijing (No. 20131000602).
CR [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], OPT PREC ENG
   [Anonymous], IEEE C COMP VIS PATT
   BADCOCK JC, 1990, PERCEPTION, V19, P617, DOI 10.1068/p190617
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Chia-Chih Chen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3425, DOI 10.1109/CVPR.2011.5995555
   Curio C, 2000, IEEE T INTELL TRANSP, V1, P155, DOI 10.1109/6979.892152
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Nguyen DT, 2013, PATTERN RECOGN, V46, P1485, DOI 10.1016/j.patcog.2012.10.024
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Felzenszwalb PedroF., 2008, IEEE C COMPUTER VISI
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gavrila D., 2000, PROC EUROPEAN C COMP, P37, DOI [DOI 10.1007/3-540-45053-X, 10.1007/3-540-45053-X-3., DOI 10.1007/3-540-45053-X-3]
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Gerónimo D, 2010, COMPUT VIS IMAGE UND, V114, P583, DOI 10.1016/j.cviu.2009.07.008
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Han J, 2007, PATTERN RECOGN, V40, P1771, DOI 10.1016/j.patcog.2006.11.010
   Hoiem D., 2006, CVPR
   Ioffe S, 2001, INT J COMPUT VISION, V43, P45, DOI 10.1023/A:1011179004708
   Kira Z, 2012, IEEE INT C INT ROBOT, P2396, DOI 10.1109/IROS.2012.6386029
   Le QV., 2011, NEURAL INFORM PROCES
   Li M., 2008, 2008 19 INT C PATTER, P1, DOI DOI 10.1109/ICPR.2008.4761705
   Maji S., 2008, IEEE C COMPUTER VISI, P1
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Naik SK, 2003, IEEE T IMAGE PROCESS, V12, P1591, DOI 10.1109/TIP.2003.819231
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliveira L, 2010, PATTERN RECOGN, V43, P3648, DOI 10.1016/j.patcog.2010.05.014
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pavani SK, 2010, PATTERN RECOGN, V43, P160, DOI 10.1016/j.patcog.2009.05.011
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   SHULMAN GL, 1987, PERCEPTION, V16, P89, DOI 10.1068/p160089
   Song Y, 2000, PROC CVPR IEEE, P810, DOI 10.1109/CVPR.2000.855904
   Torralba A, 2004, PROC CVPR IEEE, P762
   TRAHANIAS PE, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P545, DOI 10.1109/ICPR.1992.202045
   TSUKIYAMA T, 1985, PATTERN RECOGN, V18, P207, DOI 10.1016/0031-3203(85)90046-9
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wen D, 2013, 2013 IEEE NINTH INTERNATIONAL CONFERENCE ON MOBILE AD-HOC AND SENSOR NETWORKS (MSN 2013), P140, DOI 10.1109/MSN.2013.53
   Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Xu R, 2012, PATTERN RECOGN, V45, P2573, DOI 10.1016/j.patcog.2012.01.004
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 57
TC 10
Z9 11
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 168
EP 181
DI 10.1016/j.jvcir.2014.11.009
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000015
DA 2024-07-18
ER

PT J
AU Koli, SM
   Purandare, RG
   Kshirsagar, SP
   Gohokar, VV
AF Koli, S. M.
   Purandare, R. G.
   Kshirsagar, S. P.
   Gohokar, V. V.
TI QoS-Optimized Adaptive Multi-layer (OQAM) architecture of wireless
   network for high quality digital video transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE OQAM; APP-MAC-PHY; EnIP; IMALr; EnAFEC; EvalVid-NS2; VoW; H.264/MPEG4
ID ERROR CONTROL
AB Quality of Service (QoS) optimization is an important design goal in wireless video transmission. The application (APP) layer 802.11e medium access control (MAC) layer, and physical (PHY) layer of the wireless protocol stack can be jointly designed for the exchange of information. This will optimize the performance of wireless network for real-time digital video transmission. This paper proposes an innovative `QoS-Optimized Adaptive Multi-layer (OQAM)' architecture. It ensures reliable and high-quality video transmission over communication channels. The channel exhibits wide variability in throughput, delay, and packet loss. The simulation is performed using EvalVid and Network Simulator-2. Enhanced Intra Prediction (EnIP) algorithm with H.264/MPEG4 Advanced Video Coding (AVC) is proposed at the APP layer. This H.264/MPEG4 AVC is a non-scalable video enCOder/DECoder (CODEC). Improved MAC Adaptive Retry Limit (IMAL(r)) is proposed as smart-packet drop mechanism at the 802.11e MAC layer. It uses packet overflow drop (P-ov,) and expired-time packet discard (P-ex) algorithm. Enhanced Adaptive Forward Error Correction (EnAFEC) is proposed at the PHY layer. The aforementioned algorithms are jointly considered in the proposed OQAM architecture, which increases the coding efficiency, reduces end-to-end delay and increases reliability of wireless network for real-time Video over Wireless (VoW) transmission. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Koli, S. M.] Smt Kashibai Navale Coll Engn, Dept Elect & Telecommun Engn, Pune 411041, Maharashtra, India.
   [Purandare, R. G.] Vishwakarma Inst Informat Technol, Dept Elect & Telecommun Engn, Pune 411048, Maharashtra, India.
   [Kshirsagar, S. P.] AnchorTek Techno Consultancy Pvt Ltd, Pune 411048, Maharashtra, India.
   [Gohokar, V. V.] Shree Sant Gajanan Maharaj Coll Engn, Dept Elect & Telecommun Engn, Pune 411041, Maharashtra, India.
RP Koli, SM (corresponding author), Smt Kashibai Navale Coll Engn, Dept Elect & Telecommun Engn, Pune 411041, Maharashtra, India.
EM smkoli.skncoe@sinhgad.edu; purandare.radhika@viit.ac.in;
   shirish@anchorteksys.com; vvgohokar@ssgmce.ac.in
RI Gohokar, Vinaya/AAY-2134-2020; Gohokar, Vinaya/J-8116-2012; Koli, Dr.
   Sanjay/ABE-9170-2021; Gohokar, Vinaya/AAR-1853-2020
OI Gohokar, Vinaya/0000-0002-7386-0234; Gohokar,
   Vinaya/0000-0002-7386-0234; Gohokar, Vinaya/0000-0002-7386-0234; Koli,
   Sanjay/0000-0001-5401-959X
CR Baguda YS, 2010, INT CONF ADV COMMUN, P565
   BAN Y, 1997, EFFECTIVE REAL TIME, P721
   CHAI Y, 7 IEEE INT C COMP IN, P534
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   HOSSEIN B, 2012, IEEE T MULTIMEDIA, V14, P401
   Hueda MR, 2001, GLOB TELECOMM CONF, P619, DOI 10.1109/GLOCOM.2001.965191
   Jiang D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1923
   Kao CC, 2012, 2012 7TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P638, DOI 10.1109/ChinaCom.2012.6417561
   Khalek AA, 2012, IEEE J SEL AREA COMM, V30, P1157, DOI 10.1109/JSAC.2012.120802
   Kim Y, 2008, Third 2008 International Conference on Convergence and Hybrid Information Technology, Vol 2, Proceedings, P33, DOI 10.1109/ICCIT.2008.218
   Koli SM, 2013, WIRELESS PERS COMMUN, V73, P913, DOI 10.1007/s11277-013-1223-8
   KOLI SM, 2014, WIRELESS PERSONAL CO, V74
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   KUO CI, 2010 6 INT C INT INF, P252
   Lin CH, 2006, 20TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P565
   MANSOUR H, 2009 16 INT C DIG SI, P1
   MIZOSOE H, 2012 IEEE C CONS EL, P65
   N SS, 2007, IEEE T VEH TECHNOL, V56, P2346, DOI 10.1109/TVT.2007.897646
   NASIOPOULOS P, 2008, EURASIP J WIREL COMM, P1
   Raty T., 2007, INT C QUAL INF COMM, P123
   Romdhani L, 2003, IEEE WCNC, P1373
   Sgardoni V, 2009, IEEE T CONSUM ELECTR, V55, P69, DOI 10.1109/TCE.2009.4814416
   Tan YB, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE AND EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P263, DOI 10.1109/ITME.2008.4743866
   Tian CH, 2009, PROCEEDINGS OF 2009 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATION, LOGISTICS AND INFORMATICS, P1, DOI 10.1109/SOLI.2009.5203894
   van der Schaar M, 2006, IEEE T MOBILE COMPUT, V5, P755, DOI 10.1109/TMC.2006.81
   van der Schaar M, 2006, IEEE T MULTIMEDIA, V8, P1082, DOI 10.1109/TMM.2006.879827
   WEN G, 2010, APPL RES COMPUT, V27
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu D, 2009, IEEE WIREL COMMUN, V16, P48, DOI 10.1109/MWC.2009.5281255
NR 29
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 210
EP 221
DI 10.1016/j.jvcir.2014.11.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000019
DA 2024-07-18
ER

PT J
AU Chen, SB
   Ding, CHQ
   Luo, B
AF Chen, Si-Bao
   Ding, Chris H. Q.
   Luo, Bin
TI Extended linear regression for undersampled face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Linear regression; Intraclass variant dictionary; Singular value
   decomposition; Face recognition; Low rank; Undersampled classification;
   Supervised learning; Pattern recognition
ID DIMENSIONALITY REDUCTION; ILLUMINATION; DICTIONARY; EIGENFACES; POSE
AB Linear Regression Classification (LRC) is a newly-appeared pattern recognition method, which formulates the recognition problem in terms of class-specific linear regression with sufficient training samples per class. In this paper, we extend LRC via intraclass variant dictionary and SVD to undersampled face recognition where there are very few, or even only one, training sample per class. Intraclass variant dictionary is adopted in undersampled situation to represent the possible variation between the training and testing samples. Three types of methods, quasi-inverse, ridge regularization and Singular Value Decomposition (SVD), are designed to solve low-rank problem of data matrix. Then the whole algorithm, named Extended LRC (ELRC), is presented for face recognition via intraclass variant dictionary and SVD. The experimental results on three well-known face databases show that the proposed ELRC has better generalization ability and is more robust to classification than many state-of-the-art methods in undersampled situation. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chen, Si-Bao; Luo, Bin] Anhui Univ, Sch Comp Sci & Technol, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230039, Anhui, Peoples R China.
   [Ding, Chris H. Q.] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA.
C3 Anhui University; University of Texas System; University of Texas
   Arlington
RP Chen, SB (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Minist Educ, Key Lab Intelligent Comp & Signal Proc, Hefei 230039, Anhui, Peoples R China.
EM sbchen@ahu.edu.cn; CHQDing@uta.edu; luobin@ahu.edu.cn
RI lu, bin/HPE-4790-2023; LUO, BIN/Y-1233-2018
OI LUO, BIN/0000-0001-5948-5055
FU National Natural Science Foundation of China [61202228, 61073116];
   Doctoral Program Foundation of Institutions of Higher Education of China
   [20103401120005]; Collegiate Natural Science Fund of Anhui Province
   [KJ2012A004, KJ2012A008]
FX We would like to thank all reviewers and editors for their detailed
   reviews, constructive criticisms and positive comments. This work was
   supported in part by the National Natural Science Foundation of China
   (61202228, 61073116), the Doctoral Program Foundation of Institutions of
   Higher Education of China (20103401120005), and Collegiate Natural
   Science Fund of Anhui Province (KJ2012A004, KJ2012A008).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   HE X, 2003, P C ADV NEURAL INFOR
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   Martinez A., 1998, AR FACE DATABASE
   Naseem I, 2012, PATTERN RECOGN, V45, P104, DOI 10.1016/j.patcog.2011.07.003
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
NR 27
TC 7
Z9 9
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1800
EP 1809
DI 10.1016/j.jvcir.2014.07.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100029
DA 2024-07-18
ER

PT J
AU Paul, JS
   Mathew, JJ
   Kesavadas, C
AF Paul, Joseph Suresh
   Mathew, Joshin John
   Kesavadas, Chandrasekhar
TI MR image enhancement using an extended neighborhood filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; Contrast Ratio; Extended neighbors; Lattice size;
   Local Histogram Equalization; Shift exponents; Degree of enhancement;
   Binary maps
AB A filtering scheme is proposed for contrast enhancement within a Region-Of-Interest (ROI) containing unconnected foreground regions of narrow spatial extent such as multiple sclerosis, or ischemic lesions in Magnetic Resonance (MR) images. This involves determination of localized multiplicative weights in the spatial domain using an extended set of neighborhood directions. The degree of enhancement is shown to depend on the number of such directions, as determined from the size of a rectangular lattice, together with a threshold value used for computing the multiplicative weights. Best performance in respect of visual quality is achieved by choosing a threshold corresponding to the maximum Contrast Ratio, and lattice size corresponding to the maximum Peak Signal-to-Noise Ratio within the ROI. It is shown that the proposed filter overrides Localized Histogram based Equalization (LHE) based techniques in terms of computational complexity, preservation of structural similarity and attaining the maximum extent of contrast stretching. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Paul, Joseph Suresh; Mathew, Joshin John] Indian Inst Informat Technol & Management Kerala, Med Image Comp & Signal Proc Lab, Trivandrum 695581, Kerala, India.
   [Kesavadas, Chandrasekhar] SCTIMST, Dept Imaging Sci & Intervent Radiol, Trivandrum, Kerala, India.
C3 Kerala University of Digital Sciences, Innovation & Technology (Digital
   University Kerala); Department of Science & Technology (India); Sree
   Chitra Tirunal Institute for Medical Sciences Technology (SCTIMST)
RP Paul, JS (corresponding author), Indian Inst Informat Technol & Management Kerala, Med Image Comp & Signal Proc Lab, Trivandrum 695581, Kerala, India.
EM j.paul@iiitmk.ac.in
RI KESAVADAS, CHANDRASEKHARAN/ABG-8488-2020
OI KESAVADAS, CHANDRASEKHARAN/0000-0003-4914-8666
CR [Anonymous], 2012, INT J SOFT COMPUT EN
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Eramian M, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P397, DOI 10.1109/CRV.2005.47
   GORDON R, 1984, APPL OPTICS, V23, P560, DOI 10.1364/AO.23.000560
   Guodong Zhang, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2462
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Hsueh-Yen Y., 2007, IEEE NUC SCI S C REC, V5, P3851
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Jain K.A., 1989, FUNDAMENTALS DIGITAL
   Khademi A, 2010, IEEE SIGNAL PROC LET, V17, P989, DOI 10.1109/LSP.2010.2082527
   LAINE AF, 1994, IEEE T MED IMAGING, V13, P725, DOI 10.1109/42.363095
   PACKARD NH, 1985, J STAT PHYS, V38, P901, DOI 10.1007/BF01010423
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Sakuldee R, 2007, PROC WRLD ACAD SCI E, V26, P434
   Shao L., 2013, IEEE T CYBERNET
   Shao L., 2013, IEEE T IMAGE PROCESS
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5
   Yang S., 2003, P ICIP 03, V1, P881
NR 23
TC 3
Z9 3
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1604
EP 1615
DI 10.1016/j.jvcir.2014.07.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100011
DA 2024-07-18
ER

PT J
AU Kapsouras, I
   Nikolaidis, N
AF Kapsouras, Ioannis
   Nikolaidis, Nikos
TI Action recognition on motion capture data using a dynemes and forward
   differences representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Action representation; Angular K-means; Skeleton
   animation; Motion capture data; Dynemes; Forward differences; Bag of
   words
ID SEQUENCE
AB In this paper we introduce a novel method for action/movement recognition in motion capture data. The joints orientation angles and the forward differences of these angles in different temporal scales are used to represent a motion capture sequence. Initially K-means is applied on training data to discover the most representative patterns on orientation angles and their forward differences. A novel K-means variant that takes into account the periodic nature of angular data is applied on the former. Each frame is then assigned to one or more of these patterns and histograms that describe the frequency of occurrence of these patterns for each movement are constructed. Nearest neighbour and SVM classification are used for action recognition on the test data. The effectiveness and robustness of this method is shown through extensive experimental results on four standard databases of motion capture data and various experimental setups. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Kapsouras, Ioannis; Nikolaidis, Nikos] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Kapsouras, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM jkapsouras@aiia.csd.auth.gr; nikolaid@aiia.csd.auth.gr
RI Nikolaidis, Nikos/F-1819-2010
OI Nikolaidis, Nikos/0000-0003-1515-7986
CR [Anonymous], 2011, HUMAN GESTURE BEHAV
   [Anonymous], 2013, P INT JOINT C ART IN
   [Anonymous], P 1 INT WORKSH MACH
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2007, IEEE INT C COMP VIS
   [Anonymous], 2006 IEEE COMP SOC C
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Burdea G. C., 2003, Virtual reality technology
   Choi J., 2008, ACM ICMR, P291
   Deng LQ, 2012, COMPUT GRAPH FORUM, V31, P202, DOI 10.1111/j.1467-8659.2011.02095.x
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   Ji XF, 2010, IEEE T SYST MAN CY C, V40, P13, DOI 10.1109/TSMCC.2009.2027608
   Jia XF, 2012, INT C PATT RECOG, P3001
   Li C, 2007, MULTIMED TOOLS APPL, V35, P55, DOI 10.1007/s11042-007-0119-6
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lin CD, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, VOLS 1 AND 2, P1
   Lv FJ, 2005, LECT NOTES COMPUT SC, V3766, P120, DOI 10.1007/11573425_12
   Nikolaidis N, 1998, IEEE T SIGNAL PROCES, V46, P3181, DOI 10.1109/78.735295
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Parent Rick., 2002, COMPUTER ANIMATION
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2010, PROC CVPR IEEE, P2077, DOI 10.1109/CVPR.2010.5539885
   Shariat S, 2011, IEEE I CONF COMP VIS, P2572, DOI 10.1109/ICCV.2011.6126545
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang JY, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 1, PROCEEDINGS, P234, DOI 10.1109/WCSE.2009.354
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 38
TC 58
Z9 69
U1 2
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1432
EP 1445
DI 10.1016/j.jvcir.2014.04.007
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100013
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
AF Al-Otum, Hazem Munawer
TI Semi-fragile watermarking for grayscale image authentication and tamper
   detection based on an adjusted expanded-bit multiscale
   quantization-based technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image authentication; Tamper detection; Semi fragile multiscale
   watermarking
ID DIGITAL WATERMARKING
AB In this work, a semi-fragile watermarking scheme, for grayscale image authentication and tamper detection, is proposed. The proposed watermarking scheme is based on implementing a modified DWT quantization-based algorithm by embedding a random watermark bit sequence into the DWT domain using an expanded-bit multiscale quantization-based technique with adjusted watermarked location. Here, the watermark bit is expanded into three similar bits and embedded in a multiscale fashion into the DWT low-frequency subbands of the 2nd DWT levels (LL2, LLHL1 and LLLH1). An adjustment of the quantized coefficients is provided based on modifying their values to fall in more secure locations within the quantization interval. Several designed criteria were used to judge the received image by classifying it into: authenticated, incidentally or maliciously attacked with high accuracy in detecting and classifying attacks. Experimental results have shown the suitability of the proposed approach for tamper detection and accurate authentication. (c) 2014 Published by Elsevier Inc.
C1 Jordan Univ Sci & Technol, EE Dept, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Ashourian M, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P375, DOI 10.1109/ISSPA.2003.1224892
   Berghel H, 1996, COMPUTER, V29, P101, DOI 10.1109/2.511977
   Chan CS, 2007, PATTERN RECOGN, V40, P681, DOI 10.1016/j.patcog.2006.05.018
   Che SB, 2007, INT C WAVEL ANAL PAT, P382
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Cox IJ, 2002, EURASIP J APPL SIG P, V2002, P126, DOI 10.1155/S1110865702000525
   Cox IJ., 2007, DIGITAL WATERMARKING
   Cruz C, 2008, MIDWEST SYMP CIRCUIT, P306, DOI 10.1109/MWSCAS.2008.4616797
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Kuo CT, 2007, PATTERN RECOGN, V40, P3691, DOI 10.1016/j.patcog.2007.03.025
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lou DC, 2000, IEEE T CONSUM ELECTR, V46, P31, DOI 10.1109/30.826378
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Preda RO, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3558734
   Preda RO, 2011, INT J ELECTRON, V98, P393, DOI 10.1080/00207217.2010.547810
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Rey C., 2002, EURASIP Journal on Applied Signal Processing, V2002, P613, DOI 10.1155/S1110865702204047
   Wu YT, 2004, PATTERN RECOGN, V37, P2349, DOI [10.1016/S0031-3203(04)00189-X, 10.1016/j.patcog.2004.05.003]
   Yang HF, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P1112
   Yu D, 2006, PATTERN RECOGN, V39, P935, DOI 10.1016/j.patcog.2005.11.023
   Yuan H, 2006, IEEE T IMAGE PROCESS, V15, P3189, DOI 10.1109/TIP.2006.877310
   Zhao Y., 2003, THESIS U TORONTO TOR
NR 24
TC 58
Z9 60
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1064
EP 1081
DI 10.1016/j.jvcir.2013.12.017
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200033
DA 2024-07-18
ER

PT J
AU Chen, S
   Li, SZ
   Su, SZ
   Cao, DL
   Ji, RR
AF Chen, Si
   Li, Shaozi
   Su, Songzhi
   Cao, Donglin
   Ji, Rongrong
TI Online semi-supervised compressive coding for robust visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Generative tracking; Discriminative tracking;
   Semi-supervised compressive coding; Online learning; Compressive
   sensing; Semi-supervised coding; Random projection
ID RESTRICTED ISOMETRY PROPERTY
AB In this paper we propose an online semi-supervised compressive coding algorithm, termed SCC, for robust visual tracking. The first contribution of this work is a novel adaptive compressive sensing based appearance model, which adopts the weighted random projection to exploit both local and discriminative information of the object. The second contribution is a semi-supervised coding technique for online sample labeling, which iteratively updates the distributions of positive and negative samples during tracking. Under such a circumstance, the pseudo-labels of unlabeled samples from the current frame are predicted according to the local smoothness regularizer and the similarity between the prior and the current model. To effectively track the object, a discriminative classifier is online updated by using the unlabeled samples with pseudo-labels in the weighted compressed domain. Experimental results demonstrate that our proposed algorithm outperforms the state-of-the-art tracking methods on challenging video sequences. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Li, Shaozi] Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China.
   Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen 361005, Peoples R China.
C3 Xiamen University; Xiamen University
RP Li, SZ (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Xiamen 361005, Peoples R China.
EM szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU National Nature Science Foundation of China [61373076, 61202143,
   61201359]; Fundamental Research Funds for the Central Universities
   [20131 21026, 2011121052]; 985 Project of Xiamen University; Natural
   Science Foundation of Fujian Province [2013105100, 2010101345,
   2011101367]; Key Projects Fund of Science and Technology in Xiamen
   [3502Z20123017]; Research Fund for the Doctoral Program of Higher
   Education of China [201101211120024]; Special Fund for Developing
   Shenzhen's Strategic Emerging Industries [JCYJ20120614164600201]; Hunan
   Provincial Natural Science Foundation [12112040]; Hunan Province
   Research Foundation of Education Committee [09A046]
FX This work is supported by the National Nature Science Foundation of
   China (Nos. 61373076, 61202143 and 61201359), the Fundamental Research
   Funds for the Central Universities (Nos. 20131 21026 and 2011121052),
   the 985 Project of Xiamen University, the Natural Science Foundation of
   Fujian Province (Nos. 2013105100, 2010101345 and 2011101367), the Key
   Projects Fund of Science and Technology in Xiamen (No. 3502Z20123017),
   the Research Fund for the Doctoral Program of Higher Education of China
   (No. 201101211120024), the Special Fund for Developing Shenzhen's
   Strategic Emerging Industries (No. JCYJ20120614164600201), the Hunan
   Provincial Natural Science Foundation (No. 12112040), and the Hunan
   Province Research Foundation of Education Committee (No. 09A046).
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], 2012, P 12 EUR C COMP VIS
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   DIACONIS P, 1984, ANN STAT, V12, P793, DOI 10.1214/aos/1176346703
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duda R., 1973, Pattern Classification and Scene Analysis
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gao JB, 2012, PATTERN RECOGN LETT, V33, P1163, DOI 10.1016/j.patrec.2012.02.007
   Gao Yue, 2014, IEEE T CIRCUITS SYST
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Jian-Yu Hsieh, 2007, Proceedings of the Fifth IASTED International Conference on Circuits, Signals, and Systems, P1, DOI 10.1145/1329125.1329139
   Johnson W.B., 1984, C MODERN ANAL PROBAB, V26
   Leistner C., 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1362, DOI 10.1109/ICCVW.2009.5457451
   Li HX, 2011, PROC CVPR IEEE, P1305, DOI 10.1109/CVPR.2011.5995483
   Li P., 2006, P ACM SIGKDD INT C K, P287
   Li PH, 2003, IMAGE VISION COMPUT, V21, P111, DOI 10.1016/S0262-8856(02)00133-6
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235
   Mason L, 2000, ADV NEUR IN, P221
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari A, 2008, LECT NOTES COMPUT SC, V5304, P588, DOI 10.1007/978-3-540-88690-7_44
   Tsagkatakis G, 2011, IEEE T CIRC SYST VID, V21, P1810, DOI 10.1109/TCSVT.2011.2133970
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 36
TC 13
Z9 13
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 793
EP 804
DI 10.1016/j.jvcir.2014.01.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200008
DA 2024-07-18
ER

PT J
AU Chen, YC
   Shiu, CW
   Horng, G
AF Chen, Yu-Chi
   Shiu, Chih-Wei
   Horng, Gwoboa
TI Encrypted signal-based reversible data hiding with public key
   cryptosystem
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Data hiding; Reversible data hiding; Encrypted signal;
   Public key cryptosystem; Paillier encryption; Security; Secret message
   recovery
ID HISTOGRAM-MODIFICATION; STEGANOGRAPHY
AB Encrypted image-based reversible data hiding (EIRDH) is a well-known method allowing that (1) the image provider gives the data hider an encrypted image, (2) the data hider embeds the secret message into it to generate the encrypted image with the embedded secret message to the receiver, and (3) finally the receiver can extract the message and recover the original image without encryption. In the literature, the data hider and image provider must be specific parties who know the shared key with the receiver in traditional encrypted image-based reversible data hiding. In this paper, we propose an encrypted signal-based reversible data hiding (ESRDH) with public key cryptosystem, not only for images. The proposed scheme is secure based on Paillier homomorphic encryption. Finally, the experimental results show that the proposed scheme has much payload and high signal quality. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Chen, Yu-Chi] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   [Shiu, Chih-Wei; Horng, Gwoboa] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 Academia Sinica - Taiwan; National Chung Hsing University
RP Chen, YC (corresponding author), Acad Sinica, Inst Informat Sci, 128 Acad Rd,Sect 2, Taipei 115, Taiwan.
EM wycchen@ieee.org; chihwei.shiu@gmail.com; gbhorng@cs.nchu.edu.tw
OI Shiu, Chih-Wei/0000-0003-1319-9023; Chen, Yu-Chi/0000-0002-5577-0016
FU Taiwan National Science Council [102-2221-E-005-051, 102-2917-I-005-007]
FX This work was supported by Taiwan National Science Council, Nos.
   102-2221-E-005-051 and 102-2917-I-005-007. Partial research results of
   this work were done, while the first author was at Department of
   Computer Science and Engineering, National Chung Hsing University.
CR Chen JN, 2013, J SYST SOFTWARE, V86, P1377, DOI 10.1016/j.jss.2012.12.053
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong WE, 2010, J SYST SOFTWARE, V83, P2653, DOI 10.1016/j.jss.2010.08.047
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Karim MSA, 2014, SIGNAL PROCESS, V94, P174, DOI 10.1016/j.sigpro.2013.06.014
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Munuera C, 2007, SIGNAL PROCESS, V87, P1528, DOI 10.1016/j.sigpro.2006.12.008
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Puech W., 2008, P SOC PHOTO-OPT INS
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Qin C, 2013, DIGIT SIGNAL PROCESS, V23, P578, DOI 10.1016/j.dsp.2012.11.002
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tsai YY, 2013, DIGIT SIGNAL PROCESS, V23, P919, DOI 10.1016/j.dsp.2012.12.014
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 29
TC 145
Z9 163
U1 0
U2 55
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1164
EP 1170
DI 10.1016/j.jvcir.2014.04.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200042
DA 2024-07-18
ER

PT J
AU Seetharaman, K
   Jeyakarthic, M
AF Seetharaman, K.
   Jeyakarthic, M.
TI Statistical distributional approach for scale and rotation invariant
   color image retrieval using multivariate parametric tests and
   orthogonality condition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Variance-Covariance; Mean vectors; Position vector; Skewness; Kurtosis;
   Query image; Target image; Tests of hypothesis
ID CLASSIFICATION; FRAMEWORK; EFFICIENT; SCHEME
AB This paper proposes a unified framework for color image retrieval, based on statistical multivariate parametric tests, namely test for equality of covariance matrices, test for equality of mean vectors, and the orthogonality test. The proposed method tests the variation between the query and target images; if it passes the test, then it proceeds to test the spectrum of energy of the two images; otherwise, the test is dropped. If the query and target images pass both the tests then it is concluded that the two images belong to the same class, i.e., both the images are same; otherwise, it is assumed that the images belong to different classes, i.e., both the images are different. The obtained test statistic values are indexed in ascending order and the image corresponds to the least value is identified as same or similar images. Here, either the query image or target image is treated as sample; the other is treated as population. Also, some other features such as Coefficient of Variation, Skewness, Kurtosis, Variance-Covariance, spectrum of energy, and number of shapes in the images are compared between the query and target images color-wise. Furthermore, to emphasize the efficiency of the proposed system, the geometrical structure, viz. test for orthogonality between the query and target images, is examined. In the case of structure images, the number of shapes in the query and target images are compared; if it matches, then the contents in the shapes are compared color-wise. The proposed system is invariant for scaling, and rotation, since the system adjusts itself and treats either the query image or the target image is the sample of other. The proposed framework provides hundred percent accuracy if the query and target images are same, whereas there is a slight variation for similar, scaled, and rotated images. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Seetharaman, K.; Jeyakarthic, M.] Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.
C3 Annamalai University
RP Seetharaman, K (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.
EM kseethadde@yahoo.com; jeya_karthic@yahoo.com
CR Anderson T.W., 1962, Tech. rep.
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   David M.W., 2012, P 13 C EUR CHAPT ASS, P345
   Deng YN, 1999, INT CONF ACOUST SPEE, P3017, DOI 10.1109/ICASSP.1999.757476
   Fuh CS, 2000, IEEE T IMAGE PROCESS, V9, P156, DOI 10.1109/83.817608
   Greenspan H, 2001, COMPUT VIS IMAGE UND, V84, P384, DOI 10.1006/cviu.2001.0946
   Greenspan H, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P27, DOI 10.1109/IVL.2000.853835
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Hsieh IS, 2001, IEEE T IMAGE PROCESS, V10, P938, DOI 10.1109/83.923290
   Hsieh JW, 2003, IEEE T IMAGE PROCESS, V12, P1404, DOI 10.1109/TIP.2003.816013
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jing F, 2004, IEEE T IMAGE PROCESS, V13, P699, DOI 10.1109/TIP.2004.826125
   JING F, 2001, P 3 ACM INT WORKSH M
   Jing F., 2002, IEEE INT S CIRC SYST
   KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Krishnamoorthi R, 2012, J VIS COMMUN IMAGE R, V23, P18, DOI 10.1016/j.jvcir.2011.07.011
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Minka TP, 1997, PATTERN RECOGN, V30, P565, DOI 10.1016/S0031-3203(96)00113-6
   Natsev A, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P395, DOI 10.1145/304181.304217
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   RAO CS, 2007, ICGST GVIP J, V7, P9
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Seetharaman K, 2013, INT J IMAGE DATA FUS, V4, P342, DOI 10.1080/19479832.2013.804007
   Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   Theoharatos C, 2005, IEEE T KNOWL DATA EN, V17, P808, DOI 10.1109/TKDE.2005.85
   Vasconcelos N., 1999, P NIPS 99 DENV CO
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WANG JZ, 2001, P ACM IEEE JOINT C D, P268
NR 34
TC 10
Z9 10
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 727
EP 739
DI 10.1016/j.jvcir.2014.01.004
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200001
DA 2024-07-18
ER

PT J
AU Hao, Y
   Xu, JL
AF Hao, Yan
   Xu, Jianlou
TI An effective dual method for multiplicative noise removal
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Multiplicative noise; Total variation; Dual method;
   Augmented Lagrangian method; Split Bregman; Multi-step projection
   method; Forward-backward method
ID MODEL; ALGORITHMS
AB The problem of multiplicative noise removal has been widely studied recently, but most models focus on the unconstrained problems. These models require knowing the prior level of noise beforehand, however, the information is not obtained in some case and the regularization parameters are not easy to be adjusted. Thus, in the paper, we mainly study an optimization problem with total variation constraint, and propose two new denoising algorithms which compute the projection on the set of images whose total variation is bounded by a constant. In the first algorithm, we firstly give the dual formula of our model, then compute the dual problem using alternating direction method of multipliers. Experimental results show that our method is simple and efficient to filter out the multiplicative noise when the prior of noise is unknown. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hao, Yan; Xu, Jianlou] Henan Univ Sci & Technol, Sch Math & Stat, Luoyang 471023, Peoples R China.
C3 Henan University of Science & Technology
RP Hao, Y (corresponding author), Henan Univ Sci & Technol, Sch Math & Stat, Luoyang 471023, Peoples R China.
EM haoyan_@126.com
FU National Natural Science Foundation of China [61301229]; doctoral
   research fund of Henan University of Science and Technology [09001708,
   09001751]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61301229) and the doctoral research fund of Henan University
   of Science and Technology (No. 09001708, 09001751). In addition, we
   would like to thank Editors and anonymous reviewers for their
   constructive comments that greatly improve this paper.
CR Achim A, 2003, IEEE T GEOSCI REMOTE, V41, P1773, DOI 10.1109/TGRS.2003.813488
   Achim A, 2006, IEEE T IMAGE PROCESS, V15, P2686, DOI 10.1109/TIP.2006.877362
   Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   [Anonymous], EURASIP J ADV SIGNAL
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bach F, 2012, OPTIMIZATION FOR MACHINE LEARNING, P19
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Duchi J., 2008, P 25 INT C MACH LEAR, P272
   Durand S, 2010, J MATH IMAGING VIS, V36, P201, DOI 10.1007/s10851-009-0180-z
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Esser E., 2009, UCLA CAM REPORTS
   Fadili JM, 2011, IEEE T IMAGE PROCESS, V20, P657, DOI 10.1109/TIP.2010.2072512
   Gabay D., 1976, Computers & Mathematics with Applications, V2, P17, DOI 10.1016/0898-1221(76)90003-1
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Jin ZM, 2011, J MATH IMAGING VIS, V39, P62, DOI 10.1007/s10851-010-0225-3
   Jin ZM, 2010, J MATH ANAL APPL, V362, P415, DOI 10.1016/j.jmaa.2009.08.036
   Krissian K, 2007, IEEE T IMAGE PROCESS, V16, P1412, DOI 10.1109/TIP.2007.891803
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li F, 2010, SIAM J IMAGING SCI, V3, P1, DOI 10.1137/090748421
   Li F, 2009, J VIS COMMUN IMAGE R, V20, P293, DOI 10.1016/j.jvcir.2009.01.003
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2012, J COMPUT APPL MATH, V236, P2200, DOI 10.1016/j.cam.2011.09.042
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Shi JN, 2008, SIAM J IMAGING SCI, V1, P294, DOI 10.1137/070689954
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Tai XC, 2009, LECT NOTES COMPUT SC, V5567, P502
   Xie H, 2002, IEEE T GEOSCI REMOTE, V40, P2196, DOI 10.1109/TGRS.2002.802473
   Ye G. B., 2010, ARXIV10120975
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
NR 35
TC 6
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 306
EP 312
DI 10.1016/j.jvcir.2013.11.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300007
DA 2024-07-18
ER

PT J
AU Koo, S
   Lee, D
   Kwon, DS
AF Koo, Seongyong
   Lee, Dongheui
   Kwon, Dong-Soo
TI Incremental object learning and robust tracking of multiple objects from
   RGB-D point set
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple objects tracking; RGB-D point set data; Gaussian mixture
   models; 3-d point set registration; Incremental learning; Robot vision;
   Visual tracking; Tempo-spatial data association
ID ALGORITHM; MIXTURE; MODEL
AB In this paper, we propose a novel model-free approach for tracking multiple objects from RGB-D point set data. This study aims to achieve the robust tracking of arbitrary objects against dynamic interaction cases in real-time. In order to represent an object without prior knowledge, the probability density of each object is represented by Gaussian mixture models (GMM) with a tempo-spatial topological graph (TSTG). A flexible object model is incrementally updated in the pro-posed tracking framework, where each RGB-D point is identified to be involved in each object at each time step. Furthermore, the proposed method allows the creation of robust temporal associations among multiple updated objects during split, complete occlusion, partial occlusion, and multiple contacts dynamic interaction cases. The performance of the method was examined in terms of the tracking accuracy and computational efficiency by various experiments, achieving over 97% accuracy with five frames per second computation time. The limitations of the method were also empirically investigated in terms of the size of the points and the movement speed of objects. Crown Copyright (C) 2013 Published by Elsevier Inc. All rights reserved.
C1 [Koo, Seongyong; Kwon, Dong-Soo] Korea Adv Inst Sci & Technol, Dept Mech Engn, Human Robot Interact Res Ctr, Taejon, South Korea.
   [Lee, Dongheui] Tech Univ Munich, Dept Elect Engn & Informat Technol, D-80290 Munich, Germany.
C3 Korea Advanced Institute of Science & Technology (KAIST); Technical
   University of Munich
RP Kwon, DS (corresponding author), Korea Adv Inst Sci & Technol, Dept Mech Engn, Human Robot Interact Res Ctr, Taejon, South Korea.
EM kwonds@kaist.ac.kr
RI Kwon, Dong-Soo/C-1540-2011
FU DFG excellence initiative research cluster "Cognition for Technical
   System-CoTeSys"; Industrial Strategic Technology Development Program
   [10044009]; Ministry of Knowledge Economy(MKE), Korea
FX This work was supported in part within the DFG excellence initiative
   research cluster "Cognition for Technical System-CoTeSys", and
   financially supported by the Industrial Strategic Technology Development
   Program (10044009, Development of a self-improving bidirectional
   sustainable HRI technology) funded by the Ministry of Knowledge
   Economy(MKE), Korea.
CR Aksoy EE, 2011, INT J ROBOT RES, V30, P1229, DOI 10.1177/0278364911410459
   Anderson B., 1979, OPTIMAL FILTERING, V11
   Bar-Yosef Y, 2011, INT CONF ACOUST SPEE, P2240
   Basu A, 1998, BIOMETRIKA, V85, P549, DOI 10.1093/biomet/85.3.549
   Bilmes J., 1998, GENTLE TUTORIAL EM A
   Blodow N, 2011, IEEE INT C INT ROBOT, P4263, DOI 10.1109/IROS.2011.6048540
   Chang L, 2012, IEEE INT CONF ROBOT, P3875, DOI 10.1109/ICRA.2012.6224575
   Chui HL, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P190, DOI 10.1109/MMBIA.2000.852377
   Dantam N, 2012, IEEE INT C INT ROBOT, P237, DOI 10.1109/IROS.2012.6385749
   Davide M., 2009, THESIS U STUDI VERON
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dindo Haris, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P4452, DOI 10.1109/IROS.2010.5654298
   Fitzpatrick P, 2003, PHILOS T R SOC A, V361, P2165, DOI 10.1098/rsta.2003.1251
   Garcia V., 2010, IEEE INT C AC SPEECH
   Goldberger J., 2005, P ADV NEUR INF PROC, P505
   Goldberger J, 2008, IEEE T PATTERN ANAL, V30, P1496, DOI 10.1109/TPAMI.2008.100
   GREENGARD L., 1998, Doc. Math., V3, P575
   Grigorescu S., 2012, IEEE RSJ INT C INT R
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Jiang Y, 2012, INT J ROBOT RES, V31, P1021, DOI 10.1177/0278364912438781
   Knoop S, 2006, IEEE INT CONF ROBOT, P1686
   Krainin M, 2011, INT J ROBOT RES, V30, P1311, DOI 10.1177/0278364911403178
   Lau B, 2010, INT J SOC ROBOT, V2, P19, DOI 10.1007/s12369-009-0036-0
   Liu ZY, 2011, IEEE INT C INT ROBOT, P3626, DOI 10.1109/IROS.2011.6048338
   Luber M, 2011, IEEE INT C INT ROBOT, P3844, DOI 10.1109/IROS.2011.6048836
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Montesano L, 2008, IEEE T ROBOT, V24, P15, DOI 10.1109/TRO.2007.914848
   NIELSEN F, 2009, 17 EUR C SIGN PROC E
   Prankl J, 2011, IEEE INT CONF ROBOT, P1784
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusu RB, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1, DOI 10.1109/IROS.2009.5354683
   Schnabel R, 2007, COMPUT GRAPH FORUM, V26, P214, DOI 10.1111/j.1467-8659.2007.01016.x
   Schulz D, 2003, INT J ROBOT RES, V22, P99, DOI 10.1177/0278364903022002002
   Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Teh Y. W., 2010, BAYESIAN NONPARAMETR, V1, P158, DOI 10.1017/CBO9780511802478.006
   Tsin Y, 2004, LECT NOTES COMPUT SC, V3023, P558
   Ueda R., POINT CLOUDS LIB TRA
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Zhang K, 2010, IEEE T NEURAL NETWOR, V21, P644, DOI 10.1109/TNN.2010.2040835
   Zhang L., 2010, IEEE RSJ INT C INT R
NR 42
TC 11
Z9 11
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 108
EP 121
DI 10.1016/j.jvcir.2013.03.020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900011
DA 2024-07-18
ER

PT J
AU Xu, LF
   Li, HL
   Zeng, LY
   Ngan, KN
AF Xu, Linfeng
   Li, Hongliang
   Zeng, Liaoyuan
   King Ngi Ngan
TI Saliency detection using joint spatial-color constraint and multi-scale
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual attention; Saliency model; Region detection; Human fixation
   prediction; Spatial constraint; Color double-opponent; Similarity
   distribution; Multi-scale technique; Segmentation-based method
ID VISUAL-ATTENTION; VIDEO; EXTRACTION; MODEL
AB In this paper, a novel method is proposed to detect salient regions in images. To measure pixel-level saliency, joint spatial-color constraint is defined, i.e., spatial constraint (SC), color double-opponent (CD) constraint and similarity distribution (SD) constraint. The SC constraint is designed to produce global contrast with ability to distinguish the difference between "center and surround". The CD constraint is introduced to extract intensive contrast of red-green and blue-yellow double opponency. The SD constraint is developed to detect the salient object and its background. A two-layer structure is adopted to merge the SC, CD and SD saliency into a saliency map. In order to obtain a consistent saliency map, the region-based saliency detection is performed by incorporating a multi-scale segmentation technique. The proposed method is evaluated on two image datasets. Experimental results show that the proposed method outperforms the state-of-the-art methods on salient region detection as well as human fixation prediction. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Xu, Linfeng; Li, Hongliang; Zeng, Liaoyuan] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
   [King Ngi Ngan] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 University of Electronic Science & Technology of China; Chinese
   University of Hong Kong
RP Li, HL (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM lfxu@uestc.edu.cn; hlli@uestc.edu.cn
RI Ngan, N/E-8240-2014; Xu, Linfeng/HME-1913-2023
OI Ngan, N/0000-0003-1946-3235; Xu, Linfeng/0000-0002-9934-0958
FU NSFC [61271289, 61179060]; National High Technology Research and
   Development Program of China (863 Program) [2012AA011503]; Ph.D.
   Programs Foundation of Ministry of Education of China [20110185110002]
FX This work was partially supported by NSFC (No. 61271289 and 61179060),
   National High Technology Research and Development Program of China (863
   Program, no. 2012AA011503), and The Ph.D. Programs Foundation of
   Ministry of Education of China (No. 20110185110002).
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Chen ZZ, 2006, IEEE T MULTIMEDIA, V8, P1117, DOI 10.1109/TMM.2006.884633
   DESIMONE R, 1995, ANNU REV NEUROSCI, V18, P193, DOI 10.1146/annurev-psych-122414-033400
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feng J, 2011, IEEE I CONF COMP VIS, P1028, DOI 10.1109/ICCV.2011.6126348
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guttmann M, 2011, COMPUT VIS IMAGE UND, V115, P1662, DOI 10.1016/j.cviu.2011.05.010
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti, 2007, Scholarpedia, V2, P3327, DOI DOI 10.4249/SCHOLARPEDIA.3327
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   James William., 1950, The Principles of Psychology, V2
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2013, SIGNAL PROCESS-IMAGE, V28, P55, DOI 10.1016/j.image.2012.10.004
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li HL, 2011, IEEE T CIRC SYST VID, V21, P1571, DOI 10.1109/TCSVT.2011.2129150
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   MAHADEVAN V, 2010, PROC CVPR IEEE, P1975, DOI DOI 10.1109/CVPR.2010.5539872
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Mirmehdi M, 2002, J VIS COMMUN IMAGE R, V13, P460, DOI 10.1006/jvci.2002.0506
   Muratov O, 2011, INT CONF ACOUST SPEE, P1217
   Niebur E, 1998, ATTENTIVE BRAIN, P163
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Setlur V, 2007, IEEE COMPUT GRAPH, V27, P80, DOI 10.1109/MCG.2007.133
   Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P496, DOI 10.1109/TCSVT.2005.844458
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang QA, 2010, J VIS COMMUN IMAGE R, V21, P453, DOI 10.1016/j.jvcir.2009.09.005
NR 44
TC 31
Z9 39
U1 0
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 465
EP 476
DI 10.1016/j.jvcir.2013.02.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400004
DA 2024-07-18
ER

PT J
AU Lee, WY
   Hsieh, LC
   Wu, GL
   Hsu, W
AF Lee, Wen-Yu
   Hsieh, Liang-Chi
   Wu, Guan-Long
   Hsu, Winston
TI Graph-based semi-supervised learning with multi-modality propagation for
   large-scale image datasets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; MapReduce; Semi-supervised learning; Large-scale data;
   Multi-label; Image annotation; Landmark retrieval; Distributed computing
AB Semi-supervised learning (SSL) is widely-used to explore the vast amount of unlabeled data in the world. Over the decade, graph-based SSL becomes popular in automatic image annotation due to its power of learning globally based on local similarity. However, recent studies have shown that the emergence of large-scale datasets challenges traditional methods. On the other hand, most previous works have concentrated on single-label annotation, which may not describe image contents well. To remedy the deficiencies, this paper proposes a new graph-based SSL technique with multi-label propagation, leveraging the distributed computing power of the MapReduce programming model. For high learning performance, the paper further presents both a multi-layer learning structure and a tag refinement approach, where the former unifies both visual and textual information of image data during learning, while the latter simultaneously suppresses noisy tags and emphasizes the other tags after learning. Experimental results based on a medium-scale and a large-scale image datasets show the effectiveness of the proposed methods. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Lee, Wen-Yu; Hsieh, Liang-Chi; Wu, Guan-Long; Hsu, Winston] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
   [Hsu, Winston] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10617, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Hsu, W (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
EM majorrei@cmlab.csie.ntu.edu.tw; viirya@gmail.com;
   garywgl@csie.ntu.edu.tw; winston@csie.ntu.edu.tw
CR [Anonymous], 2010, P ACM MULTIMEDIA
   [Anonymous], P INT C MULT RETR
   Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900
   Cormen T.H., 2009, ALL PAIRS SHORTEST P, V3rd, P684
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Elsayed T., 2008, P 46 ANN M ASS COMPU, P265, DOI DOI 10.3115/1557690.1557767
   Hanghang Tong, 2005, 13th Annual ACM International Conference on Multimedia, P862, DOI 10.1145/1101149.1101337
   He J., P 12 ANN ACM INT C M, P9, DOI 10.1145/1027527.1027531
   Jebara T., 2009, P 26 ANN INT C MACH, P441
   Kang U, 2011, KNOWL INF SYST, V27, P303, DOI 10.1007/s10115-010-0305-0
   Kuo Yin-Hsi., 2009, ACM Multimedia, P65
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Lee WY, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1121
   Lin J, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P155, DOI 10.1145/1571941.1571970
   Liu W., 2010, PROC ICML, P679
   Liu Y, 2009, IEEE T CIRC SYST VID, V19, P1841, DOI 10.1109/TCSVT.2009.2026951
   Luo W, 2012, IEEE GEOSCI REMOTE S, V9, P634, DOI 10.1109/LGRS.2011.2177064
   Misra S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/47245
   Pan J-Y, 2004, P 10 ACM SIGKDD INT, P653, DOI DOI 10.1145/1014052.1014135
   Rao D., 2009, Proc. Workshop Graph-Based Methods Natural Language Process, P58
   Talukdar P.P., 2009, Topics in graph construction for semi-supervised learning
   Wang M., 2007, ACM Multi- media, P862
   Wu F., 2010, Proceedings of the International Conference on Multimedia (MM'10), P15, DOI DOI 10.1145/1873951.1873957
   Yang Y.H., 2008, ACM International Conference on Multimedia (MM), P199
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X., 2006, THESIS CARNEGIE MELL
   Zhu X., 2008, SEMISUPERVIED LEARNI
NR 27
TC 12
Z9 13
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 295
EP 302
DI 10.1016/j.jvcir.2012.12.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Weber, J
   Lefèvre, S
AF Weber, Jonathan
   Lefevre, Sebastien
TI Fast quasi-flat zones filtering using area threshold and region merging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quasi-flat zones; Mathematical Morphology; Quasi-flat zones filtering;
   Image segmentation; Image simplification; Interactive segmentation;
   Video segmentation; Oversegmentation reduction
ID CONSTRAINED CONNECTIVITY
AB Quasi-flat zones are morphological operators which segment the image into homogeneous regions according to certain criteria. They are used as an image simplification tool or an image segmentation pre-processing, but they induced a very important oversegmentation. Several filtering methods have been proposed to deal with this issue but they suffer from different drawbacks, e.g., loss of quality or edge deformation. In this article, we propose a new method based on existing approaches which achieves better or similar results than existing approaches, does not suffer from their drawbacks and requires less computation time. It consists of two successive steps. First, small quasi-flat zones are removed according to a minimal area threshold. They are then filled through the growth of remaining zones. (c) 2013 Elsevier Inc. All rights reserved.
RP Weber, J (corresponding author), LORIA Nancy, Campus Sci BP 239, F-54506 Vandoeuvre Les Nancy, France.
EM jonathan.weber@loria.fr; sebastien.lefevre@univ-ubs.fr
RI Weber, Jonathan/S-4449-2019; Lefevre, Sebastien/S-9444-2017
OI Weber, Jonathan/0000-0002-3694-4703; Lefevre,
   Sebastien/0000-0002-2384-8202
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Angulo J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P125
   ANGULO J, 2003, THESIS ECOLE MINES P
   Brunner D, 2007, IMAGE VISION COMPUT, V25, P1352, DOI 10.1016/j.imavis.2006.09.002
   Carleer AP, 2005, PHOTOGRAMM ENG REM S, V71, P1285, DOI 10.14358/PERS.71.11.1285
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Derivaux S, 2010, PATTERN RECOGN LETT, V31, P2364, DOI 10.1016/j.patrec.2010.07.007
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Rivest J.-F., 1992, Journal of Electronic Imaging, V1, P136, DOI 10.1117/12.55184
   SERRA J, 1993, P SOC PHOTO-OPT INS, V2030, P65, DOI 10.1117/12.146672
   Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817
   Soille P, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P487, DOI 10.1109/ICIAP.2007.4362825
   Soille P, 2010, INT J REMOTE SENS, V31, P5879, DOI 10.1080/01431161.2010.512622
   Soille P, 2009, LECT NOTES COMPUT SC, V5720, P59, DOI 10.1007/978-3-642-03613-2_6
   Weber J, 2011, LECT NOTES COMPUT SC, V6671, P178, DOI 10.1007/978-3-642-21569-8_16
   Weber J, 2011, INT SYMP IMAGE SIG, P265
   ZANOGUERA F, 2001, THESIS ECOLE MINES P
NR 17
TC 8
Z9 8
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 397
EP 409
DI 10.1016/j.jvcir.2013.01.011
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zonoobi, D
   Kassim, AA
AF Zonoobi, Dornoosh
   Kassim, Ashraf A.
TI On the reconstruction of sequences of sparse signals - The Weighted-CS
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Compressive sampling; Weighted l(1) minimization;
   Probability model; Sequential CS; Priori knowledge; Time-varying
   signals; Medical image reconstruction
ID MINIMIZATION
AB In this paper, we study the problem of recursively reconstructing time sequences of sparse signals, where sparsity changes smoothly with time. The idea is to use the signal/image of the previous time instance to extract an estimated probability model for the signal/image of interest, and then use this model to guide the reconstruction process. We examine and illustrate the performance of our approach, "Weighted-CS", with both synthetic and real medical signals/images. It is shown that we can achieve significant performance improvement, using fewer number of samples, compared to other state-of-art Compressive Sensing methods. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zonoobi, Dornoosh; Kassim, Ashraf A.] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.
C3 National University of Singapore
RP Zonoobi, D (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.
EM dornoosh@nus.edu.sg; ashraf@nus.edu.sg
OI Kassim, Ashraf/0000-0001-7435-8564; Zonoobi,
   Dornoosh/0000-0003-1907-4571
CR [Anonymous], MIT BIH DAT DISTR
   Asif MS, 2009, 2009 43RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1 AND 2, P3, DOI 10.1109/CISS.2009.5054679
   Becker S., 2009, NESTA FAST ACCURATE
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chartrand R, 2007, IEEE SIGNAL PROC LET, V14, P707, DOI 10.1109/LSP.2007.898300
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4595, DOI 10.1109/TSP.2010.2051150
   Venkatesh YV, 2010, IEEE IMAGE PROC, P3369, DOI 10.1109/ICIP.2010.5652720
   Zhang Y., 2008, TR0811 CAAM RIC U
   Zonoobi D, 2011, IEEE J-STSP, V5, P927, DOI 10.1109/JSTSP.2011.2160711
NR 13
TC 10
Z9 14
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 196
EP 202
DI 10.1016/j.jvcir.2012.05.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000013
DA 2024-07-18
ER

PT J
AU El-ghazal, A
   Basir, O
   Belkasim, S
AF El-ghazal, A.
   Basir, O.
   Belkasim, S.
TI Invariant curvature-based Fourier shape descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fourier descriptors; Feature extraction; Curvature-scale space;
   Content-based image retrieval; Shape matching; Invariant descriptors;
   Shape retrieval; Shape signature
ID PATTERN-RECOGNITION; GENERIC FOURIER; IMAGE-ANALYSIS; SCALE-SPACE;
   RETRIEVAL; REPRESENTATION; DISCRIMINATION; ROTATION; OBJECTS
AB Shape descriptors have demonstrated encouraging potential for retrieving images based on image content, and a number of them have been reported in the literature. Nevertheless, most of the reported descriptors are still face accuracy and computational challenges. Fourier descriptors are considered to be promising descriptors as they are based on a sound theoretical foundation and also have the advantages of computational efficiency and attractive invariance properties. This paper proposes a new curvature-based Fourier descriptor (CBFD) for shape retrieval. The proposed descriptor takes an unconventional view of the curvature-scale-space representation of a shape contour as it treats it as a 2-D binary image (hence referred to as curvature-scale image, or CSI). The invariant descriptor is derived from the 2-D Fourier transform of the curvature-scale image. This method allows the descriptor to capture the detailed dynamics of the shape curvature and enhance the efficiency of the shape-matching process. Experiments using the widely known MPEG-7 databases in conjunction with a created noisy database have been conducted in order to compare the performance of the proposed descriptor with six commonly used shape-retrieval descriptors: curvature-scale-space descriptor (CSSD), angular radial transform descriptors (ARTD), Zernike moment descriptors (ZMD), radial Tchebichef moment descriptors (RTMD), generic Fourier descriptor (GFD), and the 1-D Fourier descriptor (1-FD). The performance of the proposed descriptor has surpassed that of many of these notable descriptors. (c) 2012 Elsevier Inc. All rights reserved.
C1 [El-ghazal, A.; Basir, O.] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON NSL 3G1, Canada.
   [Belkasim, S.] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30303 USA.
C3 University of Waterloo; University System of Georgia; Georgia State
   University
RP El-ghazal, A (corresponding author), Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON NSL 3G1, Canada.
EM aelghaza@engmail.uwaterloo.ca; obasir@uwaterloo.ca; sbelkasim@cs.gsu.edu
RI Basir, Otman/ISU-4477-2023
OI Basir, Otman/0000-0002-6454-0538
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Abbasi S, 2000, IMAGE VISION COMPUT, V18, P199, DOI 10.1016/S0262-8856(99)00019-0
   Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   [Anonymous], P IEEE ITN C MULT EX
   [Anonymous], P ICIVR
   [Anonymous], GEOMETRIC METHODS CO
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Arbter K., 1989, PIXELS FEATURE
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   CASASENT D, 1976, APPL OPTICS, V15, P1795, DOI 10.1364/AO.15.001795
   Celebi ME, 2005, ITCC 2005: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, P788, DOI 10.1109/ITCC.2005.3
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   DUBOIS SR, 1986, IEEE T PATTERN ANAL, V8, P55, DOI 10.1109/TPAMI.1986.4767752
   EICHMANN G, 1990, P SOC PHOTO-OPT INS, V1297, P86, DOI 10.1117/12.21302
   El Oirrak A, 2002, PATTERN RECOGN LETT, V23, P1109, DOI 10.1016/S0167-8655(02)00027-2
   El-ghazal A., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P161
   El-ghazal A, 2008, IEEE IMAGE PROC, P953, DOI 10.1109/ICIP.2008.4711914
   El-Ghazal A, 2009, SIGNAL PROCESS-IMAGE, V24, P572, DOI 10.1016/j.image.2009.04.001
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   GOSHTASBY A, 1985, IEEE T PATTERN ANAL, V7, P738, DOI 10.1109/TPAMI.1985.4767734
   Hirata K., 1992, 3 INT C EXT DAT TECH, P56
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jan S., 2007, P 6 ACM INT C IM VID
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kunttu I, 2007, IET IMAGE PROCESS, V1, P231, DOI 10.1049/iet-ipr:20060113
   Kunttu I, 2006, PATTERN RECOGN LETT, V27, P123, DOI 10.1016/j.patrec.2005.08.022
   Latecki L. J., 2000, IEEE C COMP VIS PATT
   Latecki LJ, 2005, IMAGE VISION COMPUT, V23, P227, DOI 10.1016/j.imavis.2004.06.015
   Li S, 2005, J AM SOC INF SCI TEC, V56, P729, DOI 10.1002/asi.20163
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Lu GJ, 1999, MULTIMEDIA SYST, V7, P165, DOI 10.1007/s005300050119
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R., 2005, IEEE TENCON C, P2098
   PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   Schomaker L., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P585
   Sun JD, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P139
   Tao Y., 1999, 7SPIE S STORAGE RETR, P631
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   van Leuken Reinier H., 2008, Proceedings of the Fifth IASTED International Conference on Signal Processing, Pattern Recognition, and Applications, P93
   WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Yadav RB, 2007, OPT LASER ENG, V45, P695, DOI 10.1016/j.optlaseng.2006.11.001
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
   Zhang DS, 2003, J VIS COMMUN IMAGE R, V14, P41, DOI 10.1016/S1047-3203(03)00003-8
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 56
TC 31
Z9 45
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 622
EP 633
DI 10.1016/j.jvcir.2012.01.011
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500004
DA 2024-07-18
ER

PT J
AU Wang, YF
   Chen, JW
   He, Y
AF Wang, Yunfei
   Chen, Jianwen
   He, Yun
TI A pixel-wise directional intra prediction method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Intra coding; Directional intra prediction; Pixel-wise;
   H.264/AVC; DCT; RDOQ; PDIP
AB In a decade where the prominence of video applications has become increasingly prevalent, the optimization of video coding processes remains as important as ever. The directional intra prediction has been proved as an effective tool for intra picture coding. However, in a directional intra prediction based coding structure, there is a considerable gap between the transform efficiency of DCT and the optimal transform KLT. In this paper, we analyze these problems and propose a pixel-wise directional intra prediction (PDIP) method to solve this problem. This method exploits the reconstruction value of the adjacent pixels to predict the current pixel, and keeps the block-based lossy coding structure of H.264/AVC. The proposed method can significantly improve the coding efficiency with little decoding complexity increment. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Wang, Yunfei; Chen, Jianwen; He, Yun] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Microwave & Digital Commun, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, YF (corresponding author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, State Key Lab Microwave & Digital Commun, Beijing 100084, Peoples R China.
EM wangyf038@mails.tsinghua.edu.cn; jwchen@ee.ucla.edu; hey@tsinghua.edu.cn
RI chen, jw/IQW-1558-2023; he, yun/JMB-6362-2023
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   [Anonymous], 2003, ITU T RECOMMENDATION
   [Anonymous], 1995, ITU T RECOMMENDATION
   Bjontegaard G., 2001, Q6SG16 ITUT VCEG
   Chen Q., 2004, P PCS 2004 SAN FRANC
   Cohen Robert, 2010, JOINT COLL TEAM VID
   Crouse M., 1995, Proceedings. DCC '95 Data Compression Conference (Cat. No.95TH8037), P342, DOI 10.1109/DCC.1995.515524
   Karczewicz M., 2008, Q6SG16 ITUT VCEG
   Karczewicz M., 2007, Q6SG16 ITUT VCEG
   Kwon SK, 2006, J VIS COMMUN IMAGE R, V17, P186, DOI 10.1016/j.jvcir.2005.05.010
   Lee YL, 2006, IEEE T IMAGE PROCESS, V15, P2610, DOI 10.1109/TIP.2006.877396
   Lin C.-C. Weisi, 2011, J VIS COMMUN IMAGE R, V22, P297
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   Yang EH, 2009, IEEE T CIRC SYST VID, V19, P122, DOI 10.1109/TCSVT.2008.2009260
   Ye Yan, 2008, P ICIP OCT
NR 15
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 599
EP 603
DI 10.1016/j.jvcir.2012.02.004
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500001
DA 2024-07-18
ER

PT J
AU Chen, DY
   Luo, YS
AF Chen, Duan-Yu
   Luo, Yi-Shiou
TI Content-aware video resizing based on salient visual cubes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Seam carving; Visual cubes; Spatiotemporal analysis; Visual attention;
   Video resizing; Content aware; Visual continuity; Video dynamics
ID ATTENTION; SEARCH; MODEL
AB State of the art methods for video resizing usually produce perceivable visual discontinuities. Therefore, how to preserve the visual continuity in video frames is one of the most critical issues. In this paper, we propose a novel approach for modeling dynamic visual attention based on spatiotemporal analysis in order to detect the focus of interest automatically. The continuously varied co-sited blocks in a video cube are first detected and their variations are characterized as visual cubes, which are further employed to determine a proper extent of salient regions in video frames. Once the proper extent through video cubes is determined, the resizing process then can be conducted to find the global optimum. Our experiment shows that the proposed content-aware video resizing based on spatiotemporal visual cubes can effectively generate resized videos while keeping their isotropic manipulation and the continuous dynamics of visual perception. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Chen, Duan-Yu; Luo, Yi-Shiou] Yuan Ze Univ, Dept Elect Engn, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Chen, DY (corresponding author), Yuan Ze Univ, Dept Elect Engn, Tao Yuan, Taiwan.
EM dychen@saturn.yzu.edu.tw; s984629@mail.yzu.edu.tw
CR [Anonymous], P 11 IEEE INT C COMP
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2006, P 14 ACM INT C MULT
   [Anonymous], 2007, P IEEE C COMP VIS PA
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chen B., 2008, P EUR
   Chen DY, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1085, DOI 10.1109/ICME.2008.4607627
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HUA G, 2009, P 9 AS C COMP VIS AC
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   James W., 1890, The Principles of Psychology, V1
   Ke Y., 2007, P IEEE INT C COMP VI
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Li S, 2007, IEEE T CIRC SYST VID, V17, P1383, DOI 10.1109/TCSVT.2007.903798
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Navalpakkam V., 2006, P IEEE C COMPUTER VI, P2049
   PAL NR, 1991, IEEE T SYST MAN CYB, V21, P1260, DOI 10.1109/21.120079
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Wu HS, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866185
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang X., 2010, P IEEE C COMP VIS PA
   Zhang YF, 2008, COMPUT GRAPH FORUM, V27, P1797, DOI 10.1111/j.1467-8659.2008.01325.x
NR 26
TC 4
Z9 7
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 226
EP 236
DI 10.1016/j.jvcir.2010.12.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300003
DA 2024-07-18
ER

PT J
AU Lai, JH
   Chen, CL
   Kao, CC
   Chien, SY
AF Lai, Jui-Hsin
   Chen, Chieh-Li
   Kao, Chieh-Chi
   Chien, Shao-Yi
TI Tennis Video 2.0: A new presentation of sports videos with content
   separation and rendering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive video; Video analysis; Video enrichment; Video rendering;
   Event search; Scalable video; Video annotation; Object segmentation;
   Sprite; Matting
ID BALL TRACKING; SOCCER VIDEO
AB This paper proposes a new method for presenting sports videos. Tennis videos are used as an example for the implementation of a viewing program called as Tennis Video 2.0. For the methods in video analysis, background generation by considering the pixels in temporal and spatial distribution is proposed; foreground segmentation combining automatic trimap generation and matting model is proposed. To provide more functions in watching videos, the rendering flow of video contents and the semantic Scalability are proposed. With the new analysis and rendering tools, the presentation of sports videos has three properties-Structure, Interactivity, and Scalability. The experiments show that several broadcasting game videos are employed to evaluate the robustness and performance of the proposed system. For user study, 20 evaluators highly identify that Tennis Video 2.0 is a new presentation of sports videos and give people better viewing experience. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chien, Shao-Yi] Natl Taiwan Univ, Grad Inst Elect Engn, Media IC & Syst Lab, Taipei 106, Taiwan.
   Natl Taiwan Univ, Dept Elect Engn, Taipei 106, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Chien, SY (corresponding author), Natl Taiwan Univ, Grad Inst Elect Engn, Media IC & Syst Lab, BL 421,1,Sec 4,Roosevelt Rd, Taipei 106, Taiwan.
EM juihsin.lai@gmail.com; chiehli.chen@gmail.com; chiehchi.kao@gmail.com;
   sychien@cc.ee.ntu.edu.tw
OI Chien, Shao-Yi/0000-0002-0634-6294
CR [Anonymous], P 11 ACM INT C MULT
   [Anonymous], 2003, ADV VID COD GEN AUD
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Brown M., 2003, P 9 IEEE INT C COMP
   Cai R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P37
   Chang CH, 2010, J VIS COMMUN IMAGE R, V21, P595, DOI 10.1016/j.jvcir.2010.03.006
   Chen CY, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P337
   Chen HT, 2008, J INF SCI ENG, V24, P143
   Chen HT, 2007, INT CONF ACOUST SPEE, P1097
   Chen HT, 2009, J VIS COMMUN IMAGE R, V20, P204, DOI 10.1016/j.jvcir.2008.11.008
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   Chuang YY, 2001, PROC CVPR IEEE, P264
   CHUANG YY, 2002, ACM SIGGRAPH 2002
   Farin D, 2006, IEEE T CIRC SYST VID, V16, P492, DOI 10.1109/TCSVT.2006.872781
   HAN J, 2008, IEEE T CIRCUITS SYST, P1628
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   HUNG MH, 2008, IEEE T CIRCUITS SYST, P1713
   Inamoto N., 2004, Proceedings of ACM ACE, V74, P42
   *ITU, 1993, REC JPEG STAND
   Jui-Hsin Lai, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P676, DOI 10.1109/MMSP.2008.4665161
   Kokaram A, 2006, IEEE SIGNAL PROC MAG, V23, P47, DOI 10.1109/MSP.2006.1621448
   Kolonias I, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P154
   LAI JH, 2008, P IEEE INT WORKSH MU, P672
   Liang DW, 2007, IEEE T CONSUM ELECTR, V53, P1138, DOI 10.1109/TCE.2007.4341597
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2003, IEEE T CIRC SYST VID, V13, P394, DOI 10.1109/TCSVT.2003.811607
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   REA N, 2005, P IEEE INT C IM PROC, V3, P1204
   Smolic A, 1999, IEEE T CIRC SYST VID, V9, P1227, DOI 10.1109/76.809158
   TANG Q, 2005, P 13 ANN ACM INT C M
   Tien M. C., 2009, P 17 ACM INT C MULT, P1133
   Tien MC, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1477, DOI 10.1109/ICME.2008.4607725
   Wang J., 2004, P 12 ANN ACM INT C M, P32
   WIKSTRAND G, 2002, P 2 NORD C HUM COMP, P255
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu X., 2006, Proceedings of ACM Multimedia, P619
   Zhang D., 2002, ACM Multimedia, P315
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 39
TC 10
Z9 12
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 271
EP 283
DI 10.1016/j.jvcir.2011.01.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300007
DA 2024-07-18
ER

PT J
AU Lee, SH
   Lee, SH
   Yang, JH
   Cho, NI
AF Lee, Sang Heon
   Lee, Sang Hwa
   Yang, Jeong Hyu
   Cho, Nam Ik
TI A motion vector prediction method for multi-view video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view video coding; Motion vector prediction; Disparity vector
   prediction; Inter-view prediction; JMVM; View-temporal prediction;
   Probability of inter-view prediction; Magnitude of MV prediction
   residual
ID COMPENSATION; ILLUMINATION
AB This paper proposes a new motion vector (MV) prediction method in multi-view video coding (MVC). In order to exploit the information in adjacent views, inter-view MVs as well as temporal MVs are used in conventional MVC. Since the inter-view MVs are usually uncorrelated with the temporal MVs and most neighboring partitions have temporal MVs only, the conventional DPCM coding gain of inter-view MV is very low and thus the inter-view MVs are seldom selected. In order to increase the probability of interview MV selection, we define a virtual inter-view MV which can be generated from temporal MVs. Then, an inter-view MV is predicted using these neighboring virtual inter-view MVs, leading to less prediction error than using the temporal MVs. As a result, bit-rates are decreased by up to 9% for the view-temporal prediction structure. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lee, Sang Heon; Lee, Sang Hwa; Cho, Nam Ik] Seoul Natl Univ, Inst New Media & Commun, San 56-1, Shilim Dong, Gwanak Gu, South Korea.
   [Yang, Jeong Hyu] LG Elect DTV Lab, Gwanak Gu, South Korea.
C3 Seoul National University (SNU)
RP Lee, SH (corresponding author), Seoul Natl Univ, Inst New Media & Commun, San 56-1, Shilim Dong, Gwanak Gu, South Korea.
EM leesh007@ispl.snu.ac.kr; lsh@ipl.snu.ac.kr; jayu@lge.com;
   nicho@snu.ac.kr
RI Cho, Nam Ik/I-5029-2014
OI cho, nam ik/0000-0001-5297-4649
FU MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center) [NIPA-2010-(C1090-1011-0003)]
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   support program supervised by the NIPA (National IT Industry Promotion
   Agency) (NIPA-2010-(C1090-1011-0003)).
CR BJONTEGAARD G, 2001, ITUTVCEGVCEGM33
   Chung T, 2008, IEEE IMAGE PROC, P2440, DOI 10.1109/ICIP.2008.4712286
   Fecker U, 2008, IEEE T CIRC SYST VID, V18, P1258, DOI 10.1109/TCSVT.2008.926997
   Hur JH, 2007, IEEE T CIRC SYST VID, V17, P1496, DOI 10.1109/TCSVT.2007.903774
   *ISO IEC, 2005, ISOIECJTC1SC29WG11
   *ISO IEC JTC, 2008, ISOIECJTC1SC29WG11
   *ITU T, 2005, 1499610 ITUT ISOIEC
   Kim JH, 2007, IEEE T CIRC SYST VID, V17, P1519, DOI 10.1109/TCSVT.2007.909976
   Kitahara M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P97, DOI 10.1109/ICME.2006.262559
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   PANDIT P, 2007, ISOIECJTC1SC29WG11JV
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   SEHOON Y, 2007, IEEE P ICIP 2007, P209
   Smolic A, 2004, IEEE T CIRC SYST VID, V14, P348, DOI 10.1109/TCSVT.2004.823395
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
NR 17
TC 3
Z9 3
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 677
EP 681
DI 10.1016/j.jvcir.2010.04.006
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400007
DA 2024-07-18
ER

PT J
AU Biswas, A
   Bhowmick, P
   Bhattacharya, BB
AF Biswas, Arindam
   Bhowmick, Partha
   Bhattacharya, Bhargab B.
TI Construction of isothetic covers of a digital object: A combinatorial
   approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Connected component; Digital geometry; Digital object; Isothetic cover;
   Isothetic polygon; Image processing; Pattern recognition; Shape analysis
ID APPROXIMATIONS
AB An isothetic cover of a digital object not only specifies a simple representation of the object but also provides an approximate information about its structural content and geometric characteristics. When the cover "tightly" encloses the object, it is said to be an outer isothetic cover; and when the cover tightly inscribes the object, it is an inner isothetic cover. If a set of horizontal and vertical grid lines is imposed on the object plane, then the outer (inner) isothetic cover is defined by a set of isothetic polygons, having their edges lying on the grid lines, such that the effective area corresponding to the object is minimized (maximized). Increasing or decreasing the grid size, therefore, decreases or increases the complexity or the accuracy of the isothetic cover corresponding to a given object, which, in turn, extracts the object information at different resolutions. In this paper, a combinatorial algorithm is presented for varying grid sizes, which is free of any backtracking and can produce the isothetic cover of a connected component in a time linear in the length of the perimeter of the cover. The algorithm has also been extended for finding the isothetic covers of real-world digital objects having multiple components with or without holes. Experimental results that demonstrate applications of an isothetic cover to diverse problems of pattern analysis and computer vision, are reported for various data sets. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Biswas, Arindam] Bengal Engn & Sci Univ, Dept Informat Technol, Sibpur, India.
   [Bhowmick, Partha] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Bhattacharya, Bhargab B.] Indian Stat Inst, Adv Comp & Microelect Unit, Kolkata, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST);
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Statistical Institute; Indian
   Statistical Institute Kolkata
RP Biswas, A (corresponding author), Bengal Engn & Sci Univ, Dept Informat Technol, Sibpur, India.
EM abiswas@it.becs.ac.in
RI Bhattacharya, Bhargab/AAE-6130-2020; Biswas, Arindam/X-9730-2019
OI Biswas, Arindam/0000-0002-2141-0215
CR AKINDELE OT, 1933, P INT C DOC AN REC I, P341
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], 1982, Digital Picture Processing
   Antonacopoulos A, 2002, LECT NOTES COMPUT SC, V2423, P236
   Bemporad A, 2004, COMP GEOM-THEOR APPL, V27, P151, DOI 10.1016/S0925-7721(03)00048-8
   Bhowmick P, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P343
   Bhowmick P, 2005, LECT NOTES COMPUT SC, V3776, P407
   Bhowmick P., 2007, PROC INT C COMPUTING, P422
   Bhowmick P, 2006, LECT NOTES COMPUT SC, V4338, P299
   Biswas A, 2005, LECT NOTES ARTIF INT, V3801, P1057
   Biswas A, 2005, LECT NOTES COMPUT SC, V3540, P930
   Biswas A, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P356
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Freeman H., 1961, PROC NATL ELECT C, V17, P421
   Gatos B., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P559, DOI 10.1109/ICDAR.1999.791849
   Gatos B, 2000, INT C PATT RECOG, P492, DOI 10.1109/ICPR.2000.903591
   GATRELL LB, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P184, DOI 10.1109/ROBOT.1989.99987
   Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886
   Kamon Y., 1995, PROC IEEE INT C ROBO, P2470
   KLETTE R, 2004, M KAUFMANN SERIES CO
   Lengyel J., 1990, Computer Graphics, V24, P327, DOI 10.1145/97880.97915
   Liu MF, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P39
   Morales A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1711, DOI 10.1109/IRDS.2002.1044002
   Nandy SC, 2000, J ALGORITHMS, V37, P538, DOI 10.1006/jagm.2000.1092
   Pal SankarK., 2004, PATTERN RECOGN
   Pal SK, 2004, IEEE T KNOWL DATA EN, V16, P292, DOI 10.1109/TKDE.2003.1262181
   SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P260, DOI 10.1109/TC.1972.5008948
   SKLANSKY J, 1976, IEEE T SYST MAN CYB, V6, P637, DOI 10.1109/TSMC.1976.4309569
   SKLANSKY J, 1972, IEEE T COMPUT, VC 21, P1355, DOI 10.1109/T-C.1972.223507
   Sloboda F., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P488
   Tadrat J, 2007, IRI 2007: PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P227, DOI 10.1109/IRI.2007.4296625
   TOUSSAINT G, 1997, COURSE NOTES GRIDS C
   Yacoub S, 2005, PROC INT CONF DOC, P452, DOI 10.1109/ICDAR.2005.187
   Ye QX, 2007, J VIS COMMUN IMAGE R, V18, P504, DOI 10.1016/j.jvcir.2007.07.003
   Yin PY, 2006, J VIS COMMUN IMAGE R, V17, P1108, DOI 10.1016/j.jvcir.2006.04.004
   Zhu W, 2007, IEEE T KNOWL DATA EN, V19, P1131, DOI 10.1109/TKDE.2007.1044
NR 36
TC 28
Z9 32
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 295
EP 310
DI 10.1016/j.jvcir.2010.02.001
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800003
DA 2024-07-18
ER

PT J
AU Köse, K
   Çetin, AE
   Güdükbay, U
   Onural, L
AF Kose, Kivanc
   Cetin, A. Enis
   Gudukbay, Ugur
   Onural, Levent
TI 3D Model compression using Connectivity-Guided Adaptive Wavelet
   Transform built into 2D SPIHT
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SPIHT; Mesh compression; Adaptive wavelet transform; Projection; Image
   compression; Static mesh; Connectivity coding; Progressive mesh
   representation
ID IMAGE; SURFACES
AB Connectivity-Guided Adaptive Wavelet Transform based mesh compression framework is proposed. The transformation uses the connectivity information of the 3D model to exploit the inter-pixel correlations. Orthographic projection is used for converting the 3D mesh into a 2D image-like representation. The proposed conversion method does not change the connectivity among the vertices of the 3D model. There is a correlation between the pixels of the composed image due to the connectivity of the 3D mesh. The proposed wavelet transform uses an adaptive predictor that exploits the connectivity information of the 3D model. Known image compression tools cannot take advantage of the correlations between the samples. The wavelet transformed data is then encoded using a zero-tree wavelet based method. Since the encoder creates a hierarchical bitstream, the proposed technique is a progressive mesh compression technique. Experimental results show that the proposed method has a better rate distortion performance than MPEG-3DGC/MPEG-4 mesh coder. (C) 2009 Elsevier Inc. All tights reserved.
C1 [Kose, Kivanc; Cetin, A. Enis; Onural, Levent] Bilkent Univ, Dept Elect & Elect Engn, TR-06800 Ankara, Turkey.
   [Gudukbay, Ugur] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University; Ihsan Dogramaci Bilkent University
RP Köse, K (corresponding author), Bilkent Univ, Dept Elect & Elect Engn, TR-06800 Ankara, Turkey.
EM kkivanc@ee.bilkent.edu.tr; cetin@ee.bilkent.edu.tr;
   gudukbay@cs.bilkent.edu.tr; onural@ee.bilkent.edu.tr
RI Kose, Kivanc/AAG-8130-2019; Onural, Levent/KVY-6526-2024; Gudukbay,
   Ugur/F-1012-2011
OI Kose, Kivanc/0000-0003-3185-2639; Onural, Levent/0000-0003-2581-971X;
   Gudukbay, Ugur/0000-0003-2462-6959
FU European Commission [511568]
FX This work is supported by European Commission Sixth Framework Program
   with Grant No. 511568 (3DTV NoE). The Cow and Lamp models are courtesy
   of Viewpoint Data Laboratories, Inc. The Skeleton Hand model is courtesy
   of the Stereolithography Archive at Clemson University. The Horse model
   is courtesy of Cyberware, Inc. Homer Simpson and Nine-Handle Torus
   models are obtained from INRIA Gamma Team 3D Meshes Research database.
   Stanford Bunny, Happy Buddha and Dragon models are courtesy of the
   Stanford Computer Graphics Laboratory.
CR Alliez P, 2005, MATH VIS, P3, DOI 10.1007/3-540-26808-1_1
   Alliez P, 2001, COMPUT GRAPH FORUM, V20, pC480, DOI 10.1111/1467-8659.00541
   [Anonymous], DEFLATE COMPRESSED D
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Briceno H. M., 2003, ACM SIGGRAPH/Eurographics Symposium on Computer Animation, P136
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   GAILLY JL, 2009, GZIP COMPRESSION SOF
   Gerek ÖN, 2000, IEEE T IMAGE PROCESS, V9, P1649, DOI 10.1109/83.869176
   Gu XF, 2002, ACM T GRAPHIC, V21, P355
   GUILLEMOT C, 1991, INT CONF ACOUST SPEE, P2813, DOI 10.1109/ICASSP.1991.150987
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Khodakovsky A, 2000, COMP GRAPH, P271, DOI 10.1145/344779.344922
   KHODAKOVSKY A, 2000, P ACM SIGGRAPH, P95
   Köse K, 2007, 3DTV CONF, P185, DOI 10.1109/3DTV.2007.4379443
   Köse K, 2006, PROC SPIE, V6247, DOI 10.1117/12.666702
   Lounsbery M, 1997, ACM T GRAPHIC, V16, P34, DOI 10.1145/237748.237750
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Morán F, 2004, IEEE T CIRC SYST VID, V14, P937, DOI 10.1109/TCSVT.2004.830663
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   POPOVIC J, 1997, P SIGGRAPH 97, P217
   RAO SM, 1982, IEEE T ANTENN PROPAG, V30, P409, DOI 10.1109/TAP.1982.1142818
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   ROTE G, 1991, INFORM PROCESS LETT, V38, P123, DOI 10.1016/0020-0190(91)90233-8
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sander PedroV., 2002, EGRW 02, P87
   Sander PV, 2001, COMP GRAPH, P409, DOI 10.1145/383259.383307
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Smolic A, 2008, SIGNALS COMMUN TECHN, P239, DOI 10.1007/978-3-540-72532-9_8
   TAUBIN G, 1998, P SIGGRAPH 98, P123
   *VRML, 1997, 147721 ISOIEC VRML
   2000, JPEG FINAL COMMITT 1
NR 33
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 17
EP 28
DI 10.1016/j.jvcir.2009.09.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200003
DA 2024-07-18
ER

PT J
AU Song, T
   Lee, VS
   Chen, Q
   Rusinek, H
   Laine, AF
AF Song, Ting
   Lee, Vivian S.
   Chen, Qun
   Rusinek, Henry
   Laine, Andrew F.
TI An automated three-dimensional plus time registration framework for
   dynamic MR renography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MR renography; Dynamic MR; 3D plus time registration; Dynamic
   contrast-enhanced imaging; Wavelet representation; Anisotropic
   diffusion; Fourier-based registration; Automated respiratory motion
   correction; WRFT
ID KIDNEY
AB Dynamic contrast-enhanced 3D images of the kidneys, or 3D MR renography, has the potential for broad clinical applications, but suffers from respiratory motion that limits analysis and interpretation. Manual registration is prohibitively labor-intensive. In this paper, a fully automated technique, Wavelet Representation and the Fourier Transform (WRFT) method, that corrects for translation and rotation motion in 3D MR renography is presented. The method was composed by anisotropic denoising, wavelet-based feature extraction, and Fourier-based registration. This was first evaluated on a set of simulated MR renography images with defined degrees of kidney motion. The method was then tested on 24 clinical patient MR renography data sets. Results of clinical testing were compared with the results obtained using a mutual information registration method. Based on intrarenal time-intensity curves, our method showed robust and consistent agreement with the results of manually coregistered data sets. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Song, Ting; Laine, Andrew F.] Columbia Univ, Dept Biomed Engn, New York, NY 10027 USA.
   [Song, Ting; Lee, Vivian S.; Chen, Qun; Rusinek, Henry] NYU, Sch Med, Ctr Biomed Imaging, New York, NY 10016 USA.
C3 Columbia University; New York University
RP Song, T (corresponding author), 1001 Rockville Pike 506, Rockville, MD 20852 USA.
EM songting@gmail.com
RI Chen, Qun/HGD-0868-2022
CR [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   Boykov Y., 2001, MEDICAL IMAGE COMPUT, P1058
   de Priester JA, 2001, J MAGN RESON IMAGING, V14, P134, DOI 10.1002/jmri.1163
   Duan Q, 2004, P SOC PHOTO-OPT INS, V5373, P331, DOI 10.1117/12.535813
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Giele ELW, 2001, J MAGN RESON IMAGING, V14, P741, DOI 10.1002/jmri.10020
   Grattan-Smith JD, 2003, PEDIATR RADIOL, V33, P293, DOI 10.1007/s00247-003-0896-7
   Gupta SN, 2003, MAGNET RESON MED, V49, P506, DOI 10.1002/mrm.10394
   Jin Y., 2004, Biomedical Engineering, P1
   Kalifa M, 2003, IEEE T MED IMAGING, V22, P351, DOI 10.1109/TMI.2003.809691
   Lee VS, 2003, RADIOLOGY, V227, P289, DOI 10.1148/radiol.2271020383
   Montagnat J, 2003, PATTERN RECOGN LETT, V24, P815, DOI 10.1016/S0167-8655(02)00184-8
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   SHANNO DF, 1970, MATH COMPUT, V24, P647, DOI 10.2307/2004840
   Stone HS, 2003, J VIS COMMUN IMAGE R, V14, P114, DOI 10.1016/S1047-3203(03)00002-6
   Stone HS, 2001, IEEE T GEOSCI REMOTE, V39, P2235, DOI 10.1109/36.957286
   SUN Y, 2004, IEEE INT S BIOIM ISB
   SUN Y, 2004, IEEE INT S IM PROC I
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Yim PJ, 2001, COMP MED SY, P516, DOI 10.1109/CBMS.2001.941771
   Ying S, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING, PROCEEDINGS, P98, DOI 10.1109/ISBI.2002.1029202
   Yuksel SE, 2005, INT CONGR SER, V1281, P773, DOI 10.1016/j.ics.2005.03.146
NR 22
TC 7
Z9 8
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 1
EP 8
DI 10.1016/j.jvcir.2009.09.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200001
DA 2024-07-18
ER

PT J
AU Han, PY
   Jin, ATB
   Abas, FS
AF Han, Pang Ying
   Jin, Andrew Teoh Beng
   Abas, Fazly Salleh
TI Neighbourhood preserving discriminant embedding in face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neighbourhood preserving embedding; Within-neighbourhood scatter;
   Between-neighbourhood scatter; Class discrimination; Face recognition;
   Graph embedding; Fisher's criterion; Face manifold
ID EIGENFACES; FRAMEWORK
AB In this paper, we present an effective technique on discriminative feature extraction for face recognition. The proposed technique incorporates Graph Embedding and the Fisher's criterion where we call it as Neighbourhood Preserving Discriminant Embedding (NPDE). Utilizing the Graph Embedding criterion, the underlying nonlinear face data structure is revealed as representative and discriminative features for analysis. We employ Neighbourhood Preserving Embedding (NPE) for the purpose. NPE takes into account the restriction that neighbouring points in the high-dimensional space must remain within the same neighbourhood in the low dimension space and be located in a similar relative spatial situation (without changing the local structure of the nearest neighbours of each data point). Furthermore, by taking the advantage of the Fisher's criterion, the discriminating power of NPDE is further boosted. Based on this intuition, NPIDE obtains better discriminative capability and experimentally verified in ORL, PIE and FRGC. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Jin, Andrew Teoh Beng] Yonsei Univ, Seoul 120749, South Korea.
   [Han, Pang Ying; Abas, Fazly Salleh] Multimedia Univ, Jolan Ayer Keroh Lama 75450, Melaka, Malaysia.
C3 Yonsei University; Multimedia University
RP Jin, ATB (corresponding author), Yonsei Univ, Seoul 120749, South Korea.
EM yhpang@mmu.edu.my; bjteoh@yonsei.ac.kr; fazly.salleh.abas@mmu.edu.my
RI Pang, Ying Han/AGW-5132-2022; Teoh, Andrew Beng Jin/F-4422-2010
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484; PANG, YING
   HAN/0000-0002-3781-6623
FU Korea Science and Engineering Foundation (KOSET); Biometrics Engineering
   Research Center (BERC) at Yonsei University [R112002105080020 (2009)]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSET) through the Biometrics Engineering Research Center (BERC) at
   Yonsei University (Grant No. R112002105080020 (2009)).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M., 2001, P C ADV NEUR INF PRO, V15
   BICHSEL M, 1994, CVGIP-IMAG UNDERSTAN, V59, P254, DOI 10.1006/ciun.1994.1017
   Chen HT, 2005, PROC CVPR IEEE, P846
   DAVID M, 2003, P IB C PATT REC IM A, P530
   de Ridder D., 2002, PH200201 DELFT U TEC
   FRANCIS RB, 2003, J MACH LEARN RES, V3, P1
   Hadid A, 2002, INT C PATT RECOG, P111, DOI 10.1109/ICPR.2002.1044625
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Li SZ, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P47, DOI 10.1109/RATFG.2001.938909
   Liang D, 2005, PATTERN RECOGN LETT, V26, P2374, DOI 10.1016/j.patrec.2005.04.011
   Martel Y, 2005, NONLINEARITY, V18, P55, DOI 10.1088/0951-7715/18/1/004
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   PANG S, 2006, P 3 INT S NEUR NETW, P134
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SAMARIA F, 1994, P 2 IEEE WORKSH APPL, P1615
   Saul L.K., 2000, INTRO LOCALLY LINEAR
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yan SC, 2005, PROC CVPR IEEE, P830
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   YOSHUA B, 2004, ADV NEURAL INFORM PR, V16
   Zeng XH, 2007, LECT NOTES ARTIF INT, V4632, P81
   Zhang JF, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA'04), P296
NR 29
TC 32
Z9 35
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 532
EP 542
DI 10.1016/j.jvcir.2009.08.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400004
DA 2024-07-18
ER

PT J
AU Zha, ZJ
   Mei, T
   Wang, JD
   Wang, ZF
   Hua, XS
AF Zha, Zheng-Jun
   Mei, Tao
   Wang, Jingdong
   Wang, Zengfu
   Hua, Xian-Sheng
TI Graph-based semi-supervised learning with multiple labels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Graph-based learning; Multiple labels; Semi-supervised learning; Video
   concept detection
AB Conventional graph-based semi-supervised learning methods predominantly focus on single label problem. However, it is more popular in real-world applications that an example is associated with multiple labels simultaneously. In this paper, we propose a novel graph-based learning framework in the setting of semi-supervised learning with multiple labels. This framework is characterized by simultaneously exploiting the inherent correlations among multiple labels and the label consistency over the graph. Based on the proposed framework, we further develop two novel graph-based algorithms. We apply the proposed methods to video concept detection over TRECVID 2006 corpus and report superior performance compared to the state-of-the-art graph-based approaches and the representative semi-supervised multi-label learning methods. (C) 2008 Elsevier Inc. All rights reserved
C1 [Zha, Zheng-Jun] Univ Sci & Technol China, MOE Microsoft Key Lab Multimedia Comp & Commun, Hefei 230027, Peoples R China.
   [Zha, Zheng-Jun; Wang, Zengfu] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
   [Mei, Tao; Wang, Jingdong; Hua, Xian-Sheng] Internet Media Grp, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Zha, ZJ (corresponding author), Univ Sci & Technol China, MOE Microsoft Key Lab Multimedia Comp & Commun, Hefei 230027, Peoples R China.
EM zzjun@mail.ustc.edu.cn; tmei@microsoft.com; i-jingdw@microsoft.com;
   zfwang@ustc.edu.cn; xshua@microsoft.com
RI Zha, Zheng-Jun/AAF-8667-2020; Wang, Jingdong/E-9920-2017; Mei,
   Tao/GQZ-0596-2022; Zha, Zheng-Jun/AAE-8408-2020
OI Wang, Jingdong/0000-0002-4888-4445; Mei, Tao/0000-0002-5990-7307; Zha,
   Zheng-Jun/0000-0003-2510-8993
CR [Anonymous], 1999, AAAI 99 WORKSH TEXT
   [Anonymous], P NAT C ART INT INN
   [Anonymous], 2008, COMPUT SCI
   [Anonymous], 2004, ADV NEURAL INFORM PR
   [Anonymous], 22220068 ADVENT COL
   [Anonymous], 2007, P 15 ACM INT C MULT, DOI DOI 10.1145/1291233.1291430
   [Anonymous], P ACM INT C MULT
   [Anonymous], P INT WORKSH MULT IN
   Belkin M, 2004, LECT NOTES COMPUT SC, V3120, P624, DOI 10.1007/978-3-540-27819-1_43
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Chen G., 2008, P SIAM INT C DAT MIN, P410, DOI DOI 10.1137/1.9781611972788.37
   CHEN MY, 2007, 8 C LARG SCAL SEM AC
   Elissee Andre., 2001, Advances in Neural Information Processing Systems, P681
   GHAMRAWI N, 2005, P ACM INT C INF KNOW
   Godbole S, 2004, LECT NOTES ARTIF INT, V3056, P22
   HU DY, 1992, LINEAR ALGEBRA APPL, V172, P283, DOI 10.1016/0024-3795(92)90031-5
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Kang F., 2006, CVPR, V2, P1719
   Kazawa H., 2005, ADV NEURAL INFORM PR, P649
   LANCASTER P, 1987, MATH SOCIAL SCI, V13
   Mei T., 2007, TREC VID RETR EV ONL
   NAPHADE MR, 2005, RC23612 IBM TJ WATS
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   QJ GJ, 2007, P ACM INT C MULT MM, P17
   Rosenberg C, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P29
   Tang JH, 2008, IEEE T MULTIMEDIA, V10, P620, DOI 10.1109/TMM.2008.921853
   Zha ZJ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1321, DOI 10.1109/ICME.2008.4607686
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
NR 29
TC 116
Z9 132
U1 2
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2009
VL 20
IS 2
BP 97
EP 103
DI 10.1016/j.jvcir.2008.11.009
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 414JD
UT WOS:000263858800004
DA 2024-07-18
ER

PT J
AU Herman, GT
AF Herman, Gabor T.
TI A note on exact image reconstruction from a limited number of
   projections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image reconstruction; Computerized tomography; Peeling; Algebraic
   reconstruction techniques; ART; Projections; Algorithm; Digital
   difference analyzer
AB In a recent paper in this journal by Kesidis and Papamarkos "A new method for the exact reconstruction of any gray-scale image from its projections is proposed." In this note we point out that this method is a special case of a well-known approach (peeling) and that it can produce exact reconstructions only under assumptions that are not realistic for practical methods of data collection. Further, we point out that some statements made in the paper regarding disadvantages of the algebraic reconstruction techniques (ART) as compared to the method of the paper are false. (C) 2008 Elsevier Inc. All rights reserved.
C1 CUNY, Grad Ctr, Dept Comp Sci, New York, NY 10016 USA.
C3 City University of New York (CUNY) System
RP Herman, GT (corresponding author), CUNY, Grad Ctr, Dept Comp Sci, 365 5th Ave, New York, NY 10016 USA.
EM gabortherman@yahoo.com
FU National Heart, Lung, and Blood Institute [R01 1HL070472]
FX The work of the author is supported by Award No. R01 1HL070472 from the
   National Heart, Lung, and Blood Institute. He is grateful for the
   comments of Yair Censor and of Yehoshua Zeevi on a preliminary version
   of this note. The content is solely the responsibility of the author and
   does not necessarily represent the official views of the National Heart,
   Lung, and Blood Institute or the National Institutes of Health.
CR Carazo J.M., 2006, ELECT TOMOGRAPHY MET, V2nd, P217, DOI DOI 10.1007/978-0-387-69008-7
   CARVALHO BM, SNARK05 PROGRAMMING
   CENSOR Y, 1981, SIAM REV, V23, P444, DOI 10.1137/1023097
   FRIEDER G, 1971, J THEOR BIOL, V33, P189, DOI 10.1016/0022-5193(71)90224-4
   Herman GT, 2008, INVERSE PROBL, V24, DOI 10.1088/0266-5611/24/4/045011
   HERMAN GT, 1973, J THEOR BIOL, V42, P1, DOI 10.1016/0022-5193(73)90145-8
   Kesidis AL, 2008, J VIS COMMUN IMAGE R, V19, P285, DOI 10.1016/j.jvcir.2008.03.004
   Maritz MF, 1998, SIAM J APPL MATH, V59, P58, DOI 10.1137/S0036139996309539
NR 8
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 65
EP 67
DI 10.1016/j.jvcir.2008.11.004
PG 3
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700007
PM 20046950
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Hu, HM
   Jiang, D
   Li, B
AF Hu, Hai-Miao
   Jiang, Dong
   Li, Bo
TI An error resilient video coding and transmission solution over
   error-prone channels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error resilience; Video transmission; FMO; Error concealment; ZIG-ZAG
   scan; Macroblock border gradient
ID H.264/AVC; NETWORKS; STANDARD
AB With the rapid development of network and multimedia technology, the error control in video coding and video transmission over error-prone channels has become increasingly important. The DCT based predictive coding and VLC based entropy coding greatly increase the coding efficiency, but make the compressed video stream very sensitive to transmission errors. Therefore, this paper proposes a reliable error resilient video coding and video transmission framework. In order to improve the robustness to packet loss errors, an error resilient video coding algorithm named Z-FMO is proposed. Some channel may bring random bit errors, an adaptive error concealment algorithm based on macroblock boundary gradient namely ECMBG is proposed aiming at such problem. As the indispensable part of a video transmission system, we implement an adaptive video transmission control algorithm JCBAF. Experimental results show that the proposed framework performs well both in R-D performance and subjective quality. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Hu, Hai-Miao; Jiang, Dong; Li, Bo] Beihang Univ, Digital Media Lab, Sch Engn & Comp Sci, Beijing 100083, Peoples R China.
C3 Beihang University
RP Li, B (corresponding author), Beihang Univ, Digital Media Lab, Sch Engn & Comp Sci, Beijing 100083, Peoples R China.
EM boli@buaa.edu.cn
RI Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888
FU NSFC [60505007]; Equipment Advanced Research Project; National Defense
   Basic Research Foundation; Program for New Century Excellent Talents in
   University
FX Supported by the NSFC (60505007), the Equipment Advanced Research
   Project, the National Defense Basic Research Foundation and the Program
   for New Century Excellent Talents in University. The research was made
   in the State Key Lab of Virtual Reality Technologies.
CR [Anonymous], 2004, NS2 NETWORK SIMULATO
   CALAFATE CMT, 2003, EVALUATION H 264 COD
   *ITU, VCEGN80 ITU
   Kumar S, 2006, J VIS COMMUN IMAGE R, V17, P425, DOI 10.1016/j.jvcir.2005.04.006
   Kwon SK, 2006, J VIS COMMUN IMAGE R, V17, P186, DOI 10.1016/j.jvcir.2005.05.010
   Lambert P, 2006, J VIS COMMUN IMAGE R, V17, P358, DOI 10.1016/j.jvcir.2005.05.008
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Shorten RN, 2005, AUTOMATICA, V41, P725, DOI 10.1016/j.automatica.2004.09.017
   STOCKHAMMER T, 2002, P IWDC CAPR IT, P645
   WANG YK, 2003, P INT PACK VID WORKS
   WENGER S, 1999, VID COD EXP GROUP VC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P542, DOI 10.1109/ICIP.2001.958171
   Worrall ST, 2001, IEE P-COMMUN, V148, P197, DOI 10.1049/ip-com:20010398
   Wu DP, 2000, IEEE T CIRC SYST VID, V10, P923, DOI 10.1109/76.867930
   2007, JVT REFERENCE SOFTWA
NR 16
TC 2
Z9 2
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 35
EP 44
DI 10.1016/j.jvcir.2008.09.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700004
DA 2024-07-18
ER

PT J
AU Wang, B
   Shu, HZ
   Luo, LM
AF Wang, Bin
   Shu, Huazhong
   Luo, Limin
TI A genetic algorithm with chromosome-repairing for min - # and min - ε
   polygonal approximation of digital curves
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Genetic algorithms; Chromosome repairing; Digital curves; Polygonal
   approximations; Integral square error; Optimization; Split technique;
   Merge technique
ID DOMINANT POINT DETECTION; CHAIN-CODED CURVES; SEQUENTIAL METHOD;
   DIGITIZED-CURVES
AB A genetic algorithm for solving min - epsilon polygonal approximation and min - # polygonal approximation is proposed in this paper. It combines traditional split-and-merge techniques with a novel chromosome-repairing scheme to cope with constraints. Due to this combination of techniques we call our new method SMCR. In this new scheme an infeasible solution cannot only be easily transformed into a feasible one, but also be optimized. The experimental results show that the proposed SMCR has higher performance than the other GA-based methods and some non-GA-based methods. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Wang, Bin; Shu, Huazhong; Luo, Limin] Southeast Univ, Sch Engn & Comp Sci, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Wang, B (corresponding author), Southeast Univ, Sch Engn & Comp Sci, 2 Sipailou, Nanjing 210096, Peoples R China.
EM binwang@seu.edu.cn
FU China Postdoctoral Science Foundation [20080431056]; Gaoxiao Natural
   Science Research Program of Jiangsu Province [08KJB510002]; Changjiang
   Scholars and Innovative Research Team in University [NCET-04-0477];
   National Natural Science Foundation of China [60873048]
FX This work was partially supported by the China Postdoctoral Science
   Foundation Funded Project (Grant No.20080431056), Gaoxiao Natural
   Science Research Program of Jiangsu Province (Grant No.08KJB510002),
   Changjiang Scholars and Innovative Research Team in University (Grant
   No.NCET-04-0477) and National Natural Science Foundation of China (Grant
   No.60873048).
CR ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O
   Cronin TM, 1999, PATTERN RECOGN LETT, V20, P617, DOI 10.1016/S0167-8655(99)00025-2
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Ho SY, 2001, PATTERN RECOGN, V34, P2305, DOI 10.1016/S0031-3203(00)00159-X
   Horng JH, 2002, PATTERN RECOGN LETT, V23, P1657, DOI 10.1016/S0167-8655(02)00129-0
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   KOLESNIKOV A, 2005, P INT C IM PROC ICIP, V1, P1553
   LEU JG, 1988, PATTERN RECOGN LETT, V7, P231, DOI 10.1016/0167-8655(88)90107-9
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   Masood A, 2007, J VIS COMMUN IMAGE R, V18, P264, DOI 10.1016/j.jvcir.2006.12.002
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RAY BK, 1995, PATTERN RECOGN LETT, V16, P161, DOI 10.1016/0167-8655(94)00081-D
   RAY BK, 1994, PATTERN RECOGN LETT, V15, P161, DOI 10.1016/0167-8655(94)90045-0
   Rosin PL, 2003, PATTERN RECOGN, V36, P505, DOI 10.1016/S0031-3203(02)00076-6
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SARKAR B, 2004, INT J IMAGE GRAPHICS, V4, P223
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   Sun YN, 2000, INT J PATTERN RECOGN, V14, P297, DOI 10.1142/S0218001400000209
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Toussaint G.T, 1988, MACHINE INTELLIGENCE, V6, P71
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   WU WY, 1993, CVGIP-GRAPH MODEL IM, V55, P79, DOI 10.1006/cgip.1993.1006
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Yin PY, 1998, PATTERN RECOGN LETT, V19, P1017, DOI 10.1016/S0167-8655(98)00082-8
   Yin PY, 1999, INT J PATTERN RECOGN, V13, P1061, DOI 10.1142/S0218001499000598
   Yin PY, 2004, J VIS COMMUN IMAGE R, V15, P241, DOI 10.1016/j.jvcir.2003.12.001
   Yin PY, 2003, PATTERN RECOGN, V36, P1783, DOI 10.1016/S0031-3203(02)00321-7
NR 29
TC 13
Z9 13
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 45
EP 56
DI 10.1016/j.jvcir.2008.10.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700005
DA 2024-07-18
ER

PT J
AU Wu, HH
   Claypool, M
   Kinicki, R
AF Wu, Huahui
   Claypool, Mark
   Kinicki, Robert
TI ARMOR - A system for adjusting repair and media scaling for video
   streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video quality; User study; Streaming MPEG; Temporal scaling; Quality
   scaling; Forward error correction
ID QUALITY
AB To optimize scarce network resources and present the highest quality video streaming video systems, need adapt to the video content as well as the network conditions. This paper presents ARMOR, a video streaming system that dynamically adjusts repair and media scaling to meet current video and network conditions. In order to adapt effectively, ARMOR, and any dynamic video adaptation system, needs to predict the video quality as perceived by end users over the range of scaling and repair choices. Thus, this paper first proposes a novel video quality metric called distorted playable frame rate that provides estimation of user perceptual quality considering temporal and quality degradations. Comprehensive user studies show distorted playable frame rate is more accurate than other video quality metrics. Analytic experiments with distorted playable frame rate and the ARMOR optimization algorithm illustrate the predictive power of the metric in a dynamic, streaming video system. Lastly, implementation and experiments of a complete, fully-functioning ARMOR system show the effective practicality of the proposed approach. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Wu, Huahui] Google, Cambridge, MA 02142 USA.
   [Claypool, Mark; Kinicki, Robert] Worcester Polytech Inst, Dept Comp Sci, Worcester, MA 01609 USA.
C3 Google Incorporated; Worcester Polytechnic Institute
RP Wu, HH (corresponding author), Google, 5 Cambridge Ctr, Cambridge, MA 02142 USA.
EM hwu@google.com; claypool@cs.wpi.edu; rek@cs.wpi.edu
RI Claypool, Mark/ABC-5316-2020
CR [Anonymous], 2006, DATAGRAM CONGESTION
   ASHMAWI W, 2001, P 2001 C APPL TECHN, P83
   Carson Mark, NIST NET LINUX BASED
   CHUNG J, 2003, P PACK VID WORKSH
   Frossard P, 2001, IEEE T IMAGE PROCESS, V10, P1815, DOI 10.1109/83.974566
   ITU-R, 2002, BT50011 ITU R
   JAISWAL S, 2004, P IEEE INF HONG KONG
   Krasic C., 2003, Proceedings of the 13th International Workshop on Network and Operating Systems Support for Digital Audio and Video, P112
   Liao RRF, 2001, WIREL NETW, V7, P541, DOI 10.1023/A:1016730812076
   MAYERPATEL K, 2002, P ACM MULTIMEDIA DEC
   NGAN K, 2003, IEEE T CIRCUITS SYST
   PADHYE J, 1998, P ACM SIGGCOMM VANC
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018
   Rizzo L., 1997, COMPUTER COMMUNICATI
   SAKAZAWA S, 1996, P 7 INT WORKSH PACK
   WINKLER S, 2005, P SPIE HUM VIS EL IM
   Wolf S., 2007, P 3 INT WORKSH VID P
   WU H, 2005, P WORKSH NETW OP SYY
   Wu Huahui, 2005, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), V1, P315
NR 20
TC 2
Z9 3
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2008
VL 19
IS 8
BP 489
EP 499
DI 10.1016/j.jvcir.2008.07.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 383ZY
UT WOS:000261714300003
DA 2024-07-18
ER

PT J
AU Kumwilaisak, W
AF Kumwilaisak, Wtittipong
TI Foveation image coding with fuzzy-based joint parameter selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Foveation image coding; Discrete wavelet transform; Scaling down factor;
   Joint parameter selection; Foveated wavelet image quality index; SPIHT
   codec; List significant pixel; Fuzzy logic system
ID COMPRESSION; ALGORITHMS
AB This paper presents a novel method of the foveation image coding based on the fuzzy-based joint parameter selection. Our objective is to maximize foveated wavelet image quality index (FWQ1) of the reconstructed image. With the foveated visual sensitivity model, image regions are first prioritized. The image regions close to foveation points have higher priorities than those far away from the foveation points. The discrete wavelet transform (DWT) is utilized to transform the considering image to the wavelet domain. The wavelet coefficients from different image regions are weighted using the foveated visual sensitivity model and then scaled down before entropy encoding. To achieve the objective, we use a fuzzy logic system and an iterative search to select image coding parameters under the bit budget constraint. The coding parameters consist of a number of weighted wavelet coefficients in the list significant pixel (LSP) of the SPIHT codec [A. Said, W.A. Pearlman, A new, fast, and efficient image codec based on set partitioning in hierarchical trees, IEEE Trans. Circuits Syst. Video Technol. 6 (3) (1996) 243-250], represented as N-LSP, and a scaling down factor (QP). There are two inputs and one output in the proposed fuzzy logic system. The inputs are N-LSP and targeted bit per pixel used to encode an image. The output is an interval of QP. The QP value corresponding to the input N-LSP giving the highest FWQ1 is selected from the derived interval. We iteratively search for the values of N-LSP and QP providing the highest FWQ1. Then, the SPIHT codec is used to generate a scalable bitstream of the discrete wavelet coefficients with the optimal pair of N-LSP and QP. The sub-optimal search algorithm to compute both N-LSP and QP with low complexity is also proposed. Our simulation results show that the proposed scheme provides a better reconstructed image quality comparing to previous work in both objective and subjective qualities. (C) 2008 Elsevier Inc. All rights reserved.
C1 King Mongkuts Univ Technol, Dept Elect & Telecommun, Commun & Multimedia Lab, Bangkok 10140, Thailand.
C3 King Mongkuts University of Technology Thonburi; King Mongkuts
   University of Technology North Bangkok
RP Kumwilaisak, W (corresponding author), King Mongkuts Univ Technol, Dept Elect & Telecommun, Commun & Multimedia Lab, Bangkok 10140, Thailand.
EM wuttipong.kum@kmutt.ac.th
FU The Thailand Research Fund (TRF)
FX This research is supported by The Thailand Research Fund (TRF).
CR [Anonymous], P 13 S COMP GEOM
   [Anonymous], IEEE P
   Arnow TL, 2007, IEEE T IMAGE PROCESS, V16, P813, DOI 10.1109/TIP.2006.891335
   BANDERA C, 1989, IEEE ICSMC CAMBR MA, P596
   BANKS MS, 1991, J OPT SOC AM A, V8, P1775, DOI 10.1364/JOSAA.8.001775
   Boccignone G, 2005, IEEE T CIRC SYST VID, V15, P365, DOI 10.1109/TCSVT.2004.842603
   CAMACHO P, 1996, IEEE ICIP, V1, P307
   Geisler W. S., 1998, P SPIE, V3299
   Hellendoorn H., 1993, J INTELLIGENT FUZZY, V1, P109
   Ho CC, 2005, IEEE T CIRC SYST VID, V15, P1365, DOI 10.1109/TCSVT.2005.856929
   KLEMENT EP, 2004, HDB FUZZY BLIDUNGSZE
   Kortum P, 1996, P SOC PHOTO-OPT INS, V2657, P350, DOI 10.1117/12.238732
   KOSKO B, 1994, THEORETICAL ASPECTS, pCH12
   Kuyel T, 1999, IEEE T SYST MAN CY A, V29, P235, DOI 10.1109/3468.747859
   LARSEN PM, 1980, INT J MAN MACH STUD, V12, P3, DOI 10.1016/S0020-7373(80)80050-2
   Lee H, 2006, IEEE SIGNAL PROC LET, V13, P553, DOI 10.1109/LSP.2006.874464
   Lee J, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P45, DOI 10.1109/ICIP.1997.638669
   Lee S, 2003, IEEE T CIRC SYST VID, V13, P149, DOI 10.1109/TCSVT.2002.808441
   MAMDANI EH, 1974, P I ELECTR ENG, V121, P1585, DOI 10.1049/piee.1974.0328
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   PACINI PJ, 1992, NEURAL NETWORKS FUZZ, P379
   ROBSON JG, 1981, VISION RES, V21, P409, DOI 10.1016/0042-6989(81)90169-3
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHARPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445
   Sullivan G. J., 2004, SPIE C APPL DIG IM P
   Tsumura N, 1996, P SOC PHOTO-OPT INS, V2657, P361, DOI 10.1117/12.238733
   WALLACE RS, 1994, INT J COMPUT VISION, V13, P71, DOI 10.1007/BF01420796
   Wang L. X., 1994, Adaptive Fuzzy Systems and Control: Design and Stability Analysis
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   WANG Z, 2001, P IEEE INT C IM PROC
NR 30
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2008
VL 19
IS 7
BP 450
EP 463
DI 10.1016/j.jvcir.2008.07.005
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 363NU
UT WOS:000260274800004
DA 2024-07-18
ER

PT J
AU Yang, NC
   Chang, WH
   Kuo, CM
   Li, TH
AF Yang, Nal-Chung
   Chang, Wei-Han
   Kuo, Chung-Ming
   Li, Tsia-Hsing
TI A fast MPEG-7 dominant color extraction with new similarity measure for
   image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE dominant color descriptor; color quantization; dissimilarity measure;
   MPEG-7
ID QUANTIZATION; ALGORITHM
AB Dominant color descriptor (DCD) is one of the color descriptors proposed by MPEG-7 that has been extensively used for image retrieval. Among the color descriptors, DCD describes the salient color distributions in an image or a region of interest. DCD provides an effective, compact, and intuitive representation of colors presented in an image. In this paper, we will develop an efficient scheme for dominant color extraction. This approach significantly improves the efficiency of computation for dominant color extraction. In addition, we propose a modification for the MPEG-7 dissimilarity measure, which effectively improves the accuracy of perceptive similarity. Experimental results show that the proposed method achieves performance improvement riot only in saving features extraction cost but also perceptually similar image retrieval. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Yang, Nal-Chung; Chang, Wei-Han; Kuo, Chung-Ming; Li, Tsia-Hsing] I Shou Univ, Dept Informat Engn, Saga 840, Japan.
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Saga 840, Japan.
EM kuocm@isu.edu.tw
CR [Anonymous], 2001, JTC1SC29WG11N391 ISO
   BALASUBRAMANIAN R, 1994, J OPT SOC AM A, V11, P2777, DOI 10.1364/JOSAA.11.002777
   CELENK M, 1990, COMPUT VISION GRAPH, V52, P145, DOI 10.1016/0734-189X(90)90052-W
   Deng YN, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P21, DOI 10.1109/ISCAS.1999.779933
   Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450
   Heckbert P., 1982, Computer Graphics, V16, P297, DOI 10.1145/965145.801294
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   LIM YW, 1990, PATTERN RECOGN, V23, P935, DOI 10.1016/0031-3203(90)90103-R
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Ma WY, 1997, P SOC PHOTO-OPT INS, V3016, P496, DOI 10.1117/12.274547
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Mojsilovic A, 2002, IEEE T IMAGE PROCESS, V11, P1238, DOI 10.1109/TIP.2002.804260
   Po LM, 2004, IEEE IMAGE PROC, P1533
   SCHEUNDERS P, 1996, IEEE INT C IMAGE PRO, V3, P1031
   WAN SJ, 1990, COLOR RES APPL, V15, P52, DOI 10.1002/col.5080150109
NR 16
TC 90
Z9 101
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2008
VL 19
IS 2
BP 92
EP 105
DI 10.1016/j.jvcir.2007.05.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 264MD
UT WOS:000253290600002
DA 2024-07-18
ER

PT J
AU Wu, JH
   Cai, JF
   Chen, CW
AF Wu, Jianhua
   Cai, Jianfei
   Chen, Chang Wen
TI Rate-distortion analysis of leaky prediction based FGS video for
   constant quality constrained rate adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE rate-distortion; leaky prediction; fine granularity scalability;
   constant quality; bit allocation
AB For leaky prediction based FGS (Fine Granularity Scalability), constant quality constrained rate adaptation, i.e., how to optimally truncate/allocate bits given the current channel bandwidth, is still an open problem. The difficulty lies in obtaining accurate R-D (ratedistortion) curves for leaky prediction based FGS (L-FGS) due to the dependency among video frames. In this paper, we propose an accurate R-D model, which considers not only the distortion introduced in the current frame and the propagated distortion from the reference frame due to rate adaptation, but also the correlation between them. An excellent property of our proposed R-D model is that even when applying the model for a long video sequence without any update of the actual distortion values, the estimation error is still negligible and the error is not accumulated. Based on our proposed R-D model, a sliding window technique is further developed to solve the problem of constant quality constrained bit allocation. Experimental results show that the proposed R-D model is very accurate and the corresponding bit allocation algorithm can achieve much more smooth video quality than the traditional uniform bit allocation under both CBR (constant bit rate) and VBR (variable bit rate) channels. (c) 2006 Elsevier Inc. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   Florida Inst Technol, Dept Elect & Comp Engn, Melbourne, FL 32901 USA.
C3 Nanyang Technological University; Florida Institute of Technology
RP Cai, JF (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM pg02320384@ntu.edu.sg; asjfcai@ntu.edu.sg; cchen@fit.edu
RI Wu, Jian/AAU-5221-2020; Wu, Jian/AAU-5221-2020; Cai, Jianfei/A-3691-2011
OI Wu, Jian/0000-0001-9933-7364; Wu, Jian/0000-0002-3394-1507; Cai,
   Jianfei/0000-0002-9444-3763
CR Conklin GJ, 1999, IEEE T CIRC SYST VID, V9, P909, DOI 10.1109/76.785728
   DAI M, 2003, ACM NOSSDAV 03, P60
   Domanski M, 2000, IEEE T CIRC SYST VID, V10, P1088, DOI 10.1109/76.875513
   HAN S, 2002, IEEE ICIP 2002
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   Huang HC, 2002, IEEE T CIRC SYST VID, V12, P372, DOI 10.1109/TCSVT.2002.800314
   Lakshman TV, 1998, P IEEE, V86, P952, DOI 10.1109/5.664282
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   LIU Y, 2003, IEEE ICME 2003, P565
   Pao IM, 2001, IEEE T CIRC SYST VID, V11, P199, DOI 10.1109/76.905985
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P533, DOI 10.1109/83.334987
   SCHAAR M, 2000, MOTION COMPENSATION
   Song HJ, 2001, IEEE T CIRC SYST VID, V11, P512, DOI 10.1109/76.915357
   Sun HF, 1996, IEEE T CIRC SYST VID, V6, P191, DOI 10.1109/76.488826
   TAN TK, 1994, IEEE T CIRC SYST VID, V4, P203, DOI 10.1109/76.285629
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang Q, 2002, IEEE SIGNAL PROC LET, V9, P33, DOI 10.1109/97.991132
   Wilson D, 1999, IEEE T CIRC SYST VID, V9, P783, DOI 10.1109/76.780366
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
   WU J, 2004, SPIE VCIP 2004, P1305
   YUE Y, 2001, IEEE T CIRCUITS  MAR, P345
   Zhang XM, 2003, IEEE T CIRC SYST VID, V13, P121, DOI 10.1109/TCSVT.2002.808437
   ZHAO L, 2002, IEEE ISCAS 2002
NR 23
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 45
EP 58
DI 10.1016/j.jvcir.2006.09.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100004
DA 2024-07-18
ER

PT J
AU Kim, C
   Shih, HH
   Kuo, CCJ
AF Kim, Changsung
   Shih, Hsuan-Huei
   Kuo, C. -C. Jay
TI Fast H.264 Intra-prediction mode selection using joint spatial and
   transform domain features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video coding; H.264; AVC; intra-mode decision; intra prediction
AB A fast H.264 Intra-prediction mode selection scheme is proposed in this work. The objective is to reduce the encoder complexity without significant rate-distortion performance degradation. The proposed method uses spatial and transform domain features of the target block jointly to filter out the majority of candidate modes. This is justified by examining the posterior error probability and the average rate-distortion loss. For the final mode selection, either the feature-based or the RDO (rate-distortion optimization)-based method is applied to 2-3 candidate modes. It is demonstrated by experimental results that the proposed scheme demands only 7-10% of the complexity of the RDO (rate-distortion optimized) mode decision scheme with little quality degradation. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ So Calif, Integrated Media Syst Ctr, Dept Elect Engn, Los Angeles, CA 90089 USA.
   MAVs Lab Inc, Lungtan 325, Tau Yuan, Taiwan.
C3 University of Southern California
RP Kuo, CCJ (corresponding author), Univ So Calif, Integrated Media Syst Ctr, Dept Elect Engn, Los Angeles, CA 90089 USA.
EM changsuk@sipi.usc.edu; maverick@mavslab.com; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR CHEONG HY, 2002, 5 M GEN SWITZ OCT 9
   CHIANG YQT, 1997, IEEE T CIRCUITS SYST
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Erol B, 1998, IEEE DATA COMPR CONF, P259, DOI 10.1109/DCC.1998.672154
   HALBACH T, 2002, JVT 4 M KLAG AUSTR J
   HE Z, 2001, IEEE T CIRCUIT SYST, V11
   JEON B, 2003, JVT 10 M WAIK HAW DE
   *JVT TEST MOD AD H, 2003, EV SHEET MOT EST DRA
   Kim C, 2004, IEEE IMAGE PROC, P769
   KIM CS, 2003, SPIE INT S ITCOM 200
   KIM CS, 2004, IS T SPIE 16 ANN S E
   LI X, 2002, 6 M AW ISL JAP DEC 5
   Pan F., 2003, JVT 7 M PATT 2 THAIL
   SONG HJ, 1998, IEEE INT S CIRC SYST
   TOPIWALA P, 2001, 15 M ITU T Q 6 SG16
   *UB VID INC, 2002, EM H 26L STAND OV TM
   WIEGAND T, 2003, IEEE T CIRCUITS SYST, V7, P1
   YANG KH, 1998, ICIP 98, V2, P387
   YANG KH, 1997, P INT C IM PROC SANT, V2, P41
NR 19
TC 28
Z9 41
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 291
EP 310
DI 10.1016/j.jvcir.2005.05.002
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000006
DA 2024-07-18
ER

PT J
AU Kumar, S
   Xu, LY
   Mandal, MK
   Panchanathan, S
AF Kumar, Sunil
   Xu, Liyang
   Mandal, Mrinal K.
   Panchanathan, Sethuraman
TI Error resiliency schemes in H.264/AVC standard
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; JVT; MPEG-4 part 10; video coding standards; video coding;
   video compression; error resiliency; error resilient video coding
ID VIDEO CODING STANDARD; PRONE CHANNELS; CONCEALMENT; TRANSMISSION;
   ALGORITHM; RECOVERY
AB Real-time transmission of video data in network environments, such as wireless and Internet, is a challenging task, as it requires high compression efficiency and network-friendly design. H.264/AVC is the newest international video coding standard, jointly developed by groups from ISO/IEC and ITU-T, which aims at achieving improved compression performance and a network-friendly video representation for different types of applications, such as conversational, storage, and streaming. In this paper, we discuss various error resiliency schemes employed by H.264/AVC. The related topics such as non-normative error concealment and network environment are also described. Some experimental results are discussed to show the performance of error resiliency schemes. (c) 2005 Elsevier Inc. All rights reserved.
C1 Clarkson Univ, Dept Elect & Comp Engn, Potsdam, NY 13699 USA.
   Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
C3 Clarkson University; University of Alberta; Arizona State University;
   Arizona State University-Tempe
RP Kumar, S (corresponding author), Clarkson Univ, Dept Elect & Comp Engn, Potsdam, NY 13699 USA.
EM skumar@clarkson.edu; xul@clarkson.edu; mandal@ece.ualberta.ca;
   panch@asu.edu
CR CALAFATE CM, 2004, INT WORKSH WIR ADH N, P23
   CALAFATE CT, 2003, 4 EURASIP C FOC VID
   CHEN TPC, 2002, WIRELESS COMMUNICATI
   CHEN Y, 2002, JVTC125
   Chu WJ, 1998, IEEE T CIRC SYST VID, V8, P74, DOI 10.1109/76.660830
   GHANDI MM, 2006, ELSEVIER J VISUAL CO, V17, P444
   Girod B, 1999, P IEEE, V87, P1707, DOI 10.1109/5.790632
   Grangetto M, 2003, IEEE COMMUN LETT, V7, P596, DOI 10.1109/LCOMM.2003.821331
   HANNUKSELA MM, 2002, JVTB109
   *ISO IEC, 2000, 1449614502 ISOIEC
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   KARCZEWICZ M, 2001, VCEGL27R1
   Kumar S, 2004, REAL-TIME IMAGING, V10, P315, DOI 10.1016/j.rti.2004.07.003
   LAM WM, 1993, P ICASSP, V5, P417
   Lee SH, 2001, ELECTRON LETT, V37, P218, DOI 10.1049/el:20010147
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Reader C., 2002, JVTD068
   ROTH R, 2001, VCEGM77 ITUT SG16
   Salama P, 2000, IEEE J SEL AREA COMM, V18, P1129, DOI 10.1109/49.848263
   SHIRANI IS, 2000, P IEEE INT C IM PROC
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   STOCKHAMMER T, 2002, JVTC132
   SULLIVAN G, 2002, JVTC117
   Talluri R, 1998, IEEE COMMUN MAG, V36, P112, DOI 10.1109/35.685373
   Valente S, 2001, IEEE T CONSUM ELECTR, V47, P568, DOI 10.1109/30.964147
   VARSA V, 2001, VCEGN62 ITUT SG16
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wenger S, 1998, IEEE T CIRC SYST VID, V8, P867, DOI 10.1109/76.735382
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   WENGER S, 2002, JVTC089
   WENGER S, 2001, VCEGN52
   WENGER S, 1999, Q15I62 ITUT SG16
   WENGER S, 1999, Q15I61 ITUT SG16
   WENGER S, 1999, Q15I60 ITUT SG16
   WENGER S, 1997, WORKSH AUD VIS SERV
   Wenger S., 1999, Q15I16R1 ITUT SG16
   WENGER S, 2002, JVTB027
   WENGER S, 2002, JVTB028
   WENGER S, 2002, JVTB024
   WENGER S, 2001, VCEGN79R1 ITUT SG16
   WENGER S, 2001, VCEGL34D2 ITUT SG16
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2000, IEEE J SEL AREA COMM, V18, P1050, DOI 10.1109/49.848255
   Yan B, 2003, IEEE T CONSUM ELECTR, V49, P1416, DOI 10.1109/TCE.2003.1261249
   YE JC, 2002, JVTD136
   Zeng WJ, 1999, IEEE T CIRC SYST VID, V9, P648, DOI 10.1109/76.767129
   Zheng JH, 2003, IEEE T BROADCAST, V49, P383, DOI 10.1109/TBC.2003.819050
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 50
TC 78
Z9 102
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 425
EP 450
DI 10.1016/j.jvcir.2005.04.006
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000013
DA 2024-07-18
ER

PT J
AU Cheng, SC
   Wu, TL
AF Cheng, Shyi-Chyi
   Wu, Tian-Luu
TI Scene-adaptive video partitioning by semantic object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video segmentation; shortest-path labeling; motion estimation;
   foreground object; object tracking; moment-preserving techniques
ID IMAGE SEGMENTATION; MOTION ESTIMATION; ALGORITHM; SEQUENCES; EFFICIENT
AB An adaptive mechanism for video partitioning by semantic objects tracking is proposed. A video scene consists of the sequence of frames between two adjacent video scene changes which can be detected according to the video scene complexity. In general, the video scene complexity can be described in twofold characteristics-the temporal domain motion complexity and the spatial domain activity complexity. For this purpose, we propose a novel spatial-temporal segmentation method as a general segmentation algorithm combining several types of information including color and motion. A region within a foreground object is called as a foreground region, which is characterized as a moving uniform region. An algorithm for object tracking based on the foreground regions is also included in order to recognize camera and object movements and obtain correct video shots. By analyzing foreground objects between consecutive frames, the types of scene change and the types of camera movement can be detected according to the number of entering and existing regions and the motion vectors, respectively. Based on these parameters, the frames of a video sequence are categorized into normal, cut, fade, and dissolve classes. Adaptation is realized by grouping variable number of the labeled frames as a unit, which contains a scene change to be automatically determined by the moment-preserving thresholding techniques. Experimental results are presented to demonstrate the performance of the new method in terms of better segmentation. (c) 2005 Elsevier Inc. All rights reserved.
C1 Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung 824, Taiwan.
   Yung Ta Inst Technol & Commerce, Dept Elect Engn, Pingtung 909, Taiwan.
C3 National Kaohsiung University of Science & Technology
RP Cheng, SC (corresponding author), Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, 1 Univ Rd, Kaohsiung 824, Taiwan.
EM csc@ccms.nkfust.edu.tw
CR AKUTSU A, 1992, P SOC PHOTO-OPT INS, V1818, P1522
   CHANG SF, 1998, IEEE T CIRCUITS SYST, V8
   CHANG SF, 1997, P ACM MULT C SEATTL
   Cheng SC, 2005, IEEE T MULTIMEDIA, V7, P189, DOI 10.1109/TMM.2005.843358
   Cheng SC, 2003, IEE P-VIS IMAGE SIGN, V150, P270, DOI 10.1049/ip-vis:20030520
   Chien SY, 2003, IEEE T CIRC SYST VID, V13, P453, DOI 10.1109/TCSVT.2003.811605
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   CORMEN TH, 1999, MIT ELECTR ENG COMPU
   Dufaux F, 2000, IEEE T IMAGE PROCESS, V9, P497, DOI 10.1109/83.826785
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   GUKNSEL B, 1998, J ELECTRON IMAGING, V7, P592
   HSIEH JW, 1999, COMPUT COMMUN, P40
   KASTURI R, 1991, COMPUTER VISION PRIN, P469
   Kikukawa T., 1992, Transactions of the Institute of Electronics, Information and Communication Engineers A, VJ75-A, P204
   Kompatsiaris I, 2000, IEEE T CIRC SYST VID, V10, P1388, DOI 10.1109/76.889030
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   LI J, 2003, P IEEE INT C IM PROC, V3, P949
   Luo HT, 2003, IEEE T MULTIMEDIA, V5, P379, DOI 10.1109/TMM.2003.813285
   Nagasaka A., 1995, Visual Database Systems II, P113
   PAPPAS TN, 1992, IEEE T SIGNAL PROCES, V40, P901, DOI 10.1109/78.127962
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   Pei SC, 1999, IEEE T IMAGE PROCESS, V8, P614, DOI 10.1109/83.760310
   Sethi I. K., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P329, DOI 10.1117/12.205299
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SMITH M, 1998, P INT WORKSH CONT BA
   TSAI WH, 1984, COMPUT VIS GRAPH IMA, P377
   Tsaig Y, 2002, IEEE T CIRC SYST VID, V12, P597, DOI 10.1109/TCSVT.2002.800513
   *VID GROUP, 2000, ISOIECJTCISC29WG11N3
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
   Xiong W, 1998, COMPUT VIS IMAGE UND, V71, P166, DOI 10.1006/cviu.1998.0711
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   ZHANG HJ, 1994, P SOC PHOTO-OPT INS, V2182, P142, DOI 10.1117/12.171062
NR 34
TC 3
Z9 4
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 72
EP 97
DI 10.1016/j.jvcir.2005.02.003
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900005
DA 2024-07-18
ER

PT J
AU Liu, TY
   Lo, KT
   Zhang, XD
   Feng, H
AF Liu, TY
   Lo, KT
   Zhang, XD
   Feng, H
TI A new cut detection algorithm with constant false-alarm ratio for video
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE cut detection; video retrieval; constant false-alarm ratio;
   shot-boundary detection video; segmentation
ID SCENE CHANGE DETECTION
AB In this paper, a new cut detection algorithm with constant false-alarm ratio (CFAR) is proposed for video segmentation. In our method, a theoretical threshold determination strategy using the non-parameter based CFAR processing technique is developed to achieve a controllable precision as well as an evaluative recall performance for video cut detection. Simulation results show that this algorithm leads to very good detection performance as compared to the existing techniques. (C) 2003 Elsevier Inc. All rights reserved.
C1 City Univ Hong Kong, Dept Comp Engn & Informat Technol, Hong Kong, Hong Kong, Peoples R China.
   Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
   Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 City University of Hong Kong; Hong Kong Polytechnic University; Tsinghua
   University
RP Hong Kong Polytech Univ, Ctr Multimedia Signal Proc, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
EM t-tyliu@microsoft.com; enktlo@polyu.eclu.hk; zhangxd@tsinghua.edu.cn;
   itjfeng@cityu.edu.hk
RI Lo, Kwok Tung KT/O-2143-2013
CR [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   CARLYLE JW, 1964, IEEE T INFORM THEORY, V10, P146, DOI 10.1109/TIT.1964.1053663
   Fernando WAC, 2000, IEEE T CONSUM ELECTR, V46, P769, DOI 10.1109/30.883445
   HAMPAPUR A, 1995, J MULTIMEDIA TOOLS A, V1, P1
   Hanjalic A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P710, DOI 10.1109/MMCS.1999.778571
   Lupatini G, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P34, DOI 10.1109/RIDE.1998.658276
   Minkler G., 1990, PRINCIPLES AUTOMATIC
   Sethi I. K., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P329, DOI 10.1117/12.205299
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Zhang H., 1995, Multimedia Tools and Applications, V1, P89, DOI 10.1007/BF01261227
NR 11
TC 13
Z9 15
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 132
EP 144
DI 10.1016/j.jvcir.2003.10.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800002
DA 2024-07-18
ER

PT J
AU Wu, W
   Huang, DQ
   Yao, Y
   Shen, ZN
   Zhang, H
   Yan, CG
   Zheng, BL
AF Wu, Wei
   Huang, Daoquan
   Yao, Yang
   Shen, Zhuonan
   Zhang, Hua
   Yan, Chenggang
   Zheng, Bolun
TI Feature rectification and enhancement for no-reference image quality
   assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No-reference; Image quality assessment; Feature rectification; Neural
   network
ID STATISTICS; DISTORTION; FILTERS
AB The assessment of image is a critical task in computer vision, particularly in a no-referenced context, which presents numerous challenges. Though Deep neural networks have exhibited excellent performance on no-reference quality assessment (NR-IQA), the distortion-aware NR-IQA methods are limited to specific distortion type and struggle to handle realistic distortion scenarios. In this work, we propose a feature rectification and enhancement convolutional neural network namely FREIQA for NR-IQA. Our approach targets to fully utilize the multi-stage semantic features to produce a well fused and rectified score vector for effective image quality regression. Specifically, the multi-stage semantic features extracted by a pre-trained backbone would be rectified with a multi-level channel attention module before integrating to a global score vector. The fused score vector then will be gradually optimized through the perception feature provided by the multi-stage semantic feature, and finally sent to quality regression network to obtain the image quality score. Experimental results on public benchmarks including LIVE, TID2013, CSIQ, LIVEC, KADID-10k, KonIQ-10k and Waterloo exploration database show that our FREIQA achieve the state-of-the-art performance.
C1 [Wu, Wei; Huang, Daoquan; Yao, Yang; Shen, Zhuonan; Zhang, Hua; Yan, Chenggang; Zheng, Bolun] Hangzhou Dianzi Univ, Hangzhou 310061, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhang, H (corresponding author), Hangzhou Dianzi Univ, Hangzhou 310061, Peoples R China.
EM ww@hdu.edu.cn; 1758398270@qq.com; fkmog@hdu.edu.cn;
   shenzhuonan@hdu.edu.cn; zhangh@hdu.edu.cn; cgyan@hdu.edu.cn;
   blzheng@hdu.edu.cn
FU National Key Research and Develop-ment Program of China
   [2020YFB1406604]; Key R&D Program of Zhejiang, China [2023C01044];
   National Natural Science Foundation of China [62001146, U21B2024];
   Fundamental Research Funds for the Provincial Universities of Zhejiang,
   China [GK239909299001-013, GK229909299001-009]
FX <B>Acknowledgments</B> This work was supported by National Key Research
   and Develop-ment Program of China under Grants 2020YFB1406604, the Key
   R&D Program of Zhejiang, China under Grant No. 2023C01044. This work is
   also supported by National Natural Science Foundation of China under
   Grants No. 62001146, U21B2024, and the Fundamental Research Funds for
   the Provincial Universities of Zhejiang, China under Grants No.
   GK239909299001-013 and GK229909299001-009.
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Furnari A, 2017, J VIS COMMUN IMAGE R, V46, P165, DOI 10.1016/j.jvcir.2017.03.019
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Golestaneh S Alireza, 2022, P IEEE CVF WINT C AP, P1220
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hou GJ, 2023, ACM T MULTIM COMPUT, V19, DOI 10.1145/3578584
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiang QP, 2022, IEEE T CIRC SYST VID, V32, P5959, DOI 10.1109/TCSVT.2022.3164918
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Khosravi MH, 2019, J VIS COMMUN IMAGE R, V60, P217, DOI 10.1016/j.jvcir.2018.11.019
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee SH, 2023, J VIS COMMUN IMAGE R, V94, DOI 10.1016/j.jvcir.2023.103850
   Lin HH, 2019, INT WORK QUAL MULTIM
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Luo SH, 2023, J VIS COMMUN IMAGE R, V95, DOI 10.1016/j.jvcir.2023.103897
   Ma KD, 2020, IEEE T PATTERN ANAL, V42, P851, DOI 10.1109/TPAMI.2018.2889948
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Pan Zhaoqing, 2023, IEEE Transactions on Artificial Intelligence, P148, DOI 10.1109/TAI.2022.3146804
   Pleiss G., 2017, ARXIV
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Ren HY, 2018, AAAI CONF ARTIF INTE, P7308
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Shamsuddin AF, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103636
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thongkor K, 2018, J VIS COMMUN IMAGE R, V53, P146, DOI 10.1016/j.jvcir.2018.03.005
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2020, IEEE T IMAGE PROCESS, V29, P7414, DOI 10.1109/TIP.2020.3002478
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yan QS, 2019, IEEE T IMAGE PROCESS, V28, P2200, DOI 10.1109/TIP.2018.2883741
   Yang S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1383, DOI 10.1145/3343031.3350990
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Yu SD, 2023, J VIS COMMUN IMAGE R, V94, DOI 10.1016/j.jvcir.2023.103848
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang SQ, 2023, J VIS COMMUN IMAGE R, V97, DOI 10.1016/j.jvcir.2023.103979
   Zhao HR, 2022, IEEE T CIRC SYST VID, V32, P4138, DOI 10.1109/TCSVT.2021.3123621
   Zheng B., DomainPlus: Cross-transform domain learning towards high dynamic range imaging.
   Zheng BL, 2022, IEEE T COMPUT IMAG, V8, P346, DOI 10.1109/TCI.2022.3171417
   Zheng BL, 2022, IEEE T PATTERN ANAL, V44, P7705, DOI 10.1109/TPAMI.2021.3115139
   Zheng BL, 2020, IEEE T CIRC SYST VID, V30, P3982, DOI 10.1109/TCSVT.2019.2931045
   Zheng BL, 2020, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR42600.2020.00369
   Zhou XF, 2023, IEEE T CYBERNETICS, V53, P539, DOI 10.1109/TCYB.2022.3163152
   Zhou XF, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3132082
   Zhou XF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3091312
   Zhu SY, 2019, IEEE T CIRC SYST VID, V29, P1559, DOI 10.1109/TCSVT.2019.2895840
NR 67
TC 2
Z9 2
U1 6
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104030
DI 10.1016/j.jvcir.2023.104030
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EZ9E4
UT WOS:001142870100001
DA 2024-07-18
ER

PT J
AU He, SH
   Xu, DW
   Yang, L
   Dai, HJ
   Wang, SS
AF He, Songhan
   Xu, Dawen
   Yang, Lin
   Dai, Haojun
   Wang, Shanshan
TI An anti-steganalysis adaptive steganography for HEVC video based on PU
   partition modes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive video steganography; Anti-steganalysis; HEVC Steganalysis; PU
   partition mode
ID ALGORITHM; CNN
AB Calibration-based steganalysis methods are a fatal threat to current HEVC steganography algorithms. The current steganography algorithms based on prediction unit (PU) still lack resistance to this type of steganalysis. The reason is that the improvements in HEVC codec provide more potential steganographic space as well as introduce more detectable distortion. Therefore, a HEVC video steganography method that has resistance to PU shift-based steganalysis is proposed in this paper. First, the PU shift phenomenon that exists in PU-based steganography is introduced. Then the existing calibration-based steganalysis method is enhanced. According to the encoding rules of HEVC, the distortion cost function according to the difference of rate distortion cost (RD cost) during recompression is designed, which aims to obtain better resistance to calibration-based steganalysis. Experimental results demonstrate that the steganography algorithm designed in this paper provides excellent resistance ability for calibration-based steganalysis.
C1 [He, Songhan; Yang, Lin; Dai, Haojun] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Peoples R China.
   [He, Songhan; Xu, Dawen; Yang, Lin; Dai, Haojun; Wang, Shanshan] Ningbo Univ Technol, Sch Cyber Sci & Engn, Ningbo 315211, Peoples R China.
C3 Ningbo University; Ningbo University of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Cyber Sci & Engn, Ningbo 315211, Peoples R China.
EM dawenxu@126.com
RI he, songhan/KVY-0154-2024
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [62071267]; Zhejiang
   Provincial Natural Science Foundation of China [LR20F020001]; Ningbo
   Natural Science Foundation [2023J022]
FX This work is supported by the National Natural Science Foundation of
   China (62071267) , Zhejiang Provincial Natural Science Foundation of
   China (LR20F020001) , Ningbo Natural Science Foundation (2023J022) .
CR Chang PC, 2014, J VIS COMMUN IMAGE R, V25, P239, DOI 10.1016/j.jvcir.2013.10.007
   Dai HJ, 2024, IEEE T CIRC SYST VID, V34, P2663, DOI 10.1109/TCSVT.2023.3309861
   Dong Y, 2023, IEEE T DEPEND SECURE, V20, P769, DOI 10.1109/TDSC.2022.3144139
   Dong Y, 2023, IEEE T MULTIMEDIA, V25, P2698, DOI 10.1109/TMM.2022.3150180
   He SH, 2024, IEEE T MULTIMEDIA, V26, P687, DOI 10.1109/TMM.2023.3269663
   He SH, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103549
   Huang K, 2020, MULTIMED TOOLS APPL, V79, P31147, DOI 10.1007/s11042-020-09435-y
   JCT-VC, 2014, HEVC reference model HM 16.15 gitlab
   Li J, 2023, J INF SECUR APPL, V73, DOI 10.1016/j.jisa.2023.103439
   Li ZH, 2023, IEEE T DEPEND SECURE, V20, P606, DOI 10.1109/TDSC.2022.3140899
   Li ZH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11081015
   Li ZH, 2019, CMC-COMPUT MATER CON, V59, P563, DOI 10.32604/cmc.2019.05565
   Liu JD, 2022, IEEE T MULTIMEDIA, V24, P2084, DOI 10.1109/TMM.2021.3075858
   Liu YX, 2019, MULTIMED TOOLS APPL, V78, P6459, DOI 10.1007/s11042-018-6320-y
   Qin CA, 2022, J INF SECUR APPL, V68, DOI 10.1016/j.jisa.2022.103252
   [盛琪 Sheng Qi], 2017, [光电子·激光, Journal of Optoelectronics·Laser], V28, P433
   Yang L, 2023, J INF SECUR APPL, V73, DOI 10.1016/j.jisa.2023.103442
   Yang YY, 2019, MULTIMED TOOLS APPL, V78, P8423, DOI 10.1007/s11042-018-6859-7
   Zhai LM, 2020, IEEE T INF FOREN SEC, V15, P1762, DOI 10.1109/TIFS.2019.2949428
   Zhang H., 2014, P 2 ACM WORKSH INF H, P115
   Zhang ZZ, 2021, EURASIP J IMAGE VIDE, V2021, DOI 10.1186/s13640-021-00547-5
NR 21
TC 1
Z9 1
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 103995
DI 10.1016/j.jvcir.2023.103995
EA DEC 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD0O1
UT WOS:001129978000001
DA 2024-07-18
ER

PT J
AU Yu, Y
   Pu, FL
   Chen, HJ
   Tang, R
   Li, JW
   Xu, X
AF Yu, Yao
   Pu, Fangling
   Chen, Hongjia
   Tang, Rui
   Li, Jinwen
   Xu, Xin
TI Night vision self-supervised Reflectance-Aware Depth Estimation based on
   reflectance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular depth estimation; Reflectance extraction; Night vision
ID RECONSTRUCTION
AB The depth estimation of nighttime images is a challenging problem due to the lack of accurate ground-truth depth labels. Although various self-supervised methods leveraging texture information have been proposed to solve the problem, the performance is still not satisfactory due to the imaging limitations of visible cameras. To this end, we propose a self-supervised Reflectance-Aware Depth Estimation approach based on reflectance for nighttime images. Two major factors strengthen the proposed approach: a Reflectance Extraction Network and a feature consistency loss. We introduce the Reflectance Extraction Network to extract texture information based on the finding that the texture is beneficial for depth estimation. Then, we utilize the feature consistency loss to help the baseline network to learn the intrinsic feature rather than the images' light. Experiment results on the challenging Oxford RobotCar dataset confirm the robustness and effectiveness of our approach.
C1 [Yu, Yao; Pu, Fangling; Chen, Hongjia; Tang, Rui; Li, Jinwen; Xu, Xin] Wuhan Univ, Elect Informat Sch, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Pu, FL (corresponding author), Wuhan Univ, Elect Informat Sch, Wuhan 430079, Peoples R China.
EM flpu@whu.edu.cn
FU National Key Research and Devel-opment Program of China [2022YFC3331202]
FX This work was supported by the National Key Research and Devel-opment
   Program of China (Grant No. 2022YFC3331202) .
CR [Anonymous], 2023, ARXIV
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Guizilini V, 2020, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR42600.2020.00256
   Han D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111729
   He L, 2021, NEUROCOMPUTING, V440, P251, DOI 10.1016/j.neucom.2021.01.126
   Hu JJ, 2019, IEEE I CONF COMP VIS, P3868, DOI 10.1109/ICCV.2019.00397
   Johnston A, 2020, PROC CVPR IEEE, P4755, DOI 10.1109/CVPR42600.2020.00481
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee JH, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103459
   Lengyel A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4379, DOI 10.1109/ICCV48922.2021.00436
   Levinson J, 2011, IEEE INT VEH SYM, P163, DOI 10.1109/IVS.2011.5940562
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604
   Liu LN, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12717, DOI 10.1109/ICCV48922.2021.01250
   Lo CC, 2021, IEEE IMAGE PROC, P3343, DOI 10.1109/ICIP42928.2021.9506550
   Long JY, 2022, LECT NOTES COMPUT SC, V13338, P166, DOI 10.1007/978-3-031-06794-5_14
   Lu YW, 2021, IEEE WINT CONF APPL, P3832, DOI 10.1109/WACV48630.2021.00388
   Lyu X., 2020, ARXIV
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Mullapudi RT, 2018, PROC CVPR IEEE, P8080, DOI 10.1109/CVPR.2018.00843
   Pan HL, 2016, NEUROCOMPUTING, V175, P644, DOI 10.1016/j.neucom.2015.10.104
   Park S, 2017, IEEE T CONSUM ELECTR, V63, P178, DOI 10.1109/TCE.2017.014847
   Sharma A, 2020, INT CONF 3D VISION, P23, DOI 10.1109/3DV50981.2020.00012
   Shi P., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.03860
   Spencer Jaime, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14390, DOI 10.1109/CVPR42600.2020.01441
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Tian Y, 2015, NEUROCOMPUTING, V156, P96, DOI 10.1016/j.neucom.2014.12.081
   van Dijk T, 2019, IEEE I CONF COMP VIS, P2183, DOI 10.1109/ICCV.2019.00227
   Vankadari Madhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P443, DOI 10.1007/978-3-030-58604-1_27
   Wang HX, 2021, NEUROCOMPUTING, V421, P340
   Wang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16035, DOI 10.1109/ICCV48922.2021.01575
   Wang LJ, 2020, PROC CVPR IEEE, P538, DOI 10.1109/CVPR42600.2020.00062
   Wang Q, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2023.103753
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson J, 2019, IEEE I CONF COMP VIS, P2162, DOI 10.1109/ICCV.2019.00225
   Wen L, 2022, NEUROCOMPUTING, V489, P255, DOI 10.1016/j.neucom.2021.08.155
   Xie HZ, 2021, NEUROCOMPUTING, V463, P444, DOI 10.1016/j.neucom.2021.07.089
   Ye XC, 2020, NEUROCOMPUTING, V396, P76, DOI 10.1016/j.neucom.2020.02.044
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Yuan W., 2022, ARXIV
   Zhao CQ, 2022, IEEE T EM TOP COMP I, V6, P1237, DOI 10.1109/TETCI.2022.3182360
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zhou JS, 2019, IEEE I CONF COMP VIS, P6871, DOI 10.1109/ICCV.2019.00697
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhu A, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR INDUSTRIES (AI4I 2020), P1, DOI 10.1109/AI4I49448.2020.00007
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 50
TC 0
Z9 0
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103962
DI 10.1016/j.jvcir.2023.103962
EA OCT 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z1DC8
UT WOS:001109546100001
DA 2024-07-18
ER

PT J
AU Qi, HT
   Guo, X
   Xin, HL
   Li, SY
   Chen, EQ
AF Qi, Hantao
   Guo, Xin
   Xin, Hualei
   Li, Songyang
   Chen, Enqing
TI Comprehensive receptive field adaptive graph convolutional networks for
   action recognition*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Graph convolutional network; Receptive field; Temporal covariance
   pooling; Attention
AB Action recognition has shown a broad prospect for application in human-computer interaction and autonomous vehicles. According to skeleton data being lightweight and robust to environmental disturbance, skeleton-based methods are increasingly used in action recognition. Existing Graph Convolutional Networks (GCNs) have limitations such as Global Average Pooling (GAP) causing information oversmoothing, attention mechanism increasing computational complexity, and fixed spatial configuration partition strategy limiting flexibility. Our model overcomes these limitations by incorporating Temporal Covariance Pooling (TCP) for better feature utilization, Sample-Shared attention for weight sharing, and a Comprehensive Receptive Field strategy for optimal joint connections. Experiments show that the recognition accuracy of our model outperforms baseline 2s-AGCN by 1.1 % and 0.7 % under X-Sub and X-View for NTU RGB + D dataset, 1.8 % and 1.9 % in X-Sub and X-Set for NTU RGB + D 120 dataset, and 1.6 % on Kinetics-Skeleton dataset.
C1 [Qi, Hantao; Guo, Xin; Xin, Hualei; Li, Songyang; Chen, Enqing] Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou, Peoples R China.
C3 Zhengzhou University
RP Guo, X; Chen, EQ (corresponding author), Zhengzhou Univ, Sch Elect & Informat Engn, Zhengzhou, Peoples R China.
EM iexguo@zzu.edu.cn; ieeqchen@zzu.edu.cn
FU National Natural Science Foundation of China [62101503, 62101505]; Henan
   Science and Technology Research Project [222102210102]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 62101503 and 62101505, and Henan
   Science and Technology Research Project under Grants 222102210102.
CR Banerjee A, 2021, IEEE T CIRC SYST VID, V31, P2206, DOI 10.1109/TCSVT.2020.3019293
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Firat Orhan, 2016, P 2016 C N AM CHAPT, P866
   Gao ZL, 2021, ADV NEUR IN
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Kipf TN, 2017, INT C LEARN REPR
   Li B, 2017, IEEE INT C COMPUT, P187, DOI 10.1109/CSE-EUC.2017.217
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li L., 2021, 3D Human Action Representation Learning via Cross-View Consistency Pursuit, P4739, DOI [10.1109/CVPR46437.2021.00471, DOI 10.1109/CVPR46437.2021.00471]
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li SJ, 2021, IEEE ROBOT AUTOM LET, V6, P1028, DOI 10.1109/LRA.2021.3056361
   Li W, 2017, IEEE I CONF COMP VIS, P1453, DOI 10.1109/ICCV.2017.161
   Li YS, 2019, IEEE INT CON MULTI, P1066, DOI 10.1109/ICME.2019.00187
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Mankoff KD, 2013, EARTH SURF PROC LAND, V38, P926, DOI 10.1002/esp.3332
   Niepert M, 2016, PR MACH LEARN RES, V48
   Patsadu O., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P28, DOI 10.1109/JCSSE.2012.6261920
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Ren B, 2024, Arxiv, DOI arXiv:2002.05907
   Shi L., 2019, P IEEE CVF C COMP VI, P7912
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Sun ZH, 2023, IEEE T PATTERN ANAL, V45, P3200, DOI 10.1109/TPAMI.2022.3183112
   Tang YC, 2023, PRECIS AGRIC, V24, P1183, DOI 10.1007/s11119-023-10009-9
   Tang YC, 2023, ENG STRUCT, V274, DOI 10.1016/j.engstruct.2022.115158
   Tang YC, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118573
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xiaolu Ding, 2020, ICIAI 2020: Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence, P130, DOI 10.1145/3390557.3394129
   Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
NR 36
TC 0
Z9 0
U1 2
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103953
DI 10.1016/j.jvcir.2023.103953
EA OCT 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X5DD1
UT WOS:001098644500001
DA 2024-07-18
ER

PT J
AU Jishnu, CR
   Vishnukumar, S
AF Jishnu, C. R.
   Vishnukumar, S.
TI Multi exposure image fusion based on exposure correction and input
   refinement using limited low dynamic range images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Exposure value; Multi -exposure image fusion; Intermediate Exposure
   Stack; Input refinement; Recursive filter; Fast -guided filter
ID QUALITY ASSESSMENT; DENSE SIFT; ALGORITHM
AB Multi-Exposure Image Fusion (MEF) is an image processing technique that combines several images taken at various exposure levels into one high-quality image. The generation of artifacts and diminished perceptual quality of the fused image under few input images is an inevitable problem in MEF approaches. Although numerous MEF techniques have been proposed in the literature, little effort has been devoted to generate high quality fused images with minimal input images. The proposed work unveils a method for producing a fused image that exhibits superior visual quality with a minimum of two input images. The proposed work begins with refining the input images using an exposure correction strategy and a recursive filter. The refined images along with a selected exposure corrected image form an intermediate exposure stack. A weight map is constructed from the intermediate exposure stack using a set of weighting terms and a fast-guided filter is used to prevent the weight maps from being distorted by external anomalies. Finally, the fusion is performed using the pyramidal decomposition of weight maps and intermediate images. The resultant fused images obtained have been tested and proven to hold superior performance over the state-of-the-art methods in perceptual and empirical analysis. Benefiting from this approach is a framework that seeks fewer input images, an intermediate exposure stack, and a detail-enriched fused image.
C1 [Jishnu, C. R.; Vishnukumar, S.] Cochin Univ Sci & Technol, Dept Comp Applicat, Kochi 682022, Kerala, India.
C3 Cochin University Science & Technology
RP Jishnu, CR (corresponding author), Cochin Univ Sci & Technol, Dept Comp Applicat, Kochi 682022, Kerala, India.
EM wwwjishnu2008@gmail.com
RI S, Vishnukumar/Y-1739-2018
OI S, Vishnukumar/0000-0002-6464-8418
CR [Anonymous], MVA
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Fang YM, 2020, IEEE T IMAGE PROCESS, V29, P1127, DOI 10.1109/TIP.2019.2940678
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hanmandlu M, 2009, IEEE T INSTRUM MEAS, V58, P2867, DOI 10.1109/TIM.2009.2016371
   Hayat N, 2020, MULTIMED TOOLS APPL, V79, P25067, DOI 10.1007/s11042-020-09190-0
   Hayat N, 2019, J VIS COMMUN IMAGE R, V62, P295, DOI 10.1016/j.jvcir.2019.06.002
   He KM, 2015, Arxiv, DOI [arXiv:1505.00996, DOI 10.48550/ARXIV.1505.00996]
   Hu J, 2013, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2013.154
   Huang F, 2018, IEEE ACCESS, V6, P42877, DOI 10.1109/ACCESS.2018.2859355
   Huo Y.Q., 2016, SINGLE IMAGE BASED H, P1
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Kai Zeng, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P7, DOI 10.1109/QoMEX.2014.6982278
   Karakaya D, 2022, INT CONF ACOUST SPEE, P2345, DOI 10.1109/ICASSP43922.2022.9746779
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Lee SH, 2018, IEEE IMAGE PROC, P1737, DOI 10.1109/ICIP.2018.8451153
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P5805, DOI 10.1109/TIP.2020.2987133
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Ma KD, 2018, IEEE T COMPUT IMAG, V4, P60, DOI 10.1109/TCI.2017.2786138
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Rajalingam B., 2018, Int. J. Eng. Sci. Invent., V2, P52
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Reinhard E., 2010, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Wang QT, 2020, IEEE T CIRC SYST VID, V30, P2418, DOI 10.1109/TCSVT.2019.2919310
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Zhang Q, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P582, DOI 10.1145/3240508.3240595
   Zhang Q, 2019, COMPUT GRAPH FORUM, V38, P243, DOI 10.1111/cgf.13833
   Zhang XC, 2021, INFORM FUSION, V74, P111, DOI 10.1016/j.inffus.2021.02.005
NR 47
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103907
DI 10.1016/j.jvcir.2023.103907
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R2AU8
UT WOS:001062426400001
DA 2024-07-18
ER

PT J
AU Ye, ZY
   Lan, CD
   Zou, M
   Qiu, X
   Chen, J
AF Ye, Zhiyang
   Lan, Chengdong
   Zou, Min
   Qiu, Xu
   Chen, Jian
TI CCA-FPN: Channel and content adaptive object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature pyramid network; Object detection; Channel and content adaptive;
   Feature enhancement module
AB Feature pyramid network (FPN) is a typical detector commonly for solving the issue of object detection at different scales. However, the lateral connections in FPN lead to the loss of feature information due to the reduction of feature channels. Moreover, the top-down feature fusion will weaken the feature representation in the process of feature delivery because of features with different semantic information. In this paper, we propose a feature pyramid network with channel and content adaptive feature enhancement module (CCA-FPN), which uses a channel adaptive guided mechanism module (CAGM) and multi-scale content adaptive feature enhancement module (MCAFEM) to alleviate these problems. We conduct comprehensive experiments on the MS COCO dataset. By replacing FPN with CCA-FPN in ATSS, our models achieve 1.3 percentage points higher Average Precision (AP) when using ResNet50 as backbone. Furthermore, our CCA-FPN achieves 0.3 percentage points higher than the AugFPN which is the state-of-the-art FPN-based detector.
C1 [Ye, Zhiyang; Lan, Chengdong; Zou, Min; Qiu, Xu] Fuzhou Univ, Sch Adv Mfg, Quanzhou 362200, Fujian, Peoples R China.
   [Lan, Chengdong] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Fujian, Peoples R China.
   [Lan, Chengdong] Fuzhou Univ, Key Lab Intelligent Proc & Wireless Transmiss Medi, Fuzhou 350108, Fujian, Peoples R China.
C3 Fuzhou University; Fuzhou University; Fuzhou University
RP Lan, CD (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Fujian, Peoples R China.
EM lancd@fzu.edu.cn
FU National Natural Science Foundation of China [62001117, 62171134]
FX This work is supported by the National Natural Science Foundation of
   China (No. 62001117 and No. 62171134).
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Cao JX, 2020, Arxiv, DOI [arXiv:2005.11475, DOI 10.48550/ARXIV.2005.11475]
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen Z, 2018, LECT NOTES COMPUT SC, V11212, P74, DOI 10.1007/978-3-030-01237-3_5
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3183022
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3149780
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   De Brabandere B, 2016, ADV NEUR IN, V29
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu XP, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103609
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Girshick Ross, 2018, Detectron
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jin WG, 2020, PR MACH LEARN RES, V119
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X., 2019, ARXIV
   Li X., 2020, ADV NEURAL INF PROCE, V33, P21002, DOI DOI 10.48550/ARXIV.2006.04388
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2019, Arxiv, DOI arXiv:1911.09516
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo YH, 2022, MULTIMED TOOLS APPL, V81, P30685, DOI 10.1007/s11042-022-11940-1
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Maas A.L., 2013, P 30 INT C MACH LEAR, V30, P3
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514, DOI 10.48550/ARXIV.1807.06514]
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3500, DOI 10.1109/ICCV48922.2021.00350
   Xu FQ, 2022, NEURAL COMPUT APPL, V34, P14881, DOI 10.1007/s00521-022-07264-8
   Xu FQ, 2021, NEURAL COMPUT APPL, V33, P3637, DOI 10.1007/s00521-020-05217-7
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
   Zou XY, 2020, Arxiv, DOI arXiv:2008.09604
NR 55
TC 1
Z9 1
U1 15
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103903
DI 10.1016/j.jvcir.2023.103903
EA AUG 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R5DT1
UT WOS:001064560500001
DA 2024-07-18
ER

PT J
AU Zhang, GQ
   Chen, C
   Chen, YH
   Zhang, HW
   Zheng, YH
AF Zhang, Guoqing
   Chen, Chao
   Chen, Yuhao
   Zhang, Hongwei
   Zheng, Yuhui
TI Transformer-based global-local feature learning model for occluded
   person re-identification1
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Occluded person re-identification; Vision transformer; Feature fusion
ID REIDENTIFICATION
AB Most recent occluded person re-identification (re-ID) methods usually learn global features directly from pedestrian images, or use additional pose estimation and semantic analysis model to learn local features, while ignoring the relationship between global and local features, thus incorrectly retrieving different pedestrians with similar attributes as the same pedestrian. Moreover, learning local features using auxiliary models brings additional computational cost. In this work, we propose a Transformer-based dual-branch feature learning model for occluded person re-ID. Firstly, we propose a global-local feature interaction module to learn the relationship between global and local features, thus enhancing the richness of information in pedestrian features. Secondly, we randomly erase local areas in the input image to simulate the real occlusion situation, thereby improving the model's adaptability to the occlusion scene. Finally, a spilt group module is introduced to explore the local distinguishing features of pedestrian. Numerous experiments validate the effectiveness of our proposed method.
C1 [Zhang, Guoqing; Chen, Chao; Chen, Yuhao; Zhang, Hongwei; Zheng, Yuhui] Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.
   [Zhang, Guoqing] Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Social, Nanjing 210094, Peoples R China.
C3 Nanjing University of Information Science & Technology; Chinese Academy
   of Sciences; University of Science & Technology of China, CAS
RP Zhang, GQ (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp Sci, Nanjing 210044, Peoples R China.; Zhang, GQ (corresponding author), Univ Sci & Technol, Jiangsu Key Lab Image & Video Understanding Social, Nanjing 210094, Peoples R China.
EM xiayang14551@163.com; chenchao19962020@163.com
RI zhang, guoqing/GXG-4800-2022; Zhang, Hongwei/IAR-6558-2023
OI Zhang, Hongwei/0000-0002-0646-176X
FU National Natural Science Foun-dation of China [U22B2056, U20B2065,
   BK20220107]; Natural Science Foundation of Jiangsu Province of China
   [BK20211539];  [62172231]
FX This research was supported by the National Natural Science Foun-dation
   of China under Grant 62172231, U22B2056 and U20B2065; and by the Natural
   Science Foundation of Jiangsu Province of China under Grant BK20220107
   and BK20211539.
CR Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen YH, 2022, NEUROCOMPUTING, V494, P171, DOI 10.1016/j.neucom.2022.04.081
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng X., 2022, ACM INT C MULTIMEDIA
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hou RB, 2022, IEEE T PATTERN ANAL, V44, P4894, DOI 10.1109/TPAMI.2021.3079910
   Huang HJ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102789
   Jia MX, 2023, IEEE T MULTIMEDIA, V25, P1294, DOI 10.1109/TMM.2022.3141267
   Kim M, 2022, INT CONF ACOUST SPEE, P2719, DOI 10.1109/ICASSP43922.2022.9746734
   Lanchantin J, 2021, PROC CVPR IEEE, P16473, DOI 10.1109/CVPR46437.2021.01621
   Li Y., 2022, P IEEE CVF C COMP VI, P4804
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Luo WJ, 2016, ADV NEUR IN, V29
   Meng Lingchen, 2022, P IEEE CVF C COMP VI, P12309
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Shi D., 2022, IEEE C COMPUT VIS PA, P11069
   Si TZ, 2023, NEUROCOMPUTING, V523, P170, DOI 10.1016/j.neucom.2022.12.042
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Tan HC, 2023, IEEE T NEUR NET LEAR, V34, P8210, DOI 10.1109/TNNLS.2022.3144163
   Tan Lei, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P531, DOI 10.1145/3503161.3547764
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang P., 2022, IEEE Transactions on Multimedia
   Wang SJ, 2022, INFORM SCIENCES, V606, P669, DOI 10.1016/j.ins.2022.05.077
   Wang T, 2022, AAAI CONF ARTIF INTE, P2540
   Wang ZK, 2022, PROC CVPR IEEE, P4744, DOI 10.1109/CVPR52688.2022.00471
   Wu CY, 2022, PROC CVPR IEEE, P13577, DOI 10.1109/CVPR52688.2022.01322
   Wu JL, 2023, NEUROCOMPUTING, V518, P155, DOI 10.1016/j.neucom.2022.11.009
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Xu BQ, 2022, IEEE T IMAGE PROCESS, V31, P4651, DOI 10.1109/TIP.2022.3186759
   Yang JR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11865, DOI 10.1109/ICCV48922.2021.01167
   Yang Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164431
   Yang Z, 2022, PROC CVPR IEEE, P18134, DOI 10.1109/CVPR52688.2022.01762
   Ye P., 2022, INT C COMPUTER APPL
   Yongqiang Mou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P158, DOI 10.1007/978-3-030-58555-6_10
   Zhang G., 2021, IJCAI, P1295
   Zhang GQ, 2023, INFORM SCIENCES, V633, P70, DOI 10.1016/j.ins.2023.02.016
   Zhang GQ, 2022, IEEE T CIRC SYST VID, V32, P6766, DOI 10.1109/TCSVT.2022.3169422
   Zhang GQ, 2022, NEUROCOMPUTING, V486, P93, DOI 10.1016/j.neucom.2022.02.051
   Zhang GQ, 2021, IEEE T IMAGE PROCESS, V30, P8913, DOI 10.1109/TIP.2021.3120054
   Zhang GQ, 2021, INFORM SCIENCES, V578, P525, DOI 10.1016/j.ins.2021.07.058
   Zhang Guoqing, 2023, IEEE T CIRCUITS SYST, P2
   Zhang GW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P516, DOI 10.1145/3474085.3475202
   Zhang HW, 2022, IEEE T CIRC SYST VID, V32, P8599, DOI 10.1109/TCSVT.2022.3194084
   Zheng KC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4537, DOI 10.1145/3474085.3475610
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhu K, 2024, Arxiv, DOI arXiv:2104.00921
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 52
TC 2
Z9 2
U1 12
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103898
DI 10.1016/j.jvcir.2023.103898
EA AUG 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P8UN2
UT WOS:001053369800001
DA 2024-07-18
ER

PT J
AU Feng, LL
   Song, KC
   Wang, JY
   Yan, YH
AF Feng, Liangliang
   Song, Kechen
   Wang, Junyi
   Yan, Yunhui
TI Exploring the potential of Siamese network for RGBT object tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGBT tracking; Siamese network; Multi-modal fusion; Attention mechanisms
ID ROBUST
AB Siamese tracking is one of the most promising object tracking methods today due to its balance of performance and speed. However, it still performs poorly when faced with some challenges such as low light or extreme weather. This is caused by the inherent limitations of visible images, and a common way to cope with it is to introduce infrared data as an aid to improve the robustness of tracking. However, most of the existing RGBT trackers are variants of MDNet (Hyeonseob Nam and Bohyung Han, Learning multi-domain convolutional neural networks for visual tracking, in: Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 4293-4302.), which have significant limitations in terms of operational efficiency. On the contrary, the potential of Siamese tracking in the field of RGBT tracking has not been effectively exploited due to the reliance on large-scale training data. To solve this dilemma, in this paper, we propose an end-to-end Siamese RGBT tracking framework that is based on cross-modal feature enhancement and self-attention (SiamFEA). We draw on the idea of migration learning and employ local fine-tuning to reduce the dependence on large-scale RGBT data and verify the feasibility of this approach, and then we propose a reliable fusion approach to efficiently fuse the features of different modalities. Specifically, we first propose a cross-modal feature enhancement module to exploit the complementary properties of dual-modality, followed by capturing non-local attention in channel and spatial dimensions for adaptive weighted fusion, respectively. Our network was trained end-to-end on the LasHeR (Chenglong Li, Wanlin Xue, Yaqing Jia, Zhichen Qu, Bin Luo, Jin Tang, LasHeR: A Large-scale High -diversity Benchmark for RGBT Tracking, CoRR abs/2104.13202, 2021) training set and reached new SOTAs on GTOT (C. Li, H. Cheng, S. Hu, X. Liu, J. Tang, L. Lin, Learning collaborative sparse representation for grayscale-thermal tracking, IEEE Trans. Image Process, 25 (12) (2016) 5743-5756.), RGBT234 (C. Li, X. Liang, Y. Lu, N. Zhao, and J. Tang, "Rgb-t object tracking: Benchmark and baseline," Pattern Recognition, vol. 96, p. 106977, 2019.), and LasHeR (Chenglong Li, Wanlin Xue, Yaqing Jia, Zhichen Qu, Bin Luo, Jin Tang, LasHeR: A Large-scale High-diversity Benchmark for RGBT Tracking, CoRR abs/2104.13202, 2021) while running in real-time.
C1 [Feng, Liangliang; Song, Kechen; Yan, Yunhui] Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
   [Feng, Liangliang; Song, Kechen; Yan, Yunhui] Northeastern Univ, Natl Frontiers Sci Ctr Ind Intelligence & Syst Opt, Shenyang 110819, Peoples R China.
   [Feng, Liangliang; Song, Kechen; Yan, Yunhui] Northeastern Univ, Key Lab Data Analyt & Optimizat Smart Ind, Minist Educ, Shenyang, Peoples R China.
   [Wang, Junyi] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110819, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   Northeastern University - China; Northeastern University - China
RP Song, KC; Yan, YH (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
EM songkc@me.neu.edu.cn; yanyh@mail.neu.edu.cn
RI Feng, Liangliang/IAN-8223-2023; wang, junyi/GYA-3213-2022; Song,
   Kechen/T-1896-2019
OI Song, Kechen/0000-0002-7636-3460
FU National Natural Science Foundation of China [51805078]; Fundamental
   Research Funds for the Central Universities [N2103011]; Central Guidance
   on Local Science and Technology Development Fund [2022JH6/100100023];
   111 Project [B16009]
FX Acknowledgment This work was supported by the National Natural Science
   Foundation of China (51805078) , the Fundamental Research Funds for the
   Central Universities (N2103011) , the Central Guidance on Local Science
   and Technology Development Fund (2022JH6/100100023) , and the 111
   Project (B16009) .
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chenglong Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P222, DOI 10.1007/978-3-030-58542-6_14
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Feng MZ, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102881
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao Y, 2019, P IEEE INT C COMPUTE
   Guo C, 2022, VISUAL COMPUT, V38, P2555, DOI 10.1007/s00371-021-02131-4
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou Y, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103746
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jing Y., 2023, P IEEECVF C COMPUTER
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li C., 2016, P 22 INT C MULTIMEDI, P54
   Li C., 2021, arXiv, DOI DOI 10.1109/TIP.2021.3130533
   Li CL, 2019, IEEE INT CONF COMP V, P2262, DOI 10.1109/ICCVW.2019.00279
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li CL, 2017, IEEE T SYST MAN CY-S, V47, P673, DOI 10.1109/TSMC.2016.2627052
   Li CL, 2016, IEEE T IMAGE PROCESS, V25, P5743, DOI 10.1109/TIP.2016.2614135
   Li WS, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103687
   Li Z., 2021, J VIS COMMUN IMAGE R, V77
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2022, P ADV NEUR INF PROC
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu AD, 2022, Arxiv, DOI arXiv:2011.07188
   Lu AD, 2021, IEEE T IMAGE PROCESS, V30, P5613, DOI 10.1109/TIP.2021.3087341
   Luo CW, 2019, INFRARED PHYS TECHN, V99, P265, DOI 10.1016/j.infrared.2019.04.017
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Song K., 2022, IEEEASME T MECHATRON
   Song KC, 2023, ENG APPL ARTIF INTEL, V120, DOI 10.1016/j.engappai.2023.105919
   Song KC, 2023, IEEE T CIRC SYST VID, V33, P3104, DOI 10.1109/TCSVT.2022.3233131
   Tan K, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103299
   Tu ZZ, 2022, IEEE T IMAGE PROCESS, V31, P85, DOI 10.1109/TIP.2021.3125504
   Wang C., 2020, 2020 IEEE/CVF Conf. on Computer Vision and Pattern Recognition Workshops (CVPRW)
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xu Q, 2022, IEEE T MULTIMEDIA, V24, P567, DOI 10.1109/TMM.2021.3055362
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Yang X., 2022, Advances in Neural Information Processing Systems, V35, P25739
   Yang Xingyi, 2023, IEEECVF C COMPUTER V
   Yang Z, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103465
   Yongqiang W.u., 2023, J VIS COMMUN IMAGE R, V91
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Yun X., 2019, MATH PROBL ENG, V2019
   Zhang H., 2022, J VIS COMMUN IMAGE R, V89
   Zhang H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020393
   Zhang LC, 2019, IEEE INT CONF COMP V, P2252, DOI 10.1109/ICCVW.2019.00278
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang PY, 2021, INT J COMPUT VISION, V129, P2714, DOI 10.1007/s11263-021-01495-3
   Zhang PY, 2021, IEEE T IMAGE PROCESS, V30, P3335, DOI 10.1109/TIP.2021.3060862
   Zhang T., 2021, IEEE T CIRC SYST VID, V99, P1
   Zhang XC, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2019.115756
   Zhang XC, 2019, IEEE ACCESS, V7, P122122, DOI 10.1109/ACCESS.2019.2936914
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu YB, 2021, IEEE T INTELL VEHICL, V6, P121, DOI 10.1109/TIV.2020.2980735
   Zhu YB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P465, DOI 10.1145/3343031.3350928
NR 66
TC 1
Z9 1
U1 4
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103882
DI 10.1016/j.jvcir.2023.103882
EA JUN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N0QG6
UT WOS:001034159100001
DA 2024-07-18
ER

PT J
AU Kommanduri, R
   Ghorai, M
AF Kommanduri, Rangachary
   Ghorai, Mrinmoy
TI Bi-READ: Bi-Residual AutoEncoder based feature enhancement for video
   anomaly detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomaly; Residual connections; Optical flow; Unsupervised learning;
   Appearance consistency; Motion consistency
ID EVENT DETECTION
AB Video anomaly detection (VAD) refers to identifying abnormal events in the surveillance video. Typically, reconstruction based video anomaly detection techniques employ convolutional autoencoders with a limited number of layers, which extracts insufficient features leading to improper network training. To address this challenge, an end-to-end unsupervised feature enhancement network, namely Bi-Residual Convolutional AutoEncoder (Bi-ResCAE) has been proposed that can learn normal events with low reconstruction error and detect anomalies with high reconstruction error. The proposed Bi-ResCAE network incorporates long-short residual connections to enhance feature reusability and training stabilization. In addition, we propose to formulate a novel VAD model that can extract appearance and motion features by fusing both the Bi-ResCAE network and optical flow network in the objective function to recognize the anomalous object in the video. Extensive experiments on three benchmark datasets validate the effectiveness of the model. The proposed model achieves an AUC (Area Under the ROC Curve) of 84.7% on Ped1, 97.7% on Ped2, and 86.71% on the Avenue dataset. The results show that the Bi-READ performs better than state-of-the-art techniques.
C1 [Kommanduri, Rangachary; Ghorai, Mrinmoy] Indian Inst Informat Technol, Comp Vis Grp, 630,Gnan marg circle, Sri City 517646, Andhra Pradesh, India.
RP Kommanduri, R (corresponding author), Indian Inst Informat Technol, Comp Vis Grp, 630,Gnan marg circle, Sri City 517646, Andhra Pradesh, India.
EM rangachary.k@iiits.in; mrinmoy.ghorai@iiits.in
CR Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Biswas S, 2017, MACH VISION APPL, V28, P35, DOI 10.1007/s00138-016-0800-8
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Fan ZY, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103508
   Fang ZJ, 2016, MULTIMED TOOLS APPL, V75, P14617, DOI 10.1007/s11042-016-3316-3
   Feng YC, 2017, NEUROCOMPUTING, V219, P548, DOI 10.1016/j.neucom.2016.09.063
   Ganokratanaa T, 2022, PATTERN RECOGN LETT, V155, P143, DOI 10.1016/j.patrec.2021.11.001
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Guansong Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12170, DOI 10.1109/CVPR42600.2020.01219
   Guo AB, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104391
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu X, 2018, EURASIP J ADV SIG PR, DOI 10.1186/s13634-018-0574-4
   Hu X, 2014, SCI WORLD J, DOI 10.1155/2014/632575
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Li DH, 2022, PATTERN RECOGN LETT, V156, P183, DOI 10.1016/j.patrec.2022.03.004
   Li J, 2022, IEEE T IMAGE PROCESS, V31, P275, DOI 10.1109/TIP.2021.3130545
   Li NJ, 2021, IEEE T MULTIMEDIA, V23, P203, DOI 10.1109/TMM.2020.2984093
   Li NN, 2015, NEUROCOMPUTING, V155, P309, DOI 10.1016/j.neucom.2014.12.064
   Li T, 2021, NEUROCOMPUTING, V439, P256, DOI 10.1016/j.neucom.2021.01.097
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, IEEE T PATTERN ANAL, V43, P1070, DOI 10.1109/TPAMI.2019.2944377
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Mathieu M, 2016, Arxiv, DOI arXiv:1511.05440
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Park C., 2022, P IEEECVF WINTER C A, P2249
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Reddy V., 2011, Computer Vision and Pattern Recognition Workshops (CVPRW), 2011 IEEE Computer Society Conference on, P55
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Ruchika, 2022, MULTIMED TOOLS APPL, V81, P5259, DOI 10.1007/s11042-021-11781-4
   Sabih M, 2022, EXPERT SYST APPL, V192, DOI 10.1016/j.eswa.2021.116394
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Sikdar A, 2020, NEUROCOMPUTING, V415, P317, DOI 10.1016/j.neucom.2020.07.058
   Su Yang, 2011, Proceedings of the 2011 IEEE International Conference on Internet of Things and 4th IEEE International Conference on Cyber, Physical and Social Computing (iThings/CPSCom 2011), P291, DOI 10.1109/iThings/CPSCom.2011.25
   Teed Zachary, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P402, DOI 10.1007/978-3-030-58536-5_24
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Wang SQ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P636, DOI 10.1145/3240508.3240615
   Wang W., 2022, SIGNAL IMAGE VIDEO P, P1
   Wang XZ, 2022, IEEE T NEUR NET LEAR, V33, P2301, DOI 10.1109/TNNLS.2021.3083152
   Wu C., 2020, 2020 IEEE ACS 17 INT, P1
   Wu P, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107515
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Wu S, 2014, IEEE T CIRC SYST VID, V24, P85, DOI 10.1109/TCSVT.2013.2276151
   Xiao T., 2014, ASIAN C COMPUTER VIS, P66
   Yan MJ, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2019.102747
   Zhong YH, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108336
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
   Zhou W., 2022, 2022 IEEE INT C MULT, P1
NR 60
TC 5
Z9 6
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103860
DI 10.1016/j.jvcir.2023.103860
EA JUN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA L1WS1
UT WOS:001021234300001
DA 2024-07-18
ER

PT J
AU Zhang, KX
   Wang, XJ
   Chai, XL
   Shao, F
AF Zhang, Kexin
   Wang, Xuejin
   Chai, Xiongli
   Shao, Feng
TI Multi-layer and Multi-scale feature aggregation for DIBR-Synthesized
   image quality assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; DIBR-synthesized image; Distortion correction;
   BIQA
ID VIEW SYNTHESIS; GEOMETRIC DISTORTIONS; STEREOSCOPIC IMAGES; EDGE
   INTENSITY; PREDICTION; PLUS
AB Depth-Image-Based Rendering (DIBR) is one of the main fundamental techniques for generating new viewpoints in 3D video applications such as multi-viewpoint video (MVV), free viewpoint video (FVV) and virtual reality (VR). Due to the imperfections of color images, depth maps or texture restoration techniques, several types of distortions occur in synthesized views. However, most of related works evaluated the quality of DIBR-synthesized views by only detecting a specific type of distortion, such as stretching, black holes, blurring, etc., which were unable to accurately evaluate the quality of DIBR-synthesized views. In this paper, a new no-reference image quality assessment method is proposed to evaluate the quality of DIBR-synthesized images by combining multilayer and multi-scale features of images. To be specific, the distortions introduced by different stages of virtual viewpoint synthesis are first analyzed, and then multi-layer and multi-scale features are extracted to estimate the degree of texture and structure distortions. As a result, individual quality scores associated with two types of distortions (e.g., structural distortion and texture distortion) are aggregated to an overall image quality. Experimental results on two publicly available DIBR datasets show that the method has better performance than the state-of-the-art models.Index Terms: image quality assessment, DIBR-synthesized image, distortion correction, BIQA.
C1 [Zhang, Kexin; Chai, Xiongli; Shao, Feng] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
   [Wang, Xuejin] Fujian Univ Technol, Sch Comp Sci & Math, Fuzhou 350118, Peoples R China.
C3 Ningbo University; Fujian University of Technology
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
EM shaofeng@nbu.edu.cn
FU Natural Science Foundation of China [62071261]; Ningbo Natural Science
   Foundation of China [2022 J067]
FX This work was supported by the Natural Science Foundation of China
   (grant 62071261) , and Ningbo Natural Science Foundation of China (grant
   2022 J067) .
CR Ahn I, 2013, IEEE T BROADCAST, V59, P614, DOI 10.1109/TBC.2013.2281658
   [Anonymous], 2013, 3D TV SYSTEM DEPTH I, DOI DOI 10.1007/978-1-4419-9964-1_15
   [Anonymous], 2015, P IEEE TRUE VIS CAPT
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Farid MS, 2017, IEEE INT CON MULTI, P505, DOI 10.1109/ICME.2017.8019307
   Farid MS, 2015, IEEE IMAGE PROC, P3720, DOI 10.1109/ICIP.2015.7351499
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gu K, 2017, IEEE IMAGE PROC, P745, DOI 10.1109/ICIP.2017.8296380
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herzog R, 2012, COMPUT GRAPH FORUM, V31, P545, DOI 10.1111/j.1467-8659.2012.03055.x
   Jakhetiya V, 2021, IEEE T IND ELECTRON, V68, P423, DOI 10.1109/TIE.2020.2965469
   Jakhetiya V, 2019, IEEE T IND INFORM, V15, P4120, DOI 10.1109/TII.2018.2888861
   Jantet V, 2011, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2011.6115662
   Kim H, 2005, SIGNAL PROCESS-IMAGE, V20, P61, DOI 10.1016/j.image.2004.10.004
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Li LD, 2018, IEEE T MULTIMEDIA, V20, P914, DOI 10.1109/TMM.2017.2760062
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Luo GB, 2016, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2016.197
   Milani S, 2013, IEEE IMAGE PROC, P408, DOI 10.1109/ICIP.2013.6738084
   Montgomery D.C., 2010, Applied Statistics and Probability for Engineers (Edicao: 6)
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Morin L., 2012, Proc. SPIE, V8288, P557
   Muddala SM, 2016, J VIS COMMUN IMAGE R, V38, P351, DOI 10.1016/j.jvcir.2016.02.017
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2010, IEEE INT CON MULTI, P424, DOI 10.1109/ICME.2010.5583559
   Oliveira A, 2015, INT CONF ACOUST SPEE, P1186, DOI 10.1109/ICASSP.2015.7178157
   Rodrigues F, 2019, IEEE T MULTIMEDIA, V21, P1737, DOI 10.1109/TMM.2018.2888830
   Ruijters D., 2009, P 3V C TRUE VIS CAPT, P1
   Ryu S, 2014, IEEE IMAGE PROC, P585, DOI 10.1109/ICIP.2014.7025117
   Sadbhawna, 2022, IEEE T IMAGE PROCESS, V31, P2027, DOI 10.1109/TIP.2022.3147981
   Sadbhawna, 2022, IEEE T IMAGE PROCESS, V31, P1737, DOI 10.1109/TIP.2022.3145997
   Sadbhawna V., 2020, P IEEE 22 INT WORKSH, P1
   Sandic-Stankovic D, 2015, INT WORK QUAL MULTIM
   Sandic-Stankovic D, 2016, J ELECTR ENG-SLOVAK, V67, P3, DOI 10.1515/jee-2016-0001
   Shao F, 2018, IEEE T MULTIMEDIA, V20, P659, DOI 10.1109/TMM.2017.2748460
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Shao H, 2009, 3DTV CONF, P25, DOI 10.1109/3DTV.2009.5069619
   Solh M., 2011, IEEE International Conference on Multimedia and Expo (ICME), P1
   Solh M, 2012, IEEE J-STSP, V6, P495, DOI 10.1109/JSTSP.2012.2204723
   Sun C, 2012, IEEE I C EMBED SOFTW, P1391, DOI 10.1109/HPCC.2012.204
   Tanimoto M., 2008, JTC1SC29WG11 ISOIEC
   Tanimoto M, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.5
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tian SS, 2021, NEUROCOMPUTING, V423, P158, DOI 10.1016/j.neucom.2020.09.062
   Tian SS, 2019, IEEE T MULTIMEDIA, V21, P1235, DOI 10.1109/TMM.2018.2875307
   Tian SS, 2018, IEEE T IMAGE PROCESS, V27, P1652, DOI 10.1109/TIP.2017.2781420
   Tian SS, 2017, INT CONF ACOUST SPEE, P1248, DOI 10.1109/ICASSP.2017.7952356
   Wang GC, 2020, IEEE T IMAGE PROCESS, V29, P1802, DOI 10.1109/TIP.2019.2945675
   Wang XC, 2019, COMPUT VIS MEDIA, V5, P193, DOI 10.1007/s41095-019-0131-6
   Wang XJ, 2021, IEEE T MULTIMEDIA, V23, P1173, DOI 10.1109/TMM.2020.2993942
   Wang XJ, 2019, IEEE ACCESS, V7, P10242, DOI 10.1109/ACCESS.2019.2891070
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang SR, 2021, PROC CVPR IEEE, P6344, DOI 10.1109/CVPR46437.2021.00628
   Yue GH, 2019, IEEE T IMAGE PROCESS, V28, P2075, DOI 10.1109/TIP.2018.2875913
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou Y, 2018, MULTIMED TOOLS APPL, V77, P21033, DOI 10.1007/s11042-017-5543-7
   Zhou Y, 2017, IEICE T INF SYST, VE100D, P1929, DOI 10.1587/transinf.2016EDL8255
   Zhou Y, 2016, IEEE IMAGE PROC, P1012, DOI 10.1109/ICIP.2016.7532510
   Zhu C, 2016, IEEE T BROADCAST, V62, P82, DOI 10.1109/TBC.2015.2475697
   Zhu HW, 2022, AAAI CONF ARTIF INTE, P3608
NR 68
TC 2
Z9 2
U1 6
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103851
DI 10.1016/j.jvcir.2023.103851
EA MAY 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA I3VV9
UT WOS:001002099900001
DA 2024-07-18
ER

PT J
AU Li, GQ
   Liu, BW
   Chen, AB
AF Li, Guoqiang
   Liu, Bowen
   Chen, Anbang
TI DDFP:A data driven filter pruning method with pruning compensation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data driven; Model compression; Filter pruning; Pruning compensation
AB Neural network pruning techniques can be effective in accelerating neural network models, making it possible to deploy them on edge devices. In this paper, we propose to prune neural networks using data variance. Unlike other existing methods, this method is somewhat robust and does not invalidate our criteria depending on the number of data batches and the number of training sessions. We also propose a pruning compensation technique. This technique fuses the pruned convolutional information into the remaining convolutional kernel close to it. This fusion operation can effectively help retain the pruned information. We evaluate the proposed method on a number of standard datasets and compare it with several current state-of-the-art methods. Our method always achieves better performance. For example, on Tiny ImageNet, our method can prune 54.2% FLOPs of ResNet50 while obtaining a 0.22% accuracy improvement.
C1 [Li, Guoqiang; Liu, Bowen; Chen, Anbang] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066001, Peoples R China.
   [Li, Guoqiang; Liu, Bowen; Chen, Anbang] Yanshan Univ, Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066001, Peoples R China.
C3 Yanshan University; Yanshan University
RP Li, GQ (corresponding author), Yanshan Univ, Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066001, Peoples R China.
EM lig_ysu@ysu.edu.cn; liubowenLb@163.com; chenanbang1234@163.com
FU Natural Science Foundation of Hebei Province of China [F2020203003]
FX Acknowledgements This work was supported in part by the Natural Science
   Foundation of Hebei Province of China (Grant No. F2020203003) .
CR [Anonymous], 2016, PRUNING CONVOLUTIONA
   Bailin Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P639, DOI 10.1007/978-3-030-58536-5_38
   Bao YQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103306
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen PG, 2021, PROC CVPR IEEE, P5006, DOI 10.1109/CVPR46437.2021.00497
   Courbariaux M, 2015, ADV NEUR IN, V28
   Denil M., 2013, ADV NEURAL INFORM PR
   Ding XH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4490, DOI 10.1109/ICCV48922.2021.00447
   Ding XH, 2019, PROC CVPR IEEE, P4938, DOI 10.1109/CVPR.2019.00508
   Dong XY, 2017, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR.2017.205
   Fang Y, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102609
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han S, 2015, Arxiv, DOI arXiv:1506.02626
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19
   Hubara I, 2018, J MACH LEARN RES, V18
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jaderberg M, 2014, Arxiv, DOI arXiv:1405.3866
   Ji Y, 2018, ADV NEUR IN, V31
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li H, 2017, Arxiv, DOI arXiv:1608.08710
   Li TH, 2019, PROC CVPR IEEE, P3972, DOI 10.1109/CVPR.2019.00410
   Lin M, 2022, IEEE Trans. Neural Netw. Learn. Syst.
   Lin M., 2022, IEEE T PATTERN ANAL
   Lin MB, 2020, Arxiv, DOI arXiv:2001.08565
   Lin MB, 2022, IEEE T NEUR NET LEAR, V33, P7357, DOI 10.1109/TNNLS.2021.3084856
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Liu ZC, 2019, IEEE I CONF COMP VIS, P3295, DOI [10.1109/ICCV.2019.00339, 10.1109/ICCV.2019.00339D\]
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meng F, 2020, Advances in Neural Information Processing Systems, V33, P17629
   Molchanov P, 2017, Arxiv, DOI arXiv:1611.06440
   Moradi M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103259
   Paszke Adam, 2017, NIPS W
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang Q, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103260
   Wen W, 2016, ADV NEUR IN, V29
   Xiao X, 2019, ADV NEUR IN, V32
   Xuefei Ning, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P592, DOI 10.1007/978-3-030-58580-8_35
   Yang Z, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103245
   Yu JH, 2019, Arxiv, DOI arXiv:1903.11728
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y., 2022, arXiv
   Zhang Yuxin, 2022, IEEE T NEUR NET LEAR
   Zhao CL, 2019, PROC CVPR IEEE, P2775, DOI 10.1109/CVPR.2019.00289
   Zhou AJ, 2021, Arxiv, DOI arXiv:2102.04010
   Zhu MC, 2017, Arxiv, DOI arXiv:1710.01878
   Zhuang ZW, 2018, ADV NEUR IN, V31
NR 61
TC 0
Z9 0
U1 6
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103833
DI 10.1016/j.jvcir.2023.103833
EA MAY 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA M7IA6
UT WOS:001031903900001
DA 2024-07-18
ER

PT J
AU Fa, S
   Yang, XH
   Han, SY
   Feng, ZQ
   Chen, YH
AF Fa, Shuxiang
   Yang, Xiaohui
   Han, Shiyuan
   Feng, Zhiquan
   Chen, Yuehui
TI Multi-scale spatial-temporal attention graph convolutional networks for
   driver fatigue detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Driver fatigue detection Driver behavior Deep learning Graph convolution
   networks
AB With the development of deep learning, fatigue detection technology for drivers has achieved remarkable achievements. Although the image-based approach achieves good accuracy, it inevitably leads to greater model complexity, which is unsuitable for mobile terminal devices. Luckily, human skeletal data significantly reduces the impact of noise and input data volume while retaining valid information, and it can better deal with real-world driving scenarios with the benefit of robustness in complex driving situations. This paper proposes a lightweight multi-scale spatio-temporal attention graph convolutional network (MS-STAGCN) to efficiently utilize skeleton data to identify driver states by aggregating locally and globally valid face information, which achieves good performance even for lightweight design. The experimental results show that the method achieves 92.4% accuracy on the NTHU-DDD dataset, which can be applied to fatigue detection tasks of the driver in real-world driving scenarios in the future.
C1 [Yang, Xiaohui] Univ Jinan, Shandong Prov Key Lab Network Based Intelligent Co, Jinan 250022, Peoples R China.
   Univ Jinan, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
C3 University of Jinan; University of Jinan
RP Yang, XH (corresponding author), Univ Jinan, Shandong Prov Key Lab Network Based Intelligent Co, Jinan 250022, Peoples R China.
EM ise_xhyang@ujn.edu.cn
FU Shandong Provincial Natural Science Foundation [ZR2020LZH004]; National
   Natural Science Foundation of China [61603151, 6193156]; Natural Science
   Foundation of Shandong Province for Key Project [ZR2020KF006];
   University Innovation Team Project of Jinan [2019GXRC013, 2019GXRC015]
FX This work was supported by the Shandong Provincial Natural Science
   Foundation (No. ZR2020LZH004), the National Natural Science Foundation
   of China (Nos. 61603151, 6193156), the Natural Science Foundation of
   Shandong Province for Key Project (No. ZR2020KF006), and the University
   Innovation Team Project of Jinan (Nos. 2019GXRC013, 2019GXRC015).
CR Artanto D, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P235, DOI 10.1109/ICITISEE.2017.8285502
   Bai J, 2022, IEEE T CYBERNETICS, V52, P13821, DOI 10.1109/TCYB.2021.3110813
   Bener A, 2017, J TRAFFIC TRANSP ENG, V4, P496, DOI 10.1016/j.jtte.2017.07.005
   [蔡素贤 Cai Suxian], 2020, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V20, P77
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Dua M, 2021, NEURAL COMPUT APPL, V33, P3155, DOI 10.1007/s00521-020-05209-7
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Hasan MM, 2022, J SAFETY RES, V80, P215, DOI 10.1016/j.jsr.2021.12.001
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hussein Marwa K., 2021, 2021 1st Babylon International Conference on Information Technology and Science (BICITS), P45, DOI 10.1109/BICITS51482.2021.9509912
   Jamshidi S, 2021, MULTIMED TOOLS APPL, V80, P16045, DOI 10.1007/s11042-021-10542-7
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030495
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Mao HY, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422520073
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shalu B., 2020, INT J COMPUT SCI ENG, V6, P3307
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Song YF, 2021, IEEE T CIRC SYST VID, V31, P1915, DOI 10.1109/TCSVT.2020.3015051
   Song YF, 2019, IEEE IMAGE PROC, P1, DOI [10.1109/icip.2019.8802917, 10.1109/ICIP.2019.8802917, 10.1109/TFUZZ.2019.2910714]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Yan MW, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18083878
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhu TJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042224
NR 34
TC 2
Z9 2
U1 9
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103826
DI 10.1016/j.jvcir.2023.103826
EA APR 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G7EK2
UT WOS:000990745200001
DA 2024-07-18
ER

PT J
AU Wang, YF
   Yang, FZ
   Chen, Y
   Zhang, W
AF Wang, Yifan
   Yang, Fuzheng
   Chen, Ying
   Zhang, Wei
TI Virtual view synthesis using joint information from multi-view
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Virtual view synthesis; Multi-view; Virtual reality(VR); Panoramic video
ID DEPTH ESTIMATION; IMAGE; DIBR
AB Immersive media has attracted widespread attention with the development of virtual reality. Three Degree of Freedom Plus media greatly enhances the user experience by allowing users' head motion and viewpoint switching within a certain range. Due to the limitation of panoramic video acquisition and transmission, it is impossible to obtain videos from any viewpoint directly. Virtual view synthesis is the general solution to this problem. However, existing algorithms do not adequately consider the pixel correlation between multiple views. Thus, we propose a virtual view synthesis algorithm using joint information from multi-view panoramic videos to further explore the pixel correlation. Specifically, sub-pixels from different reference views in the virtual view are obtained by performing multi-view three-dimensional image warping. Dedicated area division and interpolation methods are then designed to improve the synthesized quality. Experimental results show that the proposed algorithm outperforms the state-of-the-art virtual view synthesis algorithms in performance and efficiency.
C1 [Wang, Yifan; Yang, Fuzheng; Chen, Ying; Zhang, Wei] Xidian Univ, Sch Telecommun Engn, Xian, Peoples R China.
C3 Xidian University
RP Wang, YF (corresponding author), Xidian Univ, Sch Telecommun Engn, Xian, Peoples R China.
EM yfwang_95@stu.xidian.edu.cn
FU National Science Foundation of China [61801364]; China Postdoctoral
   Science Foundation [2018M643582]; National Key Laboratory Foundation
   [6142411194215]; Fundamental Research Funds for the Central
   Universities, China [JB190116]; National Natural Science Foundation of
   Shaanxi Province, China [2019JQ-338]
FX This work was supported by the National Science Foundation of China
   under Grant 61801364, China Postdoctoral Science Foundation funded
   project 2018M643582, National Key Laboratory Foundation, China
   6142411194215, Fundamental Research Funds for the Central Universities,
   China JB190116, and National Natural Science Foundation of Shaanxi
   Province, China under Grant 2019JQ-338.
CR [Anonymous], 2017, JTC1SC29WG11 ISOIEC
   [Anonymous], 2020, JTC1SC29WG11 ISOIEC
   Badki A, 2020, PROC CVPR IEEE, P1597, DOI 10.1109/CVPR42600.2020.00167
   Boissonade P., 2019, JTC1SC29WG11 ISOIEC
   Bonatto D., 2020, ELECT IMAGING
   Ceulemans B, 2018, IEEE T MULTIMEDIA, V20, P2235, DOI 10.1109/TMM.2018.2802646
   Champel M., 2017, JTC1SC29WG11 ISOIEC
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dai J, 2017, IEEE IMAGE PROC, P1387, DOI 10.1109/ICIP.2017.8296509
   Daribo Ismael, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P167, DOI 10.1109/MMSP.2010.5662013
   de Oliveira AQ, 2018, IEEE SIGNAL PROC LET, V25, P1705, DOI 10.1109/LSP.2018.2870342
   Do Luat., 2009, Proc. 3DTV Conf, P1
   Domanski M., 2018, JTC1SC29WG11 ISOIEC
   Dore R., 2018, JTC1SC29WG11 ISOIEC
   Dziembowski A, 2016, PICT COD SYMP, DOI 10.1109/PCS.2016.7906380
   Fachada S, 2020, PROC SPIE, V11350, DOI 10.1117/12.2553069
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Frauel Y, 2004, APPL OPTICS, V43, P452, DOI 10.1364/AO.43.000452
   Furukawa Y, 2013, FOUND TRENDS COMPUT, V9, P1, DOI 10.1561/0600000052
   Gao P, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103148
   Gautier J, 2011, 3DTV CONF
   Ghorai M, 2019, IEEE T IMAGE PROCESS, V28, P5495, DOI 10.1109/TIP.2019.2920528
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Ilkoo Ahn, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P109, DOI 10.1109/ICME.2012.95
   Ilola L., 2019, JTC1SC29WG11 ISOIEC
   Jantet V, 2011, IEEE IMAGE PROC, P125, DOI 10.1109/ICIP.2011.6115662
   Jianbo Jin, 2015, 2015 IEEE International Vacuum Electronics Conference (IVEC), P1, DOI 10.1109/IVEC.2015.7223802
   Juarez E., 2020, JTC1SC29WG11 ISOIEC
   Jung CK, 2015, DISPLAYS, V40, P17, DOI 10.1016/j.displa.2015.05.006
   Jung J., 2021, JTC1SC29WG04 ISOIEC
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Kim H, 2015, DISPLAYS, V40, P24, DOI 10.1016/j.displa.2015.05.001
   Kroon B., 2018, JTC1SC29WG11 ISOIEC, P19
   Kwak S., 2019, JTC1SC29WG11 ISOIEC
   Lee G., 2019, Electronics and Telecommunications Trends, V34, P156
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]
   Lu BL, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102052
   Lu GY, 2008, COMPUT GEOSCI-UK, V34, P1044, DOI 10.1016/j.cageo.2007.07.010
   Luo GB, 2016, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2016.197
   Manap N.A., 2012, J TELECOMMUN ELECT C, V4, P51
   Mori Yuji, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P229, DOI 10.1109/3DTV.2008.4547850
   Muddala S.M., 2012, 2012 INT C 3D IM IC3, P1
   Muddala SM, 2016, J VIS COMMUN IMAGE R, V38, P351, DOI 10.1016/j.jvcir.2016.02.017
   Rana PK, 2015, IEEE J-STSP, V9, P435, DOI 10.1109/JSTSP.2014.2373331
   Salahieh B., 2020, JTC1SC29WG11 ISOIEC
   Salahieh B., 2019, JTC1SC29WG11 ISOIEC
   Salahieh B, 2018, Standard ISO/IEC JTC1/SC29/WG11 MPEG/M43748
   Sarah F., 2020, DIGITAL HOLOGRAPHY 3, pHF1D
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schuemie MJ, 2001, CYBERPSYCHOL BEHAV, V4, P183, DOI 10.1089/109493101300117884
   Seitz Steve., CVPR, V1, P519
   Senoh T., 2018, JTC1SC29WG11 ISOIEC
   Seux Christophe, 2014, CLASS ROOM BLENDER P
   Sjostrom M., 2011, 2011 3DTV C TRUE VIS, P1
   Snyder JP, 1987, Map projections-a working manual
   Snyder JP., 1993, FLATTENING EARTH 200
   Sridevi G, 2019, CIRC SYST SIGNAL PR, V38, P3802, DOI 10.1007/s00034-019-01029-w
   Thudor F., 2018, JTC1SC29WG11 ISOIEC
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Wali S, 2019, J VIS COMMUN IMAGE R, V59, P39, DOI 10.1016/j.jvcir.2018.12.047
   Wegner K., 2017, OMNIDIRECTIONAL 6 DO
   Wu SL, 2018, J VIS COMMUN IMAGE R, V57, P107, DOI 10.1016/j.jvcir.2018.10.018
   Yan B, 2013, J VIS COMMUN IMAGE R, V24, P669, DOI 10.1016/j.jvcir.2012.04.006
   Zeng JX, 2019, ARAB J SCI ENG, V44, P3549, DOI 10.1007/s13369-018-3592-5
   Zinger S, 2010, J VIS COMMUN IMAGE R, V21, P533, DOI 10.1016/j.jvcir.2010.01.004
NR 67
TC 0
Z9 0
U1 4
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103799
DI 10.1016/j.jvcir.2023.103799
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E0KU9
UT WOS:000972535400001
DA 2024-07-18
ER

PT J
AU Chen, XX
   Xu, SW
   Hu, SH
   Ma, XL
AF Chen, Xiaoxuan
   Xu, Shuwen
   Hu, Shaohai
   Ma, Xiaole
TI Image fusion based on discrete Chebyshev moments?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Attention mechanism; Chebyshev moments; Average gradient
AB Though deep learning-based methods have demonstrated strong capabilities on image fusion, they usually improve the fusion performance by increasing the width and depth of the network, increasing the compu-tational effort and being unsuitable for industrial applications. In this paper, an end-to-end network based on fixed convolution module of discrete Chebyshev moments is proposed, which does not need any pre-or post-processing. The proposed network is roughly composed of three parts: feature extraction module, fusion module and feature reconstruction module. In the feature extraction module, a novel fixed convolution module based on discrete Chebyshev moments is proposed to obtain different frequency components in a short time. To improve the image sharpness and fuse more details, a spatial attention mechanism based on average gradient is proposed in fusion module. Extensive results demonstrate that the proposed network can achieve remarkable fusion performance, high time efficiency and strong generalization ability.
C1 [Chen, Xiaoxuan; Hu, Shaohai; Ma, Xiaole] Network Technol, Beijing Key Lab Adv Informat Sci, Beijing 100000, Peoples R China.
   [Chen, Xiaoxuan; Hu, Shaohai; Ma, Xiaole] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100000, Peoples R China.
   [Xu, Shuwen] Res Inst TV & Electroacoust, Beijing 100000, Peoples R China.
C3 Beijing Jiaotong University
RP Hu, SH (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100000, Peoples R China.
EM shhu@bjtu.edu.cn
RI xu, shuwen/AFR-9340-2022
OI xu, shuwen/0000-0002-3557-5897
FU Natural Science Foundation of China [62172030]; Fundamental Research
   Funds for the Central Universities, China [2021JBM009]
FX Acknowledgments The authors would like to thank the authors who shared
   codes of image fusion and the anonymous reviewers for their insightful
   suggestions, which have greatly improved this paper. And this re-search
   was funded by Natural Science Foundation of China, grant number 62172030
   and the Fundamental Research Funds for the Central Universities, China,
   grant number 2021JBM009.
CR Budhiraja Sumit, 2021, 3 INT C SIGNAL PROCE
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Hareeta M, 2016, COMM COM INF SC, V628, P111, DOI 10.1007/978-981-10-3433-6_14
   Hill P, 2017, IEEE T IMAGE PROCESS, V26, P1076, DOI 10.1109/TIP.2016.2633863
   Jia XY, 2021, IEEE INT CONF COMP V, P3489, DOI 10.1109/ICCVW54120.2021.00389
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Lakshmipriya B., 2020, IEEE ICSCAN, P1, DOI 10.1109/ICSCAN49426.2020.9262439
   Li H, 2020, IEEE T INSTRUM MEAS, V69, P9645, DOI 10.1109/TIM.2020.3005230
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Meher B, 2019, INFORM FUSION, V48, P119, DOI 10.1016/j.inffus.2018.07.010
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Panigrahy C, 2020, APPL OPTICS, V59, P5642, DOI 10.1364/AO.391234
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Sayadi M., 2020, Iran. Conf. Mach. Vis. Image Process. MVIP, V2020, P1, DOI [10.1109/MVIP49855.2020.9116919, DOI 10.1109/MVIP49855.2020.9116919]
   Seal A, 2019, MULTIMED TOOLS APPL, V78, P30373, DOI 10.1007/s11042-019-7701-6
   Seal A, 2018, EXPERT SYST, V35, DOI 10.1111/exsy.12307
   Seal A, 2018, INT J NUMER METH BIO, V34, DOI 10.1002/cnm.2933
   Seal A, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560055
   Vanmali AV, 2017, SADHANA-ACAD P ENG S, V42, P1063, DOI 10.1007/s12046-017-0673-1
   Vishwakarma A, 2019, IEEE T INSTRUM MEAS, V68, P3367, DOI 10.1109/TIM.2018.2877285
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao B, 2021, ICCV
   Xiao B, 2016, NEUROCOMPUTING, V214, P587, DOI 10.1016/j.neucom.2016.06.050
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yap PT, 2004, IEE P-VIS IMAGE SIGN, V151, P128, DOI 10.1049/ip-vis:20040395
   Zang Y, 2021, IEEE T INSTRUM MEAS
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177
NR 34
TC 0
Z9 0
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103784
DI 10.1016/j.jvcir.2023.103784
EA FEB 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9P6TN
UT WOS:000944415500001
DA 2024-07-18
ER

PT J
AU Chang, YL
   Li, SM
   Jin, J
   Liu, AQ
   Xiang, W
AF Chang, Yongli
   Li, Sumei
   Jin, Jie
   Liu, Anqi
   Xiang, Wei
TI Stereo image quality assessment considering the difference of
   statistical feature in early visual pathway*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo image quality assessment; Retinal ganglion cells; ON and OFF
   receptive fields; Monocular and binocular features
ID RETINAL GANGLION-CELLS; RECEPTIVE-FIELDS; PATTERN; SIZE
AB Human visual theory is closely related to stereo image quality assessment (SIQA), which determines whether the evaluation results of SIQA method can keep good consistency with subjective perception. Many SIQA methods are not fully based on human visual theory, so there is still room for improvement. The research on the visual system tends to the dorsal and ventral pathways, which ignores the information differences in the early visual pathways. It is worth noting that the ON and OFF receptive fields in retinal ganglion cells (RGCs) respond asymmetrically to the statistical features of images. Inspired by this, in this paper, we propose an SIQA method based on monocular and binocular visual features, which takes into account the difference of ON and OFF response features in early visual pathways. Moreover, the different information interaction mechanisms of visual cortex are used to fuse the response maps information of left and right images. Final, monocular and binocular features are extracted and sent to support vector regression (SVR) for quality prediction. Experimental results show that the proposed method is superior to several mainstream SIQA metrics on four publicly available stereo image databases.
C1 [Chang, Yongli; Li, Sumei; Jin, Jie; Liu, Anqi] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Xiang, Wei] La Trobe Univ, Sch Engn & Math Sci, Melbourne, Vic 3086, Australia.
C3 Tianjin University; La Trobe University
RP Li, SM (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM chang_yli@163.com; chang_yli@163.com; jinjie@tju.edu.cn;
   liuanqi@tju.edu.cn; w.xiang@latrobe.edu.au
OI Li, Sumei/0000-0002-4793-3161
FU National Natural Science Founda-tion of China;  [61971306]; 
   [61520106002];  [61471262]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Grant 61971306, 61520106002, 61471262.
CR Bensalma R, 2013, MULTIDIM SYST SIGN P, V24, P281, DOI 10.1007/s11045-012-0178-3
   Chen L, 2019, SIGNAL PROCESS-IMAGE, V76, P1, DOI 10.1016/j.image.2019.03.011
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Chichilnisky EJ, 2002, J NEUROSCI, V22, P2737, DOI 10.1523/JNEUROSCI.22-07-02737.2002
   COGAN AI, 1987, VISION RES, V27, P2125, DOI 10.1016/0042-6989(87)90127-1
   Cooper EA, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004268
   CRONER LJ, 1995, VISION RES, V35, P7, DOI 10.1016/0042-6989(94)E0066-T
   Ding J, 2006, P NATL ACAD SCI USA, V103, P1141, DOI 10.1073/pnas.0509629103
   Ding Y, 2019, IET IMAGE PROCESS, V13, P1608, DOI 10.1049/iet-ipr.2018.5605
   ENGEL GR, 1967, VISION RES, V7, P753, DOI 10.1016/0042-6989(67)90038-7
   Fan Y, 2019, IEEE IMAGE PROC, P430, DOI [10.1109/icip.2019.8802956, 10.1109/ICIP.2019.8802956]
   Henriksen S, 2016, CURR BIOL, V26, pR500, DOI 10.1016/j.cub.2016.04.049
   Hobbs Ronald P, 2014, J Ophthalmic Vis Res, V9, P487, DOI 10.4103/2008-322X.150829
   HOLDEN A.L, 1997, CENTRAL VISUAL PATHW
   JAIN SCG, 2020, 24 EUROPEAN C ARTIFI, V325, P2907
   Jens Kremkow, 2013, BMC NEUROSCI
   Jiang QP, 2018, PATTERN RECOGN, V76, P242, DOI 10.1016/j.patcog.2017.11.001
   Karimi M, 2017, IEEE T MULTIMEDIA, V19, P2475, DOI 10.1109/TMM.2017.2699082
   Khan S, 2018, IEEE T IMAGE PROCESS, V27, P5892, DOI 10.1109/TIP.2018.2860279
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Lin YC, 2017, IEEE J-STSP, V11, P89, DOI 10.1109/JSTSP.2016.2632422
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu TJ, 2019, IEEE ACCESS, V7, P8058, DOI 10.1109/ACCESS.2018.2890304
   Liu Y, 2020, NEUROCOMPUTING, V405, P126, DOI 10.1016/j.neucom.2020.04.049
   Ll A., 2020, SIGNAL PROCESS-IMAGE, V87, P1
   Marc RE, 2003, PROG RETIN EYE RES, V22, P607, DOI 10.1016/S1350-9462(03)00039-9
   May KA, 2016, CURR BIOL, V26, P1571, DOI 10.1016/j.cub.2016.04.037
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   MK A, 2019, DIGIT SIGNAL PROCESS, V91, P91
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Parihar AS, 2021, IET IMAGE PROCESS, V15, P1410, DOI 10.1049/ipr2.12114
   Parihar AS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P619, DOI 10.1109/ICISC.2018.8398874
   Sagdullaev BT, 2005, VISUAL NEUROSCI, V22, P649, DOI 10.1017/S0952523805225142
   Shao F, 2016, APPL OPTICS, V55, P5488, DOI 10.1364/AO.55.005488
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Singh K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103241
   Vaidwan N., 2021, 2021 INT C INT TECHN, P1, DOI [10.1109/CONIT51480.2021.9498550, DOI 10.1109/C0NIT51480.2021.9498550]
   Wang J., 2014, INT WORKSHOP VIDEO P
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2016, INFORM SCIENCES, V351, P18, DOI 10.1016/j.ins.2016.02.043
   Yamada ES, 2001, VISION RES, V41, P119, DOI 10.1016/S0042-6989(00)00244-3
   Yang JC, 2019, IEEE T IMAGE PROCESS, V28, P1314, DOI 10.1109/TIP.2018.2878283
   Yue GH, 2018, SIGNAL PROCESS, V150, P204, DOI 10.1016/j.sigpro.2018.04.019
NR 46
TC 0
Z9 0
U1 3
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103643
DI 10.1016/j.jvcir.2022.103643
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300004
DA 2024-07-18
ER

PT J
AU Liang, PW
   Ding, WY
   Fan, L
   Wang, HY
   Li, ZH
   Yang, F
   Wang, B
   Li, CY
AF Liang, Pengwei
   Ding, Wenyu
   Fan, Lu
   Wang, Haoyu
   Li, Zihong
   Yang, Fan
   Wang, Bo
   Li, Chongyi
TI Multi-scale and multi-patch transformer for sandstorm image enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sandstorm image enhancement; Transformer; Two-stage network; Dataset
ID COLOR; RETINEX
AB Sandstorm is a meteorological phenomenon common in arid and semi-arid regions. A sandstorm can carry large volumes of sand unexpectedly, which leads to severe color deviations and significantly degraded visibility when an image is taken in such a scenario. However, existing image enhancement methods cannot enhance sandstorm images well due to the challenging degradations and the scarcity of sandstorm training data. In this paper, we propose a Transformer with rotary position embedding to perform sandstorm image enhancement via building multi-scale and multi-patch dependencies. Our key insights in this work are 1) a multi-scale Transformer can globally eliminate the color deviations of sandstorm images via aggregating global information, 2) a multi-patch Transformer can recover local details well via learning the spatial variant degradations, and 3) a U-shape Transformer with rotary position embedding as the core unit of multi-scale and multi-patch Transformer can effectively build the long-range dependencies. We also contribute a real-world Sandstorm Image Enhancement (SIE) dataset including 1,400 sandstorm images with different degrees of degradations and various scenes. Ex-periments performed on synthetic images and real-world sandstorm images demonstrate that our proposed method not only obtains visually pleasing results but also outperforms state-of-the-art methods qualitatively and quantitatively.
C1 [Liang, Pengwei; Ding, Wenyu; Fan, Lu; Wang, Haoyu; Li, Zihong; Yang, Fan; Wang, Bo] Ningxia Univ, Sch Phys & Elect Elect Engn, Yinchuan, Peoples R China.
   [Li, Chongyi] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Ningxia University; Nanyang Technological University
RP Wang, B (corresponding author), Ningxia Univ, Sch Phys & Elect Elect Engn, Yinchuan, Peoples R China.
EM tjuwb@nxu.edu.cn
RI Wang, Haoyu/AAI-7412-2021; zhang, lm/JWP-8874-2024; sun,
   jiamin/JPY-2155-2023; Liang, Pengwei/JXM-4365-2024
OI Wang, Haoyu/0000-0001-6964-6756; 
CR Abdelhamed A, 2019, IEEE COMPUT SOC CONF, P2197, DOI 10.1109/CVPRW.2019.00273
   Al-Ameen Zohair, 2016, International Journal of Intelligent Systems and Applications, V8, P10, DOI 10.5815/ijisa.2016.08.02
   Al-Shakarji N.M., 2017, P APPL IMAGERY PATTE, P1, DOI [10.1109/AIPR.2017.8457935, DOI 10.1109/AIPR.2017.8457935]
   Barnard K, 2000, LECT NOTES COMPUT SC, V1842, P390
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651
   Brainard DH, 1997, J OPT SOC AM A, V14, P1393, DOI 10.1364/JOSAA.14.001393
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cheng S, 2021, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR46437.2021.00486
   Cheng YQ, 2020, IEEE ACCESS, V8, P66931, DOI 10.1109/ACCESS.2020.2985869
   Das SD, 2020, IEEE COMPUT SOC CONF, P1994, DOI 10.1109/CVPRW50498.2020.00249
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Fu XY, 2014, IEEE INT WORKSH MULT
   Gao GX, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2020.2975833
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang SC, 2015, IEEE T IND ELECTRON, V62, P2962, DOI 10.1109/TIE.2014.2364798
   Jian Wang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P842, DOI 10.1007/978-3-319-27671-7_70
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Kenk MA, 2020, IEEE T INTELL TRANSP
   Khan S.H., 2021, arXiv
   Kim SE, 2020, IEEE T IMAGE PROCESS, V29, P1985, DOI 10.1109/TIP.2019.2948279
   Kui Jiang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8343, DOI 10.1109/CVPR42600.2020.00837
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Li CE, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157900
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li S., 2021, ARXIV
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu Z, 2021, Arxiv, DOI [arXiv:2103.14030, DOI 10.48550/ARXIV.2103.14030]
   Manzanilla A, 2019, IEEE ROBOT AUTOM LET, V4, P1351, DOI 10.1109/LRA.2019.2895272
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   [潘海明 Pan Haiming], 2018, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V30, P992
   Park TH, 2021, IEEE ACCESS, V9, P19749, DOI 10.1109/ACCESS.2021.3054899
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Shi ZH, 2020, IET IMAGE PROCESS, V14, P747, DOI 10.1049/iet-ipr.2019.0992
   Shi ZH, 2019, IEEE ACCESS, V7, P116722, DOI 10.1109/ACCESS.2019.2936444
   Song YD, 2022, Arxiv, DOI arXiv:2204.03883
   Su J, 2021, ARXIV
   Tang YC, 2022, STRUCTURES, V37, P426, DOI 10.1016/j.istruc.2021.12.055
   Ting Yan, 2014, Journal of Software, V9, P2672, DOI 10.4304/jsw.9.10.2672-2677
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang B, 2021, SIGNAL IMAGE VIDEO P, V15, P637, DOI 10.1007/s11760-020-01786-1
   Wang HJ, 2022, AGRONOMY-BASEL, V12, DOI 10.3390/agronomy12071520
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2019, SPRINGER SER GEOMECH, P39, DOI 10.1007/978-981-10-7560-5_4
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040
   Yu SY, 2016, J MOD OPTIC, V63, P2121, DOI 10.1080/09500340.2016.1184340
   Yuan L, 2021, Arxiv, DOI arXiv:2101.11986
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   [智宁 Zhi Ning], 2016, [中国图象图形学报, Journal of Image and Graphics], V21, P1585
   Zongsheng Yue, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P41, DOI 10.1007/978-3-030-58607-2_3
NR 61
TC 3
Z9 3
U1 6
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103662
DI 10.1016/j.jvcir.2022.103662
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V0HQ
UT WOS:000876919900001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Chen, WC
   Niu, PP
   Yang, HY
AF Wang, Xiangyang
   Chen, Wencong
   Niu, Panpan
   Yang, Hongying
TI Image copy-move forgery detection based on dynamic threshold with dense
   points
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move tampering; FJFMs; SLIC; Dynamic threshold; WLD
ID SIFT
AB Copy-move tampering is one of the most popular tampering techniques at present. The tampered region of the image has good fusion with the original image, which increases the difficulty of detection. After years of research, the current detection method based on key points still has the following problems: 1) Failure to achieve forgery detection of small areas/self-similar areas/smooth areas, 2) Lack of reasonable feature point extraction methods, 3) The various stages of copy-move forgery detection (CMFD) work are relatively independent and lack close connections, 4) A fixed threshold is used as the region of interest similarity metric in the matching and localization stages. The failure to consider tampered images and the diversity of tampered regions leads to the limited detection capability of the algorithm. Considering the actual situation of tampering with the picture, to solve the above problems, we propose a copy-move forgery detection method based on the dynamic threshold. First, we determine the point extraction strategy in each super pixel block according to the size of the simple line interface calculation (SLIC) super pixel block and the Weber local descriptor (WLD) descriptor to ensure the reasonable allocation of feature points and reduce unnecessary points. These key points are then characterized by the scaling, flip and rotation invariants of the fractional general Jacobi-Fourier moments (FJFMs). Then, the matching and mismatch filtering thresholds of each feature point are determined through the WLD and SLIC features, and the SLIC feature is used to replace the distance threshold to improve the detection accuracy of small manufacturing areas. Finally, based on the matching results and SLIC features, an effective positioning method is proposed to improve the speed and accuracy of positioning. Experimental results show that the proposed al-gorithm is superior to the classic methods in recent years in terms of time and accuracy.
C1 [Wang, Xiangyang; Chen, Wencong; Niu, Panpan; Yang, Hongying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Niu, Panpan/Q-9953-2017; Yang, Jing/JFK-4046-2023; Chen,
   Wencong/ABC-7907-2021
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China; Scientific Research
   Project of Liaoning Provincial Education Department; Natural Science
   Foundation of Liaoning Province;  [61472171];  [61701212];  [LJKZ0985]; 
   [2019-ZD-0468]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212) , Scientific Research
   Project of Liaoning Provincial Education Department (No. LJKZ0985) , and
   Natural Science Foundation of Liaoning Province (No. 2019-ZD-0468) .
CR Abhishek, 2021, MULTIMED TOOLS APPL, V80, P3571, DOI 10.1007/s11042-020-09816-3
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Vega EAA, 2021, NEURAL COMPUT APPL, V33, P4713, DOI 10.1007/s00521-020-05433-1
   Bag S., 2019, 2019 5 IEEE INT C, P1
   Barni M, 2021, IEEE T INF FOREN SEC, V16, P1825, DOI 10.1109/TIFS.2020.3045903
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Christlein V, 2010, IEEE INT WORKS INFOR
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Darmet L, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107536
   Dixit A, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115282
   Dixit A, 2020, MULTIMED TOOLS APPL, V79, P26061, DOI 10.1007/s11042-020-09230-9
   Elaskily MA, 2021, J INTELL FUZZY SYST, V40, P4385, DOI 10.3233/JIFS-201192
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich A.J., 2003, P DIGITAL FORENSIC R
   Gani G, 2021, EVOL SYST-GER, V12, P503, DOI 10.1007/s12530-019-09309-1
   Hosny KM, 2019, PATTERN RECOGN, V88, P153, DOI 10.1016/j.patcog.2018.11.014
   Huynh K.T., 2021, SN COMPUT SCI, V2, P1
   Jaiswal AK, 2022, NEURAL PROCESS LETT, V54, P75, DOI 10.1007/s11063-021-10620-9
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Liu Y, 2020, MULTIMED TOOLS APPL, V79, P477, DOI 10.1007/s11042-019-08044-8
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mahmood T, 2017, FORENSIC SCI INT, V279, P8, DOI 10.1016/j.forsciint.2017.07.037
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Niu P, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103068
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Rodriguez-Ortega Y, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030059
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Tinnathi S, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102966
   Wang XY, 2020, MULTIDIM SYST SIGN P, V31, P857, DOI 10.1007/s11045-019-00688-x
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yang HY, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107898
   Yang JX, 2021, DIGIT SIGNAL PROCESS, V113, DOI 10.1016/j.dsp.2021.103032
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
   Zhong JL, 2020, INFORM SCIENCES, V512, P675, DOI 10.1016/j.ins.2019.09.085
NR 50
TC 4
Z9 4
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103658
DI 10.1016/j.jvcir.2022.103658
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V1KD
UT WOS:000876994600001
DA 2024-07-18
ER

PT J
AU Tang, MY
   Yashtini, M
   Ha Kang, S
AF Tang, Mengyi
   Yashtini, Maryam
   Ha Kang, Sung
TI Counting Objects by Diffused Index: Geometry-free and training-free
   approach?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object counting; Variational analysis; Alternating minimization; Fast
   methods; Clustering; Convergence analysis
ID HOUGH TRANSFORM; IMAGE; COLORIZATION; INSTANCES; MODELS; TV
AB Counting objects is a fundamental but challenging problem. In this paper, we propose diffusion-based, geometry-free, and learning-free methodologies to count the number of objects in images. The main idea is to represent each object by a unique index value regardless of its intensity or size, and to simply count the number of index values. First, we place different vectors, refer to as seed vectors, uniformly throughout the mask image. The mask image has boundary information of the objects to be counted. Secondly, the seeds are diffused using an edge-weighted harmonic variational optimization model within each object. We propose an efficient algorithm based on an operator splitting approach and alternating direction minimization method, and theoretical analysis of this algorithm is given. An optimal solution of the model is obtained when the distributed seeds are completely diffused such that there is a unique intensity within each object, which we refer to as an index. For computational efficiency, we stop the diffusion process before a full convergence, and propose to cluster these diffused index values. We refer to this approach as Counting Objects by Diffused Index (CODI). We explore scalar and multi-dimensional seed vectors. For Scalar seeds, we use Gaussian fitting in histogram to count, while for vector seeds, we exploit a high-dimensional clustering method for the final step of counting via clustering. The proposed method is flexible even if the boundary of the object is not clear nor fully enclosed. We present counting results in various applications such as biological cells, agriculture, concert crowd, and transportation. Some comparisons with existing methods are presented.
C1 [Tang, Mengyi; Ha Kang, Sung] Georgia Inst Technol, Sch Math, 686 Cherry St, Atlanta, GA 30332 USA.
   [Yashtini, Maryam] Georgetown Univ, Dept Math & Stat, 327A St Marys Hall,37th & St,NW, Washington, DC 20057 USA.
C3 University System of Georgia; Georgia Institute of Technology;
   Georgetown University
RP Yashtini, M (corresponding author), Georgetown Univ, Dept Math & Stat, 327A St Marys Hall,37th & St,NW, Washington, DC 20057 USA.
EM tangmengyi@gatech.edu; my496@georgetown.edu; kang@math.gatech.edu
RI Yashtini, Maryam/JGM-5807-2023
CR Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Arteta C, 2016, MED IMAGE ANAL, V27, P3, DOI 10.1016/j.media.2015.03.002
   Arteta C, 2014, LECT NOTES COMPUT SC, V8691, P504, DOI 10.1007/978-3-319-10578-9_33
   Arteta C, 2012, LECT NOTES COMPUT SC, V7510, P348, DOI 10.1007/978-3-642-33415-3_43
   Ayalew Tewodros W., 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12540), P330, DOI 10.1007/978-3-030-65414-6_23
   Baker L, 2016, INT CONF IMAG VIS, P134
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Baygin Mehmet, 2018, ARXIV PREPRINT ARXIV
   Berge H, 2011, I S BIOMED IMAGING, P204, DOI 10.1109/ISBI.2011.5872388
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cha YJ, 2016, AUTOMAT CONSTR, V71, P181, DOI 10.1016/j.autcon.2016.06.008
   Chen YM, 2013, COMPUT OPTIM APPL, V54, P317, DOI 10.1007/s10589-012-9519-2
   Cholakkal H, 2019, PROC CVPR IEEE, P12389, DOI 10.1109/CVPR.2019.01268
   Chourasiya S., 2014, HEMOGLOBIN, V14, P17
   Cruz JA, 2016, MACH VISION APPL, V27, P735, DOI 10.1007/s00138-015-0734-6
   Ding J, 2018, IEEE C COMP VIS PATT
   Ding Xin, CAAI INT C ARTIFICIA, P662
   Drury JA, 2011, HISTOPATHOLOGY, V59, P1156, DOI 10.1111/j.1365-2559.2011.04046.x
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fritz M, 2005, IEEE I CONF COMP VIS, P1363
   Gall J., 2013, Decision Forests for Computer Vision and Medical Image Analysis, P143
   Hager W, 2015, J OPER RES SOC CHINA, V3, P139, DOI 10.1007/s40305-015-0078-y
   Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Kang SH, 2007, IEEE T IMAGE PROCESS, V16, P2251, DOI 10.1109/TIP.2007.903257
   Kang SH, 2011, INVERSE PROBL IMAG, V5, P407, DOI 10.3934/ipi.2011.5.407
   Kolhatkar D, 2016, 2016 WORLD CONFERENCE ON FUTURISTIC TRENDS IN RESEARCH AND INNOVATION FOR SOCIAL WELFARE (STARTUP CONCLAVE)
   Kothari S, 2009, I S BIOMED IMAGING, P795, DOI 10.1109/ISBI.2009.5193169
   Loukas CG, 2003, CYTOM PART A, V55A, P30, DOI 10.1002/cyto.a.10060
   Lu E, 2019, LECT NOTES COMPUT SC, V11363, P669, DOI 10.1007/978-3-030-20893-6_42
   Maitra M., 2012, Int J. Comput. Appl, V53, P13, DOI DOI 10.5120/8505-2274
   Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693
   Marsden M, 2018, PROC CVPR IEEE, P8070, DOI 10.1109/CVPR.2018.00842
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Shrivakshan G., 2012, INT J COMPUT SCI ISS, V9, P269
   Tulsani H., 2013, Int. J. Comput. Appl. Inf. Technol, V2, P28
   Venkatalakshmi B, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P267
   Vincent O., 2009, P 2009 SITE C INF SC, P97
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041
   Wu CL, 2010, SIAM J IMAGING SCI, V3, P300, DOI 10.1137/090767558
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xiaomin Guo, 2013, 2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2013), P293, DOI 10.1109/IHMSC.2013.76
   Xie WD, 2018, COMP M BIO BIO E-IV, V6, P283, DOI 10.1080/21681163.2016.1149104
   Yang JF, 2010, IEEE J-STSP, V4, P288, DOI 10.1109/JSTSP.2010.2042333
   Yashtini Maryam, 2015, Scale Space and Variational Methods in Computer Vision. 5th International Conference, SSVM 2015. Proceedings: LNCS 9087, P690, DOI 10.1007/978-3-319-18461-6_55
   Yashtini M, 2019, ADV COMPUT MATH, V45, P1735, DOI 10.1007/s10444-019-09702-z
   Yashtini M, 2016, SIAM J IMAGING SCI, V9, P1552, DOI 10.1137/16M1063757
   Yongming Chen, 1999, Proceedings of the First Joint BMES/EMBS Conference. 1999 IEEE Engineering in Medicine and Biology 21st Annual Conference and the 1999 Annual Fall Meeting of the Biomedical Engineering Society (Cat. No.99CH37015), DOI 10.1109/IEMBS.1999.803974
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 54
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
DI 10.1016/j.jvcir.2022.103527
EA MAY 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H3MB
UT WOS:000814201400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gong, YX
   Deng, LJ
   Tao, S
   Lu, XC
   Wu, PC
   Xie, ZW
   Ma, Z
   Xie, M
AF Gong, Yanxiang
   Deng, Linjie
   Tao, Shuai
   Lu, Xinchen
   Wu, Peicheng
   Xie, Zhiwei
   Ma, Zheng
   Xie, Mei
TI Unified Chinese License Plate detection and recognition with high
   efficiency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Chinese license plate dataset; License plate detection and recognition;
   End-to-end; Real-time
ID NEURAL-NETWORK; FRAMEWORK
AB Recently, deep learning-based methods have reached an excellent performance on License Plate (LP) detection and recognition tasks. However, it is still challenging to build a robust model for Chinese LPs since there are not enough large and representative datasets. In this work, we propose a new dataset named Chinese Road Plate Dataset (CRPD) that contains multi-objective Chinese LP images as a supplement to the existing public benchmarks. The images are mainly captured with electronic monitoring systems with detailed annotations. To our knowledge, CRPD is the largest public multi-objective Chinese LP dataset with annotations of vertices. With CRPD, a unified detection and recognition network with high efficiency is presented as the baseline. The network is end-to-end trainable with totally real-time inference efficiency (30 fps with 640 p). The experiments on several public benchmarks demonstrate that our method has reached competitive performance. The code and dataset will be publicly available at https://github.com/yxgong0/CRPD.
C1 [Gong, Yanxiang; Deng, Linjie; Tao, Shuai; Lu, Xinchen; Wu, Peicheng; Xie, Zhiwei; Ma, Zheng; Xie, Mei] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Xie, M (corresponding author), Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu, Peoples R China.
EM mxie@uestc.edu.cn
RI Gong, Yanxiang/AFD-9112-2022; ma, zheng/IRY-8826-2023
FU National Key Research and Development Program of China [2018AAA0103203]
FX Acknowledgments This work was partly supported by the National Key
   Research and Development Program of China with ID 2018AAA0103203.
CR [Anonymous], 2014, EASYPR
   Barreto SC, 2019, LECT NOTES COMPUT SC, V11524, P115, DOI 10.1007/978-3-030-21077-9_11
   Bochkovskiy A., 2020, PREPRINT
   Chen SL, 2020, IEEE T INTELL TRANSP, V21, P3686, DOI 10.1109/TITS.2019.2931791
   Deng LJ, 2019, IEEE ACCESS, V7, P153400, DOI 10.1109/ACCESS.2019.2948405
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goncalves GR, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.069801
   Graves A., 2006, P 23 INT C MACHINE L, P369
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Kessentini Y, 2019, EXPERT SYST APPL, V136, P159, DOI 10.1016/j.eswa.2019.06.036
   Laroca R., 2018, P INT JOINT C NEUR N, P1
   Laroca R, 2021, IET INTELL TRANSP SY, V15, P483, DOI 10.1049/itr2.12030
   Li H, 2019, IEEE T INTELL TRANSP, V20, P1126, DOI 10.1109/TITS.2018.2847291
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Linjie Deng, 2019, 2019 IEEE 5th International Conference on Computer and Communications (ICCC), P1685, DOI 10.1109/ICCC47050.2019.9064428
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Paszke A, 2019, ADV NEUR IN, V32
   Pfurtscheller G, 2003, CALT LIC PLAT DAT
   Qin SX, 2020, IET IMAGE PROCESS, V14, P4102, DOI 10.1049/iet-ipr.2020.1130
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Silva SM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102773
   Spanhel J, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang SZ, 2007, IEEE T INF FOREN SEC, V2, P267, DOI 10.1109/TIFS.2007.897251
   Wang WW, 2019, IEEE ACCESS, V7, P173875, DOI 10.1109/ACCESS.2019.2956357
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Xu ZB, 2018, LECT NOTES COMPUT SC, V11217, P261, DOI 10.1007/978-3-030-01261-8_16
   Yuan YL, 2017, IEEE T IMAGE PROCESS, V26, P1102, DOI 10.1109/TIP.2016.2631901
   Zemris, 2003, ZEMR LIC PLAT DAT
   Zhang C, 2021, NEUROCOMPUTING, V449, P189, DOI 10.1016/j.neucom.2021.03.103
   Zhang LJ, 2021, IEEE T INTELL TRANSP, V22, P6967, DOI 10.1109/TITS.2020.3000072
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou WG, 2012, IEEE T IMAGE PROCESS, V21, P4269, DOI 10.1109/TIP.2012.2199506
   Zhu SY, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023020
NR 41
TC 15
Z9 15
U1 8
U2 48
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103541
DI 10.1016/j.jvcir.2022.103541
EA MAY 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1V1LX
UT WOS:000805861200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khaire, P
   Kumar, P
AF Khaire, Pushpajit
   Kumar, Praveen
TI Deep learning and RGB-D based human action, human-human and human-object
   interaction recognition: A survey?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; CNN; LSTM; Human-human interaction;
   Human-object interaction; Deep learning; RGB-D sensors; Multi-modality;
   Fusion; Skeleton; GCN
ID FLOW ESTIMATION; NEURAL-NETWORK; SEQUENCES; STREAMS
AB Human activity recognition is one of the most studied topics in the field of computer vision. In recent years, with the availability of RGB-D sensors and powerful deep learning techniques, research on human activity recognition has gained momentum. From simple human atomic actions, the research has advanced towards recognizing more complex human activities using RGB-D data. This paper presents a comprehensive survey of the advanced deep learning based recognition methods and categorizes them in human atomic action, human-human interaction, human-object interaction. The reviewed methods are further classified based on the individual modality used for recognition i.e. RGB based, depth based, skeleton based, and hybrid. We also review and categorize recent challenging RGB-D datasets for the same. In addition, the paper also briefly reviews RGB-D datasets and methods for online activity recognition. The paper concludes with a discussion on limitations, challenges, and recent trends for promising future directions.
C1 [Khaire, Pushpajit; Kumar, Praveen] Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur
RP Khaire, P (corresponding author), Visvesvaraya Natl Inst Technol, Dept Comp Sci & Engn, Nagpur, India.
EM pushpjitkhaire@gmail.com
RI KHAIRE, PUSHPAJIT/AFK-2217-2022; Kumar, Praveen/AAA-8584-2022
OI KHAIRE, PUSHPAJIT/0000-0002-4065-4338; Kumar,
   Praveen/0000-0003-4820-3088
FU Science and Engineering Research Board (SERB) , India [ECR/2016/000387];
   Department of Science & Technology (DST) , Government of India
FX This research was supported by Science and Engineering Research Board
   (SERB) , India under project no. ECR/2016/000387, in coopera-tion with
   the Department of Science & Technology (DST) , Government of India. The
   views and conclusions contained in this document are those of the
   authors and should not be interpreted as representing the official
   policies, either expressed or implied, of DST-SERB or the Government of
   India. The DST-SERB or Government of India is au-thorized to reproduce
   and distribute reprints for Government purposes notwithstanding any
   copyright notation thereon. We are also thankful to all the reviewers
   for their valuable comments and suggestions to improve the scientific
   value of the paper.
CR Adama DA, 2018, SOFT COMPUT, V22, P7027, DOI 10.1007/s00500-018-3364-x
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4
   ANDERSON JR, 1982, PSYCHOL REV, V89, P369, DOI 10.1037/0033-295X.89.4.369
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2007, DOCUMENTATION MOCAP
   [Anonymous], 2017, 31 INT CONFNEURAL IN
   Bagautdinov T, 2017, PROC CVPR IEEE, P3425, DOI 10.1109/CVPR.2017.365
   Beauchamp MS, 2002, NEURON, V34, P149, DOI 10.1016/S0896-6273(02)00642-6
   Ben-Shabat Y, 2021, IEEE WINT CONF APPL, P846, DOI 10.1109/WACV48630.2021.00089
   Biswas Sovan, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P1625, DOI 10.1109/WACV.2018.00180
   Bloom V, 2015, LECT NOTES COMPUT SC, V8925, P698, DOI 10.1007/978-3-319-16178-5_49
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Cai JM, 2021, IEEE WINT CONF APPL, P2734, DOI 10.1109/WACV48630.2021.00278
   Cao CQ, 2019, IEEE T CIRC SYST VID, V29, P3247, DOI 10.1109/TCSVT.2018.2879913
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen K., 2020, ARXIV PREPRINT ARXIV
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Coppola C, 2020, INT J SOC ROBOT, V12, P201, DOI 10.1007/s12369-019-00541-y
   Coppola C, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P5055, DOI 10.1109/IROS.2016.7759742
   Cornacchia M, 2017, IEEE SENS J, V17, P386, DOI 10.1109/JSEN.2016.2628346
   Crasto N, 2019, PROC CVPR IEEE, P7874, DOI 10.1109/CVPR.2019.00807
   Dai, 2020, ARXIV PREPRINT ARXIV
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Das S, 2018, INDIA, EMPIRE, AND FIRST WORLD WAR CULTURE, P1, DOI 10.1017/ 9781139963244
   Das Srijan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P72, DOI 10.1007/978-3-030-58545-7_5
   Das S, 2019, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2019.00092
   Das S, 2019, LECT NOTES COMPUT SC, V11296, P493, DOI 10.1007/978-3-030-05716-9_40
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng YX, 2017, IEEE DEVICE RES CONF
   Deng ZW, 2016, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2016.516
   Devanne M, 2019, IEEE SYS MAN CYBERN, P3318, DOI [10.1109/smc.2019.8914457, 10.1109/SMC.2019.8914457]
   Devanne M, 2017, PATTERN RECOGN, V61, P222, DOI 10.1016/j.patcog.2016.07.041
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Ding ZH, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P610, DOI 10.1109/QRS-C.2017.134
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dreher CRG, 2020, IEEE ROBOT AUTOM LET, V5, P187, DOI 10.1109/LRA.2019.2949221
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Dutta V, 2019, J INTELL ROBOT SYST, V93, P745, DOI 10.1007/s10846-018-0815-7
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Escalante HJ, 2016, PATTERN RECOGN LETT, V73, P91, DOI 10.1016/j.patrec.2016.01.013
   Fang Z., 2018, P COMPUTER GRAPHICS, P163
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gupta Saurabh, 2015, ARXIV150504474, P5
   He DL, 2019, AAAI CONF ARTIF INTE, P8401
   He K., 2016, P IEEE C COMP VIS PA, P770, DOI DOI 10.48550/ARXIV.1512.03385
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   HeWang Feixiang He, 2021, ARXIV210305347
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Hu T, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/795360
   Huang D, 2014, LECT NOTES COMPUT SC, V8691, P410, DOI 10.1007/978-3-319-10578-9_27
   Pham HH, 2019, IET COMPUT VIS, V13, P319, DOI 10.1049/iet-cvi.2018.5014
   Pham HH, 2018, COMPUT VIS IMAGE UND, V170, P51, DOI 10.1016/j.cviu.2018.03.003
   Huynh-The T, 2020, IEEE T IND INFORM, V16, P3100, DOI 10.1109/TII.2019.2910876
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Ijjina EP, 2017, PATTERN RECOGN, V72, P504, DOI 10.1016/j.patcog.2017.07.013
   Imran J, 2020, J AMB INTEL HUM COMP, V11, P189, DOI 10.1007/s12652-019-01239-9
   Islam MM, 2021, IEEE ROBOT AUTOM LET, V6, P1729, DOI 10.1109/LRA.2021.3059624
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jegham I, 2020, FORENS SCI INT-DIGIT, V32, DOI 10.1016/j.fsidi.2019.200901
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Ji YL, 2021, IEEE T CIRC SYST VID, V31, P289, DOI 10.1109/TCSVT.2020.2975845
   Joe Yue-Hei Ng, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P1616, DOI 10.1109/WACV.2018.00179
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Ke QH, 2016, LECT NOTES COMPUT SC, V9914, P403, DOI 10.1007/978-3-319-48881-3_28
   Keçeli AS, 2018, SIGNAL IMAGE VIDEO P, V12, P1197, DOI 10.1007/s11760-018-1271-3
   Khaire P., 2020, HAD ATM RGB D DATASE
   Khaire P, 2018, PATTERN RECOGN LETT, V115, P107, DOI 10.1016/j.patrec.2018.04.035
   Khan Gulraiz, 2018, MULTIMED TOOLS APPL, P1
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kipf TN, 2016, ARXIV
   Kong Y., 2018, ARXIV180611230
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Korban Matthew, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P761, DOI 10.1007/978-3-030-58565-5_45
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li C.-L., 2018, ARXIV PREPRINT ARXIV
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Li JN, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107356
   Li J, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107037
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li Shuaicheng., Proceedings of the IEEE/CVF International Conference on Computer Vision, P13668
   Li TJ, 2021, PROC CVPR IEEE, P16261, DOI 10.1109/CVPR46437.2021.01600
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li W, 2017, IEEE I CONF COMP VIS, P1453, DOI 10.1109/ICCV.2017.161
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Li ZF, 2019, MULTIMED TOOLS APPL, V78, P19587, DOI 10.1007/s11042-019-7356-3
   Liang JW, 2019, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR.2019.00587
   Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Lin Y.C., 2012, P 20 ACM INT C MULT, P1053
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu BL, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107053
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Liu C., 2017, Pku-mmd: A large scale benchmark for continuous multi-modal human action understanding
   Liu J, 2022, IEEE T NEUR NET LEAR, V33, P1609, DOI 10.1109/TNNLS.2020.3043002
   Liu JY, 2019, IEEE T CIRC SYST VID, V29, P2667, DOI 10.1109/TCSVT.2018.2799968
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P1453, DOI 10.1109/TPAMI.2019.2898954
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, IEEE INT CON MULTI, P925, DOI 10.1109/ICME.2017.8019438
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Madrigal F., 2019, 2019 16 IEEE INT C, p1?8
   Mansur A, 2013, IEEE T CYBERNETICS, V43, P1226, DOI 10.1109/TSMCB.2012.2226879
   Mici L, 2018, NEUROCOMPUTING, V307, P14, DOI 10.1016/j.neucom.2018.04.015
   Mishra N., 2019, ARXIV PREPRINT ARXIV
   Morales J, 2017, BIOCYBERN BIOMED ENG, V37, P388, DOI 10.1016/j.bbe.2017.04.004
   Munaro M, 2013, BIOL INSPIR COGN ARC, V5, P42, DOI 10.1016/j.bica.2013.05.008
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Perez M, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108360
   Perez M, 2022, IEEE T MULTIMEDIA, V24, P366, DOI 10.1109/TMM.2021.3050642
   Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Qin Z, 2017, IEEE T IMAGE PROCESS, V26, P5680, DOI 10.1109/TIP.2017.2745209
   Ragusa F, 2021, IEEE WINT CONF APPL, P1568, DOI 10.1109/WACV48630.2021.00161
   Ramanathan V, 2016, PROC CVPR IEEE, P3043, DOI 10.1109/CVPR.2016.332
   Rani SS, 2021, MATER TODAY-PROC, V37, P3164, DOI 10.1016/j.matpr.2020.09.052
   Ranjan A, 2019, IEEE I CONF COMP VIS, P2404, DOI 10.1109/ICCV.2019.00249
   Redmon J., 2018, COMPUTER VISION PATT
   Reily B., 2020, 2020 IEEE INT C ROB
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryoo Michael S., 2020, EUR C COMP VIS
   Sanchez-Caballero A., 2020, ARXIV PREPRINT ARXIV
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453
   Shu XB, 2021, IEEE T PATTERN ANAL, V43, P1110, DOI 10.1109/TPAMI.2019.2942030
   Si CY, 2018, LECT NOTES COMPUT SC, V11205, P106, DOI 10.1007/978-3-030-01246-5_7
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Tej, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P247, DOI 10.1007/978-981-13-2553-3_24
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stroud JC, 2020, IEEE WINT CONF APPL, P614, DOI 10.1109/wacv45572.2020.9093274
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Sun C, 2019, PROC CVPR IEEE, P273, DOI 10.1109/CVPR.2019.00036
   Sun Zhichuang, 2020, ARXIV200207687
   Sung J., 2011, plan, activity, and intent recognition, V64
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan H., 2019, BMVC, P145
   Tan HL, 2021, COMPUT VIS IMAGE UND, V202, DOI 10.1016/j.cviu.2020.103107
   Tang JH, 2022, IEEE T PATTERN ANAL, V44, P636, DOI 10.1109/TPAMI.2019.2928540
   Tian L, 2020, IEEE T IMAGE PROCESS, V29, P8429, DOI 10.1109/TIP.2020.3013168
   Truong A.M., 2017, 2017 14 IEEE INT C A, P1
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Ullah A, 2018, IEEE ACCESS, V6, P1155, DOI 10.1109/ACCESS.2017.2778011
   van Gemeren C, 2014, LECT NOTES COMPUT SC, V8749, P101, DOI 10.1007/978-3-319-11839-0_9
   Vaswani A, 2017, ADV NEUR IN, V30
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang LC, 2020, IEEE INT CONF AUTOMA, P160, DOI 10.1109/FG47880.2020.00018
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1119, DOI 10.1145/2733373.2806296
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang SQ, 2015, DIGIT COMMUN NETW, V1, P20, DOI 10.1016/j.dcan.2015.02.006
   Wang TC, 2020, PROC CVPR IEEE, P4115, DOI 10.1109/CVPR42600.2020.00417
   Wang TC, 2019, IEEE I CONF COMP VIS, P5693, DOI 10.1109/ICCV.2019.00579
   Wang YC, 2020, PROC CVPR IEEE, P508, DOI 10.1109/CVPR42600.2020.00059
   Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461
   Wu CX, 2018, IEEE T PATTERN ANAL, V40, P467, DOI 10.1109/TPAMI.2017.2679054
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Xu BJ, 2019, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2019.00212
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang D, 2021, IEEE WINT CONF APPL, P2362, DOI 10.1109/WACV48630.2021.00241
   Yang ZY, 2019, IEEE T CIRC SYST VID, V29, P2405, DOI 10.1109/TCSVT.2018.2864148
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu G, 2015, LECT NOTES COMPUT SC, V9007, P50, DOI 10.1007/978-3-319-16814-2_4
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Yun S.B, 2020, ARXIV PREPRINT ARXIV
   Yunfeng D., 2021, P IEEE COMPUTER SOC
   Zechun Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P143, DOI 10.1007/978-3-030-58568-6_9
   Zhang CY, 2018, COMPUT VIS IMAGE UND, V167, P37, DOI 10.1016/j.cviu.2017.11.008
   Zhang HC, 2019, IEEE I CONF COMP VIS, P421, DOI 10.1109/ICCV.2019.00051
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang X., 2020, P IEEE CVF C COMP VI, P14333, DOI DOI 10.1109/CVPR42600202001434
   Zhao C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040716
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432
   Zhou X., 2019, arXiv
   Zhu L., 2021, PATTERN RECOGNIT
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 228
TC 19
Z9 19
U1 2
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103531
DI 10.1016/j.jvcir.2022.103531
EA MAY 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1V1LX
UT WOS:000805861200002
OA Bronze
DA 2024-07-18
ER

PT J
AU Mohammadi, IS
   Ghanbari, M
   Hashemi, MR
AF Mohammadi, Iman Soltani
   Ghanbari, Mohammad
   Hashemi, Mahmoud Reza
TI An efficient six-parameter perspective motion model for VVC*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia streaming; Video coding; Motion estimation; Spatial
   transform; BD-rate reduction
ID COMPENSATION; PREDICTION
AB Tilt and pan camera movements are common in computer games or social media videos. These types of videos contain numerous perspective transforms while today's video codecs rely on translational and affine motion models for motion compensation. The general perspective motion model with 8 parameters (8PMM) has unreasonably high processing time. In this paper, the eight-parameter perspective transform is simplified into a sixparameter transform to keep the time complexity within an acceptable range while modeling the most relevant transforms. Also, two motion prediction modes, Advanced Perspective Motion Vector Prediction (APMVP) and Perspective Model Merge (PMM), are proposed. The implementation results show an average of 7.0% BD-rate reduction over H.266/VVC Test Model with a maximum of 20% encoding time overhead. The results also show a 71% processing time reduction in comparison to 8PMM while experiencing an average of 5.6% increase in BD-Rate. Much better visual quality is measured through VMAF quality meter.
C1 [Mohammadi, Iman Soltani; Ghanbari, Mohammad; Hashemi, Mahmoud Reza] Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, England.
C3 University of Tehran; University of Essex
RP Hashemi, MR (corresponding author), Univ Tehran, Coll Engn, Sch Elect & Comp Engn, Tehran, Iran.
RI Ghanbari, Mohammad/L-4053-2019; Hashemi, Mahmoud Reza/H-2172-2011
OI Ghanbari, Mohammad/0000-0002-5482-8378; 
CR Alvarez-Mesa M, 2012, INT CONF ACOUST SPEE, P1545, DOI 10.1109/ICASSP.2012.6288186
   [Anonymous], CALL DUTY
   [Anonymous], COUNTER STRIKE
   [Anonymous], 2012, 2012 IEEE VIS COMM
   [Anonymous], GET START AV1 AVIF
   Bjotegaard G., 2001, VCEGM33
   Bossen F., 2019, JVET COMMON TEST CON
   Browne A., 2021, JVETX2002V1, P1
   Chi CC, 2012, IEEE IMAGE PROC, P213, DOI 10.1109/ICIP.2012.6466833
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Choi YJ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8090993
   Clement J., GLOBAL CONSUMER INTE
   David, MOST WATCHED GAME TW
   Fortnite, EP GAM WARN BROS INT
   GHANBARI M, 1995, SIGNAL PROCESS-IMAGE, V7, P567, DOI 10.1016/0923-5965(95)00031-2
   Grand Theft Auto, ROCKST GAM
   Han DI, 2005, LECT NOTES COMPUT SC, V3656, P1258
   Heithausen C, 2016, IEEE IMAGE PROC, P2008, DOI 10.1109/ICIP.2016.7532710
   Heithausen C, 2015, INT CONF ACOUST SPEE, P1438, DOI 10.1109/ICASSP.2015.7178208
   HM reference software, 2013, JOINT COLL TEAM VID
   Huang H, 2013, IEEE T CIRC SYST VID, V23, P1651, DOI 10.1109/TCSVT.2013.2254977
   Joint Exploration Model (JEM), 2015, JOINT VID EXPL TEAM
   Kan J., TWITCH
   Kordasiewicz RC, 2007, IEEE T CIRC SYST VID, V17, P1388, DOI 10.1109/TCSVT.2007.903777
   Laurier E, 2014, ROUTL RES CULT MEDIA, V64, P181
   Li L, 2018, IEEE T CIRC SYST VID, V28, P1934, DOI 10.1109/TCSVT.2017.2699919
   Li L, 2015, IEEE INT SYMP CIRC S, P525, DOI 10.1109/ISCAS.2015.7168686
   Liu ZY, 2019, APPL OPTICS, V58, P5465, DOI 10.1364/AO.58.005465
   Lopes F, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P558, DOI 10.1109/ICIP.2000.899487
   Milam D, 2011, LECT NOTES COMPUT SC, V6972, P113, DOI 10.1007/978-3-642-24500-8_12
   NAKAYA Y, 1994, IEEE T CIRC SYST VID, V4, P339, DOI 10.1109/76.305878
   Narroschke M, 2013, PICT COD SYMP, P321, DOI 10.1109/PCS.2013.6737748
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   Park SH, 2019, IEEE ACCESS, V7, P158075, DOI 10.1109/ACCESS.2019.2950388
   Ren WZ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071143
   Rogers J., 1983, 1983 INT TECHNICAL C
   SASIAN JM, 1992, OPT ENG, V31, P527, DOI 10.1117/12.56085
   SEFERIDIS V, 1994, IEE P-VIS IMAGE SIGN, V141, P446, DOI 10.1049/ip-vis:19941423
   SEFERIDIS V, 1993, OPT ENG, V32, P1464, DOI 10.1117/12.138613
   Seferidis V., 1992, APPL OPTICAL SCI ENG
   Seferidis V.E., 1992, PROC SPIE 1818 VISUA
   Sullivan G.J., 2019, VERSATILE VIDEO CODI
   VVC Test Model (VTM), 2019, JOINT VID EXP TEAM
   Wiegand T, 2005, IEEE T CIRC SYST VID, V15, P197, DOI 10.1109/TCSVT.2004.841690
   WOODS A, 1993, P SOC PHOTO-OPT INS, V1915, P36, DOI 10.1117/12.157041
   Yuan H, 2012, IEEE T MULTIMEDIA, V14, P1370, DOI 10.1109/TMM.2012.2190393
   Yuan H, 2010, IEEE SIGNAL PROC LET, V17, P787, DOI 10.1109/LSP.2010.2055051
   Zrida H., 2011, COMPLEXITYPERFORMANC
NR 48
TC 0
Z9 0
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103514
DI 10.1016/j.jvcir.2022.103514
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L9NQ
UT WOS:000799607600005
DA 2024-07-18
ER

PT J
AU Gao, K
   Horng, JH
   Chang, CC
AF Gao, Kai
   Horng, Ji-Hwei
   Chang, Chin-Chen
TI High-capacity reversible data hiding in encrypted images based on
   adaptive block encoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Encrypted image; Data hiding; Adaptive block encoding; Embedding
   capacity
AB This paper proposes a new high-capacity reversible data hiding scheme in encrypted images. The content owner first divides the cover image into blocks. Then, the block permutation and the bitwise stream cipher processes are applied to encrypt the image. Upon receiving the encrypted image, the data hider analyzes the image blocks and adaptively decides an optimal block-type labeling strategy. Based on the adaptive block encoding, the image is compressed to vacate the spare room, and the secret data are encrypted and embedded into the spare space. According to the granted authority, the receiver can restore the cover image, extract the secret data, or do both. Experimental results show that the embedding capacity of the proposed scheme outperforms state-of-the-art schemes. In addition, security level and robustness of the proposed scheme are also investigated.
C1 [Gao, Kai; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407, Taiwan.
   [Horng, Ji-Hwei] Natl Quemoy Univ, Dept Elect Engn, Kinmen 892, Taiwan.
C3 Feng Chia University
RP Horng, JH (corresponding author), Natl Quemoy Univ, Dept Elect Engn, Kinmen 89250, Taiwan.
EM gk0900787948@gmail.com; horng@email.nqu.edu.tw; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; Horng, Jihwei/GPX-5709-2022
OI Gao, Kai/0000-0002-7505-9037; Horng, Ji-Hwei/0000-0002-2134-5257
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., Image database of BOWS-2.
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chang CC, 2020, IEEE ACCESS, V8, P198425, DOI 10.1109/ACCESS.2020.3034936
   Chang CC, 2019, IEEE ACCESS, V7, P54117, DOI 10.1109/ACCESS.2019.2908924
   Chang CC, 2018, IEEE ACCESS, V6, P70720, DOI 10.1109/ACCESS.2018.2880904
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chen KM, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8091435
   Chen XF, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102702
   Chen YQ, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102584
   Fu YJ, 2019, INFORM SCIENCES, V494, P21, DOI 10.1016/j.ins.2019.04.043
   Gao XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107579
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   He MZ, 2019, IEEE ACCESS, V7, P141414, DOI 10.1109/ACCESS.2019.2943616
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Horng JH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092739
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   LI F, 2014, INT J NETW SECUR, V18, P410
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Malik A, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102374
   Pun C.-M., 2020, IEEE T DEPEND SECURE
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Wang Y. M., IEEE T MULTIMEDIA, V2021
   Wang Yuxin, 2020, IEEE T MULTIMEDIA
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Yi S, 2017, SIGNAL PROCESS, V133, P40, DOI 10.1016/j.sigpro.2016.10.017
   Zhang R, 2019, J INF SECUR APPL, V47, P199, DOI 10.1016/j.jisa.2019.05.005
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 32
TC 12
Z9 13
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103481
DI 10.1016/j.jvcir.2022.103481
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7YP
UT WOS:000779631900006
DA 2024-07-18
ER

PT J
AU Wu, W
   Zhou, K
   Chen, XD
AF Wu, Wen
   Zhou, Kai
   Chen, Xiao-Diao
TI Single image shadow detection via uncertainty analysis and GCN-based
   refinement strategy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Image processing; Shadow detection; Uncertainty
   quantification; Graph convolution networks
ID ILLUMINATION ESTIMATION; REMOVAL
AB Learning-based shadow detection methods have achieved an impressive performance, while these works still struggle on complex scenes, especially ambiguous soft shadows. To tackle this issue, this work proposes an efficient shadow detection network (ESDNet) and then applies uncertainty analysis and graph convolutional networks for detection refinement. Specifically, we first aggregate global information from high-level features and harvest shadow details in low-level features for obtaining an initial prediction. Secondly, we analyze the uncertainty of our ESDNet for an input shadow image and then take its intensity, expectation, and entropy into account to formulate a semi-supervised graph learning problem. Finally, we solve this problem by training a graph convolution network to obtain the refined detection result for every training image. To evaluate our method, we conduct extensive experiments on several benchmark datasets, i.e., SBU, UCF, ISTD, and even on soft shadow scenes. Experimental results demonstrate that our strategy can improve shadow detection performance by suppressing the uncertainties of false positive and false negative regions, achieving state-of-the-art results.
C1 [Wu, Wen; Zhou, Kai; Chen, Xiao-Diao] Hangzhou Dianzi Univ, Comp & Software Sch, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Wu, W; Chen, XD (corresponding author), Hangzhou Dianzi Univ, Comp & Software Sch, Hangzhou 310018, Peoples R China.
EM wuwen.hdu.cs@gmail.com; xiaodiao@hdu.edu.cn
RI Wu, Wen/HKW-7234-2023; Zhou, Kai/KVB-1378-2024
OI Wu, Wen/0000-0003-0919-3948; Zhou, Kai/0000-0003-2968-7267
FU National Natural Science Founda-tion of China [61972120, 62021002];
   National Key R&D Program of China [2020YFB1708900, TC190A4DA/3];
   National Social Science Foundation of China [20XGL029]; Natural Science
   Foun-dation of Xinjiang Autonomous Region of China [2020D01A48]; Basic
   Research Foundation of Wenzhou City in Zhejiang Province [2020G0018]
FX Acknowledgments The work was supported by the National Natural Science
   Founda-tion of China (61972120, 62021002) , the National Key R&D Program
   of China (2020YFB1708900) , TC190A4DA/3, and the National Social Science
   Foundation of China (20XGL029) , the Natural Science Foun-dation of
   Xinjiang Autonomous Region of China (2020D01A48) , and the Basic
   Research Foundation of Wenzhou City in Zhejiang Province (2020G0018) .
CR [Anonymous], 2020, J VIS COMMUN IMAGE R, V71
   [Anonymous], 2004, COMPUT VIS IMAGE UND, DOI DOI 10.1016/j.cviu.2004.03.008
   [Anonymous], 2008, Open Signal Process. J
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cucchiara R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P334, DOI 10.1109/ITSC.2001.948679
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z
   Fu J, 2019, IEEE I CONF COMP VIS, P6747, DOI 10.1109/ICCV.2019.00685
   Gal Y, 2016, PR MACH LEARN RES, V48
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gryka M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2732407
   Guo Ruiqi, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P2956, DOI 10.1109/TPAMI.2012.214
   Hamilton WL, 2017, ADV NEUR IN, V30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu XW, 2018, PROC CVPR IEEE, P7454, DOI 10.1109/CVPR.2018.00778
   Huang X, 2011, IEEE I CONF COMP VIS, P898, DOI 10.1109/ICCV.2011.6126331
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25
   Karsch K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024191
   Kendall A, 2017, 31 ANN C NEURAL INFO, V30
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Kipf T. N., 2017, 8 INT C LEARN REPR, P1
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163
   Le HE, 2018, LECT NOTES COMPUT SC, V11206, P680, DOI 10.1007/978-3-030-01216-8_41
   Li Q, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102901
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341
   Mohajerani S., 2018, 2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP), Vancouver, BC, 2018, P1
   Nielsen M, 2007, LECT NOTES COMPUT SC, V4522, P918
   Okabe Takahiro, 2009, 2009 IEEE 12th International Conference on Computer Vision (ICCV), P1693, DOI 10.1109/ICCV.2009.5459381
   Panagopoulos A, 2011, PROC CVPR IEEE, P673, DOI 10.1109/CVPR.2011.5995585
   Panagopoulos A, 2009, PROC CVPR IEEE, P651, DOI 10.1109/CVPRW.2009.5206665
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen L, 2015, PROC CVPR IEEE, P2067, DOI 10.1109/CVPR.2015.7298818
   Tambe RG, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103141
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Velickovic Petar, 2018, INT C LEARN REPR
   Vincente TFY, 2016, LECT NOTES COMPUT SC, V9910, P816, DOI 10.1007/978-3-319-46466-4_49
   Nguyen V, 2017, IEEE I CONF COMP VIS, P4520, DOI 10.1109/ICCV.2017.483
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang TY, 2020, PROC CVPR IEEE, P1877, DOI 10.1109/CVPR42600.2020.00195
   Wang YP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1007
   Wu L, 2010, COMPUT VIS IMAGE UND, V114, P915, DOI 10.1016/j.cviu.2010.04.003
   Wu S., 2019, P INT JOINT C ARTIFI, P4532
   Wu W., 2021, VISUAL COMPUT, P1
   Wu W, 2021, COMPUT GRAPH-UK, V95, P156, DOI 10.1016/j.cag.2021.02.005
   Xia YD, 2020, IEEE WINT CONF APPL, P3635, DOI [10.1109/wacv45572.2020.9093608, 10.1109/WACV45572.2020.9093608]
   Zhang L, 2020, AAAI CONF ARTIF INTE, V34, P12829
   Zheng QL, 2019, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2019.00531
   Zhou ZW, 2017, PROC CVPR IEEE, P4761, DOI 10.1109/CVPR.2017.506
   Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209
   Zhu L, 2018, LECT NOTES COMPUT SC, V11210, P122, DOI 10.1007/978-3-030-01231-1_8
NR 56
TC 4
Z9 4
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103397
DI 10.1016/j.jvcir.2021.103397
EA JAN 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I8FF
UT WOS:000779649200005
DA 2024-07-18
ER

PT J
AU Tan, K
   Xu, TB
   Wei, ZZ
AF Tan, Ke
   Xu, Ting-Bing
   Wei, Zhenzhong
TI Learning complementary Siamese networks for real-time high-performance
   visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Matching visualization; Complementary learning; Siamese
   networks
ID OBJECT TRACKING
AB Recently, Siamese based methods have made a breakthrough in the visual tracking field. However, the existing trackers still cannot take full advantage of the deep features. In this work, we improve the performances of Siamese trackers by complementary learning with different types of matching features. Specifically, a Matching Activation Network (MAN) is firstly designed to highlight the matching regions of the search image given a template. Since only sparse parts of feature maps contribute to the matching result, an important design choice is to emphasize the weak-matching features by erasing the strong-matching ones and learn complementary classifiers from both types of features. Then we propose a novel complementary region proposal network (CoRPN) to take complementary features as inputs and their outputs complement to each other, which are fused to improve the performance. Experiments show that our proposed tracker achieves leading performances on five tracking datasets while retaining real-time speed.
C1 [Tan, Ke; Xu, Ting-Bing; Wei, Zhenzhong] Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing, Peoples R China.
   [Tan, Ke; Xu, Ting-Bing; Wei, Zhenzhong] Minist Educ, Key Lab Precis Optomechatron Technol, Beijing, Peoples R China.
C3 Beihang University
RP Wei, ZZ (corresponding author), Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing, Peoples R China.
EM tanke@buaa.edu.cn; tingbing_xu@buaa.edu.cn; zhenzhongwei@buaa.edu.cn
OI Tan, Ke/0000-0001-7896-3702; Xu, Ting-Bing/0000-0002-0835-5792
FU National Science Fund for Distin-guished Young Scholars of China
   [51625501]
FX This work was supported by "National Science Fund for Distin-guished
   Young Scholars of China under Grant No. 51625501".
CR [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Erhan D, 2009, Univ Montr, V1341, P1
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li Y., 2019, ARXIV PREPRINT ARXIV
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Türetken E, 2017, IEEE T MED IMAGING, V36, P942, DOI 10.1109/TMI.2016.2640859
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiong M, 2018, P EUR C COMP VIS ECC
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang TY, 2021, IEEE T PATTERN ANAL, V43, P360, DOI 10.1109/TPAMI.2019.2929034
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 65
TC 3
Z9 3
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103299
DI 10.1016/j.jvcir.2021.103299
EA SEP 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900009
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Kirchner, M
AF Chakraborty, Sujoy
   Kirchner, Matthias
TI Sensor-based image manipulation localization with Discriminative Random
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Photo-response non-uniformity; Discriminative random field; Manipulation
   localization; Correlation predictor
ID ENERGY MINIMIZATION; FIELDS; NOISE
AB We present PRNU-based image manipulation localization as a probabilistic labeling task in a flexible discriminative random field (DRF) setup. Instead of reaching local decisions independent of each other, discriminative random fields incorporate local inter-label dependencies while keeping the formulation general enough to make label assignments depend on both local and non-local image characteristics. With an improved form of association potential combining normalized correlation and the deviation of the measured correlation from the expected correlation and an interaction potential defined as the weighted L2 norm squared between intensities of neighboring pixels, we were able to localize even considerably small manipulations on realistic tampered images. We experimented with different combinations of window sizes to capture features to predict the correlation more accurately than already existing algorithms. Experimental results indicate that our algorithm outperforms recent state of the art methods based on multiscale analysis strategies. We also found that for inspecting manipulated images which are JPEG compressed, it helps to train the predictor with JPEG images rather than with uncompressed images and for all quality factors, it is possible to work with two predictors, one trained for images with lower quality factors and another for higher quality factors.
C1 [Chakraborty, Sujoy] Stockton Univ, 101 Vera King Farris Dr, Galloway, NJ 08205 USA.
   [Kirchner, Matthias] Kitware Inc, 1712 US 9 Suite 300, Clifton Pk, NY 12065 USA.
C3 Stockton University; Kitware, Inc.
RP Chakraborty, S (corresponding author), Stockton Univ, 101 Vera King Farris Dr, Galloway, NJ 08205 USA.
EM matthias.kirchner@kitware.com
OI , Sujoy/0000-0002-4205-7553
FU DARPA; Air Force Research Laboratory (AFRL) [FA875016-2-0173]
FX This material is based on research sponsored by DARPA and Air Force
   Research Laboratory (AFRL) under agreement number FA875016-2-0173.
CR [Anonymous], 2010, J DIGITAL FORENSIC P
   [Anonymous], 2009, MEDIA FORENSICS SECU, DOI DOI 10.1117/12.805701
   Blake A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P1
   Böhme R, 2016, ARTECH H COMP SEC LI, P231
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chakraborty S., 2017, Electronic Imaging, P113
   Chakraborty S., 2020, IS T ELECT IMAGING M
   Chakraborty S, IS T ELECT IMAGING M, P2021
   Chen M., 2007, PROC SPIE ELECT IMAG, V6505, P1
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen M, 2007, LECT NOTES COMPUT SC, V4567, P342
   Chierchia Giovanni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6231, DOI 10.1109/ICASSP.2014.6854802
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Filler Tomas, 2008, 2008 15th IEEE International Conference on Image Processing - ICIP 2008, P1296, DOI 10.1109/ICIP.2008.4712000
   Fridrich J., 2013, Digital Image Forensics, P179
   Gloe T., 2012, Proceedings of the on Multimedia and security, P109
   Goljan M., 2008, P SPIE ELECT IMAGING, V6819
   Goljan M., 2008, Proceedings of SPIE, Electronic Imaging, Security, Forensics, Steganography, and Watermarking of Multimedia Contents X, V6819, P1
   He XM, 2004, PROC CVPR IEEE, P695
   Hyun DK, 2012, PROC SPIE, V8303, DOI 10.1117/12.907311
   Kirchner M, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035103
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Korus P, 2016, IEEE INT WORKS INFOR
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Kumar S, 2004, ADV NEUR IN, V16, P1531
   Kumar S, 2006, INT J COMPUT VISION, V68, P179, DOI 10.1007/s11263-006-7007-9
   Li S. Z., 2009, Markov random field modeling in image analysis
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mandelli S, 2020, IEEE SIGNAL PROC LET, V27, P1285, DOI 10.1109/LSP.2020.3008855
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467
   Plath N., 2009, P 26 ANN INT C MACH, P817, DOI DOI 10.1145/1553374.1553479
   Roig G, 2013, IEEE I CONF COMP VIS, P2312, DOI 10.1109/ICCV.2013.287
   Schmidt M., 2011, Ugm: A matlab toolbox for probabilistic undirected graphical models
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Sutton C, 2012, FOUND TRENDS MACH LE, V4, P267, DOI 10.1561/2200000013
   van Houten W, 2009, DIGIT INVEST, V6, P48, DOI 10.1016/j.diin.2009.05.003
   Verbeek J., 2008, NERUAL INFORM PROCES, P1553
   Yuille A, 2011, MARKOV RANDOM FIELDS FOR VISION AND IMAGE PROCESSING, P77
NR 41
TC 0
Z9 0
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103273
DI 10.1016/j.jvcir.2021.103273
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600010
OA Bronze
DA 2024-07-18
ER

PT J
AU Yang, JY
   Huang, Y
   Shao, ZP
   Liu, CP
AF Yang, Jianyu
   Huang, Yao
   Shao, Zhanpeng
   Liu, Chunping
TI Learning discriminative motion feature for enhancing multi-modal action
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion feature; Bag of features; Dynamic image; Action recognition
ID ACTION RECOGNITION; HIERARCHICAL MODEL
AB Video action recognition is an important topic in computer vision tasks. Most of the existing methods use CNN-based models, and multiple modalities of image features are captured from the videos, such as static frames, dynamic images, and optical flow features. However, these mainstream features contain much static information including object and background information, where the motion information of the action itself is not distinguished and strengthened. In this work, a new kind of motion feature is proposed without static information for video action recognition. We propose a quantization of motion network based on the bag-of feature method to learn significant and discriminative motion features. In the learned feature map, the object and background information is filtered out, even if the background is moving in the video. Therefore, the motion feature is complementary to the static image feature and the static information in the dynamic image and optical flow. A multi-stream classifier is built with the proposed motion feature and other features, and the performance of action recognition is enhanced comparing to other state-of-the-art methods.
C1 [Yang, Jianyu; Huang, Yao] Soochow Univ, Sch Rail Transportat, Suzhou 215000, Peoples R China.
   [Shao, Zhanpeng] Zhejiang Univ Technol, Sch Comp Sci & Technol, Hangzhou 310023, Peoples R China.
   [Liu, Chunping] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215000, Peoples R China.
C3 Soochow University - China; Zhejiang University of Technology; Soochow
   University - China
RP Shao, ZP (corresponding author), Zhejiang Univ Technol, Sch Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM jyyang@suda.edu.cn; zpshao@zjut.edu.cn
RI LU, CX/KFB-9510-2024; wen, liang/JNR-7720-2023; XIE,
   WANYING/JNR-9259-2023
OI Shao, Zhanpeng/0000-0002-8130-5230
FU National Natural Science Foundation of China (NSFC) [61773272,
   61976191]; Six Talent Peaks Project of Jiangsu Province, China
   [XYDXX-053]
FX This work was supported by the National Natural Science Founda-tion of
   China (NSFC No. 61773272, 61976191) and the Six Talent Peaks Project of
   Jiangsu Province, China (No. XYDXX-053) .
CR Baccouche M, 2010, LECT NOTES COMPUT SC, V6353, P154
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, ADV NEUR IN, V29
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Fernando B, 2017, INT J COMPUT VISION, V124, P335, DOI 10.1007/s11263-017-1030-x
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jiang M, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102846
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, ARXIV170506950
   Kingma D. P., 2014, arXiv
   Klaser A., 2008, BMVC 2008 19 BRIT MA, P1
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li Q, 2017, INT J MULTIMED INF R, V6, P85, DOI 10.1007/s13735-016-0117-4
   Li Q, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P159, DOI 10.1145/2911996.2912001
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Passalis N, 2017, IEEE I CONF COMP VIS, P5766, DOI 10.1109/ICCV.2017.614
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Pirsiavash H, 2014, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2014.85
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shao ZP, 2019, IEEE T CIRC SYST VID, V29, P2986, DOI 10.1109/TCSVT.2018.2871660
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tu ZG, 2019, IEEE T CIRC SYST VID, V29, P1423, DOI 10.1109/TCSVT.2018.2830102
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Wang Y, 2017, IEEE INT CONF COMP V, P2129, DOI 10.1109/ICCVW.2017.249
   Weng JW, 2017, PROC CVPR IEEE, P445, DOI 10.1109/CVPR.2017.55
   Wu HZ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P620, DOI 10.1145/3343031.3350891
   Yang JY, 2021, IEEE T MULTIMEDIA, V23, P883, DOI 10.1109/TMM.2020.2990082
   Yang JY, 2019, IEEE INT CON MULTI, P1078, DOI 10.1109/ICME.2019.00189
   Zheng YD, 2020, IEEE T IMAGE PROCESS, V29, P7970, DOI 10.1109/TIP.2020.3007826
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhu C, 2021, IEEE-CAA J AUTOMATIC, V8, P1600, DOI 10.1109/JAS.2019.1911534
NR 47
TC 5
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103263
DI 10.1016/j.jvcir.2021.103263
EA AUG 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800002
DA 2024-07-18
ER

PT J
AU Wen, HL
   You, SD
   Fu, Y
AF Wen, Huanglu
   You, Shaodi
   Fu, Ying
TI Cross-modal dynamic convolution for multi-modal emotion recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Artificial neural networks; Pattern; recognition Affective behavior;
   Multi-modal temporal sequences
ID BODY; REPRESENTATIONS; NETWORK; FUSION; FACE
AB Understanding human emotions requires information from different modalities like vocal, visual, and verbal. Since human emotion is time-varying, the related information is usually represented as temporal sequences and we need to identify both emotion-related clues and their cross-modal interactions inside. However, emotion related clues are sparse and misaligned in temporally unaligned sequences, making it hard for previous multi-modal emotion recognition methods to catch helpful cross-modal interactions. To this end, we present cross-modal dynamic convolution. To deal with sparsity, cross-modal dynamic convolution models the temporal dimension locally to avoid being overwhelmed by unrelated information. Cross-modal dynamic convolution is easy to stack, enabling it to model long-range cross-modal temporal interactions. Besides, models with cross modal dynamic convolution are more stable during training than with cross-modal attention, bringing more possibilities in multi-modal sequential model designing. Extensive experiments show that our method can achieve competitive performance compared to previous works while being more efficient.
C1 [Wen, Huanglu; Fu, Ying] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China.
   [You, Shaodi] Univ Amsterdam, Inst Informat, Comp Vis Res Grp, Amsterdam, Netherlands.
C3 Beijing Institute of Technology; University of Amsterdam
RP Fu, Y (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China.
EM fuying@bit.edu.cn
RI Fu, Ying/HMD-6838-2023; Shaodi, YOU/AAA-4524-2022; Fu,
   Ying/HKF-7270-2023
OI Shaodi, YOU/0000-0001-8973-645X; 
FU National Natural Science Foundation of China [61827901, 62088101,
   61936011]
FX This work was supported by the National Natural Science Foundation of
   China under Grants No. 61827901, No. 62088101, and No. 61936011.
CR Abdat F, 2011, UKSIM EURO SYMP COMP, P196, DOI 10.1109/EMS.2011.20
   [Anonymous], 1997, NEURAL COMPUT
   Ba J.L., 2016, P ADV NEUR INF PROC
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Belin P, 2011, BRIT J PSYCHOL, V102, P711, DOI 10.1111/j.2044-8295.2011.02041.x
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cañamero L, 2005, NEURAL NETWORKS, V18, P445, DOI 10.1016/j.neunet.2005.03.003
   Castellano G, 2008, LECT NOTES COMPUT SC, V4868, P92, DOI 10.1007/978-3-540-85099-1_8
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   de Gelder B, 2006, NAT REV NEUROSCI, V7, P242, DOI 10.1038/nrn1872
   Delbrouck JB, 2020, PROCEEDINGS OF THE SECOND GRAND CHALLENGE AND WORKSHOP ON MULTIMODAL LANGUAGE (CHALLENGE-HML), VOL 1, P1
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Erickson K, 2003, BRAIN COGNITION, V52, P52, DOI 10.1016/S0278-2626(03)00008-3
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Gilleade K, 2005, DIGRA 2005 CHANGING
   Gilles D., 2014, 2014 IEEE INT C, P960
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Gunes H, 2005, IEEE SYS MAN CYBERN, P3437
   Jordan MI., 1997, ADV PSYCHOL, V121, P471, DOI [DOI 10.1016/S0166-4115(97)80111-2, 10.1016/s0166-4115(97)80111-2]
   Kockmann M, 2011, SPEECH COMMUN, V53, P1172, DOI 10.1016/j.specom.2011.01.007
   Liang PP, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P150
   Liu Lingjie, 2020, ARXIV PREPRINT ARXIV
   Mittal T., 2020, ARXIV PREPRINT ARXIV, P14234
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Pham H, 2019, AAAI CONF ARTIF INTE, P6892
   Ramirez GA, 2011, LECT NOTES COMPUT SC, V6975, P396, DOI 10.1007/978-3-642-24571-8_51
   Sahay S, 2020, PROCEEDINGS OF THE SECOND GRAND CHALLENGE AND WORKSHOP ON MULTIMODAL LANGUAGE (CHALLENGE-HML), VOL 1, P29
   Saxbe DE, 2013, SOC COGN AFFECT NEUR, V8, P806, DOI 10.1093/scan/nss075
   Schuller B, 2005, P INT 2005 P EUR C S
   Shenoy A, 2020, PROCEEDINGS OF THE SECOND GRAND CHALLENGE AND WORKSHOP ON MULTIMODAL LANGUAGE (CHALLENGE-HML), VOL 1, P19
   Tsai Y. H., 2019, 7 INT C LEARN REPR I
   Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YS, 2019, AAAI CONF ARTIF INTE, P7216
   Wu CH, 2016, BRIT J EDUC TECHNOL, V47, P1304, DOI 10.1111/bjet.12324
   Wu Felix, 2019, P INT C LEARN REPR
   Yacoub S. M., 2003, INTERSPEECH
   Yuan J, 2008, J ACOUST SOC AM, V124, P2078, DOI 10.1121/1.2968700
   Zadeh A., 2017, P 2017 C EMP METH NA, P1103, DOI 10.18653/v1/D17-1115
   Zadeh A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2236
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5642
   Zadeh A, 2018, AAAI CONF ARTIF INTE, P5634
NR 43
TC 10
Z9 10
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103178
DI 10.1016/j.jvcir.2021.103178
EA JUN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA TL1KZ
UT WOS:000674615200002
DA 2024-07-18
ER

PT J
AU Sena, J
   Jorda, A
   Schwartz, WR
AF Sena, Jessica
   Jorda, Artur
   Schwartz, William Robson
TI A content-based late fusion approach applied to pedestrian detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edestrian detection; Content-based fusion; Spatial consensus; Multiple
   detectors; Late fusion
AB The diversity of pedestrians detectors proposed in recent years has encouraged some works to fuse them to achieve a more accurate detection. The intuition behind it is to combine the detectors based on its spatial consensus. The hypothesis is that a location pointed by multiple detectors has a high probability of actually belonging to a pedestrian, while false positive regions have little consensus among detectors (small support) which allows discarding the false positives in these regions. We proposed a novel method called Content-Based Spatial Consensus (CSBC), which, in addition to relying on spatial consensus, considers the content of the detection windows to learn a weighted-fusion of pedestrian detectors. The result is a reduction in false alarms and an enhancement in the detection. In this work, we also demonstrated that there is small influence of the feature used to learn the contents of the windows of each detector, which enables our method to be efficient even employing simple features. The CSBC overcomes state-of-the-art fusion methods in the ETH dataset and the Caltech dataset. Particularly, our method is also more efficient, since fewer detectors are necessary to achieve expressive results.
C1 [Sena, Jessica; Jorda, Artur; Schwartz, William Robson] Univ Fed Minas Gerais, Dept Comp Sci, Smart Surveillance Interest Grp, Av Presidente Antonio Carlos 6627, Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais
RP Sena, J (corresponding author), Univ Fed Minas Gerais, Dept Comp Sci, Smart Surveillance Interest Grp, Av Presidente Antonio Carlos 6627, Belo Horizonte, MG, Brazil.
EM jessicasena@dcc.ufmg.br; arturjordao@dcc.ufmg.br; william@dcc.ufmg.br
RI Schwartz, William Robson/E-6612-2011; Sena, Jessica/AAR-2655-2020
OI Sena, Jessica/0000-0002-5128-3632
FU National Council for Scientific and Technological Development - CNPq
   [438629/2018-3, 309953/2019-7]; Minas Gerais Research Foundation
   -FAPEMIG [APQ-00567-14, PPM-00540-17]; Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior -Brasil (CAPES) [001]
FX The authors would like to thank the National Council for Scientific and
   Technological Development - CNPq (Grants similar to 438629/2018-3 and
   similar to 309953/2019-7) and the Minas Gerais Research Foundation
   -FAPEMIG (Grants similar to APQ-00567-14 and similar to PPM-00540-17.
   This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior -Brasil (CAPES) -Finance Code 001.
CR [Anonymous], 2018, P EUR C COMP VIS
   [Anonymous], 2016, IEEE ICC
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2015, BMVC
   [Anonymous], 2010, ADV NEURAL INF PROCE
   [Anonymous], 2013, CVPR
   [Anonymous], 2013, CVPR
   [Anonymous], 2013, CVPR
   [Anonymous], 2014, ECCV
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Cao Y., 2020, P IEEE CVF C COMP VI, P11583
   Costea AD, 2014, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2014.307
   de Melo VHC, 2014, INT C PATT RECOG, P4346, DOI 10.1109/ICPR.2014.744
   de Melo VHC, 2013, IEEE IMAGE PROC, P4146, DOI 10.1109/ICIP.2013.6738854
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J., 2009, CVPR09
   Doll ar P., 2009, CVPR
   Dollar P., 2009, BMV
   Duan PF, 2015, IEEE IC COMP COM NET
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Jordao A., 2016, IAPR INT C PATT REC, P1
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Khan R, 2013, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR.2013.369
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P5571, DOI 10.1109/TIP.2020.2985284
   Li XL, 2017, AAAI CONF ARTIF INTE, P4147
   Luo P, 2014, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2014.120
   Marin J., 2013, ICCV
   Mathias M, 2013, IEEE I CONF COMP VIS, P1505, DOI 10.1109/ICCV.2013.190
   Morvant E, 2014, LECT NOTES COMPUT SC, V8621, P153, DOI 10.1007/978-3-662-44415-3_16
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Paisitkriangkrai S, 2013, IEEE I CONF COMP VIS, P1057, DOI 10.1109/ICCV.2013.135
   Pop D.O., 2017, ESANN 2017
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Schwartz W.R., 2011, CIARP 2011
   Schwartz W.R., IB C PATT REC, P181
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Toca M.C. C., 2015, BMVC
   Trichet R, 2018, IEEE WINT CONF APPL, P1066, DOI 10.1109/WACV.2018.00122
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wagner J., 2016, EUR S ART NEUR NETW
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wold H., 1985, Partial least squares
   Zhang SS, 2014, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2014.126
   Zitnick III C.L., 2013, US Patent App., Patent No. [13/794,857, 13794857]
NR 52
TC 0
Z9 0
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103091
DI 10.1016/j.jvcir.2021.103091
EA APR 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xie, YR
   Song, TC
   Li, W
AF Xie, Yurui
   Song, Tiecheng
   Li, Wei
TI Semantic-aware visual attributes learning for zero-shot recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero-shot learning; Human-designed attributes; Visual attributes;
   Semantic representation
ID OBJECT
AB Zero-shot learning (ZSL) aims to recognize unseen image classes without requiring any training samples of these specific classes. The ZSL problem is typically achieved by building up a semantic embedding space like attributes to bridge the visual features and class labels of images. Currently, most ZSL approaches focus on learning a visual-semantic alignment from seen classes using only the human-designed attributes, and then ZSL problem is solved by transferring semantic knowledge from seen classes to the unseen classes. However, few works indicate if the human-designed attributes are discriminative enough for image class prediction. To address this issue, we propose a semantic-aware dictionary learning (SADL) framework to explore these discriminative visual attributes across seen and unseen classes. Furthermore, the semantic cues are elegantly integrated into the feature representations via learned visual attributes for recognition task. Experiments conducted on two challenging benchmark datasets show that our approach outweighs other state-of-the-art ZSL methods.
C1 [Xie, Yurui] Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
   [Song, Tiecheng] Chongqing Univ Posts & Telecommun, 2 Chongwen Rd, Chongqing, Peoples R China.
   [Li, Wei] Southwest Jiaotong Univ, 999 Xi An Rd, Chengdu, Peoples R China.
C3 Chengdu University of Information Technology; Chongqing University of
   Posts & Telecommunications; Southwest Jiaotong University
RP Xie, YR (corresponding author), Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
EM gloriousxyr@163.com; songtc@cqupt.edu.cn; liwei@swjtu.edu.cn
FU National Natural Science Foundation of China [61806028, 61702065];
   Program for Educational Foundation of Sichuan Province, China [18ZB0125]
FX This work was supported by The National Natural Science Foundation of
   China (No. 61806028, No. 61702065), and in part by the Program for
   Educational Foundation of Sichuan Province, China (No. 18ZB0125).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   [Anonymous], 2014, ICLR
   Ashual O, 2019, IEEE I CONF COMP VIS, P4560, DOI 10.1109/ICCV.2019.00466
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Jiang HJ, 2018, LECT NOTES COMPUT SC, V11214, P121, DOI 10.1007/978-3-030-01249-6_8
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ren YZ, 2017, J VIS COMMUN IMAGE R, V42, P192, DOI 10.1016/j.jvcir.2016.11.004
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song J, 2020, PROC CVPR IEEE, P3921, DOI 10.1109/CVPR42600.2020.00398
   Song J, 2019, ADV NEUR IN, V32
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Song J, 2018, LECT NOTES COMPUT SC, V11213, P474, DOI 10.1007/978-3-030-01240-3_29
   Thomas SS, 2016, J VIS COMMUN IMAGE R, V38, P367, DOI 10.1016/j.jvcir.2016.03.015
   Tong B, 2019, PROC CVPR IEEE, P11459, DOI 10.1109/CVPR.2019.01173
   Verma VK, 2017, LECT NOTES ARTIF INT, V10535, P792, DOI 10.1007/978-3-319-71246-8_48
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V59, P563, DOI 10.1016/j.jvcir.2019.02.006
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 38
TC 2
Z9 2
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103010
DI 10.1016/j.jvcir.2020.103010
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500002
DA 2024-07-18
ER

PT J
AU Zhang, L
   Chen, LT
   Ou, WH
   Zhou, CA
AF Zhang, Lei
   Chen, Leiting
   Ou, Weihua
   Zhou, Chuan
TI Semi-supervised cross-modal representation learning with GAN-based
   Asymmetric Transfer Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-modal retrieval; Modality gap; Generative adversarial network
AB In this paper, we proposed a semi-supervised common representation learning method with GAN-based Asymmetric Transfer Network (GATN) for cross modality retrieval. GATN utilizes the asymmetric pipeline to guarantee the semantic consistency and adopt (Generative Adversarial Network) GAN to fit the distributions of different modalities. Specifically, the common representation learning across modalities includes two stages: (1) the first stage, GATN trains source mapping network to learn the semantic representation of text modality by supervised method; and (2) the second stage, GAN-based unsupervised modality transfer method is proposed to guide the training of target mapping network, which includes generative network (target mapping network) and discriminative network. Experimental results on three widely-used benchmarks show that GATN have achieved better performance comparing with several existing state-of-the-art methods.
C1 [Zhang, Lei; Chen, Leiting; Zhou, Chuan] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
   [Zhang, Lei; Chen, Leiting; Zhou, Chuan] Univ Elect Sci & Technol China, Digital Media Technol Key Lab Sichuan Prov, Chengdu, Peoples R China.
   [Chen, Leiting] Inst Elect & Informat Engn UESTC Guangdong, Dongguan, Peoples R China.
   [Ou, Weihua] Guizhou Normal Univ, Sch Big Data & Comp Sci, Guiyang, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; Guizhou Normal University
RP Zhou, CA (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China.
EM zhouchuan@uestc.edu.cn
RI Ou, Weihua/AAD-9887-2020
OI Zhang, Lei/0000-0002-4477-5532
FU Key-Area Research and Development Program of Guangdong Province
   [2019B010136003]; Sichuan Science and Technology Program [2019YJ0176,
   2019YJ0177, 2019YFQ0005]; National Natural Science Foundation of China
   [61762021, 61962010]; Nature Science Foundation of Guizhou Province
   [[2017]1130]; Excellent scientific and technological talents in Guizhou
   Province [[2019]5670]
FX This work was supported by Key-Area Research and Development Program of
   Guangdong Province (No. 2019B010136003), Sichuan Science and Technology
   Program (No. 2019YJ0176, No. 2019YJ0177, No. 2019YFQ0005), National
   Natural Science Foundation of China under Grants 61762021 and 61962010,
   Nature Science Foundation of Guizhou Province under Grant [2017]1130 and
   Excellent scientific and technological talents in Guizhou Province
   (Grant [2019]5670).
CR Andrew G., 2013, ICML, P1247
   [Anonymous], 2011, P ICML
   Belkin M, 2004, LECT NOTES COMPUT SC, V3120, P624, DOI 10.1007/978-3-540-27819-1_43
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Dong F, 2018, J VIS COMMUN IMAGE R, V57, P28, DOI 10.1016/j.jvcir.2018.10.006
   Feng FX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P7, DOI 10.1145/2647868.2654902
   Finn C, 2016, ADV NEUR IN, V29
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hu P, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P635, DOI 10.1145/3331184.3331213
   Huang X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1893
   Huang X, 2020, IEEE T CYBERNETICS, V50, P1047, DOI 10.1109/TCYB.2018.2879846
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Peng Y, 2016, P INT JOINT C ART IN, P3846
   Peng YX, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3284750
   Peng YX, 2018, IEEE T MULTIMEDIA, V20, P405, DOI 10.1109/TMM.2017.2742704
   Quadrianto Novi., 2011, ICML, P425
   Radford A., 2015, ARXIV
   Rashtchian C., 2010, P NAACL HLT 2010 WOR, V2010, P139, DOI DOI 10.5555/1866696.1866717
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang BK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P154, DOI 10.1145/3123266.3123326
   Wang K, 2016, ARXIV ABS160706215
   Wang KY, 2013, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2013.261
   Wei YC, 2017, IEEE T CYBERNETICS, V47, P449, DOI 10.1109/TCYB.2016.2519449
   Xia ZQ, 2019, J VIS COMMUN IMAGE R, V59, P108, DOI 10.1016/j.jvcir.2019.01.011
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan F, 2015, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2015.7298966
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhang X., 2015, Deep Transfer Network: Unsupervised Domain Adaptation
NR 35
TC 1
Z9 1
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102899
DI 10.1016/j.jvcir.2020.102899
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200002
DA 2024-07-18
ER

PT J
AU Tang, PJ
   Tan, YL
   Li, JZ
   Tan, B
AF Tang, Pengjie
   Tan, Yunlan
   Li, Jinzhong
   Tan, Bin
TI Translating video into language by enhancing visual and language
   representations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video description; Feature enhancing; CNN; LSTM; Semantic
AB It is a fundamental task of translating videos into natural language automatically by computer. At present, the models for video description based on deep learning have made a great breakthrough. However, the static information loss is serious during encoding stage for motion feature of videos, and the linguistic feature from LSTM network lack personalized expression, leading to inappropriate words and poor semantics in generation sentences. In this work, a model with enhanced features of visual and language is proposed to address the challenges. First, static features of video frames from the first LSTM layer are incorporated, then fed into another LSTM layer according by frame sequence. Second, the feature of word is combined with the output of LSTM network for predicted probability of candidate word on each time step. The experimental results demonstrate effectiveness of the proposed approach with competitive performance compared with other state-of-the-art methods on various metrics.
C1 [Tang, Pengjie; Tan, Yunlan; Li, Jinzhong; Tan, Bin] Jinggangshan Univ, Coll Elect & Informat Engn, Jian 343009, Jiangxi, Peoples R China.
   [Tang, Pengjie; Tan, Yunlan; Li, Jinzhong; Tan, Bin] Jiangxi Engn Lab IoT Technol Crop Growth, Jian 343009, Jiangxi, Peoples R China.
C3 Jinggangshan University
RP Tan, YL (corresponding author), Jinggangshan Univ, Coll Elect & Informat Engn, Jian 343009, Jiangxi, Peoples R China.
EM tanyunlan@163.com
FU Ph.D. Research Initiation Project of Jinggangshan University [JZB1923,
   JZB1807]; Bidding Project for the Foundation of College's Key Research
   on Humanities and Social Science of Jiangxi Province [JD17082]; Research
   Foundation of Art Planning of Jiangxi Province [YG2017283]; National
   Natural Science Foundation of PR China [61976159]
FX This work was supported in part by Ph.D. Research Initiation Project of
   Jinggangshan University (No. JZB1923, JZB1807), Bidding Project for the
   Foundation of College's Key Research on Humanities and Social Science of
   Jiangxi Province (No. JD17082), and Research Foundation of Art Planning
   of Jiangxi Province (No. YG2017283), and National Natural Science
   Foundation of PR China (No. 61976159).
CR [Anonymous], 2016, PROC 24 ACM INT C MU, DOI [DOI 10.1145/2964284.2984065, 10.1145/2964284.2984065]
   [Anonymous], 2016, P 24 ACM INT C MULTI, DOI DOI 10.1145/2964284.2984066
   Ballas Nicolas, 2015, Comput. Sci
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Chen JW, 2019, AAAI CONF ARTIF INTE, P8167
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dong JF, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1082, DOI 10.1145/2964284.2984064
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin Chin-Yew, 2004, P 42 ANN M AOC COMP, P605, DOI [DOI 10.3115/.1218955.1219032, DOI 10.3115/1218955.1219032]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pan PB, 2016, PROC CVPR IEEE, P1029, DOI 10.1109/CVPR.2016.117
   Pan YW, 2017, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2017.111
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach M, 2013, IEEE I CONF COMP VIS, P433, DOI 10.1109/ICCV.2013.61
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shaw D, 2011, IMPACT OF THE ECONOMIC CRISIS ON EAST ASIA: POLICY RESPONSES FROM FOUR ECONOMIES, P190
   Shen ZQ, 2017, PROC CVPR IEEE, P5159, DOI 10.1109/CVPR.2017.548
   Shetty R., 2016, P 24 ACM INT C MULTI, P1073
   Simonyan K., 2014, CORR
   Simonyan K, 2014, ADV NEUR IN, V27
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Thomason J., 2014, COLING, P1218
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S., 2015, P ANN C N AM CHAPT A, P1494, DOI 10.3115/v1/N15-1173
   Venugopalan S., 2016, EMNLP, P1961
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang BR, 2018, PROC CVPR IEEE, P7622, DOI 10.1109/CVPR.2018.00795
   Wang JB, 2018, PROC CVPR IEEE, P7512, DOI 10.1109/CVPR.2018.00784
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443
   Wang X, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON MATHEMATICS AND ARTIFICIAL INTELLIGENCE (ICMAI 2018), P79, DOI 10.1145/3208788.3208802
   Xu H., 2015, WORKSH CLOS LOOP VIS
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Xu R, 2015, AAAI CONF ARTIF INTE, P2346
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yao K., 2015, Depth-gated recurrent neural networks
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yu Y, 2017, PROC CVPR IEEE, P3261, DOI 10.1109/CVPR.2017.347
NR 56
TC 1
Z9 1
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102875
DI 10.1016/j.jvcir.2020.102875
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400005
DA 2024-07-18
ER

PT J
AU Xiao, L
   Wu, B
   Hu, YM
AF Xiao, Ling
   Wu, Bo
   Hu, Youmin
TI OSED: Object-specific edge detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Region proposal; Edge detection; Deep supervision; Convolutional neural
   network
AB Object-specific edge detection (OSED) aims to detect object edges in an image along with classify the edge into object or non-object. It prunes edges which are not belonging to the object class for following processing, such as, feature matching for object detection, localization and three-dimensional reconstruction. In this paper, an OSED method that combines region proposal detectors with deep supervision nets to identify object-specific edges is proposed. It minimizes errors of object proposal by learning from hidden layers. Additionally, it combines features from different scales to detect object edges. In order to evaluate the performance of the OSED, we present two datasets which are captured in real scenes. The OSED method demonstrates a high accuracy of 90% and a high speed of 0.5 s for an image whose size is 512 x 448 pixels on the proposed datasets.
C1 [Xiao, Ling; Wu, Bo; Hu, Youmin] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Luoyu Rd 1037, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Hu, YM (corresponding author), Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Luoyu Rd 1037, Wuhan 430074, Hubei, Peoples R China.
EM youmhwh@hust.edu.cn
FU China Scholarship Council [201806160119]
FX The research work was funded by the China Scholarship Council with a
   scholarship (No. 201806160119).
CR Abouelfarag A, 2017, ADV BUS INFORM SYST, P1, DOI 10.4018/978-1-5225-2492-2.ch001
   Akula A, 2014, INFRARED PHYS TECHN, V63, P103, DOI 10.1016/j.infrared.2013.12.012
   Bai K, 2018, J SEISM EXPLOR, V27, P531
   Bar-On I, 2009, PROCEEDINGS OF THE 9TH BIENNIAL CONFERENCE ON ENGINEERING SYSTEMS DESIGN AND ANALYSIS - 2008, VOL 1, P97
   Bertasius G, 2015, PROC CVPR IEEE, P4380, DOI 10.1109/CVPR.2015.7299067
   Chen LC, 2016, PROC CVPR IEEE, P4545, DOI 10.1109/CVPR.2016.492
   Fan P, 2019, QUANTUM INF PROCESS, V18, DOI 10.1007/s11128-018-2131-3
   Geng Hao, 2013, 2013 5th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC 2013), P527, DOI 10.1109/IHMSC.2013.273
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Gupta Ashish, 2011, Platelets, DOI 10.3109/09537104.2010.547958
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He YS, 2019, IEEE T IMAGE PROCESS, V28, P1613, DOI 10.1109/TIP.2018.2880568
   Hwang J.J., 2015, P IEEE C COMP VIS PA
   Karsch K, 2013, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2013.281
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li ES, 2009, 2009 INTERNATIONAL CONFERENCE ON ENVIRONMENTAL SCIENCE AND INFORMATION APPLICATION TECHNOLOGY,VOL I, PROCEEDINGS, P465, DOI 10.1109/ESIAT.2009.49
   Liu Y, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278091
   Liu Y, 2016, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2016.32
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Moradi M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033013
   Pai YT, 2010, PATTERN RECOGN, V43, P3177, DOI 10.1016/j.patcog.2010.03.014
   Prasad M, 2006, LECT NOTES COMPUT SC, V4338, P94
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Romani L, 2019, J COMPUT APPL MATH, V349, P532, DOI 10.1016/j.cam.2018.08.006
   Rong WB, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (IEEE ICMA 2014), P577, DOI 10.1109/ICMA.2014.6885761
   Shan Q, 2014, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR.2014.511
   Shen Y, 2018, LECT NOTES COMPUT SC, V11046, P389, DOI 10.1007/978-3-030-00919-9_45
   Simonyan K., 2014, CORR
   Traore BB, 2018, ECOL INFORM, V48, P257, DOI 10.1016/j.ecoinf.2018.10.002
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang LM, 2007, LECT NOTES COMPUT SC, V4843, P189
   Wang S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/76278
   Wen CB, 2018, J VIS COMMUN IMAGE R, V57, P84, DOI 10.1016/j.jvcir.2018.10.017
   Wu JL, 2018, GEOTECH SP, P377
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Zeng ZL, 2018, 2018 JOINT 7TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV) AND 2018 2ND INTERNATIONAL CONFERENCE ON IMAGING, VISION & PATTERN RECOGNITION (ICIVPR), P19, DOI 10.1109/ICIEV.2018.8641005
   Zhang Y, 2017, 2017 IEEE 3RD INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC), P457, DOI 10.1109/ITOEC.2017.8122336
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 44
TC 0
Z9 0
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102918
DI 10.1016/j.jvcir.2020.102918
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400022
DA 2024-07-18
ER

PT J
AU Sun, S
AF Sun, Shuo
TI Application of fuzzy image restoration in criminal investigation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fuzzy image restoration; Image degradation; Criminal investigation
ID QUALITY ASSESSMENT; STRUCTURAL SIMILARITY
AB The advancement of science and technology has a positive effect on the development of law disciplines. The development of algorithms and artificial intelligence also has a certain impact on judicial practice. Image restoration is a significant technique in image processing. It aims to objectively restore the content or quality of the original image from the degraded image. Image degradation is always generated in image transmission, such as distortion, blur. In modern video surveillance system, image restoration is significant for criminal investigation. However, image restoration based on conventional filter algorithms cannot achieve satisfactory performance. Thus, we first introduce the image restoration algorithms based on different degradation model. Then, we propose some applications of fuzzy image restoration in criminal investigation. We conduct experiments on both degraded images and videos and experimental results have shown the effectiveness of fuzzy image restoration applying to the criminal investigation. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Sun, Shuo] Sch Henan Univ Econ & Law, Zhengzhou, Peoples R China.
RP Sun, S (corresponding author), Sch Henan Univ Econ & Law, Zhengzhou, Peoples R China.
EM 460317053@qq.com
FU School of Law of Henan University of Economics and Law
FX This work was supported by the School of Law of Henan University of
   Economics and Law for giving me a strong interest in law.
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2014, DEEP LEARNING FACE A
   [Anonymous], 2016, ADV FACE DETECTION F
   [Anonymous], 2013, 4 INT IEEE WORKSH 3D
   Chang J, 2019, J VIS COMMUN IMAGE R, V58, P316, DOI 10.1016/j.jvcir.2018.11.047
   Chen G.H., 2006, P 2006 IEEE INT C AC, V2, pII
   Dong WS, 2015, INT J COMPUT VISION, V114, P217, DOI 10.1007/s11263-015-0808-y
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Kheradmand A, 2014, IEEE T IMAGE PROCESS, V23, P5136, DOI 10.1109/TIP.2014.2362059
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Papyan V., 2015, IEEE T IMAGE PROCESS, P1
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   RICHARDSON WH, 1972, J OPT SOC AM, V62, P55, DOI 10.1364/JOSA.62.000055
   Shi YY, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P329, DOI 10.1109/ICECT.2009.116
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu ML, 2017, J COMPUT SCI TECH-CH, V32, P1162, DOI 10.1007/s11390-017-1791-2
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yu K., 2018, CRAFTING TOOLCHAIN I
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 28
TC 4
Z9 4
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102704
DI 10.1016/j.jvcir.2019.102704
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900029
DA 2024-07-18
ER

PT J
AU Pal, T
   Bit, SD
AF Pal, Tamal
   Bit, Sipra Das
TI Low overhead spatiotemporal video compression over smartphone based
   Delay Tolerant Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Colour filter array; Sobel filter; Inter-frame compression; Intra-frame
   compression; Delay tolerant network; Wi-fi direct
AB In this paper we provide a lightweight video compression scheme, Low Overhead Spatio-Temporal Video compression (Lost-Vision) scheme which is done through inter-frame and intra-frame compression. In inter-frame compression redundant frames are removed by a proposed interpolation search-based method and a lightweight edge detection technique. Then intra-frame compression is done by a proposed adaptive column dropping technique modifying an existing technique namely ICCD. At the receiver end, we propose two reconstruction filters targeting to improve reconstruction quality. Performance of our scheme in terms of energy efficiency and reconstruction quality is evaluated both theoretically and practically. In practical implementation, the proposed video compression scheme is assessed in a real environment with different terrains using a smartphones/tablet-based DTN-like network. A Comparison of our scheme with three recent works on video compression shows our scheme's dominance over the competing works with 52%, 45.6% and 53% energy in saving yet maintaining acceptable reconstruction quality. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Pal, Tamal; Bit, Sipra Das] Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Sibpur, Howrah, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Pal, T (corresponding author), Indian Inst Engn Sci & Technol, Dept Comp Sci & Technol, Sibpur, Howrah, India.
EM tamalpal91@yahoo.co.in; sdasbit@yahoo.co.in
CR Alain M, 2015, SIGNAL PROCESS-IMAGE, V37, P47, DOI 10.1016/j.image.2015.07.011
   Azim Mostafa A., 2015, WIRELESS SENSOR MULT, P202, DOI DOI 10.1201/B19230
   Basu S., 2018, IEEE T SYST MAN CYBE
   Basu S., 2016, HUMAN MOBILITY BASED
   Chefi A, 2013, J SYST ARCHITECT, V59, P818, DOI 10.1016/j.sysarc.2013.07.010
   Cheng D, 2018, PIPELINES 2018: PLANNING AND DESIGN, P111
   Ching-Lung Su., 2014, IEEE T CIRCUITS SYST, V24, P1016
   Contreras D, 2015, AD HOC NETW, V25, P444, DOI 10.1016/j.adhoc.2014.08.007
   Das Bit S., 2008, Foundations of Computing and Decision Sciences, V33, P211
   Das N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   Dhungel A, 2011, PROCEEDINGS OF THE 49TH ANNUAL ASSOCIATION FOR COMPUTING MACHINERY SOUTHEAST CONFERENCE (ACMSE '11), P216
   Dolly DRJ, 2017, J COMPUT SCI-NETH, V18, P1, DOI 10.1016/j.jocs.2016.11.003
   Duan LJ, 2015, SIGNAL PROCESS-IMAGE, V38, P45, DOI 10.1016/j.image.2015.08.005
   Furnari A, 2017, J VIS COMMUN IMAGE R, V46, P165, DOI 10.1016/j.jvcir.2017.03.019
   Galan-Hernandez JC, 2018, ENG APPL ARTIF INTEL, V69, P127, DOI 10.1016/j.engappai.2017.12.008
   Hosseini MS, 2012, IEEE INT WORKSH MULT, P31, DOI 10.1109/MMSP.2012.6343411
   Kaporis Alexis, 2019, INFORM COMPUT, V270, P1
   Kim J, 2010, IEEE T CIRC SYST VID, V20, P848, DOI 10.1109/TCSVT.2010.2045923
   Li Z, 2014, AD HOC NETW, V22, P61, DOI 10.1016/j.adhoc.2014.05.004
   Pal T, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   Pal T, 2018, COMPUT ELECTR ENG, V70, P594, DOI 10.1016/j.compeleceng.2017.09.006
   Paul PS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P280, DOI 10.1109/PERCOMW.2015.7134047
   PRERNA, 2016, 7 IEEE ANN INF
   Shaw MQ, 2015, SIGNAL PROCESS-IMAGE, V39, P355, DOI 10.1016/j.image.2015.04.008
   Vasilakis E, 2015, FORTHICSTR450 CARV L
   Wang XQ, 2016, IEEE T CIRC SYST VID, V26, P673, DOI 10.1109/TCSVT.2015.2416571
   Xiao JS, 2017, SIGNAL PROCESS-IMAGE, V50, P21, DOI 10.1016/j.image.2016.11.001
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
   Zhang L, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON PUBLIC ADMINISTRATION (6TH), VOL II, P105, DOI 10.1145/1878961.1878982
   Zhang X, 2017, IEEE T IMAGE PROCESS, V26, P633, DOI 10.1109/TIP.2016.2629447
NR 32
TC 4
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102813
DI 10.1016/j.jvcir.2020.102813
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900019
DA 2024-07-18
ER

PT J
AU Vlasic, T
   Ralasic, I
   Tafro, A
   Sersic, D
AF Vlasic, Tin
   Ralasic, Ivan
   Tafro, Azra
   Sersic, Damir
TI Spline-like Chebyshev polynomial model for compressive imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Polynomial representation of image; Chebyshev moments; Runge phenomenon;
   Sparse modeling; Compressive sensing; 2D-imaging
ID FINITE RATE; INTERPOLATION; APPROXIMATION; STRATEGIES; TRANSFORM;
   SIGNALS; MOMENTS; ERROR
AB This paper introduces a novel spline-like parametric model for an image representation obtained directly from compressive imaging (CI) measurements. As a representation basis we use Chebyshev polynomials. To avoid common problem of blocking artifacts in block-based reconstruction algorithms, a desired number of derivatives are equated on the block boundaries in a spline-like fashion. This introduces a new set of constraints that fits into CI setup. Unlike splines, the proposed system of equations is underdetermined to provide a necessary degree of freedom for achieving sparsity by solving an l(1) optimization problem. Recovered coefficients of the parametric model can be further used for image processing where operations can be elegantly defined and calculated. This offers a new framework for acquisition and processing of analog signals without converting them into samples. Experiments on real measurements show that our model achieves sparse representation without visible blocking artifacts from a reduced set of CI measurements. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Vlasic, Tin; Ralasic, Ivan; Tafro, Azra; Sersic, Damir] Univ Zagreb, Fac Elect Engn & Comp, Dept Elect Syst & Informat Proc, Unska 3, Zagreb 10000, Croatia.
   [Tafro, Azra] Univ Zagreb, Fac Forestry, Dept Proc Tech, Svetosimunska Cesta 25, Zagreb 10000, Croatia.
C3 University of Zagreb; University of Zagreb
RP Vlasic, T (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Elect Syst & Informat Proc, Unska 3, Zagreb 10000, Croatia.
EM Tin.Vlasic@fer.hr; Ivan.Ralasic@fer.hr; Azra.Tafro@fer.hr;
   Damir.Sersic@fer.hr
RI Sersic, Damir/AAE-1370-2022; Vlašić, Tin/AAE-1346-2022; Tafro,
   Azra/AAD-1656-2021; Tafro, Azra/AAP-2257-2021
OI Vlašić, Tin/0000-0002-4672-5272; Tafro, Azra/0000-0002-1083-7934
FU European Regional Development Fund [KK.01.1.1.01.0009]; Croatian Science
   Foundation [IP-2014-09-2625]
FX This work was supported by the European Regional Development Fund
   [KK.01.1.1.01.0009] (DATACROSS); and the Croatian Science Foundation
   [IP-2014-09-2625].
CR Abdulhussan SH, 2017, IEEE ACCESS, V5, P2470, DOI 10.1109/ACCESS.2017.2669218
   Adcock B, 2017, APPL NUMER HARMON AN, P93, DOI 10.1007/978-3-319-69802-1_3
   Adcock B, 2018, FOUND COMPUT MATH, V18, P661, DOI 10.1007/s10208-017-9350-3
   Adcock B, 2017, FORUM MATH SIGMA, V5, P1, DOI 10.1017/fms.2016.32
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Boyd JP, 2007, APPL MATH LETT, V20, P971, DOI 10.1016/j.aml.2006.10.001
   Boyd JP, 2010, COMPUT MATH APPL, V60, P3108, DOI 10.1016/j.camwa.2010.10.015
   Brugiapaglia S, 2018, IEEE T INFORM THEORY, V64, P6638, DOI 10.1109/TIT.2017.2788445
   Caliari M, 2005, APPL MATH COMPUT, V165, P261, DOI 10.1016/j.amc.2004.07.001
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen CS, 2012, IEEE T SIGNAL PROCES, V60, P2851, DOI 10.1109/TSP.2012.2189391
   Chen DC, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ENGINEERING (CSE), P1226, DOI 10.1109/CSE.2014.237
   Chkifa A, 2018, MATH COMPUT, V87, P1415, DOI 10.1090/mcom/3272
   Dabov K., 2008, P SIGN PROC AD SPARS, P1
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dragotti PL, 2007, IEEE T SIGNAL PROCES, V55, P1741, DOI 10.1109/TSP.2006.890907
   Driscoll T. A., 2014, Chebfun guide
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   EDEN M, 1986, SIGNAL PROCESS, V10, P385, DOI 10.1016/0165-1684(86)90046-0
   HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475
   Krahmer F, 2014, IEEE T IMAGE PROCESS, V23, P612, DOI 10.1109/TIP.2013.2288004
   Kumar A, 2019, IEEE T IMAGE PROCESS, V28, P2921, DOI 10.1109/TIP.2019.2892663
   Li LD, 2014, IEEE SIGNAL PROC LET, V21, P122, DOI 10.1109/LSP.2013.2294333
   Maravic I, 2004, IEEE T SIGNAL PROCES, V52, P175, DOI 10.1109/TSP.2003.819984
   Mason J. C., 2003, CHEBYSHEV POLYNOMIAL
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Mukundan R, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II, P23
   NEAGOE VE, 1990, IEEE T ACOUST SPEECH, V38, P1812, DOI 10.1109/29.60116
   Oliveira PAM, 2015, IEEE SIGNAL PROC LET, V22, P1137, DOI 10.1109/LSP.2015.2389899
   Paim G, 2018, ANALOG INTEGR CIRC S, V97, P503, DOI 10.1007/s10470-018-1343-x
   Potts D, 2014, LINEAR ALGEBRA APPL, V441, P61, DOI 10.1016/j.laa.2013.02.006
   Potts D, 2013, LINEAR ALGEBRA APPL, V439, P1024, DOI 10.1016/j.laa.2012.10.036
   Ralasic I, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2018), P44, DOI 10.1109/ICFSP.2018.8552059
   Ralasic I, 2019, IEEE T INSTRUM MEAS, V68, P502, DOI 10.1109/TIM.2018.2847018
   Rauhut H, 2016, APPL COMPUT HARMON A, V40, P321, DOI 10.1016/j.acha.2015.02.003
   Sankaranarayanan AC, 2016, IEEE SIGNAL PROC MAG, V33, P81, DOI 10.1109/MSP.2016.2581846
   Senapati RK, 2014, IET IMAGE PROCESS, V8, P213, DOI 10.1049/iet-ipr.2012.0295
   Shu HZ, 2010, IEEE T IMAGE PROCESS, V19, P3171, DOI 10.1109/TIP.2010.2052276
   Trefethen LN, 2015, COMMUN ACM, V58, P91, DOI 10.1145/2814847
   TREFETHEN LN, 1991, J APPROX THEORY, V65, P247, DOI 10.1016/0021-9045(91)90090-W
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Unser M, 2000, P IEEE, V88, P569, DOI 10.1109/5.843002
   Vetterli M, 2002, IEEE T SIGNAL PROCES, V50, P1417, DOI 10.1109/TSP.2002.1003065
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wojtaszczyk P, 2010, FOUND COMPUT MATH, V10, P1, DOI 10.1007/s10208-009-9046-4
   Xu K, 2016, APPL NUMER MATH, V102, P17, DOI 10.1016/j.apnum.2015.12.002
   Yang D, 2018, IEEE SIGNAL PROC LET, V25, P55, DOI 10.1109/LSP.2017.2768660
   Yao HT, 2019, NEUROCOMPUTING, V359, P483, DOI 10.1016/j.neucom.2019.05.006
NR 55
TC 6
Z9 6
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102731
DI 10.1016/j.jvcir.2019.102731
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200010
DA 2024-07-18
ER

PT J
AU Liu, SG
   Song, ZC
   Zhang, XL
   Zhu, T
AF Liu, Shiguang
   Song, Zhichao
   Zhang, Xiaoli
   Zhu, Ting
TI Progressive complex illumination image appearance transfer based on CNN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Appearance transfer; Complex illumination; Histogram reshaping; Color
   transfer
ID COLOR TRANSFER
AB Image appearance transfer is the process of transferring the appearance features from the user-supplied reference image to the target image. Since traditional appearance transfer methods are based on low-level feature, it is difficult to obtain natural effect in the case of complex illumination between the target image and the reference image. This is mainly because that the appearance mapping relation with complex illumination is a highly nonlinear problem. Although traditional methods are good at dealing with linear transformations, they are less suitable for solving the highly nonlinear problems caused by such complex illumination. Moreover, convolutional neural network (CNN) can extract the hierarchical abstraction features at different levels of the network layer, so it can be conveniently used to realize progressive transfer. In this paper, we propose a novel method for progressive appearance transfer for images with complex illumination. Firstly, we convert the input images from the RGB color space to the HSV color space. The illumination transfer is carried out only in the illumination channel of the image, and for the other two channels, the color distribution of the reference image is transferred to the target image. Secondly, CNN is specially designed to extract the hierarchical feature maps. To achieve progressive transfer, the histogram reshaping method is carried out by using the hierarchical feature maps extracted from the CNN. The appearance transfer results are obtained after the illumination transfer and color transfer. To optimize the transfer results, we adopt the joint bilateral filter to smooth the noises. The experimental results show that our method can effectively solve the problem of progressive appearance transfer for images with complex illumination. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Shiguang; Song, Zhichao; Zhang, Xiaoli; Zhu, Ting] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
C3 Tianjin University
RP Liu, SG (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM lsg@tju.edu.cn
FU Natural Science Foundation of China [61672375, 61170118]
FX This work was partly supported by the Natural Science Foundation of
   China under grant nos. 61672375 and 61170118.
CR [Anonymous], P SIGGRAPH AS 2016 T
   Celikcan U., 2016, SIGNAL IMAGE VIDEO P, V11, P1
   Chang Y, 2007, IEEE T IMAGE PROCESS, V16, P329, DOI 10.1109/TIP.2006.888347
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Faridul H.S., 2014, State of the Art Reports, V3, P1
   Feng B., 2016, WIREL COMMUN SIGNAL, P1
   Han Y, 2017, IEEE T MULTIMEDIA, V19, P80, DOI 10.1109/TMM.2016.2608000
   He MJ, 2017, PROCEEDINGS OF 2017 VI INTERNATIONAL CONFERENCE ON NETWORK, COMMUNICATION AND COMPUTING (ICNCC 2017), P1, DOI 10.1145/3171592.3171610
   Hwang Y, 2014, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2014.427
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Ironi R., 2005, RENDERING TECHNIQUES, P201
   Lee J., 2016, SIGGRAPH ASIA 2016 P, DOI [10.1145/3005274.3005320, DOI 10.1145/3005274.3005320]
   Li Q, 2018, INT C ELECTR MACH SY, P468, DOI 10.23919/ICEMS.2018.8549353
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Limmer M., 2016, IEEE C COMP VIS PATT, P282
   Liu SG, 2012, J VIS COMMUN IMAGE R, V23, P173, DOI 10.1016/j.jvcir.2011.09.006
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Nguyen RMH, 2014, COMPUT GRAPH FORUM, V33, P319, DOI 10.1111/cgf.12500
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Pitie F., 2007, COMPUT VIS IMAGE UND, P123
   Pitie F., 2018, METHODS APPL DIGITAL, P231
   Pitié F, 2007, COMPUT VIS IMAGE UND, V107, P123, DOI 10.1016/j.cviu.2006.11.011
   Pouli T., 2010, Proceedings ofNPAR, P81
   Ran LH, 2015, LECT NOTES COMPUT SC, V9179, P67, DOI 10.1007/978-3-319-21067-4_8
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saha S, 2018, J VIS COMMUN IMAGE R, V51, P95, DOI 10.1016/j.jvcir.2018.01.005
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shih YC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508419
   Son CH, 2017, IEEE T IMAGE PROCESS, V26, P5381, DOI 10.1109/TIP.2017.2724241
   Song ZC, 2017, IEEE T MULTIMEDIA, V19, P702, DOI 10.1109/TMM.2016.2631123
   Starck JL, 2003, IEEE T IMAGE PROCESS, V12, P706, DOI 10.1109/TIP.2003.813140
   Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168
   Venkata US, 2018, J VIS COMMUN IMAGE R, V52, P24, DOI 10.1016/j.jvcir.2018.01.015
   Wang C., 2015, IEEE INT C IM PROC, P1972
   Wang J.Z., 2000, ADV VISUAL INFORM SY, P947
   Wang L., 2018, Proceedings of Computer Graphics International, P67
   Wen CL, 2008, COMPUT GRAPH FORUM, V27, P1765, DOI 10.1111/j.1467-8659.2008.01321.x
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
   Yu Y, 2016, ACM T GRAPHIC, DOI DOI 10.1145/2790296
   Zachary J.M., 2001, INFORM THEORETIC APP
NR 41
TC 7
Z9 9
U1 2
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102636
DI 10.1016/j.jvcir.2019.102636
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600021
DA 2024-07-18
ER

PT J
AU Chen, X
   Zhang, LY
   Liu, T
   Kamruzzaman, MM
AF Chen, Xue
   Zhang, Lanyong
   Liu, Tong
   Kamruzzaman, M. M.
TI Research on deep learning in the field of mechanical equipment fault
   diagnosis image quality
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Mechanical equipment; Equipment maintenance; Image
   quality
AB Image quality assessment (IQA) is an indispensable technique in computer vision, which is widely applied in image classification, image clustering. With the development of deep learning, deep neural network (DNN)-based methods have shown impressive performance. Thus, in this paper, we propose a novel method for mechanical equipment fault diagnosis based on IQA. More specifically, we first conduct data acquisition base on our practice. Afterwards, we leverage image processing method for removing noise. Subsequently, we leverage CNN-based method for image classification. Finally, different mechanical equipment images will be grouped into different categories and fault detection can be achieved. Extensive experiments demonstrate the effectiveness and robustness of our method. (C) 2019 Published by Elsevier Inc.
C1 [Chen, Xue; Liu, Tong] Beihua Univ, Coll Mech Engn, Jilin 132021, Jilin, Peoples R China.
   [Zhang, Lanyong] Harbin Engn Univ, Coll Automat, Harbin, Heilongjiang, Peoples R China.
   [Kamruzzaman, M. M.] Jouf Univ, Dept Comp & Informat Sci, Sakaka, Al Jouf, Saudi Arabia.
C3 Beihua University; Harbin Engineering University; Al Jouf University
RP Zhang, LY (corresponding author), Harbin Engn Univ, Coll Automat, Harbin, Heilongjiang, Peoples R China.
EM chenxue@beihua.edu.cn; zhanglanyong@hrbeu.edu.cn; liutong@beihua.edu.cn;
   mmkamruzzaman@ju.edu.sa
RI Kamruzzaman, M.M./F-6702-2011; Kamruzzaman, M.M./F-6702-2011
OI Kamruzzaman, M.M./0000-0001-8464-1523; Kamruzzaman,
   M.M./0000-0001-7471-694X
FU Science and Technology Project of the 13th Five-Year Plan of Jilin
   Provincial Department of Education [JJKH20170027KJ]; China Scholarship
   Council Project; Program for Promotion of Young Teachers in Beihua
   University; Fundamental Research Funds for the Central Universities
   [3072019CF0407]; Jouf university, Sakaka, Aljouf, KSA
FX This work was supported by Science and Technology Project of the 13th
   Five-Year Plan of Jilin Provincial Department of Education (No.
   JJKH20170027KJ), China Scholarship Council Project and the Program for
   Promotion of Young Teachers in Beihua University."and Jouf university,
   Sakaka, Aljouf, KSA. Fundamental Research Funds for the Central
   Universities (3072019CF0407).
CR Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   [Anonymous], 2015, PROC CVPR IEEE
   Bridges A. L., 2015, TEL C
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Chilimbi T., 2016, US C OP SYST DES IMP
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deborah T., 2016, BEHAV BRAIN SCI, V39
   EGUCHI T, 1985, SMPTE J, V94, P1002, DOI 10.5594/J07889
   Gal Y., 2016, INT C MACH LEARN, P1056
   Garrison K. E., 2017, PSYCHOPHYSIOLOGY, V31, P912
   Gomez P, 2016, BIOL PSYCHOL, V119, P101, DOI 10.1016/j.biopsycho.2016.07.011
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Keskar N. S., 2016, MINIMA, V51, P76
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JY, 2017, FRONT HUM NEUROSCI, V11, P1, DOI 10.3389/fnhum.2017.00133
   Liu Z., 2016, IEEE INT C COMP VIS, P3
   Lv YS, 2015, IEEE T INTELL TRANSP, V16, P865, DOI 10.1109/TITS.2014.2345663
   Mädebach A, 2018, PSYCHON B REV, V25, P2301, DOI 10.3758/s13423-018-1468-z
   Manry M., 2016, IEEE T ACOUST SPEECH, V22, P164
   Mason L., 2017, J COMPUT ASSISTED LE, V33
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Steppacher I, 2016, CEPHALALGIA, V36, P249, DOI 10.1177/0333102415587705
   Wang H., 2015, ACM SIGKDD INT C KNO
   Zhang C., 2016, UNDERSTANDING DEEP L
   Zhu CL, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00954
NR 26
TC 12
Z9 12
U1 5
U2 50
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 402
EP 409
DI 10.1016/j.jvcir.2019.06.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA IL0CB
UT WOS:000476962600037
DA 2024-07-18
ER

PT J
AU Liang, HH
   Zhang, XP
   Cheng, H
AF Liang, H. H.
   Zhang, Xinpeng
   Cheng, Hang
TI Huffman-code based retrieval for encrypted JPEG images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Encrypted JPEG image; Quantization table; Huffman code;
   Confidentiality; Integrity; Format compatibility
AB This paper proposes a retrieval scheme for encrypted JPEG images, based on Huffman code in the JPEG bitstream. Three parties are involved: content owner, cloud server, and authorized user. First, the content owner produces encrypted images by jointly using a stream cipher, permutation cipher, then uploads them to a cloud server. Especially, the conversion between encrypted quantization tables is still valid. With the same secret key, the authorized user submits the encrypted query image to the server. Second, the server extracts Huffman-code histogram from the encrypted image as a feature. Although the Huffman-code histogram is changed during encryption, encrypted images with similar content to the query image are returned to the user after feature comparison. Finally, through decryption and hash verification, the user can obtain authenticated plaintext images. Experimental results show that the proposed scheme ensures confidentiality, integrity and format compatibility, while image retrieval of different quality factors is still effective. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liang, H. H.; Zhang, Xinpeng] Shanghai Univ, Key Lab Specialty Fiber Opt & Opt Access Networks, Joint Int Res Lab Specialty Fiber Opt & Adv Commu, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
   [Liang, H. H.] Changshu Inst Technol, Dept Comp Sci & Engn, Suzhou, Peoples R China.
   [Cheng, Hang] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
C3 Shanghai University; Changshu Institute of Technology; Fuzhou University
RP Liang, HH (corresponding author), Shanghai Univ, Key Lab Specialty Fiber Opt & Opt Access Networks, Joint Int Res Lab Specialty Fiber Opt & Adv Commu, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.; Liang, HH (corresponding author), Changshu Inst Technol, Dept Comp Sci & Engn, Suzhou, Peoples R China.
EM lhh@cslg.edu.cn
FU National Natural Science Foundation of China [U1636206, 61602295,
   61525203, 61472235]; Shanghai Excellent Academic Leader Plan
   [16XD1401200]; Natural Science Foundation of Fujian Province
   [2017J01502]; Scientific Research Foundation of Fuzhou University
   [510483]
FX This work was supported by National Natural Science Foundation of China
   (U1636206, 61602295, 61525203 and 61472235), the Shanghai Excellent
   Academic Leader Plan (16XD1401200), Natural Science Foundation of Fujian
   Province (2017J01502), and Scientific Research Foundation of Fuzhou
   University (510483).
CR CCITT Recommendation T.81 Int. Tele. Union, 1992, INF TECHN DIG COMPR
   Cheng H, 2016, MULTIMED TOOLS APPL, V75, P13791, DOI 10.1007/s11042-015-2741-z
   Cheng H, 2016, J VIS COMMUN IMAGE R, V40, P111, DOI 10.1016/j.jvcir.2016.06.016
   Li K, 2015, IEEE T INF FOREN SEC, V10, P1918, DOI 10.1109/TIFS.2015.2435697
   Lu WJ, 2014, IEEE ACCESS, V2, P125, DOI 10.1109/ACCESS.2014.2307057
   Lu W, 2010, PROC SPIE, V7541, DOI 10.1117/12.838745
   Lu WJ, 2009, INT CONF ACOUST SPEE, P1533, DOI 10.1109/ICASSP.2009.4959888
   Ren K, 2012, IEEE INTERNET COMPUT, V16, P69, DOI 10.1109/MIC.2012.14
   Schaefer G, 2017, 2017 INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP), P22, DOI 10.1109/ICVISP.2017.29
   Sun W., 2016, P 24 ACM INT C MULT, P581
   Weng L, 2016, IEEE T KNOWL DATA EN, V28, P2738, DOI 10.1109/TKDE.2016.2587258
   Weng L, 2015, IEEE T INF FOREN SEC, V10, P152, DOI 10.1109/TIFS.2014.2365998
   Wong WK, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P139
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xu YY, 2017, J VIS COMMUN IMAGE R, V43, P164, DOI 10.1016/j.jvcir.2017.01.006
   Yuan JW, 2015, IEEE INFOCOM SER, DOI 10.1109/INFOCOM.2015.7218593
   Zhang XP, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P446, DOI 10.1109/ChinaSIP.2014.6889282
   Zhang Y, 2014, INT CONF DIGIT SIG, P269, DOI 10.1109/ICDSP.2014.6900669
   Zhenxing Qian, 2018, IEEE Transactions on Dependable and Secure Computing, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   2012, IEEE T IMAGE PROCESS, V21, P4593, DOI DOI 10.1109/TIP.2012.2204272
NR 20
TC 21
Z9 21
U1 2
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 149
EP 156
DI 10.1016/j.jvcir.2019.03.021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100016
DA 2024-07-18
ER

PT J
AU Liu, TJ
   Liu, KH
   Shen, KH
AF Liu, Tsung-Jung
   Liu, Kuan-Hsien
   Shen, Kuan-Hung
TI Learning based no-reference metric for assessing quality of experience
   of stereoscopic images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Disparity-depth map; No reference; Quality of experience; Stereoscopic
   image; Visual discomfort
ID DISPARITY
AB Human's perception plays a very important role on image assessment, especially for stereoscopic images. In general, viewing stereoscopic 3D images will cause visual fatigue, eyestrain, dizziness or headache. Therefore, how to evaluate human's perception of visual quality on 3D images becomes an emerging topic. In this paper, we propose a no-reference assessment metric for stereoscopic image quality of experience (QoE). First, the stereoscopic image pairs are used to calculate the disparity maps by optical flow estimation. Then the depth information are extracted from the disparity map, called as disparity-depth map. Next, we extract four types of features based on pixel value and distribution of disparity-depth map. Two regression models are used to predict visual discomfort scores. Also, we test the proposed method on EPFL 3D image database and IEEE-SA stereoscopic image database, respectively. The experiment results show that our proposed QoE assessment metric achieves excellent performance compared with state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Tsung-Jung; Shen, Kuan-Hung] Natl Chung Hsing Univ, Dept Elect Engn, Taichung 40227, Taiwan.
   [Liu, Tsung-Jung; Shen, Kuan-Hung] Natl Chung Hsing Univ, Grad Inst Commun Engn, Taichung 40227, Taiwan.
   [Liu, Kuan-Hsien] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 40401, Taiwan.
C3 National Chung Hsing University; National Chung Hsing University;
   National Taichung University of Science & Technology
RP Liu, KH (corresponding author), Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung 40401, Taiwan.
EM tjliu@dragon.nchu.edu.tw; khliu@nutc.edu.tw
RI Liu, Tsung-Jung/AAH-5125-2021
OI Liu, Tsung-Jung/0000-0003-4296-0942; Liu, Kuan-Hsien/0000-0002-1411-2113
FU Ministry of Science and Technology, Taiwan [MOST 104-2218-E-005-005,
   MOST 106-2218-E-025-001-MY2]
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under Grant No. MOST 104-2218-E-005-005 and MOST
   106-2218-E-025-001-MY2.
CR [Anonymous], 2011, 2011 17 INT C DIG SI, DOI DOI 10.1109/ICDSP.2011.6004985
   [Anonymous], 2010, P ANN REL MAINT S JA
   [Anonymous], 2010, P INT WORKSH VID PRO
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen JY, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0127-4
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Glantz SA., 2002, Primer of Biostatistics, V5th ed
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Huang R., 2016, P IEEE INT S BROADB, P1
   Jia S., 2017, MULTIMED TOOLS APPL, P1
   Jin L., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2521, DOI 10.1109/ICIP.2011.6116175
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Liu KH, 2015, IEEE IMAGE PROC, P4067, DOI 10.1109/ICIP.2015.7351570
   Liu TJ, 2019, IEEE ACCESS, V7, P8058, DOI 10.1109/ACCESS.2018.2890304
   Liu TJ, 2018, IEEE T IMAGE PROCESS, V27, P1138, DOI 10.1109/TIP.2017.2771422
   Liu TJ, 2017, IEEE T NEUR NET LEAR, V28, P107, DOI 10.1109/TNNLS.2015.2500268
   Liu TJ, 2013, APSIPA TRANS SIGNAL, V2, DOI 10.1017/ATSIP.2013.5
   Liu TJ, 2015, IEEE IMAGE PROC, P3155, DOI 10.1109/ICIP.2015.7351385
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Liu XG, 2017, IEEE SYST J, V11, P2829, DOI 10.1109/JSYST.2015.2478119
   Liyuan Xing, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P373, DOI 10.1109/MMSP.2010.5662049
   Maalouf A, 2011, INT CONF ACOUST SPEE, P1161
   Mittal A, 2011, 2011 IEEE DIGITAL SIGNAL PROCESSING WORKSHOP AND IEEE SIGNAL PROCESSING EDUCATION WORKSHOP (DSP/SPE), P338, DOI 10.1109/DSP-SPE.2011.5739236
   Oh H, 2016, IEEE T IMAGE PROCESS, V25, P615, DOI 10.1109/TIP.2015.2506340
   Olsson R., 1999, P SPIE INT SOC OPTIC, V6803, P6803
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan YX, 2005, IEEE T MULTIMEDIA, V7, P269, DOI 10.1109/TMM.2005.843364
   Park J, 2015, IEEE T IMAGE PROCESS, V24, P1101, DOI 10.1109/TIP.2014.2383327
   Park J, 2014, IEEE J-STSP, V8, P415, DOI 10.1109/JSTSP.2014.2311885
   Qi F, 2012, IEEE INT SYMP CIRC S, P1712
   Roth S., 2010, OPTICAL FLOW SOFTWAR
   Shao F, 2016, IEEE T MULTIMEDIA, V18, P2104, DOI 10.1109/TMM.2016.2594142
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Shunyong Zhou, 2011, 2011 International Conference on Multimedia Technology, P5421
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Tsung-Jung Liu, 2016, 2016 IEEE International Conference on Image Processing (ICIP). Proceedings, P609, DOI 10.1109/ICIP.2016.7532429
   Wu CC, 2013, IEEE T MULTIMEDIA, V15, P1121, DOI 10.1109/TMM.2013.2241043
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   2018, IEEE T IMAGE PROCESS, V27, P1202, DOI DOI 10.1109/TIP.2017.2774045
   2009, QOM 2009 INT WORKSH, P180
NR 41
TC 19
Z9 20
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 272
EP 283
DI 10.1016/j.jvcir.2019.04.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100028
DA 2024-07-18
ER

PT J
AU Xia, ZQ
   Lin, J
   Feng, XY
AF Xia, Zhaoqiang
   Lin, Jie
   Feng, Xiaoyi
TI Trademark image retrieval via transformation-invariant deep hashing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Trademark image retrieval; Deep hashing; Transformation-invariant
   feature; Spatial transformer network; Recurrent convolutional network;
   Sample-weighted loss
ID PARALLEL FRAMEWORK; SHAPE
AB Trademark images are usually used to distinguish goods due to their uniqueness, and the amount becomes too huge to search these images accurately and fast. Most existing methods utilize conventional dense features to search visually-similar images, however, the performance and search time are not satisfactory. In this paper, we propose a unified deep hashing framework to learn the binary codes for trademark images, resulting in good performance with less search time. The unified framework integrates two types of deep convolutional networks (i.e., spatial transformer network and recurrent convolutional network) for obtaining transformation-invariant features. These features are discriminative for describing trademark images and robust to different types of transformations. The two-stream networks are followed by the hashing layer. Network parameters are learned by minimizing a sample-weighted loss, which can leverage the hard-searched images. We conduct experiments on two benchmark image sets, i.e., NPU-TM and METU, and verify the effectiveness and efficiency of our proposed approach over state-of-the-art. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xia, Zhaoqiang; Feng, Xiaoyi] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.
   [Lin, Jie] Inst Infocomm Res, Deep Learning Dept, Singapore 138632, Singapore.
C3 Northwestern Polytechnical University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Xia, ZQ (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710129, Shaanxi, Peoples R China.
EM zxia@nwpu.edu.cn
RI Xia, Zhaoqiang/AAC-4021-2019
OI Xia, Zhaoqiang/0000-0003-0630-3339
FU National Natural Science Foundation of China [61702419]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2018JQ6090]
FX This work is partly supported by the National Natural Science Foundation
   of China (No. 61702419), and the Natural Science Basic Research Plan in
   Shaanxi Province of China (No. 2018JQ6090).
CR [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], ARXIV171106016
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, J COMPUTATIONAL INFO
   [Anonymous], INT J IMAGE GRAPH
   [Anonymous], CVPR
   [Anonymous], P ACM SAC IAR
   [Anonymous], 2015, PROC 28 INT C NEURAL
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Ciocca G, 2001, PATTERN RECOGN, V34, P1639, DOI 10.1016/S0031-3203(00)00055-8
   CORTELAZZO G, 1994, PATTERN RECOGN, V27, P1005, DOI 10.1016/0031-3203(94)90140-6
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eakins JP, 1998, IEEE MULTIMEDIA, V5, P53, DOI 10.1109/93.682526
   Eakins JP, 2001, ADV PTRN RECOGNIT, P319
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Goyal A, 2014, SIGNAL IMAGE VIDEO P, V8, P1273, DOI 10.1007/s11760-012-0353-x
   Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3
   Jiang H, 2006, PATTERN RECOGN, V39, P988, DOI 10.1016/j.patcog.2005.08.012
   Jiang QY, 2017, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2017.348
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lan T, 2017, LECT NOTES COMPUT SC, V10668, P231, DOI 10.1007/978-3-319-71598-8_21
   Li WJ, 2016, IJCAI, P1711
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P6521, DOI 10.1109/TGRS.2018.2839705
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   loffe Sergey, BATCH NORMALIZATION
   Lu XQ, 2018, IEEE T IMAGE PROCESS, V27, P106, DOI 10.1109/TIP.2017.2755766
   Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI [10.1109/TMAG.2017.2763198, 10.1007/s11263-018-1117-z]
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Phan R, 2010, COMPUT VIS IMAGE UND, V114, P66, DOI 10.1016/j.cviu.2009.07.004
   Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712
   Rusiñol M, 2011, LECT NOTES COMPUT SC, V6611, P314, DOI 10.1007/978-3-642-20161-5_32
   Schietse J, 2007, P ACM INT C IM VID R, P518, DOI DOI 10.1145/1282280.1282355
   Shen DF, 2005, IEEE IMAGE PROC, P2977
   Suganthan PN, 2002, IEEE T NEURAL NETWOR, V13, P835, DOI 10.1109/TNN.2002.1021884
   Do TT, 2016, LECT NOTES COMPUT SC, V9909, P219, DOI 10.1007/978-3-319-46454-1_14
   Tursun O, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P514, DOI 10.1109/MVA.2015.7153243
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wei CH, 2009, PATTERN RECOGN, V42, P386, DOI 10.1016/j.patcog.2008.08.019
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Xia Z., 2016, IMAGE PROCESSING THE, P1
   Xia ZQ, 2017, SIGNAL PROCESS-IMAGE, V59, P109, DOI 10.1016/j.image.2017.06.008
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan YJ, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P306, DOI 10.1109/BigMM.2015.43
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
   Zhou K, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1215, DOI 10.1145/2733373.2806320
NR 53
TC 11
Z9 13
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 108
EP 116
DI 10.1016/j.jvcir.2019.01.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600011
DA 2024-07-18
ER

PT J
AU Ding, XB
   Liu, ZG
   Xu, HB
AF Ding, Xiaobing
   Liu, Zhigang
   Xu, Haibo
TI The passenger flow status identification based on image and WiFi
   detection for urban rail transit stations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rail transit; Safety of stations; Passenger flow identification;
   Passengers' limiter of station; Emergency warning
ID SAFETY
AB During the peak hours, the concentration of passenger flow is relatively high for some busy subway lines, if the measures can't be taken in time, more serious accidents may happen, which will influence the social image of the subway. At present, the passenger flow of the key stations is judged mainly by the experience of the staffs, and then the corresponding measures are taken, the errors may be large, and the relevant technical research is urgently needed. First, a data collection device called "the elf of passenger flow-collecting", which integrates high definition camera image acquisition equipment and WIFI probe technology was set up. It can be used to collect the original passenger flow data of congestion points of subway stations. Second, a convolution neural network passenger flow identification algorithm based on deep learning is designed, which is used to estimate the P-0 of stations. Third, because of the error in the video image recognition algorithm, the WIFI probe data acquisition scheme is designed, and the SQL preprocessing assembly for WIFI data processing is established. The noise of WIFI probe is preprocessed, and the flow rate of P-5 based on WIFI probe is obtained. The difference between P-0 and P-5 is defined, and the degree of the difference between P-0 and P-5 is calculated, so the final passenger flow P(6 )can be obtained. Finally, the Songjiang University Hall Station of Shanghai Metro line 9 was taken as an experimental analysis object, the high definition camera and WIFI probe are set up on the spot, the passenger flow video data and the WIFI data are collected synchronously, so the real-time passenger flow in the station's internal position is estimated, and the accuracy is corrected, meanwhile the passenger flow early warning of the station position is obtained. An emergency response plan based on passenger flow early warning level is proposed, and the flow chart of passenger flow density inside Songjiang University hall station is drawn. The construction of the equipment platform and the identification and correction methods of passenger flow are of good practical guiding significance for the Metro to run safely. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Ding, Xiaobing; Liu, Zhigang] Shanghai Univ Engn Sci, Sch Urban Rail Transportat, Shanghai, Peoples R China.
   [Xu, Haibo] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou, Guangdong, Peoples R China.
C3 Shanghai University of Engineering Science; South China University of
   Technology
RP Xu, HB (corresponding author), South China Univ Technol, Sch Automat Sci & Engn, Guangzhou, Guangdong, Peoples R China.
EM 201510101991@mail.scut.edu.cn
OI Xu, Haibo/0000-0002-6632-4644; ding, xiaobing/0000-0003-1739-7684
FU National Key Research and Development Plan of China [2016YFC0802500];
   National Natural Science Foundation of China [71601110, 61672002]
FX The research described in this paper was supported by Project supported
   by the National Key Research and Development Plan of China (Grant No.
   2017YFC0804900); Project supported by the National Key Research and
   Development Plan of China (Grant No. 2016YFC0802500); the National
   Natural Science Foundation of China (Grant No. 71601110 and 61672002).
CR [Anonymous], IEEE INT C IM PROC I
   Collins R., 2000, CMURITR0012, DOI [10.1039/c1pp90001c, DOI 10.1039/C1PP90001C]
   Cootes TF, 2001, PROC SPIE, V4322, P236, DOI 10.1117/12.431093
   Ding XB, 2017, SAFETY SCI, V94, P10, DOI 10.1016/j.ssci.2016.12.015
   Galic S, 2000, IWISPA 2000: PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P63, DOI 10.1109/ISPA.2000.914892
   Gao R, 2015, SAFETY SCI, V80, P94, DOI 10.1016/j.ssci.2015.07.015
   Handte M., 2014, CROWD DENSITY ESTIMA
   Kalal Z, 2010, IEEE IMAGE PROC, P3789, DOI 10.1109/ICIP.2010.5653525
   Lu HH, 2010, IEEE VTS VEH TECHNOL
   Mikkelsen L, 2016, INT WORKSH RES NETW, V302-308, DOI [10.1109/RNDM.2016.7608302, DOI 10.1109/RNDM.2016.7608302]
   Musa ABM., 2012, P 10 ACM C EMBEDDED, P281, DOI [10.1145/2426656.2426685, DOI 10.1145/2426656.2426685]
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Zhang Ze-xu, 2003, Acta Electronica Sinica, V31, P1299
NR 15
TC 17
Z9 18
U1 2
U2 50
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 119
EP 129
DI 10.1016/j.jvcir.2018.11.033
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100013
DA 2024-07-18
ER

PT J
AU Lu, ZY
   Lu, BJ
   Zhang, HD
   Fu, Y
   Qiu, YN
   Zhan, TM
AF Lu Zhenyu
   Lu Bingjian
   Zhang Hengde
   Fu You
   Qiu Yunan
   Zhan Tianming
TI A method of visibility forecast based on hierarchical sparse
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FCM; Sparse representation; Predict; Visibility
ID LOW-RANK
AB This paper proposes a visibility forecast method based on hierarchical sparse representations. Firstly, it selects meteorological factors from the data of 138 ground stations located in Beijing, Tianjin and Hebei during the months (Oct-to-Dec. and January) of years 2002-2016. Then, it uses fuzzy C means algorithm (FCM) to construct historical databases containing 5000 samples. Finally, it takes the meteorological factors corresponding to visibility as the sample of historical databases, and uses a hierarchical sparse representation to predict the visibility of new inputs. Experiment, conducted with the data of European Centre for Medium-Range Weather Forecasts (ECMWF), indicates a better performance of the hierarchical sparse representation in contrast to a sparse representation. And the visibility forecast based on hierarchical sparse representation is better than Beijing Regional Environmental Meteorology Prediction System (BREMPS) and BP neural network. The hierarchical sparse representation is simple and easy to expand, which improves the accuracy and reduce the absolute error, which is convenience for other meteorological analysis. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Lu Zhenyu; Lu Bingjian; Fu You; Qiu Yunan] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210049, Jiangsu, Peoples R China.
   [Lu Zhenyu] Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhang Hengde] Natl Meteorol Ctr, Beijing 100081, Peoples R China.
   [Zhan Tianming] Nanjing Audit Univ, Sch Informat & Engn, Nanjing 211815, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing Audit
   University
RP Zhan, TM (corresponding author), Nanjing Audit Univ, Sch Informat & Engn, Nanjing 211815, Jiangsu, Peoples R China.
EM ztm@nau.edu.cn
RI Lu, Zhenyu/AAA-5077-2019
FU National Natural Science Foundation of China [61773220, 61502206];
   Nature Science Foundation of Jiangsu Province [BK20150523]
FX This work has been supported in part by the National Natural Science
   Foundation of China (Grant No. 61773220, 61502206), the Nature Science
   Foundation of Jiangsu Province under Grant (No. BK20150523).
CR Abdessamad J, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268766
   Abrol V, 2016, SPEECH COMMUN, V85, P71, DOI 10.1016/j.specom.2016.09.004
   Akhtar N, 2017, PATTERN RECOGN, V65, P136, DOI 10.1016/j.patcog.2016.12.017
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], ENV ENG
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], METEOROL TECHNOL PRO
   [Anonymous], METEOROL RES APPL
   [Anonymous], DROUGHT METEOROL
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   [马学款 MA XueKuan], 2007, [气候与环境研究, Climatic and Environmental Research], V12, P795
   Mishra D, 2015, ATMOS ENVIRON, V102, P239, DOI 10.1016/j.atmosenv.2014.11.050
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   PASINI A, 1995, NUOVO CIMENTO C, V18, P505, DOI 10.1007/BF02506781
   Wang DS, 2017, DATA, V2, DOI 10.3390/data2030029
   [吴波 Wu Bo], 2017, [热带气象学报, Journal of Tropical Meteorology], V33, P104
   [赵秀娟 Zhao Xiujuan], 2016, [应用气象学报, Journal of Applied Meteorolgical Science], V27, P160
NR 18
TC 4
Z9 5
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 160
EP 165
DI 10.1016/j.jvcir.2018.11.029
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100017
DA 2024-07-18
ER

PT J
AU Zhao, JW
   Chen, C
   Zhou, ZH
   Cao, FL
AF Zhao, Jianwei
   Chen, Chen
   Zhou, Zhenghua
   Cao, Feilong
TI Single image super-resolution based on adaptive convolutional sparse
   coding and convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Convolutional sparse coding; Convolutional neural
   network; Adaptive
AB The convolutional sparse coding-based super-resolution (CSC-SR) method has shown its good performance in single image super-resolution. It divides the low-resolution (LR) image into low-frequency part and the high-frequency part, and reconstructs their corresponding high-resolution (HR) image with bicubic interpolation and convolutional sparse coding (CSC) method, respectively. This paper is devoted to improve the performance of CSC-SR method. As convolutional neural network (CNN) can reveal the mapping relation between the LR image and the HR image for the low-frequency part better, we replace the bicubic interpolation with CNN to reconstruct the HR image for the low-frequency part. In addition, we propose an adaptive CSC method to reconstruct the HR image for the high-frequency part. We name our proposed super-resolution method as hybrid adaptive convolutional sparse coding-based super-resolution (HACSC-SR) method. Many comparison experiments illustrate that our proposed HACSC-SR method is superior to CSC-SR, CNN as well as several existing super-resolution methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhao, Jianwei; Chen, Chen; Zhou, Zhenghua; Cao, Feilong] China Jiliang Univ, Dept Informat Sci & Math, Hangzhou 310018, Zhejiang, Peoples R China.
C3 China Jiliang University
RP Cao, FL (corresponding author), China Jiliang Univ, Dept Informat Sci & Math, Hangzhou 310018, Zhejiang, Peoples R China.
EM feilongcao@gmail.com
FU National Nature Science Foundation of China [61571410, 61672477];
   Zhejiang Provincial Nature Science Foundation of China [LY18F020018]
FX The research was supported by National Nature Science Foundation of
   China (Nos. 61571410, 61672477) and Zhejiang Provincial Nature Science
   Foundation of China (LY18F020018).
CR [Anonymous], MARTA SANZ SOLE
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], DEEP LEARNING FACE R
   [Anonymous], 2008, NIPS
   [Anonymous], DEEP NETWORK CASCADE
   [Anonymous], LEARNING DEEP CONVOL
   [Anonymous], INT C CURV SURF
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao Feilong, 2016, IEEE Trans Neural Netw Learn Syst, V27, P1550, DOI 10.1109/TNNLS.2015.2512563
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Dai D, 2015, COMPUT GRAPH FORUM, V34, P95, DOI 10.1111/cgf.12544
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   FUNAHASHI K, 1989, NEURAL NETWORKS, V2, P183, DOI 10.1016/0893-6080(89)90003-8
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   HORNIK K, 1990, NEURAL NETWORKS, V3, P551, DOI 10.1016/0893-6080(90)90005-6
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95
   KANG MG, 1995, IEEE T IMAGE PROCESS, V4, P594, DOI 10.1109/83.382494
   Kato Y., 2016, 2016 14 IEEE INT NEW, P1, DOI DOI 10.1109/MHS.2016.7824232
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Schulter S, 2015, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2015.7299003
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wohlberg B, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6854992
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhong LW, 2014, PR MACH LEARN RES, V32
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
NR 50
TC 9
Z9 10
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 651
EP 661
DI 10.1016/j.jvcir.2018.12.036
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100062
DA 2024-07-18
ER

PT J
AU Li, JG
   Chen, X
AF Li JiGuang
   Chen Xin
TI A robust enhancement system based on observer-backstepping controller
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robustness; Adaptive function; Observer
AB A large mount of data is indispensable in deep learning. The learning results can be different because of the noise or contaminate tags. So in this paper, a controller design method is proposed to reduce the influence due to noise or damaged label. Our method is based on backstepping control method and observer. In our work, an adaptive function is designed to eliminate the influence of the unmodelable part of the system because of the contaminated tags. For the noise, the observer is used to accurately estimated and effectively compensated. Experimental results show the effectiveness of our method. Our modified system has good performance and can accurately response the input training data in the case of the unmodelable part of the system and the external noise. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Li JiGuang; Chen Xin] Nanjing Univ Aeronaut & Astronaut, Sch Automat, Nanjing 210016, Jiangsu, Peoples R China.
   [Li JiGuang] Xian Aeronaut Univ, Sch Aerocraft, Xian 710077, Shanxi, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Xi'an Aeronautical
   Institute
RP Li, JG (corresponding author), Nanjing Univ Aeronaut & Astronaut, Sch Automat, Nanjing 210016, Jiangsu, Peoples R China.; Li, JG (corresponding author), Xian Aeronaut Univ, Sch Aerocraft, Xian 710077, Shanxi, Peoples R China.
EM jiguangli_nua@126.com
CR Chen Fuyang, 2016, IEEE T IND ELECTRON, V25, P37
   Chen H., 2018, IEEE Photonics J, V10, P1
   Chen HT, 2018, IEEE T VEH TECHNOL, V67, P4819, DOI 10.1109/TVT.2018.2818538
   Chen L., 2018, MATH PROBL ENG, V9, P1
   Chen Ming, 2015, Control and Decision, V30, P877, DOI 10.13195/j.kzyjc.2014.0300
   Chiang HK, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016651373
   Guo F, 2018, MECH SYST SIGNAL PR, V111, P314, DOI 10.1016/j.ymssp.2018.03.058
   Liu SY, 2017, NONLINEAR DYNAM, V88, P465, DOI 10.1007/s11071-016-3253-8
   Liu ZQ, 2017, IEEE ACCESS, V5, P17567, DOI 10.1109/ACCESS.2017.2742001
   Ma G., 2017, IEEE ACCESS, P1954
   Rosaldo-Serrano M.A., 2018, J INTELL ROB SYST, V6, P1
   Shi D, 2018, IEEE ACCESS, V6, P32349, DOI 10.1109/ACCESS.2018.2842198
   Shi Z., 2017, ADV MECH ENG, V9, P168
   Song SN, 2018, IEEE ACCESS, V6, P7728, DOI 10.1109/ACCESS.2018.2802906
   Wang G., 2018, MATH PROBL ENG, V9, P1
   Wang WP, 2017, ADV MECH ENG, V9, DOI 10.1177/1687814017705842
   Wu C.-Z., 2017, SCI REP, V7, P1
   Xia J., 2015, MATH PROBL ENG, P1
   Yang Y, 2015, J FRANKLIN I, V352, P16, DOI 10.1016/j.jfranklin.2014.09.014
   Zhao DD, 2017, IEEE ACCESS, V5, P1263, DOI 10.1109/ACCESS.2017.2656881
   Zhou H., 2015, MATH PROBL ENG, V6, P1
NR 21
TC 1
Z9 1
U1 4
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 34
EP 38
DI 10.1016/j.jvcir.2018.10.010
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400005
DA 2024-07-18
ER

PT J
AU Tian, Y
   Zeng, HQ
   Xing, L
   Chen, J
   Zhu, JQ
   Ma, KK
AF Tian, Yu
   Zeng, Huanqiang
   Xing, Lu
   Chen, Jing
   Zhu, Jianqing
   Ma, Kai-Kuang
TI A multi-order derivative feature-based quality assessment model for
   light field image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light field image; Image quality assessment; Multi-order derivative
   feature
ID DEPTH ESTIMATION; SIMILARITY
AB This paper presents an image quality assessment (IQA) model exploring the multi-order derivative feature, called Multi-order Derivative Feature-based Model (MDFM), for evaluating the perceptual quality of light field image (LFI). In our approach, for the input reference and distorted LFIs, the multi-order derivative features are extracted by using the discrete derivative filter to represent the image details in different degrees. Then, the similarities of the extracted derivative features are measured independently. Finally, the weight map is established through the maximum value of the second-order derivative feature of reference and distorted LFIs, which is further utilized to pool the similarity map for generating the final score. Extensive simulation results have demonstrated that the proposed MDFM is more consistent with the perception of the HVS on the evaluation of LFI than the classical and state-of-the-art IQA methods. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Tian, Yu; Zeng, Huanqiang; Xing, Lu; Chen, Jing] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
   [Zhu, Jianqing] Huaqiao Univ, Sch Engn, Quanzhou, Peoples R China.
   [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
C3 Huaqiao University; Huaqiao University; Nanyang Technological University
RP Zeng, HQ (corresponding author), Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
EM zeng0043@hqu.edu.cn; jingzi@hqu.edu.cn; jqzhu@hqu.edu.cn;
   ekkma@ntu.edu.sg
RI Ma, Kai-Kuang/KBA-9411-2024; Zeng, Huanqiang/U-2017-2018; Zhu,
   Jianqing/AHA-0351-2022
OI Zhu, Jianqing/0000-0001-8840-3629
FU National Natural Science Foundation of China [61871434, 61602191,
   61802136]; Natural Science Foundation of Fujian Province [2016J01308,
   2017J05103]; Fujian-100 Talented People Program; High-level Talent
   Innovation Program of Quanzhou City [2017G027]; Promotion Program for
   Young and Middle-aged Teacher in Science and Technology Research of
   Huaqiao University [ZQN-YX403, ZQN-PY418]; High-Level Talent Project
   Foundation of Huaqiao University [1485201, 14BS204, 16BS108]; Graduate
   Student Scientific Research Innovation Project Foundation of Huaqiao
   University
FX This work was supported in part by the National Natural Science
   Foundation of China under the grants 61871434, 61602191, and 61802136,
   in part by the Natural Science Foundation of Fujian Province under the
   grants 2016J01308 and 2017J05103, in part by the Fujian-100 Talented
   People Program, in part by High-level Talent Innovation Program of
   Quanzhou City under the grant 2017G027, in part by the Promotion Program
   for Young and Middle-aged Teacher in Science and Technology Research of
   Huaqiao University under the grants ZQN-YX403 and ZQN-PY418, and in part
   by the High-Level Talent Project Foundation of Huaqiao University under
   the grants 1485201, 14BS204 and 16BS108, and in part by the Graduate
   Student Scientific Research Innovation Project Foundation of Huaqiao
   University.
CR Adhikarla VK, 2017, PROC CVPR IEEE, P3720, DOI 10.1109/CVPR.2017.396
   [Anonymous], FIN REP VID QUAL EXP
   Bae SH, 2016, IEEE T IMAGE PROCESS, V25, P2392, DOI 10.1109/TIP.2016.2545863
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen J, 2018, IEEE SIGNAL PROC LET, V25, P1403, DOI 10.1109/LSP.2018.2861212
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P4889, DOI 10.1109/TIP.2018.2839524
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Farid H, 2004, IEEE T IMAGE PROCESS, V13, P496, DOI 10.1109/TIP.2004.823819
   Feng MT, 2018, IEEE T IMAGE PROCESS, V27, P3586, DOI 10.1109/TIP.2018.2814217
   Fu Y, 2018, IEEE T CIRC SYST VID, V28, P2428, DOI 10.1109/TCSVT.2018.2854176
   Gul MSK, 2018, IEEE T IMAGE PROCESS, V27, P2146, DOI 10.1109/TIP.2018.2794181
   Hou J., 2018, IEEE T CIRC SYST VID
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Ni ZK, 2016, IEEE SIGNAL PROC LET, V23, P1394, DOI 10.1109/LSP.2016.2599294
   Paudyal P, 2017, IEEE T BROADCAST, V63, P507, DOI 10.1109/TBC.2017.2704430
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Wang YL, 2018, IEEE T IMAGE PROCESS, V27, P4274, DOI 10.1109/TIP.2018.2834819
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Xing L, 2018, SIGNAL PROCESS, V145, P233, DOI 10.1016/j.sigpro.2017.12.013
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yeung HWF, 2018, LECT NOTES COMPUT SC, V11210, P138, DOI 10.1007/978-3-030-01231-1_9
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 28
TC 36
Z9 39
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 212
EP 217
DI 10.1016/j.jvcir.2018.11.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400025
DA 2024-07-18
ER

PT J
AU Chen, QQ
   Sang, L
AF Chen, Ququ
   Sang, Lei
TI Face-mask recognition for fraud prevention using Gaussian mixture model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gussian Mixture Model (GMM); Dlib; Deep learning; Fraud prevention
ID ROBUST
AB With the rapid development of biometric identification technology, face recognition has been one of the most widely used as its important component. It facilitates a series of applications such as security, military, transportation, education and other fields. The demand for face feature recognition is increasing. However the current techniques still exist some deficiencies. In this paper, we proposed a face-mask recognition method for fraud prevention based on Gaussian Mixture Model. We address the problem of identifying the face and mask in the area of financial security precaution. And we show how to combine opencv with dlib to recognition face and extract it. We use Gaussian Mixture Model (GMM) to construct the model of human faces. According to this, we calculate the similarity between the face sample and the model. By analyzing and learning the features of faces, we can predict whether the image of which we test is a human face or a mask. Compared with other traditional method of face recognition, our approach has been targeted to strengthen the ability to recognize abnormal faces such as sunglasses, masks and respirator, and reduce the potential danger of these unusual faces in the security field. It is simple to be calculated and has a higher accuracy. In addition, our method have enhanced the robustness of the algorithm about mask recognition. (C) 2018 Published by Elsevier Inc.
C1 [Chen, Ququ] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
   [Sang, Lei] Hefei Univ Technol, Acad Photoelect Technol, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Chen, QQ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM ququchen8@gmail.com
CR Tran AT, 2016, KSII T INTERNET INF, V10, P1824, DOI 10.3837/tiis.2016.04.020
   [Anonymous], P CVPR
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Liu Xiao, 2013, P CVPR
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Rao WW, 2017, IEEE ICC
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang L., 2015, ICMR
   Zhang LM, 2017, IEEE T CYBERNETICS, V47, P3866, DOI 10.1109/TCYB.2016.2585764
   Zhang LM, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886775
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2016, IEEE T IMAGE PROCESS, V25, P553, DOI 10.1109/TIP.2015.2502147
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P258, DOI 10.1109/TCYB.2015.2400821
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2014, INFORM SCIENCES, V254, P141, DOI 10.1016/j.ins.2013.08.020
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, SIGNAL PROCESS, V93, P1597, DOI 10.1016/j.sigpro.2012.05.012
   Zhang Luming, 2014, PERCEPTION GUIDED MU
   Zhang Luming, 2009, FEATURE SELECTION FA
   Zhang Luming, 2015, BIOL INSPIRED MEDIA
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 34
TC 20
Z9 20
U1 3
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 795
EP 801
DI 10.1016/j.jvcir.2018.08.016
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100070
DA 2024-07-18
ER

PT J
AU Kamranian, Z
   Tombari, F
   Nilchi, ARN
   Monadjemi, A
   Navab, N
AF Kamranian, Zahra
   Tombari, Federico
   Nilchi, Ahmad Reza Naghsh
   Monadjemi, Amirhassan
   Navab, Nassir
TI Co-segmentation via visualization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Co-segmentation; Convolutional Neural Network (CNN); Feature
   visualization; Occlusion sensitivity; Adaptive learning
ID OBJECT; COSEGMENTATION; RECOGNITION; APPEARANCE; SHAPE
AB This paper addresses the co-segmentation problem using feature visualization for CNNs. Visualization is exploited as an auxiliary information to discriminate salient image regions (dubbed as "heat-regions") from non-salient ones. Region occlusion sensitivity is proposed for feature visualization. The co-segmentation problem is formulated via a convex quadratic optimization which is initialized by the heat-regions. The information obtained through the visualization is considered as an extra energy term in the cost function. The results of the visualization demonstrate that there exist some heat-regions which are not productive in the co-segmentation. To detect helpful regions among them, an adaptive strategy in the form of an iterative algorithm is proposed according to the consistency among all images. Comparison experiments conducted on two benchmark datasets, iCoseg and MSRC, illustrate the superior performance of the proposed approach over state-of-the-art algorithms.
C1 [Kamranian, Zahra; Nilchi, Ahmad Reza Naghsh; Monadjemi, Amirhassan] Univ Isfahan, Fac Comp Engn, Dept Artificial Intelligence, Esfahan 8174673441, Iran.
   [Kamranian, Zahra; Tombari, Federico; Navab, Nassir] Tech Univ Munich, Comp Aided Med Procedures & Augmented Real, Munich, Germany.
   [Navab, Nassir] Johns Hopkins Univ, Comp Aided Med Procedures, Baltimore, MD USA.
C3 University of Isfahan; Technical University of Munich; Johns Hopkins
   University
RP Nilchi, ARN (corresponding author), Univ Isfahan, Fac Comp Engn, Dept Artificial Intelligence, Esfahan 8174673441, Iran.
EM zahra.kamranian@eng.ui.ac.ir; tombari@in.tum.de; nilchi@eng.ui.ac.ir;
   monadjemi@eng.ui.ac.ir; navab@cs.tum.edu
RI Kamranian, Zahra/AAB-5139-2019
OI Kamranian, Zahra/0000-0002-2932-9091
CR [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XP, 2015, IEEE T IMAGE PROCESS, V24, P3966, DOI 10.1109/TIP.2015.2456636
   Fathi A, 2013, NEURAL COMPUT APPL, V22, pS163, DOI 10.1007/s00521-012-1118-8
   Fu HZ, 2015, PROC CVPR IEEE, P4428, DOI 10.1109/CVPR.2015.7299072
   Fu HZ, 2015, IEEE T IMAGE PROCESS, V24, P3415, DOI 10.1109/TIP.2015.2442915
   Grn F., 2016, Comput Graphics Forum, V48
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Kowdle A, 2010, TRENDS TOPICS COMPUT, P211, DOI DOI 10.1007/978-3-642-35740-4_17
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li BN, 2011, COMPUT BIOL MED, V41, P1, DOI 10.1016/j.compbiomed.2010.10.007
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li KQ, 2016, IEEE T IMAGE PROCESS, V25, P1898, DOI 10.1109/TIP.2016.2526900
   Long J.L., 2014, Advances in neural information processing systems, V27, P1601
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Meng FM, 2016, COMPUT VIS IMAGE UND, V146, P67, DOI 10.1016/j.cviu.2016.02.004
   Meng FM, 2013, IEEE T IMAGE PROCESS, V22, P4809, DOI 10.1109/TIP.2013.2278461
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Meyer, 2000, MATRIX ANAL APPL LIN, DOI 10.1137/1.9780898719512
   Oquab M., 2015, PROC CVPR IEEE, P685
   Pratondo A, 2017, J VIS COMMUN IMAGE R, V43, P1, DOI 10.1016/j.jvcir.2016.11.019
   Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shimoda W, 2016, LECT NOTES COMPUT SC, V9908, P218, DOI 10.1007/978-3-319-46493-0_14
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Simonyan K., 2013, arXiv preprint arXiv:1312.6034
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Tao WB, 2015, IEEE T IMAGE PROCESS, V24, P943, DOI 10.1109/TIP.2014.2387384
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Wang F, 2014, PROC CVPR IEEE, P3142, DOI 10.1109/CVPR.2014.402
   Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang DW, 2015, IEEE I CONF COMP VIS, P594, DOI 10.1109/ICCV.2015.75
   Zhang DW, 2015, PROC CVPR IEEE, P2994, DOI 10.1109/CVPR.2015.7298918
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou B., 2014, CORR, V1412, P6856
   Zhu HY, 2014, IEEE WINT CONF APPL, P485, DOI 10.1109/WACV.2014.6836062
NR 58
TC 3
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 201
EP 214
DI 10.1016/j.jvcir.2018.05.014
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100018
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Li, LD
   Wang, SQ
   Wu, JJ
   Zhang, Y
AF Zhou, Yu
   Li, Leida
   Wang, Shiqi
   Wu, Jinjian
   Zhang, Yun
TI No-reference quality assessment of DIBR-synthesized videos by measuring
   temporal flickering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video quality evaluation; View synthesis; DIBR; Flickering; Singular
   value decomposition
ID COMPRESSION; DISTORTION; VIEWS
AB Depth-image-based-rendering (DIBR) is the most popular view synthesis method. The rendering process in DIBR introduces artifacts to synthesized views. Temporal inconsistency of these artifacts causes flickering, which is one of the dominant distortions in DIBR-synthesized videos. We propose a no-reference quality index for DIBR-synthesized videos. A two-stage flickering region detection method is first proposed by calculating the gradient distance between the matching blocks in adjacent frames followed by a refinement operation. Subsequently, the distortion intensity of flickering regions is measured in singular value decomposition domain. The average flickering intensity is computed as the quality score. Experimental results show that our method outperforms the state-of-the-arts on the IRCCyN/IVC database and ranks the second on the SIAT database, which is only slightly worse than the best-performing one. Furthermore, the presented method is applied to improve the performances of existing metrics and benchmark DIBR algorithms, which achieves very promising results for both tasks.
C1 [Zhou, Yu; Li, Leida] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
   [Wu, Jinjian] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
C3 China University of Mining & Technology; City University of Hong Kong;
   Xidian University; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS
RP Li, LD (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM lileida@cumt.edu.cn
RI Li, Li/AEM-3636-2022; Wu, Jinjian/GQH-0222-2022; Wang,
   Shiqi/AAR-5013-2020; Zhang, Yun/V-7261-2019; li, li/HII-4157-2022
OI Wang, Shiqi/0000-0002-6338-1432; Zhang, Yun/0000-0001-9457-7801; 
FU the National Natural Science Foundation of China [61771473, 61379143];
   Six Talent Peaks Project in Jiangsu Province [XYDXX-063]; Qing Lan
   Project; Key Project for Guangdong Provincial Science and Technology
   Development [2017B010110014]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants 61771473 and 61379143, Six Talent Peaks
   Project in Jiangsu Province under Grant XYDXX-063, the Qing Lan Project
   and the Key Project for Guangdong Provincial Science and Technology
   Development under Grant 2017B010110014.
CR [Anonymous], 1981, P NAT TEL C NEW ORL
   [Anonymous], 2015, P IEEE TRUE VIS CAPT
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Conze P., 2012, ELECT IMAG INT SOC O, V8288, P8256
   Dandawate YH, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P138, DOI 10.1109/ICCIMA.2007.231
   Ding Y, 2014, ELECTRON LETT, V50, P79, DOI 10.1049/el.2013.3365
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P2016, DOI 10.1109/TIP.2017.2669840
   Farid M., 2017, P IEEE INT C MULT EX
   Farid MS, 2015, IEEE IMAGE PROC, P3720, DOI 10.1109/ICIP.2015.7351499
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Jain R., 1995, MACHINE VISION
   Kim HG, 2016, IEEE IMAGE PROC, P1027, DOI 10.1109/ICIP.2016.7532513
   Köppel M, 2010, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP.2010.5652138
   Kumar E. Boopathi, 2017, 2017 2nd International Conference on Communication and Electronics Systems (ICCES). Proceedings, P234, DOI 10.1109/CESYS.2017.8321272
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Lin P. T., 2016, 12 IEEE ASME INT C M, P1
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Ndjiki-Nya P, 2010, IEEE INT CON MULTI, P424, DOI 10.1109/ICME.2010.5583559
   Onat E., 2017, 25 SIGN PROC COMM AP, P1
   Patan RJ, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1551, DOI 10.1109/ICCSP.2016.7754419
   Roberts, 1965, MACHINE PERCEPTION 3
   Saad M., 2014, IEEE T IMAGE PROCESS, V23, P684
   Sandic-Stankovic D., 2015, P IEEE 7 INT WORKSH, P1
   Sandic-Stankovic D, 2016, J ELECTR ENG-SLOVAK, V67, P3, DOI 10.1515/jee-2016-0001
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Shao Hang., 2009, Proc. 3DTV Conf, P1
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Sun C., 2012, IEEE INT C HIGH PERF, P1391
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang JH, 2017, IEEE T IMAGE PROCESS, V26, P1202, DOI 10.1109/TIP.2016.2642791
   Wu QB, 2018, IEEE T BROADCAST, V64, P367, DOI 10.1109/TBC.2017.2786023
   Wu QB, 2017, IEEE T MULTIMEDIA, V19, P2490, DOI 10.1109/TMM.2017.2700206
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Yang Y, 2017, OPTIK, V138, P21, DOI 10.1016/j.ijleo.2017.03.029
   Yi Wan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457892
   Yue GH, 2017, J VIS COMMUN IMAGE R, V49, P382, DOI 10.1016/j.jvcir.2017.09.011
   Zhao Y., 2010, P SPIE, V7744
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 45
TC 15
Z9 17
U1 3
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 30
EP 39
DI 10.1016/j.jvcir.2018.05.023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100004
DA 2024-07-18
ER

PT J
AU Zhu, SJ
   Li, YH
   Kalra, S
   Tizhoosh, HR
AF Zhu, Shujin
   Li, Yuehua
   Kalra, Shivam
   Tizhoosh, H. R.
TI Multiple disjoint dictionaries for representation of histopathology
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Image representation; Histopathology; Wholeslide
   imaging; Bag-of-words; Dictionary learning; LBP; SVM; Deep learning
ID SEGMENTATION; CLASSIFICATION; TEXTURE; BAG; WORDS; COLOR
AB With the availability of whole-slide imaging in pathology, high-resolution images offer a more convenient disease observation but also require content-based retrieval of large scans. The bag-of-visual-words methodology has shown a high ability to describe the image content for recognition and retrieval purposes. In this work, a variant of the bag-of-visual-words with multiple dictionaries for histopathology image classification is proposed and tested on the image dataset Kimia Path24 with more than 27,000 patches of size 1000 x 1000 belonging to 24 different classes. Features are extracted from patches and clustered to form multiple codebooks. The histogram intersection approach and support vector machines are exploited to build multiple classifiers. At last, the majority voting determines the final classification for each patch. The experiments demonstrate the superiority of the proposed method for histopathology images that surpasses deep networks, LBP and other BoW results.
C1 [Zhu, Shujin; Li, Yuehua] Nanjing Univ Sci & Technol, Sch Elect & Opt Engn, Nanjing, Jiangsu, Peoples R China.
   [Zhu, Shujin; Kalra, Shivam; Tizhoosh, H. R.] Univ Waterloo, Lab Knowledge Inference Med Image Anal KIMIA Lab, Waterloo, ON, Canada.
C3 Nanjing University of Science & Technology; University of Waterloo
RP Zhu, SJ (corresponding author), Univ Waterloo, Lab Knowledge Inference Med Image Anal KIMIA Lab, Waterloo, ON, Canada.
EM tizhoosh@uwaterloo.ca
RI li, yueyue/IVH-9846-2023; LI, Yue/GRS-8071-2022; Tizhoosh, Hamid
   R/G-1369-2014; li, yue/IXD-9935-2023; li, yue/HSF-7296-2023
FU China Scholarship Council; Natural Sciences and Engineering Research
   Council of Canada (NSERC)
FX The authors thank China Scholarship Council and Natural Sciences and
   Engineering Research Council of Canada (NSERC) for supporting this
   project.
CR Agarwal A, 2006, LECT NOTES COMPUT SC, V3951, P30
   Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   Altunbay D, 2010, IEEE T BIO-MED ENG, V57, P665, DOI 10.1109/TBME.2009.2033804
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], CHIN C IM GRAPH TECH
   [Anonymous], ARXIV171005726
   [Anonymous], LOCALBINARYPATTERNS
   [Anonymous], 2013, ARXIV13060178
   [Anonymous], 2007, MIR
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], SURVEY TEXT MINING
   [Anonymous], 2017, ARXIV170507522
   [Anonymous], ARXIV171001249
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Avni U, 2011, IEEE T MED IMAGING, V30, P733, DOI 10.1109/TMI.2010.2095026
   Banerji S, 2013, LECT NOTES COMPUT SC, V8047, P490, DOI 10.1007/978-3-642-40261-6_59
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015
   Caicedo JC, 2011, J BIOMED INFORM, V44, P519, DOI 10.1016/j.jbi.2011.01.011
   Caicedo JC, 2009, LECT NOTES ARTIF INT, V5651, P126, DOI 10.1007/978-3-642-02976-9_17
   Comaniciu D, 2002, ADV PTRN RECOGNIT, P541
   Datar M, 2008, I S BIOMED IMAGING, P292, DOI 10.1109/ISBI.2008.4540990
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Diamant I, 2017, IEEE T BIO-MED ENG, V64, P1380, DOI 10.1109/TBME.2016.2605627
   Fan Jianping., 2004, ACM International Conference on Multimedia, P540, DOI [DOI 10.1145/1027527, DOI 10.1145/1027527.1027660]
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hermosilla G, 2014, LECT NOTES COMPUT SC, V8827, P486, DOI 10.1007/978-3-319-12568-8_60
   Huang PW, 2010, PATTERN RECOGN, V43, P1550, DOI 10.1016/j.patcog.2009.10.014
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Kong J, 2009, PATTERN RECOGN, V42, P1080, DOI 10.1016/j.patcog.2008.10.035
   Kothari S, 2013, J AM MED INFORM ASSN, V20, P1099, DOI 10.1136/amiajnl-2012-001540
   Kyungsuk Pyun, 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P501, DOI 10.1109/ICME.2002.1035657
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Madabhushi Anant, 2009, Imaging Med, V1, P7, DOI 10.2217/IIM.09.9
   Maji S., 2008, COMPUTER VISION PATT
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Ozdemir E, 2013, IEEE T MED IMAGING, V32, P474, DOI 10.1109/TMI.2012.2230186
   Pedrosa GV, 2014, COMP MED SY, P165, DOI 10.1109/CBMS.2014.60
   Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25
   Sujatha KS, 2012, PROCEDIA ENGINEER, V38, P2196, DOI 10.1016/j.proeng.2012.06.264
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Tsai ChihFong., 2012, ISRN Artificial Intelligence, V2012
   Wang G., 2006, CVPR, P1597
   Wang J, 2013, BIOMED SIGNAL PROCES, V8, P634, DOI 10.1016/j.bspc.2013.06.004
   Xu Y, 2014, MED IMAGE ANAL, V18, P591, DOI 10.1016/j.media.2014.01.010
   Xu Y, 2012, PROC CVPR IEEE, P964, DOI 10.1109/CVPR.2012.6247772
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhang XF, 2015, IEEE T MED IMAGING, V34, P496, DOI 10.1109/TMI.2014.2361481
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zheng L, 2003, IEEE T INF TECHNOL B, V7, P249, DOI 10.1109/TITB.2003.822952
   Zheng YL, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0093624, 10.1371/journal.pone.0109765]
NR 55
TC 12
Z9 12
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 243
EP 252
DI 10.1016/j.jvcir.2018.06.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100021
OA hybrid
DA 2024-07-18
ER

PT J
AU Dong, WQ
   Xiao, S
   Li, YX
AF Dong, Wenqian
   Xiao, Song
   Li, Yongxu
TI Hyperspectral pansharpening based on guided filter and Gaussian filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral image; Panchromatic image; Image fusion; Guided filter
ID FUSION TECHNIQUE; IMAGES
AB Hyperspectral pansharpening aims to integrate the panchromatic (PAN) and hyperspectral (HS) images into a single HS image with high spatial and high spectral resolution. This paper proposes a novel hyperspectral pansharpening method based on guided filter and gaussian filter. Most guided filter based researches extract the spatial details from the PAN image or the single band HS intensity component, and incorrect generation of the intensity component causes the spectral distortion. Different from the traditional guided filter based methods, the structure of the HS image is fully considered by the proposed method. We first use the high frequency layer of each band of the HS image as the guidance image of the guided filter. Then, the total spatial details are extracted from both the PAN image and the HS image. The total spatial details are finally injected into each band of the HS image low frequency layer to generate the fused image. Experiments demonstrate that the proposed method outperforms some state-of-the-art methods in terms of objective quality assessment and subjective visual effect.
C1 [Dong, Wenqian; Xiao, Song; Li, Yongxu] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Xiao, S (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
EM xiaosong@mail.xidian.edu.cn
FU NSFC [61372069]; National Defense Pre-research Foundation; SRF for ROCS,
   SEM [JY0600090102]; "111" project [B08038]; Fundamental Research Funds
   for the Central Universities
FX The authors would like to thank the Editor and the anonymous reviewers
   for their insightful comments and suggestions which have greatly
   improved this paper. This work was supported by NSFC (No. 61372069),
   National Defense Pre-research Foundation, SRF for ROCS, SEM
   (JY0600090102), "111" project (No. B08038) and the Fundamental Research
   Funds for the Central Universities.
CR Aiazzi B, 2006, PHOTOGRAMM ENG REM S, V72, P591, DOI 10.14358/PERS.72.5.591
   Alparone L, 2003, INT GEOSCI REMOTE SE, P458
   Alparone L, 2007, IEEE T GEOSCI REMOTE, V45, P3012, DOI 10.1109/TGRS.2007.904923
   [Anonymous], INFORM FUSION
   [Anonymous], SENSORS
   [Anonymous], ENG REMOTE SENS
   Baronti S, 2011, IEEE J-STSP, V5, P446, DOI 10.1109/JSTSP.2011.2104938
   CHAVEZ PS, 1989, PHOTOGRAMM ENG REM S, V55, P339
   Draper N. R., 2014, Applied regression analysis
   Garzelli A, 2006, INT GEOSCI REMOTE SE, P3810, DOI 10.1109/IGARSS.2006.976
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   Hastie T., 2003, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Laben C. A., 2000, US Patent, Patent No. 6,011,875
   Liao WZ, 2015, IEEE J-STARS, V8, P2984, DOI 10.1109/JSTARS.2015.2420582
   Liu JG, 2000, INT J REMOTE SENS, V21, P3461, DOI 10.1080/014311600750037499
   Loncan L, 2015, IEEE GEOSC REM SEN M, V3, P27, DOI 10.1109/MGRS.2015.2440094
   Mookambiga A, 2016, MULTIDIM SYST SIGN P, V27, P863, DOI 10.1007/s11045-016-0415-2
   Qu JH, 2017, IEEE GEOSCI REMOTE S, V14, P2152, DOI 10.1109/LGRS.2017.2755679
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Simoes M, 2015, IEEE T GEOSCI REMOTE, V53, P3373, DOI 10.1109/TGRS.2014.2375320
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Wald L, 1997, PHOTOGRAMM ENG REM S, V63, P691
   Wei Q, 2015, IEEE T IMAGE PROCESS, V24, P4109, DOI 10.1109/TIP.2015.2458572
   Wei Q, 2015, IEEE J-STSP, V9, P1117, DOI 10.1109/JSTSP.2015.2407855
   Wei Q, 2015, IEEE T GEOSCI REMOTE, V53, P3658, DOI 10.1109/TGRS.2014.2381272
   Yokoya N, 2012, IEEE T GEOSCI REMOTE, V50, P528, DOI 10.1109/TGRS.2011.2161320
   Zhang LF, 2012, IEEE T GEOSCI REMOTE, V50, P879, DOI 10.1109/TGRS.2011.2162339
   Zhu XX, 2013, IEEE T GEOSCI REMOTE, V51, P2827, DOI 10.1109/TGRS.2012.2213604
NR 29
TC 6
Z9 6
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 171
EP 179
DI 10.1016/j.jvcir.2018.03.014
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800016
DA 2024-07-18
ER

PT J
AU Ding, BY
   Wen, GJ
AF Ding, Baiyuan
   Wen, Gongjian
TI Sparsity constraint nearest subspace classifier for target recognition
   of SAR images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Syntheticaperture radar (SAR); Target recognition; Sparsity constraint
   nearest subspace classifier (SNSC); Sparse representation based
   classification (SRC)
AB This paper proposes a sparsity constraint nearest subspace classifier (SNSC) for target recognition of synthetic aperture radar (SAR) images. Unlike optical images, SAR images are highly sensitive to target azimuth. Therefore, the global dictionary collaborated by samples from different classes has high between-class correlation, which will impair the performance of sparse representation-based classification (SRC). Furthermore, even on the subspace spanned by a single class, only a small number of samples with similar azimuths to the test image are highly correlated with the test image. Thus, the linear coefficients over the subspace are actually sparse ones. Therefore, in this paper we impose sparsity constraint on nearest subspace classifier (NSC) classifier and apply it to SAR target recognition. The target label of the test sample is decided to be the class with the minimum reconstruction error. The proposed method is tested on moving and stationary target acquisition and recognition (MSTAR) dataset and compared with several state-of-the-art methods and the experimental results verify the validity and robustness of the proposed method.
C1 [Ding, Baiyuan; Wen, Gongjian] Natl Univ Def Technol, Sci & Technol Automat Target Recognit Lab, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China
RP Ding, BY (corresponding author), Natl Univ Def Technol, Sci & Technol Automat Target Recognit Lab, Changsha 410073, Hunan, Peoples R China.
EM dingbaiyuan_nudt@163.com
CR [Anonymous], 2010, P IEEE 4 INT S COMM, DOI [DOI 10.1109/ISCCSP.2010.5463416, https://doi.org/10.1109/ISCCSP.2010.5463416]
   Argenti F, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2277512
   Bhanu B, 2002, P SOC PHOTO-OPT INS, V4727, P290, DOI 10.1117/12.478686
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Ding BY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9111150
   Ding BY, 2017, IEEE J-STARS, V10, P3334, DOI 10.1109/JSTARS.2017.2671919
   Ding BY, 2017, REMOTE SENS LETT, V8, P821, DOI 10.1080/2150704X.2017.1331052
   Ding BY, 2017, IEEE GEOSCI REMOTE S, V14, P979, DOI 10.1109/LGRS.2017.2692386
   Ding BY, 2017, IET RADAR SONAR NAV, V11, P682, DOI 10.1049/iet-rsn.2016.0357
   Ding BY, 2017, NEUROCOMPUTING, V219, P130, DOI 10.1016/j.neucom.2016.09.007
   Dong GG, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2421440
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Doo S.H., 2015, P APSAR, P1
   El-Darymli K, 2016, IEEE ACCESS, V4, P6014, DOI 10.1109/ACCESS.2016.2611492
   Liu HC, 2013, NEUROCOMPUTING, V113, P97, DOI 10.1016/j.neucom.2013.01.033
   Majumdar A, 2010, IEEE T SYST MAN CY B, V40, P1359, DOI 10.1109/TSMCB.2009.2038493
   Singh IP, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P1, DOI 10.1109/HEALTH.2008.4600098
   Touzi R, 2002, IEEE T GEOSCI REMOTE, V40, P2392, DOI 10.1109/TGRS.2002.803727
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao Q, 2001, IEEE T AERO ELEC SYS, V37, P643, DOI 10.1109/7.937475
NR 22
TC 23
Z9 23
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 170
EP 176
DI 10.1016/j.jvcir.2018.02.012
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300017
DA 2024-07-18
ER

PT J
AU Gao, GY
   Han, C
   Ma, K
   Liu, CH
   Ding, GY
   Liu, EW
AF Gao, Guangyu
   Han, Cen
   Ma, Kun
   Liu, Chi Harold
   Ding, Gangyi
   Liu, Erwu
TI Optimal feature combination analysis for crowd saliency prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd; Saliency; Random forest; Visual attention; Face detection
ID VISUAL-ATTENTION
AB Crowd saliency prediction refers to predicting where people look at in crowd scene. Humans have remarkable ability to rapidly direct their gaze to select visual information of interest when looking at a visual scene. Until now, research efforts are still focused on what type of feature is representative for crowd saliency, and which type of learning model is robust for crowd saliency prediction. In this paper, we propose a Random Forest (RF) based crowd saliency prediction approach with optimal feature combination, i.e., the Feature Combination Selection for Crowd Saliency (FCSCS) framework. More specifically, we first define three representative crowd saliency features, namely, FaceSizeDiff, FacePoseDiff and FaceWhrDiff. Next, we adopt the Random Forest (RF) algorithm to construct our saliency learning model. Then, we evaluate the performance of FCSCS framework with different feature combinations (fifteen combinations in our experiments). Those selected features include low-level features (i.e., color, intensity, orientation), four crowd features (i.e., face size, face density, frontal face, profile face) and three new defined features (i.e., FaceSizeDiff, FacePoseDiff and FaceWhrDiff). We use FCSCS framework to obtain the optimal feature combination that is most suitable for crowd saliency prediction and further train the saliency model based on the optimal feature combination. After that, we evaluate the performance of the crowd saliency prediction classifiers. Finally, we conduct extensive experiments and empirical evaluation to demonstrate the satisfactory performance of our approach.
C1 [Gao, Guangyu; Han, Cen; Ma, Kun; Liu, Chi Harold; Ding, Gangyi] Beijing Inst Technol, Sch Software, Beijing 100081, Peoples R China.
   [Liu, Erwu] Tongji Univ, Sch Elect & Informat, Shanghai 200092, Peoples R China.
C3 Beijing Institute of Technology; Tongji University
RP Gao, GY (corresponding author), Beijing Inst Technol, Sch Software, Beijing 100081, Peoples R China.
EM guangyugao@bit.edu.cn; mysayalhan@gmail.com; kunma@bit.edu.cn;
   chiliu@bit.edu.cn; dgy@bit.edu.cn; erwuliu@tongji.edu.cn
RI Liu, Chi Harold/Z-4017-2019; Liu, Erwu/K-7692-2015
OI Liu, Chi Harold/0000-0002-0252-329X; Liu, Erwu/0000-0002-2706-6208
FU National Natural Science Foundation of China [61401023]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61401023.
CR [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], STATIC SALIENCY VS D
   [Anonymous], 2015, CVPR
   [Anonymous], 2011, J VIS
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Chiappino S, 2015, INT CONF ACOUST SPEE, P2110, DOI 10.1109/ICASSP.2015.7178343
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Jiang M, 2014, LECT NOTES COMPUT SC, V8695, P17, DOI 10.1007/978-3-319-10584-0_2
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kok VJ, 2016, NEUROCOMPUTING, V177, P342, DOI 10.1016/j.neucom.2015.11.021
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lim MK, 2014, INT C PATT RECOG, P3957, DOI 10.1109/ICPR.2014.678
   Luo DW, 2016, I COMP CONF WAVELET, P1, DOI 10.1109/ICCWAMTIP.2016.8079794
   Ma K, 2016, INT CONF WIRE COMMUN
   Mathialagan CS, 2015, PROC CVPR IEEE, P4858, DOI 10.1109/CVPR.2015.7299119
   Mingyuan Gao, 2018, IEEE Transactions on Intelligent Transportation Systems, V19, P900, DOI 10.1109/TITS.2017.2709346
   Nguyen TV, 2015, IEEE T CIRC SYST VID, V25, P77, DOI 10.1109/TCSVT.2014.2333151
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   Ouerhani N., 2004, ELECT LETT COMPUTER, V3, P13, DOI [10.5565/rev/elcvia.66, DOI 10.5565/REV/ELCVIA.66]
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Torralba A, 2003, J OPT SOC AM A, V20, P1407, DOI 10.1364/JOSAA.20.001407
   Vu TH, 2015, IEEE I CONF COMP VIS, P2893, DOI 10.1109/ICCV.2015.331
   Wang JW, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2522380
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Xu M, 2015, IEEE I CONF COMP VIS, P3907, DOI 10.1109/ICCV.2015.445
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 39
TC 2
Z9 2
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 1
EP 8
DI 10.1016/j.jvcir.2017.11.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700001
DA 2024-07-18
ER

PT J
AU Gvozden, G
   Grgic, S
   Grgic, M
AF Gvozden, Goran
   Grgic, Sonja
   Grgic, Mislav
TI Blind image sharpness assessment based on local contrast map statistics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No-reference; Image quality assessment; Contrast; Percentile; Dynamic
   range; Wavelet
ID QUALITY ASSESSMENT; PHASE
AB This paper presents a fast blind image sharpness/blurriness assessment model (BISHARP) which operates in spatial and transform domain. The proposed model generates local contrast image maps by computing the root mean-squared values for each image pixel within a defined size of local neighborhood. The resulting local contrast maps are then transformed into the wavelet domain where the reduction of high frequency content is evaluated in the presence of varying blur strengths. It was found that percentile values computed from sorted, level-shifted, high-frequency wavelet coefficients can serve as reliable image sharpness/blurriness estimators. Furthermore, it was found that higher dynamic range of contrast maps significantly improves model performance. The results of validation performed on seven image databases showed a very high correlation with perceptual scores. Due to low computational requirements the proposed model can be easily utilized in real world image processing applications.
C1 [Gvozden, Goran; Grgic, Sonja; Grgic, Mislav] Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, Unska 3-12, Zagreb 10000, Croatia.
C3 University of Zagreb
RP Gvozden, G (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, Unska 3-12, Zagreb 10000, Croatia.
EM goran.gvozden@fer.hr
RI ; Grgic, Mislav/B-6128-2008
OI Grgic, Sonja/0000-0002-0802-3288; Grgic, Mislav/0000-0001-6230-3734
CR [Anonymous], NIPS
   [Anonymous], 2005, SUBJECTIVE QUALITY A
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Bex PJ, 2002, J OPT SOC AM A, V19, P1096, DOI 10.1364/JOSAA.19.001096
   Caviedes J, 2004, SIGNAL PROCESS-IMAGE, V19, P147, DOI 10.1016/j.image.2003.08.002
   Ferzli Rony, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P445
   Ferzli R, 2006, IEEE IMAGE PROC, P2949, DOI 10.1109/ICIP.2006.312925
   Frazor RA, 2006, VISION RES, V46, P1585, DOI 10.1016/j.visres.2005.06.038
   Gao Y, 2011, IEEE IMAGE PROC, P1249, DOI 10.1109/ICIP.2011.6115659
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Hillaire S, 2008, IEEE VIRTUAL REALITY 2008, PROCEEDINGS, P47
   ITU-T Tutorial,, 2004, OBJ PERC ASS VID QUA
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   KNILL DC, 1990, J OPT SOC AM A, V7, P1113, DOI 10.1364/JOSAA.7.001113
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Ma K., ARXIV161201227
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mantiuk R., 2007, Forsch. Wiss. Rechnen, V72, P11
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Pelli DG, 2013, VISION RES, V90, P10, DOI 10.1016/j.visres.2013.04.015
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Saad M. A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3093, DOI 10.1109/ICIP.2011.6116319
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sang Q.-B., 2014, PLOS ONE, V9, P1
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Shahid M, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-40
   Sheikh H.R., 2005, LIVE IMAGE QUALITY A, V2
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Simoncelli E.P., 1990, SUBBAND CODING, P143
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2017, Digital Video image quality and perceptual coding, P225, DOI DOI 10.1201/9781420027822-7
   Wang Z, 2006, IEEE IMAGE PROC, P2945, DOI 10.1109/ICIP.2006.313136
   Webster MA, 2002, NAT NEUROSCI, V5, P839, DOI 10.1038/nn906
   Winkler S, 2001, PROC SPIE, V4299, P114, DOI 10.1117/12.429540
   Xu SP, 2017, IETE TECH REV, V34, P223, DOI 10.1080/02564602.2016.1151385
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Zaric A, 2012, AUTOMATIKA, V53, P344, DOI 10.7305/automatika.53-4.241
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang XX, 2016, J VIS COMMUN IMAGE R, V35, P257, DOI 10.1016/j.jvcir.2016.01.002
NR 59
TC 26
Z9 31
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 145
EP 158
DI 10.1016/j.jvcir.2017.11.017
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700015
DA 2024-07-18
ER

PT J
AU Wang, RG
   Xie, YF
   Yang, J
   Xue, LX
   Hu, M
   Zhang, QY
AF Wang, Ronggui
   Xie, Yunfei
   Yang, Juan
   Xue, Lixia
   Hu, Min
   Zhang, Qingyang
TI Large scale automatic image annotation based on convolutional neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Automatic image annotation; Adaptive label; Multitasking;
   Convolutional neural network
AB Automatic image annotation is one of the most important challenges in computer vision, which is critical to many real-world researches and applications. In this paper, we focus on the issue of large scale image annotation with deep learning. Firstly, considering the existing image data, especially the network images, most of the labels of themselves are inaccurate or imprecise. We propose a Multitask Voting (MV) method, which can improve the accuracy of original annotation to a certain extent, thereby enhancing the training effect of the model. Secondly, the MV method can also achieve the adaptive label, whereas most existing methods pre-specify the number of tags to be selected. Additionally, based on convolutional neural network, a large scale image annotation model MVAIACNN is constructed. Finally, we evaluate the performance with experiments on the MIRFlickr25K and NUS-WIDE datasets, and compare with other methods, demonstrating the effectiveness of the MVAIACNN. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Wang, Ronggui; Xie, Yunfei; Yang, Juan; Xue, Lixia; Hu, Min; Zhang, Qingyang] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM yangjuan6985@163.com
RI Lin, Kuan-Yu/JXM-6653-2024; Hu, Min/HLH-2112-2023
FU National Natural Science Foundation of China [61672202]
FX We express our sincere thanks to the Dr. He for providing the NUS-WIDE
   dataset, and the authors would also like to thank the anonymous
   reviewers for their useful comments and suggestions to raise the
   standard of the paper. This work is partly supported by the National
   Natural Science Foundation of China under Project code (61672202).
CR Anantrasirichai N, 2015, IEEE IMAGE PROC, P3957, DOI 10.1109/ICIP.2015.7351548
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], 2010, PROC ACM SIGMM INT C
   [Anonymous], 2012, INT C MACH LEARN WOR
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   He YH, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P523, DOI 10.1145/2671188.2749330
   Hironobu Y.M., 1999, Proceedings of First International Workshop on Multimedia Intelligent Storage and Retrieval Management, P405
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Marée R, 2005, PROC CVPR IEEE, P34
   Shi R, 2004, LECT NOTES COMPUT SC, V3115, P545
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun Yi, 2014, NEURIPS, DOI DOI 10.1007/978-3-030-01252-6_48
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
NR 13
TC 29
Z9 32
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 213
EP 224
DI 10.1016/j.jvcir.2017.07.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800018
DA 2024-07-18
ER

PT J
AU Chen, CY
   Pham, HX
   Pavlovic, V
   Cai, JF
   Shi, GM
   Gao, YF
   Cheng, H
AF Chen, Chongyu
   Pham, Hai Xuan
   Pavlovic, Vladimir
   Cai, Jianfei
   Shi, Guangming
   Gao, Yuefang
   Cheng, Hui
TI Using 3D face priors for depth recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth recovery; Image restoration; Face model
ID MODELS
AB For methods primarily rely on low-level and rigid prior information. However, as the depth quality deteriorates, the recovered depth maps become increasingly unreliable, especially for non-rigid objects. Thus, additional high-level and non-rigid information is needed to improve the recovery quality. Taking as a starting point the human face that is the primary prior available in many high-level tasks, in this paper, we incorporate face priors into the depth recovery process. In particular, we propose a joint optimization framework that consists of two main steps: transforming the face model for better alignment and applying face priors for improved depth recovery. Face priors from both sparse and dense 3D face models are studied. By comparing with the baseline method on benchmark datasets, we demonstrate that the proposed method can achieve up to 23.8% improvement in depth recovery with more accurate face registrations, bringing inspirations to both non-rigid object modeling and analysis. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Chen, Chongyu; Cheng, Hui] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Pham, Hai Xuan; Pavlovic, Vladimir] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
   [Cai, Jianfei] Nanyang Technol Univ, Sch Comp Sci, Singapore 639798, Singapore.
   [Shi, Guangming] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Gao, Yuefang] South China Agr Univ, Coll Math & Informat, Guangzhou 510642, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Rutgers University System; Rutgers University
   New Brunswick; Nanyang Technological University; Xidian University;
   South China Agricultural University
RP Cheng, H (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM chenchy47@mail.sysu.edu.cn; hxpl@cs.rutgers.edu;
   vladimir@cs.rutgers.edu; asjfcai@ntu.edu.sg; gmshi@xidian.edu.cn;
   gaoyuefang@scau.edu.cn; chengh9@mail.sysu.edu.cn
RI Chen, Chongyu/IWM-0773-2023; Cai, Jianfei/A-3691-2011
OI Cai, Jianfei/0000-0002-9444-3763; Pavlovic, Vladimir/0000-0003-3979-1236
FU Singapore National Research Foundation under its International Research
   Centre @ Singapore Funding Initiative; NSF, USA [CNS-1229628]; National
   Natural Science Foundation of China [61602533]; Fundamental Research
   Funds for the Central Universities; 111 Project [B07048]; Science and
   Technology Planning Project of Guangdong Province, China
   [2016A020210086]
FX This research is partially by the Singapore National Research Foundation
   under its International Research Centre @ Singapore Funding Initiative
   and administered by the IDM Programme Office and the NSF Project
   CNS-1229628, USA. This work is also partially supported by the National
   Natural Science Foundation of China under Grant 61602533, The
   Fundamental Research Funds for the Central Universities, the 111 Project
   (No. B07048), and Science and Technology Planning Project of Guangdong
   Province (No. 2016A020210086), China.
CR Ahlberg J., 2001, An updated parameterized face
   Aldrian O, 2013, IEEE T PATTERN ANAL, V35, P1080, DOI 10.1109/TPAMI.2012.206
   [Anonymous], 2013, EURASIP J WIRELESS C
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   [Anonymous], 2004, Linear Least-Squares Optimization for Point-to-Plane Icp Surface Registration
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Bouaziz S., 2013, SIGGRAPH
   Cai Q., 2010, EUR C COMP VIS ECCV
   Cao C., 2013, SIGGRAPH
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen CY, 2015, LECT NOTES COMPUT SC, V9006, P336, DOI 10.1007/978-3-319-16817-3_22
   Chen CY, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2700475
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Feng ZH, 2015, IEEE T IMAGE PROCESS, V24, P3425, DOI 10.1109/TIP.2015.2446944
   Heo J, 2010, THESIS
   Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275
   Ismaeil K.A., 2016, IEEE T PATTERN ANAL, P1
   Jung SW, 2013, IEEE T CIRC SYST VID, V23, P269, DOI 10.1109/TCSVT.2012.2203734
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Kuster C., 2011, Proc. Annual Workshop on Vision, P17
   Maimone A, 2011, INT SYM MIX AUGMENT
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Mutto C., 2012, SPRINGERBRIEFS ELECT, P33
   Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Pham H.X., 2014, P INT C PATT REC ICP
   Qi F, 2013, PATTERN RECOGN LETT, V34, P70, DOI 10.1016/j.patrec.2012.06.003
   Richardt C, 2012, COMPUT GRAPH FORUM, V31, P247, DOI 10.1111/j.1467-8659.2012.03003.x
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   ter Haar FB, 2008, LECT NOTES COMPUT SC, V5305, P652, DOI 10.1007/978-3-540-88693-8_48
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang H., 2012, ICRA
   Weise T., 2011, SIGGRAPH
   Welsh B., 1991, THESIS
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Zhang C, 2013, IEEE MULTIMEDIA, V20, P17, DOI 10.1109/MMUL.2013.12
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 44
TC 4
Z9 4
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 16
EP 29
DI 10.1016/j.jvcir.2017.06.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700002
DA 2024-07-18
ER

PT J
AU Chandrika, BK
   Aparna, P
   Sumam, DS
AF Chandrika, B. K.
   Aparna, P.
   Sumam, David S.
TI Perceptually lossless coder for volumetric medical image data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compression; Visual perception; Human visual system; Bilateral
   symmetry; MRI and CT images
ID PARALLEL FRAMEWORK; QUALITY ASSESSMENT
AB With the development of modern imaging techniques, every medical examination would result in a huge volume of image data. Analysis, storage and/or transmission of these data demands high compression without any loss of diagnostically significant data. Although, various 3-D compression techniques have been proposed, they have not been able to meet the current requirements. This paper proposes a novel method to compress 3-D medical images based on human vision model to remove visually insignificant information. The block matching algorithm applied to exploit the anatomical symmetry remove the spatial redundancies. The results obtained are compared with those of lossless compression techniques. The results show better compression without any degradation in visual quality. The rate-distortion performance of the proposed coders is compared with that of the state-of-the-art lossy coders. The subjective evaluation performed by the medical experts confirms that the visual quality of the reconstructed image is excellent. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Chandrika, B. K.] Manipal Univ, Manipal Inst Technol, Dept Elect & Elect Engn, Manipal 576104, Karnataka, India.
   [Aparna, P.; Sumam, David S.] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Surathkal 575025, India.
C3 Manipal Academy of Higher Education (MAHE); National Institute of
   Technology (NIT System); National Institute of Technology Karnataka
RP Chandrika, BK (corresponding author), Manipal Univ, Manipal Inst Technol, Dept Elect & Elect Engn, Manipal 576104, Karnataka, India.
EM chandrika.bk@manipal.edu
RI K, Chandrika B/R-6747-2019; S., Sumam David/E-5843-2017
OI K, Chandrika B/0000-0002-7178-3079; S., Sumam David/0000-0001-6503-2837
CR Ait-Aoudia S, 2006, LECT NOTES COMPUT SC, V4263, P563
   Al-Ameen Z, 2015, INTERDISCIP SCI, V7, P319, DOI 10.1007/s12539-015-0022-1
   Amraee S, 2011, IEEE INT CON MULTI
   [Anonymous], 2013, P 18 INT C DIGITAL S
   [Anonymous], 2016, KAKADU VERSION 7 4 J
   Bilgin A., 1998, IEEE C P DAT COMPR
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chandrika BK, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS, AND CONTROL TECHNOLOGY (I4CT), P53, DOI 10.1109/I4CT.2014.6914144
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Clunie DA, 2000, PROC SPIE, V3980, P74, DOI 10.1117/12.386389
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kowalik-Urbaniak I., 2014, MED IMAGING INT SOC
   Kowalik-Urbaniak IA, 2015, LECT NOTES COMPUT SC, V9164, P3, DOI 10.1007/978-3-319-20801-5_1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy G, 2006, LECT NOTES COMPUT SC, V3952, P508
   Menegaz G, 2003, IEEE T MED IMAGING, V22, P424, DOI 10.1109/TMI.2003.809689
   Miaou SG, 2009, IEEE T INF TECHNOL B, V13, P818, DOI 10.1109/TITB.2009.2022971
   Nadenau M., 2000, Proceedings of the IEEE, P1, DOI DOI 10.1.1.5.2376&REP=REP1&TYPE=PDF
   Razaak M, 2014, IEEE J BIOMED HEALTH, V18, P1552, DOI 10.1109/JBHI.2014.2326891
   Safranek R. J., 1989, INT C AC SPEECH SIGN
   Sanchez Victor, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6622, DOI 10.1109/ICASSP.2014.6854881
   Sanchez V, 2009, IEEE T MED IMAGING, V28, P1062, DOI 10.1109/TMI.2009.2012899
   Sanchez V, 2009, IEEE IMAGE PROC, P2525, DOI 10.1109/ICIP.2009.5414013
   Santos J. M., 2014, IEEE INT C IM PROC
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   TZANNES A, 2000, COMPRESSION 3 DIMENS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wongsawat Y, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1560, DOI 10.1109/ICALIP.2008.4590113
   Wu D, 2006, IEEE T MED IMAGING, V25, P335, DOI 10.1109/TMI.2006.870483
   Wu XL, 1996, INT CONF ACOUST SPEE, P1890, DOI 10.1109/ICASSP.1996.544819
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
NR 34
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 23
EP 32
DI 10.1016/j.jvcir.2017.03.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500003
DA 2024-07-18
ER

PT J
AU Furnari, A
   Farinella, GM
   Bruna, AR
   Battiato, S
AF Furnari, Antonino
   Farinella, Giovanni Maria
   Bruna, Arcangelo Ranieri
   Battiato, Sebastiano
TI Distortion adaptive Sobel filters for the gradient estimation of wide
   angle images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gradient estimation; Adaptive filters; Radial distortion; Wide angle
   images
ID SCALE-SPACE; CALIBRATION; FEATURES
AB We introduce a set of distortion adaptive Sobel filters for the direct estimation of geometrically correct gradients of wide angle images. The definition of the filters is based on Sobel's rationale and accounts for the geometric transformation undergone by wide angle images due to the presence of radial distortion. Moreover, we show that a local normalization of the filters magnitude is essential to achieve state-of-the-art results. To perform the experimental analysis, we propose an evaluation pipeline and a benchmark dataset of images belonging to different scene categories. Experiments on both, synthetic and real images, show that our approach outperforms the current state-of-the-art in both gradient estimation and keypoint matching for images characterized by large amounts of radial distortion. The collected dataset and the MATLAB code of the proposed method can be downloaded at our web page http://iplab.dmi.unict.it/DASF/. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Furnari, Antonino; Farinella, Giovanni Maria; Battiato, Sebastiano] Univ Catania, Dept Math & Comp Sci, Catania, Italy.
   [Bruna, Arcangelo Ranieri] STMicroelectronics, Adv Syst Technol Comp Vis, Catania, Italy.
C3 University of Catania; STMicroelectronics
RP Furnari, A (corresponding author), Univ Catania, Dept Math & Comp Sci, Catania, Italy.
EM furnari@dmi.unict.it; gfarinella@dmi.unict.it; arcangelo.bruna@st.com;
   battiato@dmi.unict.it
RI Battiato, Sebastiano/ABI-1584-2020; Bruna, Arcangelo
   Ranieri/I-7842-2019; Battiato, Sebastiano/F-5842-2012; Battiato,
   Sebastiano/O-7799-2019; FARINELLA, Giovanni Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; Bruna, Arcangelo
   Ranieri/0000-0002-9147-4978; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432; FURNARI, Antonino/0000-0001-6911-0302
FU the Netherlands; ENIAC
FX This work has been performed in the project PANORAMA, co-funded by
   grants from Belgium, Italy, France, the Netherlands, the United Kingdom,
   and the ENIAC Joint Undertaking.
CR Ainouz S, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.3.037001
   [Anonymous], INT WORKSH ULTR WID
   [Anonymous], ACM T GRAPH
   [Anonymous], SIGN SYST C
   [Anonymous], EURASIP J IMAGE VIDE
   [Anonymous], PATTERN CLASSIFICATI
   [Anonymous], J OPTICAL SOC AM JOS
   [Anonymous], EXP SYST APPL
   [Anonymous], SCENES
   [Anonymous], WORKSH ASS COMP VIS
   Arican Z, 2010, IEEE IMAGE PROC, P3505, DOI 10.1109/ICIP.2010.5650845
   Battiato S, 2014, IEEE T IMAGE PROCESS, V23, P2081, DOI 10.1109/TIP.2014.2312649
   Bogdanova I, 2007, IEEE T IMAGE PROCESS, V16, P1888, DOI 10.1109/TIP.2007.899008
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cinaroglu I, 2014, SIG PROCESS COMMUN, P2275, DOI 10.1109/SIU.2014.6830719
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cruz-Mota J, 2012, INT J COMPUT VISION, V98, P217, DOI 10.1007/s11263-011-0505-4
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   Farinella GM, 2011, IET COMPUT VIS, V5, P320, DOI 10.1049/iet-cvi.2010.0056
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Fleck M., 1995, Perspective Projection: the Wrong Imaging Model
   Furnari A, 2017, IEEE T HUM-MACH SYST, V47, P6, DOI 10.1109/THMS.2016.2612002
   Furnari A, 2017, IEEE T IMAGE PROCESS, V26, P696, DOI 10.1109/TIP.2016.2627816
   Furnari A, 2015, IEEE IMAGE PROC, P3250, DOI 10.1109/ICIP.2015.7351404
   Furnari A, 2015, LECT NOTES COMPUT SC, V9280, P205, DOI 10.1007/978-3-319-23234-8_20
   Furnari A, 2014, IEEE IMAGE PROC, P5681, DOI 10.1109/ICIP.2014.7026149
   Hansen P., 2007, IEEE INT C COMPUTER
   Hughes C, 2009, IET INTELL TRANSP SY, V3, P19, DOI 10.1049/iet-its:20080017
   Hughes C, 2010, APPL OPTICS, V49, P3338, DOI 10.1364/AO.49.003338
   Islam MS, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P505, DOI 10.1109/DICTA.2009.86
   JAA DOMKE., 2006, British Machine Vision Conference, /, P509
   Kannala J, 2004, INT C PATT RECOG, P10, DOI 10.1109/ICPR.2004.1333993
   Lourenço M, 2012, IEEE T ROBOT, V28, P752, DOI 10.1109/TRO.2012.2184952
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Messina G, 2002, IEEE T CONSUM ELECTR, V48, P409, DOI 10.1109/TCE.2002.1037022
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pingle K.K., 1969, AUTOMATIC INTERPRETA, P277
   Puig L, 2011, IEEE I CONF COMP VIS, P1599, DOI 10.1109/ICCV.2011.6126420
   Puig Luis., 2013, Omnidirectional Vision Systems
   Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
NR 42
TC 19
Z9 19
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 165
EP 175
DI 10.1016/j.jvcir.2017.03.019
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500015
DA 2024-07-18
ER

PT J
AU Liu, YW
   Liu, JX
   Argyriou, A
   Ci, S
AF Liu, Yanwei
   Liu, Jinxia
   Argyriou, Antonios
   Ci, Song
TI Cross-layer optimized authentication and error control for wireless 3D
   medical video streaming over LTE
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cross-layer optimization; 3D medical video; Authentication; LTE; Error
   control
ID RESOURCE-ALLOCATION; MULTIMEDIA; DESIGN
AB 3D video for tele-medicine applications is gradually gaining momentum since the 3D technology can provide precise location information. However, the weak link for 3D video streaming is the necessary wireless link of the communication system. Neglecting the wireless impairments can severely degrade the performance of 3D video streaming that communicates complex critical medical data. In this paper, we propose systematic methodology for ensuring high performance of the 3D medical video streaming system. First, we present a recursive end-to-end distortion estimation approach for MVC (multiview video coding)-based 3D video streaming over error-prone networks by considering the 3D inter-view prediction. Then, based on the previous model, we develop a cross-layer optimization scheme that considers the LTE wireless physical layer (PHY). In this optimization, the authentication requirements of 3D medical video are also taken into account. The proposed cross-layer optimization approach jointly controls and manages the authentication, video coding quantization of 3D video, and the modulation and channel coding scheme (MCS) of the LTE wireless PHY to minimize the end-to-end video distortion. Experimental results show that the proposed approach can provide superior 3D medical video streaming performance in terms of peak signal-to-noise ratio (PSNR) when compared to state-of-the-art approaches that include joint source-channel optimized streaming with multi-path hash-chaining based authentication, and also conventional video streaming with single path hash-chaining-based authentication. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Yanwei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Liu, Jinxia] Zhejiang Wanli Univ, Ningbo, Zhejiang, Peoples R China.
   [Argyriou, Antonios] Univ Thessaly, Volos, Greece.
   [Ci, Song] Univ Nebraska, Omaha, NE 68182 USA.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Zhejiang Wanli University; University of Thessaly; University of
   Nebraska System
RP Liu, JX (corresponding author), Zhejiang Wanli Univ, Ningbo, Zhejiang, Peoples R China.
EM liujinxia1969@126.com
RI Argyriou, Antonios/AAF-9586-2021; liu, yanwei/L-2453-2019; Liu,
   Jinxia/H-1794-2011; Ci, Song/R-8324-2019
OI Argyriou, Antonios/0000-0002-2510-3124; 
FU Zhejiang Provincial Natural Science Foundation of China [LY17F010001];
   Public welfare project of Zhejiang Province - China [2014C31072]; Ningbo
   Natural Science Foundation of China [2015A610133]; National Natural
   Science Foundation of China [61472388]
FX This work was supported in part by Zhejiang Provincial Natural Science
   Foundation of China under Grant LY17F010001, Public welfare project of
   Zhejiang Province - China under Grant 2014C31072, Ningbo Natural Science
   Foundation of China under Grant 2015A610133 and National Natural Science
   Foundation of China under Grant 61472388.
CR [Anonymous], 2006, Elements of Information Theory
   [Anonymous], JCT3VJ1001
   Argyriou A, 2008, IEEE T MULTIMEDIA, V10, P1121, DOI 10.1109/TMM.2008.2001371
   Boho A, 2013, IEEE SIGNAL PROC MAG, V30, P97, DOI 10.1109/MSP.2012.2230220
   Chang C., 2016, P WORKSH MOB EV INT
   Constantinescu L, 2012, IEEE T INF TECHNOL B, V16, P40, DOI 10.1109/TITB.2011.2174064
   Fan JM, 2011, 2011 INTERNATIONAL CONFERENCE ON COMPUTER, ELECTRICAL, AND SYSTEMS SCIENCES, AND ENGINEERING (CESSE 2011), P100
   Gennaro R, 2001, INFORM COMPUT, V165, P100, DOI 10.1006/inco.2000.2916
   Guo LK, 2014, IEEE T MOBILE COMPUT, V13, P1927, DOI 10.1109/TMC.2013.84
   Jensen TL, 2010, IEEE T VEH TECHNOL, V59, P3766, DOI 10.1109/TVT.2010.2053727
   Li J, 2010, P 2010 IEEE INT S AP, P3, DOI [DOI 10.1109/ICIECS.2010.5678245, 10.1109/ISAF.2010.5712271, DOI 10.1109/ISAF.2010.5712271, 10.1145/1852786.1852804, DOI 10.1145/1852786.1852804]
   Li Z, 2007, IEEE T MULTIMEDIA, V9, P837, DOI 10.1109/TMM.2007.893338
   Liao HE, 2010, IEEE T BIO-MED ENG, V57, P1476, DOI 10.1109/TBME.2010.2040278
   Masala E., 2010, IEEE INT WORKSH MULT, P1
   Mohaghegh H., 2015, 37 ANN IEEE INT C EN
   Setton E, 2005, IEEE WIREL COMMUN, V12, P59, DOI 10.1109/MWC.2005.1497859
   Shen ZK, 2005, IEEE T WIREL COMMUN, V4, P2726, DOI 10.1109/TWC.2005.858010
   Sun QB, 2008, P IEEE, V96, P97, DOI 10.1109/JPROC.2007.909926
   Tan AS, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/632545
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   van Beurden MHPH, 2012, 3D RES, V3, DOI 10.1007/3DRes.01(2012)3
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang YJ, 2013, IEEE T NETW SERV MAN, V10, P245, DOI 10.1109/TNSM.2013.051313.120343
   Welch G, 2011, VIRTUAL REALITIES: DAGSTUHL SEMINAR 2008, P139, DOI 10.1007/978-3-211-99178-7_8
   Zamani S., 2016, IEEE WORKSH STAT SIG, P1
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
   Zhang Z., 2007, IEEE T CIRCUITS SYST, V17, P1661
   Zhao D, 2016, INT J COMPUT ASS RAD, V11, P207, DOI 10.1007/s11548-015-1289-8
   Zhao PH, 2016, SIGNAL PROCESS-IMAGE, V40, P36, DOI 10.1016/j.image.2015.11.005
   Zhu L, 2011, 2011 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION AND INDUSTRIAL APPLICATION (ICIA2011), VOL III, P1
   Zhu XL, 2016, IEEE T INF FOREN SEC, V11, P141, DOI 10.1109/TIFS.2015.2481366
NR 32
TC 4
Z9 4
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 208
EP 218
DI 10.1016/j.jvcir.2017.04.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500019
DA 2024-07-18
ER

PT J
AU Lim, J
   Heo, M
   Lee, C
   Kim, CS
AF Lim, Jaemoon
   Heo, Minhyeok
   Lee, Chul
   Kim, Chang-Su
TI Contrast enhancement of noisy low-light images based on
   structure-texture-noise decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image enhancement; Contrast enhancement; Structure-texture-noise
   decomposition; Noise removal; Denoising; Texture retrieval; Texture
   enhancement
ID QUALITY ASSESSMENT; DARK; STATISTICS; ALGORITHMS; REMOVAL; DCT
AB A noisy low-light image enhancement algorithm based on structure-texture-noise (STN) decomposition is proposed in this work. We split an input image into structure, texture, and noise components, and enhance the structure and texture components separately. More specifically, we first enhance the contrast of the structure image, by extending a 2D-histogram-based image enhancement scheme based on the characteristics of low-light images. Then, we reconstruct the texture image by retrieving residual texture components from the noise image and enhance it by exploiting the perceptual response of the human visual system (HVS). Experimental results on both synthetic and real-world images demonstrate that the proposed STN algorithm sharpens the texture and enhances the contrast more effectively than conventional algorithms, while providing robust performance under various noise and illumination conditions. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Lim, Jaemoon] Samsung Elect Co Ltd, Suwon, South Korea.
   [Heo, Minhyeok; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Lee, Chul] Pukyong Natl Univ, Dept Comp Engn, Busan, South Korea.
C3 Samsung; Samsung Electronics; Korea University; Pukyong National
   University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM jaemoon.lim@samsung.com; mhheo@mcl.korea.ac.kr; chullee@pknu.ac.kr;
   changsukim@korea.ac.kr
RI Lee, Chul/W-3762-2019
OI Lee, Chul/0000-0001-9329-7365; Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [NRF-2015R1A2A1A10055037]; MSIP, Korea, under the Information Technology
   Research Center (ITRC) [IITP-2016-R2720-16-0007]
FX This work was supported partly by the National Research Foundation of
   Korea (NRF) grant funded by the Korea government (MSIP) (No.
   NRF-2015R1A2A1A10055037), and partly by the MSIP, Korea, under the
   Information Technology Research Center (ITRC) support program
   (IITP-2016-R2720-16-0007), supervised by the Institute for Information &
   communications Technology Promotion (IITP).
CR Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], P APSIPA ASC
   [Anonymous], IEEE T CONSUM ELECT
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chen ZY, 2006, IEEE T IMAGE PROCESS, V15, P2290, DOI 10.1109/TIP.2006.875204
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Davis L.S., 1975, Comput. Graph. Image Process, V4, P248, DOI DOI 10.1016/0146-664X(75)90012-X
   Dong XC, 2011, INT C PAR DISTRIB SY, P9, DOI 10.1109/ICPADS.2011.115
   Fadili MJ, 2010, P IEEE, V98, P983, DOI 10.1109/JPROC.2009.2024776
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Fu HY, 2012, INT C PATT RECOG, P3656
   Gilles J, 2007, J MATH IMAGING VIS, V28, P285, DOI 10.1007/s10851-007-0020-y
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jha RK, 2012, IET IMAGE PROCESS, V6, P230, DOI 10.1049/iet-ipr.2010.0392
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Lee C, 2014, IEEE T CIRC SYST VID, V24, P576, DOI 10.1109/TCSVT.2013.2276154
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Lim J, 2015, IEEE IMAGE PROC, P4131, DOI 10.1109/ICIP.2015.7351583
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Loza A, 2013, DIGIT SIGNAL PROCESS, V23, P1856, DOI 10.1016/j.dsp.2013.06.002
   Lu HM, 2016, 2016 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C), P34, DOI 10.1109/IS3C.2016.19
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Malm H., 2007, PROC IEEE ICCV, P1
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Rivera AR, 2012, IEEE T IMAGE PROCESS, V21, P3967, DOI 10.1109/TIP.2012.2198667
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad Y, 2003, ITERATIVE METHODS SP, DOI DOI 10.1137/1.9780898718003
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tsai PS, 2009, IEEE T CIRC SYST VID, V19, P574, DOI 10.1109/TCSVT.2009.2014022
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Xu Q, 2010, IEEE IMAGE PROC, P1185, DOI 10.1109/ICIP.2010.5651838
   Zhang XD, 2012, INT C PATT RECOG, P2034
NR 44
TC 34
Z9 37
U1 1
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 107
EP 121
DI 10.1016/j.jvcir.2017.02.016
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100010
DA 2024-07-18
ER

PT J
AU Xu, DW
   Wang, RD
   Zhu, YN
AF Xu, Dawen
   Wang, Rangding
   Zhu, Yani
TI Tunable data hiding in partially encrypted H.264/AVC videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Encrypted domain; H.264/AVC; Context adaptive binary
   arithmetic coding; (CABAC); Bin-string substitution
ID MANY-CORE PROCESSORS; WATERMARKING SCHEME; PARALLEL FRAMEWORK; IMAGES;
   COMPRESSION; STANDARD; DOMAIN; ROBUST
AB An improved scheme of data hiding directly in partially encrypted H.264/AVC videos using CABAC bin-string substitution is proposed. The encryption of Luma prediction modes is designed in addition to residual encryption and motion vector encryption in order to significantly improve the structural deterioration. Both the bin-strings of abs_level and the bin-strings of abs_MVD are exploited for data hiding to provide a higher flexibility for users to select the tradeoff between hiding capacity and video quality. Since the data embedding is done in the encrypted domain, the proposed scheme preserves the confidentiality of video content. With an encrypted video containing the hidden data, the receiver can accomplish data extraction directly in encrypted domain using only the data-hiding key, or obtain a decrypted video similar to the original version using only the cryptographic key. Experimental results have demonstrated that the proposed scheme can achieve better scrambling performance and higher embedding capacity. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Xu, Dawen] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Wang, Rangding] Ningbo Univ, CKC Software Lab, Ningbo 315211, Zhejiang, Peoples R China.
   [Zhu, Yani] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Ningbo University of Technology; Ningbo University; Zhejiang University
   of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM dawenxu@126.com
RI xu, dawen/ABF-5343-2021
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [61301247, 61672302];
   Zhejiang Provincial Natural Science Foundation of China [LY17F020013,
   LZ15F020002]; Public Welfare Technology Application Research Project of
   Zhejiang Province [2015C33237]
FX This work is supported by the National Natural Science Foundation of
   China (61301247 and 61672302), Zhejiang Provincial Natural Science
   Foundation of China (LY17F020013 and LZ15F020002), and Public Welfare
   Technology Application Research Project of Zhejiang Province
   (2015C33237).
CR [Anonymous], 2003, ADV VID COD GEN AUD
   Boyadjis B., 2016, IEEE T CIRC SYST VID
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Stütz T, 2012, IEEE T CIRC SYST VID, V22, P325, DOI 10.1109/TCSVT.2011.2162290
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Nguyen TS, 2016, SIGNAL PROCESS-IMAGE, V44, P84, DOI 10.1016/j.image.2016.03.010
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Xu DW, 2016, J VIS COMMUN IMAGE R, V36, P229, DOI 10.1016/j.jvcir.2016.02.002
   Xu DW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033028
   Xu DW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053022
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yao YZ, 2016, SIGNAL PROCESS, V128, P531, DOI 10.1016/j.sigpro.2016.05.004
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhao B, 2010, INFORM SCIENCES, V180, P4672, DOI 10.1016/j.ins.2010.08.003
   Zheng P. J., 2012, 14 INF HID C BERK CA, P1
   Zhou L, 2013, IEEE T INF FOREN SEC, V8, P1947, DOI 10.1109/TIFS.2013.2286456
NR 31
TC 23
Z9 23
U1 0
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 34
EP 45
DI 10.1016/j.jvcir.2017.02.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100004
DA 2024-07-18
ER

PT J
AU Huang, C
   Li, HL
   Li, W
   Wu, QB
   Xu, LF
AF Huang, Chao
   Li, Hongliang
   Li, Wei
   Wu, Qingbo
   Xu, Linfeng
TI Store classification using Text-Exemplar-Similarity and
   Hypotheses-Weighted-CNN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Store classification; Deep convolutional network; Hypotheses-weighted
   CNN; Image classification; Text-Exemplar-Similarity
ID REPRESENTATION; FEATURES; SCENE
AB Store classification is a challenging task due to the large variation of view, scale, illumination and occlusion. To efficiently distinguish different stores, we introduce two features: Text-Exemplar-Similarity and Hypotheses-Weighted-CNN. For the first feature, the similarity with the discriminative characters is used to represent the text information. For the second feature, we first generate a set of object hypotheses. Then, we introduce two priors: edge boundary and repeatness prior to give a higher weight to the hypotheses enclosing the object. After the generation of two features, a simple and efficient optimization method is used to find the best weight for each feature. Extensive experiments are evaluated to verify the superiority of the proposed method. We built a new 9-class store dataset composed of photos and images from the internet. The experiments show that our method is nearly 10% higher than the state-of-art methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Huang, Chao; Li, Hongliang; Li, Wei; Wu, Qingbo; Xu, Linfeng] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Huang, C (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM huangchao_uestc@aliyun.com; hlli@uestc.edu.cn; weili.cv@gmail.com;
   wqb.uestc@gmail.com; lfxu@uestc.edu.cn
RI Huang, Chao/L-1445-2019; Xu, Linfeng/HME-1913-2023; Huang,
   Chao/JJD-0553-2023; Wu, Qingbo/AAF-6872-2019
OI Xu, Linfeng/0000-0002-9934-0958; Huang, Chao/0000-0001-8775-3192; Wu,
   Qingbo/0000-0003-2936-6340; Li, Wei/0000-0002-8278-1765
FU National Natural Science Foundation of China [61525102, 61601102,
   61502084]
FX This work was supported in part by National Natural Science Foundation
   of China (Nos. 61525102, 61601102, 61502084).
CR [Anonymous], J VISUAL COMMUN IMAG
   [Anonymous], TECH REP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2013, Proceedings of the 21st ACM International Conference on Multimedia
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], ARXIV13101531
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], ARXIV14065726
   Breiman L., 2001, Mach. Learn., V45, P5
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Dong YS, 2015, ACM T INTEL SYST TEC, V7, DOI 10.1145/2738050
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Jiang XH, 2016, NEUROCOMPUTING, V185, P163, DOI 10.1016/j.neucom.2015.12.042
   Ke Y., 2004, P 2004 IEEE COMP SOC, V2, pII
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li L. J., 2007, IEEE INT C COMPUTER, P1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Movshovitz-Attias Y, 2015, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2015.7298778
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Shi CZ, 2013, PROC CVPR IEEE, P2961, DOI 10.1109/CVPR.2013.381
   Shi JH, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P191, DOI 10.1109/ChinaSIP.2015.7230389
   Song TC, 2013, PATTERN RECOGN LETT, V34, P1323, DOI 10.1016/j.patrec.2013.04.020
   Song TC, 2013, IEEE SIGNAL PROC LET, V20, P59, DOI 10.1109/LSP.2012.2229273
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Wang C, 2014, LECT NOTES COMPUT SC, V8694, P431, DOI 10.1007/978-3-319-10599-4_28
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Zamir Amir Roshan., 2013, ACM Multimedia, P665
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   Zhu Q., 2006, Proceedings of ACM MM'06, ACM, P211
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 50
TC 2
Z9 3
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 21
EP 28
DI 10.1016/j.jvcir.2017.01.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600002
DA 2024-07-18
ER

PT J
AU Cui, ZX
   Fan, QB
   Dong, YC
   Liu, T
AF Cui, Zhuo-Xu
   Fan, Qibin
   Dong, Yichuan
   Liu, Tong
TI A nonconvex nonsmooth regularization method with structure tensor total
   variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Nonconvex nonsmooth regularization; Structure tensor; Image restoration
   and reconstruction; Alternating minimization methods
ID TOTAL VARIATION MINIMIZATION; VECTOR-VALUED IMAGES; NORM REGULARIZATION;
   MATRIX COMPLETION; RECOVERY; RECONSTRUCTION; RESTORATION; ALGORITHM;
   PDES
AB In this paper, a novel regularization method for image restoration and reconstruction is introduced which is accomplished by adopting a nonconvex nonsmooth penalty that depends on the eigenvalues of structure tensor of the underlying image. At first, an alternating minimization scheme is developed in which the problem can be decomposed into three subproblems, two of them are convex and the remaining one is smooth. Then, the convergence of the sequence which generate by the alternating minimization algorithm is proved. Finally, the efficient performance of the proposed method is demonstrated through experimental results for both grayscale and vector-value images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Cui, Zhuo-Xu; Fan, Qibin; Dong, Yichuan; Liu, Tong] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Fan, QB (corresponding author), Wuhan Univ, Sch Math & Stat, Wuhan 430072, Peoples R China.
EM zhuoxucui@whu.edu.cn; qbfan@whu.edu.cn; ycdong@whu.edu.cn;
   tongliu@whu.edu.cn
OI Cui, Zhuo-Xu/0000-0001-9283-881X
FU National Science Foundation of China [61179039]; National Key Basic
   Research Development Program (973 Program) of China [2011CB707100]
FX This work is supported by the National Science Foundation of China under
   Grant 61179039 and the National Key Basic Research Development Program
   (973 Program) of China under Grant 2011CB707100.
CR [Anonymous], 1987, PROC ISPRS INTERCOMM
   [Anonymous], J AM STAT ASS
   Attouch H, 2010, MATH OPER RES, V35, P438, DOI 10.1287/moor.1100.0449
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Cui Z.-X., ARXIV160500479
   DEMOMENT G, 1989, IEEE T ACOUST SPEECH, V37, P2024, DOI 10.1109/29.45551
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Estellers V, 2015, IEEE T IMAGE PROCESS, V24, P1777, DOI 10.1109/TIP.2015.2409562
   FRANK IE, 1993, TECHNOMETRICS, V35, P109, DOI 10.2307/1269656
   Ghadimi S, 2013, SIAM J OPTIMIZ, V23, P2341, DOI 10.1137/120880811
   Hoelen CGA, 1998, OPT LETT, V23, P648, DOI 10.1364/OL.23.000648
   Hu Y, 2013, IEEE T PATTERN ANAL, V35, P2117, DOI 10.1109/TPAMI.2012.271
   Ito K., 2015, INVERSE PROBLEMS TIK, P5
   Jin ZF, 2016, J SCI COMPUT, V66, P849, DOI 10.1007/s10915-015-0045-0
   Lefkimmiatis S, 2015, SIAM J IMAGING SCI, V8, P1090, DOI 10.1137/14098154X
   Lefkimmiatis S, 2013, IEEE T IMAGE PROCESS, V22, P1873, DOI 10.1109/TIP.2013.2237919
   Nikolova M, 2013, SIAM J SCI COMPUT, V35, pA397, DOI 10.1137/10080172X
   Nikolova M, 2010, IEEE T IMAGE PROCESS, V19, P3073, DOI 10.1109/TIP.2010.2052275
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scherzer O, 2009, APPL MATH SCI, V167, P27
   SNYDER DL, 1993, J OPT SOC AM A, V10, P1014, DOI 10.1364/JOSAA.10.001014
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Tao DP, 2013, IEEE T MULTIMEDIA, V15, P833, DOI 10.1109/TMM.2013.2238909
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperlé D, 2002, IEEE SIGNAL PROC MAG, V19, P16, DOI 10.1109/MSP.2002.1028349
   Vogel C. R., 2002, FRONTIERS APPL MATH
   Xiao J, 2015, IEEE T IMAGE PROCESS, V24, P1587, DOI 10.1109/TIP.2015.2401430
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Zhang CH, 2010, ANN STAT, V38, P894, DOI 10.1214/09-AOS729
NR 36
TC 3
Z9 3
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 30
EP 40
DI 10.1016/j.jvcir.2016.12.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400004
OA Bronze
DA 2024-07-18
ER

PT J
AU Chen, ZH
   Dai, C
   Jiang, L
   Sheng, B
   Zhang, J
   Lin, WY
   Yuan, YB
AF Chen, Zhihua
   Dai, Chao
   Jiang, Lei
   Sheng, Bin
   Zhang, Jing
   Lin, Weiyao
   Yuan, Yubo
TI Structure-aware image inpainting using patch scale optimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Texture synthesis; Local structure multiplier; Patch
   scale optimization
ID COMPLETION; FRAMEWORK; INDEX
AB Image inpainting is widely used in many image processing applications such as image stitching, image editing and object removal. The main challenge stems from producing visually plausible results after reconstruction. Most of the image inpainting algorithms cannot maintain structure continuity and texture consistency precisely. To address this problem, we propose a robust exemplar-based inpainting algorithm. Firstly, we present local structure multiplier to contain sufficient structure information in the priority function which ensures the structure continuity. Secondly, we combine color feature and space distance between two patches to search for the optimized patch to avoid texture inconsistency. At last, we calculate the average pixel difference between two patches under each candidate scale, we select the scale which the minimal average pixel difference is to be the optimized scale. We copy the target patch with the optimized patch. Extensive experiments show the effectiveness of the proposed method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chen, Zhihua; Dai, Chao; Jiang, Lei; Zhang, Jing; Yuan, Yubo] E China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.
   [Sheng, Bin; Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 East China University of Science & Technology; Shanghai Jiao Tong
   University
RP Yuan, YB (corresponding author), E China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.; Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM shengbin@cs.sjtu.edu.cn; ybyuan@ecust.edu.cn
RI lin, yuxi/HKF-6212-2023; yuan, yubo/HSG-3147-2023; Yuan,
   Yubo/O-7235-2016
OI Lin, Weiyao/0000-0001-8307-7107; Yuan, Yubo/0000-0002-7577-3257
FU National Natural Science Foundation of China [61572316, 61133009,
   61370714, 61402174]; National High-tech R&D Program of China (863
   Program) [2015AA015904]; Science and Technology Commission of Shanghai
   Municipality Program [13511505000]; Interdisciplinary Program of
   Shanghai Jiao Tong University [14JCY10]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments. The work is supported by the
   National Natural Science Foundation of China (Nos. 61572316, 61133009,
   61370714, 61402174), National High-tech R&D Program of China (863
   Program) (Grant No. 2015AA015904), the Science and Technology Commission
   of Shanghai Municipality Program (No. 13511505000), the
   Interdisciplinary Program of Shanghai Jiao Tong University (No.
   14JCY10).
CR Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bornemann F, 2007, J MATH IMAGING VIS, V28, P259, DOI 10.1007/s10851-007-0017-6
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Chan RH, 2009, IEEE T IMAGE PROCESS, V18, P1467, DOI 10.1109/TIP.2009.2019806
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Darabi S., 2012, ACM T GRAPHIC, V32, P8201
   Dobrosotskaya JA, 2008, IEEE T IMAGE PROCESS, V17, P657, DOI 10.1109/TIP.2008.919367
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Gepshtein S, 2013, IEEE T IMAGE PROCESS, V22, P2983, DOI 10.1109/TIP.2013.2237916
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P539, DOI 10.1109/TIP.2005.863057
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P555, DOI 10.1109/TIP.2005.863055
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Hesabi S., 2012, P 16 CSI INT S ART I
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Komodakis N, 2007, IEEE T IMAGE PROCESS, V16, P2649, DOI 10.1109/TIP.2007.906269
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3401, DOI 10.1109/ICIP.2011.6116441
   Le Meur O, 2013, IEEE T IMAGE PROCESS, V22, P3779, DOI 10.1109/TIP.2013.2261308
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Li F, 2014, IEEE T IMAGE PROCESS, V23, P4242, DOI 10.1109/TIP.2014.2346030
   Li F, 2011, J VIS COMMUN IMAGE R, V22, P529, DOI 10.1016/j.jvcir.2011.06.006
   Li YR, 2013, IEEE T IMAGE PROCESS, V22, P752, DOI 10.1109/TIP.2012.2222896
   Liang L., 2001, MICROSOFT RES
   Liu YQ, 2013, IEEE T IMAGE PROCESS, V22, P1699, DOI 10.1109/TIP.2012.2218828
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Rares A, 2005, IEEE T IMAGE PROCESS, V14, P1454, DOI 10.1109/TIP.2005.854466
   Tang CW, 2013, J VIS COMMUN IMAGE R, V24, P1115, DOI 10.1016/j.jvcir.2013.07.010
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zhang J, 2014, IEEE T CIRC SYST VID, V24, P915, DOI 10.1109/TCSVT.2014.2302380
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
NR 37
TC 20
Z9 22
U1 0
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 312
EP 323
DI 10.1016/j.jvcir.2016.06.029
PN A
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500027
DA 2024-07-18
ER

PT J
AU Li, W
   Huang, C
   Luo, B
   Meng, FM
   Song, TC
   Shi, HC
AF Li, Wei
   Huang, Chao
   Luo, Bing
   Meng, Fanman
   Song, Tiecheng
   Shi, Hengcan
TI Person re-identification based on multi-region-set ensembles
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Video surveillance; Feature representation
ID PARALLEL FRAMEWORK; HEVC; DECISION
AB Person re-identification is an important topic in video surveillance. We present a new feature representation for person re-identification based on multi-region-set ensembles (MRSE) by combining some semantic regions with their contextual information. The motivation of this paper is that people can recognize and identify whether it's the same person by one or several local regions of the appearance. Our approach is divided into three steps: firstly, we segment the person into some semantic regions such as "hair", "face", "up-cloth" (upper clothes) and "lo-cloth" (lower clothes). After getting these regions, we form multiple sets of different combination by selecting a few regions and concatenating the features of them. We then combine the distance of all multiple sets for computing the similarity of a query-gallery image pair. Finally, we achieve higher rank-1 recognition rate and competitive performance compared with the state-of-the-art on iLIDS, VIPeR, CAVIAR4REID, 3DPeS four challenging datasets. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Li, Wei; Huang, Chao; Luo, Bing; Meng, Fanman; Song, Tiecheng; Shi, Hengcan] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Li, W (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM weili.cv@gmail.com
RI Huang, Chao/L-1445-2019; Huang, Chao/JJD-0553-2023
OI Huang, Chao/0000-0001-8775-3192; Li, Wei/0000-0002-8278-1765
FU National Natural Science Foundation of China [61271289, 61502084];
   program for Science and Technology Innovative Research Team for Young
   Scholars in Sichuan Province, China [2014TD0006]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61271289, 61502084), and by the program for Science and
   Technology Innovative Research Team for Young Scholars in Sichuan
   Province, China (No. 2014TD0006).
CR [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], 2013, IEEE C COMP VIS PATT
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bhuiyan A., 2014, COMPUTER VISION, P147
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong SG, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6296-4_1
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hirzer M, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P203, DOI 10.1109/AVSS.2012.55
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li HL, 2014, IEEE T IMAGE PROCESS, V23, P3545, DOI 10.1109/TIP.2014.2330759
   Li HL, 2014, IEEE T CIRC SYST VID, V24, P789, DOI 10.1109/TCSVT.2013.2280851
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Liu Z, 2015, NEUROCOMPUTING, V168, P1144, DOI 10.1016/j.neucom.2015.05.008
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329
   Ma B., 2014, Asian Conference on Computer Vision, P505
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Satta R., ARXIV13075748
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Xu Yuanlu, 2013, INT C COMP VIS ICCV
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yu-Chen Chang, 2012, 2012 International Symposium on Intelligent Signal Processing and Communications Systems (ISPACS 2012), P1, DOI 10.1109/ISPACS.2012.6473442
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 37
TC 4
Z9 4
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 67
EP 75
DI 10.1016/j.jvcir.2016.06.009
PN A
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500008
DA 2024-07-18
ER

PT J
AU Wang, B
   Wang, CG
   Huang, JF
AF Wang, Bin
   Wang, Cungang
   Huang, Jifeng
TI Multiple clusters parts-based sparse representation for single example
   face identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Parts-based; Single example; Face identification; Sparse representation
ID PARALLEL FRAMEWORK; RECOGNITION; IMAGE; SAMPLE
AB While great progress has been made on face identification, it is still highly challenging under real-world conditions, e.g., illumination variation and occlusion with insufficient labeled examples. In this paper, we proposed a probabilistic generative model and a face identification approach based on the model to attack the above challenge. The proposed model learns multiple clusters parts-based representation built upon three concepts: part, component and cluster. Face parts, represented by the linear combination of a set of components, refer to regions like eye and mouth. Cluster refers to a group of faces with similar appearance. A face is the summation of all parts. Based upon the learned face representation, we derived a similarity measure over faces for single example face identification. The proposed approach is able to fully exploit unlabeled data and face representation can provide informative features. We validate the effectiveness of the proposed approach through a set of experiments. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wang, Bin; Huang, Jifeng] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai, Peoples R China.
   [Wang, Cungang] Liaocheng Univ, Sch Comp Sci, Liaocheng 252400, Peoples R China.
C3 Shanghai Normal University; Liaocheng University
RP Wang, CG (corresponding author), Liaocheng Univ, Sch Comp Sci, Liaocheng 252400, Peoples R China.
EM cungwang@163.com
FU National Natural Science Foundation of China [61503251]; General
   Scientific Research Project of Shanghai Normal University [SK201510];
   Key Project of Scientific Research and Innovation of Shanghai Municipal
   Education Commission [1422125]
FX This work is supported by National Natural Science Foundation of China
   (Grant No. 61503251), General Scientific Research Project of Shanghai
   Normal University (Grant No. SK201510) and Key Project of Scientific
   Research and Innovation of Shanghai Municipal Education Commission
   (Grant No. 1422125).
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], INT C ART INT STAT
   [Anonymous], EUR C MACH LEARN
   [Anonymous], IEEE WORKSH FAC PROC
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], CBCL187
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Ganchev K, 2010, J MACH LEARN RES, V11, P2001
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lu JW, 2011, IEEE I CONF COMP VIS, P1943, DOI 10.1109/ICCV.2011.6126464
   Martinez A.M., 1998, AR FACE DATABASE
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   Ross DA, 2006, J MACH LEARN RES, V7, P2369
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang B, 2013, IEEE IMAGE PROC, P2587, DOI 10.1109/ICIP.2013.6738533
   Wang B, 2014, NEUROCOMPUTING, V145, P495, DOI 10.1016/j.neucom.2014.05.004
   Wang B, 2013, KSII T INTERNET INF, V7, P1252, DOI 10.3837/tiis.2013.05.018
   Wang B, 2013, KSII T INTERNET INF, V7, P522, DOI 10.3837/tiis.2013.03.007
   Weber M., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P20, DOI 10.1109/AFGR.2000.840607
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53
   Zhang Y., 2008, IEEE C COMPUTER VISI, P1
   Zhang Y, 2011, IEEE T NEURAL NETWOR, V22, P1207, DOI 10.1109/TNN.2011.2156808
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhao X, 2013, IEEE T INF FOREN SEC, V8, P1654, DOI 10.1109/TIFS.2013.2263498
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 43
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 237
EP 250
DI 10.1016/j.jvcir.2016.06.019
PN A
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500022
DA 2024-07-18
ER

PT J
AU Zhang, GQ
   Sun, HJ
   Ji, ZX
   Xia, GY
   Feng, L
   Sun, QS
AF Zhang, Guoqing
   Sun, Huaijiang
   Ji, Zexuan
   Xia, Guiyu
   Feng, Lei
   Sun, Quansen
TI Kernel dictionary learning based discriminant analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kernel method; Sparse representation; Dictionary learning; Feature
   learning
ID SPARSE REPRESENTATION; FACE RECOGNITION; K-SVD; IMAGE; EIGENFACES
AB Sparse representation based classification (SRC) has been successfully applied in many applications. But how to determine appropriate features that can best work with SRC remains an open question. Dictionary learning (DL) has played an import role in the success of sparse representation, while SRC treats the entire training set as a structured dictionary. In addition, as a linear algorithm, SRC cannot handle the data with highly nonlinear distribution. Motivated by these concerns, in this paper, we propose a novel feature learning method (termed kernel dictionary learning based discriminant analysis, KDL-DA). The proposed algorithm aims at learning a projection matrix and a kernel dictionary simultaneously such that in the reduced space the sparse representation of the data can be easily obtained, and the reconstruction residual can be further reduced. Thus, KDL-DA can achieve better performances in the projected space. Extensive experimental results show that our method outperforms many state-of-the-art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Guoqing; Sun, Huaijiang; Ji, Zexuan; Xia, Guiyu; Feng, Lei; Sun, Quansen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Sun, HJ (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM xiayang14551@163.com; sunhuaijiang@njust.edu.cn
RI zhang, guoqing/GXG-4800-2022
FU National Science Foundation of China [61273251, 61401209]; Natural
   Science Foundation of Jiangsu Province, China [BK20140790]; China
   Postdoctoral Science Foundation [2014T70525, 2013M531364]
FX This work was supported by the National Science Foundation of China
   under Grants 61273251 and 61401209, in part by the Natural Science
   Foundation of Jiangsu Province, China under Grant BK20140790, and in
   part by China Postdoctoral Science Foundation under Grants 2014T70525
   and 2013M531364.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2013, International Conference on Machine Learning
   [Anonymous], 2014, P SIAM INT C DAT MIN
   [Anonymous], 1998, 24 CVC U AUT BARC
   [Anonymous], 7694 CIT
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2008.4587408
   [Anonymous], 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587841
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Engan K, 1999, INT CONF ACOUST SPEE, P2443, DOI 10.1109/ICASSP.1999.760624
   Feng ZZ, 2013, PATTERN RECOGN, V46, P2134, DOI 10.1016/j.patcog.2013.01.016
   Gao SH, 2014, IEEE T IMAGE PROCESS, V23, P623, DOI 10.1109/TIP.2013.2290593
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gu SH, 2014, ADV NEUR IN, V27
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Nguyen HV, 2013, IEEE T IMAGE PROCESS, V22, P5123, DOI 10.1109/TIP.2013.2282078
   Nguyen HV, 2012, INT CONF ACOUST SPEE, P2021, DOI 10.1109/ICASSP.2012.6288305
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Huang K., 2006, Advances in neural information processing systems, V19, P609, DOI DOI 10.7551/MITPRESS/7503.001.0001
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Lai ZH, 2014, IEEE T NEUR NET LEAR, V25, P1779, DOI 10.1109/TNNLS.2013.2295717
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Sun YB, 2014, IEEE T IMAGE PROCESS, V23, P3816, DOI 10.1109/TIP.2014.2331760
   Thiagarajan JJ, 2014, IEEE T IMAGE PROCESS, V23, P2905, DOI 10.1109/TIP.2014.2322938
   Tropp JA, 2010, P IEEE, V98, P948, DOI 10.1109/JPROC.2010.2044010
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wei L, 2014, KNOWL-BASED SYST, V70, P212, DOI 10.1016/j.knosys.2014.06.027
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie GS, 2015, IEEE I CONF COMP VIS, P1179, DOI 10.1109/ICCV.2015.140
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Zang F, 2011, NEUROCOMPUTING, V74, P2176, DOI 10.1016/j.neucom.2011.02.012
   Zhang GQ, 2016, PATTERN RECOGN, V60, P613, DOI 10.1016/j.patcog.2016.06.012
   Zhang GQ, 2016, NEUROCOMPUTING, V171, P1193, DOI 10.1016/j.neucom.2015.07.048
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou TY, 2013, IEEE T IMAGE PROCESS, V22, P244, DOI 10.1109/TIP.2012.2202678
NR 68
TC 11
Z9 13
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 470
EP 484
DI 10.1016/j.jvcir.2016.07.015
PN B
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600007
OA Bronze
DA 2024-07-18
ER

PT J
AU Jafar, IF
   Darabkh, KA
   Saifan, RR
AF Jafar, Iyad F.
   Darabkh, Khalid A.
   Saifan, Ramzi R.
TI SARDH: A novel sharpening-aware reversible data hiding algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image contrast; Sharpening; Embedding capacity
ID ENHANCEMENT; IMAGES; REPLACEMENT
AB Reversible data hiding (RDH) algorithms allow data protection and exact recovery of the original cover image upon data extraction. Most of RDH algorithms attempt to embed data while maintaining high peak signal-to-noise ratio. However, it has been deemed recently that some applications may demand improving the image contrast while embedding data. Additionally, stego images with better contrast could be less attractive to attacker, given the fact they have no idea about the original cover image. In this paper, we propose a sharpening-aware RDH (SARDH) algorithm that is capable of embedding significant amount of data in addition to sharpening the image. Experimental results proved the ability of SARDH algorithm in embedding large payloads and providing sharper stego images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Jafar, Iyad F.; Darabkh, Khalid A.; Saifan, Ramzi R.] Univ Jordan, Dept Comp Engn, Amman 11942, Jordan.
C3 University of Jordan
RP Jafar, IF (corresponding author), Univ Jordan, Dept Comp Engn, Amman 11942, Jordan.
EM Iyad.jafar@ju.edu.jo
RI Saifan, Ramzi R/Q-3675-2017
OI Darabkh, Khalid/0000-0002-0362-1975
CR Alattar AM, 2003, IEEE IMAGE PROC, P501
   Beghdadi A., 2004, P IEEE 1 INT S CONTR
   Chiang-Lung Liu, 2012, 2012 International Symposium on Computer, Consumer and Control (IS3C 2012), P448, DOI 10.1109/IS3C.2012.119
   Darabkh K. A., 2014, J SOFTWARE ENG APPL, V7, P859
   Darabkh KA, 2015, INF TECHNOL CONTROL, V44, P315, DOI 10.5755/j01.itc.44.3.8949
   Darabkh KA, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1182, DOI 10.1109/MIPRO.2014.6859747
   Fallahpour M, 2007, IEICE ELECTRON EXPR, V4, P205, DOI 10.1587/elex.4.205
   Fillatre L, 2012, IEEE T SIGNAL PROCES, V60, P556, DOI 10.1109/TSP.2011.2174231
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   GORDON R, 1984, APPL OPTICS, V23, P560, DOI 10.1364/AO.23.000560
   Hiary S., 2015, MULTIMEDIA IN PRESS
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jaarah E., 2015, P 2015 IEEE JORD C A
   Jafar I., 2007, P INT C IM PROC COMP
   Jafar Iyad F., 2011, IAENG International Journal of Computer Science, V38, P192
   Jafar I, 2008, INTEGR COMPUT-AID E, V15, P131
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Jafar IF, 2016, COMPUT J, V59, P423, DOI 10.1093/comjnl/bxv067
   Jafar IF, 2014, PROC SPIE, V9159, DOI 10.1117/12.2064524
   Jafar IF, 2013, IEEE T IMAGE PROCESS, V22, P1223, DOI 10.1109/TIP.2012.2228496
   Jafar IF, 2012, COMPUT J, V55, P1041, DOI 10.1093/comjnl/bxr120
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Liu SH, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3990
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Matz SC, 2006, IEEE T IMAGE PROCESS, V15, P900, DOI 10.1109/TIP.2005.863935
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Raji A, 1998, PATTERN RECOGN LETT, V19, P1207, DOI 10.1016/S0167-8655(98)00109-3
   Salamon D., 2007, DATA COMPRESSION COM
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Yang C. Y., 2012, J INFORM HIDING MULT, V3, P142
   Yip SK, 2005, IEEE IMAGE PROC, P409
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
   Zhu X, 2010, IEEE T IMAGE PROCESS, V19, P3116, DOI 10.1109/TIP.2010.2052820
NR 42
TC 11
Z9 11
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 239
EP 252
DI 10.1016/j.jvcir.2016.06.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900023
DA 2024-07-18
ER

PT J
AU Lu, HM
   Li, YJ
   Xu, X
   Li, JR
   Liu, ZF
   Li, X
   Yang, JM
   Serikawa, S
AF Lu, Huimin
   Li, Yujie
   Xu, Xing
   Li, Jianru
   Liu, Zhifei
   Li, Xin
   Yang, Jianmin
   Serikawa, Seiichi
TI Underwater image enhancement method using weighted guided trigonometric
   filtering and artificial light correction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep-sea imaging; Inherent optical property; Image enhancement
ID VISIBILITY
AB This paper describes a novel method for enhancing optical images using a weighted guided trigonometric filter and the camera's spectral properties in turbid water. Absorption, scattering, and artificial lighting are three major distortion issues in underwater optical imaging. Absorption permanently removes photons from the imaging path. Scattering is caused by large suspended particles found in turbid water, which redirect the angle of the photon path. Artificial lighting results in footprint effects, which cause vignetting distortion in the captured image. Our contributions include a novel deep-sea imaging method that compensates for the attenuation discrepancy along the propagation path, and an effective underwater scene enhancement scheme. The recovered images are characterized by a reduced noise level, better exposure of dark regions, and improved global contrast such that the finest details and edges are significantly enhanced. Our experiments showed that the average Peak Signal to Noise Ratio (PSNR) improved by at least 1 dB when compared with state-of-the-art-methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lu, Huimin; Serikawa, Seiichi] Kyushu Inst Technol, Dept Elect & Elect Engn, Kitakyushu, Fukuoka 8048550, Japan.
   [Li, Jianru; Liu, Zhifei] Tongji Univ, State Key Lab Marine Geol, Shanghai 200092, Peoples R China.
   [Lu, Huimin; Li, Xin; Yang, Jianmin] Shanghai Jiao Tong Univ, State Key Lab Ocean Engn, Shanghai 200240, Peoples R China.
   [Li, Yujie] Yangzhou Univ, Sch Informat Engn, Yangzhou 225127, Jiangsu, Peoples R China.
   [Xu, Xing] Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China.
C3 Kyushu Institute of Technology; Tongji University; Shanghai Jiao Tong
   University; Yangzhou University; University of Electronic Science &
   Technology of China
RP Lu, HM (corresponding author), Kyushu Inst Technol, Dept Elect & Elect Engn, Kitakyushu, Fukuoka 8048550, Japan.; Lu, HM (corresponding author), Shanghai Jiao Tong Univ, State Key Lab Ocean Engn, Shanghai 200240, Peoples R China.
EM luhuimin@ieee.org; liyujie@yzu.edu.cn
RI Liu, Zhifei/L-8817-2019; Li, Yujie/AAH-3298-2019; Li,
   YuJie/HGT-8657-2022; Liu, Liu/JXM-8208-2024; Li, YuJie/JAC-4451-2023
OI Li, Yujie/0000-0002-0275-2797; 
FU Open Fund of the Key Laboratory of Marine Geology and Environment in
   Chinese Academy of Sciences [MGE2015KG02]; Research Fund of State Key
   Laboratory of Ocean Engineering in Shanghai Jiao Tong University - China
   [1315, 1510]; Research Fund of State Key Laboratory of Marine Geology in
   Tongji University - China [MGK1407];  [15F15077];  [13J10713];
   Grants-in-Aid for Scientific Research [15F15077] Funding Source: KAKEN
FX This work was partially supported by the Grant in Aid for Japan Society
   for the Promotion of Science - Japan (No. 15F15077), Open Fund of the
   Key Laboratory of Marine Geology and Environment in Chinese Academy of
   Sciences (No. MGE2015KG02), Research Fund of State Key Laboratory of
   Ocean Engineering in Shanghai Jiao Tong University - China (Nos. 1315,
   1510), Research Fund of State Key Laboratory of Marine Geology in Tongji
   University - China (MGK1407), and Grant in Aid for Japan Society for the
   Promotion of Science - Japan (No. 13J10713). The first author also
   wishes to thank the Japan Agency for Marine-Earth Science and Technology
   (JAMSTEC) for offering the deep-sea images and videos.
CR Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], 2013, 2013 MTS IEEE OCEANS
   Bazeille, 2006, P CAR MIL MAR CMM 06, P1
   Bertalmío M, 2007, IEEE T IMAGE PROCESS, V16, P1058, DOI 10.1109/TIP.2007.891777
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chambah M, 2004, PROC SPIE, V5293, P157
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Fattal R., 2008, SIGGRAPH, P1
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Kocak DM, 2008, MAR TECHNOL SOC J, V42, P52, DOI 10.4031/002533208786861209
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Pele O., 2012, IMPROVING PERCEPTUAL, P1
   Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1655, DOI 10.1109/TPAMI.2007.1141
   Schettini R., 2012, INT REV COMPUT SOFTW, V7, P3470
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shirron, 2012, P SOC PHOTO-OPT INS, V8372, P1
   Sooknanan K., 2012, P SOC PHOTO-OPT INS, V8305, P1
   Treibitz T, 2012, IEEE T IMAGE PROCESS, V21, P4662, DOI 10.1109/TIP.2012.2208978
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Zheng YJ, 2013, IEEE T PATTERN ANAL, V35, P1480, DOI 10.1109/TPAMI.2012.210
NR 26
TC 70
Z9 74
U1 1
U2 68
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 504
EP 516
DI 10.1016/j.jvcir.2016.03.029
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100043
DA 2024-07-18
ER

PT J
AU Nguyen, TS
   Chang, CC
   Huynh, NT
AF Thai-Son Nguyen
   Chang, Chin-Chen
   Ngoc-Tu Huynh
TI A novel reversible data hiding scheme based on difference-histogram
   modification and optimal EMD algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; EMD; High efficiency; Histogram modification;
   Reversibility; Block Classification; Pixel Selection; High Image Quality
ID IMAGE WATERMARKING; COMPRESSED IMAGES; PREDICTION
AB Data hiding techniques, which are classified into two groups: irreversible and reversible techniques, have been gained more and more attention recently. In which, reversible data hiding (RDH) is paid more attention since it is capable to recover original host images after revealing the secret data. However, there always is tradeoff between embedding capacity and image quality. The more secret data is embedded, the lower image quality is obtained. Therefore, in this paper, we propose a new RDH scheme to embed a large amount of secrets without causing dramatically damage to images. We develop an optimal exploiting modification direction matrix to modify the difference histogram. By carefully selecting image regions and using the optimal EMD table, the output image quality can be preserved while the embedding capacity of the scheme can be significantly enhanced. Experimental results demonstrated that our scheme outperforms previous schemes in terms of embedding capacity and image quality. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Thai-Son Nguyen; Chang, Chin-Chen; Ngoc-Tu Huynh] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Thai-Son Nguyen] Tra Vinh Univ, Dept Informat Technol, Tra Vinh City, Tra Vinh Provin, Vietnam.
   [Ngoc-Tu Huynh] Da Nang Univ, Coll Informat Technol, Da Nang City, Vietnam.
C3 Feng Chia University; Tra Vinh University; University of Danang
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM thaison@tvu.edu.vn; ccc@cs.ccu.edu.tw
RI Nguyen, Thai-Son/AGD-3594-2022; Chang, Ching-Chun/JAN-6210-2023
OI Nguyen, Thai-Son/0000-0001-7008-0462; 
CR Chan CS, 2011, PATTERN RECOGN LETT, V32, P1679, DOI 10.1016/j.patrec.2011.07.023
   Chang CC., 2014, INT J NETWORK SECUR, V16, P201
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Hong W., 2010, EURASIP J ADV SIGNAL, V2010
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Nguyen TS, 2014, KSII T INTERNET INF, V8, P2005, DOI 10.3837/tiis.2014.06.011
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
   Zhou JT, 2012, IEEE SIGNAL PROC LET, V19, P287, DOI 10.1109/LSP.2012.2190508
NR 27
TC 23
Z9 28
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 389
EP 397
DI 10.1016/j.jvcir.2015.10.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700035
DA 2024-07-18
ER

PT J
AU Tong, XJ
   Zhang, M
   Wang, Z
   Liu, Y
   Xu, H
   Ma, J
AF Tong, Xiao-Jun
   Zhang, Miao
   Wang, Zhu
   Liu, Yang
   Xu, Hui
   Ma, Jing
TI A fast encryption algorithm of color image based on four-dimensional
   chaotic system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image encryption; Four-dimensional chaotic system; Hyper-chaos;
   Pseudo-random sequence generator; Diffusion and scrambling;
   Column-major; Row-major; Cat map with parameters
ID PERMUTATION; HYPERCHAOS; BAKER
AB As the low complexity of low-dimensional chaotic system and the slow speed of image encryption, this paper proposes a fast encryption algorithm of color image based on four-dimensional chaotic system. Firstly, we propose a new method of designing four-dimensional chaotic system based on the classical equations of three-dimensional chaotic system, to increase the complexity and key space of the encryption algorithm. Secondly, according to the nature of color images' pixels channel, we design a new pseudo-random sequence generator and reuse the random sequence, to improve the speed of image encryption. Finally, the methods of row-major and column-major are used to diffuse the original image and the cat map with parameter is used to scramble the image pixels, respectively, to achieve the effect of encryption. The results of simulation and security analysis show that the proposed encryption algorithm is of good performance on security, robustness and high encryption speed. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Tong, Xiao-Jun; Zhang, Miao; Liu, Yang; Xu, Hui] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
   [Wang, Zhu] Harbin Inst Technol, Sch Informat & Elect Engn, Weihai 264209, Peoples R China.
   [Ma, Jing] Sci & Technol Informat Assurance Lab, Beijing 100072, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
EM tong_xiaojun@163.com
FU National Natural Science Foundation of China [60973162]; Natural Science
   Foundation of Shandong Province of China [ZR2014FM026, ZR2009GM037];
   Science and Technology of Shandong Province, China [2013GGX10129,
   2010GGX10132, 2012GGX10110]; National Cryptology Development Foundation
   of China [MMJJ201301006]; Foundation of Science and Technology on
   Information Assurance Laboratory [KJ-14-005]; Engineering Technology and
   Research Center of Weihai Information Security
FX This work was supported by the National Natural Science Foundation of
   China (60973162), the Natural Science Foundation of Shandong Province of
   China (ZR2014FM026 and ZR2009GM037), the Science and Technology of
   Shandong Province, China (2013GGX10129, 2010GGX10132 and 2012GGX10110),
   the National Cryptology Development Foundation of China (No.
   MMJJ201301006), Foundation of Science and Technology on Information
   Assurance Laboratory (No. KJ-14-005) and the Engineering Technology and
   Research Center of Weihai Information Security.
CR Arroyo D, 2009, CHAOS SOLITON FRACT, V41, P2613, DOI 10.1016/j.chaos.2008.09.051
   Bao Fang, 2012, Journal of Xi'an University of Technology, V28, P193
   Boriga R, 2014, SIGNAL PROCESS-IMAGE, V29, P887, DOI 10.1016/j.image.2014.04.001
   Cang SJ, 2010, NONLINEAR DYNAM, V59, P515, DOI 10.1007/s11071-009-9558-0
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jia HY, 2009, ACTA PHYS SIN-CH ED, V58, P4469, DOI 10.7498/aps.58.4469
   Jia QA, 2007, PHYS LETT A, V366, P217, DOI 10.1016/j.physleta.2007.02.024
   Li YX, 2005, INT J BIFURCAT CHAOS, V15, P3367, DOI 10.1142/S0218127405013988
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sun FY, 2010, OPT COMMUN, V283, P2066, DOI 10.1016/j.optcom.2010.01.028
   Tang LR, 2009, ACTA PHYS SIN-CH ED, V58, P1446, DOI 10.7498/aps.58.1446
   Tong XJ, 2013, COMMUN NONLINEAR SCI, V18, P1725, DOI 10.1016/j.cnsns.2012.11.002
   Tong XJ, 2009, SIGNAL PROCESS, V89, P480, DOI 10.1016/j.sigpro.2008.09.011
   Wang J., 2011, ACTA PHYS SINICA, V60
   Wang XY, 2015, ENTROPY-SWITZ, V17, P3877, DOI 10.3390/e17063877
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhou Q, 2012, J SYST SOFTWARE, V85, P400, DOI 10.1016/j.jss.2011.08.032
   [朱从旭 Zhu Congxu], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P1735
NR 29
TC 43
Z9 45
U1 2
U2 61
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 219
EP 234
DI 10.1016/j.jvcir.2015.09.014
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700020
DA 2024-07-18
ER

PT J
AU Zhang, LB
   Zhang, J
   Wang, S
   Chen, J
AF Zhang, Libao
   Zhang, Jue
   Wang, Shuang
   Chen, Jie
TI Residential area extraction based on saliency analysis for high spatial
   resolution remote sensing images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Remote sensing image processing; Residential area extraction; Saliency
   analysis; Lifting wavelet transform; Logarithm co-occurrence histogram;
   Color opponency; Feature competition; Threshold
ID FEATURES; MODEL
AB Traditional residential area extraction methods for remote sensing image depend on classification, segmentation and prior knowledge which are time-consuming and difficult to build. In this paper, an efficient, saliency analysis-based residential area extraction method is proposed. In the proposed model, an adaptive directional prediction-based lifting wavelet transform (ADP-LWT) is introduced to obtain the orientation feature. A logarithm co-occurrence histogram is employed to compute the intensity feature. The color opponency and diagram objection based on the information are proposed to extract color feature from the contrast in the red-green opponent channel. The saliency map is obtained through a weighted combination based on the feature competition and the residential area is extracted by saliency map threshold segmentation. The experimental results reveal that the residential area extracted by our model has more demarcated boundaries and better performance in background subtraction. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhang, Libao; Zhang, Jue; Wang, Shuang; Chen, Jie] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Zhang, LB (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
EM libaozhang@163.com
FU National Natural Science Foundation of China [61571050, 61071103];
   Fundamental Research Funds for the Central Universities [2012LYB50]
FX This work was sponsored by the National Natural Science Foundation of
   China (Nos. 61571050 and 61071103) and by the Fundamental Research Funds
   for the Central Universities (2012LYB50).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2013, 2013 IEEE C COMP VIS
   Arvor D, 2013, ISPRS J PHOTOGRAMM, V82, P125, DOI 10.1016/j.isprsjprs.2013.05.003
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen Q, 2012, IET IMAGE PROCESS, V6, P426, DOI 10.1049/iet-ipr.2010.0078
   Cheng M.M., 2011, TECHNICAL REPORT
   Dahiya S., 2013, IEEE 3 INT ADV COMP
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Gleyzes JP, 2003, INT GEOSCI REMOTE SE, P300
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang CB, 2011, J SUPERCOMPUT, V58, P20, DOI 10.1007/s11227-010-0532-x
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain A, 1998, IEEE T IMAGE PROCESS, V7, P124, DOI 10.1109/83.650858
   Li ZC, 2011, IEEE T IMAGE PROCESS, V20, P2017, DOI 10.1109/TIP.2010.2099128
   Lu SJ, 2014, IEEE T PATTERN ANAL, V36, P195, DOI 10.1109/TPAMI.2013.158
   Marcellin M.W., 2002, JPEG2000 IMAGE COMPR
   Murai H, 1997, INT J REMOTE SENS, V18, P811, DOI 10.1080/014311697218773
   Solomon SG, 2007, NAT REV NEUROSCI, V8, P276, DOI 10.1038/nrn2094
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tong XH, 2014, IEEE J-STARS, V7, P3998, DOI 10.1109/JSTARS.2013.2272212
   USUI S, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P1327, DOI 10.1109/ICNN.1993.298750
   Wang Z., 2008, IEEE INT C SPEECH SI
   Xiong J.-n., 2011, INT C COMP INF SCI I
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang L., 2014, GEOSCI REMOTE SENS L, V12, P58
   Zhang LB, 2014, IEEE J-STARS, V7, P4704, DOI 10.1109/JSTARS.2014.2319736
   Zhang LB, 2014, IEEE GEOSCI REMOTE S, V11, P916, DOI 10.1109/LGRS.2013.2281827
   Zhong P, 2007, IEEE T GEOSCI REMOTE, V45, P3978, DOI 10.1109/TGRS.2007.907109
   Zhong YF, 2014, IEEE T GEOSCI REMOTE, V52, P7023, DOI 10.1109/TGRS.2014.2306692
NR 33
TC 19
Z9 21
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 273
EP 285
DI 10.1016/j.jvcir.2015.09.019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700025
DA 2024-07-18
ER

PT J
AU Chang, MK
   Chen, TC
   Shen, CA
   Huang, WJ
   Kuo, CH
   Kuo, CC
AF Chang, Min-Kuan
   Chen, Ting-Chen
   Shen, Che-An
   Huang, Wan-Jen
   Kuo, Chih-Hung
   Kuo, Chia-Chen
TI New results on connectivity in wireless network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Small structure; Realistic connection; Continuum; Critical probability;
   Directional graph; Percolation; Full connectivity; Wireless network
ID PERCOLATION
AB In this work, we discuss when two users are able to exchange multimedia content and when that exchange is always possible. Two thresholds are of interest, a threshold for percolation and a threshold for full connectivity. To derive these thresholds, when discussing the bond percolation, we consider not only four directions, upper, right, left, and lower, but also more directions like upper-right, lower-right, upper-left, lower-left. In addition, small structures are proposed to help obtain the necessary conditions for percolation and full connectivity. We find that if the probability of four directions being open is greater than 0.3118 or the transmission radius of every node is longer than 1.52d/k, we can find a crossing path in our network and the percolation ensues. Furthermore, if that is greater than 0.3799 or the transmission radius of every node is longer than 1.579d/k, a fully-connected network graph exists for sure. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kuo, Chia-Chen] Natl Ctr High Performance Comp, Hsinchu, Taiwan.
RP Huang, WJ (corresponding author), 70 Lienhai Rd, Kaohsiung 80424, Taiwan.
EM minkuanc@dragon.nchu.edu.tw; ctc0724@gmail.com; ann0929@hotmail.com.tw;
   wjhuang@faculty.nsysu.edu.tw; chkuo@ee.ncku.edu.tw; cckuo@narlabs.org.tw
RI Chang, Min-Kuan/AAM-4077-2020
OI Chang, Min-Kuan/0000-0002-0979-0892
FU National Center for High-performance Computing, Taiwan [03104A7100]
FX This work was supported by the National Center for High-performance
   Computing, Taiwan, under Grants 03104A7100.
CR Chang MC, 2012, INT J PHOTOENERGY, V2012, DOI 10.1155/2012/303961
   Dousse O, 2005, IEEE ACM T NETWORK, V13, P425, DOI 10.1109/TNET.2005.845546
   Franceschetti M., 2007, Random Networks for Communication
   Franceschetti M, 2007, IEEE T INFORM THEORY, V53, P1009, DOI 10.1109/TIT.2006.890791
   GILBERT EN, 1961, J SOC IND APPL MATH, V9, P533, DOI 10.1137/0109045
   Grimmett Geoffrey, 1989, Percolation
   Johnson D.B., 1996, Mobile Computing, DOI DOI 10.1007/978-0-585-29603-65
   Kong Z., 2009, 7th International Symposium on Modeling and Optimization in Mobile, Ad Hoc, and Wireless Networks, P1, DOI DOI 10.1109/WI0PT.2009.5291573
   Penkin D., 2010, IEEE SCVT 2010, P1, DOI DOI 10.1109/SCVT.2010.5720460
   Perkins C. E., 1999, P 2 IEEE WORKSH MOB, P1185
   Shen CC, 2006, IEEE T MOBILE COMPUT, V5, P317, DOI 10.1109/TMC.2006.1599402
   Vaze R, 2012, IEEE INFOCOM SER, P513, DOI 10.1109/INFCOM.2012.6195792
NR 12
TC 0
Z9 0
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 74
EP 82
DI 10.1016/j.jvcir.2015.07.013
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300006
DA 2024-07-18
ER

PT J
AU Chen, HT
   Tang, CW
AF Chen, Hsiao-Tzu
   Tang, Chih-Wei
TI Robust tracking using visual cue integration for mobile mixed images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Reflection; Multi-cue integration; Camera motion;
   Particle filter; Motion compensation; Layer separation; Co-inference
ID OBJECT TRACKING; BLIND SEPARATION; REFLECTION; LAYERS; MODEL
AB The transmitted scene superposed with the reflected scene from a transparent surface leads to mixed images. Few methods have been devoted for tracking on mixed images while such images are ubiquitous in the real world. Thus, this paper proposes a robust single object tracking scheme for mixed images acquired by mobile cameras. Layer separation that decomposes mixed images extracts intrinsic dynamic layers before tracking. In order to make the tracker robust against camera motion, motion compensation is applied to both layer separation and prediction stage of the particle filter. To maximize the observation likelihood and thus optimize particle weights in the face of reflections, the proposed scheme combines sequential importance resampling (SIR) based co-inference and maximum likelihood for multi-cue integration. Experimental results show that the proposed scheme effectively improves tracking accuracy on mixed images with camera motion. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chen, Hsiao-Tzu; Tang, Chih-Wei] Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Tang, CW (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
EM tzuchen248@gmail.com; cwtang@ce.ncu.edu.tw
FU Ministry of Science and Technology of Taiwan [NSC-101-2221-E-008-060,
   MOST-103-2221-E-008-061]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the Grants NSC-101-2221-E-008-060 and
   MOST-103-2221-E-008-061.
CR Ahmed MA, 2011, PROC CVPR IEEE, P705, DOI 10.1109/CVPR.2011.5995670
   [Anonymous], PETS2001 2 IEEE INT
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bar-Shalom Yaakov, 2011, TRQACKING DATA FUSIO
   Barrow H. G., 1978, Computer Vision Systems, P3
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bergman N., 1999, Ph. D. thesis
   CICHOCKI A., 2002, Adaptive Blind Signal and Image Processing: Learning Algorithms and Applications
   Doucet A., 1998, SEQUENRIAL M CARLO M
   Elgharib M. A., 2013, P EUR C VIS MED PROD
   Farid H., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P262, DOI 10.1109/CVPR.1999.786949
   Gai K, 2012, IEEE T PATTERN ANAL, V34, P19, DOI 10.1109/TPAMI.2011.87
   Guo XJ, 2014, PROC CVPR IEEE, P2195, DOI 10.1109/CVPR.2014.281
   Hsiao-Tzu Chen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6548, DOI 10.1109/ICASSP.2014.6854866
   Hubei D.H., 1995, EYE BRAIN VISION SCI, V22
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Levin A, 2007, IEEE T PATTERN ANAL, V29, P1647, DOI 10.1109/TPAMI.2007.1106
   Li H, 2013, INT CONF ACOUST SPEE, P1641, DOI 10.1109/ICASSP.2013.6637930
   Li X, 2013, IEEE T IMAGE PROCESS, V22, P3028, DOI 10.1109/TIP.2013.2253478
   Lu JY, 2011, IEEE IMAGE PROC, P489, DOI 10.1109/ICIP.2011.6116558
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Sarel B, 2004, LECT NOTES COMPUT SC, V2034, P328
   Serby D, 2004, INT C PATT RECOG, P184, DOI 10.1109/ICPR.2004.1334091
   Shafer S., 1984, TR136 U ROCH DEP COM
   Wang LF, 2014, IEEE T CIRC SYST VID, V24, P1132, DOI 10.1109/TCSVT.2014.2302496
   Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606
   Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xie CJ, 2014, J VIS COMMUN IMAGE R, V25, P423, DOI 10.1016/j.jvcir.2013.12.012
   Yan Q, 2013, IEEE INT SYMP CIRC S, P937, DOI 10.1109/ISCAS.2013.6572002
   Yang M, 2009, IEEE I CONF COMP VIS, P1554, DOI 10.1109/ICCV.2009.5459252
   Young T., 1800, PHILOS T R SOC, V92, P12, DOI [10.1098/rstl.1802.0004, DOI 10.1098/RSPL.1800.0044, DOI 10.1098/RSTL.1802.0004]
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
NR 37
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 208
EP 218
DI 10.1016/j.jvcir.2015.04.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900019
DA 2024-07-18
ER

PT J
AU Chen, CY
   Cai, JF
   Lin, WS
   Shi, GM
AF Chen, Chongyu
   Cai, Jianfei
   Lin, Weisi
   Shi, Guangming
TI Incremental low-rank and sparse decomposition for compressing videos
   captured by fixed cameras
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low-rank and sparse decomposition; Incremental low-rank and sparse
   decomposition; CUR decomposition; Video coding; Stationary camera;
   Background subtraction; Background subtraction based video coding;
   Background prediction based video coding
ID MATRIX
AB Videos captured by stationary cameras are usually with a static or gradually changed background. Existing schemes are not able to globally exploit the strong background temporal redundancy. In this paper, motivated by the recent advance on low-rank and sparse decomposition (LRSD), we propose to apply it for the compression of videos captured by fixed cameras. In particular, the LRSD is employed to decompose the input video into the low-rank component, representing the background, and the sparse component, representing the moving objects, which are encoded by different methods. Moreover, we further propose an incremental LRSD (ILRSD) algorithm to reduce the large memory requirement and high computational complexity of the existing LRSD algorithm, which facilitates the process of large-scale video sequences without much performance loss. Experimental results show that the proposed coding scheme can significantly improve the existing standard codecs, H.264/AVC and HEVC, and outperform the state-of-the-art background modeling based coding schemes. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chen, Chongyu; Shi, Guangming] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Cai, Jianfei; Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Xidian University; Nanyang Technological University
RP Cai, JF (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM cychen@mail.xidian.edu.cn; asjfcai@ntu.edu.sg; wslin@ntu.edu.sg;
   gmshi@xidian.edu.cn
RI Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012; Chen,
   Chongyu/IWM-0773-2023; Cai, Jianfei/A-3691-2011
OI Lin, Weisi/0000-0001-9866-1947; Cai, Jianfei/0000-0002-9444-3763
FU MoE AcRF Tier 2 Grant, Singapore [T208B1218]; Major State Basic Research
   Development Program of China (973 Program) [2013CB329402]; National
   Natural Science Foundation of China [61227004, 61372131, 11204014]; 111
   Project [B07048]; Fundamental Research Funds for the Central
   Universities [K5051399020]; Research Fund for the Doctoral Program of
   Higher Education of China [20130203120009]
FX This work is partially supported by MoE AcRF Tier 2 Grant, Singapore,
   Grant No.: T208B1218, the Major State Basic Research Development Program
   of China (973 Program, No. 2013CB329402), the National Natural Science
   Foundation of China (Nos. 61227004, 61372131, 11204014), the 111 Project
   (No. B07048), the Fundamental Research Funds for the Central
   Universities (No. K5051399020), and the Research Fund for the Doctoral
   Program of Higher Education of China (No. 20130203120009).
CR [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], ARXIV10095055
   [Anonymous], 2011, INT C MACH LEARN ICM
   [Anonymous], INT C ART INT STAT
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Bredies K, 2008, SIAM J SCI COMPUT, V30, P657, DOI 10.1137/060663556
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chen C., 2012, P 20 ACM INT C MULT, P713, DOI DOI 10.1145/2393347.2396294
   Drineas P, 2008, SIAM J MATRIX ANAL A, V30, P844, DOI 10.1137/07070471X
   Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367
   Gao Y, 2012, INTELL SYST SER, P1
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Mackey Lester W, 2011, ADV NEURAL INFORM PR, P1134, DOI DOI 10.5555/2986459.2986586
   Paul M., 2011, P IEEE ICIP, P3521
   Paul M, 2011, IEEE T CIRC SYST VID, V21, P1242, DOI 10.1109/TCSVT.2011.2138750
   Paul M, 2010, INT CONF ACOUST SPEE, P734, DOI 10.1109/ICASSP.2010.5495033
   Sullivan G. J., 2004, SPIE C APPL DIGITAL, VXXVII
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan T. K., 2005, RECOMMENDED SIMULATI
   Wang SQ, 2012, IEEE INT SYMP CIRC S, P145
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xianguo Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1067, DOI 10.1109/ICME.2012.136
   Xianguo Zhang, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P78, DOI 10.1109/PCS.2010.5702583
   Zhang X., 2010, P VIS COMM IM PROC, V7744
   Zhang XY, 2012, PROCEEDINGS OF THE ASME 10TH FUEL CELL SCIENCE, ENGINEERING, AND TECHNOLOGY CONFERENCE, 2012, P1, DOI 10.1109/ACC.2007.4282196
NR 26
TC 16
Z9 17
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 338
EP 348
DI 10.1016/j.jvcir.2014.12.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000031
DA 2024-07-18
ER

PT J
AU Kim, HG
   Seo, SJ
   Song, BC
AF Kim, Hak Gu
   Seo, Seung Ji
   Song, Byung Cheol
TI Multi-frame de-raining algorithm using a motion-compensated non-local
   mean filter for rainy video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Rain streaks; Rain detection; Rain removal; Visibility enhancement;
   Spatio-temporal non-local mean filtering; Post-processing; Non-rain
   block matching; Flickering artifact removal
ID REMOVAL
AB This paper proposes a rain detection and removal algorithm that is robust against camera motion. The proposed algorithm initially detects possible rain streaks by using spatial properties, such as the luminance and structure of rain streaks. Then, the rain streak candidates are selected based on a Gaussian distribution model. Finally, these detected regions are improved with an advanced temporal property in a block-matching process. After the rain detection step, a non-rain block-matching algorithm for each block is performed between adjacent frames to find blocks similar to the block that has rain pixels. If similar blocks are obtained, the rain region of the block is reconstructed by spatio-temporal non-local mean filtering using similar neighboring regions. Finally, a specific post-processing is performed for visibility enhancement and flickering artifact removal. Experiment results show that the proposed algorithm uses only five temporally adjacent frames for rain removal but outperforms previous methods in terms of subjective visual quality. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Kim, Hak Gu; Seo, Seung Ji; Song, Byung Cheol] Inha Univ, Dept Elect Engn, Inchon 402751, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, 253 Yonghyun 4dong, Inchon 402751, South Korea.
EM bcsong@inha.ac.kr
RI Song, Byungcheol/AAH-9770-2019
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [2012R1A1B3000446]; Ministry of
   Science, ICT & Future Planning (MSIP), Korea; National ICT Industry
   Promotion Agency (NIPA) [2014-H0502-14-3027]; Hyundai NGV
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2012R1A1B3000446), and was supported by the Ministry of
   Science, ICT & Future Planning (MSIP), Korea, under ICT/SW Creative
   Research Program supervised by the National ICT Industry Promotion
   Agency (NIPA) (2014-H0502-14-3027), and was supported by the Hyundai
   NGV.
CR Barnum P., 2007, P 1 INT WORKSH PHOT, P1
   Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Ji RR, 2014, IEEE T IMAGE PROCESS, V23, P3099, DOI 10.1109/TIP.2014.2324291
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2013, IEEE IMAGE PROC, P914, DOI 10.1109/ICIP.2013.6738189
   Lee JH, 2001, IEEE T CIRC SYST VID, V11, P1289, DOI 10.1109/76.974683
   Miao Y., 2011, AS CONTR C TAIW MAY
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   Xue XW, 2012, IEEE INT WORKSH MULT, P170, DOI 10.1109/MMSP.2012.6343435
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
NR 16
TC 5
Z9 5
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 317
EP 328
DI 10.1016/j.jvcir.2014.10.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000029
DA 2024-07-18
ER

PT J
AU Peng, RB
   Varshney, PK
AF Peng, Renbin
   Varshney, Pramod K.
TI A human visual system-driven image segmentation algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Image segmentation; Human visual system; HVS-driven
   segmentation; Just-noticeable difference (JND) model; Markov random
   fields; Quality metrics; Boundary- and region-based segmentation
ID ENERGY MINIMIZATION; EDGE DETECTOR; DISTORTION; MODEL; TEXTURE; REGION
AB This paper presents a novel image segmentation algorithm driven by human visual system (HVS) properties. Segmentation quality metrics, based on perceptual properties of HVS with respect to segmentation, are integrated into an energy function. The energy function encodes the HVS properties from both region-based and boundary-based perspectives, where the just-noticeable difference (JND) model is employed when calculating the difference between the image contents. Extensive experiments are carried out to compare the performances of three variations of the presented algorithm and several representative segmentation and clustering algorithms available in the literature. The results show superior performance of our approach.
C1 [Peng, Renbin] Facebook Inc, Menlo Pk, CA 94025 USA.
   [Varshney, Pramod K.] Syracuse Univ, Dept Elect Engn & Comp Sci, Syracuse, NY 13244 USA.
C3 Facebook Inc; Syracuse University
RP Peng, RB (corresponding author), Facebook Inc, 1601 Willow Rd, Menlo Pk, CA 94025 USA.
EM rpeng@syr.edu
CR Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   Andersson T, 2013, IEEE T IMAGE PROCESS, V22, P621, DOI 10.1109/TIP.2012.2220148
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Beghdadi A., 2007, 9 INT S SIGN PROC IT, P1
   Bergman R, 2011, IEEE T IMAGE PROCESS, V20, P1668, DOI 10.1109/TIP.2010.2088970
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bowyer K, 1999, IEEE COMP SOC C COMP
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chen F, 2013, IEEE T IMAGE PROCESS, V22, P992, DOI 10.1109/TIP.2012.2226044
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Couto D.C., 2009, INT WORKSH VID PROC
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   Eches O, 2013, IEEE T IMAGE PROCESS, V22, P5, DOI 10.1109/TIP.2012.2204270
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Gelasca E. D., 2004, COMP VIS PATT REC WO, V4, P5
   GEMAN D, 1987, IMAGE VISION COMPUT, V5, P61, DOI 10.1016/0262-8856(87)90028-X
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Ghita O, 2014, IEEE T IMAGE PROCESS, V23, P4576, DOI 10.1109/TIP.2014.2347240
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Heucke L, 2000, IEEE SIGNAL PROC LET, V7, P129, DOI 10.1109/97.844629
   Huang SC, 2013, IEEE T NEUR NET LEAR, V24, P1920, DOI 10.1109/TNNLS.2013.2270314
   Huang SC, 2011, IEEE T CIRC SYST VID, V21, P1, DOI 10.1109/TCSVT.2010.2087812
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Jung C, 2012, IEEE T IMAGE PROCESS, V21, P1272, DOI 10.1109/TIP.2011.2164420
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   Leordeanu M, 2014, IEEE T PATTERN ANAL, V36, P1312, DOI 10.1109/TPAMI.2014.17
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   Li HL, 2014, IEEE T IMAGE PROCESS, V23, P3545, DOI 10.1109/TIP.2014.2330759
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Lin Weisi., 2005, Digital Video Image Quality and Perceptual Coding, chapter Computational Models for Just-noticeable Difference, page, P281
   Lin WS, 2005, IEEE T CIRC SYST VID, V15, P900, DOI 10.1109/TCSVT.2005.848345
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085
   Mi X., IMAGE SEGMENTATION P
   Mishra A, 2009, IEEE I CONF COMP VIS, P468, DOI 10.1109/ICCV.2009.5459254
   Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171
   Mobahi H, 2011, INT J COMPUT VISION, V95, P86, DOI 10.1007/s11263-011-0444-0
   Murat A. Bagct, 2002, P ICASSP 2002, V4, pIV
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Paskaleva BS, 2014, IEEE T IMAGE PROCESS, V23, P2315, DOI 10.1109/TIP.2014.2315154
   Pham DL, 2000, ANNU REV BIOMED ENG, V2, P315, DOI 10.1146/annurev.bioeng.2.1.315
   Pujol X. M., 2003, THESIS U GIRONA SPAI
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shen DF, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P377
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shui PL, 2014, IEEE T GEOSCI REMOTE, V52, P6434, DOI 10.1109/TGRS.2013.2296561
   Spratling MW, 2013, IEEE T IMAGE PROCESS, V22, P1629, DOI 10.1109/TIP.2012.2235850
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler G., 2006, IMAGE ANAL RANDOM FI, Vsecond
   Xu Q, 2014, IEEE T IMAGE PROCESS, V23, P2944, DOI 10.1109/TIP.2014.2311656
   Yang XK, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P609
   Yi CC, 2012, IEEE T IMAGE PROCESS, V21, P4256, DOI 10.1109/TIP.2012.2199327
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
   Zhang J, 1998, J ELECTRON IMAGING, V7, P52, DOI 10.1117/1.482626
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2582, DOI 10.1109/TIP.2011.2121080
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
   Zhang XH, 2008, J VIS COMMUN IMAGE R, V19, P30, DOI 10.1016/j.jvcir.2007.06.001
   Zhang Y.J., 2006, Advances in image and video segmentation
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
NR 67
TC 4
Z9 6
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 66
EP 79
DI 10.1016/j.jvcir.2014.11.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yan, J
   Chen, X
   Deng, DX
   Zhu, QP
AF Yan, Jia
   Chen, Xi
   Deng, Dexiang
   Zhu, Qiuping
TI Visual object tracking via online sparse instance learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Multiple instance learning; Integrated sparse
   representation; Tracking by detection; Random projection; Online
   learning; Appearance variation; Occlusion
AB Sparse representation has been attracting much more attention in visual tracking. However most sparse representation based trackers only focus on how to model the target appearance and do not consider the learning of sparse representation when the training samples are imprecise, and hence may drift or fail in the challenging scene. In this paper, we present a novel online tracking algorithm. The tracker integrates the online multiple instance learning into the recent sparse representation scheme. For tracking, the integrated sparse representation combining texture, intensity and local spatial information is proposed to model the target. This representation takes both occlusion and appearance change into account. Then, an efficient online learning approach is proposed to select the most distinguishable features to separate the target from the background samples. In addition, the sparse representation is dynamically updated online with respect to the current context. Both qualitative and quantitative evaluations on challenging benchmark video sequences demonstrate that the proposed tracking algorithm performs favorably against several state-of-the-art methods. (C) 2014 Published by Elsevier Inc.
C1 [Yan, Jia; Deng, Dexiang; Zhu, Qiuping] Wuhan Univ, Sch Elect Informat, Dept Elect Engn, Wuhan 430072, Hubei, Peoples R China.
   [Chen, Xi] Wuhan Univ, Sch Int Software, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP Chen, X (corresponding author), Wuhan Univ, Sch Int Software, Wuhan 430072, Hubei, Peoples R China.
EM robertchenxi2011@gmail.com
CR Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   [Anonymous], 2013, IEEE transactions on image processing, DOI DOI 10.1109/TIP.2012.2202677
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Han ZJ, 2011, PATTERN RECOGN, V44, P2170, DOI 10.1016/j.patcog.2011.03.002
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Viola P., 2006, NIPS 18, P1419
   Wang Q, 2012, IEEE T IMAGE PROCESS, V21, P4454, DOI 10.1109/TIP.2012.2205700
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang SP, 2013, NEUROCOMPUTING, V100, P31, DOI 10.1016/j.neucom.2011.11.031
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu QP, 2013, IET COMPUT VIS, V7, P448, DOI 10.1049/iet-cvi.2012.0248
NR 31
TC 6
Z9 6
U1 1
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 231
EP 246
DI 10.1016/j.jvcir.2014.11.013
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000021
DA 2024-07-18
ER

PT J
AU Liu, YX
   Law, NF
   Siu, WC
AF Liu, Yun-Xia
   Law, Ngai-Fong
   Siu, Wan Chi
TI Patch based image denoising using the finite ridgelet transform for less
   artifacts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Shrinkage; Finite ridgelet transform; Artifact; Visual
   quality
ID STRUCTURAL SIMILARITY; LEARNED DICTIONARIES; SPATIAL ADAPTATION;
   WAVELET; DOMAIN; SPARSE
AB Patch based denoising methods have proved to lead to state-of-the-art results. However, in contrast with intensive pursuing of higher peak signal to noise ratio (PSNR), less attention is paid to visual quality improvement of denoised images. In this paper, we first compare the denoising performance in edge and smooth regions. Results reveal that edge regions are the main source for potential performance improvement. This motivates us to investigate the use of the finite ridgelet transform as a local transform for better preservation of directional singularities. A two stage denoising algorithm is then proposed to improve the representation of detail structures. Experimental results in denoising images which only contain white noise show that the proposed algorithm consistently outperforms other methods in terms of PSNR and Structural SIMilarity index. Denoised images by the proposed method also demonstrate good visual quality with the least artifacts and fake structures in experiments on natural images. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Liu, Yun-Xia; Law, Ngai-Fong; Siu, Wan Chi] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Liu, YX (corresponding author), Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
EM yunxia.liu@connect.polyu.hk; ennflaw@polyu.edu.hk; enwcsiu@polyu.edu.hk
RI Law, Bonnie/M-9973-2015
OI Law, Bonnie/0000-0002-9809-5110
FU Centre for Signal Processing, Department of Electronic and Information
   Engineering; Hong Kong Polytechnic University
FX This work is supported by the Centre for Signal Processing, Department
   of Electronic and Information Engineering and the Hong Kong Polytechnic
   University. Yun-Xia Liu acknowledges the research studentships provided
   by the University.
CR Aguado AS, 2000, P ROY SOC A-MATH PHY, V456, P503, DOI 10.1098/rspa.2000.0528
   Angelino CV, 2010, IEEE IMAGE PROC, P1129, DOI 10.1109/ICIP.2010.5651316
   [Anonymous], 2011, IEEE C COMP VIS PATT
   [Anonymous], PHYSIEA D, DOI DOI 10.1016/0167-2789(92)90242-F
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Chatterjee P, 2009, IEEE T IMAGE PROCESS, V18, P1438, DOI 10.1109/TIP.2009.2018575
   Chen GY, 2007, PATTERN RECOGN, V40, P578, DOI 10.1016/j.patcog.2006.04.039
   Chen GY, 2005, PATTERN RECOGN, V38, P2314, DOI 10.1016/j.patcog.2005.02.008
   Chen GY, 2005, PATTERN RECOGN, V38, P115, DOI 10.1016/j.patcog.2004.05.009
   Chen QA, 2010, PATTERN RECOGN, V43, P4089, DOI 10.1016/j.patcog.2010.07.002
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Guleryuz OG, 2007, IEEE T IMAGE PROCESS, V16, P3020, DOI 10.1109/TIP.2007.908078
   Hou YK, 2011, IEEE T IMAGE PROCESS, V20, P268, DOI 10.1109/TIP.2010.2052281
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Li SN, 2009, LECT NOTES COMPUT SC, V5879, P836
   Pardo A, 2011, PATTERN RECOGN LETT, V32, P2145, DOI 10.1016/j.patrec.2011.06.022
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rabbani H, 2009, PATTERN RECOGN, V42, P2181, DOI 10.1016/j.patcog.2009.01.005
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Terrades OR, 2006, PATTERN RECOGN LETT, V27, P587, DOI 10.1016/j.patrec.2005.09.024
   Wang X, 2007, IEEE T PATTERN ANAL, V29, P886, DOI 10.1109/TPAMI.2007.1027
   Wang X, 2010, PATTERN RECOGN, V43, P3693, DOI 10.1016/j.patcog.2010.05.032
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
NR 30
TC 15
Z9 15
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1006
EP 1017
DI 10.1016/j.jvcir.2014.02.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200028
DA 2024-07-18
ER

PT J
AU Starosolski, R
AF Starosolski, Roman
TI New simple and efficient color space transformations for lossless image
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible color space transformation; Lossless image compression; Human
   vision system; Image coding; RCT; YCoCg-R; Karhunen-Loeve
   transformation; JPEG-LS; JPEG2000; JPEG XR
AB We present simple color space transformations for lossless image compression and compare them with established transformations including RCT, YCoCg-R and with the optimal KLT for 3 sets of test images and for significantly different compression algorithms: JPEG-LS, JPEG2000 and JPEG XR. One of the transformations, RDgDb, which requires just 2 integer subtractions per image pixel, on average results in the best ratios for JPEG2000 and JPEG XR, while for a specific set or in case of JPEG-LS its compression ratios are either the best or within 0.1 bpp from the best. The overall best ratios were obtained with JPEG-LS and the modular-arithmetic variant of RDgDb (mRDgDb). Another transformation (LDgEb), based on analog transformations in human vision system, is with respect to complexity and average ratios better than RCT and YCoCg-R, although worse than RDgDb; for one of the sets it obtains the best ratios. (c) 2014 Elsevier Inc. All rights reserved.
C1 Silesian Tech Univ, Inst Comp Sci, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Starosolski, R (corresponding author), Silesian Tech Univ, Inst Comp Sci, PL-44100 Gliwice, Poland.
EM rstarosolski@polsl.pl
RI Starosolski, Roman/AAF-6974-2019
OI Starosolski, Roman/0000-0003-1322-3345
FU Institute of Computer Science, Silesian University of Technology
   [BK-219/RAu2/2012]; GCONiI - Upper-Silesian Center for Scientific
   Computations [POIG.02.03.01-24-099/13]
FX This work was supported by BK-219/RAu2/2012 grant from the Institute of
   Computer Science, Silesian University of Technology and by
   POIG.02.03.01-24-099/13 grant: GCONiI - Upper-Silesian Center for
   Scientific Computations.
CR [Anonymous], P SPIE
   Barequet R, 1999, IEEE DATA COMPR CONF, P501, DOI 10.1109/DCC.1999.755700
   Chen X., 2011, LECT NOTES ELECT ENG, V73, P3, DOI DOI 10.1007/978-90-481-9965-5
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Domanski M., 2001, P IEEE INT C IM PROC, V3, P454
   Gegenfurtner KR, 2003, ANNU REV NEUROSCI, V26, P181, DOI 10.1146/annurev.neuro.26.041002.131116
   Hao PW, 2003, IEEE IMAGE PROC, P633
   Hao PW, 2001, IEEE T SIGNAL PROCES, V49, P2314, DOI 10.1109/78.950787
   Janczur P., 2011, THESIS SILESIAN U TE
   Malvar HS, 2008, PROC SPIE, V7073, DOI 10.1117/12.797091
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Singh SK, 2011, SIGNAL PROCESS-IMAGE, V26, P662, DOI 10.1016/j.image.2011.08.001
   Strutz T, 2012, EUR SIGNAL PR CONF, P1204
   Wu XL, 2000, IEEE T IMAGE PROCESS, V9, P994, DOI 10.1109/83.846242
NR 14
TC 46
Z9 50
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1056
EP 1063
DI 10.1016/j.jvcir.2014.03.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200032
DA 2024-07-18
ER

PT J
AU Richtsfeld, A
   Mörwald, T
   Prankl, J
   Zillich, M
   Vincze, M
AF Richtsfeld, Andreas
   Moerwald, Thomas
   Prankl, Johann
   Zillich, Michael
   Vincze, Markus
TI Learning of perceptual grouping for object segmentation on RGB-D data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Object segmentation; Perceptual organization; RGB-D
   images; B-spline fitting; Object reconstruction; SVM learning;
   Graph-based segmentation
ID COMPUTER VISION; ORGANIZATION
AB Object segmentation of unknown objects with arbitrary shape in cluttered scenes is an ambitious goal in computer vision and became a great impulse with the introduction of cheap and powerful RGB-D sensors. We introduce a framework for segmenting RGB-D images where data is processed in a hierarchical fashion. After pre-clustering on pixel level parametric surface patches are estimated. Different relations between patch-pairs are calculated, which we derive from perceptual grouping principles, and support vector machine classification is employed to learn Perceptual Grouping. Finally, we show that object hypotheses generation with Graph-Cut finds a globally optimal solution and prevents wrong grouping. Our framework is able to segment objects, even if they are stacked or jumbled in cluttered scenes. We also tackle the problem of segmenting objects when they are partially occluded. The work is evaluated on publicly available object segmentation databases and also compared with state-of-the-art work of object segmentation. (C) 2013 The Authors. Published by Elsevier Inc. All rights reserved.
C1 [Richtsfeld, Andreas; Moerwald, Thomas; Prankl, Johann; Zillich, Michael; Vincze, Markus] Vienna Univ Technol, Automat & Control Inst ACIN, A-1040 Vienna, Austria.
C3 Technische Universitat Wien
RP Richtsfeld, A (corresponding author), Vienna Univ Technol, Automat & Control Inst ACIN, Gusshausstr 25-29, A-1040 Vienna, Austria.
EM ari@acin.tuwien.ac.at
FU European Community's Seventh Framework Programme [215181]; Austrian
   Science Fund (FWF) [I513-N23, TRP 139-N23]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme [FP7/2007-2013] under
   Grant agreement No. 215181 (CogX) and by the Austrian Science Fund (FWF)
   under Grant agreement No. I513-N23 (Vision@home) and No. TRP 139-N23
   (InSitu).
CR Ahmad UA, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P67
   Almaddah A, 2011, IEEE INT C INT ROBOT, P807, DOI 10.1109/IROS.2011.6048331
   Bergström N, 2011, IEEE INT C INT ROBOT, P827, DOI 10.1109/IROS.2011.6048162
   Boyer KL, 1999, COMPUT VIS IMAGE UND, V76, P1, DOI 10.1006/cviu.1999.0797
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Calderon F, 2007, LECT NOTES COMPUT SC, V4756, P321
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   Cottrell J A, 2010, CONTINUUM, P355
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fisher R.B., 1989, SURFACES OBJECTS COM
   Hager GD, 2011, INT J ROBOT RES, V30, P1477, DOI 10.1177/0278364911399340
   Koffka K, 1935, PRINCIPLES GESTALT P, V20
   KOHLER W, 1959, AM PSYCHOL, V14, P727
   Kootstra Gert, 2011, IEEE International Conference on Robotics and Automation, P3423
   Kootstra G., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P442, DOI 10.1109/ICHR.2010.5686837
   Kootstra G., 2011, SEM PERC MAPP EXPL S, P1
   LEONARDIS A, 1995, INT J COMPUT VISION, V14, P253, DOI 10.1007/BF01679685
   Metzger W, 1936, LAWS SEEING
   Mishra AK, 2012, IEEE INT CONF ROBOT, P4406, DOI 10.1109/ICRA.2012.6225107
   PALMER S, 1994, PSYCHON B REV, V1, P29, DOI 10.3758/BF03200760
   Palmer S.E., 1999, PHOTONS PHENOMENOLOG
   PALMER SE, 1992, COGNITIVE PSYCHOL, V24, P436, DOI 10.1016/0010-0285(92)90014-S
   Piegl L., 1997, COMPUT AIDED DESIGN, V28, P665
   Prankl J., 2010, P BRIT MACH VIS C
   Richtsfeld A., 2012, 2012 IEEE RSJ INT C
   Richtsfeld A, 2009, ADVANCES IN ROBOTICS RESEARCH, P99, DOI 10.1007/978-3-642-01213-6_10
   Richtsfeld Andreas., 2012, The object segmentation database (OSD)
   ROCK I, 1990, SCI AM, V263, P84, DOI 10.1038/scientificamerican1290-84
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rubin Edgar., VISUELL WAHRGENOMMEN
   Sala Pablo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562979
   Sala P, 2010, LECT NOTES COMPUT SC, V6315, P603, DOI 10.1007/978-3-642-15555-0_44
   SARKAR S, 1993, IEEE T SYST MAN CYB, V23, P382, DOI 10.1109/21.229452
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Todorovic D., 2008, Scholarpedia, V3, P5345, DOI [DOI 10.4249/SCHOLARPEDIA.5345, 10.4249/scholarpedia.5345]
   Vicente S, 2009, IEEE I CONF COMP VIS, P755, DOI 10.1109/ICCV.2009.5459287
   Wertheimer M., 1958, READINGS PERCEPTION, P115
   Wertheimer M, 1923, PSYCHOL FORSCH, V4, P301, DOI 10.1007/BF00410640
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Zillich Michael, 2007, 31 WORKSH AUSTR ASS, P25
NR 42
TC 41
Z9 45
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 64
EP 73
DI 10.1016/j.jvcir.2013.04.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900007
PM 24478571
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Liu, HX
   Song, B
   Qin, H
   Qiu, ZL
AF Liu, Haixiao
   Song, Bin
   Qin, Hao
   Qiu, Zhiliang
TI Dictionary learning based reconstruction for distributed compressed
   video sensing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed sensing; Distributed video coding; Dictionary learning;
   Undersampled correlation noise model; Distributed compressed video
   sensing; Sparse recovery; Maximum likelihood; Energy minimization
ID ALGORITHM
AB Distributed compressed video sensing (DCVS) is a framework that integrates both compressed sensing and distributed video coding characteristics to achieve a low-complexity video coding. However, how to design an efficient reconstruction by leveraging more realistic signal models that go beyond simple sparsity is still an open challenge. In this paper, we propose a novel "undersampled" correlation noise model to describe compressively sampled video signals, and present a maximum-likelihood dictionary learning based reconstruction algorithm for DCVS, in which both the correlation and sparsity constraints are included in a new probabilistic model. Moreover, the signal recovery in our algorithm is performed during the process of dictionary learning, instead of being employed as an independent task. Experimental results show that our proposal compares favorably with other existing methods, with 0.1-3.5 dB improvements in the average PSNR, and a 2-9 dB gain for non-key frames when key frames are subsampled at an increased rate. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Liu, Haixiao; Song, Bin; Qin, Hao; Qiu, Zhiliang] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
C3 Xidian University
RP Liu, HX (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
EM hxliu@stu.xidian.edu.cn; bsong@mail.xidian.edu.cn;
   hqin@mail.xidian.edu.cn; zlqiu@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61271173, 60802032];
   Fundamental Research Funds for the Central Universities [K5051201045];
   111 Project [B08038]; ISN State Key Laboratory
FX This work has been supported by the National Natural Science Foundation
   of China (Nos. 61271173 and 60802032), the Fundamental Research Funds
   for the Central Universities (No. K5051201045), the 111 Project (No.
   B08038), and also supported by the ISN State Key Laboratory.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   [Anonymous], CVX MATLAB SOFTWARE
   Brites C, 2008, IEEE T CIRC SYST VID, V18, P1177, DOI 10.1109/TCSVT.2008.924107
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen Hung-Wei, 2010, SPIE VISUAL COMMUNIC
   Do TT, 2009, IEEE IMAGE PROC, P1393, DOI 10.1109/ICIP.2009.5414631
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1537
   Gan L., 2008, P EUR SIGN PROC C
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Hung-Wei Chen, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P210, DOI 10.1109/PCS.2010.5702466
   Kang LW, 2009, INT CONF ACOUST SPEE, P1169, DOI 10.1109/ICASSP.2009.4959797
   Liu H., 2011, IEEE INT C SIGN PROC, P670
   Liu HX, 2013, IEEE SIGNAL PROC LET, V20, P315, DOI 10.1109/LSP.2013.2245893
   Liu ZR, 2011, IEEE T CIRC SYST VID, V21, P1704, DOI 10.1109/TCSVT.2011.2133890
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Prades-Nebot J., 2009, 2009 Picture Coding Symposium, PCS 2009, P1, DOI DOI 10.1109/PCS.2009.5167431
   Tosic I, 2011, IEEE T IMAGE PROCESS, V20, P921, DOI 10.1109/TIP.2010.2081679
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   Wright SJ, 2009, IEEE T SIGNAL PROCES, V57, P2479, DOI 10.1109/TSP.2009.2016892
   Xiaoran Hao, 2010, Proceedings 2010 3rd IEEE International Conference on Broadband Network & Multimedia Technology (IC-BNMT 2010), P850, DOI 10.1109/ICBNMT.2010.5705210
   Xu WB, 2010, IEEE INT SYMP CIRC S, P1145, DOI 10.1109/ISCAS.2010.5537317
   Zheng J, 2009, OPT ENG, V48, DOI 10.1117/1.3206733
NR 26
TC 12
Z9 15
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1232
EP 1242
DI 10.1016/j.jvcir.2013.08.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700002
DA 2024-07-18
ER

PT J
AU Chang, CY
   Lai, CC
   Lai, CT
   Chen, SJ
AF Chang, Chuan-Yu
   Lai, Chih-Chin
   Lai, Cheng-Ting
   Chen, Shao-Jer
TI Integrating PSONN and Boltzmann function for feature selection and
   classification of lymph nodes in ultrasound images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lymph node; Ultrasound image; Feature selection; Classification; Support
   vector machine; Particle swarm optimization; Boltzmann function; Region
   of interest (ROI)
ID DIAGNOSIS
AB Lymph nodes (LNs), part of the lymphatic system, are important in the proper functioning of the immune system. LN metastasis is an important index for staging malignant tumors. The present study proposes a system that classifies lymph nodes according to pathological change from ultrasound (US) images. Features are selected and extracted from the US images. A feature selection method that integrates the particle swarm optimization neural network (PSONN) with the Boltzmann function is proposed to select significant features. A multi-class support vector machine (SVM) is adopted to classify diseases of the LN in the region of interests (ROIs) of US images into six categories. The experimental results show that the proposed approach decreases the number of selected features and that its classification is highly accurate. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Chang, Chuan-Yu; Lai, Cheng-Ting] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
   [Lai, Chih-Chin] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
   [Chen, Shao-Jer] Buddhist Tzu Chi Gen Hosp, Dept Med Imaging, Dalin, Chia Yi, Taiwan.
C3 National Yunlin University Science & Technology; National University
   Kaohsiung; Buddhist Tzu Chi General Hospital; Dalin Tzu Chi Hospital
RP Lai, CC (corresponding author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
EM cclai@nuk.edu.tw
RI Chang, Chuan-Yu/O-2139-2013; Chang, Chuan-Yu/X-9186-2019
OI Chang, Chuan-Yu/0000-0001-9476-8130
FU National Science Council of Taiwan [NSC 94-2213-E-303-002, NSC
   96-2221-E-303-001]; Buddhist Dalin Tzu Chi General Hospital, Chia-Yi,
   Taiwan [DTCRD 96(2)-13]; department of pathology, Buddhist Dalin Tzu Chi
   General Hospital, Chia-Yi, Taiwan
FX This work was financially supported by the National Science Council of
   Taiwan under grants NSC 94-2213-E-303-002 and NSC 96-2221-E-303-001 and
   by Buddhist Dalin Tzu Chi General Hospital, Chia-Yi, Taiwan, under grant
   DTCRD 96(2)-13. The authors would like to thank the department of
   pathology, Buddhist Dalin Tzu Chi General Hospital, Chia-Yi, Taiwan, for
   their support and guidance.
CR [Anonymous], LOGIQ 700 EXP SER
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang CY, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 1, PROCEEDINGS, P55, DOI 10.1109/ISDA.2008.255
   Chuang LY, 2008, COMPUT BIOL CHEM, V32, P29, DOI 10.1016/j.compbiolchem.2007.09.005
   Chung P.-C., 2004, THESIS NATL CHENG KU
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S., 1994, NEURAL NETWORKS, V2
   Haykin S, 1999, NEURAL NETWORKS
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang CL, 2006, EXPERT SYST APPL, V31, P231, DOI 10.1016/j.eswa.2005.09.024
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kennedy J., 2001, Swarm Intelligence
   Kumon RE, 2010, GASTROINTEST ENDOSC, V71, P53, DOI 10.1016/j.gie.2009.08.027
   Lai CC, 2009, EXPERT SYST APPL, V36, P248, DOI 10.1016/j.eswa.2007.09.003
   LOH HH, 1988, IEEE T IND ELECTRON, V35, P323, DOI 10.1109/41.192665
   Meinel L Arbash, 2009, P SOC PHOTO-OPT INS, V7260
   Mougiakakou SG, 2007, ARTIF INTELL MED, V41, P25, DOI 10.1016/j.artmed.2007.05.002
   Oh IS, 2004, IEEE T PATTERN ANAL, V26, P1424, DOI 10.1109/TPAMI.2004.105
   PUDIL P, 1994, INT C PATT RECOG, P279, DOI 10.1109/ICPR.1994.576920
   Siebers S, 2009, IFMBE PROC, V25, P514, DOI 10.1007/978-3-642-03879-2_144
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   WU CM, 1992, CVGIP-GRAPH MODEL IM, V54, P407, DOI 10.1016/1049-9652(92)90025-S
   Yu S.-N., 2006, THESIS NATL CHUNG CH
   Zenk J, 2007, ULTRASOUND MED BIOL, V33, P246, DOI 10.1016/j.ultrasmedbio.2006.08.005
   Zhang JH, 2008, COMPUT BIOL MED, V38, P234, DOI 10.1016/j.compbiomed.2007.10.005
   Zhang J, 2007, COMPUT METH PROG BIO, V88, P75, DOI 10.1016/j.cmpb.2007.07.008
   Zhang JH, 2006, J ULTRAS MED, V25, P995, DOI 10.7863/jum.2006.25.8.995
   Zhou F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P610, DOI 10.1109/ICIP.2001.958567
NR 30
TC 9
Z9 9
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 23
EP 30
DI 10.1016/j.jvcir.2012.10.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600003
DA 2024-07-18
ER

PT J
AU Zhang, XJ
   Hu, YQ
   Rajan, D
AF Zhang, Xuejie
   Hu, Yiqun
   Rajan, Deepu
TI Dynamic distortion maps for image retargeting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retargeting; Image warping; Visual distortion; Geometrical
   distortion; Dynamic distortion map; Mesh optimization; Sparse linear
   system; Multi-level optimization
AB We present an image retargeting method that incorporates image content distortion into a mesh optimization process through the generation of dynamic distortion maps. The warping process is driven by the distortion produced by the warping process itself. We retarget the image through an iterative mesh optimization process to minimize the visual distortion. An adaptive distortion map is iteratively constructed to describe the visual distortion between the original image and the retargeted image. The mesh mapping from the source image to the retargeted image is optimized through an energy minimization process. The objective of the optimization is to allow the distortion produced by the retargeting process to be distributed to smooth and highly textured regions which cause less visual distortion while preserving the geometrical structure of the mesh at regions that may cause distortion after retargeting. Experimental evaluation of the algorithm is done both subjectively and objectively. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zhang, Xuejie; Rajan, Deepu] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Hu, Yiqun] Univ Western Australia, Sch Comp Sci & Software Engn, Nedlands, WA 6009, Australia.
C3 Nanyang Technological University; University of Western Australia
RP Rajan, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Block N4,Nanyang Ave, Singapore 639798, Singapore.
EM asdrajan@ntu.edu.sg
RI Rajan, Deepu/A-3666-2011; yang, zhou/KBB-6972-2024
FU Media Development Authority [NRF2008IDM-IDM004-032]
FX This research was supported by the Media Development Authority under
   grant NRF2008IDM-IDM004-032.
CR [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], 2006, P 14 ACM INT C MULT
   [Anonymous], P WORKSH DYN VIS
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Cho Taeg Sang, 2008, PROC IEEE C COMPUT V, P1
   Deselaers T, 2008, IEEE C COMPUTER VISI, P1
   Gal R., 2006, P 17 EUROGRAPHICS C, P297, DOI DOI 10.2312/EGWR/EGSR06/297-303
   Grundmann M, 2010, PROC CVPR IEEE, P569, DOI 10.1109/CVPR.2010.5540165
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Hu YQ, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P346
   Jin Y, 2010, VISUAL COMPUT, V26, P769, DOI 10.1007/s00371-010-0472-8
   Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x
   Kim JS, 2009, PROC CVPR IEEE, P1730, DOI 10.1109/CVPRW.2009.5206666
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Niu YZ, 2010, PROC CVPR IEEE, P537, DOI 10.1109/CVPR.2010.5540169
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Shamir Ariel., 2009, ACM SIGGRAPH ASIA 20, P1, DOI DOI 10.1145/1665817.1665828
   Wang Y.-S., 2010, ACM T GRAPHIC, V29, P1
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wolf L., 2007, Computer Vision and Pattern Recognition, P1
NR 26
TC 4
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 81
EP 92
DI 10.1016/j.jvcir.2012.11.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600009
DA 2024-07-18
ER

PT J
AU Chatterjee, A
   Tudu, B
   Paul, KC
AF Chatterjee, Arpitam
   Tudu, Bipan
   Paul, Kanai Ch.
TI Towards optimized binary pattern generation for grayscale digital
   halftoning: A binary particle swarm optimization (BPSO) approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital halftoning; Particle swarm optimization; Binary particle swarm
   optimization; Pattern LUT; Edge-enhanced halftone; Blue-noise
   halftoning; Green-noise halftoning; Optimized binary halftone
ID BLUE-NOISE; NEURAL-NETWORK; IMPLEMENTATION; MODULATION; VISIBILITY;
   ALGORITHM; MODELS
AB Grayscale digital halftoning produces bi-level representation of original continuous tone images. This process plays pivotal role for devices like printers, plasma panels, LCD displays, etc. The bi-level images can be considered as binary images where '0' and '1' correspond to black and white, respectively. This paper investigates potential of binary particle swarm optimization (BPSO) to generate faithful binary halftone patterns. The cost function addresses important characteristics of original images and pleasant visual appearance of halftone images. The paper also shows the application of pattern look-up-table (p-LUT) approach to address the high processing time of BPSO optimization and simple gradient-based edge enhancement for improved edge retention. Results are evaluated subjectively by statistical measures and psychovisual test. Results are evaluated objectively using image quality evaluation metrics as well. The comparisons with state-of-the-art techniques are also drawn. The evaluation results along with the comparisons show the competitive potential of the presented technique. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Chatterjee, Arpitam; Paul, Kanai Ch.] Jadavpur Univ, Dept Printing Engn, Kolkata 700032, India.
   [Tudu, Bipan] Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata 700032, India.
C3 Jadavpur University; Jadavpur University
RP Chatterjee, A (corresponding author), Jadavpur Univ, Dept Printing Engn, Kolkata 700032, India.
EM arpitamchatterjee@gmail.com
RI Mukherjee, Dr. Gunjan/JAC-1946-2023
OI Mukherjee, Dr. Gunjan/0000-0002-3959-3718; Paul, Kanai
   Chandra/0000-0002-7942-1363; tudu, bipan/0000-0001-9323-4276
FU Department of Science & Technology (DST) under the Innovative Promotion
   of University Research & Scientific Excellence (PURSE) grant, Government
   of India
FX The work has been sponsored by Department of Science & Technology (DST)
   under the Innovative Promotion of University Research & Scientific
   Excellence (PURSE) grant, Government of India.
CR Analoui M., 1992, SPIE HUMAN VISION VI, V111
   ANASTASSIOU D, 1988, ELECTRON LETT, V24, P619, DOI 10.1049/el:19880419
   [Anonymous], 2009, USC SIPI IM DAT
   Barkol O, 2010, IEEE IMAGE PROC, P2489, DOI 10.1109/ICIP.2010.5652547
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chatterjee A., 2011, SIGNAL IMAGE VIDEO P
   Chatterjee A., 2011, P IEEE INT C REC TRE, P229
   CHU CH, 1991, P SOC PHOTO-OPT INS, V1606, P470, DOI 10.1117/12.50379
   Daly S., 1987, SUBROUTINE GENERATIO
   Damera-Venkata N, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P1081, DOI 10.1109/ICIP.2001.958685
   Damera-Venkata N, 2001, IEEE T IMAGE PROCESS, V10, P104, DOI 10.1109/83.892447
   Engelbrecht A., 2007, Computational Intelligence: An Introduction, Vsecond
   ESCHBACH R, 1991, J OPT SOC AM A, V8, P1844, DOI 10.1364/JOSAA.8.001844
   Floyd R.W., 1975, INT S DIGEST TECHNIC, P36
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Huang WB, 2008, EXPERT SYST APPL, V34, P2491, DOI 10.1016/j.eswa.2007.04.013
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Jin NB, 2007, IEEE T ANTENN PROPAG, V55, P556, DOI 10.1109/TAP.2007.891552
   Kameyama K, 2009, IEICE T INF SYST, VE92D, P1354, DOI 10.1587/transinf.E92.D.1354
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Kim SH, 2002, IEEE T IMAGE PROCESS, V11, P258, DOI 10.1109/83.988959
   Lau DanielL., 2001, Modern Digital Halftoning
   Lau DL, 1999, J OPT SOC AM A, V16, P1575, DOI 10.1364/JOSAA.16.001575
   Lau DL, 2003, IEEE SIGNAL PROC MAG, V20, P28, DOI 10.1109/MSP.2003.1215229
   Lee C, 2010, IEEE T IMAGE PROCESS, V19, P435, DOI 10.1109/TIP.2009.2032941
   Levien R., 1992, IS TS 8 INT C ADV NO, P280
   Li PS, 2004, IEEE T IMAGE PROCESS, V13, P201, DOI 10.1109/tip.2003.819232
   Lui KC, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P202, DOI 10.1109/ISIMP.2004.1434035
   Mantere T, 2000, P SOC PHOTO-OPT INS, V4197, P297, DOI 10.1117/12.403775
   MITSA T, 1992, J OPT SOC AM A, V9, P1920, DOI 10.1364/JOSAA.9.001920
   NASANEN R, 1984, IEEE T SYST MAN CYB, V14, P920, DOI 10.1109/TSMC.1984.6313320
   Nayak N, 2010, COMM COM INF SC, V95, P1, DOI 10.1007/978-3-642-14825-5_1
   Ostromoukhov V, 2001, COMP GRAPH, P567, DOI 10.1145/383259.383326
   Pappas TN, 2003, IEEE SIGNAL PROC MAG, V20, P14, DOI 10.1109/MSP.2003.1215228
   Park SH, 1998, P SOC PHOTO-OPT INS, V3300, P330, DOI 10.1117/12.298296
   Rodríguez JB, 2008, IEEE T IMAGE PROCESS, V17, P1368, DOI 10.1109/TIP.2008.926145
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shen JH, 2009, SIAM REV, V51, P567, DOI 10.1137/060653317
   Shoop BL, 1997, INT J OPTOELECTRON, V11, P217
   Stucki P., 1981, MECCA MULTIPLE ERROR
   Su CY, 2010, IEEE T CONSUM ELECTR, V56, P1755, DOI 10.1109/TCE.2010.5606322
   SULLIVAN J, 1991, IEEE T SYST MAN CYB, V21, P33, DOI 10.1109/21.101134
   ULICHNEY R, 1993, P SOC PHOTO-OPT INS, V1913, P332, DOI 10.1117/12.152707
   Ulichney R., 1987, DIGITAL HALFTONING
   Waite J., 2006, TECHNOLOGY TEACH OCT, P1
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wong PW, 1997, IEEE T IMAGE PROCESS, V6, P1567, DOI 10.1109/83.641416
   Yu XM, 2004, ELECTR POW SYST RES, V71, P27, DOI 10.1016/j.epsr.2004.01.002
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 51
TC 8
Z9 8
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1245
EP 1259
DI 10.1016/j.jvcir.2012.09.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300008
DA 2024-07-18
ER

PT J
AU Deng, ZP
   Chan, YL
   Jia, KB
   Fu, CH
   Siu, WC
AF Deng, Zhi-Pin
   Chan, Yui-Lam
   Jia, Ke-Bin
   Fu, Chang-Hong
   Siu, Wan-Chi
TI Iterative search strategy with selective bi-directional prediction for
   low complexity multiview video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3DTV; Multiview video coding; Disparity estimation; Motion estimation;
   Bi-directional prediction; Hierarchical B picture; Adaptive search
   range; JMVC
ID MOTION ESTIMATION; FAST DISPARITY; ALGORITHM; IMAGE
AB The multiview video coding (MVC) extension of H.264/AVC is the emerging standard for compression of impressive 3D and free-viewpoint video. The coding structure in MVC adopts motion and disparity estimation to exploit temporal and inter-view dependencies in MVC. It results in a considerable increase in encoding complexity. Most of the computational burden comes from uni-directional and bi-directional prediction. In this paper, an iterative search strategy is designed to speed up the uni-directional prediction in MVC. It can work with an adaptive search range adjustment through a confidence measure of a loop constraint to obtain both motion and disparity vectors jointly. Furthermore, a selective bi-directional prediction algorithm is proposed to enhance the coding performance by analyzing the statistical characteristics of bi-directional prediction in MVC. Experimental results demonstrate that, by using the proposed fast search, the temporal and inter-view redundancies of multiview video can be eliminated sufficiently with low complexity. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Deng, Zhi-Pin; Chan, Yui-Lam; Fu, Chang-Hong; Siu, Wan-Chi] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
   [Deng, Zhi-Pin; Jia, Ke-Bin] Beijing Univ Technol, Dept Elect Informat & Control Engn, Beijing, Peoples R China.
C3 Hong Kong Polytechnic University; Beijing University of Technology
RP Chan, YL (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Kowloon, Hong Kong, Peoples R China.
EM zhipindeng@gmail.com; enylchan@polyu.edu.hk; kebinj@bjut.edu.cn;
   enchfu@hotmail.com; enwcsiu@polyu.edu.hk
RI Fu, Chang-Hong/AAR-7176-2021; Chan, Yui-Lam/C-3799-2014
OI Fu, Chang-Hong/0000-0001-8221-2311; Chan, Yui-Lam/0000-0002-1473-094X
FU Centre for Signal Processing, Department of EIE, PolyU; Internal
   Competitive Research Grant, PolyU, Hong Kong, China [PolyU G-YJ27];
   National Natural Science Foundation of China [30970780]
FX The work described in this paper is partially supported by the Centre
   for Signal Processing, Department of EIE, PolyU, a grant from the
   Internal Competitive Research Grant, PolyU, Hong Kong, China (PolyU
   G-YJ27), and a National Natural Science Foundation of China under Grant
   No. 30970780.
CR Bjontegaard G., 2001, Document VCEG-M33
   Chan YL, 2001, IEEE T IMAGE PROCESS, V10, P1223, DOI 10.1109/83.935038
   Daribo I, 2010, J VIS COMMUN IMAGE R, V21, P487, DOI 10.1016/j.jvcir.2009.12.004
   Deng Z.-P., 2010, INT C TRUE VIS CAPT
   Ding LF, 2008, IEEE T MULTIMEDIA, V10, P1553, DOI 10.1109/TMM.2008.2007314
   Flierl M, 2007, IEEE T CIRC SYST VID, V17, P1474, DOI 10.1109/TCSVT.2007.903780
   Ho Y.S., 2007, 14 INT WORKSH SYST S, P479
   Huo H. Yang. J., 2007, JVTV071
   Huo JY, 2009, IEEE INT SYMP CIRC S, P2593, DOI 10.1109/ISCAS.2009.5118332
   Kim Y, 2005, IEEE T CONSUM ELECTR, V51, P1227, DOI 10.1109/TCE.2005.1561849
   Kim Y, 2007, IEEE T CONSUM ELECTR, V53, P712, DOI 10.1109/TCE.2007.381750
   Lai P., 2006, P SPIE VIS COMMUN IM
   Lee S.-H., 2006, JVTU040
   Li XM, 2008, IEEE T CONSUM ELECTR, V54, P2037, DOI 10.1109/TCE.2008.4711270
   Lin HC, 2010, IEEE INT SYMP CIRC S, P113, DOI 10.1109/ISCAS.2010.5536999
   Lin JP, 2009, IEEE INT SYMP CIRC S, P2589, DOI 10.1109/ISCAS.2009.5118331
   Lu JB, 2007, IEEE T CIRC SYST VID, V17, P737, DOI 10.1109/TCSVT.2007.896659
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   MPEG, 2005, N7327 MPEG
   MPEG, 2005, N6909 MPEG
   Pandit P., 2008, JVTAA212
   Shen LQ, 2010, IEEE T CIRC SYST VID, V20, P925, DOI 10.1109/TCSVT.2010.2045910
   Shen LQ, 2009, IEEE T BROADCAST, V55, P761, DOI 10.1109/TBC.2009.2030453
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Su Y., 2006, JVTU211
   Sullivan G.J., 2009, H264 ITUT
   Vetro A., 2005, M12077 MPEG
   Wang RS, 2000, IEEE T CIRC SYST VID, V10, P397, DOI 10.1109/76.836284
   WU SW, 1994, IEEE T IMAGE PROCESS, V3, P684, DOI 10.1109/83.334976
   Xu X., 2008, 15 IEEE INT C IM PRO, P2000
   Zhu W, 2010, IEEE T CONSUM ELECTR, V56, P957, DOI 10.1109/TCE.2010.5506026
NR 31
TC 13
Z9 15
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 522
EP 534
DI 10.1016/j.jvcir.2012.01.016
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800011
DA 2024-07-18
ER

PT J
AU Tsang, SH
   Chan, YL
   Siu, WC
AF Tsang, Sik-Ho
   Chan, Yui-Lam
   Siu, Wan-Chi
TI Flash scene video coding using weighted prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Brightness variation; Flash scene; H.264; Histogram difference;
   Illumination change; Motion estimation; Scene change detection; Weighted
   prediction
ID PARAMETER-ESTIMATION; COMPENSATION
AB A novel algorithm for coding flash scenes is proposed. In principle, flash scenes can be detected by analyzing the histogram differences between frames. The proposed algorithm then suggests an adaptive coding order technique for increasing the efficiency of video coding by taking account of characteristics of flash scenes in video contents. The use of adaptive coding technique also benefits to enhance the accuracy of derived motion vectors for determination of weighting parameter sets. Experimental results show that a significant improvement of coding performance in terms of bitrate and PSNR can be achieved in comparison with the conventional weighted prediction algorithms. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Tsang, Sik-Ho; Chan, Yui-Lam; Siu, Wan-Chi] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Chan, YL (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
EM enylchan@polyu.edu.hk
RI Chan, Yui-Lam/C-3799-2014
OI Chan, Yui-Lam/0000-0002-1473-094X; TSANG, Sik Ho/0000-0002-8578-0696
FU Centre for Signal Processing; Department of EIE, PolyU [PolyU G-YJ27]
FX The work described in this paper is partially supported by the Centre
   for Signal Processing and a grant from the Internal Competitive Research
   Grant, Department of EIE, PolyU (PolyU G-YJ27).
CR [Anonymous], 2007, H264 ITUT
   Aoki H, 2008, IEEE IMAGE PROC, P2112, DOI 10.1109/ICIP.2008.4712204
   Bjontegaard G., 2001, ITUTQ6SG16
   Boyce JM, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P789
   Chen QQ, 2007, IEEE INT SYMP CIRC S, P989, DOI 10.1109/ISCAS.2007.378135
   Joint Video Team (JVT), REF SOFTW JOINT MOD
   Kato H, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P27
   Kim JH, 2007, IEEE T CIRC SYST VID, V17, P1519, DOI 10.1109/TCSVT.2007.909976
   Kim SH, 2003, IEEE T CIRC SYST VID, V13, P289, DOI 10.1109/TCSVT.2003.811359
   Qian XM, 2006, IEEE T CIRC SYST VID, V16, P1245, DOI 10.1109/TCSVT.2006.881858
   Sprljan N., 2009, JTC1SC29WG11 ISOIEC
   Tsang SH, 2010, SIGMAP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATION, P118
   Tsang SH, 2010, IEEE IMAGE PROC, P2069, DOI 10.1109/ICIP.2010.5654032
   Wang J., 2005, IEEE 2nd International Conference on Mobile Technology, Applications and Systems, P1
   Zhang R, 2008, IEEE IMAGE PROC, P2836
NR 15
TC 1
Z9 1
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2012
VL 23
IS 2
BP 264
EP 270
DI 10.1016/j.jvcir.2011.11.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 891EB
UT WOS:000300198900004
DA 2024-07-18
ER

PT J
AU Joo, H
   Yoon, C
   Um, TW
   Song, H
AF Joo, Hyunchul
   Yoon, Changwoo
   Um, Tai-Won
   Song, Hwangjun
TI A novel fountain code-based mobile IPTV multicast system architecture
   over WiMAX network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mobile IPTV; WiMAX; Fountain code; Channel zapping time; Processing
   complexity; Resource usage; Decoding failure rate; Quality of
   experience; Genetic algorithm
ID CHANNEL CONTROL ALGORITHM; VIDEO MULTICAST; SERVICES; LAYER; FEC;
   ADAPTATION; BROADCAST
AB In this paper, we present a novel fountain code-based mobile IPTV multicast system architecture over WiMAX network. In the proposed system, the transmission algorithm at a base station determines the control parameters of a fountain-encoded IPTV multicast stream adaptively to the wireless link states of subscribers in order to provide a stable IPTV service with minimum resource usage on WiMAX network, and the channel grouping algorithm at a server makes near-optimal channel grouping based on channel selection preferences to pursue an effective tradeoff between the channel zapping time and the processing complexity of a subscriber. Finally, experimental results are provided to show the performance of the proposed system. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Joo, Hyunchul; Song, Hwangjun] POSTECH Pohang Univ Sci & Technol, Pohang 790784, South Korea.
   [Yoon, Changwoo; Um, Tai-Won] ETRI, Broadcasting & Telecommun Convergence Res Lab, Taejon 305700, South Korea.
C3 Pohang University of Science & Technology (POSTECH); Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Song, H (corresponding author), POSTECH Pohang Univ Sci & Technol, Pohang 790784, South Korea.
EM hwangjun@postech.ac.kr
FU KCC/MKE/KEIT [KI002183]; MKE(The Ministry of Knowledge Economy), Korea,
   under the ITRC(Information Technology Research Center)
   [NIPA-2011-(C1090-1111-0004)]
FX This work was supported by the IT R&D program of KCC/MKE/KEIT [KI002183,
   Development of Open-IPTV platform Technologies for IPTV Convergence
   Service and Content Sharing] and the MKE(The Ministry of Knowledge
   Economy), Korea, under the ITRC(Information Technology Research Center)
   support program supervised by the NIPA(National IT Industry Promotion
   Agency) (NIPA-2011-(C1090-1111-0004)).
CR *3GPP2, 2004, AS00190 3GPP2 TSGA
   Alay Ö, 2010, MOBILE NETW APPL, V15, P425, DOI 10.1007/s11036-009-0202-5
   [Anonymous], 2005, 23246 3GPP TS
   [Anonymous], 1997, M1225 ITUR
   [Anonymous], 2006, 26346 3GPP TS
   [Anonymous], 2004, IEEE Standard for Local and Metropolitan Area Networks Part 16: Air Interface for Fixed Broadband Wireless Access Systems, P1
   [Anonymous], 2004, Wiley InterScience electronic collection.
   Astély D, 2009, IEEE COMMUN MAG, V47, P44, DOI 10.1109/MCOM.2009.4907406
   Boyce JM, 2005, IEEE ICCE, P1
   Cho C, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P971
   Choi M, 2010, COMPUT COMMUN, V33, P2271, DOI 10.1016/j.comcom.2010.06.018
   Courtade T., 2009, IEEE International Conference on Communications, ICC, P1
   Eiben A. E., 2015, INTRO EVOLUTIONARY C
   Erceg V, 1999, IEEE J SEL AREA COMM, V17, P1205, DOI 10.1109/49.778178
   *ETSI, 2004, 302304 ETSI EN, V1
   *ETSI, 2007, ETSITR102542V131
   HARRIS A, 2005, ENABLING IPTV WHAT C
   HOROWITZ E, 2003, FUNDAMENTALS COMPUTE
   Hou F, 2009, IEEE T WIREL COMMUN, V8, P1508, DOI 10.1109/TWC.2009.080417
   *IEEE 802 16 TGE, 2004, 80216ED4 IEEE 802 16
   Jiang T, 2007, IEEE COMMUN MAG, V45, P78, DOI 10.1109/MCOM.2007.4290318
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   Joo H, 2010, J VIS COMMUN IMAGE R, V21, P89, DOI 10.1016/j.jvcir.2009.04.004
   *JVT, JOINT VID TEAM JVT R
   KIM J, 2006, INT C ADV COMM TECHN, V1, P465
   Lee DB, 2007, IEEE T BROADCAST, V53, P789, DOI 10.1109/TBC.2007.910919
   Lee DB, 2010, J VIS COMMUN IMAGE R, V21, P245, DOI 10.1016/j.jvcir.2010.01.002
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Luby M, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4511656
   MacKay DJC, 2005, IEE P-COMMUN, V152, P1062, DOI 10.1049/ip-com:20050237
   MARFIA G, 2011, IFIP INT C NEW TECHN
   Mladenov T, 2010, IEEE T CONSUM ELECTR, V56, P1264, DOI 10.1109/TCE.2010.5606257
   Nafaa A, 2008, IEEE COMMUN MAG, V46, P72, DOI 10.1109/MCOM.2008.4427233
   Nikaein N, 2000, IEEE ICC, P954, DOI 10.1109/ICC.2000.853639
   OPNET modeler, OPNET MOD
   Park Y, 2006, CONSUM COMM NETWORK, P178
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   She J, 2007, IEEE COMMUN MAG, V45, P87, DOI 10.1109/MCOM.2007.4290319
   SHOKROLLAHI A, 2003, DR200306001 DIG FOUN
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Siebert P, 2009, IEEE T BROADCAST, V55, P407, DOI 10.1109/TBC.2008.2012019
   Stallings W., 2004, DATA COMPUTER COMMUN, V7th
   Wang JF, 2007, IEEE J SEL AREA COMM, V25, P712, DOI 10.1109/JSAC.2007.070508
   Won H, 2009, IEEE T WIREL COMMUN, V8, P4540, DOI 10.1109/TWC.2009.080330
   ZFZAL J, 2006, J MULTIMEDIA, V1, P25
   ARCHITECTURE MICROSO
NR 46
TC 5
Z9 7
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 161
EP 172
DI 10.1016/j.jvcir.2011.09.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100016
DA 2024-07-18
ER

PT J
AU Han, PY
   Jin, ATB
   Ann, TK
AF Han, Pang Ying
   Jin, Andrew Teoh Beng
   Ann, Toh Kar
TI Kernel Discriminant Embedding in face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Dimensionality reduction; Kernel trick; Graph
   Embedding; Fisher's criterion; Nonlinear structure; Geometrical
   structure; Discriminant projection
ID EIGENFACES
AB In this paper, we present a novel and effective feature extraction technique for face recognition. The proposed technique incorporates a kernel trick with Graph Embedding and the Fisher's criterion which we call it as Kernel Discriminant Embedding (KDE). The proposed technique projects the original face samples onto a low dimensional subspace such that the within-class face samples are minimized and the between-class face samples are maximized based on Fisher's criterion. The implementation of kernel trick and Graph Embedding criterion on the proposed technique reveals the underlying structure of data. Our experimental results on face recognition using ORL, FRGC and FERET databases validate the effectiveness of KDE for face feature extraction. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Jin, Andrew Teoh Beng] Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul 120749, South Korea.
   [Han, Pang Ying] Multimedia Univ, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
   [Jin, Andrew Teoh Beng] Sunway Univ, Bandar Sunway 46150, Pj Selangor, Malaysia.
C3 Yonsei University; Multimedia University; Sunway University
RP Jin, ATB (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, C613 Sinchon Dong, Seoul 120749, South Korea.
EM yhpang@mmu.edu.my; bjteoh@yonsei.ac.kr; katoh@yonsei.ac.kr
RI Pang, Ying Han/AGW-5132-2022; Teoh, Andrew Beng Jin/F-4422-2010
OI Teoh, Andrew Beng Jin/0000-0001-5063-9484; PANG, YING
   HAN/0000-0002-3781-6623
FU Korea Science and Engineering Foundation (KOSEF) through the Biometrics
   Engineering Research Center (BERC) at Yonsei University [R11200210508
   0020]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) through the Biometrics Engineering Research Center (BERC) at
   Yonsei University (Grant No. R11200210508 0020 (2010)).
CR [Anonymous], 2007, P 20 INT JOINT C ART
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BELKIN M, 2001, P C ADV NEURAL INFOR, V15, P585
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ku YS, 2009, OPT ENG, V48, DOI 10.1117/1.3275449
   Liu QS, 2004, IEEE T CIRC SYST VID, V14, P42, DOI 10.1109/TCSVT.2003.818352
   PANG YH, 2009, ELSEVIER J VIS COMMU, V20, P532
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Zeng XH, 2007, LECT NOTES ARTIF INT, V4632, P81
NR 17
TC 6
Z9 7
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 634
EP 642
DI 10.1016/j.jvcir.2011.07.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800006
DA 2024-07-18
ER

PT J
AU Lu, C
   Singh, M
   Cheng, I
   Basu, A
   Mandal, M
AF Lu, Cheng
   Singh, Meghna
   Cheng, Irene
   Basu, Anup
   Mandal, Mrinal
TI Efficient video sequences alignment using unbiased bidirectional dynamic
   time warping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video alignment; Video synchronization; Temporal registration; Symmetric
   alignment; Temporal offset; Dynamic time warping; Symmetric transfer
   error; MRI
AB In this paper, we propose an efficient technique to synchronize video sequences of events that are acquired via uncalibrated cameras at unknown and dynamically varying temporal offsets. Unlike other existing techniques that just take unidirectional alignment into consideration, the proposed technique considers symmetric alignments and compute the optimal alignment. We also establish sub-frame accuracy video alignment. The advantages of our approach are validated by tests conducted on several pairs of real and synthetic sequences. We present qualitative and quantitative comparisons with other existing techniques. A unique application of this work in generating high-resolution 4D MRI data from multiple low-resolution MRI scans is described. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Lu, Cheng; Singh, Meghna; Mandal, Mrinal] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   [Cheng, Irene; Basu, Anup] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2V4, Canada.
C3 University of Alberta; University of Alberta
RP Mandal, M (corresponding author), Univ Alberta, Dept Elect & Comp Engn, 2nd Floor,ECERF Bldg, Edmonton, AB T6G 2V4, Canada.
EM lcheng4@ualberta.ca; meghna@ece.ualberta.ca; locheng@ualberta.ca;
   basu@ualberta.ca; mandal@e-ce.ualberta.ca
RI Lu, Cheng/AAH-1606-2021
OI Lu, Cheng/0000-0002-7651-3924
CR CARCERONI RL, 2004, IEEE P CVPR, V1, P746
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   DAI C, 2006, P INT C IM PROC, V1, P501
   Giese MA, 2000, INT J COMPUT VISION, V38, P59, DOI 10.1023/A:1008118801668
   Hartley R., 2004, Multiple view geometry in computer vision, V2nd, P87, DOI DOI 10.2277/0521540518
   Hess R, 2007, PROC CVPR IEEE, P154
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lei C, 2006, IEEE T IMAGE PROCESS, V15, P2473, DOI 10.1109/TIP.2006.877438
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Perperidis D., 2004, MED IMAGE COMPUTING, V3216, P441
   Pooley DW, 2003, IEEE IMAGE PROC, P413
   RAO C, 2003, P INT C COMP VIS, V1, P939
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Singh M, 2008, LECT NOTES COMPUT SC, V5303, P554, DOI 10.1007/978-3-540-88688-4_41
   Singh M, 2007, IEEE T MULTIMEDIA, V9, P1004, DOI 10.1109/TMM.2007.898937
   Tresadern P., 2003, Proceedings of the 14th British Machine Vision Conference, P629
   TUYTELAARS T, 2004, IEEE COMP SOC C COMP, V1, P762
   Wolf L, 2006, INT J COMPUT VISION, V68, P43, DOI 10.1007/s11263-005-4841-0
NR 18
TC 4
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 606
EP 614
DI 10.1016/j.jvcir.2011.06.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800003
DA 2024-07-18
ER

PT J
AU Chuang, CH
   Chen, BN
   Chang, CC
   Cheng, SC
AF Chuang, Chi-Han
   Chen, Bob-Nan
   Chang, Chin-Chun
   Cheng, Shyi-Chyi
TI Computation-aware fast motion estimation for H.264/AVC using image
   indexing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fast block matching; Image indexing; H.264/AVC; Motion estimation;
   Computation awareness; Inter mode decision; Multilevel block indexing;
   Multiple-frame referencing
ID SUCCESSIVE ELIMINATION ALGORITHM; SEARCH ALGORITHM; SCHEME
AB The key to designing a real-time video coding system is efficient motion estimation, which reduces temporal redundancies. The motion estimation of the H.264/AVC coding standard can use multiple references and multiple block sizes to improve rate-distortion performance. The computational complexity of H.264 is linearly dependent on the number of allowed reference frames and block sizes using a full exhaustive search. Many fast block-matching algorithms reduce the computational complexity of motion estimation by carefully designing search patterns with different shapes or sizes, which have a significant impact on the search speed and distortion performance. However, the search speed and the distortion performance often conflict with each other in these methods, and their high computational complexity incurs a large amount of memory access. This paper presents a novel block-matching scheme with image indexing, which sets a proper priority list of search points, to encode a H.264 video sequence. This study also proposes a computation-aware motion estimation method for the H.264/AVC. Experimental results show that the proposed method achieves good performance and offers a new way to design a cost-effective real-time video coding system. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chuang, Chi-Han; Chen, Bob-Nan; Chang, Chin-Chun; Cheng, Shyi-Chyi] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung 20224, Taiwan.
C3 National Taiwan Ocean University
RP Cheng, SC (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, 2 Pei Ning Rd, Keelung 20224, Taiwan.
EM csc@mail.ntou.edu.tw
FU National Science Council, Taiwan [NSC 97-2221-E-019-032]
FX This work was supported in part by National Science Council, Taiwan
   under Grant NSC 97-2221-E-019-032.
CR [Anonymous], 1996, 138182 ISOIEC
   [Anonymous], 2004, JOINT VIDEO TEAM REF
   [Anonymous], 144962 ISOIEC
   Chen CY, 2006, IEEE T MULTIMEDIA, V8, P698, DOI 10.1109/TMM.2006.876296
   Chen MJ, 2006, IEEE T MULTIMEDIA, V8, P478, DOI 10.1109/TMM.2006.870739
   CHEN MJ, 1994, IEEE T CIRC SYST VID, V4, P504, DOI 10.1109/76.322998
   Cheng SC, 2003, IMAGE VISION COMPUT, V21, P809, DOI 10.1016/S0262-8856(03)00095-7
   Cheng SC, 2006, J VIS COMMUN IMAGE R, V17, P42, DOI 10.1016/j.jvcir.2005.08.006
   Cho C.-Y., 2006, P 31 IEEE INT C AC S, VII, P565
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   González-Díaz I, 2008, IEEE T CIRC SYST VID, V18, P1369, DOI 10.1109/TCSVT.2008.2004917
   Huang SY, 2006, J VIS COMMUN IMAGE R, V17, P767, DOI 10.1016/j.jvcir.2005.07.002
   Huang YW, 2006, IEEE T CIRC SYST VID, V16, P507, DOI 10.1109/TCSVT.2006.872783
   *ITU T, 2003, H264 ITUT
   *ITU T, 1998, H263 ITUT
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Jakubowski M, 2007, OPTO-ELECTRON REV, V15, P118, DOI 10.2478/s11772-007-0008-6
   Joch A, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P501
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Kuo TY, 2006, IEEE T CIRC SYST VID, V16, P1185, DOI 10.1109/TCSVT.2006.883512
   Lai JZC, 2007, PATTERN RECOGN, V40, P351, DOI 10.1016/j.patcog.2006.04.024
   Lai JZC, 2004, IEEE T IMAGE PROCESS, V13, P1554, DOI 10.1109/TIP.2004.837559
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Liu ZY, 2008, IEICE T FUND ELECTR, VE91A, P1944, DOI 10.1093/ietfec/e91-a.8.1944
   Mak CM, 2008, IEEE T CIRC SYST VID, V18, P735, DOI 10.1109/TCSVT.2008.918790
   McNames J, 2001, IEEE T PATTERN ANAL, V23, P964, DOI 10.1109/34.955110
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Spiegel M.R., 1981, MATH HDB FORMULAS TA
   Su YP, 2006, IEEE T CIRC SYST VID, V16, P447, DOI 10.1109/TCSVT.2006.869970
   Tai PL, 2003, IEEE T CIRC SYST VID, V13, P901, DOI 10.1109/TCSVT.2003.816510
   Theodridis S., 2003, PATTERN RECOGNITION
   Tsai TH, 2006, IEEE T CIRC SYST VID, V16, P1542, DOI 10.1109/TCSVT.2006.885726
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wei SD, 2006, IEEE IMAGE PROC, P2361, DOI 10.1109/ICIP.2006.312900
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
   Xu XZ, 2008, IEEE T CIRC SYST VID, V18, P285, DOI 10.1109/TCSVT.2008.918122
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 39
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 451
EP 464
DI 10.1016/j.jvcir.2011.05.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000001
DA 2024-07-18
ER

PT J
AU Hu, WC
   Yang, CY
   Huang, DY
AF Hu, Wu-Chih
   Yang, Ching-Yu
   Huang, Deng-Yuan
TI Robust real-time ship detection and tracking for visual surveillance of
   cage aquaculture
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual surveillance; Cage aquaculture; Ocean farming; Wave ripple
   removal; Fast 4-connected component labeling; Improved full search
   algorithm; Adaptive template block matching; Ship detection and tracking
ID VIDEO; PEOPLE; MOTION; IMAGE; MODEL
AB This paper presents a visual surveillance scheme for cage aquaculture that automatically detects and tracks ships (intruders). For ship detection and tracking, we propose a robust foreground detection and background updating to effectively reduce the influence of sea waves. Furthermore, we propose a fast 4-connected component labeling method to greatly reduce the computational cost associated with the conventional method. Wave ripples are removed from regions with ships. An improved full search algorithm based on adaptive template block matching with a wave ripple removal is presented to quickly, accurately, and reliably track overlapping ships whose scales change. Experimental results demonstrate that the proposed schemes have outstanding performance in ship detection and tracking. The proposed visual surveillance system for cage aquaculture triggers an alarm if intruders are detected. The security of cage aquaculture can be increased. The proposed visual surveillance can thus greatly help the popularization of cage aquaculture for ocean farming. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hu, Wu-Chih; Yang, Ching-Yu] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Makung City, Penghu, Taiwan.
   [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, Dacun, Changhua, Taiwan.
C3 National Penghu University of Science & Technology; Da Yeh University
RP Hu, WC (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Makung City, Penghu, Taiwan.
EM wchu@npu.edu.tw; chingyu@npu.edu.tw; kevin@mail.dyu.edu.tw
FU National Science Council, Taiwan [NSC97-2221-E-346-004]
FX This paper was supported by the National Science Council, Taiwan, under
   Grant No. NSC97-2221-E-346-004. The author wishes to express the
   appreciation to Mr. Jung-Fu Hsu and Chung-Yuan Su for their help with
   the experiments. The authors also gratefully acknowledge the helpful
   comments and suggestions of the reviewers, which have improved the
   presentation.
CR Carmona EJ, 2008, PATTERN RECOGN LETT, V29, P272, DOI 10.1016/j.patrec.2007.10.007
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Chen T.H., 2007, P 2 INT C INN COMP I
   Chen T.Y., 2008, P 4 INT C INT INF HI, P655
   Chen TY, 2009, INT J INNOV COMPUT I, V5, P785
   Lin CT, 2006, IEEE SYS MAN CYBERN, P2057, DOI 10.1109/ICSMC.2006.385163
   Dahmane M, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P136, DOI 10.1109/CRV.2005.65
   Fahn C.S., 2005, P 2005 NAT COMP S TA
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hu W.-C., 2010, ICIC EXPRESS LETT B, V1, P45
   HU W-C., 2011, Journal of Information Hiding and Multimedia Signal Processing, V2, P123
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hu WC, 2010, INT J INNOV COMPUT I, V6, P5115
   Hu WC, 2009, INT J INNOV COMPUT I, V5, P4075
   Huang DY, 2009, PATTERN RECOGN LETT, V30, P275, DOI 10.1016/j.patrec.2008.10.003
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Liao HYM, 2006, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2006.1692634
   Luo QM, 2006, IRI 2006: PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P432
   Poppe C, 2009, J VIS COMMUN IMAGE R, V20, P428, DOI 10.1016/j.jvcir.2009.05.001
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Remagnino P, 2004, PATTERN RECOGN, V37, P675, DOI 10.1016/j.patcog.2003.09.017
   Robert-Inacio F., 2007, P IMAGE VISION COMPU, P169
   VEERARAGHAVAN H., 2007, Proc. IEEE Conf. Computer Vision Pattern Recognition, P1
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Zheng WL, 2009, J VIS COMMUN IMAGE R, V20, P9, DOI 10.1016/j.jvcir.2008.09.001
NR 25
TC 51
Z9 58
U1 1
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 543
EP 556
DI 10.1016/j.jvcir.2011.03.009
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000009
DA 2024-07-18
ER

PT J
AU Wang, XY
   Li, FP
   Wang, SG
AF Wang Xing-yuan
   Li Fan-ping
   Wang Shu-guo
TI Fractal image compression based on spatial correlation and hybrid
   genetic algorithm
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fractal image compression; Block coding; PIFS; Spatial correlation;
   Hybrid genetic algorithm; Simulated annealing; Neighborhood; Dyadic
   mutation operator
AB In order to solve the high complexity of the conventional encoding scheme for fractal image compression, a spatial correlation hybrid genetic algorithm based on the characteristics of fractal and partitioned iterated function system (PITS) is proposed in this paper. There are two stages for the algorithm: (I) Make use of spatial correlation in images for both range and domain pool to exploit local optima. (2) Adopt simulated annealing genetic algorithm (SAGA) to explore the global optima if the local optima are not satisfied. In order to avoid premature convergence, the algorithm adopt dyadic mutation operator to take place of the traditional one. Experiment results show that the algorithm convergent rapidly. At the premise of good quality of the reconstructed image, the algorithm saved the encoding time and obtained high compression ratio. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Wang Xing-yuan; Li Fan-ping; Wang Shu-guo] Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Wang, XY (corresponding author), Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116024, Peoples R China.
EM wangxy@dlut.edu.cn
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [60573172]; Superior
   University doctor subject special scientific research foundation of
   China [20070141014]; National Natural Science Foundation of Liaoning
   province [20082165]
FX This research is supported by the National Natural Science Foundation of
   China (No. 60573172), the Superior University doctor subject special
   scientific research foundation of China (No. 20070141014) and the
   National Natural Science Foundation of Liaoning province (No. 20082165).
CR [Anonymous], 2002, Genetic Algorithm: Theory, Application, and Software Implementation
   BARNSLEY MF, 1989, CONSTR APPROX, V5, P3, DOI 10.1007/BF01889596
   BARNSLEY MF, 1985, P ROY SOC LOND A MAT, V399, P243, DOI 10.1098/rspa.1985.0057
   Barnsley MF., 1993, Fractals Everywhere
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Mitra SK, 1998, IEEE T IMAGE PROCESS, V7, P586, DOI 10.1109/83.663505
   PEITGEN HO, 1992, CHAO FRACTALS NEW FR
   POTTS JC, 1994, IEEE T SYST MAN CYB, V24, P73, DOI 10.1109/21.259687
   Torres L., 1996, VIDEO CODING 2 GENER
   Truong TK, 2004, CHAOS SOLITON FRACT, V22, P1071, DOI 10.1016/j.chaos.2004.03.015
   VENCES L, 1997, P COMPUTACION VISUAL, P35
   Wang Z, 2000, SIGNAL PROCESS-IMAGE, V15, P767, DOI 10.1016/S0923-5965(99)00018-1
   Wu MS, 2006, CHAOS SOLITON FRACT, V28, P497, DOI 10.1016/j.chaos.2005.07.004
NR 16
TC 42
Z9 46
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 505
EP 510
DI 10.1016/j.jvcir.2009.07.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400001
DA 2024-07-18
ER

PT J
AU Lai, CH
   Wu, JL
AF Lai, Chao-Hung
   Wu, Jiunn-Lin
TI Robust image watermarking against local geometric attacks using
   multiscale block matching method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking: Local geometric attack; Stirmark; Deformable mesh
   model; Image registration; Resynchronization; Multiscale block matching;
   AM based watermarking
ID DIGITAL WATERMARKING; REGISTRATION
AB This paper presents an image registration algorithm against the local geometric attack which is recently considered as the public enemy of most watermarking schemes. The watermark is embedded and retrieved using an amplitude modulation watermarking scheme. This work gives consideration to all the fidelity, robustness, and capacity. Moreover, the watermark bits act as implicit anchors to help correct local geometric distortions. In the proposed registration algorithm, an automatically multi-scaled neighborhood-matching approach is used to quickly and efficiently estimate local displacement, and a multi-resolution framework is superimposed to estimate both small and large local geometric distortions. Experimental results demonstrate the robustness and efficiency of the proposed algorithm. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Lai, Chao-Hung; Wu, Jiunn-Lin] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 National Chung Hsing University
RP Wu, JL (corresponding author), Natl Chung Hsing Univ, Dept Comp Sci & Engn, 250 Kuo Kuang Rd, Taichung 402, Taiwan.
EM jlwu@cs.nchu.edu.tw
OI Wu, Jiunn-Lin/0000-0003-4046-8196
FU National Science Council [NSC 952221-E-005-064]
FX The authors would like to thank the anonymous reviewers. Their comments
   helped improve this manuscript. This research is partially supported by
   National Science Council Grant NSC 952221-E-005-064.
CR ALATTAR AM, 2003, P INT S CIRCUITS SYS, V2, P928
   Alghoniemy M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1291, DOI 10.1109/ICME.2000.871003
   Amornraksa T, 2006, IMAGE VISION COMPUT, V24, P111, DOI 10.1016/j.imavis.2005.09.018
   [Anonymous], STIRMARK 4 0
   [Anonymous], 1883, Journal des Sciences Militaires
   Barni M, 1999, P SOC PHOTO-OPT INS, V3657, P31, DOI 10.1117/12.344689
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Coltuc D, 2002, PROC SPIE, V4675, P701, DOI 10.1117/12.465331
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Dugelay JL, 2006, IEEE T IMAGE PROCESS, V15, P2831, DOI 10.1109/TIP.2006.877311
   Dugelay JL, 2000, PROC SPIE, V3971, P338, DOI 10.1117/12.384988
   FENG D, 2007, IEEE COMPUT GRAPH, V27, P41
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   JIANG D, 2005, P 3 AUSTR INF SEC WO, V44, P81
   Kerckhoffs A., 1883, J. des Sci. militaires, V1, P5
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Lichtenauer J, 2003, PROC SPIE, V5020, P203, DOI 10.1117/12.503186
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Loo P, 2001, PROC SPIE, V4314, P606, DOI 10.1117/12.435445
   Periaswamy S, 2003, IEEE T MED IMAGING, V22, P865, DOI 10.1109/TMI.2003.815069
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Shen DG, 1997, IEEE T PATTERN ANAL, V19, P431, DOI 10.1109/34.589203
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Shirley P., 2000, REALISTIC RAY TRACIN
   SOLACHIDIS V, 2000, P EUR SIGN PROC C, V4
   Suhail MA, 2003, IEEE T INSTRUM MEAS, V52, P1640, DOI 10.1109/TIM.2003.817155
   Tsang KF, 2001, PROC SPIE, V4314, P385, DOI 10.1117/12.435422
   Voloshynovskiy S, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P999, DOI 10.1109/ICIP.2001.958294
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Xia XG, 1998, OPT EXPRESS, V3, P497, DOI 10.1364/OE.3.000497
   Xiang SJ, 2008, IEEE T CIRC SYST VID, V18, P777, DOI 10.1109/TCSVT.2008.918843
   2007, ULEAD PHOTOIMPACT 12
NR 33
TC 15
Z9 15
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 377
EP 388
DI 10.1016/j.jvcir.2009.03.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900002
DA 2024-07-18
ER

PT J
AU Shen, LQ
   Liu, Z
   Zhang, ZY
   Shi, XL
AF Shen, Liquan
   Liu, Zhi
   Zhang, Zhaoyang
   Shi, Xuli
TI Frame-level bit allocation based on incremental PID algorithm and frame
   complexity estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; H.264; Rate control; Frame-level bit allocation;
   Incremental PID; Buffer control; Frame complexity estimation; Video
   quality variation
ID H.264
AB Since the current rate control schemes in H.264 do not have the capability of efficient frame-level bit allocation, the video quality varies significantly from frame to frame especially for sequences with sudden scene changes or high motion activities. To overcome the limitation of frame-level bit allocation, we improve H.264 rate control scheme using two tools, the incremental proportional-integral-differential (PID) algorithm and the frame complexity estimation. The incremental PID algorithm is first introduced to control the buffer and reduce the influence of the buffer abrupt fluctuation in the process of frame-level bit allocation. To reduce more video quality variations, the frame target bit allocation is also adjusted by frame complexity that is estimated by residual energy. Simulation results show that the proposed rate control scheme, without introducing expensive computational complexity, decreases the average standard deviation of video quality by 32.29%. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Shen, Liquan; Liu, Zhi; Zhang, Zhaoyang; Shi, Xuli] Shanghai Univ, Key Lab Adv Display & Syst Applicat, Minist Educ, Shanghai 200072, Peoples R China.
C3 Shanghai University
RP Shen, LQ (corresponding author), Shanghai Univ, Key Lab Adv Display & Syst Applicat, Minist Educ, Shanghai 200072, Peoples R China.
EM jsslq@163.com; liuzhisjtu@163.com; zhyzhang@yc.shu.edu.cn
RI LIU, Zhi/D-4518-2012; Shen, Liquan/D-4832-2012; Zhang,
   Zhaoyang/AFQ-9161-2022
OI LIU, Zhi/0000-0002-8428-1131; 
FU National Natural Science Foundation of China [60332030]; Shanghai
   Rising-Star Program [08QA14031]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 60332030, and is sponsored by Shanghai Rising-Star
   Program (No. 08QA14031). The authors also thank the anonymous reviewers
   for their careful reviews and constructive suggestions that improved
   this paper.
CR Cai JF, 2006, J VIS COMMUN IMAGE R, V17, P783, DOI 10.1016/j.jvcir.2004.11.005
   D'Souza A.F., 1988, DESIGN CONTROL SYSTE
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   He ZH, 2005, IEEE T CIRC SYST VID, V15, P973, DOI 10.1109/TCSVT.2005.852417
   Jiang MQ, 2006, IEEE T MULTIMEDIA, V8, P467, DOI 10.1109/TMM.2006.870713
   Jiang MQ, 2005, IEEE T CONSUM ELECTR, V51, P281, DOI 10.1109/TCE.2005.1405733
   LEOU J, 2000, NEW RATE CONTROL SCH
   LI G, 2003, 7 M PATT THAIL, P7
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Phillips C.L., 1991, Basic feedback control systems
   Ribas-Corbera J, 2000, IEEE T CIRC SYST VID, V10, P1154, DOI 10.1109/76.875518
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Shin IH, 2004, SIGNAL PROCESS-IMAGE, V19, P341, DOI 10.1016/j.image.2003.12.002
   SU SG, 2005, IMPROVED BASIC UNIT
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   SUN Y, 2001, IEEE T CIRCUITS SYST, V11, P345
   Wang LM, 2000, SIGNAL PROCESS-IMAGE, V15, P493, DOI 10.1016/S0923-5965(99)00009-0
   WONG CW, 2004, ICME, V7, P221
   Yi XQ, 2006, J VIS COMMUN IMAGE R, V17, P407, DOI 10.1016/j.jvcir.2005.04.005
NR 19
TC 26
Z9 28
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2009
VL 20
IS 1
BP 28
EP 34
DI 10.1016/j.jvcir.2008.08.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 397IZ
UT WOS:000262657700003
DA 2024-07-18
ER

PT J
AU Kim, JH
   Kim, BG
AF Kim, Jong-Ho
   Kim, Byung-Gyu
TI Fast block mode decision algorithm in H.264/AVC video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video coding; image compression; image coding; prediction methods; video
   processing
ID PREDICTION
AB The recent video coding standard H.264/AVC show extremely higher coding efficiency compare to any other previous standards. H.264/AVC can achieve over 50% of bit rate saving with same quality using the rate-distortion process, but it brings high computational complexity. In this paper, we propose an algorithm that can reduce the complexity of the codec by reducing the block mode decision process adaptively. Block mode decision process in H.264/AVC consists of inter mode decision process and intra mode decision process. We deal with reduction method for inter and intra mode decision. In this paper an efficient method is proposed to reduce the inter mode decision complexity using the direct prediction methods based on block correlation and adaptive rate distortion cost threshold for early stopping. The fast intra mode reduction algorithm based on inter mode information is also proposed to reduce the computational complexity. The experimental results show that the proposed algorithm can achieve up to 63.34-77.39% speed up ratio with a little PSNR loss. Increment in bit requirement is also not much noticeable. (c) 2007 Elsevier Inc. All rights reserved.
EM pooney@etri.re.kr; bg.kim@ieee.org
CR Cheng CC, 2005, IEEE INT SYMP CIRC S, P1509
   Choi I, 2004, IEEE IMAGE PROC, P1141
   FENG B, 2005, IEEE INT S MULT 12 1
   Fu FW, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1191
   Grecos C, 2005, IEEE T BROADCAST, V51, P256, DOI 10.1109/TBC.2005.846192
   *ISO IEC, 2003, 1449610 ISOIEC 10
   Jing X, 2004, ELECTRON LETT, V40, P1050, DOI 10.1049/el:20045243
   Kim BG, 2006, ETRI J, V28, P425, DOI 10.4218/etrij.06.0105.0189
   Kim C, 2004, IEEE IMAGE PROC, P769
   Kim JH, 2006, IEEE IMAGE PROC, P2357, DOI 10.1109/ICIP.2006.312899
   LEE J, 2004, P IEEE INT C MULT EX, V2, P1131, DOI DOI 10.1109/ICME.2004.1394416
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Suh K, 2005, ETRI J, V27, P511, DOI 10.4218/etrij.05.0905.0032
   TU YK, ICME 2003, P789
   Zheng YF, 2011, IEEE IMAGE PROC
NR 15
TC 22
Z9 27
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2008
VL 19
IS 3
BP 175
EP 183
DI 10.1016/j.jvcir.2007.09.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 290FT
UT WOS:000255109400003
DA 2024-07-18
ER

PT J
AU Redondo, R
   Fischer, S
   Sroubek, F
   Cristóbal, G
AF Redondo, R.
   Fischer, S.
   Sroubek, F.
   Cristobal, G.
TI A 2D Wigner Distribution-based multisize windows technique for image
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Wigner Distribution; image fusion; multifocus
ID FREQUENCY SIGNAL ANALYSIS; TIME; TOOL
AB We present a scheme for image fusion based on a 2D implementation of the Wigner Distribution (WD) combined with a multisize windows technique. The joint space-frequency distribution provided by the WD can be managed as a measure of saliency that indicates which regions among different sources (channels) should be preserved. However such a saliency measure varies significantly according to the local analysis (window) in which the WD is calculated. Hence, large windows provide high resolution and robustness against possible noise present in channels and small windows provide accurate localization. The multisize windows technique combines the saliency measures of different windows taking advantage of the benefit contributed by each size. The performance assessment was conducted in artificial multifocus images under different noise exposures as well as real multifocus scenarios. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Redondo, R.; Fischer, S.; Sroubek, F.; Cristobal, G.] CSIC, Inst Opt, E-28006 Madrid, Spain.
   [Sroubek, F.] Acad Sci Czech Republ, Prague, Czech Republic.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto
   de Optica (Daza de Valdes); Czech Academy of Sciences
RP Redondo, R (corresponding author), CSIC, Inst Opt, Serrano 121, E-28006 Madrid, Spain.
EM rafa@optica.csic.es
RI Sroubek, Filip/G-6882-2014; Cristobal, Gabriel/B-7216-2012
OI Sroubek, Filip/0000-0001-6835-4911; Cristobal,
   Gabriel/0000-0001-6408-2269
CR CHOI HI, 1989, IEEE T ACOUST SPEECH, V37, P862, DOI 10.1109/ASSP.1989.28057
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P372
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P217
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P276
   Forster B, 2004, MICROSC RES TECHNIQ, V65, P33, DOI 10.1002/jemt.20092
   Gabarda S, 2004, PROC SPIE, V5558, P624, DOI 10.1117/12.561108
   Haykin S, 1997, IEEE T SIGNAL PROCES, V45, P1619, DOI 10.1109/78.600003
   Hormigo J, 1998, IEEE T SIGNAL PROCES, V46, P1757, DOI 10.1109/78.678519
   MARTIN W, 1985, SIGNAL PROCESS, V8, P215, DOI 10.1016/0165-1684(85)90075-1
   REDONDO R, 2005, APPL DIGITAL IMAGE P, V5909, P410
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   Sroubek F, 2005, P SOC PHOTO-OPT INS, V5839, P264, DOI 10.1117/12.608399
   Stankovic L, 1999, IEEE T SIGNAL PROCES, V47, P1099, DOI 10.1109/78.752607
   Stankovic L, 1998, IEEE SIGNAL PROC LET, V5, P224, DOI 10.1109/97.712105
   STANKOVIC L, 1994, IEEE T SIGNAL PROCES, V42, P225, DOI 10.1109/78.258146
   STANKOVIC S, 1995, IEEE T SIGNAL PROCES, V43, P1719, DOI 10.1109/78.398736
   Ville J., 1948, Cbles Transmissions, V2, P61
   Wang Y., 2000, Multisensor Image Fusion: Concept, Method and Applications
   Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749
NR 19
TC 7
Z9 8
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2008
VL 19
IS 1
BP 12
EP 19
DI 10.1016/j.jvcir.2007.06.009
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 257SY
UT WOS:000252820000002
DA 2024-07-18
ER

PT J
AU Tourapis, AM
   Wu, F
   Li, SP
AF Tourapis, Alexis M.
   Wu, Feng
   Li, Shipeng
TI An extension of direct macroblock coding in Predictive (P) slices of the
   H.264 standard
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video coding; H.264; motion compensation; direct prediction; motion
   prediction
AB The consideration of better motion compensation techniques for inter-frame prediction is one of the key reasons why the new H.264 (MPEG-4 AVC) video coding standard can achieve considerably better coding efficiency compared to older standards such as MPEG-2/4 and H.263. These include the use of multiple references and block sizes, a better interpolation filter for subpixel motion compensation, and more efficient exploitation of the spatio-temporal correlation between motion vectors of adjacent blocks through the consideration of SKIP and DIRECT modes. In this paper, we introduce additional methods into H.264 that further enhance motion compensation and can lead to additional improvements in coding efficiency. This is achieved by further exploiting motion vector temporal correlation through the introduction of a new DIRECT macroblock type and an enhancement to the existing Skip Macroblock type within Predictive (P) slices. These new macroblock types can lead to a considerable reduction in the bits required for encoding motion information, while retaining or even improving quality under a Rate Distortion Optimization Framework. Our simulation results suggest that the proposed improvements can lead up to 7.6% average bitrate reduction or equivalently 0.39 dB quality improvement over the current H.264 standard. (c) 2005 Elsevier Inc. All rights reserved.
C1 DoCoMo USA Labs, San Jose, CA 95110 USA.
   Microsoft Res Asia, Sigma Ctr 3F, Beijing 100080, Peoples R China.
C3 NTT Docomo; Microsoft Research Asia; Microsoft
RP Tourapis, AM (corresponding author), DoCoMo USA Labs, 181 Metro Dr, San Jose, CA 95110 USA.
EM alexismt@ieee.org
RI Wu, Feng/KCY-3017-2024; Li, Shipeng/AAA-3374-2020
OI Li, Shipeng/0000-0001-5368-4256
CR Bjontegaard G, 2001, 13 VCEG M AUST TX
   SULLIVAN G, 2003, 20 VCEG M PALM MALL
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   Tourapis AM, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P700
   TOURAPIS AM, 2001, P 2001 IEEE INT C IM
   TOURAPIS AM, 2002, JVTC128 ISOIECJTC1SC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 7
TC 1
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 311
EP 321
DI 10.1016/j.jvcir.2005.04.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000007
DA 2024-07-18
ER

PT J
AU Chan, DY
   Lin, SJ
   Chang, CY
AF Chan, Din-Yuen
   Lin, Shou-Jen
   Chang, Chun-Yuan
TI A rate control scheme using Kalman filtering for H.263
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE bit-rate control; Kalman filtering; H.263
AB This paper proposes a rate control framework for H.263 video coding called the low-delay Kalman filtering rate controller (LKFrc), whose main part is the adaptive Kalman filter. In LKFrc, a low-delay two-stage selector is proposed to select the representative frames of video. The first stage can rapidly pre-select the relatively significant frames. The second selection stage is embedded in the prediction model of Kalman filter. By the prediction model, LKFrc can distribute a proper bit budget to the pre-selected frame or definitely skip this frame. The measurement model of Kalman filter exploits a rate-distortion (R-D) model to meet the given bit budget by selecting an appropriate picture-level quantization parameter (QP). From the picture-level QP, the subsequent macro block-level QPs are rapidly yielded by a rapid offset model using the relative macroblock activity. In comparison with the TMN8 model, the LKFrc framework can obtain better PSNRs, higher motion continuities and lower flickering effects with lower computation cost. (c) 2005 Elsevier Inc. All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung, Taiwan.
   Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 I Shou University; National Chiayi University
RP Chan, DY (corresponding author), I Shou Univ, Dept Informat Engn, Ta Hsu Hsiang, Kaohsiung, Taiwan.
EM dychan@mail.ncyu.edu.tw
CR Berger Toby, 1971, RATE DISTORTION THEO
   Bist A, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P61, DOI 10.1109/ICIP.1996.560601
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Choi J, 1999, IEEE T IMAGE PROCESS, V8, P537, DOI 10.1109/83.753741
   Côté G, 1998, IEEE T CIRC SYST VID, V8, P849, DOI 10.1109/76.735381
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   *ISO IEC, 1995, 138182 ISO IEC
   *ITUT SG 15 EXP GR, 1995, VID COD TEST MOD NEA
   JORDI R, 2000, IEEE T CIRCUITS SYST, V10, P1154
   Lin LJ, 1998, IEEE T CIRC SYST VID, V8, P446, DOI 10.1109/76.709411
   Ng KT, 1997, ISCAS '97 - PROCEEDINGS OF 1997 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I - IV, P1389, DOI 10.1109/ISCAS.1997.622137
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   WEYGAND T, 1996, IEEE T CIRCUITS SYST, V6, P182
   ZDEPSKI J, 1991, IEEE T COMMUN, V39, P947, DOI 10.1109/26.87184
NR 14
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2005
VL 16
IS 6
BP 734
EP 748
DI 10.1016/j.jvcir.2005.03.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JQ
UT WOS:000242026600005
DA 2024-07-18
ER

PT J
AU Kang, LW
   Leou, JJ
AF Kang, LW
   Leou, JJ
TI An error resilient coding scheme for H.264/AVC video transmission based
   on data embedding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilient coding; error concealment; H.264/AVC video; transmission
   error; data embedding
ID CONCEALMENT; PROTECTION
AB For entropy-coded H.264/AVC video frames, a transmission error in a codeword will not only affect the underlying codeword but also may affect subsequent codewords, resulting in a great degradation of the received video frames. In this study, an error resilient coding scheme for H.264/AVC video transmission is proposed. At the encoder, for an H.264/AVC intra-coded I frame, the important data for each macroblock (MB) are extracted and embedded into the next frame by the proposed MB-interleaving slice-based data embedding scheme for I frames. For an H.264/AVC inter-coded P frame, two types of important data with different error recovery capabilities for each MB are extracted and embedded into the next frame by the proposed MB-interleaving slice-based data embedding scheme for P frames. At the decoder, if the important data for a corrupted MB can be correctly extracted, the extracted important data for the corrupted MB will facilitate the employed error concealment scheme to conceal the corrupted MB; otherwise, the employed error concealment scheme is simply used to conceal the corrupted MB. As compared with some recent error resilient approaches based on data embedding, in this study, the important data selection mechanism for different types of MBs, the detailed data embedding mechanism, and the error detection and concealment scheme performed at the decoder are well developed to design an integrated error resilient coding scheme. Additionally, two types of important data with different transmission error recovery capabilities for each MB in P frames can provide more reliable error resiliency. Based on the simulation results obtained in, this study, the proposed scheme can recover high-quality H.264/AVC video frames from the corresponding corrupted video frames up to a video packet loss rate of 20%. (C) 2004 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM jjleou@cs.ccu.edu.tw
CR Frossard P, 2001, IEEE T CIRC SYST VID, V11, P989, DOI 10.1109/76.946516
   Gallant M, 2001, IEEE T CIRC SYST VID, V11, P357, DOI 10.1109/76.911161
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Kang LW, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P461
   Kang LW, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P532
   Kang LW, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P29
   KANG LW, 2002, P IEEE PAC RIM C MUL, P814
   KANG LW, 2004, P IEEE INT C MULT EX
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Stockhammer T, 2002, IEEE T CIRC SYST VID, V12, P465, DOI [10.1109/TCSVT.2002.800317, 10.1109/TCSVT.2002.806317]
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y., 2002, VIDEO PROCESSING COM
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yilmaz A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P679
   Yin P, 2001, INT CONF ACOUST SPEE, P1453, DOI 10.1109/ICASSP.2001.941204
   Zeng WJ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P113
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
NR 25
TC 11
Z9 15
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2005
VL 16
IS 1
BP 93
EP 114
DI 10.1016/j.jvcir.2004.04.003
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 885SN
UT WOS:000226177300006
DA 2024-07-18
ER

PT J
AU Venkatachalapathya, K
   Krishnamoorthya, R
   Viswanath, K
AF Venkatachalapathya, K
   Krishnamoorthya, R
   Viswanath, K
TI A new adaptive search strategy for fast block based motion estimation
   algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE fast block search algorithm; motion estimation; threshold; video
   compression
AB Block based motion estimation algorithms are used for video sequence compression, among which full search algorithm is the most widely used because it provides the best match in the search area but it is computationally intensive. Hence many fast block search algorithms are proposed. All fast block search algorithm (FBSA) are based on the assumption that the block distortion measure decreases mono-tonically as the search point moves towards the global minimum. Hence the search becomes inefficient if the complexity of the error surface increases (i.e., for multimodal or rough surface) which in turn increases the error. In this paper, we propose a new strategy which makes this FBSA adaptive for multimodal surface by taking the relative difference between the local minima and other search points and selecting more than one winner for the next step, depending upon the distortion among the search points. (C) 2004 Published by Elsevier Inc.
C1 Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.
C3 Annamalai University
RP Venkatachalapathya, K (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.
EM chalapathy65@rediff.com
OI Ramasamy, Krishnamoorthy/0000-0003-1823-5855
CR [Anonymous], P NAT TEL C NOV
   Chan YL, 2001, IEEE T IMAGE PROCESS, V10, P1223, DOI 10.1109/83.935038
   Chen YS, 2001, IEEE T IMAGE PROCESS, V10, P1212, DOI 10.1109/83.935037
   Feng J, 1998, IEE P-VIS IMAGE SIGN, V145, P173, DOI 10.1049/ip-vis:19981916
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   JONG HM, 1994, IEEE T CIRCUIT SYSTE, V4
   KWATRA SC, 1987, IEEE T COMMUN, V35, P747, DOI 10.1109/TCOM.1987.1096840
   Lee LW, 1993, IEEE T CIRC SYST VID, V3, P85, DOI 10.1109/76.180692
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Mitchell J.L., 1997, MPEG VIDEO COMPRESSI
   PICKERING MR, 1997, IEEE T CIRCUIT SYSTE
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   SRINIVASAN R, 1985, IEEE T COMMUN, V33, P888, DOI 10.1109/TCOM.1985.1096398
NR 15
TC 5
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 203
EP 213
DI 10.1016/j.jvcir.2003.08.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800006
DA 2024-07-18
ER

PT J
AU Cao, XY
   Lin, T
   Zhao, LP
   Yang, YF
   Zhou, KL
   Wei, H
   Chen, XY
AF Cao, Xueyan
   Lin, Tao
   Zhao, Liping
   Yang, Yufen
   Zhou, Kailun
   Wei, Hu
   Chen, Xianyi
TI Fast intra coding in AVS3 based on direct non-first pre-coding skip
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Audio-Video Coding Standard; QTBT; EQT; CU pre-coding; Intra prediction
ID CU SIZE DECISION; MODE DECISION; ALGORITHM
AB The third generation of Audio Video Coding Standard (AVS3) adopts sophisticated block partitioning structure with a multi-type tree, which includes Quad-Tree (QT), Binary-Tree (BT), and Extend Quad-Tree (EQT). During multi-type tree recursive block partitioning and pre-coding process of encoding, each Coding Unit (CU) of each Size at each Location (CUeSeL) of the picture is repeatedly pre-coded many times when visiting each branch of each tree. Although there are early termination mechanism, the number of visits for each CUeSeL is still very high and up to more than fifty. This process brings very high coding complexity. In order to reduce the coding complexity of AVS3, this paper proposes a method named Direct Non-First Pre-coding Skip (DNFPS) for a CUeSeL to directly and completely skip all non-first pre-coding under specific conditions. The conditions include, but are not limited to, those related to the first pre-coding. The contributions of the paper are as follows. In I pictures, for a CUeSeL with top-left location (x, y), if both x and y are multiples of 64 or if a set of conditions related to first pre-coding is satisfied, then each non-first pre-coding is skipped, and the coding result of the first pre-coding is reused for each non-first pre-coding skipped. In non-I pictures, each non-first pre-coding is skipped, and the coding result of the first pre-coding is reused for each non-first pre-coding skipped, provided a set of conditions related to first pre-coding is satisfied. The experimental results demonstrate that DNFPS has a negligible impact on coding efficiency under All Intra (AI) configurations, and coding runtime is reduced by 16 %.
C1 [Cao, Xueyan; Lin, Tao; Zhou, Kailun] Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.
   [Zhao, Liping] Shaoxing Univ, Sch Comp Sci & Engn, Shaoxing, Zhejiang, Peoples R China.
   [Yang, Yufen] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai, Peoples R China.
   [Wei, Hu] Molchip Technol Shanghai Co Ltd, Shanghai, Peoples R China.
   [Chen, Xianyi] Hisense Elect Informat Grp Co Ltd, Qingdao, Peoples R China.
C3 Tongji University; Shaoxing University; Shanghai Institute of Technology
RP Zhao, LP (corresponding author), Shaoxing Univ, Sch Comp Sci & Engn, Shaoxing, Zhejiang, Peoples R China.
EM zhaoliping_jian@126.com
RI zhao, liping/N-4269-2017; chen, xian/KHW-2227-2024
FU National Natural Science Foundation of China [62271321]; Zhejiang
   Provincial Natural Science Foundation of China [LZ24F010003,
   LZ24F020006, LR23F020001, LZ23F020003, LY20F020011, LTY22F020003,
   TY22F025548]; Science and Technology Plan Project in Basic Public
   Welfare class of Shaoxing city [2022A11002, 2023A11006]; Social Sciences
   and Humanities Youth Foundation of Ministry of Education of China
   [21YJCZH039]; Scientific Research Foundation of Shanghai Institute
   Technology [YJ2022-67]
FX <BOLD>Acknowledgements</BOLD> This work was financially supported
   partially by the National Natural Science Foundation of China (No.
   62271321) , the Zhejiang Provincial Natural Science Foundation of China
   (No. LZ24F010003, No. LZ24F020006, No. LR23F020001, No. LZ23F020003, No.
   LY20F020011, No. LTY22F020003, No. TY22F025548) , the Science and
   Technology Plan Project in Basic Public Welfare class of Shaoxing city
   (No. 2022A11002, No. 2023A11006) , the Social Sciences and Humanities
   Youth Foundation of Ministry of Education of China (No. 21YJCZH039) ,
   the Scientific Research Foundation of Shanghai Institute Technology (No.
   YJ2022-67) .
CR Bjotegaard G., 2001, VCEGM33
   Dong XC, 2022, IEEE T MULTIMEDIA, V24, P400, DOI 10.1109/TMM.2021.3052348
   Fan K, 2020, IEEE INT CONF MULTI
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Lei M., 2019, AVS document M4880
   Li Y, 2017, IEEE T MULTIMEDIA, V19, P1431, DOI 10.1109/TMM.2017.2669863
   Ma SW, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3461-9
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Tan HL, 2016, IEEE T BROADCAST, V62, P128, DOI 10.1109/TBC.2015.2505406
   Wang M, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954510
   Wang M, 2019, IEEE DATA COMPR CONF, P300, DOI 10.1109/DCC.2019.00038
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu T, 2021, IEEE ACCESS, V9, P7540, DOI 10.1109/ACCESS.2021.3049148
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Xu C., 2022, 2022 21 INT S COMMUN, P195, DOI [10.1109/ISCIT55906.2022.9931199, DOI 10.1109/ISCIT55906.2022.9931199]
   Xu X., 2020, AVS N2926
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang YF, 2022, MULTIMED TOOLS APPL, V81, P2043, DOI 10.1007/s11042-021-11418-6
   Zhang J, 2019, PICT COD SYMP, DOI 10.1109/pcs48520.2019.8954503
   Zhang QW, 2020, IEEE ACCESS, V8, P203516, DOI 10.1109/ACCESS.2020.3036858
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhao LP, 2020, IEEE T MULTIMEDIA, V22, P786, DOI 10.1109/TMM.2019.2931414
   Zhou KL, 2023, IEEE T MULTIMEDIA, V25, P584, DOI 10.1109/TMM.2021.3129358
   Zhou QY, 2021, IEEE T MULTIMEDIA, V23, P3867, DOI 10.1109/TMM.2020.3033092
NR 25
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104027
DI 10.1016/j.jvcir.2023.104027
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE6M5
UT WOS:001144125800001
DA 2024-07-18
ER

PT J
AU Li, A
   Yi, Y
   Liang, D
AF Li, Ao
   Yi, Yang
   Liang, Daan
TI Residual attention fusion network for video action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; Temporal modeling; Channel-wise attention;
   Pixel-wise attention
ID HISTOGRAMS; LSTM
AB Human action recognition in videos is a fundamental and important topic in computer vision, and modeling spatial-temporal dynamics in a video is crucial for action classification. In this paper, a novel attention module named Channel-wise Non-local Attention Module (CNAM) is proposed to highlight the important features both spatially and temporally. Besides, another new attention module named Channel-wise Attention Recalibration Module (CARM) is developed to focus on capturing discriminative features at channel level. Based on these two attention modules, a novel convolutional neural network named Residual Attention Fusion Network (RAFN) is proposed to model long-range temporal structure and capture more discriminative action features at the same time. More specifically, first, a sparse temporal sampling strategy is adopted to uniformly sample video data as input to RAFN along the temporal dimension. Secondly, the attention modules CNAM and CARM are plugged into residual network for highlighting important action regions around actors. Finally, the classification scores of four streams of RAFN are combined by late fusion. The experimental results on HMDB51 and UCF101 demonstrate the effectiveness and excellent recognition performance of our proposed method.
C1 [Li, Ao; Yi, Yang; Liang, Daan] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
   [Yi, Yang] Sun Yat Sen Univ, Xinhua Coll, Guangzhou 510520, Peoples R China.
   [Yi, Yang] Guangdong Key Lab Big Data Anal & Proc, Guangzhou 510275, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Li, A (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Peoples R China.
EM liao29@mail3.sysu.edu.cn
RI xie, jing/KDO-9486-2024; Liu, Chang/KGL-6678-2024; YANG,
   DAN/KCL-5217-2024; CAO, ying/KFA-2972-2024
OI Li, Ao/0000-0002-8190-3062
FU Guangzhou Science and Technology Project [202002030273]; National
   Natural Science Foundation of China [61672546, 61573385]
FX This work was partly supported by the Guangzhou Science and Technology
   Project [grant number 202002030273] ; and the National Natural Science
   Foundation of China [grant numbers 61672546, 61573385] .
CR Bao XP, 2019, PROC INT C TOOLS ART, P598, DOI 10.1109/ICTAI.2019.00089
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Dai SL, 2018, IEEE T CIRC SYST VID, V28, P2484, DOI 10.1109/TCSVT.2017.2772026
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diba A, 2018, LECT NOTES COMPUT SC, V11208, P299, DOI 10.1007/978-3-030-01225-0_18
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2018, LECT NOTES COMPUT SC, V11220, P388, DOI 10.1007/978-3-030-01270-0_23
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Ghiasi G, 2018, ADV NEUR IN, V31
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kar A, 2017, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR.2017.604
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li J, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107037
   Lin WY, 2018, AAAI CONF ARTIF INTE, P7130
   Long X, 2018, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2018.00817
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Ouyang X, 2019, IEEE ACCESS, V7, P40757, DOI 10.1109/ACCESS.2019.2906654
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Saleh A, 2018, PATTERN RECOGN LETT, V105, P4, DOI 10.1016/j.patrec.2017.06.010
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sun L, 2017, IEEE I CONF COMP VIS, P2166, DOI 10.1109/ICCV.2017.236
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tu ZG, 2019, IEEE T IMAGE PROCESS, V28, P2799, DOI 10.1109/TIP.2018.2890749
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YB, 2017, PROC CVPR IEEE, P2097, DOI 10.1109/CVPR.2017.226
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Yi Y, 2017, EXPERT SYST APPL, V78, P259, DOI 10.1016/j.eswa.2017.02.020
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang SW, 2018, IEEE T MULTIMEDIA, V20, P769, DOI 10.1109/TMM.2017.2758524
NR 42
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 103987
DI 10.1016/j.jvcir.2023.103987
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DT6R0
UT WOS:001134369600001
DA 2024-07-18
ER

PT J
AU Sui, Y
   Ding, D
   Pan, X
   Xu, XZ
   Liu, S
   Yuan, B
   Chen, ZZ
AF Sui, Yang
   Ding, Ding
   Pan, Xiang
   Xu, Xiaozhong
   Liu, Shan
   Yuan, Bo
   Chen, Zhenzhong
TI Corner-to-Center long-range context model for efficient learned image
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Learned image compression; Context model; Transformer
AB In the framework of learned image compression, the context model plays a pivotal role in capturing the de-pendencies among latent representations. To reduce the decoding time resulting from the serial autoregressive context model, the parallel context model has been proposed as an alternative that necessitates only two passes during the decoding phase, thus facilitating efficient image compression in real-world scenarios. However, performance degradation occurs due to its incomplete casual context. To tackle this issue, we conduct an in-depth analysis of the performance degradation observed in existing parallel context models, focusing on two aspects: the Quantity and Quality of information utilized for context prediction and decoding. Based on such analysis, we propose the Corner-to-Center transformer-based Context Model symbolscript designed to enhance context and latent predictions and improve rate-distortion performance. Specifically, we leverage the logarithmic-based prediction order to predict more context features from corner to center progressively. In addition, to enlarge the receptive field in the analysis and synthesis transformation, we use the Long-range Crossing Attention Module (LCAM) in the encoder/decoder to capture the long-range semantic information by assigning the different window shapes in different channels. Extensive experimental evaluations show that the proposed method is effective and outperforms the state-of-the-art parallel methods. Finally, according to the subjective analysis, we suggest that improving the detailed representation in transformer-based image compression is a promising direction to be explored.
C1 [Sui, Yang; Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, 94 Brett Rd, Piscataway, NJ 08854 USA.
   [Ding, Ding; Pan, Xiang; Xu, Xiaozhong; Liu, Shan] Tencent Amer, Media Lab, 2747 Pk Blvd, Palo Alto, CA 94306 USA.
   [Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Hubei, Peoples R China.
C3 Rutgers University System; Rutgers University New Brunswick; Wuhan
   University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Hubei, Peoples R China.
EM yang.sui@rutgers.edu; zzchen@whu.edu.cn
RI Yuan, Bo/HDN-6321-2022
OI Yuan, Bo/0000-0003-0222-8095; Sui, Yang/0000-0003-3020-0612
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   Balle J, 2018, ICLR
   Balle J, 2017, 5 INT C LEARN REPR I
   Ball‚ J, 2017, Arxiv, DOI [arXiv:1611.01704, 10.48550/arXiv.1611.01704]
   Begaint J., 2020, ARXIV
   Bellard F., 2016, BPG image format, V1, P2
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Choi Y, 2019, IEEE I CONF COMP VIS, P3146, DOI 10.1109/ICCV.2019.00324
   Cui Z, 2021, PROC CVPR IEEE, P10527, DOI 10.1109/CVPR46437.2021.01039
   d'Ascoli S, 2021, PR MACH LEARN RES, V139, DOI 10.1088/1742-5468/ac9830
   Dosovitskiy A., 2019, INT C LEARN REPR
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Golts A, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103208
   Graham B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12239, DOI 10.1109/ICCV48922.2021.01204
   He DL, 2022, PROC CVPR IEEE, P5708, DOI 10.1109/CVPR52688.2022.00563
   He DL, 2021, PROC CVPR IEEE, P14766, DOI 10.1109/CVPR46437.2021.01453
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Kim JH, 2022, PROC CVPR IEEE, P5982, DOI 10.1109/CVPR52688.2022.00590
   Koyuncu AB, 2022, Arxiv, DOI arXiv:2203.02452
   Lee J., 2018, INT C LEARN REPR ICL
   Liu HJ, 2019, Arxiv, DOI arXiv:1904.09757
   Liu JH, 2020, Arxiv, DOI [arXiv:2002.03370, DOI 10.48550/ARXIV.2002.03370]
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   Mentzer F, 2018, PROC CVPR IEEE, P4394, DOI 10.1109/CVPR.2018.00462
   Minnen D, 2020, IEEE IMAGE PROC, P3339, DOI [10.1109/icip40778.2020.9190935, 10.1109/ICIP40778.2020.9190935]
   Minnen D, 2018, ADV NEUR IN, V31
   Naseer M, 2021, ADV NEUR IN, V34
   Qian Y., 2020, INT C LEARN REPR
   Qian Y, 2021, INT C LEARN REPR
   Raghu M, 2021, ADV NEUR IN, V34
   Sun ZH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5574, DOI 10.1145/3474085.3475698
   Theis L., 2017, ICLR
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   van den Oord A, 2016, ADV NEUR IN, V29
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Xiao T, 2021, ADV NEUR IN, V34
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
   Zou RJ, 2022, PROC CVPR IEEE, P17471, DOI 10.1109/CVPR52688.2022.01697
NR 41
TC 0
Z9 0
U1 2
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 103990
DI 10.1016/j.jvcir.2023.103990
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4R4
UT WOS:001130085500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, FY
   Zhou, ZQ
   Men, CY
   Sun, Q
   Huang, KJ
AF Liu, Fengyin
   Zhou, Ziqun
   Men, Changyou
   Sun, Quan
   Huang, Kejie
TI IFGLT: Information fusion guided lightweight Transformer for image
   denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Transformer; Lightweight network
ID NETWORK; FILTER; NOISE
AB Image denoising is a low-level computer vision task that aims to reconstruct high-quality images from noisy ones. However, large networks with a high computational burden have been employed in existing works in pursuit of high-quality images. This paper introduces an Information Fusion Guided Lightweight Transformer (IFGLT) that can lessen the computational burden and achieve superior restoration results. The Feature Enhancement Module (FEM) optimizes the computing cost of the Transformer layer by layer using various techniques such as group mapping, channel generation, fusion convolution, and window rearrangement. The Information Compensation Module (ICM) gradually compensates for missing information by leveraging the original image. The Lightweight Sample Module (LSM) performs up-sampling and down-sampling with the minimal computing cost by altering the order of feature transformation. The experimental results demonstrate that our proposed IFGLT attains higher objective indices and achieves better visual effects with reduced computing cost in comparison to conventional methods.
C1 [Liu, Fengyin] Zhejiang Univ, Polytech Inst, Hangzhou, Zhejiang, Peoples R China.
   [Zhou, Ziqun; Huang, Kejie] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
   [Men, Changyou; Sun, Quan] Hangzhou Vango Technol Inc, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Huang, KJ (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
EM lfengyin@zju.edu.cn; zhouziqun@zju.edu.cn; mency@vangotech.com;
   sunq@vangotech.com; huangkejie@zju.edu.cn
RI , 黄科杰/J-5919-2019; Huang, Kejie/E-7511-2018
OI Huang, Kejie/0000-0003-3722-9979
FU Hangzhou Major Technology Innovation Project of Artificial Intelligence
   [2022AIZD0060]; National Natural Science Foundation of China [62274142,
   M-0499]
FX <B>Acknowledgments</B> This research has been supported by Hangzhou
   Major Technology Innovation Project of Artificial Intelligence (Grant
   No. 2022AIZD0060) and the National Natural Science Foundation of China
   (Grant No. 62274142 and M-0499) .
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Berg A., 2010, Large scale visual recognition challenge
   BERNSTEIN R, 1987, IEEE T CIRCUITS SYST, V34, P1275, DOI 10.1109/TCS.1987.1086066
   Chang M, 2020, Arxiv, DOI arXiv:2001.10291
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen LY, 2021, IEEE COMPUT SOC CONF, P182, DOI 10.1109/CVPRW53098.2021.00027
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Fan CM, 2022, IEEE INT SYMP CIRC S, P2333, DOI 10.1109/ISCAS48785.2022.9937486
   Franzen R, 1999, Kodak lossless true color image suite
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Kim Y, 2019, IEEE ACCESS, V7, P63447, DOI 10.1109/ACCESS.2019.2917537
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338
   Lei Ba J., 2016, arXiv
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu D, 2018, ADV NEUR IN, V31
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mao XJ, 2016, Arxiv, DOI [arXiv:1603.09056, DOI 10.48550/ARXIV.1603.09056]
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Peng YL, 2019, NEUROCOMPUTING, V345, P67, DOI 10.1016/j.neucom.2018.12.075
   Pham T. Q., 2005, 2005 IEEE International Conference on Multimedia and Expo
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Shi WZ, 2016, Arxiv, DOI arXiv:1609.05158
   Soh JW, 2021, INT C PATT RECOG, P747, DOI 10.1109/ICPR48806.2021.9412605
   Sun B, 2022, Arxiv, DOI arXiv:2203.08921
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tian CW, 2020, NEURAL NETWORKS, V131, P251, DOI 10.1016/j.neunet.2020.07.025
   Tian CW, 2020, NEURAL NETWORKS, V121, P461, DOI 10.1016/j.neunet.2019.08.022
   Varish N, 2018, APPL INTELL, V48, P2930, DOI 10.1007/s10489-017-1125-7
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Xia ZH, 2020, IEEE WINT CONF APPL, P2415, DOI 10.1109/WACV45572.2020.9093586
   Yue ZS, 2023, Arxiv, DOI arXiv:1908.11314
   Zhang K, 2022, IEEE T PATTERN ANAL, V44, P6360, DOI 10.1109/TPAMI.2021.3088914
   Zhang K, 2023, Arxiv, DOI arXiv:2203.13278
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3600632
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhou ZQ, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23041886
   Zhou ZQ, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010030
NR 52
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103994
DI 10.1016/j.jvcir.2023.103994
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DE1A9
UT WOS:001130251000001
DA 2024-07-18
ER

PT J
AU Samaranayake, H
   Mudannayake, O
   Perera, D
   Kumarasinghe, P
   Suduwella, C
   De Zoysa, K
   Wimalaratne, P
AF Samaranayake, Harin
   Mudannayake, Oshan
   Perera, Dushani
   Kumarasinghe, Prabhash
   Suduwella, Chathura
   De Zoysa, Kasun
   Wimalaratne, Prasad
TI Detecting Water in Visual Image Streams from UAV with Flight Constraints
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Water Surface Identification; Unmanned Ariel Vehicles; Drones; UNet;
   Dense Optical Flow
AB Unmanned Ariel Vehicles (UAVs) require identifying water surfaces during flight maneuvers, mainly for safety in execution and its applications. We introduce two novel techniques to identify water surfaces from frontfacing and downward-facing cameras mounted on a UAV. The first method - UNet-RAU, a unique architecture based on UNet and Reflection Attention Units, segments water pixels from front-facing camera views, utilizing the reflection property of water surfaces. On the On-Road and Off-Road datasets of Puddle-1000, UNet-RAU improved its performance by 2% over the state-of-the-art FCN-RAU. Additionally, the UNet-RAU generated an F1-score of 80.97% on our Drone-Water-Front dataset. The second method - Dense Optical Flow based Water Detection (DOF-WD), detects water surfaces in videos of downward-facing cameras. This method utilizes downwash-generated ripples and natural texture features on a water surface to identify water in low and high altitudes, respectively. We empirically validated the performance of the DOF-WD method using our Drone-Water-Down dataset.
C1 [Samaranayake, Harin; Mudannayake, Oshan; Perera, Dushani; Kumarasinghe, Prabhash; Suduwella, Chathura; De Zoysa, Kasun; Wimalaratne, Prasad] Univ Colombo, Sch Comp, Colombo 07, Sri Lanka.
C3 University of Colombo
RP Kumarasinghe, P (corresponding author), Univ Colombo, Sch Comp, Colombo 07, Sri Lanka.
EM harin.ncsl@gmail.com; oshan.ivantha@gmail.com; udi@ucsc.cmb.ac.lk;
   jpk@ucsc.cmb.ac.lk; cps@ucsc.cmb.ac.lk; kasun@ucsc.cmb.ac.lk;
   spw@ucsc.cmb.ac.lk
OI Ushettige, Dushani Imesha Perera/0000-0002-0168-9239; Kumarasinghe,
   Prabhash/0000-0003-2370-2569
CR Alsdorf DE, 2003, SCIENCE, V301, P1491, DOI 10.1126/science.1089802
   Bertels L, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8121010
   Bin Xie, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3186, DOI 10.1109/IROS.2007.4398994
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Elhassan S., 2013, Standing Water Detection Using Radar, P1
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Han XF, 2018, LECT NOTES COMPUT SC, V11210, P105, DOI 10.1007/978-3-030-01231-1_7
   Koparan C, 2018, WATER-SUI, V10, DOI 10.3390/w10030264
   Li RR, 2018, IEEE J-STARS, V11, P3954, DOI 10.1109/JSTARS.2018.2833382
   LYZENGA DR, 1985, INT J REMOTE SENS, V6, P115, DOI 10.1080/01431168508948428
   Matthies L, 2003, P SOC PHOTO-OPT INS, V5083, P231, DOI 10.1117/12.496942
   Mettes P, 2017, COMPUT VIS IMAGE UND, V154, P182, DOI 10.1016/j.cviu.2016.04.003
   Mettes P, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P283
   Nguyen Chuong V., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5251, DOI 10.1109/ICRA.2017.7989616
   Pekel JF, 2014, REMOTE SENS ENVIRON, V140, P704, DOI 10.1016/j.rse.2013.10.008
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Pombeiro R, 2015, OCEANS-IEEE
   Rankin AL, 2006, SEL TOP ELECTR SYST, V42, P177, DOI 10.1142/9789812772572_0023
   Rankin Arturo L., 2011, IEEE International Conference on Robotics and Automation, P5329
   Rankin A, 2010, IEEE INT C INT ROBOT, P215, DOI 10.1109/IROS.2010.5650402
   Ridolfi E, 2018, WATER-SUI, V10, DOI 10.3390/w10030297
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Steccanella L, 2019, ADV INTELL SYST COMP, V867, P613, DOI 10.1007/978-3-030-01370-7_48
   Suduwella C, 2017, DRONET'17: PROCEEDINGS OF THE 3RD WORKSHOP ON MICRO AERIAL VEHICLE NETWORKS, SYSTEMS, AND APPLICATIONS, P27, DOI 10.1145/3086439.3086442
   Wang L, 2019, IEEE ACCESS, V7, P167497, DOI 10.1109/ACCESS.2019.2953768
   Zhou ZW, 2018, Arxiv, DOI arXiv:1807.10165
NR 27
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103933
DI 10.1016/j.jvcir.2023.103933
EA SEP 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T2LX0
UT WOS:001076359400001
DA 2024-07-18
ER

PT J
AU Wang, Z
   Feng, QY
   Corredor, G
   Koyuncu, C
   Lu, C
AF Wang, Zhao
   Feng, Qianyu
   Corredor, German
   Koyuncu, Can
   Lu, Cheng
TI Measuring dense false positive regions from segmentation result for
   whole slide tissue histology image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Evaluation metric; Histology image
AB Evaluating a segmentation model is critical for constructing computer-aided diagnosis (CAD) systems, in which the segmented regions will be used for downstream analysis. However, existing segmentation evaluation metrics may not reflect every aspect of a trained segmentation model performance in the context of the whole slide tissue histology images (WSIs). Specifically, existing segmentation metrics generally ignore the impact of densely packed false positive pixels (DFP) in the WSI segmentation result. This study presents a new and efficient metric, named MAFaR, accounting for DFP regions in digital WSI segmentation. The proposed metric consists of two modules: 1) Estimation of DFP regions; 2) Calculation of MAFaR score. In module 1, a Gaussian Kernel Density Estimation method was used to estimate the density of the false positive (FP) regions in segmentation result (SR). Then a two-step Mean-shift clustering algorithm was applied to the high-density FP regions to estimate the DFP regions. In module 2, the ratio of DFP regions area to the positive regions area were used for MAFaR calculation. We conducted two experiments to evaluate the effectiveness of the MAFaR score. In the first experiment, we compared MAFaR with existing metrics related to FP regions, the proposed MAFaR score can reflect the impact of DFP regions. In the second experiment, MAFaR scores were compared with the manual evaluation scores given by three experienced engineers and found high correlation (Spearman's rank correlation coefficients greater than 0.7) and high agreement (Kendall coefficient = 0.839). Therefore, the MAFaR can be used with other segmentation metrics for evaluating WSI segmentation.
C1 [Wang, Zhao; Feng, Qianyu] Shaanxi Normal Univ, Coll Comp Sci, Xian 710119, Shaanxi, Peoples R China.
   [Corredor, German; Koyuncu, Can] Case Western Reserve Univ, Dept Biomed Engn, Cleveland, OH 44106 USA.
   [Corredor, German; Koyuncu, Can] Louis Stokes Cleveland VA Med Ctr, Cleveland, OH 44106 USA.
   [Lu, Cheng] Southern Med Univ, Guangdong Prov Peoples Hosp, Guangdong Acad Med Sci, Dept Radiol, Guangzhou 510080, Peoples R China.
   [Lu, Cheng] Southern Med Univ, Guangdong Prov Peoples Hosp, Med Res Inst, Guangdong Acad Med Sci, Guangzhou 510080, Peoples R China.
   [Lu, Cheng] Guangdong Prov Key Lab Artificial Intelligence Med, Guangzhou 510080, Peoples R China.
   [Lu, Cheng] Guangdong Acad Med Sci, Guangdong Prov People Hosp, 106 Zhongshaner Rd, Guangzhou 510060, Guangdong, Peoples R China.
C3 Shaanxi Normal University; University System of Ohio; Case Western
   Reserve University; University System of Ohio; Case Western Reserve
   University; US Department of Veterans Affairs; Veterans Health
   Administration (VHA); Louis Stokes Cleveland Veterans Affairs Medical
   Center; Guangdong Academy of Medical Sciences & Guangdong General
   Hospital; Southern Medical University - China; Guangdong Academy of
   Medical Sciences & Guangdong General Hospital; Southern Medical
   University - China; South China University of Technology; Guangdong
   Academy of Medical Sciences & Guangdong General Hospital; Southern
   Medical University - China
RP Lu, C (corresponding author), Guangdong Acad Med Sci, Guangdong Prov People Hosp, 106 Zhongshaner Rd, Guangzhou 510060, Guangdong, Peoples R China.
EM lucheng@gdph.org.cn
RI Corredor, Germán/AAA-3422-2022
FU Guangdong Provincial Key Labora-tory of Artificial Intelligence in
   Medical Image Analysis and Application [2022B1212010011]; National
   Natural Science Foundation of China [82272084]
FX This work was supported by the Guangdong Provincial Key Labora-tory of
   Artificial Intelligence in Medical Image Analysis and Application (No.
   2022B1212010011) , National Natural Science Foundation of China
   (82272084) .
CR Amgad M, 2019, BIOINFORMATICS, V35, P3461, DOI 10.1093/bioinformatics/btz083
   Botev ZI, 2010, ANN STAT, V38, P2916, DOI 10.1214/10-AOS799
   Chen L, 2018, IEEE T MED IMAGING, V37, P2453, DOI 10.1109/TMI.2018.2835303
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Khokher MR, 2013, IET IMAGE PROCESS, V7, P201, DOI 10.1049/iet-ipr.2012.0082
   Kim J, 2012, J MACH LEARN RES, V13, P2529
   Legendre P, 2005, J AGR BIOL ENVIR ST, V10, P226, DOI 10.1198/108571105X46642
   Lindeberg T, 1997, COMPUT VIS IMAGE UND, V67, P88, DOI 10.1006/cviu.1996.0510
   Lu C, 2015, IET IMAGE PROCESS, V9, P735, DOI 10.1049/iet-ipr.2014.0192
   Lu C, 2014, IEEE J BIOMED HEALTH, V18, P594, DOI 10.1109/JBHI.2013.2277837
   Maier-Hein L, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07619-7
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Reinke A., 2021, Common limitations of image processing metrics: A picture story
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Sun L, 2020, IEEE T MED IMAGING, V39, P2000, DOI 10.1109/TMI.2019.2962792
   Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x
   Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464
   Yeghiazaryan V., 2015, Department of Computer Science An Overview of Current Evaluation Methods Used in Medical Image Segmentation CS-RR-15-08 An Overview of Current Evaluation Methods Used in Medical Image Segmentation
NR 24
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103929
DI 10.1016/j.jvcir.2023.103929
EA AUG 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R9VW0
UT WOS:001067764500001
DA 2024-07-18
ER

PT J
AU Wang, WQ
   An, P
   Huang, XP
   Huang, KQ
   Yang, C
AF Wang, Weiqian
   An, Ping
   Huang, Xinpeng
   Huang, Kunqiang
   Yang, Chao
TI Intermediate deep feature coding for human-machine vision collaboration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Collaborative intelligence; Deep feature coding; Non-uniform
   quantization; Compact representation
ID IMAGE; DESCRIPTORS; NETWORK; CLOUD
AB Traditional image coding are mainly designed for human vision. While for collaborative intelligence, deep feature coding is specific for machine vision, which includes feature extraction and compression. Actually, deep features can build a bridge between human and machine vision. Therefore, we focus on generalized deep feature extraction and compression for multitask, which includes image reconstruction task for human vision and computer visual tasks for machine vision. After analyzing correlation among multitask, a reconstruction guided feature extraction strategy and feature fusion based network are proposed to get more generalized intermediate deep feature, which contains sufficient information friendly for human and machine vision. Besides, a non-uniform quantization method based on importance and a compact representation method for feature distribution information protection are proposed for high efficiency feature coding. Eventually, we come up with an entire intermediate deep feature coding framework including feature extraction and compression. Experimental results indicate the performance gains with our framework.
C1 [Wang, Weiqian; An, Ping; Huang, Xinpeng; Huang, Kunqiang; Yang, Chao] Shanghai Univ, Sch Commun & Informat Engn, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP An, P (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM wq2693@shu.edu.cn; anping@shu.edu.cn; huangxinpeng@shu.edu.cn;
   huangxinpeng@shu.edu.cn; yangchaoie@shu.edu.cn
RI Huang, xp/JRX-2837-2023
OI Huang, Xinpeng/0000-0002-2373-642X
FU National Natural Science Foundation of China [62071287, 62020106011,
   61901252]; Science and Technology Commission of Shanghai Municipality
   [20DZ2290100]
FX This work was supported in part by the National Natural Science
   Foundation of China [Grants 62071287, 62020106011, and 61901252] ,
   Science and Technology Commission of Shanghai Municipality under Grant
   20DZ2290100.
CR Alvar SR, 2019, IEEE IMAGE PROC, P1705, DOI [10.1109/ICIP.2019.8803110, 10.1109/icip.2019.8803110]
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Bacca J, 2020, OPT EXPRESS, V28, P8528, DOI 10.1364/OE.381479
   Chen Z, 2020, IEEE T IMAGE PROCESS, V29, P2230, DOI 10.1109/TIP.2019.2941660
   Choi H., 2018, 2018 6th International Conference on Brain-Computer Interface (BCI), P1
   Choi H, 2018, IEEE IMAGE PROC, P3743, DOI 10.1109/ICIP.2018.8451100
   da Silveira RA, 2011, CURR OPIN NEUROBIOL, V21, P664, DOI 10.1016/j.conb.2011.05.007
   Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522
   Duan LY, 2019, IEEE MULTIMEDIA, V26, P44, DOI 10.1109/MMUL.2018.2873844
   Duan LY, 2016, IEEE T IMAGE PROCESS, V25, P179, DOI 10.1109/TIP.2015.2500034
   Duan LY, 2020, IEEE T IMAGE PROCESS, V29, P8680, DOI 10.1109/TIP.2020.3016485
   Eshratifar AE, 2021, IEEE T MOBILE COMPUT, V20, P565, DOI 10.1109/TMC.2019.2947893
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   Franzen R., 2013, Kodak lossless true color image suite
   Gao W., 2018, SCI SIN INFORM
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Hu YY, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102750
   Jiao SM, 2019, OPT LETT, V44, P5186, DOI 10.1364/OL.44.005186
   Jin X, 2019, NEUROCOMPUTING, V370, P166, DOI 10.1016/j.neucom.2019.06.102
   Kang YP, 2017, ACM SIGPLAN NOTICES, V52, P615, DOI 10.1145/3093336.3037698
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li AN, 2020, NEUROCOMPUTING, V411, P416, DOI 10.1016/j.neucom.2020.06.021
   Li Y, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Li YW, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103149
   Lou YH, 2019, IEEE J SEL AREA COMM, V37, P1489, DOI 10.1109/JSAC.2019.2916488
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma SW, 2019, IEEE T CIRC SYST VID, V29, P3095, DOI 10.1109/TCSVT.2018.2873102
   Muthumbi A, 2019, BIOMED OPT EXPRESS, V10, P6351, DOI 10.1364/BOE.10.006351
   Redondi A, 2016, IEEE T MOBILE COMPUT, V15, P3000, DOI 10.1109/TMC.2016.2519340
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang SR, 2019, IEEE IMAGE PROC, P2691, DOI [10.1109/ICIP.2019.8803255, 10.1109/icip.2019.8803255]
   Wang W., 2019, SPIE COS PHOTONICS A
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia SF, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102843
   Zhang SH, 2019, J VIS COMMUN IMAGE R, V62, P166, DOI 10.1016/j.jvcir.2019.05.003
   Zhang X, 2017, IEEE T IMAGE PROCESS, V26, P633, DOI 10.1109/TIP.2016.2629447
NR 40
TC 1
Z9 1
U1 4
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103859
DI 10.1016/j.jvcir.2023.103859
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K7JZ8
UT WOS:001018178800001
DA 2024-07-18
ER

PT J
AU García-Lucas, D
   Cebrián-Márquez, G
   Díaz-Honrubia, AJ
   Mallikarachchi, T
   Cuenca, P
AF Garcia-Lucas, D.
   Cebrian-Marquez, G.
   Diaz-Honrubia, A. J.
   Mallikarachchi, T.
   Cuenca, P.
TI A fast full partitioning algorithm for HEVC-to-VVC video transcoding
   using Bayesian classifiers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; VVC; Transcoding; MTT; Naive-Bayes
AB The Versatile Video Coding (VVC) standard was released in 2020 to replace the High Efficiency Video Coding (HEVC) standard, making it necessary to convert HEVC encoded content to VCC to exploit its compression performance, which was achieved by using a larger block size of 128 x 128 pixels, among other new coding tools. However, 80.93% of the encoding time is spent on finding a suitable block partitioning. To reduce this time, this proposal presents an HEVC-to-VVC transcoding algorithm focused on accelerating the CTU partitioning decisions. The transcoder takes different information from the input bitstream of HEVC, and feeds it to two Bayes-based models. Experimental results show a time saving in the transcoding process of 45.40%, compared with the traditional cascade transcoder. This time gain has been obtained on average for all test sequences in the Random Access scenario, at the expense of only 1.50% BD-rate.
C1 [Garcia-Lucas, D.] Univ Oviedo, Dept Comp Sci, Oviedo, Spain.
   [Cebrian-Marquez, G.; Cuenca, P.] Univ Castilla La Mancha, High Performance Networks & Architectures Grp, Ciudad Real, Spain.
   [Diaz-Honrubia, A. J.] Univ Politecn Madrid, ETS Ingn Informat, Madrid, Spain.
   [Mallikarachchi, T.] Cardiff Metropolitan Univ, Sch Technol, Cardiff, Wales.
C3 University of Oviedo; Universidad de Castilla-La Mancha; University of
   Sevilla; Universidad Politecnica de Madrid; Cardiff Metropolitan
   University
RP García-Lucas, D (corresponding author), Univ Oviedo, Dept Comp Sci, Oviedo, Spain.
EM garcialucdavid@uniovi.es; gabriel.cebrian@uclm.es;
   antoniojesus.diaz@upm.es; tmallikarachchi@cardiffmet.ac.uk;
   pedro.cuenca@uclm.es
OI Garcia Lucas, David/0000-0001-6934-1901
FU Regional Government of Castilla-La Mancha [SBPLY/21/180501/000195];
   Spanish Ministry of Science, Innovation and Universities; European
   Commission (FEDER) [PID2021-123627OB-C52, PID2021-128167OA-I00]; Spanish
   Ministry of Education, Culture and Sports [FPU16/05692]
FX This work has been supported by the Regional Government of Castilla-La
   Mancha under project SBPLY/21/180501/000195, by the Spanish Ministry of
   Science, Innovation and Universities and the European Commission (FEDER)
   under projects PID2021-123627OB-C52 and PID2021-128167OA-I00, and by the
   Spanish Ministry of Education, Culture and Sports under Grant
   FPU16/05692.
CR [Anonymous], 1996, Advances in knowledge discovery & data mining
   AOMedia, 2019, AV1 BITSTR DEC PROC
   Bjontegaard G., 2008, VCEGAI11
   Borges A, 2021, EUR SIGNAL PR CONF, P555, DOI 10.23919/Eusipco47968.2020.9287453
   Borges A, 2019, IEEE IMAGE PROC, P3571, DOI [10.1109/ICIP.2019.8803482, 10.1109/icip.2019.8803482]
   Bross B., 2020, JVET-S2001
   Bross B, 2019, Document JVET-N1001
   Ciou Y.-S., 2022, P IEEE INT C CONS EL, P471
   *CISC, 2019, CIS VIS NETW IND FOR
   Cisco, 2020, CISC ANN INT REP 201
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Franche JF, 2018, IEEE T CIRC SYST VID, V28, P3452, DOI 10.1109/TCSVT.2017.2754491
   Garcia-Lucas D., 2021, IMAGE COMMUN, V94
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   ISO/IEC ITU-T, 2003, ITU T RECOMMENDATION
   ISO/IEC ITU-T, 2013, ITU T RECOMMENDATION
   ITU-T, 2008, ITU T P910 SUBJECTIV
   JCT-VC, 2017, HEVC TEST MOD VERS 1
   JVET, 2022, VVC TEST MOD VERS 17
   JVET, 2018, VVC TEST MOD VERS 2
   Li X., 2017, JVET H1010
   Liu YQ, 2022, 2022 IEEE 14TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP), DOI 10.1109/IVMSP54334.2022.9816276
   Liu Z, 2022, IEEE DATA COMPR CONF, P468, DOI 10.1109/DCC52660.2022.00079
   Mukherjee D., 2015, SMPTE Motion Imaging Journal, V124, P44
   Pan ZQ, 2021, IEEE SIGNAL PROC LET, V28, P1260, DOI 10.1109/LSP.2021.3086692
   Sullivan G.J., 2018, JVETL1000
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang Y., 2021, IEEE Transactions on Circuits and Systems for Video Technology
   Witten IH, 2011, MOR KAUF D, P1
   Yeo Woon-Ha, 2021, Journal of Multimedia Information System, V8, P147
   Zhang YH, 2018, IEEE DATA COMPR CONF, P207, DOI 10.1109/DCC.2018.00029
NR 33
TC 2
Z9 2
U1 3
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103829
DI 10.1016/j.jvcir.2023.103829
EA MAY 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J5AF7
UT WOS:001009735700001
OA hybrid
DA 2024-07-18
ER

PT J
AU He, YQ
   Zhang, Z
   Wang, Z
   Luo, YK
   Su, L
   Li, WY
   Wang, P
   Zhang, W
AF He, Yunqian
   Zhang, Zhi
   Wang, Zhe
   Luo, Yongkang
   Su, Li
   Li, Wanyi
   Wang, Peng
   Zhang, Wen
TI IPC-Net: Incomplete point cloud classification network based on data
   augmentation and similarity measurement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Incomplete point clouds; Point cloud classification; Data augmentation;
   Similarity measurement
AB Existing point cloud classification researches are usually conducted on datasets with complete structure and clear semantics. However, in real point cloud scenes, the occlusion and truncation may destroy the completeness of objects affecting the classification performance. To solve this problem, we propose an incomplete point cloud classification network (IPC-Net) with data augmentation and similarity measurement. The proposed network learns the feature representation of incomplete point clouds and the semantic differences compared to the complete ones for classification. Specifically, IPC-Net adopts a random erasing-based data augmentation to deal with incomplete point clouds. IPC-Net also introduces an auxiliary loss function weighted by attention scores to measure the similarity between the incomplete and the complete point clouds. Extensive experiments verify that IPC-Net has the ability to classify incomplete point clouds and significantly improves the robustness of point cloud classification under different completeness.
C1 [He, Yunqian; Zhang, Zhi; Wang, Zhe; Su, Li; Zhang, Wen] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Luo, Yongkang; Li, Wanyi; Wang, Peng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Harbin Engineering University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Luo, YK (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
EM yongkang.luo@ia.ac.cn
FU Development Project of Ship Situational Intelligent Awareness System
   [MC-201920-X01]; National Natural Science Foundation of China [91748131,
   U1613213, 61771471]
FX This work was supported in part by the Development Project of Ship
   Situational Intelligent Awareness System (MC-201920-X01) , and in part
   by the National Natural Science Foundation of China under Grants
   (91748131, U1613213, 61771471) .
CR Atzmon M, 2018, Arxiv, DOI arXiv:1803.10091
   Hua BS, 2018, PROC CVPR IEEE, P984, DOI 10.1109/CVPR.2018.00109
   Cabon Y, 2020, Arxiv, DOI arXiv:2001.10773
   Chen Y., 2020, arXiv
   Cheng SL, 2021, IEEE T IMAGE PROCESS, V30, P4436, DOI 10.1109/TIP.2021.3072214
   Choi Y., 2020, arXiv
   Cui Y. An, 2020, IEEE Transactions on Instrumentation and Measurement, V70, P1
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Gadelha M, 2018, LECT NOTES COMPUT SC, V11211, P105, DOI 10.1007/978-3-030-01234-2_7
   Guo YL, 2015, IEEE T INSTRUM MEAS, V64, P683, DOI 10.1109/TIM.2014.2358131
   Hermosilla P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275110
   Jiang MY, 2018, Arxiv, DOI [arXiv:1807.00652, 10.48550/arXiv.1807.00652]
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Li JX, 2018, PROC CVPR IEEE, P9397, DOI 10.1109/CVPR.2018.00979
   Li RH, 2020, PROC CVPR IEEE, P6377, DOI 10.1109/CVPR42600.2020.00641
   Li YZ, 2018, ADV NEUR IN, V31
   Liu XH, 2019, AAAI CONF ARTIF INTE, P8778
   Liu YC, 2019, IEEE I CONF COMP VIS, P5238, DOI 10.1109/ICCV.2019.00534
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Ma X, 2022, Arxiv, DOI arXiv:2202.07123
   Magri L, 2018, INT CONF 3D VISION, P131, DOI 10.1109/3DV.2018.00025
   Mao JG, 2019, IEEE I CONF COMP VIS, P1578, DOI 10.1109/ICCV.2019.00166
   Muller Rafael, 2019, arXiv
   Prokudin S, 2019, IEEE I CONF COMP VIS, P4331, DOI 10.1109/ICCV.2019.00443
   Qiu S, 2022, IEEE T MULTIMEDIA, V24, P1943, DOI 10.1109/TMM.2021.3074240
   Qiu S, 2021, IEEE WINT CONF APPL, P3812, DOI 10.1109/WACV48630.2021.00386
   Qi CR, 2017, Arxiv, DOI [arXiv:1706.02413, DOI 10.48550/ARXIV.1706.02413]
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Uy MA, 2019, IEEE I CONF COMP VIS, P1588, DOI 10.1109/ICCV.2019.00167
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wen X, 2020, PROC CVPR IEEE, P1936, DOI 10.1109/CVPR42600.2020.00201
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie Haozhe, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P365, DOI 10.1007/978-3-030-58545-7_21
   Xu X., 2020, P IEEE CVF C COMP VI, P5661
   Xu YF, 2018, LECT NOTES COMPUT SC, V11212, P90, DOI 10.1007/978-3-030-01237-3_6
   Yan X., 2019, Pointnet=pointnet + + pytorch
   Yan X, 2020, PROC CVPR IEEE, P5588, DOI 10.1109/CVPR42600.2020.00563
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang CB, 2021, Arxiv, DOI arXiv:2011.12562
   Zhao HS, 2019, PROC CVPR IEEE, P5550, DOI 10.1109/CVPR.2019.00571
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zitian Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7659, DOI 10.1109/CVPR42600.2020.00768
NR 51
TC 3
Z9 3
U1 13
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103769
DI 10.1016/j.jvcir.2023.103769
EA JAN 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C6IO7
UT WOS:000962933700001
DA 2024-07-18
ER

PT J
AU Chen, S
   Qiu, LX
   Tian, ZM
   Yan, Y
   Wang, DH
   Zhu, SZ
AF Chen, Si
   Qiu, Liuxiang
   Tian, Zimin
   Yan, Yan
   Wang, Da-Han
   Zhu, Shunzhi
TI MTNet: Mutual tri-training network for unsupervised domain adaptation on
   person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Person re-identification; Domain adaptation; Mutual
   learning; Self-paced learning
AB The existing unsupervised domain adaptation (UDA) methods on person re-identification (re-ID) often employ clustering to assign pseudo labels for unlabeled target domain samples. However, it is difficult to give accurate pseudo labels to unlabeled samples in the clustering process. To solve this problem, we propose a novel mutual tri-training network, termed MTNet, for UDA person re-ID. The MTNet method can avoid noisy labels and enhance the complementarity of multiple branches by collaboratively training the three different branch networks. Specifically, the high-confidence pseudo labels are used to update each network branch according to the joint decisions of the other two branches. Moreover, inspired by self-paced learning, we employ a sample filtering scheme to feed unlabeled samples into the network from easy to hard, so as to avoid trapping in the local optimal solution. Extensive experiments show that the proposed method can achieve competitive performance compared with the state-of-the-art person re-ID methods.
C1 [Chen, Si; Qiu, Liuxiang; Tian, Zimin; Wang, Da-Han; Zhu, Shunzhi] Xiamen Univ Technol, Sch Comp & Informat Engn, Fujian Key Lab Pattern Recognit & Image Understand, Xiamen 361024, Peoples R China.
   [Yan, Yan] Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
C3 Xiamen University of Technology; Xiamen University
RP Zhu, SZ (corresponding author), Xiamen Univ Technol, Sch Comp & Informat Engn, Fujian Key Lab Pattern Recognit & Image Understand, Xiamen 361024, Peoples R China.
EM szzhu@xmut.edu.cn
RI Qiu, Liuxiang/JTU-4054-2023
OI Chen, Si/0000-0002-5631-7942; Qiu, Liuxiang/0009-0000-2789-2254
FU National Natural Sci-ence Foundation of China, China [62071404]; Natural
   Sci-ence Foundation of Fujian Province, China [2021J011185, 2020J01001];
   Youth Innovation Foundation of Xiamen City, China [3502Z20206068]; Joint
   Funds of 5th Round of Health and Education Research Program of Fujian
   Province, China [2019-WJ-41]; Science and Technology Planning Project of
   Fujian Province, China [2020H0023]
FX This work was supported in part by the National Natural Science
   Foundation of China, China (No. 62071404) ; the Natural Science
   Foundation of Fujian Province, China (Nos. 2021J011185 and 2020J01001) ;
   the Youth Innovation Foundation of Xiamen City, China (No.
   3502Z20206068) ; the Joint Funds of 5th Round of Health and Education
   Research Program of Fujian Province, China (No. 2019-WJ-41) ; and the
   Science and Technology Planning Project of Fujian Province, China (No.
   2020H0023) .
CR [Anonymous], 2018, PROC EUR C COMPUT VI
   Chen DD, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2014
   Chen H, 2023, INT J MODEL SIMUL SC, V14, DOI [10.1145/3549823.3549824, 10.1142/S1793962324500016, 10.1080/10298436.2021.2020269]
   Chen W, 2023, IEEE T PATTERN ANAL, V45, P7270, DOI 10.1109/TPAMI.2022.3218591
   Cireundefinedan D.C., 2011, IJCAI INT JOINT C AR, VTwo, P1237, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-210
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Dyer C., 2016, ARXIV160207776, DOI DOI 10.18653/V1/N16-1024
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Felzenszwalb P., 2008, 2008 IEEE C COMP VIS, DOI [10.1109/CVPR.2008.4587597, DOI 10.1109/CVPR.2008.4587597]
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ge Yu, 2022, ISCTT 2022; 7th International Conference on Information Science, Computer Technology and Transportation, P1
   Ge Y., 2020, P INT C LEARNING REP
   Ge Y., 2020, P NIPS, V33, P11309
   Ge YX, 2020, Arxiv, DOI arXiv:2008.10313
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guo XF, 2020, IEEE T KNOWL DATA EN, V32, P1680, DOI 10.1109/TKDE.2019.2911833
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2021, Arxiv, DOI arXiv:2108.05045
   Huang HJ, 2018, Arxiv, DOI [arXiv:1812.11369, DOI 10.48550/ARXIV.1812.11369]
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Li M., 2018, PROC EUR C COMPUT, P737
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu GQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103310
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Ming ZQ, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104394
   Natarajan N., 2013, ADV NEURAL INFORM PR, P1196, DOI DOI 10.5555/2999611.2999745
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Pawan Kumar M., 2010, NIPS
   Peng JJ, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108349
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Soviany P, 2022, INT J COMPUT VISION, V130, P1526, DOI 10.1007/s11263-022-01611-x
   Tagore NK, 2020, PROCEEDINGS OF THE 17TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS - DCNET, OPTICS, SIGMAP AND WINSYS (ICETE), VOL 2, P103, DOI 10.5220/0009885001030112
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang WH, 2022, IEEE T IMAGE PROCESS, V31, P1532, DOI 10.1109/TIP.2022.3140614
   Wang XP, 2021, IEEE T CIRC SYST VID, V31, P4020, DOI 10.1109/TCSVT.2020.3043444
   Wang XP, 2021, IEEE T IMAGE PROCESS, V30, P3017, DOI 10.1109/TIP.2021.3056223
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xiang S., 2022, MACH LEARN, P1
   Yang FX, 2020, AAAI CONF ARTIF INTE, V34, P12597
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yang Zou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P87, DOI 10.1007/978-3-030-58536-5_6
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu Xingrui, 2019, PROC INT C MACH LEAR, P7164
   Zhai Y, 2020, COMPUTER VISION ECCV, P594, DOI DOI 10.1007/978-3-030-58571-6_35
   Zhang Y, 2017, IEEE I CONF COMP VIS, P2039, DOI 10.1109/ICCV.2017.223
   Zhao Q, 2015, AAAI CONF ARTIF INTE, P3196
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu ZQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103303
NR 62
TC 5
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103749
DI 10.1016/j.jvcir.2022.103749
EA JAN 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8D4ZO
UT WOS:000918303100001
DA 2024-07-18
ER

PT J
AU Azadegan, H
   Shirazi, AAB
AF Azadegan, Hamid
   Shirazi, Ali-Asghar Beheshti
TI Improving video quality by predicting inter-frame residuals based on an
   additive 3D-CNN model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality improvement; Compression error; Video compression; Deep
   learning; Inter prediction
ID ENHANCEMENT
AB Video compression is essential for uploading videos to online platforms which usually have bandwidth limitations. However, the compression reduces the visual quality. To overcome this problem, the visual quality of the low bitrate compressed videos for various standards, including H.264 and HEVC in decoders, needs to be improved. Accordingly, this paper proposes a novel method for improving video quality based on 3D convolutional neural networks (CNNs). This method is totally compatible with the encoders of video compression standards, i.e., H.264, VVC, and HEVC, and can be implemented easily. In particular, the proposed neural network model receives five frames of the low bitrate compressed video as input and subsequently predicts the compression error of frames using the first and fifth frames. Finally, it reconstructs an improved version of the frame with high quality. The CNN is an Additive (3D) model that can predict the eliminated inter-frame redundancies resulting from compression. Our goal is to increase the peak signal to noise ratio (PSNR) and structural index similarity (SSIM) of the luminance (Y) and chrominance (U, V) frames in the video. Additive 3D CNN achieves an average of 12.4%, 9.9% and 5% BD-rate increases for LP, LB and RA for the Y component. The results indicate that the new proposed algorithm outperforms the previous methods in terms of PSNR, SSIM, and BD-rate.
C1 [Azadegan, Hamid; Shirazi, Ali-Asghar Beheshti] Iran Univ Sci & Technol, Dept Elect Engn, Tehran 1311416846, Iran.
C3 Iran University Science & Technology
RP Shirazi, AAB (corresponding author), Iran Univ Sci & Technol, Dept Elect Engn, Tehran 1311416846, Iran.
EM h_azadegan@vu.iust.ac.ir; abeheshti@iust.ac.ir
RI Beheshti Shirazi, Ali Asghar/T-6012-2018; Azadegan, Hamid/HJG-7117-2022
OI Azadegan, Hamid/0000-0003-3481-9391
CR [Anonymous], 2007, PROC INT C IMAGE PRO
   Asmare M.H., 2010, International Journal on Electrical Engineering and Informatics, V2, P29, DOI 10.15676/ijeei.2010.2.1.3
   Barnett T., 2018, AMERICASEMEAR CISCO
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bossen Frank., 2011, Joint Collaborative Team on Video Coding (JCT-VC), JCTVC-F900
   Bross B, 2021, P IEEE, V109, P1463, DOI 10.1109/JPROC.2020.3043399
   Byeon W, 2018, LECT NOTES COMPUT SC, V11220, P781, DOI 10.1007/978-3-030-01270-0_46
   Dai YY, 2017, LECT NOTES COMPUT SC, V10132, P28, DOI 10.1007/978-3-319-51811-4_3
   Ding DD, 2022, IEEE T IMAGE PROCESS, V31, P773, DOI 10.1109/TIP.2021.3134465
   Guan ZY, 2021, IEEE T PATTERN ANAL, V43, P949, DOI 10.1109/TPAMI.2019.2944806
   Hu H., 2010, VIDEO ENHANCEMENT CO
   Jin ZP, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1368, DOI 10.1109/ICASSP.2018.8461356
   Jing Li, 2009, Journal of Electronics, V26, P88, DOI 10.1007/s11767-007-0052-x
   Kingma D. P., 2015, INT C LEARNING REPRE
   Krishnamurthy R, 1999, IEEE T CIRC SYST VID, V9, P713, DOI 10.1109/76.780361
   Li C, 2017, IEEE IMAGE PROC, P4577, DOI 10.1109/ICIP.2017.8297149
   Lin RQ, 2016, IEEE DATA COMPR CONF, P617, DOI 10.1109/DCC.2016.83
   Ma L, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM)
   Meng XD, 2021, IEEE T CIRC SYST VID, V31, P2401, DOI 10.1109/TCSVT.2020.3019919
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Nguyen VA, 2009, IEEE IMAGE PROC, P2777, DOI 10.1109/ICIP.2009.5414193
   Rao Y., 2011, J INF HIDING MULTIME, V2, P282
   Song XD, 2018, IEEE IMAGE PROC, P1133, DOI 10.1109/ICIP.2018.8451589
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   VQEG, VQEG VIDEO DATASETS
   Wan T, 2008, INT CONF ACOUST SPEE, P1309
   Wang TT, 2018, IEEE DATA COMPR CONF, P197, DOI 10.1109/DCC.2018.00028
   Wang TT, 2017, IEEE DATA COMPR CONF, P410, DOI 10.1109/DCC.2017.42
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Xiao WH, 2020, IEEE T MULTIMEDIA, V22, P1680, DOI 10.1109/TMM.2020.2978664
   Xiph.org, XIPHORG DERFS TEST M
   Yang R, 2019, IEEE T CIRC SYST VID, V29, P2039, DOI 10.1109/TCSVT.2018.2867568
   Yang R, 2018, PROC CVPR IEEE, P6664, DOI 10.1109/CVPR.2018.00697
   Yang R, 2017, IEEE INT CON MULTI, P817, DOI 10.1109/ICME.2017.8019299
   Zhang YB, 2010, IEEE T IMAGE PROCESS, V19, P1248, DOI 10.1109/TIP.2009.2039055
   Zhang YB, 2009, IEEE T CIRC SYST VID, V19, P1289, DOI 10.1109/TCSVT.2009.2022798
   Zhao L, 2019, IEEE T IMAGE PROCESS, V28, P4832, DOI 10.1109/TIP.2019.2913545
   Zhao T., 2022, P 30 ACM INT C MULTI, P3045
   Zheng HT, 2018, LECT NOTES COMPUT SC, V11210, P87, DOI 10.1007/978-3-030-01231-1_6
NR 40
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103734
DI 10.1016/j.jvcir.2022.103734
EA DEC 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7U9LQ
UT WOS:000912446500001
DA 2024-07-18
ER

PT J
AU Verma, B
AF Verma, Bindu
TI A two stream convolutional neural network with bi-directional GRU model
   to classify dynamic hand gesture?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamichandgesture; Gatedrecurrentunit; Convolutionalneuralnetwork;
   Recurrentneuralnetwork
ID RECOGNITION; MANIFOLD
AB Dynamic hand gesture recognition is still an interesting topic for the computer vision community. A set of feature vectors can represent any hand gesture. A Recurrent Neural Network (RNN) can recognize these feature vectors as a hand gesture that analyzes the temporal and contextual information of the gesture sequence. Thus, we proposed a hybrid deep learning framework to recognize dynamic hand gestures. In the Hybrid model GoogleNet is pipelined with a Bidirectional GRU unit to recognize the dynamic hand gesture. Dynamic hand gestures consist of many frames, and features of each frame need to be extracted to get the temporal and dynamic information of the performed gesture. As RNN takes input as a sequence of feature vectors, we extract features from videos using pretrained GoogleNet. As Gated Recurrent Unit is one of the variants of RNN to classify the sequential data, we created a feature vector that corresponds to each video and passed it to the bidirectional GRU (BGRU) network to classify the gestures. We evaluate our model on four publicly available hand gesture datasets. The proposed method performs well and is comparable with the existing methods. For instance, we achieved 98.6% accuracy on Northwestern University Hand Gesture(NWUHG), 99.6% on SKIG, 99.4% on Cambridge Hand Gesture (CHG) datasets respectively. We performed our experiments on DHG14/28 dataset and achieved an accuracy of 97.8% with 14-gesture classes and 92.1% on 28-gesture classes. DHG14/28 dataset contains skeleton and depth data, and our proposed model used depth data and achieved comparable accuracy.
C1 [Verma, Bindu] Delhi Technol Univ, Dept Informat Technol, New Delhi, India.
C3 Delhi Technological University
RP Verma, B (corresponding author), Delhi Technol Univ, Dept Informat Technol, New Delhi, India.
EM bindu.cvision@gmail.com
CR Ameur S, 2020, ENTERTAIN COMPUT, V35, DOI 10.1016/j.entcom.2020.100373
   [Anonymous], 2018, P 11 INDIAN C COMPUT
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   Azad R, 2019, IEEE T CIRC SYST VID, V29, P1729, DOI 10.1109/TCSVT.2018.2855416
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   DeSmedt Q., 2016, P IEEE C COMP VIS PA, P1
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2013, IEEE SYS MAN CYBERN, P2103, DOI 10.1109/SMC.2013.360
   Hou JX, 2019, LECT NOTES COMPUT SC, V11134, P273, DOI 10.1007/978-3-030-11024-6_18
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Lai K, 2018, INT C PATT RECOG, P3451, DOI 10.1109/ICPR.2018.8545718
   Li C. L., 2021, ARXIV PREPRINT ARXIV
   Li DX, 2018, INT C PATT RECOG, P3365, DOI 10.1109/ICPR.2018.8545502
   Li YK, 2021, COMPUT GRAPH-UK, V97, P191, DOI 10.1016/j.cag.2021.04.017
   Liu JB, 2020, PROC CVPR IEEE, P5750, DOI 10.1109/CVPR42600.2020.00579
   Liu L., 2013, 2013 10 IEEE INT C W, P1
   Liu L., 2013, IJCAI
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Ma CY, 2018, VISUAL COMPUT, V34, P1053, DOI 10.1007/s00371-018-1556-0
   Maghoumi M, 2020, LECT NOTES COMPUT SC, V11844, P16, DOI 10.1007/978-3-030-33720-9_2
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Mujahid A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094164
   Nguyen XS, 2019, PROC CVPR IEEE, P12028, DOI 10.1109/CVPR.2019.01231
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Rui Y, 2019, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2019.2932058
   Sarma D., 2020, ARXIV200708847
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Shi L., 2020, P ASIAN C COMPUTER V
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Verma B., 2016, INT C SOFT COMP PATT, P304
   Verma B, 2021, MULTIMED TOOLS APPL, V80, P14019, DOI 10.1007/s11042-020-10341-6
   Verma B, 2020, MULTIMED TOOLS APPL, V79, P2213, DOI 10.1007/s11042-019-08266-w
   Verma B, 2018, IET INTELL TRANSP SY, V12, P721, DOI 10.1049/iet-its.2017.0331
   Wang GT, 2021, PROC CVPR IEEE, P15114, DOI 10.1109/CVPR46437.2021.01487
   Wang J., 2019, ARXIV190709173
   Wu Z., 2020, IEEE T MULTIMED
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Yang HM, 2021, SIGNAL IMAGE VIDEO P, V15, P617, DOI 10.1007/s11760-020-01783-4
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang W, 2020, VISUAL COMPUT, V36, P2433, DOI 10.1007/s00371-020-01955-w
   Zhang XY, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11040091
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
NR 49
TC 5
Z9 5
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103554
DI 10.1016/j.jvcir.2022.103554
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100004
DA 2024-07-18
ER

PT J
AU Xu, JS
   Klein, J
   Jochims, J
   Weissner, N
   Kays, R
AF Xu, Jianshuang
   Klein, Johannes
   Jochims, Joern
   Weissner, Niklas
   Kays, Ruediger
TI A reliable and unobtrusive approach to display area detection for
   imperceptible display camera communication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Display area detection; Display camera communication; Rectangle
   detection; Pattern recognition; Visible light communication
ID LINE SEGMENT DETECTOR; EDGE-DETECTION
AB Object framework detection has been extensively studied in computer vision for applications such as document digitization and whiteboard scanning. Similarly, it is essential for display-camera communication systems, particularly when imperceptible data modulation is employed to enable simultaneous video playback and data transmission. Reliable and accurate localization of the encoded display area is critical for data demodulation and decoding. However, existing systems typically adapt established methods developed for other applications that do not meet the system requirements for high-rate data transmission.In this article, we propose a novel method for display area detection in the camera images by embedding a new localization marker into the display corners. While the localization marker is less obtrusive than conventional fiducial markers, our detection algorithm demonstrated excellent reliability regardless of the display content and background, according to simulation and experimental results. In addition, the detector achieved subpixel accuracy and real-time performance with modern smartphones.
C1 [Xu, Jianshuang; Klein, Johannes; Jochims, Joern; Weissner, Niklas; Kays, Ruediger] TU Dortmund Univ, Commun Technol Inst, D-44221 Dortmund, Germany.
C3 Dortmund University of Technology
RP Xu, JS (corresponding author), TU Dortmund Univ, Commun Technol Inst, D-44221 Dortmund, Germany.
EM jianshuang.xu@tu-dortmund.de
RI Xu, Jianshuang/JNS-0406-2023
OI Jochims, Jorn/0000-0003-4584-3389
FU German Federal Ministry of Educa-tion and Research [03VP03900]
FX Acknowledgments This work was supported by the German Federal Ministry
   of Educa-tion and Research under grant agreement no. 03VP03900, also
   referred to as DaViD.
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2015, International Organization for Standardization
   Asif MR, 2017, J VIS COMMUN IMAGE R, V46, P176, DOI 10.1016/j.jvcir.2017.03.020
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen CS, 2019, IEEE T IMAGE PROCESS, V28, P156, DOI 10.1109/TIP.2018.2865681
   Dickson PE, 2008, IEEE INT SYM MULTIM, P702, DOI 10.1109/ISM.2008.35
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Fan Jing, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538554
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hao T., 2012, Proceedings of the 10th international conference on Mobile systems, applications, and services, P85, DOI 10.1145/2307636.2307645
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hranilovic S, 2006, IEEE J SEL TOP QUANT, V12, P859, DOI 10.1109/JSTQE.2006.876601
   ISO, 2006, 16 ISO ISOIEC, VISO/IEC 16
   ITU, 2015, BT709 ITU
   Izz M, 2016, IEEE INFOCOM SER
   Javed K, 2017, PROC INT CONF DOC, P105, DOI 10.1109/ICDAR.2017.26
   Kays R, 2015, I SYMP CONSUM ELECTR, P554, DOI 10.1109/ICCE.2015.7066522
   Li Tianxing., 2015, ACM SIGMOBILE MOBILE, V18, P62
   Liu N., 2018, US Patent, Patent No. [10,134,163, 10134163]
   Peng C., 2019, IEEE ICC, P1, DOI DOI 10.1109/icc.2019.8761989
   Perli SD, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P137
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shi SY, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P157, DOI 10.1145/2750858.2805824
   Sobel I., 1968, STANF ART PROJ, P271
   Takezawa Y, 2017, PROC INT CONF DOC, P27, DOI 10.1109/ICDAR.2017.345
   Topal C, 2012, J VIS COMMUN IMAGE R, V23, P862, DOI 10.1016/j.jvcir.2012.05.004
   Tropin DV, 2021, INT C PATT RECOG, P9689, DOI 10.1109/ICPR48806.2021.9413271
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang Anran., 2015, ACM MOBISYS, P181, DOI [/10.1145/2742647.2742652, 10.1145/2742647.2742652]
   Wang Q, 2015, INT CON DISTR COMP S, P537, DOI 10.1109/ICDCS.2015.61
   Wenzel T, 2017, IEEE INT VEH SYM, P1039, DOI 10.1109/IVS.2017.7995851
   Wenzel T, 2016, IEEE INT VEH SYM, P316, DOI 10.1109/IVS.2016.7535404
   Wu XL, 2015, INT CONF ACOUST SPEE, P1657, DOI 10.1109/ICASSP.2015.7178252
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu JS, 2019, INT CONF WIREL OPT, P105, DOI 10.1109/wocc.2019.8770659
   Yuan W., 2012, P 2012 IEEE WORKSH A, P345, DOI DOI 10.1109/WACV.2012.6162992
   Zhang K, 2021, IEEE T MOBILE COMPUT, V20, P861, DOI 10.1109/TMC.2019.2956493
   Zhang L, 2002, PATTERN RECOGN LETT, V23, P1771, DOI 10.1016/S0167-8655(02)00151-4
   Zhang ZY, 2007, DIGIT SIGNAL PROCESS, V17, P414, DOI 10.1016/j.dsp.2006.05.006
NR 42
TC 6
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103510
DI 10.1016/j.jvcir.2022.103510
EA APR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600003
DA 2024-07-18
ER

PT J
AU Lee, JH
   Kim, CS
AF Lee, Jae-Han
   Kim, Chang-Su
TI Single-image depth estimation using relative depths
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular depth estimation; Relative depth; 3D analysis
ID TEXTURE; RECOGNITION; MOTION; SHAPE
AB Depth estimation from a single RGB image is a challenging task. It is ill-posed since a single 2D image may correspond to various 3D scenes at different scales. On the other hand, estimating the relative depth relationship between two objects in a scene is easier and may yield more reliable results. Thus, in this paper, we propose a novel algorithm for monocular depth estimation using relative depths. First, using a convolutional neural network, we estimate two types of depths at multiple spatial resolutions: ordinary depth maps and relative depth tensors. Second, we restore a relative depth map from each relative depth tensor. A relative depth map is equivalent to an ordinary depth map with global scale information removed. For the restoration, sparse pairwise comparison matrices are constructed from available relative depths, and missing entries are filled in using the alternative least square (ALS) algorithm. Third, we decompose the ordinary and relative depth maps into components and recombine them to yield a final depth map. To reduce the computational complexity, relative depths at fine spatial resolutions are directly used to refine the final depth map. Extensive experimental results on the NYUv2 dataset demonstrate that the proposed algorithm provides state-of-the-art performance.
C1 [Lee, Jae-Han; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
C3 Korea University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul 02841, South Korea.
EM jaehanlee@mcl.korea.ac.kr; changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU DAPA [UD190031RD]; ADD, Republic of Korea
FX Acknowledgments This work was conducted by Center for Applied Research
   in Artifi-cial Intelligence (CARAI) grant funded by DAPA and ADD,
   Republic of Korea (UD190031RD) .
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Biswas J, 2012, IEEE INT CONF ROBOT, P1697, DOI 10.1109/icra.2012.6224766
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chakrabarti Ayan, 2016, Advances in Neural Information Processing Systems, P2658
   Chen CH, 2008, INT C PATT RECOG, P1814
   Chen Wei, 2016, Advances in Neural Information Processing Systems, P1659
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Clerc M, 2002, IEEE T PATTERN ANAL, V24, P536, DOI 10.1109/34.993560
   Delage E., 2006, COMP VIS PATT REC 20, V2, P2418, DOI DOI 10.1109/CVPR.2006.23
   DIACONIS P, 1977, J ROY STAT SOC B MET, V39, P262, DOI 10.1111/j.2517-6161.1977.tb01624.x
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Flint A, 2011, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2011.6126501
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gupta A., 2010, ADV NEURAL INFORM PR, P1288
   Gupta A, 2010, LECT NOTES COMPUT SC, V6314, P482, DOI 10.1007/978-3-642-15561-1_35
   Hang, 2018, DEEP ATTENTION BASED
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heo M, 2018, LECT NOTES COMPUT SC, V11208, P39, DOI 10.1007/978-3-030-01225-0_3
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Johnson, 2012, MATRIX ANAL
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Karsch K, 2012, LECT NOTES COMPUT SC, V7576, P775, DOI 10.1007/978-3-642-33715-4_56
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205
   Kim S, 2016, LECT NOTES COMPUT SC, V9912, P143, DOI 10.1007/978-3-319-46484-8_9
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Konrad J, 2013, IEEE T IMAGE PROCESS, V22, P3485, DOI 10.1109/TIP.2013.2270375
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu A, 2014, LECT NOTES COMPUT SC, V8694, P703, DOI 10.1007/978-3-319-10599-4_45
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee J.-H., ICCV, P2021
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Lee JH, 2018, PROC CVPR IEEE, P330, DOI 10.1109/CVPR.2018.00042
   Lee Jae-Han, 2020, ECCV
   Lee Seon-Ho, 2021, ICLR
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Lim Kyungsun, 2020, ICLR
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97
   Maki A, 2002, INT J COMPUT VISION, V48, P75, DOI 10.1023/A:1016057422703
   Malik J, 1997, INT J COMPUT VISION, V23, P149, DOI 10.1023/A:1007958829620
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037
   Rajagopalan AN, 2004, IEEE T PATTERN ANAL, V26, P1521, DOI 10.1109/TPAMI.2004.102
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594
   SAATY TL, 1977, J MATH PSYCHOL, V15, P234, DOI 10.1016/0022-2496(77)90033-5
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   SEN PK, 1968, J AM STAT ASSOC, V63, P1379
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, CORR
   Tan MX, 2019, PR MACH LEARN RES, V97
   Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Wedel A, 2006, LECT NOTES COMPUT SC, V4174, P475
   Xian K, 2020, PROC CVPR IEEE, P608, DOI 10.1109/CVPR42600.2020.00069
   Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Xu D, 2017, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2017.25
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Ye M, 2011, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2011.6126310
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhang ZY, 2019, PROC CVPR IEEE, P4101, DOI 10.1109/CVPR.2019.00423
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zoran D, 2015, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2015.52
NR 91
TC 3
Z9 3
U1 4
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103459
DI 10.1016/j.jvcir.2022.103459
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PF
UT WOS:000783924700005
DA 2024-07-18
ER

PT J
AU Mazumdar, A
   Bora, PK
AF Mazumdar, Aniruddha
   Bora, Prabin Kumar
TI Two-stream encoder-decoder network for localizing image forgeries
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Forgery localization; CNN; Encoder-decoder network
ID LOCALIZATION
AB This paper proposes a novel two-stream encoder-decoder network that utilizes both the high-level and the low-level image features for precisely localizing forged regions in a manipulated image. This is motivated by the fact that the forgery creation process generally introduces both the high-level artefacts (e.g., unnatural contrast) and the low-level artefacts (e.g., noise inconsistency) to the forged images. In the proposed two-stream network, one stream learns the low-level manipulation-related features in the encoder side by extracting noise residuals through a set of high-pass filters in the first layer. In the second stream, the encoder learns the highlevel image manipulation features from the input image RGB values. The coarse feature maps each encoder are upsampled by the corresponding decoder network to produce the dense feature maps. The dense feature maps of the two streams are concatenated and fed to a final convolutional layer with sigmoidal activation to produce the pixel-wise prediction. We have carried out experimental analyses on multiple standard forensics datasets to evaluate the performance of the proposed method. The experimental results show the efficacy of the proposed method with respect to the state-of-the-art.
C1 [Mazumdar, Aniruddha; Bora, Prabin Kumar] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Mazumdar, A (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, Assam, India.
EM m.aniruddha@iitg.ac.in
CR Adams J, 1998, IEEE MICRO, V18, P20, DOI 10.1109/40.743681
   [Anonymous], 2013, ICML
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bondi L, 2017, IEEE COMPUT SOC CONF, P1855, DOI 10.1109/CVPRW.2017.232
   BOUMAN KL, 2016, INT SUST REM FOR C, P1
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Cozzolino D., 2019, IEEE T INF FORENSICS
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Deng RX, 2018, LECT NOTES COMPUT SC, V11210, P570, DOI 10.1007/978-3-030-01231-1_35
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horn B.K.P, 1986, Robot Vision
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kniaz VV, 2019, ADV NEUR IN, V32, P215
   Krawetz N., 2007, HACKER FACTOR SOLUTI, P1
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Ng T.T., 2004, ADVENT Technical Report
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   RADON J, 1986, IEEE T MED IMAGING, V5, P170, DOI 10.1109/TMI.1986.4307775
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Tiwari SK, 2019, LECT NOTES COMPUT SC, V11941, P473, DOI 10.1007/978-3-030-34869-4_51
   Wu Y., 2018, IEEE WINT CONF APPL, P168, DOI DOI 10.1109/WACV.2018.00211
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Zampoglou M, 2017, MULTIMED TOOLS APPL, V76, P4801, DOI 10.1007/s11042-016-3795-2
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
NR 41
TC 5
Z9 5
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103417
DI 10.1016/j.jvcir.2021.103417
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, YK
   Fu, FW
AF Zhao, Yongkang
   Fu, Fang-Wei
TI A contrast improved OR and XOR based (k, n) visual cryptography scheme
   without pixel expansion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Multiple decryptions; Contrast; Perfect recovery;
   Threshold
AB Visual cryptography scheme (VCS) is a branch of secret sharing, in which a secret image is encrypted into n noise-like shares. In the recovering phase, the secret image can be reconstructed by stacking sufficient shares. It's obvious that VCS with multiple decryptions can further widen the range of application. However, the investigations on the existing scheme with multiple decryptions are not sufficient. In this paper, we develop a novel contrast improved OR and XOR based (k, n)-VCS without pixel expansion. Significantly, we give a general simplified calculation formula to compute the theoretical contrast of the proposed scheme. In addition, if there are no computing devices, then we can reconstruct the secret image by stacking the shares directly. Meanwhile, we recover the secret image perfectly by performing XOR operation when computing devices are available. Since the proposed scheme is based on the parity basis matrices, our scheme has no pixel expansion. Finally, Theoretical analysis and experimental results are conducted to evaluate the efficiency and security of the proposed scheme.
C1 [Zhao, Yongkang] Nankai Univ, Chern Inst Math, Tianjin 300071, Peoples R China.
   Nankai Univ, LPMC, Tianjin 300071, Peoples R China.
C3 Nankai University; Nankai University
RP Zhao, YK (corresponding author), Nankai Univ, Chern Inst Math, Tianjin 300071, Peoples R China.
EM zhaoyk@mail.nankai.edu.cn; fwfu@nankai.edu.cn
RI Fu, Fang-Wei/L-8164-2015
FU National Key Research and De-velopment Program of China
   [2018YFA0704703]; Na-tional Natural Science Foundation of China
   [61971243]; Natural Science Foundation of Tianjin [20JCZDJC00610];
   Fundamental Research Funds for the Central Universities of China (Nankai
   University)
FX Acknowledgements This research is supported by the National Key Research
   and De-velopment Program of China (Grant No. 2018YFA0704703) , the
   Na-tional Natural Science Foundation of China (Grant No. 61971243) , the
   Natural Science Foundation of Tianjin (20JCZDJC00610) , and the
   Fundamental Research Funds for the Central Universities of China (Nankai
   University) .
CR [Anonymous], 2009, PATTERN RECOGN
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Cimato S, 2003, 2003 IEEE INFORMATION THEORY WORKSHOP, PROCEEDINGS, P139, DOI 10.1109/ITW.2003.1216714
   Fu ZX, 2019, MULTIMED TOOLS APPL, V78, P2367, DOI 10.1007/s11042-018-6364-z
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hu H, 2018, KSII T INTERNET INF, V12, P3401, DOI 10.3837/tiis.2018.07.022
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Liu F, 2010, IEEE T INF FOREN SEC, V5, P27, DOI 10.1109/TIFS.2009.2037660
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wu H.C., 2008, COLOR VISUAL CRYPTOG, V3, P173
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yan X.H., 2016, P SOC COMP 2 INT C Y, V1, P249, DOI DOI 10.1007/978-981-10-2053-7_23
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P13, DOI 10.1007/s11554-016-0639-2
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 25
TC 3
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103408
DI 10.1016/j.jvcir.2021.103408
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PA
UT WOS:000783924200002
DA 2024-07-18
ER

PT J
AU Fan, GJ
   Pan, ZB
   Zhou, Q
   Gao, XY
   Zhang, XR
AF Fan, Guojun
   Pan, Zhibin
   Zhou, Quan
   Gao, Xinyi
   Zhang, Xiaoran
TI A comparative study between PVO-based framework and multi-predictor
   mechanism in reversible data hiding*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; General multi-predictor framework;
   Pixel-value-ordering (PVO); Additional predictors; Adaptive complexity
ID IMAGE; WATERMARKING; EXPANSION; ALGORITHM; VIDEO
AB Sorting-based reversible data hiding (RDH) methods like pixel-value-ordering (PVO) can predict pixel values accurately and achieve an extremely low distortion on the embedded image. However, the excellent performance of these methods was not well explained in previous works, and there are unexploited common points among them. In this paper, we propose a general multi-predictor (GMP) framework to summarize PVO-based RDH methods and explain their high prediction accuracy. Moreover, by utilizing the proposed GMP framework, a more efficient sorting-based RDH method is given as an example to show the generality and applicability of our framework. Comparing with other PVO-based methods, the proposed example method can achieve significant improvement in embedding performance. It is hopeful that more efficient sorting-based RDH algorithms can be designed according to our proposed framework by designing better predictors and their combination methods.
C1 [Fan, Guojun; Pan, Zhibin; Gao, Xinyi; Zhang, Xiaoran] Xi An Jiao Tong Univ, Fac Elect & Informat Engn, Xian 710049, Peoples R China.
   [Zhou, Quan] China Acad Space Technol, Natl Key Lab Sci & Technol Space Microwave, Xian 710100, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Fac Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU National Key Laboratory Foundation of China [HTKJ2020KL504015]; National
   Natural Science Foundation of China [U1903213]; Key Science and
   Technology Program of Shaanxi Province [2020GY-005]; Open Project of the
   National Laboratory of Pattern Recognition [202100033]
FX This work is supported in part by the National Key Laboratory Foundation
   of China (Grant No. HTKJ2020KL504015) , the National Natural Science
   Foundation of China (Grant No. U1903213) , the Key Science and
   Technology Program of Shaanxi Province (Grant No. 2020GY-005) and the
   Open Project of the National Laboratory of Pattern Recognition (Grant
   No. 202100033) .
CR Caldelli R, 2010, EURASIP J INF SECUR, DOI 10.1155/2010/134546
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Dragoi IC, 2018, IEEE IMAGE PROC, P1668, DOI 10.1109/ICIP.2018.8451299
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Fan GJ, 2021, SIGNAL PROCESS, V180, DOI 10.1016/j.sigpro.2020.107888
   Gao ED, 2019, INFORM SCIENCES, V505, P549, DOI 10.1016/j.ins.2019.07.101
   He WG, 2020, IEEE T INF FOREN SEC, V15, P3859, DOI 10.1109/TIFS.2020.3002377
   He WG, 2020, INFORM SCIENCES, V520, P431, DOI 10.1016/j.ins.2020.02.003
   He WG, 2017, J VIS COMMUN IMAGE R, V46, P58, DOI 10.1016/j.jvcir.2017.03.010
   Huang LC, 2013, J SYST SOFTWARE, V86, P716, DOI 10.1016/j.jss.2012.11.024
   Jiang J, 2000, IEE P-VIS IMAGE SIGN, V147, P575, DOI 10.1049/ip-vis:20000767
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kim S, 2019, IEEE T CIRC SYST VID, V29, P3236, DOI 10.1109/TCSVT.2018.2878932
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2019, IEEE T CIRC SYST VID, V29, P2176, DOI 10.1109/TCSVT.2018.2859792
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2020, IEEE SIGNAL PROC LET, V27, P915, DOI 10.1109/LSP.2020.2996507
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P26047, DOI 10.1007/s11042-019-7692-3
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qi WF, 2020, IEEE T CIRC SYST VID, V30, P2300, DOI 10.1109/TCSVT.2019.2942489
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tang HJ, 2006, IEICE T INF SYST, VE89D, P2250, DOI 10.1093/ietisy/e89-d.7.2250
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P685, DOI 10.1109/TIP.2003.810588
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
NR 47
TC 6
Z9 6
U1 3
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103349
DI 10.1016/j.jvcir.2021.103349
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700003
DA 2024-07-18
ER

PT J
AU Zhang, JP
   Zhang, L
   Liu, TY
   Wang, YH
AF Zhang, Jinpu
   Zhang, Lei
   Liu, Tianyu
   Wang, Yuehuan
TI YOLSO: You Only Look Small Object
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Small object detection; Background-aware; Granular feature aggregation;
   Accurate location; High speed
AB Small object detection is challenging and far from satisfactory. Most general object detectors suffer from two critical issues with small objects: (1) Feature extractor based on classification network cannot express the characteristics of small objects reasonably due to insufficient appearance information of targets and a large amount of background interference around them. (2) The detector requires a much higher location accuracy for small objects than for general objects. This paper proposes an effective and efficient small object detector YOLSO to address the above problems. For feature representation, we analyze the drawbacks in previous backbones and present a Half-Space Shortcut (HSSC) module to build a background-aware backbone. Furthermore, a coarse to-fine Feature Pyramid Enhancement (FPE) module is introduced for layer-wise aggregation at a granular level to enhance the semantic discriminability. For loss function, we propose an exponential L1 loss to promote the convergence of regression, and a focal IOU loss to focus on prime samples with high classification confidence and high IOU. Both of them significantly improves the location accuracy of small objects. The proposed YOLSO sets state-of-the-art results on two typical small object datasets, MOCOD and VeDAI, at a speed of over 200 FPS. In the meantime, it also outperforms the baseline YOLOv3 by a wide margin on the common COCO dataset.
C1 [Zhang, Jinpu; Zhang, Lei; Liu, Tianyu; Wang, Yuehuan] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, YH (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Peoples R China.
EM yuehwang@hust.edu.cn
OI zhang, jinpu/0000-0002-0617-0452; Wang, Yuehuan/0000-0001-7046-7587
CR Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen XZ, 2015, ADV NEUR IN, V28
   Dai JF, 2016, ADV NEUR IN, V29
   Dai YJ, 2022, SEP SCI TECHNOL, V57, P656, DOI 10.1080/01496395.2021.1927094
   Eggert C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P172, DOI 10.1145/3078971.3078990
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   ICIG2019, 2019, MOR COMM OBJ DET MOC
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kisantal M., 2019, P 9 INT C ADV COMP I, DOI 10.5121/csit.2019.91713
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laurense VA, 2017, P AMER CONTR CONF, P5586, DOI 10.23919/ACC.2017.7963824
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ming Q., 2021, ARXIV PREPRINT ARXIV
   Ming Q, 2021, AAAI CONF ARTIF INTE, V35, P2355
   Ming Q, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13142664
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Redmon Joseph, 2013, Darknet: Open Source Neural Networks in C, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, CORR
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wells P., 2000, INT C IM PROC ITS AP
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou X., 2019, arXiv
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538
   Zou Z., 2019, ARXIV PREPRINT ARXIV
NR 42
TC 6
Z9 8
U1 3
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103348
DI 10.1016/j.jvcir.2021.103348
EA OCT 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WP1JM
UT WOS:000712896500003
DA 2024-07-18
ER

PT J
AU Liang, S
   Liu, RH
   Qian, JS
AF Liang, Song
   Liu, Ruihang
   Qian, Jiansheng
TI Fixation prediction for advertising images: Dataset and benchmark
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency prediction; Advertising; OCR; Lightweight architecture
ID SALIENCY DETECTION; VISUAL-ATTENTION; EYE FIXATIONS; PICTORIAL; SCENES;
   BRAND; TEXT
AB Existing saliency prediction methods focus on exploring a universal saliency model for natural images, relatively few on advertising images which typically consists of both textual regions and pictorial regions. To fill this gap, we first build an advertising image database, named ADD1000, recording 57 subjects' eye movement data of 1000 ad images. Compared to natural images, advertising images contain more artificial scenarios and show stronger persuasiveness and deliberateness, while the impact of this scene heterogeneity on visual attention is rarely studied. Moreover, text elements and picture elements express closely related semantic information to highlight product or brand in ad images, while their respective contribution to visual attention is also less known. Motivated by these, we further propose a saliency prediction model for advertising images based on text enhanced learning (TEL-SP), which comprehensively considers the interplay between textual region and pictorial region. Extensive experiments on the ADD1000 database show that the proposed model outperforms existing state-of-the-art methods.
C1 [Liang, Song; Liu, Ruihang; Qian, Jiansheng] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Qian, JS (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
EM qianzhangiqa@126.com
OI Qian, Jiansheng/0000-0002-1117-6453; Liang, Song/0000-0003-4251-3798
CR [Anonymous], P ADV NEUR INF PROC
   [Anonymous], 2021, P IEEE C COMP VIS PA
   Bannier K, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204560
   Borji A., 2015, P CVPR WORKSH FUT DA
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Castelhano, 2008, VISUAL ADVERTISING H
   Chen CLZ, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3447393
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Cheng, 2020, P IEEE T PATT AN MAC
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Cozot, PLOS ONE, V15
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dickinson CA, 2009, ATTEN PERCEPT PSYCHO, V71, P1251, DOI 10.3758/APP.71.6.1251
   Galley N., 2015, Advances in visual perception research, P83
   Grigaliunaite V, 2016, SCI ANN ECON BUS, V63, P391, DOI 10.1515/saeb-2016-0130
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Higgins E, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00210
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Howard, 2017, P IEEE C COMP VIS PA
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Hutchinson J.W., 2017, ROUTLEDGE INT HDB CO, P61
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jakstiene S., 2008, Communications of the IBIMIA, V3, P50
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Jiang HY, 2016, J CONSUM BEHAV, V15, P126, DOI 10.1002/cb.1551
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   JOHAR JS, 1991, J ADVERTISING, V20, P23, DOI 10.1080/00913367.1991.10673345
   Judd T., 2012, A benchmark of computational models of saliency to predict human fixations
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   JUST MA, 1976, COGNITIVE PSYCHOL, V8, P441, DOI 10.1016/0010-0285(76)90015-3
   Kamath S.S., 2016, INT VIDE ANAL AUDI M, V10165, P48
   Kessous A, 2015, J MARKET MANAG-UK, V31, P1899, DOI 10.1080/0267257X.2015.1088889
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Kummerer M., 2016, DeepGaze II: Reading fixations from deep features trained on object recognition
   Kummerer M., 2014, ARXIV14111045
   Le Meur O, 2016, VISION RES, V121, P72, DOI 10.1016/j.visres.2016.01.005
   Leigh RJ, 2004, BRAIN, V127, P460, DOI 10.1093/brain/awh035
   Li, 2021, P IEEE C COMP VIS PA
   Li LD, 2020, IEEE T IMAGE PROCESS, V29, P3898, DOI 10.1109/TIP.2020.2968285
   Liang M, 2015, IEEE T IMAGE PROCESS, V24, P1178, DOI 10.1109/TIP.2015.2395713
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu Y, 2020, PROC CVPR IEEE, P2643, DOI 10.1109/CVPR42600.2020.00272
   Lynch M., 2015, TECHNOLOGY MULTISENS
   MA Z, 2009, P INT C MULT EXP
   MARCELLA C, 2018, P IEEE T IM PROC, V27, P5142
   Mei J, 2022, IEEE T PATTERN ANAL, V44, P4374, DOI 10.1109/TPAMI.2021.3065086
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Miniotas, 2007, ELECT ENG, V2
   Momtaz HZ, 2016, J INTEGR NEUROSCI, V15, P37, DOI 10.1142/S0219635216500023
   Noguer, 2015, ENHANCING LOW LEVEL
   Nuijten KCM, 2013, INT J ARTS TECHNOL, V6, P5, DOI 10.1504/IJART.2013.050686
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Pajak M, 2013, J VISION, V13, DOI 10.1167/13.5.2
   Pan J., 2017, PROC IEEE C COMPUT V
   Pieters R, 2004, J MARKETING, V68, P36, DOI 10.1509/jmkg.68.2.36.27794
   Pochun T, 2018, AUSTRALAS MARK J, V26, P338, DOI 10.1016/j.ausmj.2018.09.002
   Rayner K, 2001, J EXP PSYCHOL-APPL, V7, P219, DOI 10.1037/1076-898X.7.3.219
   Reddy N, 2020, IEEE INT C INT ROBOT, P10241, DOI 10.1109/IROS45743.2020.9341574
   Riche N., 2012, P ACCV NOV, P586
   ROBERT R, 2013, INTERACT COMPUT, V25, P218
   RYU YS, 2009, INT C ENG PSYCHOL CO
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Schnotz W, 2003, LEARN INSTR, V13, P141, DOI 10.1016/S0959-4752(02)00017-8
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tatler BW, 2008, J EYE MOVEMENT RES, V2
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang GT, 2021, PROC CVPR IEEE, P15114, DOI 10.1109/CVPR46437.2021.01487
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang WG, 2020, IEEE T PATTERN ANAL, V42, P1913, DOI 10.1109/TPAMI.2019.2905607
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Xiao Y., 2016, P 2 INT C EC MAN ENG, V87
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu N., 2018, ARXIV180903327
   YANG S, 2020, IEEE T MULTIMED, V22
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang YF, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103224
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhuge M., ARXIV PREPRINT ARXIV
NR 93
TC 5
Z9 5
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103356
DI 10.1016/j.jvcir.2021.103356
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA WP1JM
UT WOS:000712896500002
DA 2024-07-18
ER

PT J
AU Liu, JX
   Yu, D
   Tang, Z
AF Liu, Jixin
   Yu, Dan
   Tang, Zheng
TI Video summary generation by visual shielding compressed sensing coding
   and double-layer affinity propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual shielding; Video summary technology; Compressed sensing;
   Double-layer affinity propagation; Feature fusion
ID KEY-FRAME EXTRACTION; KEYFRAME EXTRACTION
AB Video summary technology based on keyframe extraction is an effective means to rapidly access video content. Traditional video summary generation technology requires high video resolution, which poses a problem as most existing studies have no targeted solutions for videos that are subject to privacy protection. We propose a novel keyframe extraction algorithm for video data in the visual shielding domain, named visual shielding compressed sensing coding and double-layer affinity propagation (VSCS-DAP). VSCS-DAP involves three main steps. First, the video is compressed by compressed sensing technology to provide a visual shielding effect (protecting the privacy of monitored figures), while the data volume is significantly reduced. Then, pyramid histogram of oriented gradients (PHOG) features are extracted from the compressed video to be clustered by the first step affinity propagation (AP) to gain the summaries of the first stage. Finally, the PHOG and Hist fusion features are extracted from the keyframes of the first stage, and they cluster the fused PHOG-Hist features by the second step AP algorithm to obtain the final output summaries. Experimental results obtained on two common video datasets show that our method exhibits advantages including low redundancy and few missing frames, low computational complexity, strong real-time performance, and robustness to vision-shielded video.
C1 [Liu, Jixin; Yu, Dan; Tang, Zheng] Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
   [Liu, Jixin] Hangzhou Joyware Ltd Corp, Hangzhou 310051, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Liu, JX (corresponding author), Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
EM liujixin@njupt.edu.cn
RI LIU, Jixin/AHC-0596-2022
CR Demir M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1071, DOI 10.1109/ICCVW.2015.140
   Ejaz N, 2012, J VIS COMMUN IMAGE R, V23, P1031, DOI 10.1016/j.jvcir.2012.06.013
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gygli M, 2014, LECT NOTES COMPUT SC, V8695, P505, DOI 10.1007/978-3-319-10584-0_33
   Hannane R, 2018, J VIS COMMUN IMAGE R, V55, P179, DOI 10.1016/j.jvcir.2018.06.002
   Hannane R, 2016, INT J MULTIMED INF R, V5, P89, DOI 10.1007/s13735-016-0095-6
   Hannane R, 2016, I C COMP GRAPH IM VI, P312, DOI 10.1109/CGiV.2016.67
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Jin K., 2013, APPL MECH MAT, V347-350, P3866
   Knoche H, 1999, INT WORKSH QUAL SERV, P12, DOI 10.1109/IWQOS.1999.766473
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar M., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2437, DOI 10.1109/ICIP.2011.6116136
   Kuncheva LI, 2018, J VIS COMMUN IMAGE R, V52, P118, DOI 10.1016/j.jvcir.2018.02.010
   Lai JL, 2012, J VIS COMMUN IMAGE R, V23, P114, DOI 10.1016/j.jvcir.2011.08.005
   Li Y., 2010, ACM International Conference on Multimedia, P851
   Liu JX, 2017, IET SIGNAL PROCESS, V11, P115, DOI 10.1049/iet-spr.2016.0026
   Liu X, 2012, INT C PATT RECOG, P2565
   Loukas C, 2018, COMPUT METH PROG BIO, V165, P13, DOI 10.1016/j.cmpb.2018.07.004
   Mei SH, 2015, PATTERN RECOGN, V48, P522, DOI 10.1016/j.patcog.2014.08.002
   Momin B.F., 2017, INT C ADV COMM CONTR
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Pan L., 2015, International Journal of Multimedia and Ubiquitous Engineering, V10, P385
   Ren TW, 2010, ADV PATTERN RECOGNIT, P243, DOI 10.1007/978-1-84996-507-1_10
   Thakre KS, 2016, PROCEDIA COMPUT SCI, V78, P790, DOI 10.1016/j.procs.2016.02.058
   Tongwei Ren, 2008, 2008 IEEE International Conference on Data Mining Workshops, P874, DOI 10.1109/ICDMW.2008.55
   Valdes V, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2240136.2240138
   Xu Q, 2012, INT C PATT RECOG, P1892
   Xu Q, 2014, INFORM SCIENCES, V278, P736, DOI 10.1016/j.ins.2014.03.088
   Yang Y, 2011, P AM MATH SOC, V139, P3171, DOI 10.1090/S0002-9939-2011-10735-4
   Yuan Luo, 2018, Pattern Recognition and Image Analysis, V28, P225, DOI 10.1134/S1054661818020190
NR 31
TC 3
Z9 3
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103321
DI 10.1016/j.jvcir.2021.103321
EA OCT 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700001
DA 2024-07-18
ER

PT J
AU Bonomi, M
   Pasquini, C
   Boato, G
AF Bonomi, Mattia
   Pasquini, Cecilia
   Boato, Giulia
TI Dynamic texture analysis for detecting fake faces in video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Manipulated videos; Deepfakes; Video forensics; Local Derivative
   Patterns
ID RECOGNITION
AB The creation of manipulated multimedia content involving human characters has reached in the last years unprecedented realism, calling for automated techniques to expose synthetically generated faces in images and videos.
   This work explores the analysis of spatio-temporal texture dynamics of the video signal, with the goal of characterizing and distinguishing real and fake sequences. We propose to build a binary decision on the joint analysis of multiple temporal segments and, in contrast to previous approaches, to exploit the textural dynamics of both the spatial and temporal dimensions. This is achieved through the use of Local Derivative Patterns on Three Orthogonal Planes (LDP-TOP), a compact feature representation known to be an important asset for the detection of face spoofing attacks.
   Experimental analyses on state-of-the-art datasets of manipulated videos show the discriminative power of such descriptors in separating real and fake sequences, and also identifying the creation method used. Linear Support Vector Machines (SVMs) are used which, despite the lower complexity, yield comparable performance to previously proposed deep models for fake content detection.
C1 [Bonomi, Mattia; Pasquini, Cecilia; Boato, Giulia] Univ Trento, Dept Comp Sci & Informat Engn, Via Sommar 9, I-38123 Trento, Italy.
   [Pasquini, Cecilia] Univ Innsbruck, Inst Informat, Technikerstr 21A, A-6020 Innsbruck, Austria.
C3 University of Trento; University of Innsbruck
RP Pasquini, C (corresponding author), Univ Trento, Dept Comp Sci & Informat Engn, Via Sommar 9, I-38123 Trento, Italy.
EM cecilia.pasquini@unitn.it
OI Pasquini, Cecilia/0000-0002-2125-6983
FU project PREMIER (PREserving Media trustworthiness in the artificial
   Intelligence ERa) - Italian Ministry of Education, University, and
   Research (MIUR) within the PRIN 2017 program; Archimedes Privatstiftung,
   Innsbruck, Austria
FX This work was supported by the project PREMIER (PREserving Media
   trustworthiness in the artificial Intelligence ERa) , funded by the
   Italian Ministry of Education, University, and Research (MIUR) within
   the PRIN 2017 program. The second author was partially supported by
   Archimedes Privatstiftung, Innsbruck, Austria.
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Agarwal, 2019, IEEE COMPUTER VISION
   Amerini I, 2019, IEEE INT CONF COMP V, P1205, DOI 10.1109/ICCVW.2019.00152
   [Anonymous], 2019, DeepFakes Github
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   Bonomi M, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013009
   Chen DM, 2009, ICIEA: 2009 4TH IEEE CONFERENCE ON INDUSTRIAL ELECTRONICS AND APPLICATIONS, VOLS 1-6, P230, DOI 10.1109/ICIEA.2009.5138202
   Chen T., 2008, IEEE COMPUTER VISION
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   De Natale, 2015, IEEE T INF FOREN SEC, P746
   Demir, 2019, FAKECATCHER DETECTIO
   Dirik AE, 2007, 2007 IEEE WORKSHOP ON SIGNAL PROCESSING APPLICATIONS FOR PUBLIC SECURITY AND FORENSICS, P1
   Dang-Nguyen DT, 2012, EUR SIGNAL PR CONF, P1234
   Durall Lopez R, 2019, Unmasking deepfakes with simple features
   Facebook, 2020, DEEPF DET CHALL DFDC
   Fernandes Steven, 2019, IEEE INT C COMP VIS
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hasan HR, 2019, IEEE ACCESS, V7, P41596, DOI 10.1109/ACCESS.2019.2905689
   Jabid T, 2010, IEEE ICCE
   Jain A.K., 2019, ABS191001717 CORR
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li YZ, 2018, IEEE INT WORKS INFOR
   Lyu S, 2005, IEEE T SIGNAL PROCES, V53, P845, DOI 10.1109/TSP.2004.839896
   Marra F, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035099
   Marra F, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P384, DOI 10.1109/MIPR.2018.00084
   Matern F, 2019, IEEE WINT CONF APPL, P83, DOI 10.1109/WACVW.2019.00020
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Nguyen H. H., 2019, ABS190606876 CORR
   Nguyen T. T., 2019, CoRR
   Pan F, 2009, SCI CHINA SER F, V52, P329, DOI 10.1007/s11432-009-0053-5
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Phan QT, 2016, IEEE IMAGE PROC, P404, DOI 10.1109/ICIP.2016.7532388
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Sabir E., 2019, INTERFACES GUI, V3, P80
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Souza L, 2018, ENG APPL ARTIF INTEL, V72, P368, DOI 10.1016/j.engappai.2018.04.013
   Sun, 2016, AEU-INT J ELECTRON C
   Thies J, 2019, COMMUN ACM, V62, P96, DOI 10.1145/3292039
   Tian-Tsong Ng, 2005, 13th Annual ACM International Conference on Multimedia, P239
   UIJLINGS J, 2015, INT J MULTIMEDIA INF, V4
   Verdoliva, 2017, ACM WORKSH INF HID M
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Vincent J., 2019, WATCH J PEELE USE AI
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Xiao JY, 2019, IEEE ACCESS, V7, P55432, DOI 10.1109/ACCESS.2019.2913648
   Yang X, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P113, DOI 10.1145/3335203.3335724
   Yang X, 2019, INT CONF ACOUST SPEE, P8261, DOI 10.1109/ICASSP.2019.8683164
   Yongzhen Ke, 2013, Journal of Theoretical and Applied Information Technology, V49, P844
   Yu N, 2019, IEEE I CONF COMP VIS, P7555, DOI 10.1109/ICCV.2019.00765
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang X, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035107
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 57
TC 14
Z9 14
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103239
DI 10.1016/j.jvcir.2021.103239
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, J
   Li, ZX
   Zhang, CL
   Ma, HF
AF Zhang, Jia
   Li, Zhixin
   Zhang, Canlong
   Ma, Huifang
TI Stable self-attention adversarial learning for semi-supervised semantic
   image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Self-Attention Mechanism; Adversarial Learning; Semi-Supervised
   Learning; Spectral Normalization; Semantic Image Segmentation
AB The application of adversarial learning for semi-supervised semantic image segmentation based on convolutional neural networks can effectively reduce the number of manually generated labels required in the training process. However, the convolution operator of the generator in the generative adversarial network (GAN) has a local receptive field, so that the long-range dependencies between different image regions can only be modeled after passing through multiple convolutional layers. The present work addresses this issue by introducing a selfattention mechanism in the generator of the GAN to effectively account for relationships between widely separated spatial regions of the input image with supervision based on pixel-level ground truth data. In addition, the adjustment of the discriminator has been demonstrated to affect the stability of GAN training performance. This is addressed by applying spectral normalization to the GAN discriminator during the training process. Our method has better performance than existing full/semi-supervised semantic image segmentation techniques.
C1 [Zhang, Jia; Li, Zhixin; Zhang, Canlong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Ma, Huifang] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
C3 Guangxi Normal University; Northwest Normal University - China
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Li, Zhixin/ABI-9264-2022; Ma, Huifang/JTV-4982-2023
OI Li, Zhixin/0000-0002-5313-6134; Ma, Huifang/0000-0002-5104-8982
FU National Natural Science Foundation of China [61966004, 61663004,
   61762078, 61866004]; Guangxi Natural Science Foundation
   [2019GXNSFDA245018, 2018GXNSFDA281009]; Innovation Project of Guangxi
   Graduate Education [YCSW2020111]; Guangxi "Bagui Scholar" Teams for
   Innovation and Research Project; Guangxi Talent Highland Project of Big
   Data Intelligence and Application; Guangxi Collaborative Innovation
   Center of Multi-source Information Integration and Intelligent
   Processing
FX This work is supported by National Natural Science Foundation of China
   (Nos. 61966004, 61663004, 61762078, 61866004), Guangxi Natural Science
   Foundation (Nos. 2019GXNSFDA245018, 2018GXNSFDA281009), Innovation
   Project of Guangxi Graduate Education YCSW2020111, Guangxi "Bagui
   Scholar" Teams for Innovation and Research Project, Guangxi Talent
   Highland Project of Big Data Intelligence and Application, and Guangxi
   Collaborative Innovation Center of Multi-source Information Integration
   and Intelligent Processing.
CR [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], 2018, REALISTIC EVALUATION
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2017, P 5 INT C LEARN REPR
   Arjovsky M., 2017, WASSERSTEIN GAN
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Fawzi A., 2016, Neural Information Processing Systems (NeurIPS), V29, P1632
   Fawzi Alhussein, 2018, Adv. Neural Inform. Process. Syst, DOI DOI 10.48550/ARXIV.1802.08686
   Feng Z., 2020, EMNLP
   French G., 2019, ARXIV PREPRINT ARXIV
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gilmer J., 2018, ARXIV PREPRINT ARXIV
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hung W.-C., 2018, ARXIV PREPRINT ARXIV
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kalluri T, 2019, IEEE I CONF COMP VIS, P5258, DOI 10.1109/ICCV.2019.00536
   Kingma D. P., 2014, arXiv
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Z., 2017, ARXIV PREPRINT ARXIV
   Liu ST, 2019, INT CONF ACOUST SPEE, P1902, DOI [10.1109/icassp.2019.8683590, 10.1109/ICASSP.2019.8683590]
   Liu XM, 2019, IEEE ACCESS, V7, P3046, DOI 10.1109/ACCESS.2018.2889321
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luc P., 2016, NIPS WORKSHOP ADVERS
   Mittal S., 2019, SEMISUPERVISED SEMAN
   Miyato Takeru, 2018, P ICLR
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sawatzky J., 2019, ARXIV PREPRINT ARXIV
   Shen T, 2018, AAAI CONF ARTIF INTE, P5446
   Shuai B, 2018, IEEE T PATTERN ANAL, V40, P1480, DOI 10.1109/TPAMI.2017.2712691
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Stekovic S., 2018, ARXIV PREPRINT ARXIV
   Sun FD, 2019, PATTERN RECOGN LETT, V120, P62, DOI 10.1016/j.patrec.2019.01.009
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tsai Yi-Hsuan, 2017, CVPR, P3789
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YZ, 2018, PR MACH LEARN RES, V80
   Xu H, 2009, J MACH LEARN RES, V10, P1485
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 51
TC 15
Z9 16
U1 4
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103170
DI 10.1016/j.jvcir.2021.103170
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LW
UT WOS:000674617500002
DA 2024-07-18
ER

PT J
AU Xu, ZP
   Liu, JR
   Lu, W
   Xu, BZ
   Zhao, XF
   Li, B
   Huang, JW
AF Xu, Zhaopeng
   Liu, Jiarui
   Lu, Wei
   Xu, Bozhi
   Zhao, Xianfeng
   Li, Bin
   Huang, Jiwu
TI Detecting facial manipulated videos based on set convolutional neural
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital video forensics; Deepfake; Set convolutional neural network; Set
   reduce
AB With the boom of artificial intelligence, facial manipulation technology is becoming more simple and more numerous. At the same time, the technology also has a large and profound negative impact on face forensics, such as Deepfakes. In this paper, in order to aggregate multiframe features to detect facial manipulation videos, we solve facial manipulated video detection from set perspective and propose a novel framework based on set, which is called set convolutional neural network (SCNN). Three instances of the proposed framework SCNN are implemented and evaluated on the Deepfake TIMIT dataset, FaceForensics++ dataset and DFDC Preview datset. The results show that the method outperforms previous methods and can achieve state-of-the-art performance on both datasets. As a perspective, the proposed method is a fusion promotion of single-frame digital video forensics network.
C1 [Xu, Zhaopeng; Liu, Jiarui; Lu, Wei; Xu, Bozhi] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
   [Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Li, Bin; Huang, Jiwu] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Li, Bin; Huang, Jiwu] Shenzhen Univ, Guangdong Lab Art Intelligence & Digital Econ SZ, Shenzhen 518060, Peoples R China.
   [Huang, Jiwu] Shenzhen Inst Art Intelligence & Robot Soc, Shenzhen 518060, Peoples R China.
C3 Sun Yat Sen University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS; Shenzhen University; Shenzhen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
EM xuzhp8@mail2.sysu.edu.cn; liujr9@mail2.sysu.edu.cn;
   luwei3@mail.sysu.edu.cn; xuzhp8@mail2.sysu.edu.cn;
   zhaoxianfeng@iie.ac.cn; libin@szu.edu.cn; jwhuang@szu.edu.cn
RI Zhao, Xianfeng/AAE-7278-2021; huang, jw/KVY-9917-2024; Bueno, Regis
   Cortez/AAG-3852-2020
OI Zhao, Xianfeng/0000-0002-5617-8399; Bueno, Regis
   Cortez/0000-0002-2923-4930
FU National Natural Science Foundation of China [U2001202, 62072480,
   U1736118]; National Key R&D Program of China [2019QY2202,
   2019QY(Y)0207]; Key Areas R&D Program of Guangdong, China
   [2019B010136002]; Key Scientific Research Program of Guangzhou, China
   [201804020068]
FX This work is supported by the National Natural Science Foundation of
   China (No. U2001202, No. 62072480, No. U1736118) , the National Key R&D
   Program of China (No. 2019QY2202 , No. 2019QY(Y)0207) , the Key Areas
   R&D Program of Guangdong, China (No. 2019B010136002) , the Key
   Scientific Research Program of Guangzhou, China (No. 201804020068) .
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Averbuch-Elor H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130818
   Bansal A, 2018, LECT NOTES COMPUT SC, V11209, P122, DOI 10.1007/978-3-030-01228-1_8
   Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bohme R., 2013, DIGITAL IMAGE RORENS
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Ciftci U.A., 2019, ARXIV190102212
   Conotter V, 2014, IEEE IMAGE PROC, P248, DOI 10.1109/ICIP.2014.7025049
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dolhansky B., 2019, ARXIV PREPRINT ARXIV
   Dang-Nguyen DT, 2012, IEEE INT WORKS INFOR, P252, DOI 10.1109/WIFS.2012.6412658
   Garrido P, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12552
   Garrido P, 2014, PROC CVPR IEEE, P4217, DOI 10.1109/CVPR.2014.537
   Guarnera L, 2020, IEEE ACCESS, V8, P165085, DOI 10.1109/ACCESS.2020.3023037
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   International Diabetes Federation, 2019, IDF Diabetes Atlas, Vninth
   Karras T., 2018, INT CONFLEARN REPRES
   Khodabakhsh A, 2018, 2018 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Korshunov P., 2018, ARXIV PREPRINT ARXIV
   Kumar P., 2020, P IEEE CVF WINT C AP, P2589
   Li LZ, 2020, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR42600.2020.00505
   Li YZ, 2018, IEEE INT WORKS INFOR
   Liu MY, 2017, ADV NEUR IN, V30
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Nguyen HH, 2019, INT CONF ACOUST SPEE, P2307, DOI 10.1109/ICASSP.2019.8682602
   Perov I., 2020, ARXIV200505535
   Raghavendra R, 2017, IEEE COMPUT SOC CONF, P1822, DOI 10.1109/CVPRW.2017.228
   Rahmouni N, 2017, IEEE INT WORKS INFOR
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Sabour S, 2017, ADV NEUR IN, V30
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Thies J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818056
   Upchurch P, 2017, PROC CVPR IEEE, P6090, DOI 10.1109/CVPR.2017.645
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
NR 39
TC 12
Z9 15
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103119
DI 10.1016/j.jvcir.2021.103119
EA APR 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700016
DA 2024-07-18
ER

PT J
AU Deng, HY
   Kong, J
   Jiang, M
   Liu, TS
AF Deng, Haoyang
   Kong, Jun
   Jiang, Min
   Liu, Tianshan
TI Diverse Features Fusion Network for video-based action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three-stream action recognition; Diverse features fusion; DIverse
   Compact Bilinear; Channel-spatial Attention
AB The two-stream convolutional network has been proved to be one milestone in the study of video-based action recognition. Lots of recent works modify internal structure of two-stream convolutional network directly and put top-level features into a 2D/3D convolution fusion module or a simpler one. However, these fusion methods cannot fully utilize features and the way fusing only top-level features lacks rich vital details. To tackle these issues, a novel network called Diverse Features Fusion Network (DFFN) is proposed. The fusion stream of DFFN contains two types of uniquely designed modules, the diverse compact bilinear fusion (DCBF) module and the channel-spatial attention (CSA) module, to distill and refine diverse compact spatiotemporal features. The DCBF modules use the diverse compact bilinear algorithm to fuse features extracted from multiple layers of the base network that are called diverse features in this paper. Further, the CSA module leverages channel attention and multi-size spatial attention to boost key information as well as restraining the noise of fusion features. We evaluate our three-stream network DFFN on three public challenging video action benchmarks: UCF101, HMDB51 and Something-Something V1. Experiment results indicate that our method achieves state-of-the-art performance.
C1 [Deng, Haoyang; Kong, Jun; Jiang, Min] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
   [Liu, Tianshan] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong 999077, Peoples R China.
C3 Jiangnan University; Hong Kong Polytechnic University
RP Kong, J (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
EM kongjun@jiangnan.edu.cn
FU National Natural Science Foundation of China [61362030, 61201429]; China
   Postdoctoral Science Foundation [2015M581720, 2016M600360]; Jiangsu
   Postdoctoral Science Foundation, China [1601216C]; Scientific and
   Technological Aid Program of Xinjiang, China [2017E0279]; 111 Projects,
   China [B12018]
FX This work was partially supported by the National Natural Science
   Foundation of China (61362030, 61201429), China Postdoctoral Science
   Foundation (2015M581720, 2016M600360), Jiangsu Postdoctoral Science
   Foundation, China (1601216C), Scientific and Technological Aid Program
   of Xinjiang, China (2017E0279), 111 Projects, China under Grant B12018.
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Charikar M, 2004, THEOR COMPUT SCI, V312, P3, DOI 10.1016/S0304-3975(03)00400-6
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Feichtenhofer C, 2016, ADV NEUR IN, V29
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fukui A., 2016, ARXIV PREPRINT ARXIV
   Gao RH, 2018, PROC CVPR IEEE, P5937, DOI 10.1109/CVPR.2018.00622
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Goyal R., 2017, ICCV, V1, P5
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lee MG, 2018, LECT NOTES COMPUT SC, V11214, P392, DOI 10.1007/978-3-030-01249-6_24
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Lin W., 2018, P AAAI C ART INT, V32
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Pham N, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P239, DOI 10.1145/2487575.2487591
   Park J., 2018, ARXIV PREPRINT ARXIV
   Peng YX, 2019, IEEE T CIRC SYST VID, V29, P773, DOI 10.1109/TCSVT.2018.2808685
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Quan YH, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.102794
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L, 2018, IEEE IPCCC
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Y, 2017, IEEE INT CONF COMP V, P2129, DOI 10.1109/ICCVW.2017.249
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Yin W., 2016, Transactions of the Association for computational linguistics, V4, P259, DOI [DOI 10.1162/TACL_A_00097, DOI 10.1162/TACLA00244, 10.1162/tacla00097, DOI 10.1162/TACLA00097]
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhao Yue., 2018, Advances in Neural Information Processing Systems, P2204
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
   Zhu Y, 2019, LECT NOTES COMPUT SC, V11363, P363, DOI 10.1007/978-3-030-20893-6_23
NR 57
TC 5
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103121
DI 10.1016/j.jvcir.2021.103121
EA APR 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700017
DA 2024-07-18
ER

PT J
AU Taghipour, A
   Ghassemian, H
AF Taghipour, Ashkan
   Ghassemian, Hassan
TI A bottom-up and top-down human visual attention approach for
   hyperspectral anomaly detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral image; Visual attention; Anomaly detection; Bottom-up
   attention; Top-down attention
ID SPATIAL CORRELATION; SALIENCY DETECTION; CLASSIFICATION; MODEL;
   ALGORITHM; IMAGES; SEGMENTATION; SENSITIVITY; GUIDANCE; FEATURES
AB Hyperspectral anomaly detection (HAD) is a branch of target detection which tries to locate pixels that are spectrally or spatially different from their background. In this paper, a visual attention approach is developed to leverage HAD. Traditional HAD methods often try to locate anomalous pixels based on spectral information. However, the spatial features of hyperspectral datasets provide valuable information. Here, we aim to fuse spatial and spectral anomaly features based on bottom-up (BU) and top-down (TD) visual attention mechanisms. Owe to the BU attention, spatial features are extracted by mimicking the primary visual cortex neurons functionality. Also, spectral information is obtained throughout a deep neural network that imitating the TD visual attention. The BU and TD approaches' results are then integrated to provide both spectral and spatial information. The key findings of our results demonstrate the proposed method outperforms the six state-of-the-art AD methods based on different evaluation metrics.
C1 [Taghipour, Ashkan; Ghassemian, Hassan] Tarbiat Modares Univ, Image Proc & Informat Anal Lab, Fac Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Ghassemian, H (corresponding author), Tarbiat Modares Univ, Image Proc & Informat Anal Lab, Fac Elect & Comp Engn, Tehran, Iran.
EM ghassemi@modares.ac.ir
OI Taghipour, Ashkan/0000-0002-1950-5143
CR [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   Bitar AW, 2019, IEEE T GEOSCI REMOTE, V57, P5239, DOI 10.1109/TGRS.2019.2897635
   Borji A., 2018, 181003716 CORR
   Borji A, 2016, IEEE T NEUR NET LEAR, V27, P1214, DOI 10.1109/TNNLS.2015.2480683
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Carlotto MJ, 2005, IEEE T GEOSCI REMOTE, V43, P374, DOI 10.1109/TGRS.2004.841481
   Chang SZ, 2018, IEEE T GEOSCI REMOTE, V56, P3747, DOI 10.1109/TGRS.2018.2810124
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Cheng J, 2012, IEEE T MED IMAGING, V31, P2355, DOI 10.1109/TMI.2012.2218118
   Dalla Mura M, 2010, IEEE T GEOSCI REMOTE, V48, P3747, DOI 10.1109/TGRS.2010.2048116
   Díaz M, 2018, IEEE T GEOSCI REMOTE, V56, P1159, DOI 10.1109/TGRS.2017.2761019
   Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Ghamisi P, 2019, IEEE GEOSC REM SEN M, V7, P6, DOI 10.1109/MGRS.2018.2890023
   Goldberg H, 2007, IEEE GEOSCI REMOTE S, V4, P581, DOI 10.1109/LGRS.2007.903083
   Golipour M, 2016, IEEE T GEOSCI REMOTE, V54, P805, DOI 10.1109/TGRS.2015.2466657
   Guo QD, 2014, IEEE J-STARS, V7, P2351, DOI 10.1109/JSTARS.2014.2302446
   He S., 2018, 180305753 CORR
   Huang FH, 2019, J VIS COMMUN IMAGE R, V58, P233, DOI 10.1016/j.jvcir.2018.11.004
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Kong FQ, 2016, J VIS COMMUN IMAGE R, V40, P525, DOI 10.1016/j.jvcir.2016.07.019
   Li F, 2018, IEEE T GEOSCI REMOTE, V56, P4050, DOI 10.1109/TGRS.2018.2821168
   Li JY, 2015, IEEE J-STARS, V8, P2523, DOI 10.1109/JSTARS.2015.2437073
   Li ST, 2018, IEEE GEOSCI REMOTE S, V15, P1605, DOI 10.1109/LGRS.2018.2853705
   López MT, 2006, PATTERN RECOGN, V39, P2194, DOI 10.1016/j.patcog.2006.04.018
   López MT, 2006, PATTERN RECOGN LETT, V27, P469, DOI 10.1016/j.patrec.2005.09.010
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Ma DD, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050745
   Ma DD, 2017, INT GEOSCI REMOTE SE, P648, DOI 10.1109/IGARSS.2017.8127037
   Ma N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030693
   Mahdavi-Meymand Amin, 2021, ISH Journal of Hydraulic Engineering, V27, P58, DOI 10.1080/09715010.2019.1574619
   Masoudnia S., 2020, ARXIV200314194
   Matteoli S, 2014, IEEE J-STARS, V7, P2317, DOI 10.1109/JSTARS.2014.2315772
   Miconi T, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004770
   Nasrabadi NM, 2014, IEEE SIGNAL PROC MAG, V31, P34, DOI 10.1109/MSP.2013.2278992
   Ning HY, 2019, IEEE T GEOSCI REMOTE, V57, P2263, DOI 10.1109/TGRS.2018.2872590
   Nothdurft Hans-Christoph, 2005, P233, DOI 10.1016/B978-012375731-9/50042-2
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Taghipour Ashkan, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P52, DOI 10.1109/PRIA.2019.8785982
   Taghipour A, 2019, INT J REMOTE SENS, V40, P8683, DOI 10.1080/01431161.2019.1620374
   Taghipour A, 2017, IEEE GEOSCI REMOTE S, V14, P1136, DOI 10.1109/LGRS.2017.2700329
   Taghipour A, 2016, IRAN CONF ELECTR ENG, P1219, DOI 10.1109/IranianCEE.2016.7585707
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tu B, 2018, J VIS COMMUN IMAGE R, V56, P160, DOI 10.1016/j.jvcir.2018.09.010
   Vafadar M, 2018, IEEE J-STARS, V11, P4076, DOI 10.1109/JSTARS.2018.2870123
   Vafadar M, 2018, IEEE GEOSCI REMOTE S, V15, P577, DOI 10.1109/LGRS.2018.2796083
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P1155, DOI 10.1109/TGRS.2018.2864987
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
   Wang Q, 2018, IEEE T GEOSCI REMOTE, V56, P5910, DOI 10.1109/TGRS.2018.2828161
   Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wolfe JM, 2003, J EXP PSYCHOL HUMAN, V29, P483, DOI 10.1037/0096-1523.29.2.483
   Xie WY, 2020, IEEE T GEOSCI REMOTE, V58, P5416, DOI 10.1109/TGRS.2020.2965995
   Xie WY, 2019, IEEE T GEOSCI REMOTE, V57, P4218, DOI 10.1109/TGRS.2018.2890212
   Zare A, 2018, IEEE T PATTERN ANAL, V40, P2342, DOI 10.1109/TPAMI.2017.2756632
   Zhang SQ, 2018, IEEE T GEOSCI REMOTE, V56, P3265, DOI 10.1109/TGRS.2018.2797200
   Zhang WX, 2019, IEEE T GEOSCI REMOTE, V57, P4810, DOI 10.1109/TGRS.2019.2893116
NR 64
TC 3
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103113
DI 10.1016/j.jvcir.2021.103113
EA APR 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA TM2UA
UT WOS:000675405700012
DA 2024-07-18
ER

PT J
AU Ma, S
   Zhao, XF
AF Ma, Sai
   Zhao, Xianfeng
TI Steganalytic feature based adversarial embedding for adaptive JPEG
   steganography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Adversarial embedding; Non-data-driven
ID IMAGE; DISTORTION
AB In this paper, we present a novel adversarial embedding scheme named Steganalytic Feature based Adversarial Embedding (SFAE), which is elaborately designed in a non-data-driven style. Firstly, a novel DCTR based adversary is designed to generate adversarial stego images which can not only resist feature based steganalysis but also deep learning based steganalysis. Specifically, our adversary consists of an end-to-end neural network structure, while its inner weights are set according to DCTR rather than learned from datasets. Secondly, we use the minimum distance to the cover in steganalytic space as the criterion to select the optimal adversarial stego image, rather than fooling the adversary. Last but not least, we present two SFAE implementations to adapt to different cases. One is Iterative SFAE, which needs to calculate gradients multiple times. Iterative SFAE is more secure but has higher complexity. It fits the case that the steganographer has adequate computing resources. Another implementation is Oneshot SFAE, which can calculate gradients once. Oneshot SFAE trades the security for lower complexity. It fits the steganographer that has stricter requirements for running time. Experiments demonstrate that SFAE is effective to improve the security of conventional steganographic schemes against the state-of-the-art steganalysis including both feature based steganalysis and deep learning based steganalysis.
C1 [Ma, Sai; Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100195, Peoples R China.
   [Ma, Sai; Zhao, Xianfeng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100195, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhao, XF (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100195, Peoples R China.
EM masai@iie.ac.cn; zhaoxianfeng@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU NSFC [61972390, U1736214, 61902391, 61872356, 61802393]; National Key
   Technology RD Program [2019QY0701]; IIE CAS Climbing Program
FX This work was supported by NSFC under 61972390, U1736214, 61902391,
   61872356 and 61802393, National Key Technology R&D Program under
   2019QY0701, and IIE CAS Climbing Program.
CR [Anonymous], 2017, Electronic Imaging
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bernard S, 2021, IEEE T INF FOREN SEC, V16, P812, DOI 10.1109/TIFS.2020.3021913
   Bernard S, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P216, DOI 10.1145/3335203.3335737
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen KJ, 2019, IEEE T INF FOREN SEC, V14, P1052, DOI 10.1109/TIFS.2018.2869353
   Chen Kuo-Chin, 2016, 2016 International Conference of Asian Union of Magnetics Societies (ICAUMS), DOI 10.1109/ICAUMS.2016.8479871
   Denemark T, 2015, IEEE INT WORKS INFOR
   Denemark T, 2017, INT CONF ACOUST SPEE, P2117, DOI 10.1109/ICASSP.2017.7952530
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2007, PROC SPIE, V6505, DOI 10.1117/12.697471
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Holub V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2075239
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kouider S, 2013, IEEE INT CON MULTI
   Kurakin Alexey, 2017, INT C LEARN REPR
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Mo HX, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9035101
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Zhang WM, 2017, IEEE T CIRC SYST VID, V27, P2274, DOI 10.1109/TCSVT.2016.2587388
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
NR 36
TC 4
Z9 4
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103066
DI 10.1016/j.jvcir.2021.103066
EA MAR 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700001
DA 2024-07-18
ER

PT J
AU Lyu, QY
   Luo, JW
   Liu, K
   Yin, XL
   Liu, JR
   Lu, W
AF Lyu, Qiyue
   Luo, Junwei
   Liu, Ke
   Yin, Xiaolin
   Liu, Jiarui
   Lu, Wei
TI Copy Move Forgery Detection based on double matching?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital forensics; Copy move forgery detection; Delaunay triangle;
   Double matching
AB Copy Move is a technique widespreadly used in digital image tampering, meaning Copy Move Forgery Detection (CMFD) is still a significant research. In this paper, a novel CMFD method is proposed, including double matching process and region localizing process. In double matching process, the first matching is conducted on Delaunay triangles consisting of Local Intensity Order Pattern (LIOP) keypoints, to find the approximate location of suspicious regions. In order to find sufficient keypoint pairs, the existing set of matching triangles is expanded by adding their neighbors iteratively, covering the whole tampered regions, and the second matching with a looser threshold is conducted on the vertices. In the region localizing process, considering the case of multiple copies, Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is used to classify the keypoint pairs described in a new model. Experimental results indicate that the proposed method, with good robustness, outperforms some state-of-the-art methods.
C1 [Lyu, Qiyue; Luo, Junwei; Liu, Ke; Yin, Xiaolin; Liu, Jiarui; Lu, Wei] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Prov Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangdong Prov Key Lab Informat Secur Technol, Minist Educ,Key Lab Machine Intelligence & Adv Co, Guangzhou 510006, Peoples R China.
EM lvqyue@mail2.sysu.edu.cn; luojw8@mail2.sysu.edu.cn;
   liuk66@mail2.sysu.edu.cn; yinxl6@mail2.sysu.edu.cn;
   liujr9@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn
FU National Natural Science Foundation of China [62072480, U2001202,
   U1736118]; National Key R&D Program of China [2019QY2202,
   2019QY(Y)0207]; Key Areas R&D Program of Guangdong [2019B010136002]; Key
   Scientific Research Program of Guangzhou [201804020068]
FX This work is supported by the National Natural Science Foundation of
   China (No. 62072480, No. U2001202, No. U1736118), the National Key R&D
   Program of China (No. 2019QY2202, No. 2019QY(Y)0207), the Key Areas R&D
   Program of Guangdong (No. 2019B010136002), the Key Scientific Research
   Program of Guangzhou (No. 201804020068).
CR Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Dyer R., 2019, SURVEY DELAUNAY STRU
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich A.J., 2003, DIG FOR RES WORKSH C, P19, DOI DOI 10.1109/PACIIA.2008.240
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Liang YX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P3132, DOI 10.1145/3292500.3330646
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Liu K, 2019, MULTIMED TOOLS APPL, V78, P31387, DOI 10.1007/s11042-019-07930-5
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu W, 2021, IEEE T CIRC SYST VID, V31, P2909, DOI 10.1109/TCSVT.2020.3027843
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouyang K., 2020, ARXIV200202318
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zeng LW, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107576
   Zhong JL, 2020, IEEE T INF FOREN SEC, V15, P2134, DOI 10.1109/TIFS.2019.2957693
NR 46
TC 23
Z9 23
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103057
DI 10.1016/j.jvcir.2021.103057
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700008
DA 2024-07-18
ER

PT J
AU Xiao, ZJ
   Zhang, ZK
   Hung, KW
   Lui, SM
AF Xiao, Zhijiao
   Zhang, Zhikai
   Hung, Kwok-Wai
   Lui, Simon
TI Real-time video super-resolution using lightweight depthwise separable
   group convolutions with channel shuffling *
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Lightweight alignment module; Channel shuffle;
   Residual networks
ID IMAGE SUPERRESOLUTION
AB In recent years, convolutional neural networks (CNNs) have accelerated the developments of video super resolution (SR) for achieving higher image quality. However, the computational cost of existing CNN-based video super-resolution is too heavy for real-time applications. In this paper, we propose a new video super-resolution framework using lightweight frame alignment module and well-designed up-sampling module for real-time processing. Specifically, our framework, which is called as Lightweight Shuffle Video Super-Resolution Network (LSVSR), combines channel shuffling, depthwise convolution and pointwise group convolution to significantly reduce the computational burden during frame alignment and high-resolution frame reconstruction. On the public benchmark datasets, our proposed network outperforms the state-of-the-art lightweight video SR networks in terms of objective (PSNR and SSIM) and subjective evaluations, number of network parameters and floating-point operations. Our network can achieve real-time 540P to 2160P 4? super-resolution for more than 60fps using desktop GPUs or mobile phones with neural processing unit.
C1 [Xiao, Zhijiao; Zhang, Zhikai] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Hung, Kwok-Wai; Lui, Simon] Tencent Mus Entertainment, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Hung, KW (corresponding author), Tencent Mus Entertainment, Shenzhen, Peoples R China.
EM guoweihung@tencent.com
RI Lui, Simon/JEP-7364-2023; sparrow, sarah/AAD-9855-2020
OI Lui, Simon/0000-0002-0829-2867; 
FU NSFC [62002230]
FX This work is supported by NSFC No: 62002230.
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Chang QL, 2018, NEUROCOMPUTING, V275, P969, DOI 10.1016/j.neucom.2017.09.035
   Choi Jungwook, 2018, PACT PARAMETERIZED C
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dean J., 2015, NIPS DEEP LEARNING R
   Ding Y., 2019, ARXIV PREPRINT ARXIV
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Drulea M, 2011, IEEE INT C INTELL TR, P318, DOI 10.1109/ITSC.2011.6082986
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Haris M, 2019, PROC CVPR IEEE, P3892, DOI 10.1109/CVPR.2019.00402
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang J.-J., 2018, LEARNING APPROACHES, P283
   Huang Y, 2015, ADV NEUR IN, V28
   Hung KW, 2019, MULTIMED TOOLS APPL, V78, P22813, DOI 10.1007/s11042-019-7633-1
   Hung KW, 2019, IEEE ACCESS, V7, P99804, DOI 10.1109/ACCESS.2019.2929223
   Hung KW, 2019, IEEE ACCESS, V7, P74711, DOI 10.1109/ACCESS.2019.2920774
   Hung KW, 2014, IEEE T CIRC SYST VID, V24, P2018, DOI 10.1109/TCSVT.2014.2329352
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Keller SH, 2007, LECT NOTES COMPUT SC, V4485, P801
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim JH, 2020, Arxiv, DOI arXiv:1811.12043
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Tian Y., 2018, ARXIV181006526
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yu JS, 2018, IEEE ACCESS, V6, P58096, DOI 10.1109/ACCESS.2018.2873385
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 44
TC 7
Z9 7
U1 0
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103038
DI 10.1016/j.jvcir.2021.103038
EA FEB 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QS8UL
UT WOS:000626168600001
DA 2024-07-18
ER

PT J
AU Xie, YR
   Song, TC
   Li, W
AF Xie, Yurui
   Song, Tiecheng
   Li, Wei
TI Semantic-aware visual attributes learning for zero-shot recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero-shot learning; Human-designed attributes; Visual attributes;
   Semantic representation
ID OBJECT
AB Zero-shot learning (ZSL) aims to recognize unseen image classes without requiring any training samples of these specific classes. The ZSL problem is typically achieved by building up a semantic embedding space like attributes to bridge the visual features and class labels of images. Currently, most ZSL approaches focus on learning a visual-semantic alignment from seen classes using only the human-designed attributes, and then ZSL problem is solved by transferring semantic knowledge from seen classes to the unseen classes. However, few works indicate if the human-designed attributes are discriminative enough for image class prediction. To address this issue, we propose a semantic-aware dictionary learning (SADL) framework to explore these discriminative visual attributes across seen and unseen classes. Furthermore, the semantic cues are elegantly integrated into the feature representations via learned visual attributes for recognition task. Experiments conducted on two challenging benchmark datasets show that our approach outweighs other state-of-the-art ZSL methods.
C1 [Xie, Yurui] Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
   [Song, Tiecheng] Chongqing Univ Posts & Telecommun, 2 Chongwen Rd, Chongqing, Peoples R China.
   [Li, Wei] Southwest Jiaotong Univ, 999 Xi An Rd, Chengdu, Peoples R China.
C3 Chengdu University of Information Technology; Chongqing University of
   Posts & Telecommunications; Southwest Jiaotong University
RP Xie, YR (corresponding author), Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
EM gloriousxyr@163.com; songtc@cqupt.edu.cn; liwei@swjtu.edu.cn
FU National Natural Science Foundation of China [61806028, 61702065];
   Program for Educational Foundation of Sichuan Province, China [18ZB0125]
FX This work was supported by The National Natural Science Foundation of
   China (No. 61806028, No. 61702065), and in part by the Program for
   Educational Foundation of Sichuan Province, China (No. 18ZB0125).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   [Anonymous], 2014, ICLR
   Ashual O, 2019, IEEE I CONF COMP VIS, P4560, DOI 10.1109/ICCV.2019.00466
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Jiang HJ, 2018, LECT NOTES COMPUT SC, V11214, P121, DOI 10.1007/978-3-030-01249-6_8
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ren YZ, 2017, J VIS COMMUN IMAGE R, V42, P192, DOI 10.1016/j.jvcir.2016.11.004
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song J, 2020, PROC CVPR IEEE, P3921, DOI 10.1109/CVPR42600.2020.00398
   Song J, 2019, ADV NEUR IN, V32
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Song J, 2018, LECT NOTES COMPUT SC, V11213, P474, DOI 10.1007/978-3-030-01240-3_29
   Thomas SS, 2016, J VIS COMMUN IMAGE R, V38, P367, DOI 10.1016/j.jvcir.2016.03.015
   Tong B, 2019, PROC CVPR IEEE, P11459, DOI 10.1109/CVPR.2019.01173
   Verma VK, 2017, LECT NOTES ARTIF INT, V10535, P792, DOI 10.1007/978-3-319-71246-8_48
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V59, P563, DOI 10.1016/j.jvcir.2019.02.006
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 38
TC 0
Z9 0
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500005
DA 2024-07-18
ER

PT J
AU Heravi, FMZ
   Nait-Ali, A
AF Heravi, Farnaz Majid Zadeh
   Nait-Ali, Amine
TI Adult-child 3D backward face aging model (3D B-FAM)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D modeling; Face aging; Textured 3D mesh; Biometrics; Anthropometry;
   Depth perception; Forensics
ID PERCEPTION; SIMULATION; SHAPE; AGE; DISTINCTIVENESS; ATTRACTIVENESS;
   APPEARANCE; TEXTURES; METRICS; SYSTEM
AB Face aging has been widely considered in many studies regarding all the potential applications. However, the de-aging known as the rejuvenation or backward modeling has recently received more attention. Previous studies mainly focused on rejuvenating faces from aged adults into young adults using two-dimensional (2D) models. In this work, we propose an extension of a previous 2D adult-child B-FAM into 3D model. This model allows a digital face appearance rejuvenation within a range of [75-3] years old. To evaluate the performances of the proposed approach, first, we proposed two performance evaluation modes, namely: Generic Perception Based and Biometric Verification Mode. Then, the performances have been evaluated over our own 3D database, called Face Time-Machine database constructed using 75 females and 70 males, leading to 500 textured surface meshes. Finally, results show that they are perceptually satisfying and system performance increases by using the faces obtained from our model. (C) 2020 Published by Elsevier Inc.
C1 [Heravi, Farnaz Majid Zadeh; Nait-Ali, Amine] Univ Paris Est Creteil, LISSI, F-94400 Vitry Sur Seine, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Nait-Ali, A (corresponding author), Univ Paris Est Creteil, LISSI, F-94400 Vitry Sur Seine, France.
EM naitali@u-pec.fr
CR [Anonymous], 2001, BEAUTYCHECK CAUSES C
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   BIEDERMAN I, 1989, PSYCHOL REV, V96, P2, DOI DOI 10.1037/0033-295X.96.1.2
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   BULTHOFF HH, 1992, P NATL ACAD SCI USA, V89, P60, DOI 10.1073/pnas.89.1.60
   BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021
   Chan Mark, 2005, INT C COMP AN IM PAT
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Clark L, 2006, ORNITHOL MONOGR, P3
   Donnai D., 1990, J MED GENET, V27
   EDELMAN S, 1992, VISION RES, V32, P2385, DOI 10.1016/0042-6989(92)90102-O
   Farazdaghi E, 2017, IET BIOMETRICS, V6, P478, DOI 10.1049/iet-bmt.2016.0079
   Fei HY, 2018, J VIS COMMUN IMAGE R, V56, P139, DOI 10.1016/j.jvcir.2018.09.012
   Frimenko R, 2016, IET BIOMETRICS, V5, P181, DOI 10.1049/iet-bmt.2014.0103
   Fu Y, 2006, IEEE T CIRC SYST VID, V16, P830, DOI 10.1109/TCSVT.2006.877398
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Goldman AI, 2005, COGNITION, V94, P193, DOI 10.1016/j.cognition.2004.01.005
   Guo GD, 2011, IEEE I CONF COMP VIS, P2510, DOI 10.1109/ICCV.2011.6126537
   Guo JJ, 2017, ACM T APPL PERCEPT, V14, DOI 10.1145/2996296
   Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0
   Heravi FMZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8101170
   Imai T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209639
   Jiang FY, 2008, IEEE IMAGE PROC, P1648, DOI 10.1109/ICIP.2008.4712088
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lavoué G, 2010, IEEE T MULTIMEDIA, V12, P636, DOI 10.1109/TMM.2010.2060475
   Li Qi, 2019, ARXIV190302133
   Liao HB, 2012, J VIS COMMUN IMAGE R, V23, P924, DOI 10.1016/j.jvcir.2012.06.005
   Little AC, 2011, PHILOS T R SOC B, V366, P1638, DOI 10.1098/rstb.2010.0404
   Liu YF, 2019, PROC CVPR IEEE, P11869, DOI 10.1109/CVPR.2019.01215
   Liu ZC, 2004, IEEE COMPUT GRAPH, V24, P30, DOI 10.1109/MCG.2004.1297008
   Majid Zadeh Heravi F., 2017, 2016 INT C BIOENGINE, P1
   MARK LS, 1983, PERCEPT PSYCHOPHYS, V33, P193, DOI 10.3758/BF03202839
   Marks J., 2005, REALISM FACIAL IMAGE, V24
   Nute S J, 2000, J Orthod, V27, P31, DOI 10.1093/ortho/27.1.31
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   OToole AJ, 1997, PERCEPTION, V26, P719, DOI 10.1068/p260719
   OTOOLE AJ, 1993, J OPT SOC AM A, V10, P405, DOI 10.1364/JOSAA.10.000405
   Panis G, 2016, IET BIOMETRICS, V5, P37, DOI 10.1049/iet-bmt.2014.0053
   Park U., 2008, 2008 8 IEEE INT C AU, P0, DOI [10.1109/AFGR.2008.4813408, DOI 10.1109/AFGR.2008.4813408]
   PERRETT DI, 1992, PHILOS T ROY SOC B, V335, P23, DOI 10.1098/rstb.1992.0003
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   ROWLAND DA, 1995, IEEE COMPUT GRAPH, V15, P70, DOI 10.1109/38.403830
   Scandrett CM, 2006, PATTERN RECOGN LETT, V27, P1776, DOI 10.1016/j.patrec.2006.02.007
   Shen CT, 2014, J INF SCI ENG, V30, P1131
   Song JK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P899
   Suo J., 2007, MULTIRESOLUTION DYNA
   TAKEUCHI A, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P187
   Tiddeman B, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.946630
   TODD JT, 1980, SCI AM, V242, P132, DOI 10.1038/scientificamerican0280-132
   Urbanova P., 2016, Egyp. J. Foren. Sci., V6, P135, DOI [10.1016/j.ejfs.2016.04.004, DOI 10.1016/J.EJFS.2016.04.004]
   VALENTINE T, 1991, Q J EXP PSYCHOL-A, V43, P161, DOI 10.1080/14640749108400966
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wanga Q., 2001, CREATING ANIMATABLE, P3
   Yang HY, 2018, PROC CVPR IEEE, P31, DOI 10.1109/CVPR.2018.00011
   Yun F, 2004, IEEE SYS MAN CYBERN, P2180
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
NR 57
TC 0
Z9 0
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102803
DI 10.1016/j.jvcir.2020.102803
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA OD3DV
UT WOS:000579732400001
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Manandhar, D
   Bastan, M
   Yap, KH
AF Manandhar, Dipu
   Bastan, Muhammet
   Yap, Kim-Hui
TI Semantic granularity metric learning for visual search
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learnin; Metric learning; Metric loss functions; Semantic
   similarity; Visual search
ID IMAGE SIMILARITY; DEEP; REPRESENTATION
AB Existing metric learning methods often do not consider different granularly in visual similarly. However, in many domains, images exhibit similarly at multiple granularities with visual semantic concepts, e.g. fashion demonstrates similarly ranging from clothing of the exact same instance to similar looks/design or common category. Therefore, training image triplets/pairs inherently possess different degree of information. Nevertheless, the existing methods often treat them with equal importance which hinder capturing underlying granularities in image similarly. In view of this, we propose a new semantic granularly metric learning (SGML) that develops a novel idea of detecting and leveraging attribute semantic space and integrating it into deep metric learning to capture multiple granularities of similarly. The proposed framework simultaneously learns image attributes and embeddings with multitask-CNN where the tasks are linked by semantic granularly similarly mapping to leverage correlations between the tasks. To this end, we propose a new soft-binomial deviance loss that effectively integrates informativeness of training samples into metric-learning on-the-fly during training. Compared to recent ensemble-based methods, SGML is conceptually elegant, computationally simple yet effective. Extensive experiments on benchmark datasets demonstrate its superiorly e.g., 1-4.5%-Recall@1 improvement over the state-of-the-arts (Kim a al., 2018; Cakir a al., 2019) on DeepFashion-Inshop
C1 [Manandhar, Dipu; Yap, Kim-Hui] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
   [Bastan, Muhammet] Amazon, Palo Alto, CA USA.
   [Manandhar, Dipu] Univ Surrey, Guildford, Surrey, England.
   [Bastan, Muhammet] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University; Amazon.com; University of Surrey;
   Nanyang Technological University
RP Manandhar, D (corresponding author), Univ Surrey, Guildford, Surrey, England.
EM dipu002@e.ntu.edu.sg; mbastan@amazon.com; ekhyap@ntu.edu.sg
FU Infocomm Media Development Authority, Singapore; NVIDIA AI Technology
   Center
FX This research was carried out at the Rapid-Rich Object Search (ROSE) Lab
   at the Nanyang Technological University, Singapore. The ROSE Lab is
   supported by the Infocomm Media Development Authority, Singapore. We
   gratefully acknowledge the support of NVIDIA AI Technology Center for
   their donation of GPUs used for our research at the ROSE Lab.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Alzu'bi A, 2015, J VIS COMMUN IMAGE R, V32, P20, DOI 10.1016/j.jvcir.2015.07.012
   [Anonymous], 2010, CNSTR2010001 CALTECH
   [Anonymous], 2014, ARXIV14117923
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai JL, 2019, IEEE T MULTIMEDIA, V21, P3178, DOI 10.1109/TMM.2019.2920601
   Balntas V., 2016, BMVC, V1, P3
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cakir F, 2019, PROC CVPR IEEE, P1861, DOI 10.1109/CVPR.2019.00196
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chong SC, 2018, J VIS COMMUN IMAGE R, V56, P207, DOI 10.1016/j.jvcir.2018.09.017
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Friedman S, 2001, IND REL RES, P1, DOI 10.1097/00054725-200102000-00001
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han K, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P2040, DOI 10.1145/3240508.3240550
   Harwood B, 2017, IEEE I CONF COMP VIS, P2840, DOI 10.1109/ICCV.2017.307
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Horiguchi S, 2018, IEEE T MULTIMEDIA, V20, P2836, DOI 10.1109/TMM.2018.2814339
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang JS, 2015, IEEE I CONF COMP VIS, P1062, DOI 10.1109/ICCV.2015.127
   Huang M, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1262, DOI 10.1109/ICISCE.2016.270
   Kang CC, 2015, IEEE T MULTIMEDIA, V17, P370, DOI 10.1109/TMM.2015.2390499
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Kiapour MH, 2015, IEEE I CONF COMP VIS, P3343, DOI 10.1109/ICCV.2015.382
   Kim W, 2018, LECT NOTES COMPUT SC, V11205, P760, DOI 10.1007/978-3-030-01246-5_45
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Leibe B., 2017, ARXIV170307737CS
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Liong VE, 2017, IEEE T MULTIMEDIA, V19, P1234, DOI 10.1109/TMM.2016.2646180
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Manandhar D., 2018, EUR C COMPUT VIS
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Opitz M, 2020, IEEE T PATTERN ANAL, V42, P276, DOI 10.1109/TPAMI.2018.2848925
   Opitz M, 2017, IEEE I CONF COMP VIS, P5199, DOI 10.1109/ICCV.2017.555
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paszke A., 2017, NIPS W
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Qiurui Wang, 2019, IEEE Transactions on Multimedia, V21, P1839, DOI 10.1109/TMM.2018.2890360
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sadeghi H, 2019, J VIS COMMUN IMAGE R, V62, P152, DOI 10.1016/j.jvcir.2019.05.004
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shankar D., 2017, ARXIV170302344
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tang Y., 2019, IEEE T MULTIMED
   Ustinova E, 2016, ADV NEUR IN, V29
   Vo N., 2018, ARXIV180303310
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang J, 2017, IEEE I CONF COMP VIS, P2612, DOI [10.1109/ICCV.2017.283, 10.1109/ICCV.2017.65]
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang X, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P7, DOI 10.1145/2911996.2912002
   Wang XS, 2019, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR.2019.00535
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Xuan H., 2018, EUR C COMP VIS
   Yang XS, 2016, IEEE T MULTIMEDIA, V18, P1832, DOI 10.1109/TMM.2016.2582379
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu BS, 2019, IEEE I CONF COMP VIS, P6499, DOI 10.1109/ICCV.2019.00659
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zhang L, 2017, IEEE T MULTIMEDIA, V19, P1220, DOI 10.1109/TMM.2016.2646219
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zheng WZ, 2019, PROC CVPR IEEE, P72, DOI 10.1109/CVPR.2019.00016
NR 72
TC 6
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102871
DI 10.1016/j.jvcir.2020.102871
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chi, BW
   Yu, M
   Jiang, GY
   He, ZY
   Peng, ZJ
   Chen, F
AF Chi, Biwei
   Yu, Mei
   Jiang, Gangyi
   He, Zhouyan
   Peng, Zongju
   Chen, Fen
TI Blind tone mapped image quality assessment with image segmentation and
   visual perception
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High dynamic range image; Tone mapped image; Image quality assessment;
   Image segmentation; Visual perception; Feature clustering
ID NATURALNESS; INFORMATION; SIMILARITY; INDEX
AB With tone mapping, high dynamic range (HDR) image contents can be displayed on low dynamic range (LDR) display devices, in which some important visual information may be distorted. Thus, the tone mapped image (TMI) quality assessment is one of important issues in HDR image/video processing fields. Considering the difference of visual distortion degrees between the flat and complex regions in TMI, and considering that high-quality TMI should preserve as much information as possible of its original HDR image especially in the high/low luminance regions, this paper proposes a new blind TMI quality assessment method with image segmentation and visual perception. First, we design different features to describe the distortion of TMI's different regions with two kinds of TMI segmentation. Then, considering that there lacks an efficient algorithm to quantify the importance of features, a feature clustering scheme is designed to eliminate the poor effect feature components in the extracted features to improve the effectiveness of the selected features. Finally, considering the diversity of tone mapping operator (TMO), which may cause global and local distortion of TMI, some other global features are also combined. At last, a final feature vector is formed to synthetically describe the distortion in TMI and used to blindly predict the TMI's quality. Experimental results in the public ESPL-LIVE HDR database show that the Pearson linear correlation coefficient and Spearman rank order correlation coefficient of the proposed method reach 0.8302 and 0.7887, respectively, which is superior to the state-of-the-art blind TMI quality assessment methods, and it means that the proposed method is highly consistent with human visual perception. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Chi, Biwei; Yu, Mei; Jiang, Gangyi; He, Zhouyan; Peng, Zongju; Chen, Fen] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
   [Yu, Mei; Jiang, Gangyi] Nanjing Univ, Natl Key Lab Software New Technol, Nanjing, Peoples R China.
C3 Ningbo University; Nanjing University
RP Yu, M; Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Peoples R China.
EM yumei2@126.com; jianggangyi@126.com
RI Chen, Fen/ABG-7013-2021; zhouyan, he/GXM-4974-2022; jiang,
   gang/KII-8233-2024
FU National Natural Science Foundation of China [61671258, 61871247,
   61931022, 61671412, 61620106012]; K.C. Wong Magna Fund of Ningbo
   University
FX This work was supported by the National Natural Science Foundation of
   China (61671258, 61871247, 61931022, 61671412 and 61620106012); and K.C.
   Wong Magna Fund of Ningbo University.
CR [Anonymous], 2015, PEKING DAILY NEWS
   [Anonymous], [No title captured]
   [Anonymous], 2018, 2018 INT C IM VIS CO
   Barkowsky M, 2010, IEEE IMAGE PROC, P3245, DOI 10.1109/ICIP.2010.5651143
   Cai H, 2019, J VIS COMMUN IMAGE R, V61, P250, DOI 10.1016/j.jvcir.2019.04.006
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   He Q, 2018, IEEE INT CONF MULTI
   Jiang GY, 2018, IEEE ACCESS, V6, P2231, DOI 10.1109/ACCESS.2017.2782320
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Jiang SY, 2018, ASIA S PACIF DES AUT, P227, DOI 10.1109/ASPDAC.2018.8297310
   Khan IR, 2018, IEEE T IND ELECTRON, V65, P3469, DOI 10.1109/TIE.2017.2760247
   Kottayil NK, 2018, IEEE T IMAGE PROCESS, V27, P1512, DOI 10.1109/TIP.2017.2778570
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P4725, DOI 10.1109/TIP.2017.2713945
   Kundu D, 2017, IEEE T IMAGE PROCESS, V26, P2957, DOI 10.1109/TIP.2017.2685941
   Kundu D, 2016, IEEE IMAGE PROC, P96, DOI 10.1109/ICIP.2016.7532326
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nafchi HZ, 2015, IEEE SIGNAL PROC LET, V22, P1026, DOI 10.1109/LSP.2014.2381458
   Nasrinpour HR, 2015, IEEE IMAGE PROC, P4947, DOI 10.1109/ICIP.2015.7351748
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Sarmah MJ, 2017, IEEE I C COMP INT CO, P1
   Song Y, 2018, SIGNAL PROCESS, V146, P33, DOI 10.1016/j.sigpro.2017.12.020
   Song Y, 2016, APPL OPTICS, V55, P10084, DOI 10.1364/AO.55.010084
   Su EY, 2018, IEEE ACCESS, V6, P47001, DOI 10.1109/ACCESS.2018.2866997
   Tan Hai-feng, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P379, DOI 10.1109/ICCSEE.2012.157
   Wang HC, 2008, INT J COMPUT VISION, V76, P217, DOI 10.1007/s11263-007-0053-0
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Wu L, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P280, DOI 10.1109/BigMM.2017.65
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang KF, 2019, IEEE T CIRC SYST VID, V29, P640, DOI 10.1109/TCSVT.2018.2810212
   Yanping Lu, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457862
   Yeganeh H, 2013, IEEE T IMAGE PROCESS, V22, P657, DOI 10.1109/TIP.2012.2221725
   Yue GH, 2019, IEEE T IND ELECTRON, V66, P3784, DOI 10.1109/TIE.2018.2851984
   Zhang JG, 2016, MULTIMEDIA SYST, V22, P343, DOI 10.1007/s00530-015-0464-7
NR 42
TC 10
Z9 10
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102752
DI 10.1016/j.jvcir.2020.102752
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800008
DA 2024-07-18
ER

PT J
AU Yang, SR
   Lin, CY
   Liao, K
   Zhao, Y
   Liu, MQ
AF Yang, Shangrong
   Lin, Chunyu
   Liao, Kang
   Zhao, Yao
   Liu, Meiqin
TI Unsupervised fisheye image correction through bidirectional loss with
   geometric prior
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised; Fisheye image correction; Bidirectional loss; Geometric
   prior; Inpainting; Deep learning
ID VIEW
AB Neural network based methods for fisheye distortion correction are effective and increasingly popular, although training network require a high amount of labeled data. In this paper, we propose an unsupervised fisheye correction network to address the aforementioned issue. During the training process, the predicted parameters are employed to correct strong distortion that exists in the fisheye image and synthesize the corresponding distortion using the original distortion-free image. Thus, the network is constrained with bidirectional loss to obtain more accurate distortion parameters. We calculate the two losses at the image level as opposed to directly minimizing the difference between the predicted and ground truth of distortion parameters. Additionally, we leverage the geometric prior that the distortion distribution depends on the geometric regions of fisheye images and the straight line should be straight in the corrected images. The network focuses more on the geometric prior regions as opposed to equally perceiving the whole image without any attention mechanisms. To generate more appealing corrected results in visual appearance, we introduce a coarse-to-fine inpainting network to fill the hole regions caused by the irreversible mapping function using distortion parameters. Each module of the proposed network is differentiable, and thus the entire framework is completely end-to-end. When compared with the previous supervised methods, our method is more flexible and shows better practical applications for distortion rectification. The experiment results demonstrate that our proposed method outperforms state-of-the-art methods on the correction performance without any labeled distortion parameters. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yang, Shangrong; Lin, Chunyu; Liao, Kang; Zhao, Yao; Liu, Meiqin] Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Lin, CY (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing Key Lab Adv Informat Sci & Network, Beijing 100044, Peoples R China.
EM cylin@bjtu.edu.cn
RI Yang, Shangrong/JXN-8480-2024; Lin, Chunyu/AAI-5185-2021; Liao,
   Kang/ADB-6353-2022
OI Lin, Chunyu/0000-0003-2847-0349; 
FU National Key R&D Program of China [2018YFB1201601]; National Natural
   Science Foundation of China [61772066, 61972028]; Fundamental Research
   Funds for the Central Universities [2018JBZ001]
FX This work was supported in part by National Key R&D Program of China
   (2018YFB1201601), in part by supported by National Natural Science
   Foundation of China (Nos. 61772066, 61972028) and Fundamental Research
   Funds for the Central Universities (2018JBZ001).
CR Alemán-Flores M, 2014, IMAGE PROCESS ON LIN, V4, P327, DOI 10.5201/ipol.2014.106
   [Anonymous], [No title captured]
   [Anonymous], 2012, ECCV
   [Anonymous], 2014, NEURIPS
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Arjovsky M., 2017, ARXIV170107875
   Barreto J. P., 2009, BMVC
   BASU A, 1995, PATTERN RECOGN LETT, V16, P433, DOI 10.1016/0167-8655(94)00115-J
   Bukhari F, 2013, J MATH IMAGING VIS, V45, P31, DOI 10.1007/s10851-012-0342-2
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Fernandes LAF, 2008, PATTERN RECOGN, V41, P299, DOI 10.1016/j.patcog.2007.04.003
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Gao Y, 2018, IEEE T INTELL TRANSP, V19, P320, DOI 10.1109/TITS.2017.2750087
   Hughes C, 2010, IEEE T PATTERN ANAL, V32, P2289, DOI 10.1109/TPAMI.2010.159
   Gulrajani I, 2017, ADV NEUR IN, V30
   King DB, 2015, ACS SYM SER, V1214, P1
   Lee H, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P629, DOI 10.1109/ITSC.2016.7795619
   Liao K., 2019, IEEE T CIRCUITS SYST
   Melo R, 2013, IEEE I CONF COMP VIS, P537, DOI 10.1109/ICCV.2013.72
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   Rong J., 2016, ACCV
   Schneider D, 2009, ISPRS J PHOTOGRAMM, V64, P259, DOI 10.1016/j.isprsjprs.2009.01.001
   Shah S, 1996, PATTERN RECOGN, V29, P1775, DOI 10.1016/0031-3203(96)00038-6
   Ying XH, 2008, INT J COMPUT VISION, V78, P89, DOI 10.1007/s11263-007-0082-8
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   ZISSERMAN A, 1995, ARTIF INTELL, V78, P239, DOI 10.1016/0004-3702(95)00023-2
NR 29
TC 15
Z9 15
U1 9
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102692
DI 10.1016/j.jvcir.2019.102692
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200004
DA 2024-07-18
ER

PT J
AU Liu, Y
   Wang, HD
   Gu, Y
   Lv, XH
AF Liu, Ying
   Wang, Haodong
   Gu, Yue
   Lv, Xiaohong
TI Image classification toward lung cancer recognition by learning deep
   quality model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image classification; Cancer recognition; Deep feature; CNN
ID ITERATIVE RECONSTRUCTION; TIME; STATE; CHEST
AB Image classification aims to automatically group a set of images into several categorizations, which is widely applied in scene categorization, image clustering. Lung cancer recognition can be achieved by using image classification technique, since there are distinct differences between healthy lung and sick lung images. In this paper, we propose lung cancer recognition based on image quality assessment, which can distinguish sick lung images from healthy lung images. First, our dataset is acquired using low-dose CT scan combined with full-mode iterative recombination (IMR). Then, we incorporate both low-level and high-level features to extract deep representation from obtained dataset. Specifically, our designed low-level features include color moment and texture feature, and CNN based method is leveraged for deep feature extraction. For reducing artifacts and noise of images, we assign quality score for each training image. And quality score and deep feature are fused to generate deep representation. Afterward, we propose a probabilistic model to learn the distribution of deep representation. Finally, lung cancer recognition can be achieved using learned model. We conduct comprehensive experiments and our proposed method is verified effective. (C) 2019 Published by Elsevier Inc.
C1 [Liu, Ying; Gu, Yue; Lv, Xiaohong] Jilin Univ, Hosp 1, Dept Resp Med, Changchun 130021, Jilin, Peoples R China.
   [Wang, Haodong; Gu, Yue] Jilin Univ, Hosp 1, Dept Vasc Surg, Changchun 130021, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Lv, XH (corresponding author), Jilin Univ, Hosp 1, Dept Resp Med, Changchun 130021, Jilin, Peoples R China.
EM liuying0215@jlu.edu.cn; lvxiaoh@jlu.edu.cn
RI liu, sha/JXL-6600-2024; Li, Ruoyu/KEJ-3648-2024
OI Li, Ruoyu/0000-0002-9929-3725
FU National Science Fund for Distinguished Young Scholars [81700027]
FX This work was supported by The National Science Fund for Distinguished
   Young Scholars (No. 81700027).
CR [Anonymous], IMAGE RES MED APPL
   [Anonymous], CHINA CONTINUING MED
   [Anonymous], CHINA MODERN MED J
   [Anonymous], CT THEORY APPL RES
   [Anonymous], CHINA MODERN MED J
   [Anonymous], IMAGE RES MED APPL
   [Anonymous], CHIN J CLIN MED IMAG
   [Anonymous], WORLD HLTH INFORM DI
   [Anonymous], CONTINUING MED ED
   [Anonymous], CHIN FOREIGN MED RES
   [Anonymous], J CLIN RADIOL
   [Anonymous], CHIN J RADIOL J LEAR
   [Anonymous], IMAGE RES MED APPL
   [Anonymous], J CLIN MED LIT
   [Anonymous], CHIN SCH DOCTOR
   [Anonymous], IMAGE RES MED APPL
   [Anonymous], CHIN J RURAL MED
   [Anonymous], HENAN MED RES
   Ding SF, 2015, ARTIF INTELL REV, V43, P593, DOI 10.1007/s10462-013-9398-7
   Duan H, 2009, J SYST SOFTWARE, V82, P400, DOI 10.1016/j.jss.2008.07.007
   [樊荣荣 Fan Rongrong], 2019, [临床放射学杂志, Journal of Clinical Radiology], V38, P547
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang X, 2016, NEUROCOMPUTING, V218, P296, DOI 10.1016/j.neucom.2016.08.078
   Khawaja RDA, 2014, J COMPUT ASSIST TOMO, V38, P613, DOI 10.1097/RCT.0000000000000087
   Kim H, 2014, EUR J RADIOL, V83, P848, DOI 10.1016/j.ejrad.2014.01.025
   Liu L, 2015, COMPUT GEOSCI-UK, V83, P27, DOI 10.1016/j.cageo.2015.06.017
   Sheng L, 2017, IEEE T NEUR NET LEAR, V28, P2382, DOI 10.1109/TNNLS.2016.2580601
   Song BY, 2017, COGN COMPUT, V9, P5, DOI 10.1007/s12559-016-9442-4
   Sun HM, 2016, COMPUT GEOSCI-UK, V91, P98, DOI 10.1016/j.cageo.2016.03.012
   Tian ZW, 2016, COMPUT GEOSCI-UK, V86, P15, DOI 10.1016/j.cageo.2015.10.002
   Wang H, 2013, INFORM SCIENCES, V223, P221, DOI 10.1016/j.ins.2012.08.027
   Wang JJ, 2014, J ZHEJIANG U-SCI C, V15, P383, DOI 10.1631/jzus.C1300289
   Wang TJ, 2019, CHIN OPT LETT, V17, DOI 10.3788/COL201917.020009
   [王晓红 Wang Xiaohong], 2017, [临床放射学杂志, Journal of Clinical Radiology], V36, P1690
   Yan B, 2013, MULTIMED TOOLS APPL, V67, P383, DOI 10.1007/s11042-011-0861-7
   Yuki H, 2016, ACTA RADIOL, V57, P295, DOI 10.1177/0284185115575537
NR 36
TC 15
Z9 17
U1 2
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102570
DI 10.1016/j.jvcir.2019.06.012
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200002
DA 2024-07-18
ER

PT J
AU Hayat, N
   Imran, M
AF Hayat, Naila
   Imran, Muhammad
TI Ghost-free multi exposure image fusion technique using dense SIFT
   descriptor and guided filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-exposure fusion; Dynamic range; Dense SIFT; Histogram; Quality
   measures; Pyramids
AB A ghost-free multi-exposure image fusion technique using the dense SIFT descriptor and the guided filter is proposed in this paper. The results suggest that the presented scheme produces high-quality images using ordinary cameras and that too without the ghosting artifact. To do so, the dense SIFT descriptor is used to extract the local contrast information from source images. Whereas, for the dynamic scenes, the histogram equalization and median filtering are used to calculate the color dissimilarity feature. Three weighting terms: local contrast, brightness, and color dissimilarity feature are used to estimate the initial weights. The estimated initial weights contain discontinuities. Therefore, the guided filter is used to remove the noise and discontinuity in initial weights. Finally, the fusion is performed using a pyramid decomposition method. Experimental results prove the superiority of the proposed technique over existing state-of-the-art methods in terms of both subjective and objective evaluation. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hayat, Naila] Sardar Bahadur Khan Women Univ, Dept Comp Sci, Quetta 87300, Pakistan.
   [Imran, Muhammad] Balochistan Univ IT Engn & Management Sci, Dept Elect Engn, Quetta 87300, Pakistan.
RP Imran, M (corresponding author), Balochistan Univ IT Engn & Management Sci, Dept Elect Engn, Quetta 87300, Pakistan.
EM mi14@my.fsu.edu
RI Imran, Muhammad/HTT-4220-2023
OI Imran, Muhammad/0000-0002-1147-3159
CR [Anonymous], 2014, 2014 IEEE INT C MULT
   [Anonymous], MVA
   Artusi A, 2017, IEEE SIGNAL PROC MAG, V34, P165, DOI 10.1109/MSP.2017.2716957
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Eilertsen G., 2016, High Dynamic Range Video, P185
   Endo Y, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130834
   Florea C, 2015, INT J AP MAT COM-POL, V25, P943, DOI 10.1515/amcs-2015-0067
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gava S., 2018, THESIS
   Gonzalea RC, 2004, WAVELETS MULTIRESOLU
   Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254
   Heidrich Wolfgang, ERIK REINHARD
   Huang F, 2018, IEEE ACCESS, V6, P42877, DOI 10.1109/ACCESS.2018.2859355
   Jinno T, 2012, IEEE T IMAGE PROCESS, V21, P358, DOI 10.1109/TIP.2011.2160953
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Lee DH, 2018, SIGNAL PROCESS-IMAGE, V68, P120, DOI 10.1016/j.image.2018.07.008
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li RJ, 2007, IEEE T CONSUM ELECTR, V53, P1161, DOI 10.1109/TCE.2007.4341600
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Li ZG, 2017, IEEE T IMAGE PROCESS, V26, P1243, DOI 10.1109/TIP.2017.2651366
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nejati M, 2017, IEEE IMAGE PROC, P2234, DOI 10.1109/ICIP.2017.8296679
   Oh TH, 2015, IEEE T PATTERN ANAL, V37, P1219, DOI 10.1109/TPAMI.2014.2361338
   Paris S, 2006, LECT NOTES COMPUT SC, V3954, P568
   Qian J, 2016, EURASIP J WIREL COMM, P1, DOI 10.1186/s13638-016-0650-0
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Srikantha A, 2012, SIGNAL PROCESS-IMAGE, V27, P650, DOI 10.1016/j.image.2012.02.001
   Sun N., 2012, HDR IMAGE CONSTRUCTI
   Vanmali A. V., 2015, P 2015 21 NATL C COM, P1
   Wu SZ, 2018, LECT NOTES COMPUT SC, V11206, P120, DOI 10.1007/978-3-030-01216-8_8
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yan Q., 2019, ARXIV190410293
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
NR 42
TC 61
Z9 68
U1 3
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 295
EP 308
DI 10.1016/j.jvcir.2019.06.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600029
DA 2024-07-18
ER

PT J
AU Hua, X
   Zhang, CH
   Wei, JD
   Hu, XJ
   Wei, HL
AF Hua, Xin
   Zhang, Chunhua
   Wei, Jinda
   Hu, Xingjun
   Wei, Hongliang
TI Wind turbine bionic blade design and performance analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Numerical simulation; Source of renewable energy; Wind turbine blade
ID OBJECT DETECTION; TRAINS; DEEP
AB With the growing shortage of energy, wind power is receiving an increasing amount of attention worldwide as a clean source of renewable energy. One of the most important components of the wind turbine is the bird-wing-like blade under the working principle. Three kinds of bionic blades are designed by using bionic wing type and configuration based on the good aerodynamic performance of seagull wings, combined with the theory of wind turbine blade design-the blade element theory. Standard blade and aerodynamic performances of bionic blade are evaluated by means of numerical simulation. Under different wind speeds, the results show that the blade torque of the bionic blade of total improved airfoil increases by 10.2%, the bionic blade of partially improved airfoil increases by 14%, and the configuration improved blade increases by 7%. To verify the correctness of the numerical simulation results, we run the bionic blade and establish a corresponding experimental device in an actual experiment. The results of the experiment are consistent with the trend of the numerical simulation. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hua, Xin; Zhang, Chunhua; Wei, Jinda] Aviat Univ Air Force, Changchun 130000, Jilin, Peoples R China.
   [Hua, Xin; Hu, Xingjun] Jilin Univ, Changchun 130000, Jilin, Peoples R China.
   [Wei, Hongliang] State Grid ChangChun Elect Power Supply Co, Changchun 130000, Jilin, Peoples R China.
C3 Aviation University Air Force; Jilin University
RP Hu, XJ (corresponding author), Jilin Univ, Changchun 130000, Jilin, Peoples R China.
EM yangzhang1556@126.com
RI Zhang, Chunhua/ISB-1530-2023
OI Zhang, Chunhua/0000-0002-2099-7181
CR Alam F., 2007, P 16 AUSTR FLUID MEC
   Baker CJ, 2010, J WIND ENG IND AEROD, V98, P88, DOI 10.1016/j.jweia.2009.09.006
   Baker CJ, 2004, J WIND ENG IND AEROD, V92, P547, DOI 10.1016/j.jweia.2004.03.002
   Carrarini A, 2007, J WIND ENG IND AEROD, V95, P493, DOI 10.1016/j.jweia.2006.10.001
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Deubel Till, 2006, INT DES C DUBR CROAT, P15
   [董香婷 DONG Xiangting], 2008, [铁道学报, Journal of the China Railway Society], V30, P36
   Gohlke M, 2010, J WIND ENG IND AEROD, V98, P386, DOI 10.1016/j.jweia.2009.12.003
   [龚旭 Gong Xu], 2010, [汽车工程, Automotive Engineering], V32, P13
   [海贵春 HAI Guichun], 2006, [湖南大学学报. 自然科学版, Journal of Hunan University. Natural Sciences], V33, P40
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Jiang H., 2001, Journal of Tongji University (Natural Science), V29, P1451
   Khier W, 2000, COMPUT FLUIDS, V29, P179, DOI 10.1016/S0045-7930(99)00008-0
   Liu T. S., 2008, AIAA, P2004
   Sanquer S, 2004, J WIND ENG IND AEROD, V92, P535, DOI 10.1016/j.jweia.2004.03.004
   Song F, 2007, MAT SCI ENG A-STRUCT, V457, P254, DOI 10.1016/j.msea.2007.01.136
   Sterling M, 2010, J WIND ENG IND AEROD, V98, P10, DOI 10.1016/j.jweia.2009.08.008
   Tubaro PL, 2003, J AVIAN BIOL, V34, P243, DOI 10.1034/j.1600-048X.2003.03084.x
   [王夫亮 Wang Fuliang], 2010, [汽车工程, Automotive Engineering], V32, P477
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   [周宇 ZHOU Yu], 2010, [空气动力学学报, Acta Aerodynamica Sinica], V28, P213
NR 31
TC 23
Z9 28
U1 13
U2 91
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 258
EP 265
DI 10.1016/j.jvcir.2019.01.037
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000028
DA 2024-07-18
ER

PT J
AU Oliveira, A
   Oakley, E
   Torres, RD
   Rocha, A
AF Oliveira, Alberto
   Oakley, Eric
   Torres, Ricardo da Silva
   Rocha, Anderson
TI Relevance prediction in similarity-search systems using extreme value
   theory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Relevance prediction; Performance prediction; Extreme value theory;
   Weibull distribution; Information retrieval
AB Among the challenges present in the design of retrieval systems, how to accurately assess their performance is perhaps one of the most important. Many applications such as rank aggregation or relevance feedback can be significantly improved with online effectiveness estimation of queries. Thus, developing methodologies that can estimate performance with minimal supervision and at query time is of utmost importance for improving the results of existing retrieval systems. In this work, we explore score-based, post-retrieval approaches for relevance prediction of search systems. We first introduce two statistical methods based on the Extreme Value Theory to estimate which of the top - k objects retrieved for a query are relevant. Our prediction approach uses this estimation as a method to infer the overall performance of a query. The two relevance prediction methods were evaluated in image datasets covering several modalities and scoring approaches. We conducted experiments comparing the ground-truth relevances of several ranks with predictions generated by our proposed approach, measuring their effectiveness by way of normalized accuracy and Matthews Correlation Coefficient. Furthermore, we also evaluate the precision deducted from our approaches with the system's expected performance. Those experiments show that the proposed approaches succeed in most relevance prediction scenarios of the top-ranked objects of a query, obtaining high accuracy. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Oliveira, Alberto; Oakley, Eric; Torres, Ricardo da Silva; Rocha, Anderson] Univ Campinas Unicamp, Inst Comp, Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Oliveira, A (corresponding author), Univ Campinas Unicamp, Inst Comp, Campinas, SP, Brazil.
EM alberto.oliveira@ic.unicamp.br; rtorres@ic.unicamp.br;
   anderson.rocha@ic.unicamp.br
RI Rocha, Anderson/KHU-9621-2024; Torres, Ricardo da S./C-4526-2012
OI Oliveira, Alberto/0000-0002-4711-2777
FU Brazilian Council for Scientific and Technological Development - CNPq
   [304472/2015-8, 307560/2016-3]; Sao Paulo Research Foundation - Fapesp
   [2017/12646-3, 2014/12236-1, 2013/50155-0, 2015/24494-8, 2016/50250-1,
   2014/50715-9, 2017/20945-0]; Coordination for the Improvement of Higher
   Level Education Personnel - CAPES (DeepEyes project)
   [88881.145912/2017-01]; Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior - Brasil (CAPES) [001]; Fundacao de Amparo a Pesquisa do
   Estado de Sao Paulo (FAPESP) [16/50250-1, 14/50715-9, 17/20945-0,
   17/12646-3, 13/50155-0, 14/12236-1] Funding Source: FAPESP
FX We thank the financial support of the Brazilian Council for Scientific
   and Technological Development - CNPq (Grants #304472/2015-8 and
   #307560/2016-3), the Sao Paulo Research Foundation - Fapesp (DejaVu
   Grant #2017/12646-3 and Grants #2014/12236-1, #2013/50155-0,
   #2015/24494-8, #2016/50250-1, #2014/50715-9 and #2017/20945-0), and the
   Coordination for the Improvement of Higher Level Education Personnel -
   CAPES (DeepEyes project and Grant #88881.145912/2017-01). This study was
   financed in part by the Coordenacao de Aperfeicoamento de Pessoal de
   Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR [Anonymous], IEEE Transactions on Pattern Analysis and Machine Intelligence
   Aslam J. A., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P601, DOI 10.1145/1148170.1148275
   Aslam Javed A., 2003, P 12 INT C INF KNOWL, P484, DOI [10.1145/956863.956953, DOI 10.1145/956863.956953]
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Collins-Thompson K, 2010, LECT NOTES COMPUT SC, V5993, P140, DOI 10.1007/978-3-642-12275-0_15
   Cronen-Townsend S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P299
   Cummins R, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559170
   Cummins R, 2011, LECT NOTES COMPUT SC, V7097, P315, DOI 10.1007/978-3-642-25631-8_29
   Diaz Fernando, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P583, DOI 10.1145/1277741.1277841
   Furon  T., 2013, TECH REP
   Gumbel E. J, 1954, STAT THEORY EXTREME
   Hauff Claudia, 2008, CIKM, P1419
   Jia QH, 2015, SIGNAL PROCESS, V110, P232, DOI 10.1016/j.sigpro.2014.07.018
   Jia Qianghuai, 2014, INT C MULT FUS INF I, P1
   Kotz S., 2000, Extreme Value Distributions: Theory and Applications
   Kurland O, 2011, LECT NOTES COMPUT SC, V6931, P15, DOI 10.1007/978-3-642-23318-0_4
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Mei T, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2536798
   Mizzaro S, 2018, ACM/SIGIR PROCEEDINGS 2018, P1233, DOI 10.1145/3209978.3210146
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Patil P. B., J APPL COMPUT SCI MA, V10
   Roitman H, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P245, DOI 10.1145/3121050.3121087
   Roitman H, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P35, DOI 10.1145/3121050.3121051
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scheirer W. J., 2011, METARECOGNITION TOOL
   Scheirer WJ, 2011, IEEE T PATTERN ANAL, V33, P1689, DOI 10.1109/TPAMI.2011.54
   Shtok A, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180873
   Shtok A, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2926790
   Shtok A, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P259
   Soboroff I., 2001, SIGIR Forum, P66
   Sun  S., IEEE T IMAGE PROCESS
   Vinay V., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P398, DOI 10.1145/1148170.1148239
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Yom-Tov E., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P512, DOI 10.1145/1076034.1076121
   Zamani H, 2018, ACM/SIGIR PROCEEDINGS 2018, P105, DOI 10.1145/3209978.3210041
   Zhang ZM, 2018, LECT NOTES COMPUT SC, V10987, P277, DOI 10.1007/978-3-319-96890-2_23
   Zhao Y, 2008, LECT NOTES COMPUT SC, V4956, P52
   Zhou Y., 2006, CIKM, P567
NR 41
TC 3
Z9 3
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 236
EP 249
DI 10.1016/j.jvcir.2019.02.019
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000026
DA 2024-07-18
ER

PT J
AU Zhu, J
   Zhu, JC
   Wan, XD
   Wu, C
   Xu, C
AF Zhu, Jun
   Zhu, Jiangcheng
   Wan, Xudong
   Wu, Chao
   Xu, Chao
TI Object detection and localization in 3D environment by fusing raw
   fisheye image and attitude data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Deep learning; Data fusion; Fisheye camera; Micro
   aerial vehicle; Localization
AB In robotic systems, the fisheye camera can provide a large field of view (FOV). Usually, the traditional restoring algorithms are needed, which are computational heavy and will introduce noise into original data, since the fisheye images are distorted. In this paper, we propose a framework to detect objects from the raw fisheye images without restoration, then locate objects in the real world coordinate by fusing attitude information. A deep neural network architecture based on the MobileNet and feature pyramid structure is designed to detect targets directly on the fisheye raw images. Then, the target can be located based on the fisheye visual model and the attitude of the camera, Compared to traditional approaches, this approach has advantages in computational efficiency and accuracy. This approach is validated by experiments with a fisheye camera and an onboard computer on a micro-aerial vehicle (MAV). (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhu, Jun; Zhu, Jiangcheng; Wan, Xudong; Xu, Chao] Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Zhejiang, Peoples R China.
   [Wu, Chao] Zhejiang Univ, Sch Publ Affairs, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Xu, C (corresponding author), Zhejiang Univ, State Key Lab Ind Control Technol, Hangzhou, Zhejiang, Peoples R China.
EM cxu@zju.edu.cn
OI Zhu, Jun/0000-0003-2304-3671
FU National Natural Science Foundation of China [61473253]; Fundamental
   Research Funds for the Central Universities of China; Foundation for
   Innovative Research Groups of the National Natural Science Foundation of
   China [61621002]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61473253, the Fundamental Research Funds for the
   Central Universities of China, and the Foundation for Innovative
   Research Groups of the National Natural Science Foundation of China
   under Grant 61621002.
CR [Anonymous], P IEEE COMP SOC C CO
   Cheng ZY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Cheng ZY, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2846092
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Eichenseer A, 2016, INT CONF ACOUST SPEE, P1541, DOI 10.1109/ICASSP.2016.7471935
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Micusík B, 2003, PROC CVPR IEEE, P485
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372
   Scaramuzza Davide, 2006, 4 IEEE INT C COMPUTE, P45, DOI DOI 10.1109/ICVS.2006.3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Zhu J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1183, DOI 10.1109/ICInfA.2016.7831999
NR 36
TC 9
Z9 12
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 128
EP 139
DI 10.1016/j.jvcir.2019.01.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600013
DA 2024-07-18
ER

PT J
AU Rana, SP
   Dey, M
   Siarry, P
AF Rana, Soumya Prakash
   Dey, Maitreyee
   Siarry, Patrick
TI Boosting content based image retrieval performance through integration
   of parametric & nonparametric approaches
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CBIR; Color moments; Ranklet transform; Nonparametric statistics; Moment
   invariants; Hypothesis test
ID PATTERN RECOGNITION; TEXTURAL FEATURES; OBJECT DETECTION; COLOR;
   CLASSIFICATION; REPRESENTATION
AB The collection of digital images is growing at ever-increasing rate which rises the interest of mining the embedded information. The appropriate representation of an image is inconceivable by a single feature. Thus, the research addresses that point for content based image retrieval (CBIR) by fusing parametric color and shape features with nonparametric texture feature. The color moments, and moment invariants which are parametric methods and applied to describe color distribution and shapes of an image. The nonparametric ranklet transformation is performed to narrate the texture features. Experimentally these parametric and nonparametric features are integrated to propose a robust and effective algorithm. The proposed work is compared with seven existing techniques by determining statistical metrics across five image databases. Finally, a hypothesis test is carried out to establish the significance of the proposed work which, infers evaluated precision and recall values are true and accepted for the all image database. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Rana, Soumya Prakash; Dey, Maitreyee] London South Bank Univ, 103 Borough Rd, London SE1 0AA, England.
   [Siarry, Patrick] Univ Paris Est Creteil, 61 Ave Gen Gaulle, F-94000 Paris, France.
C3 London South Bank University; Universite Paris-Est-Creteil-Val-de-Marne
   (UPEC)
RP Rana, SP (corresponding author), London South Bank Univ, 103 Borough Rd, London SE1 0AA, England.
EM ranas9@lsbu.ac.uk; deym@lsbu.ac.uk; siarry@u-pec.fr
RI Dey, Maitreyee/T-5723-2019; Rana, Soumya/W-7977-2019
OI Dey, Maitreyee/0000-0002-6862-7032; Rana, Soumya/0000-0002-8014-8122
CR ALT FL, 1962, J ACM, V9, P240, DOI 10.1145/321119.321122
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Burger W., 2009, Principles of Digital Image Processing
   Chuang CH, 2014, J VIS COMMUN IMAGE R, V25, P1018, DOI 10.1016/j.jvcir.2014.02.014
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Cui CR, 2017, J VIS COMMUN IMAGE R, V48, P367, DOI 10.1016/j.jvcir.2017.03.011
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Feng L, 2015, J VIS COMMUN IMAGE R, V33, P104, DOI 10.1016/j.jvcir.2015.09.002
   Foley J.D., 1990, Computer graphics: Principles and practice
   Gonzalez R. C., 2006, PEARSON ED INDIA, V3rd
   Gosall N., 2012, DOCTORS GUIDE CRITIC, V3rd
   Gouiffès M, 2013, J VIS COMMUN IMAGE R, V24, P361, DOI 10.1016/j.jvcir.2013.01.009
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HODGSON RM, 1985, IMAGE VISION COMPUT, V3, P3, DOI 10.1016/0262-8856(85)90037-X
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   KIM V, 1986, COMPUT VISION GRAPH, V35, P234, DOI 10.1016/0734-189X(86)90029-0
   LANCE GN, 1966, COMPUT J, V9, P60, DOI 10.1093/comjnl/9.1.60
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo JB, 2006, IEEE T IMAGE PROCESS, V15, P1443, DOI 10.1109/TIP.2006.871081
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Masotti M, 2008, PATTERN RECOGN LETT, V29, P1980, DOI 10.1016/j.patrec.2008.06.017
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rahimi M, 2015, SIGNAL IMAGE VIDEO P, V9, P691, DOI 10.1007/s11760-013-0506-6
   Schwartz S. H., 2004, VISUAL PERCEPTION CL
   Sethi I., 2001, Proceedings of the SPIE Data Mining and Knowledge Discovery, V3, P279, DOI DOI 10.1117/12.421083
   Shaila SG, 2016, J VIS COMMUN IMAGE R, V36, P40, DOI 10.1016/j.jvcir.2016.01.003
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Weber R., 2003, PROC 12 INT C INFORM, P69
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
NR 45
TC 27
Z9 27
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 205
EP 219
DI 10.1016/j.jvcir.2018.11.015
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100022
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Shi, HQ
   Tao, L
AF Shi, Hanqin
   Tao, Liang
TI Visual comparison based on linear regression model and linear
   discriminant analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual comparison; LDA; Linear regression; SVM; Pairwise relative
   attributes
ID HUMAN AGE ESTIMATION
AB Visual comparison is that given two images, we can predict which one exhibits a particular visual attribute more than the other. The existing relative attribute methods rely on ranking SVM functions to conduct visual comparison; however, the ranking SVM functions are sensitive to the support vectors. When there are rarely effective samples, the performance of the ranking SVM model will be greatly discounted. To address this issue, we propose the pairwise relative attribute method for visual comparison by training the Linear Regression Model (LRM), which can be formulated by learning a mapping function between a vector-formed feature input with pairwise image difference and a scalar-valued output. In addition, we propose a novel feature reduction method based on the Linear Discriminant Analysis (LDA) in order to obtain a low dimensional and discriminant feature. Experimental results on the three databases of UT-Zap50K-1, OSR and PubFig demonstrate the advantages of the proposed method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Shi, Hanqin; Tao, Liang] Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
   [Shi, Hanqin] Huaibei Normal Univ, Sch Comp Sci & Technol, Huaibei 235000, Peoples R China.
C3 Anhui University; Huaibei Normal University
RP Tao, L (corresponding author), Anhui Univ, Sch Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
EM taoliang@ahu.edu.cn
FU Natural Science Foundation of Anhui Province [1508085QF127]; Natural
   Science Foundation of Anhui Higher Education Institutions of China
   [KJ2017B017, KJ2018B05]; Co-Innovation Center for Information Supply &
   Assurance Technology, Anhui University [ADXXBZ201604]
FX This work was funded by the Natural Science Foundation of Anhui Province
   (1508085QF127), the Natural Science Foundation of Anhui Higher Education
   Institutions of China (KJ2017B017, KJ2018B05) and Co-Innovation Center
   for Information Supply & Assurance Technology, Anhui University
   (ADXXBZ201604).
CR An S., 2007, P IEEE C COMP VIS PA, DOI 10.1109/CVPR.2007.383105.
   [Anonymous], 2007, P IEEE 11 INT C COMP
   Biswas A, 2013, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2013.89
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   HAITOVSKY Y, 1987, BIOMETRIKA, V74, P563, DOI 10.1093/biomet/74.3.563
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kovashka A, 2013, IEEE I CONF COMP VIS, P297, DOI 10.1109/ICCV.2013.44
   Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li S., 2013, Computer Vision-ACCV 2012, P316
   Li SX, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2580939
   Liang L, 2014, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2014.34
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Parkash A, 2012, LECT NOTES COMPUT SC, V7574, P354, DOI 10.1007/978-3-642-33712-3_26
   Qian BY, 2014, IEEE T IMAGE PROCESS, V23, P5573, DOI 10.1109/TIP.2014.2365952
   Reid D.A., 2011, 2011 International Joint Conference On Biometrics (IJCB), P1
   Shrivastava A, 2012, LECT NOTES COMPUT SC, V7574, P369, DOI 10.1007/978-3-642-33712-3_27
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Singh KK, 2016, LECT NOTES COMPUT SC, V9910, P753, DOI 10.1007/978-3-319-46466-4_45
   Xiao FY, 2015, IEEE I CONF COMP VIS, P1458, DOI 10.1109/ICCV.2015.171
   You XG, 2014, IEEE T IMAGE PROCESS, V23, P3203, DOI 10.1109/TIP.2014.2327805
   Yu A, 2015, IEEE I CONF COMP VIS, P2416, DOI 10.1109/ICCV.2015.278
   Yu A, 2014, PROC CVPR IEEE, P192, DOI 10.1109/CVPR.2014.32
   Zhang Y, 2010, PROC CVPR IEEE, P2622, DOI 10.1109/CVPR.2010.5539975
NR 33
TC 4
Z9 4
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 118
EP 124
DI 10.1016/j.jvcir.2018.10.026
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400015
DA 2024-07-18
ER

PT J
AU Zhang, GC
AF Zhang, Guangchen
TI Input-output finite-region stability and stabilization for discrete the
   2-D Roesser model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Two-dimensional Roesser model; Input-output finite region stability;
   Controllers of state feedback
ID STATE-SPACE MODEL; LINEAR-SYSTEMS; TIME STABILIZATION; BOUNDEDNESS
AB Image information is usually propagated along horizontal and vertical directions, and it is usually modeled as two-dimensional (2-D) Roesser systems. For Roesser systems, stability ensures it's normal operation, and it is regarded as a key issue. However, note that the mentioned stability above ignores the running conditions of the system in a finite-region, which probably destroy the system' normal operation before the system reaches a steady state. In this paper, many attentions are focused on the classical discrete 2-D Roesser model, and output signal is analyzed in detail on some finite region. This issue is formulated as input-out finite-domain stability (I-O FRS) and it can effectively analyze output signals' transient behavior of discrete 2D Roesser model. First, for discrete 2-D Roesser model, I-O FRS concept is established under considering the effect of exogenous disturbance set W. In particular, when exogenous disturbances W are regarded as W-2 and W-infinity, sufficient I-O FRS criteria are formulated respectively, which are described as linear matrix inequality (LMIs) conditions. Subsequently, by designing state feedback controller, I-O finite-region stabilization is realized also under exogenous disturbances W-2 and W-infinity, and compact LMIs criteria are proposed accordingly. Finally, ranges of examples are described for supporting the correctness of research results. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Guangchen] North Minzu Univ, Sch Math & Informat Sci, Yinchuan 750021, Peoples R China.
C3 North Minzu University
RP Zhang, GC (corresponding author), North Minzu Univ, Sch Math & Informat Sci, Yinchuan 750021, Peoples R China.
EM guangchen_123@163.com
CR Amato F, 2016, NONLINEAR ANAL-HYBRI, V19, P93, DOI 10.1016/j.nahs.2015.08.005
   Amato F, 2010, AUTOMATICA, V46, P1558, DOI 10.1016/j.automatica.2010.06.005
   Amato F, 2001, AUTOMATICA, V37, P1459, DOI 10.1016/S0005-1098(01)00087-5
   Amato F., 2011, P 18 IFAC WORLD C MI, P156
   Amato F, 2012, IEEE T AUTOMAT CONTR, V57, P3051, DOI 10.1109/TAC.2012.2199151
   Amato F, 2011, INT J CONTROL, V84, P1055, DOI 10.1080/00207179.2011.589082
   Amato F, 2010, AUTOMATICA, V46, P919, DOI 10.1016/j.automatica.2010.02.008
   Bachelier O., 2016, PAP LINE, V49, P136
   Bachelier O., 2016, MULTIDIMENSIONAL SYS, P1
   Benzaouia A., 2016, STUDIES SYSTEMS DECI, P28
   Benzaouia A, 2011, INT J SYST SCI, V42, P479, DOI 10.1080/00207720903576522
   Bouagada D, 2013, NUMER LINEAR ALGEBR, V20, P198, DOI 10.1002/nla.836
   Chen XM, 2013, MULTIDIM SYST SIGN P, V24, P395, DOI 10.1007/s11045-011-0166-z
   Ebihara Y, 2006, IEEE T AUTOMAT CONTR, V51, P1509, DOI 10.1109/TAC.2006.880789
   FORNASINI E, 1978, MATH SYST THEORY, V12, P59, DOI 10.1007/BF01776566
   Garcia G, 2009, IEEE T AUTOMAT CONTR, V54, P364, DOI 10.1109/TAC.2008.2008325
   Ghamgui M, 2015, CIRC SYST SIGNAL PR, V34, P3489, DOI 10.1007/s00034-015-0016-6
   Huang SP, 2014, CIRC SYST SIGNAL PR, V33, P141, DOI 10.1007/s00034-013-9610-7
   Juan Yao, 2012, Journal of Control Theory and Applications, V10, P287, DOI 10.1007/s11768-012-1143-2
   KUREK JE, 1985, IEEE T AUTOMAT CONTR, V30, P600, DOI 10.1109/TAC.1985.1103998
   Lin Z., 1989, IEEE T CIRCUITS SYST, V36
   Ma HJ, 2011, IEEE DECIS CONTR P, P8026, DOI 10.1109/CDC.2011.6160384
   Paszke W., 2011, P 2011 INT WORKSH MU, P1
   ROESSER RP, 1975, IEEE T AUTOMAT CONTR, VAC20, P1, DOI 10.1109/TAC.1975.1100844
   Thamvichai R, 2002, IEEE T CIRCUITS-II, V49, P61, DOI 10.1109/82.996060
   Xiang ZR, 2013, CIRC SYST SIGNAL PR, V32, P401, DOI 10.1007/s00034-012-9464-4
   Yeganefar N., 2013, MULT SYST NDS 2013 P, P1
   Zhang GC, 2017, SYST CONTROL LETT, V99, P9, DOI 10.1016/j.sysconle.2016.10.011
   Zhang GC, 2016, MATH METHOD APPL SCI, V39, P5757, DOI 10.1002/mma.3982
   Zhang GC, 2017, INT J SYST SCI, V48, P778, DOI 10.1080/00207721.2016.1212436
NR 30
TC 0
Z9 0
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 253
EP 261
DI 10.1016/j.jvcir.2018.11.024
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400030
DA 2024-07-18
ER

PT J
AU Tu, B
   Li, NY
   Fang, LY
   Fei, HY
   He, DB
AF Tu, Bing
   Li, Nanying
   Fang, Leyuan
   Fei, Hongyan
   He, Danbing
TI Classification of hyperspectral images via weighted spatial correlation
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hyperspectral image; Superpixel; Joint sparse representation;
   Correlation coefficient
ID REMOTE-SENSING DATA; SPARSE REPRESENTATION; NEAREST-NEIGHBOR; PROFILES;
   MOMENTS
AB Superpixel segmentation has been widely applied in hyperspectral image (HSI) classification. In this letter, a weighted spatial correlation representation (WSCR) method for HSI classification is proposed where an effective metric spatial correlation representation (SCR) that measures the correlation coefficient (CC) among different pixels in the superpixels is described, which fully utilizes the spatial information and structural features of superpixels. In addition, considering that the contribution of each SCR is different, the Gaussian weighted is considered. The proposed method includes the following steps: First, a super pixels image is obtained from HSI based on the entropy rate superpixel (ERS) algorithm. Second, the WSCRs for the training and test samples are calculated. Then, a joint sparse representation (JSR) classification is used to obtain the representation residuals of different pixels. Finally, the class label of each pixel is determined by the defined decision function that combines the WSCR and JSR. Experimental results obtained on two real HSI datasets demonstrate the superiority of the proposed methods compared to other widely used methods in terms of classification accuracy. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Tu, Bing; Li, Nanying; Fei, Hongyan; He, Danbing] Hunan Inst Sci & Technol, Sch Informat Sci & Technol, Yueyang, Peoples R China.
   [Fang, Leyuan] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
C3 Hunan Institute of Science & Technology; Hunan University
RP Fang, LY (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
EM fangleyuan@gmail.com
RI Fang, Leyuan/G-1468-2011
FU National Natural Science Foundation of China [51704115]; Key Laboratory
   Open Fund Project of Hunan Province University [17K040]; Science and
   Technology Program of Hunan Province [2016TP1021]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 51704115, by the Key Laboratory Open Fund Project of
   Hunan Province University under Grant 17K040, by the Science and
   Technology Program of Hunan Province under Grant 2016TP1021.
CR Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bioucas-Dias JM, 2013, IEEE GEOSC REM SEN M, V1, P6, DOI 10.1109/MGRS.2013.2244672
   Camps-Valls G, 2014, IEEE SIGNAL PROC MAG, V31, P45, DOI 10.1109/MSP.2013.2279179
   Chein-I Chang, 1999, IEEE 1999 International Geoscience and Remote Sensing Symposium. IGARSS'99 (Cat. No.99CH36293), P509, DOI 10.1109/IGARSS.1999.773549
   Chen Y, 2011, IEEE T GEOSCI REMOTE, V49, P3973, DOI 10.1109/TGRS.2011.2129595
   Chi J, 2014, IEEE J-STARS, V7, P2531, DOI 10.1109/JSTARS.2014.2319585
   Dalponte M, 2013, IEEE T GEOSCI REMOTE, V51, P2632, DOI 10.1109/TGRS.2012.2216272
   Fang LY, 2018, IEEE T GEOSCI REMOTE, V56, P1803, DOI 10.1109/TGRS.2017.2768479
   Fang LY, 2018, NEUROCOMPUTING, V273, P171, DOI 10.1016/j.neucom.2017.08.019
   Fang LY, 2017, IEEE T INSTRUM MEAS, V66, P1646, DOI 10.1109/TIM.2017.2664480
   Hou HR, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2017.2783351
   Kang XD, 2017, IEEE T GEOSCI REMOTE, V55, P7140, DOI 10.1109/TGRS.2017.2743102
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Lee MA, 2014, IEEE J-STARS, V7, P2562, DOI 10.1109/JSTARS.2014.2330521
   Li JJ, 2016, INT GEOSCI REMOTE SE, P3318, DOI 10.1109/IGARSS.2016.7729858
   Li ST, 2016, IEEE T GEOSCI REMOTE, V54, P7416, DOI 10.1109/TGRS.2016.2603190
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Ratle F, 2010, IEEE T GEOSCI REMOTE, V48, P2271, DOI 10.1109/TGRS.2009.2037898
   Schowengerdt R., 1997, REMOTE SENS
   Tu B, 2018, IEEE J-STARS, V11, P4063, DOI 10.1109/JSTARS.2018.2869376
   Tu B, 2018, IEEE J-STARS, V11, P4113, DOI 10.1109/JSTARS.2018.2866901
   Tu B, 2019, IEEE T GEOSCI REMOTE, V57, P1573, DOI 10.1109/TGRS.2018.2867444
   Tu B, 2018, IEEE GEOSCI REMOTE S, V15, P1417, DOI 10.1109/LGRS.2018.2842792
   Tu B, 2018, SENS IMAGING, V19, DOI 10.1007/s11220-018-0196-9
   Tu B, 2018, IEEE GEOSCI REMOTE S, V15, P340, DOI 10.1109/LGRS.2017.2787338
   Wang D, 2015, IEEE SIGNAL PROC LET, V22, P1776, DOI 10.1109/LSP.2015.2433917
   Xiao B, 2017, INFORM SCIENCES, V382, P135, DOI 10.1016/j.ins.2016.12.011
   Xiao B, 2015, PATTERN RECOGN, V48, P2772, DOI 10.1016/j.patcog.2015.04.007
   Yang JM, 2010, IEEE T GEOSCI REMOTE, V48, P1279, DOI 10.1109/TGRS.2009.2031812
   Zhang B, 2012, ENVIRON EARTH SCI, V65, P649, DOI 10.1007/s12665-011-1112-y
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang SZ, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9020139
   Zhang YX, 2015, IEEE T GEOSCI REMOTE, V53, P1346, DOI 10.1109/TGRS.2014.2337883
   Zhong YF, 2012, IEEE T GEOSCI REMOTE, V50, P894, DOI 10.1109/TGRS.2011.2162589
NR 36
TC 6
Z9 7
U1 4
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 160
EP 166
DI 10.1016/j.jvcir.2018.09.010
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500015
DA 2024-07-18
ER

PT J
AU Amiri, SH
   Jamzad, M
AF Amiri, S. Hamid
   Jamzad, Mansour
TI Leveraging multi-modal fusion for graph-based image annotation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image annotation; Tag; Manifold; Multi-modal representation; Graph-based
   learning; Supergraph
AB Considering each of the visual features as one modality in image annotation task, efficient fusion of different modalities is essential in graph-based learning. Traditional graph-based methods consider one node for each image and combine its visual features into a single descriptor before constructing the graph. In this paper, we propose an approach that constructs a subgraph for each modality in such a way that edges of subgraph are determined using a search-based approach that handles class-imbalance challenge in the annotation datasets. Multiple subgraphs are then connected to each other to have a supergraph. This follows by introducing a learning framework to infer the tags of unannotated images on the supergraph. The proposed approach takes advantages of graph-based semi-supervised learning and multi-modal representation simultaneously. We evaluate the performance of the proposed approach on different datasets. The results reveal that the proposed approach improves the accuracy of annotation systems. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Amiri, S. Hamid] Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
   [Jamzad, Mansour] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Shahid Rajaee Teacher Training University (SRTTU); Sharif University of
   Technology
RP Amiri, SH (corresponding author), Shahid Rajaee Teacher Training Univ, Dept Comp Engn, Tehran, Iran.
EM s.hamidamiri@sru.ac.ir; jamzad@sharif.edu
CR Amiri SH, 2015, PATTERN RECOGN, V48, P2241, DOI 10.1016/j.patcog.2015.01.015
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Ballan L., 2014, P ACM INT C MULTIMED
   Belkin M., 2002, NIPS
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chapelle O., 2006, SEMISUPERVISED LEARN, P193
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chen A., 2013, ICML, P1274
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049670
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Grubinger M., 2006, Language Resources and Evaluation, P13
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Lu Z., 2012, P 20 ACM INT C MULT, P499, DOI DOI 10.1145/2393347.2393418
   Lu ZW, 2011, IEEE T IMAGE PROCESS, V20, P1739, DOI 10.1109/TIP.2010.2103082
   Makadia A, 2010, INT J COMPUT VISION, V90, P88, DOI 10.1007/s11263-010-0338-6
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Tsoumakas G, 2007, LECT NOTES ARTIF INT, V4701, P406
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Wang C., 2011, Manifold Learning: Theory and Applications, P95, DOI [10.1201/b11431-6, DOI 10.1201/B11431-6]
   Wang Fei, 2006, P 23 INT C MACH LEAR, P985
   Wang H, 2011, PROC CVPR IEEE, P793, DOI 10.1109/CVPR.2011.5995379
   Wang H, 2009, IEEE I CONF COMP VIS, P2029, DOI 10.1109/ICCV.2009.5459447
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 40
TC 4
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 816
EP 828
DI 10.1016/j.jvcir.2018.08.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100072
DA 2024-07-18
ER

PT J
AU Gao, Y
   Su, YJ
   Li, QM
   Li, J
AF Gao, Yin
   Su, Yijing
   Li, Qiming
   Li, Jun
TI Single fog image restoration with multi-focus image fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Histogram analysis; Adaptive boundary constraint;
   Multi-focus image fusion
AB The images and videos captured in bad weather usually have low quality caused by reduced contrast and faded color. However, traditional techniques are not sufficient to solve the problems of halo artifacts and brightness distortion. In this paper, a multi-focus fusion method for single fog image restoration is proposed. Firstly, we estimate the global atmospheric light only in the sky regions to minimize interference from other regions. Secondly, we introduce a novel fast local Laplacian filtering with adaptive boundary constraint to optimize the transmission properly so as to reduce the halo artifacts. Finally, we remove the haze and produce a more natural effect on visual recovery by using a new multi-focus image fusion method. Experimental results show that the proposed method outperforms state-of-the-art haze removal methods in terms of efficiency and dehazing visual effect.
C1 [Gao, Yin; Su, Yijing; Li, Qiming; Li, Jun] Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Quanzhou, Peoples R China.
C3 Chinese Academy of Sciences
RP Li, J (corresponding author), Quanzhou Light Ind Inst, Training Bldg 102, Jinjiang City, Fujian, Peoples R China.
EM yngaoyin@163.com; suyj@fjirsm.ac.cn; qimingli@fjirsm.ac.cn;
   junli@fjirsm.ac.cn
RI gao, Yin/D-4589-2019; Gao, Yin/AAG-4081-2019; Skibniewski, Miroslaw
   J./P-5310-2018
OI Gao, Yin/0000-0003-3902-0087; 
FU National Key Research and Development Program of China [2016YFC11000502]
FX This work was supported by the National Key Research and Development
   Program of China Grant (No. 2016YFC11000502).
CR Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti CO, 2010, IEEE IMAGE PROC, P3541, DOI 10.1109/ICIP.2010.5651263
   Ancuti C, 2016, IEEE IMAGE PROC, P2256, DOI 10.1109/ICIP.2016.7532760
   [Anonymous], 2014, IEEE International Conference on Computational Photography (ICCP)
   [Anonymous], INT J REMOTE SENS
   Aubry M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2591009
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bonde S., 2017, INT J OCEAN OCEAN, V11, P01
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Fan Guo, 2013, International Journal of Digital Content Technology and its Applications, V7, P19, DOI 10.4156/jdcta.vol7.issue1.3
   Fang FM, 2014, SIAM J IMAGING SCI, V7, P969, DOI 10.1137/130919696
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P789, DOI 10.1016/j.compeleceng.2011.04.016
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Liu Y, 2017, IEEE ACCESS, V5, P8890, DOI 10.1109/ACCESS.2017.2710305
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700
   Tan R.T., 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wei Wang, 2015, Mathematical Problems in Engineering, V2015, DOI 10.1155/2015/131082
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 36
TC 19
Z9 22
U1 0
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 586
EP 595
DI 10.1016/j.jvcir.2018.07.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100051
DA 2024-07-18
ER

PT J
AU Tanaka, T
   Kawai, N
   Nakashima, Y
   Sato, T
   Yokoya, N
AF Tanaka, Takahiro
   Kawai, Norihiko
   Nakashima, Yuta
   Sato, Tomokazu
   Yokoya, Naokazu
TI Iterative applications of image completion with CNN-based failure
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image completion; Image inpainting; Convolutional neural network;
   Failure detection
AB Image completion is a technique to fill missing regions in a damaged or redacted image. A patch-based approach is one of major approaches, which solves an optimization problem that involves pixel values in missing regions and similar image patch search. One major problem of this approach is that it sometimes duplicates implausible texture in the image or overly smooths down a missing region when the algorithm cannot find better patches. As a practical remedy, the user may provide an interaction to identify such regions and re-apply image completion iteratively until she/he gets a desirable result. In this work, inspired by this idea, we propose a framework of human-in-the-loop style image completion with automatic failure detection using a deep neural network instead of human interaction. Our neural network takes small patches extracted from multiple feature maps obtained from the completion process as input for the automated interaction process, which is iterated several times. We experimentally show that our neural network outperforms a conventional linear support vector machine. Our subjective evaluation demonstrates that our method drastically improves the visual quality of resulting images compared to non-iterative application.
C1 [Tanaka, Takahiro; Kawai, Norihiko; Nakashima, Yuta; Sato, Tomokazu; Yokoya, Naokazu] Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara, Japan.
C3 Nara Institute of Science & Technology
RP Kawai, N (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara, Japan.
EM norihi-k@is.naist.jp
RI Nakashima, Yuta/Y-6218-2019
OI Nakashima, Yuta/0000-0001-8000-3567
FU Japan Society for the Promotion of Science (JSPS) [15K16039, 16H06302,
   18H03273, 18K11375]; Grants-in-Aid for Scientific Research [18H03273,
   15K16039, 18K11375] Funding Source: KAKEN
FX This work was partially supported by Grants-in-Aid for Scientific
   Research Nos. 15K16039, 16H06302, 18H03273, and 18K11375 from the Japan
   Society for the Promotion of Science (JSPS).
CR [Anonymous], ACM T GRAPH
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ATTR SHAR 2 0 GEN CC
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dang TT, 2013, IEEE IMAGE PROC, P398, DOI 10.1109/ICIP.2013.6738082
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Herzog R, 2012, COMPUT GRAPH FORUM, V31, P545, DOI 10.1111/j.1467-8659.2012.03055.x
   Huang JB, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601205
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kawai N, 2012, INT C PATT RECOG, P2744
   Kawai N, 2009, LECT NOTES COMPUT SC, V5414, P271, DOI 10.1007/978-3-540-92957-4_24
   Kopf J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366150
   Mansfield A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.121
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Vedantam R, 2015, IEEE I CONF COMP VIS, P2542, DOI 10.1109/ICCV.2015.292
   Voronin V., 2015, WSCG 2015 Conference on Computer Graphics, Visualization and Computer Vision, P167
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
NR 33
TC 3
Z9 3
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 56
EP 66
DI 10.1016/j.jvcir.2018.05.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100006
DA 2024-07-18
ER

PT J
AU Wu, H
   Li, YL
   Bi, XH
   Zhang, LN
   Bie, RF
   Wang, YZ
AF Wu, Hao
   Li, Yueli
   Bi, Xiaohan
   Zhang, Linna
   Bie, Rongfang
   Wang, Yingzhuo
TI Joint entropy based learning model for image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE joint entropy; learning instance; image retrieval; watershed
   segmentation; precise-recall curve; AP value; AUC value
ID SUPPORT VECTOR MACHINE; ALGORITHM; FEATURES; KERNELS
AB As one classic technique of computer vision, image retrieval could retrieve the target images from hundreds of thousands of images effectively. Furthermore, with the rapid development of deep learning, the quality of retrieval is increased obviously. However, under normal conditions, the high-quality retrieval is supported by a large number of learning instances. The large number of learning instances not only need much human source in the process of selection, but also need much computing source in the process of computation. More importantly, for some special categories, it's difficult to obtain a large number of learning instances.
   Aiming at the problem above, we proposed one joint entropy based learning model which could reduce the number of learning instances through optimizing the distribution of learning instances. Firstly, the learning instances are pre-selected using improved watershed segmentation method. Then, joint entropy model is used for reducing the possibility of double, useless even mistaken instances existence. After that, a database using a large number of images is built up. Sufficient experiments based on the database show the model's superiority that our model not only could reduce the number of learning instances but also could keep the accuracy of retrieval.
C1 [Wu, Hao; Bie, Rongfang] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing, Peoples R China.
   [Li, Yueli] Hebei Agr Univ, Coll Informat Sci & Technol, Baoding, Peoples R China.
   [Bi, Xiaohan] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Zhang, Linna] Guizhou Univ, Coll Mech Engn, Guiyang, Guizhou, Peoples R China.
   [Wang, Yingzhuo] Wendeng Technician Coll WeiHai, Weihai, Shandong, Peoples R China.
C3 Beijing Normal University; Hebei Agricultural University; Beijing
   Jiaotong University; Guizhou University
RP Bie, RF (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing, Peoples R China.
EM rongfangbie@163.com
RI Zhang, Lin/HZH-4842-2023; ZHANG, LIN/GYD-9123-2022
FU Fundamental Research Funds for the Central Universities [2016NT14];
   National Natural Science Foundation of China [61601033, 61571049,
   61401029]; Beijing Advanced Innovation Center for Future Education
   [BJAICFE2016IR-004]
FX This research is sponsored by Fundamental Research Funds for the Central
   Universities (No. 2016NT14), National Natural Science Foundation of
   China (No. 61601033, No. 61571049, No. 61401029) and Beijing Advanced
   Innovation Center for Future Education (BJAICFE2016IR-004). We
   particularly appreciate XiaoYu and Junqi Guo for their contributions of
   data collection and optimization.
CR Alain G, 2014, J MACH LEARN RES, V15, P3563
   [Anonymous], STAT
   [Anonymous], 2001, Bayesian theory, DOI 10.1088/0957-0233/12/2/702
   [Anonymous], 2006, Advances in Neural Information Processing Systems 19
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2011, IMAGE CLASSIFICATION
   [Anonymous], P ACM INT C IM VID R
   [Anonymous], COMP VIS PATT REC 20
   Arbelaez Pablo., 2007, The Berkeley segmentation dataset and benchmark
   Berens J, 2000, IEE P-VIS IMAGE SIGN, V147, P349, DOI 10.1049/ip-vis:20000630
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Getoor, 2011, P 28 INT C MACH LEAR, P833
   Griffin G., 2007, CALTECH 256 OBJECT C
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   James H., 2007, ACM T GRAPHICS, V26
   Keerthi SS, 2003, NEURAL COMPUT, V15, P1667, DOI 10.1162/089976603321891855
   Keogh E., 2011, Curse of dimensionality, Encyclopedia of Machine Learning, P257
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu S., 2007, J CHEM PHYS, V126, P191
   Liu SB, 2007, J CHEM PHYS, V126, DOI 10.1063/1.2741244
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacArthur SD, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P68, DOI 10.1109/IVL.2000.853842
   Min JH, 2005, EXPERT SYST APPL, V28, P603, DOI 10.1016/j.eswa.2004.12.008
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Ngiam J., 2011, P 28 INT C MACHINE L, P1105, DOI 10.5555/3104482.3104621
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sahami M., 2006, WWW 06, DOI DOI 10.1145/1135777.1135834
   Salakhutdinov R., 2009, AISTATS, V1
   Shafarenko L, 1997, IEEE T IMAGE PROCESS, V6, P1530, DOI 10.1109/83.641413
   Siddiquie B, 2010, PROC CVPR IEEE, P2979, DOI 10.1109/CVPR.2010.5540044
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tang J, 2009, PHYS MED BIOL, V54, P7063, DOI 10.1088/0031-9155/54/23/002
   van de Sande KEA, 2008, PROC CVPR IEEE, P2463
   Van Ginneken B, 1999, INT J COMPUT VISION, V31, P169, DOI 10.1023/A:1008018015948
   VAPNIK V, 1992, ADV NEUR IN, V4, P831
   Venu N, 2013, INT CONF ADV COMPU, P280, DOI 10.1109/ICoAC.2013.6921964
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang G, 2010, PROC CVPR IEEE, P3525, DOI 10.1109/CVPR.2010.5539955
   Wu H, 2016, J VIS COMMUN IMAGE R, V38, P573, DOI 10.1016/j.jvcir.2016.04.008
   Wu H, 2016, J VIS COMMUN IMAGE R, V38, P100, DOI 10.1016/j.jvcir.2016.02.011
   Wu H, 2015, IET COMPUT VIS, V9, P419, DOI 10.1049/iet-cvi.2014.0094
   Wu H, 2015, NEUROCOMPUTING, V159, P157, DOI 10.1016/j.neucom.2014.12.088
   Wu H, 2015, VISUAL COMPUT, V31, P367, DOI 10.1007/s00371-014-0931-8
   Wu Hao, MACH VIS APPL
   Wu QC, 2016, INT J REMOTE SENS, V37, P6012, DOI 10.1080/01431161.2016.1253897
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang TZ, 2013, IEEE I CONF COMP VIS, P281, DOI 10.1109/ICCV.2013.42
   Zhang YM, 2009, PROC CVPR IEEE, P1762, DOI 10.1109/CVPRW.2009.5206791
   Zheng YT, 2009, VISUAL COMPUT, V25, P13, DOI 10.1007/s00371-008-0294-0
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 61
TC 10
Z9 11
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 415
EP 423
DI 10.1016/j.jvcir.2018.06.021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100034
DA 2024-07-18
ER

PT J
AU Le Moan, S
   Farup, I
   Blahová, J
AF Le Moan, Steven
   Farup, Ivar
   Blahova, Jana
TI Towards exploiting change blindness for image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Perception; Visual awareness; Visual attention; Change blindness;
   Salience; Image quality
ID QUALITY ASSESSMENT; VISUAL-ATTENTION; SALIENCY; MODEL
AB Change blindness is a type of visual masking which affects our ability to notice changes introduced in visual stimuli (e.g. change in the colour or position of an object). In this paper, we propose to use it as a means to identify image attributes that are less important than others. We propose a model of visual awareness based on low-level saliency detection and image inpainting, which identifies textured regions within images that are the most prone to change blindness. Results from a user study demonstrate that our model can generate alternative versions of natural scenes which, while noticeably different, have the same visual quality as the original. We show an example of practical application in image compression.
C1 [Le Moan, Steven; Farup, Ivar; Blahova, Jana] NTNU Norwegian Univ Sci & Technol, Fac Comp Sci & Media Technol, Gjovik, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Le Moan, S (corresponding author), NTNU Norwegian Univ Sci & Technol, Fac Comp Sci & Media Technol, Gjovik, Norway.
EM steven.lemoan@gmail.com
RI Farup, Ivar/HOC-8111-2023
OI Farup, Ivar/0000-0003-3473-1138
FU Research Council of Norway (SHP project) [221073]
FX This research was funded by the Research Council of Norway (SHP project
   221073).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alam MM, 2014, J VISION, V14, DOI 10.1167/14.8.22
   [Anonymous], 1991, COMPUTATIONAL MODELS
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 1993, BT50012 IR
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1007/978-3-642-14267-3_2
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   Brady TF, 2011, J VISION, V11, DOI 10.1167/11.5.4
   Brown L, 2005, J STAT PLAN INFER, V130, P359, DOI 10.1016/j.jspi.2003.09.039
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Cakebread Caroline, 2018, PEOPLE WILL TAKE 1 2
   Cater K., 2003, P 1 INT C COMPUTER G, P39, DOI DOI 10.1145/604471.604483
   Cohen MA, 2016, TRENDS COGN SCI, V20, P324, DOI 10.1016/j.tics.2016.03.006
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Freeman J, 2011, NAT NEUROSCI, V14, P1195, DOI 10.1038/nn.2889
   Gangeh M. J., ARXIV150205928
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Healey CG, 2012, IEEE T VIS COMPUT GR, V18, P1170, DOI 10.1109/TVCG.2011.127
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jensen MS, 2011, WIRES COGN SCI, V2, P529, DOI 10.1002/wcs.130
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kopf J, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366150
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lamme VAF, 2003, TRENDS COGN SCI, V7, P12, DOI 10.1016/S1364-6613(02)00013-X
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Le Moan S., 2017, INT C IM PROC
   Le Moan S, 2015, 11 INT C SIGN IM TEC, P1
   Le Moan S, 2016, IEEE IMAGE PROC, P91, DOI 10.1109/ICIP.2016.7532325
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Lissner I, 2012, IEEE T IMAGE PROCESS, V21, P1153, DOI 10.1109/TIP.2011.2163522
   Ma LQ, 2013, IEEE T VIS COMPUT GR, V19, P1808, DOI 10.1109/TVCG.2013.99
   O'Regan JK, 1999, NATURE, V398, P34, DOI 10.1038/17953
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Preiss J, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2302684
   Racape F, 2013, SIGNAL PROCESS-IMAGE, V28, P993, DOI 10.1016/j.image.2013.05.004
   Rane SD, 2003, IEEE T IMAGE PROCESS, V12, P296, DOI 10.1109/TIP.2002.804264
   Rensink RA, 1997, PSYCHOL SCI, V8, P368, DOI 10.1111/j.1467-9280.1997.tb00427.x
   Simons DJ, 2005, CURR DIR PSYCHOL SCI, V14, P44, DOI 10.1111/j.0963-7214.2005.00332.x
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   Stirk JA, 2007, J VISION, V7, DOI 10.1167/7.10.3
   Tartavel G, 2015, J MATH IMAGING VIS, V52, P124, DOI 10.1007/s10851-014-0547-7
   Varakin DA, 2007, PERCEPTION, V36, P737, DOI 10.1068/p5572
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P1651, DOI 10.1109/TIP.2010.2044960
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
NR 55
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 31
EP 38
DI 10.1016/j.jvcir.2018.04.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA GJ3EC
UT WOS:000435167800004
DA 2024-07-18
ER

PT J
AU Tariq, J
   Kwong, S
AF Tariq, Junaid
   Kwong, Sam
TI Adaptive stopping strategies for fast intra mode decision in HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Early mode decision; HEVC; Intra mode; RMD; RDOQ; Sum of absolute
   difference; Video coding; Video coding
ID DISTORTION COST ESTIMATION; HIGHLY PARALLEL FRAMEWORK; MOTION
   ESTIMATION; PREDICTION; ALGORITHM
AB Fast intra mode decision strategies are proposed to overcome the brute force mode decision for the coding unit (CU) in High Efficiency Video Coding (HEVC). The proposed work improves the rough-mode-decision (RMD) by initializing the candidate intra mode list using the fusion of the Hadamard-cost and the statistical-inference formed using spatial/ temporal correlations. Then an early termination is predicted using optimal stopping theory that addresses early decision for a generic class of decision problems. Subsequently, a novel RD-cost prediction model is developed for early termination that is based on the RD-cost variation in the neighboring CUs with-respect-to their co-located CUs. Experimental results demonstrate that the RMD module of HEVC and the state-of-the-art fast intra mode prediction published method are outperformed by saving up to 0.61% and 0.91% Bjontegaard delta bit rate (BDBR) on average, respectively.
C1 [Tariq, Junaid] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
   [Kwong, Sam] HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
C3 City University of Hong Kong; NITEC University
RP Kwong, S (corresponding author), HITEC Univ, Dept Comp Sci & Engn, Taxila, Pakistan.
EM junaid.tariq@hitecuni.edu.pk; cssamk@cityu.edu.hk
RI Kwong, Sam/C-9319-2012
OI Kwong, Sam/0000-0001-7484-7261
FU RGC General Research Fund (GRF) [9042489 (CityU 11206317), 9042322
   (CityU 11200116)]; Chinese NSF [61672443]
FX This work is partially supported by RGC General Research Fund (GRF)
   9042489 (CityU 11206317), 9042322 (CityU 11200116) and Chinese NSF
   61672443.
CR [Anonymous], 2016, P 2016 IEEE INT S BR
   [Anonymous], ELECTRONIC JOURNAL O, DOI DOI 10.1109/VCIP.2011.6115979
   [Anonymous], 2012, MATH PROBL ENG, DOI DOI 10.1371/J0URNAL.P0NE.0029654
   Bjontegaard G., 2001, P ITU T SB16 Q 6 VCE
   Bossen F., 2011, JCTVCG1200 ITUTVCEG
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Ferguson T.S., 1991, CONTEMP MATH-SINGAP, V125, P37
   Hao Zhang, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P568, DOI 10.1007/978-3-642-34778-8_53
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Liao KY, 2010, IEEE T CIRC SYST VID, V20, P38, DOI 10.1109/TCSVT.2009.2026946
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sheng Z., 2014, MULTIMEDIA MODELING, P6
   Tan H.L., JCTVCH0166 ITUT VCGE
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1776, DOI 10.1109/SMC.2015.311
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Tariq J, 2015, IEEE SYS MAN CYBERN, P1782, DOI 10.1109/SMC.2015.312
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Vlachos DS, 2013, J PHYS CONF SER, V410, DOI 10.1088/1742-6596/410/1/012092
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang T., 2017, IEEE T CIRC SYST VID
   Zhang Y, 2015, IEEE T IND INFORM, V11, P1492, DOI 10.1109/TII.2015.2491646
   Zhao TS, 2012, IEEE T IMAGE PROCESS, V21, P2607, DOI 10.1109/TIP.2012.2186148
   Zhu J, 2013, IEEE IMAGE PROC, P1977, DOI 10.1109/ICIP.2013.6738407
NR 36
TC 20
Z9 21
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 1
EP 13
DI 10.1016/j.jvcir.2017.12.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500001
DA 2024-07-18
ER

PT J
AU Rouhi, AH
   Thom, JA
AF Rouhi, Amir H.
   Thom, James A.
TI Encoder settings impact on intra-prediction-based descriptors for video
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Encoder impact; Profile impact; Feature sensitivity; Video
   copy detection; Intra-prediction modes; I-frames; Correlogram; Visual
   features; Content-preserving transformations
ID PARALLEL FRAMEWORK
AB Intra-prediction modes (IPMs) of H.264/AVC, as visual feature components, are easily extracted from the compressed domain. However, in spite of their efficiency and effectiveness, they can be sensitive to encoder settings such as encoder-type and encoding-profile. In content-based video retrieval using different encoders between a video and its copy can affect performance. Similarly, applying different encoding-profiles can also have a negative impact. Experiments with different IPM-based descriptors, on a subset of the TRECVID/CCD 2011 collection with content-preserving visual distortions, compare the performance of four H.264/AVC encoding profiles (High10, High, Baseline and Main) and also investigate the impact of three encoders (FFmpeg, MediaCoder and JM). The research shows that ordinal pattern distribution of unified IPMs can improve their tolerance to changes in encoder settings. Furthermore, it is shown that a Correlogram rather than a Histogram of the IPMs is more robust with respect to the impact of encoding-profiles and encoder-types.
C1 [Rouhi, Amir H.; Thom, James A.] RMIT Univ, Sch Sci, Melbourne, Vic, Australia.
C3 Royal Melbourne Institute of Technology (RMIT)
RP Rouhi, AH (corresponding author), RMIT Univ, Sch Sci, Melbourne, Vic, Australia.
EM amir.rouhi@rmit.edu.au; james.thom@rmit.edu.au
CR Ahmad I., 2005, Finnish Signal Processing Symposium, P35
   [Anonymous], 2015 INT C DIG IM CO
   [Anonymous], 2017, MAR POLICY
   [Anonymous], P 29 INT C IM VIS CO
   [Anonymous], OVERVIEW GOALS TASKS
   Awad G, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2629531
   Bankoski J, 2011, IEEE INT CON MULTI
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   DeGroot M. H., 2012, PROBABILITY STAT PEA
   Guldogan E, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P9
   Gupta V., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P918, DOI 10.1109/ISSPA.2012.6310685
   Gupta V, 2011, TRECVID WORKSH NIST
   Hampapur A., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, P194, DOI 10.1117/12.451091
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P2469, DOI 10.1007/s11042-013-1561-2
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Richardson Iain E, 2011, The H. 264 advanced video compression standard
   Schaefer G, 2008, INT J IMAG SYST TECH, V18, P101, DOI 10.1002/ima.20152
   Sheskin J.D., 2004, Handbook of Parametric and Nonparametric Statistical Procedures, VThird
   Tomar S., 2006, LINUX J, V2006, P10
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yuan J., 2004, PROC ACM MULTIMEDIA, P61, DOI DOI 10.1145/1026711.1026722
   Zargari F, 2010, IEEE T CONSUM ELECTR, V56, P728, DOI 10.1109/TCE.2010.5505994
NR 23
TC 2
Z9 2
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 263
EP 269
DI 10.1016/j.jvcir.2017.12.009
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700026
DA 2024-07-18
ER

PT J
AU Deshmukh, M
   Nain, N
   Ahmed, M
AF Deshmukh, Maroti
   Nain, Neeta
   Ahmed, Mushtaq
TI A novel approach for sharing multiple color images by employing Chinese
   Remainder Theorem
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi secret sharing scheme; Boolean XOR; Chinese Remainder Theorem;
   Greatest common divisor; Multiplicative inverse
ID SECRET; SCHEME
AB Conventional approaches for encryption are unsuitable for simultaneously achieving reliability and confidentiality. Threshold-based secret sharing scheme deals with the problem of sharing a secret information into a group of n users and secret can be recovered only when a sufficient users come together, we can reconstruct a secret information from t, where t < n. There is a requirement to evolve a secure secret sharing scheme so that the reconstruction is possible only when all shares are available. In this paper, we propose a secure (n,n)-Multi Secret Sharing (MSS) scheme using Chinese Remainder Theorem (CRT). The proposed scheme shares secret information among n users and for recovery all n users are needed, if one of the user is absent then we could not reconstruct the secret information. The proposed scheme does not reveals the partial secret information, as the randomness in shares is more. The proposed scheme outperforms the existing techniques in terms of randomness and security.
C1 [Deshmukh, Maroti] Natl Inst Technol, Uttarakhand, India.
   [Deshmukh, Maroti; Nain, Neeta; Ahmed, Mushtaq] Malaviya Natl Inst Technol, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Uttarakhand; National Institute of Technology (NIT System);
   Malaviya National Institute of Technology Jaipur
RP Deshmukh, M (corresponding author), Natl Inst Technol, Uttarakhand, India.
EM marotideshmukh@nituk.ac.in
RI Deshmukh, Dr. Maroti/AAE-2889-2022; Ahmed, Mushtaq/GSN-9818-2022
OI Deshmukh, Maroti/0000-0002-1125-5987; AHMED,
   MUSHTAQ/0000-0002-7576-2531; Nain, Neeta/0000-0002-0550-0376
CR [Anonymous], 1994, WORKSH THEOR APPL CR
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Binu V.P., 2016, WIRELESS PERS COMMUN, P1
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Blundo Carlo, 1994, ANN INT CRYPT C
   Chang CC, 2016, IET IMAGE PROCESS, V10, P590, DOI 10.1049/iet-ipr.2015.0568
   Chanu Oinam Bidyapati, 2015, P 2015 INT C ADV RES
   Chao Her-Chang, 2017, DISPLAYS
   Chen CC, 2017, J INF SECUR APPL, V33, P45, DOI 10.1016/j.jisa.2017.01.006
   Chen CC, 2014, J SYST SOFTWARE, V92, P107, DOI 10.1016/j.jss.2014.01.001
   Chen GL, 2017, MATH PROBL ENG, V2017, P1, DOI [10.1155/2017/9067520, 10.1155/2017/2587069]
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Forouzan B.A., 2011, Cryptography and Network Security (Sie)
   Guo C, 2015, MULTIMED TOOLS APPL, V75, P1
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Harn L, 2016, INFORM SCIENCES, V367, P209, DOI 10.1016/j.ins.2016.06.006
   Maroti Deshmukh, 2016, 2016 IEEE 30 INT C A
   Maroti Deshmukh, 2016, INT C COMP VIS IM PR, P149
   Maroti Deshmukh, 2016, ENHANCED MODULO BASE, P212
   Maroti Deshmukh, 2016, EFFICIENT SECURE MUL
   Mignotte Maurice, 1982, WORKSH CRYPT
   Mohit Rajput, 2016, ARXIV161109261
   Nag Amitava, 2017, P 1 INT C INT COMP C
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shivani Shivendra, 2016, MULTIMEDIA TOOLS APP
   Tuncer T, 2016, DISPLAYS, V41, P1, DOI 10.1016/j.displa.2015.10.005
   Xu, 2016, 2016 IEEE EUR S SEC
   Yang CN, 2016, J SYST SOFTWARE, V116, P22, DOI 10.1016/j.jss.2015.01.031
NR 31
TC 29
Z9 29
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 291
EP 302
DI 10.1016/j.jvcir.2017.09.013
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800024
DA 2024-07-18
ER

PT J
AU Chen, J
   Wang, BH
   Zeng, HQ
   Cai, CH
   Ma, KK
AF Chen, Jing
   Wang, Bohan
   Zeng, Huanqiang
   Cai, Canhui
   Ma, Kai-Kuang
TI Sum-of-gradient based fast intra coding in 3D-HEVC for depth map
   sequence (SOG-FDIC)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; MVD; Intra prediction; Low complexity
ID VIDEO
AB As the latest video coding standard for multi-view plus depth video, 3D-HEVC yields high coding efficiency but at the cost of heavy computational complexity. To reduce the computational complexity, a fast intra coding algorithm based on sum-of-gradient criterion for depth map coding in 3D-HEVC, named SOG-FDIC, is proposed in this paper. Based on the observation that DMM modes and smaller partitioning sizes are rarely used in flat region, sum of gradient is presented to determine whether the current block belongs to the flat region so as to skip unnecessary checking of DMMs and smaller partitioning sizes. Experimental results show that the proposed algorithm can save about 21.8% coding time while keeping almost the same coding efficiency and the reconstructed video quality of depth maps and synthesized views, compared with the original 3D-HEVC. Moreover, it has been verified that the proposed method outperforms the state-of-the-art methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Chen, Jing; Wang, Bohan; Zeng, Huanqiang; Cai, Canhui; Ma, Kai-Kuang] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
   [Chen, Jing; Wang, Bohan; Zeng, Huanqiang; Cai, Canhui] Xiamen Key Lab Mobile Multimedia Commun, Xiamen, Peoples R China.
   [Ma, Kai-Kuang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore, Singapore.
C3 Huaqiao University; Nanyang Technological University
RP Chen, J (corresponding author), Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
EM chenjing8005@gmail.com; wangbohann@163.com; zeng0043@hqu.edu.cn;
   chcai@hqu.edu.cn; ekkma@ntu.edu.sg
RI Zeng, Huanqiang/U-2017-2018; Ma, Kai-Kuang/KBA-9411-2024
FU National Natural Science Foundation of China [61372107, 61401167];
   Natural Science Foundation of Fujian Province [2017J05103, 2016J01308];
   Special Program for the State Key Laboratories of China
   [FZDP2015-B-001]; Research Foundation for Talented Scholars of Huaqiao
   University [16BS709]; Promotion Program for Young and Middle-aged
   Teacher in Science and Technology Research of Huaqiao University
   [ZQN-YX403]
FX This work is partially supported by National Natural Science Foundation
   of China (Grant Nos. 61372107 and 61401167), Natural Science Foundation
   of Fujian Province (Grant Nos. 2017J05103 and 2016J01308), Special
   Program for the State Key Laboratories of China (Grant No.
   FZDP2015-B-001), Research Foundation for Talented Scholars of Huaqiao
   University (Grant No. 16BS709), and Promotion Program for Young and
   Middle-aged Teacher in Science and Technology Research of Huaqiao
   University (Grant No. ZQN-YX403).
CR [Anonymous], 2014, DOCUMENT JCT3V G1100
   [Anonymous], 2001, P ITU T VID COD EXP
   [Anonymous], 11 M GEN CH FEB
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   da Silva TL, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P229, DOI 10.1109/VCIP.2014.7051546
   Fan YC, 2014, J DISP TECHNOL, V10, DOI 10.1109/JDT.2014.2331064
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Gu Zhongyi., 2014, Multimedia and Expo, 2014 IEEE International Conference on, P1
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Ohm JR, 2013, IEEE SIGNAL PROC MAG, V30, P152, DOI 10.1109/MSP.2012.2219672
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Roberts L. G., 1980, THESIS
   Sanchez G, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P137, DOI 10.1109/VCIP.2014.7051523
   Sanchez G, 2014, IEEE IMAGE PROC, P3209, DOI 10.1109/ICIP.2014.7025649
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang LH, 2015, MULTIMED TOOLS APPL, V74, P9529, DOI 10.1007/s11042-014-2133-9
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yo-Sung Ho, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P5
   Zeng HQ, 2014, IEEE T CIRC SYST VID, V24, P1566, DOI 10.1109/TCSVT.2014.2310143
   Zhang QW, 2014, ELECTRON LETT, V50, P994, DOI 10.1049/el.2014.0065
   Zhouye G., 2013, 5 M VIENN AT 27 JUL
NR 25
TC 18
Z9 20
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 329
EP 339
DI 10.1016/j.jvcir.2017.05.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700026
DA 2024-07-18
ER

PT J
AU Wei, CH
   Lai, SH
   Chiang, CK
AF Wei, Chen-Hao
   Lai, Shang-Hong
   Chiang, Chen-Kuo
TI Video synthesis from stereo videos with iterative depth refinement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE View synthesis; Depth refinement
ID PARALLEL FRAMEWORK
AB We propose a novel depth maps refinement algorithm and generate multi-view video sequences from two-view video sequences for modern autostereoscopic display. In order to generate realistic contents for virtual views, high-quality depth maps are very critical to the view synthesis results. Therefore, refining the depth maps is the main challenging problem in the task. We propose an iterative depth refinement algorithm, including error detection and error correction, to correct errors in depth map. Error detection aims at two types of error: across-view color-depth-inconsistency error and local color depth-inconsistency error. Then, error pixels are corrected based on sampling local candidates. A trilateral filter that considers intensity, spatial and temporal terms into the filter weighting is applied to enhance the spatial and temporal consistency across frames. So the virtual views can be better synthesized according to the refined depth maps. To combine both warped images, disparity-based view interpolation is introduced to alleviate the translucent artifacts. Finally, a directional filter is applied to reduce the aliasing around the object boundaries to generate multiple high-quality virtual views between the two views. We demonstrate the superior image quality of the synthesized virtual views by using the proposed algorithm over the state-of-the-art view synthesis methods through experiments on benchmarking image and video datasets. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Wei, Chen-Hao; Lai, Shang-Hong] Natl Tsing Hua Univ, Hsinchu, Taiwan.
   [Chiang, Chen-Kuo] Natl Chung Cheng Univ, Chiayi, Taiwan.
C3 National Tsing Hua University; National Chung Cheng University
RP Chiang, CK (corresponding author), 168,Sect 1,Univ Rd, Min Hsiung Township 621, Chia Yi County, Taiwan.
EM ss780217@gmail.com; lai@cs.nthu.edu.tw; ckchiang@cs.ccu.edu.tw
RI Lai, Shang-Hong/AAS-4002-2020
OI Lai, Shang-Hong/0000-0002-5092-993X; Chiang,
   Chen-Kuo/0000-0001-5276-1109
CR [Anonymous], 2008, OpenMP Application Program Interface
   [Anonymous], 2007, CVPR
   [Anonymous], 2009, ISOIECJTC1SC29WG11 M
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chan SH, 2011, IEEE T IMAGE PROCESS, V20, P3097, DOI 10.1109/TIP.2011.2158229
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Dolson J, 2010, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2010.5540086
   Jin CM, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 1, PROCEEDINGS, P919, DOI 10.1109/ICCIT.2008.212
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lin SJ, 2009, LECT NOTES COMPUT SC, V5879, P532
   Lu CH, 2004, LECT NOTES COMPUT SC, V3046, P243
   Matyunin S., 2011, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, P1
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Morse B, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P555, DOI 10.1109/3DIMPVT.2012.59
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Patwardhan K., 2005, P IEEE INT C IMAGE P, V2, P69
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Seongyun Cho, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P368, DOI 10.1007/978-3-642-37444-9_29
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68
NR 26
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2017
VL 47
BP 48
EP 61
DI 10.1016/j.jvcir.2017.04.008
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX8TD
UT WOS:000403522200005
DA 2024-07-18
ER

PT J
AU Hu, L
   Nooshabadi, S
AF Hu, Linjia
   Nooshabadi, Saeid
TI Massive parallelization of approximate nearest neighbor search on
   KD-tree for high-dimensional image descriptor matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RD-tree; Approximate nearest neighbor search; Parallel algorithm; GPU;
   CUDA; Image descriptor matching
AB To overcome the high computing cost associated with high-dimensional digital image descriptor matching, this paper presents a massively parallel approximate nearest neighbor search (ANNS) on K-dimensional tree (RD-tree) on the modern massively parallel architectures (MPA). The proposed algorithm is of comparable quality to traditional sequential counterpart on central processing unit (CPU). However, it achieves a high speedup factor of 121 when applied to high-dimensional real-world image descriptor datasets. The algorithm is also studied for factors that impact its performance to obtain the optimal runtime configurations for various datasets. The performance of the proposed parallel ANNS algorithm is also verified on typical 3D image matching scenarios. With the classical local image descriptor signature of histograms of orientations (SHOT), the parallel image descriptor matching can achieve speedup of up to 128. Our implementation will potentially benefit realtime image descriptor matching in high dimensions. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Hu, Linjia; Nooshabadi, Saeid] Michigan Technol Univ, Dept Comp Sci, Houghton, MI 49931 USA.
C3 Michigan Technological University
RP Nooshabadi, S (corresponding author), Michigan Technol Univ, Dept Comp Sci, Houghton, MI 49931 USA.
EM linjiah@mtu.edu; saeid@mtu.edu
CR ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Arya S., 1993, DCC '93. Data Compression Conference (Cat. No.93TH0536-3), P381, DOI 10.1109/DCC.1993.253111
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Bustos B, 2006, LECT NOTES COMPUT SC, V3994, P196
   Cayton L, 2012, INT PARALL DISTRIB P, P402, DOI 10.1109/IPDPS.2012.45
   Chan T. M., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P352, DOI 10.1145/262839.263001
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   FOLEY T., 2005, HWWS 05, P15
   Garcia Vincent, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563100
   Gaster BR, 2012, COMPUTER, V45, P42, DOI 10.1109/MC.2012.257
   Gieseke F., 2014, P 31 INT C MACHINE L, P172
   Hu LJ, 2015, I SYMP CONSUM ELECTR, P186, DOI 10.1109/ICCE.2015.7066373
   Hu LJ, 2015, IEEE INT SYMP CIRC S, P2752, DOI 10.1109/ISCAS.2015.7169256
   Indyk P., 2004, HDB DISCRETE COMPUTA
   Kim J, 2015, IEEE T PARALL DISTR, V26, P2258, DOI 10.1109/TPDS.2014.2347041
   Kitaaki Yasuo, 2008, SICE 2008 - 47th Annual Conference of the Society of Instrument and Control Engineers of Japan, P3055, DOI 10.1109/SICE.2008.4655188
   Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x
   Li S., 2012, Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics, P39
   Liao SW, 2001, PROC INT CONF DATA, P615, DOI 10.1109/ICDE.2001.914876
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   NVIDIA, 2015, CUDA TOOLK DOC V7 5
   Purcell T., 2003, SIGGRAPHEUROGRAPHICS, P41
   Qiu DY, 2009, LECT NOTES COMPUT SC, V5815, P194
   Rozen T, 2008, JOURNAL WSCG, V16, P161
   Sinha S. N., 2006, WORKSH EDG COMP US N, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Winder SAJ, 2007, PROC CVPR IEEE, P17
   Wittenbrink CM, 2011, IEEE MICRO, V31, P50, DOI 10.1109/MM.2011.24
   Yang Y., 2012, MAN IN THE MIDDLE AT
   Zhou K, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409079
NR 33
TC 9
Z9 10
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 106
EP 115
DI 10.1016/j.jvcir.2017.01.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600010
DA 2024-07-18
ER

PT J
AU Zhu, SH
   Jin, DL
   Liang, ZW
   Wang, Q
   Sun, YJ
   Xu, GZ
AF Zhu, Songhao
   Jin, Dongliang
   Liang, Zhiwei
   Wang, Qiang
   Sun, Yajie
   Xu, Guozheng
TI Integration of semantic and visual hashing for image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Semantic similarity; Visual structure; Hashing code
ID SEGMENTATION
AB With the rapid proliferation of large-scale web images, recent years have witnessed more and more images labeled with user-provided tags, which leads to considerable effort made on hashing based image retrieval in huge databases. Current research efforts focus mostly on learning semantic hashing functions which design compact binary codes to map semantically similar images into similar codes; however the visual similarity is not well explored for constructing semantic hashing functions. Here a novel approach is proposed to learn hashing functions that preserve semantic and visual similarity between images. Specifically, semantic hashing codes are first learned by leveraging the similarity between textual structure and visual structure; then, the maximum entropy principle is exploited to achieve compact binary codes; finally, the function decay principle is introduced to remove noisy visual attributes. Experimental results conducted on a widely-used image dataset demonstrate the superior performance of the proposed method over the examined state-of-the-art techniques. (C) 2016 Published by Elsevier Inc.
C1 [Zhu, Songhao; Jin, Dongliang; Liang, Zhiwei; Wang, Qiang; Xu, Guozheng] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Peoples R China.
   [Zhu, Songhao; Sun, Yajie] Nanjing Univ Informat Sci & Technol, Nanjing 210044, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Information Science & Technology
RP Jin, DL (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Peoples R China.
EM njuptzsl@yeah.net
FU Natural Science Foundation of China [61305095]; Natural Science Fund of
   Jiangsu Province [BK20141426]; Key Research Foundation of Jiangsu
   Province [BE2015701]; Jiangsu blue project outstanding young teachers
   [QL00514014]; Priority Academic Program Development of Jiangsu Higher
   Education Institutions; Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology
FX This work is supported by Natural Science Foundation of China under No.
   61305095, Natural Science Fund of Jiangsu Province under No. BK20141426,
   Key Research Foundation of Jiangsu Province under No. BE2015701, Jiangsu
   blue project outstanding young teachers under Grant No. QL00514014,
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions, Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology.
CR [Anonymous], 2012, NIPS
   [Anonymous], 2009, NIPS
   Bondugula S, 2015, IEEE WINT CONF APPL, P558, DOI 10.1109/WACV.2015.80
   Broder A., 1998, ACM S THEOR COMP, P63
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chua T., 2009, ACM C IM VID RETR, P46
   Duan LY, 2015, IEEE T MULTIMEDIA, V17, P828, DOI 10.1109/TMM.2015.2419973
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   He J., 2010, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P1129
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2013, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2013.206
   Norouzi M, 2014, IEEE T PATTERN ANAL, V36, P1107, DOI 10.1109/TPAMI.2013.231
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Weiss Yair, 2009, Advances in Neural Information Processing Systems, P1753, DOI DOI 10.5555/2981780.2981999
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2156
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Zhang Y, 2016, NEUROCOMPUTING, V172, P207, DOI 10.1016/j.neucom.2015.02.080
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 27
TC 5
Z9 5
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 229
EP 235
DI 10.1016/j.jvcir.2016.08.013
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600020
DA 2024-07-18
ER

PT J
AU Rond, A
   Giryes, R
   Elad, M
AF Rond, Arie
   Giryes, Raja
   Elad, Michael
TI Poisson inverse problems by the Plug-and-Play scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Poisson denoising; Poisson deblurring; Image processing
ID NOISE; SPARSE
AB The easy-to-compute Anscombe transform offers a conversion of a Poisson random variable into a variance stabilized Gaussian one, thus becoming handy in various Poisson-noisy inverse problems. Solution to such problems can be done by applying this transform, then invoking a high-performance Gaussian noise -oriented restoration algorithm, and finally using an inverse transform. This process works well for high-SNR images, but when the noise level is high, it loses much of its effectiveness. This work suggests a novel method for coupling Gaussian denoising algorithms to Poisson noisy inverse problems. This approach is based on a general approach termed "Plug-and-Play-Prior". Deploying this to Poisson inverse-problems leads to an iterative scheme that repeats an easy treatable convex programming task, followed by a powerful Gaussian denoising This method, like the Anscombe transform, enables to plug Gaussian denoising algorithms for the Poisson-oriented problem, and yet, it is effective for all SNR ranges. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Rond, Arie; Giryes, Raja; Elad, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Rond, A (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
EM sarikr@campus.technion.ac.il; raja@tauex.tau.ac.il;
   elad@cs.technion.ac.il
RI , Miki/AAH-4640-2019
OI Giryes, Raja/0000-0002-2830-0297
FU European Research Council under EUs 7th Framework Program, ERC grant
   [320649]; Intel Collaborative Research Institute for Computational
   Intelligence; Google Faculty Research Award; Israel Science Foundation
   (ISF) [1770/14]
FX This research was supported by the European Research Council under EUs
   7th Framework Program, ERC grant agreement 320649, by the Intel
   Collaborative Research Institute for Computational Intelligence, and by
   the Google Faculty Research Award.; This research was supported by
   Israel Science Foundation (ISF) grant number 1770/14.
CR [Anonymous], 2010, Workshop on Information Theoretic Methods in Science and Engineering
   ANSCOMBE FJ, 1948, BIOMETRIKA, V35, P246, DOI 10.2307/2332343
   Boulanger J, 2010, IEEE T MED IMAGING, V29, P442, DOI 10.1109/TMI.2009.2033991
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Carlavan M, 2012, IEEE T IMAGE PROCESS, V21, P1834, DOI 10.1109/TIP.2011.2175934
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Deledalle CA, 2010, IEEE IMAGE PROC, P801, DOI 10.1109/ICIP.2010.5653394
   Dupé FX, 2012, STAT METHODOL, V9, P4, DOI 10.1016/j.stamet.2011.04.008
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Figueiredo MAT, 2010, IEEE T IMAGE PROCESS, V19, P3133, DOI 10.1109/TIP.2010.2053941
   Fisz M., 1955, Colloquium Mathematicum, V3, P138, DOI DOI 10.4064/CM-3-2-138-146
   Giryes R, 2014, IEEE T IMAGE PROCESS, V23, P5057, DOI 10.1109/TIP.2014.2362057
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Jezierska A, 2012, INT CONF ACOUST SPEE, P1085, DOI 10.1109/ICASSP.2012.6288075
   Keenan MR, 2004, SURF INTERFACE ANAL, V36, P203, DOI 10.1002/sia.1657
   Ma LY, 2013, IEEE T MED IMAGING, V32, P1277, DOI 10.1109/TMI.2013.2255883
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   Pustelnik N, 2011, IEEE T IMAGE PROCESS, V20, P2450, DOI 10.1109/TIP.2011.2128335
   Rodrigues I, 2008, IEEE IMAGE PROC, P1756, DOI 10.1109/ICIP.2008.4712115
   Romano Y, 2013, IEEE IMAGE PROC, P435, DOI 10.1109/ICIP.2013.6738090
   Salmon J, 2014, J MATH IMAGING VIS, V48, P279, DOI 10.1007/s10851-013-0435-6
   Schmidt M., 2005, minFunc: unconstrained differentiable multivariate optimization in Matlab
   Schmitt J, 2010, ASTRON ASTROPHYS, V517, DOI 10.1051/0004-6361/200913822
   Sreehari S., 2015, 151207331 ARXIV
   Sulam J, 2014, IEEE IMAGE PROC, P808, DOI 10.1109/ICIP.2014.7025162
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P1093, DOI 10.1109/TIP.2008.924386
NR 30
TC 91
Z9 101
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 96
EP 108
DI 10.1016/j.jvcir.2016.09.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cai, XX
   Song, B
AF Cai, Xiuxia
   Song, Bin
TI Combining inconsistent textures using convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Large-scale bound-constrained optimization; Image synthesis; Texture
   interpolation; Convolutional neural network
AB It is difficult for us to generate a gradually changed texture by combing two textures when they have very different textures and structures. This is a common problem in constructing panoramas and in pasting from one texture to another. The inconsistency between the sources is what we want to deal with in this paper. We present a new method for synthesizing a transition region between two source textures, such that inconsistent textures and structural properties all change gradually from one source to the other. We first extract the convolutional neural network (CNN) features of two source textures and one initial target texture at convolution and pooling layers. We set the distortion function to be the square of the difference between feature maps of source texture and target texture. And we based on feature maps compute the Gram matrix which is the inner product between feature maps in each layer. We set the second distortion function to be the square of the difference between Gram matrix of second source texture and target texture. Our target function is the weighted sum of two distortion functions we described before. We use Large-scale bound-constrained optimization method to optimize the target function and get the ultimate result. The model provides a new tool to generate a transition region between two source textures by CNN. Our method is robust to various types of images tested. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Cai, Xiuxia; Song, Bin] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
C3 Xidian University
RP Song, B (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
EM bsong@mail.xidian.edu.cn
FU National Natural Science Foundation of China [61271173, 61372068];
   Research Fund for the Doctoral Program of Higher Education of China
   [20130203110005]; Fundamental Research Funds for the Central
   Universities [K5051301033]; 111 Project [B08038]; ISN State Key
   Laboratory
FX We thank the anonymous reviewers and the editor for their valuable
   comments. This work has been supported by The National Natural Science
   Foundation of China (Nos. 61271173 and 61372068), the Research Fund for
   the Doctoral Program of Higher Education of China (No. 20130203110005),
   the Fundamental Research Funds for the Central Universities (No.
   K5051301033), the 111 Project (No. B08038), and also supported by the
   ISN State Key Laboratory.
CR [Anonymous], 2015, COMPUTER VISION PATT
   [Anonymous], 2014, ARXIV14120035
   [Anonymous], 2014 IEEE C COMP VIS
   [Anonymous], ACM T GRAPH
   [Anonymous], 2015, P CVPR
   [Anonymous], 2007, P 2 INT C DIGITAL IN, DOI DOI 10.1145/1306813.1306830
   [Anonymous], 2015, P CVPR
   [Anonymous], ACM T MATH SOFTW TOM
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Cadieu CF, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003963
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Cimpoi Mircea, 2014, ARXIV14116836
   Gatys L. A., 2015, arXiv
   Güçlü U, 2015, J NEUROSCI, V35, P10005, DOI 10.1523/JNEUROSCI.5023-14.2015
   Heeger D. J., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P229, DOI 10.1145/218380.218446
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Khaligh-Razavi S.-M., 2014, Deep supervised, but not unsupervised, models may explain it cortical representation
   Krizhevsky A., 2012, Adv. Neur. Inf. Process. Syst.
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin YX, 2009, VISUAL COMPUT, V25, P599, DOI 10.1007/s00371-009-0349-x
   Nocedal J, 2006, SPRINGER SER OPER RE, P101
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Russakovsky J., 2014, Int. J. Comp. Vis., P1
   SHANNO DF, 1970, MATH COMPUT, V24, P647, DOI 10.2307/2004840
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111
   Yu J, 2012, NEUROCOMPUTING, V79, P105, DOI 10.1016/j.neucom.2011.10.003
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
NR 29
TC 5
Z9 5
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 366
EP 375
DI 10.1016/j.jvcir.2016.07.009
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500032
DA 2024-07-18
ER

PT J
AU Lu, GY
   Ren, L
   Kolagunda, A
   Wang, XL
   Turkbey, IB
   Choyke, PL
   Kambhamettu, C
AF Lu, Guoyu
   Ren, Li
   Kolagunda, Abhishek
   Wang, Xiaolong
   Turkbey, Ismail B.
   Choyke, Peter L.
   Kambhamettu, Chandra
TI Representing 3D shapes based on implicit surface functions learned from
   RBF neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D shape presentation; Radial basis function; Neural network; 3D
   reconstruction
ID RECONSTRUCTION; KERNELS
AB We propose to represent the shape of 3D objects using a neural network classifier. The 3D shape is learned from a neural network, where Radial Basis Function (RBF) is applied as the activation function for each perceptron. The implicit functions derived from the neural network is a combination of radial basis functions, which can represent complex shapes. The use of RBF provides a rotation, translation and scaling invariant feature to represent the shape. We conduct experiments on a new prostate dataset and public datasets. Our testing results show that our neural network -based method can accurately represent various shapes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lu, Guoyu; Ren, Li; Kolagunda, Abhishek; Wang, Xiaolong; Kambhamettu, Chandra] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA.
   [Turkbey, Ismail B.; Choyke, Peter L.] NCI, NIH, Bethesda, MD 20892 USA.
C3 University of Delaware; National Institutes of Health (NIH) - USA; NIH
   National Cancer Institute (NCI)
RP Lu, GY (corresponding author), Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA.
EM luguoyu@udel.edu
OI Lu, Guoyu/0000-0002-2685-5563
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   [Anonymous], 2015, MATH PROB ENG, DOI DOI 10.1016/J.CMET.2015.09.010
   [Anonymous], 2015, IEEE WINT C APPL COM
   BenArie J, 1996, INT CONF ACOUST SPEE, P3470, DOI 10.1109/ICASSP.1996.550775
   Besl Paul J., 1992, ROBOTICS DL TENTATIV
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Breitkopf P, 2005, COMPUT STRUCT, V83, P1411, DOI 10.1016/j.compstruc.2004.07.011
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Gardner A, 2003, ACM T GRAPHIC, V22, P749, DOI 10.1145/882262.882342
   Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253
   Heimann T, 2009, IEEE T MED IMAGING, V28, P1251, DOI 10.1109/TMI.2009.2013851
   Nguyen HV, 2013, IEEE T PATTERN ANAL, V35, P970, DOI 10.1109/TPAMI.2012.186
   Jia Y., 2016, AAAI C ART INT AAAI
   Kim T, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2451236.2451241
   Kolagunda A., 2015, BRIT MACH VIS C
   Li PH, 2013, IEEE I CONF COMP VIS, P1601, DOI 10.1109/ICCV.2013.202
   Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44
   Lu G., 2014, BRIT MACH VIS C
   Lu G., 2016, IEEE INT C AC SPEECH
   Lu GY, 2015, IEEE I CONF COMP VIS, P2434, DOI 10.1109/ICCV.2015.280
   Lu GY, 2016, NEUROCOMPUTING, V173, P83, DOI 10.1016/j.neucom.2015.07.106
   Lu GY, 2013, LECT NOTES COMPUT SC, V8033, P312, DOI 10.1007/978-3-642-41914-0_31
   Morse BS, 2005, ACM SIGGRAPH 2005 CO, P78
   Museth K, 2002, ACM T GRAPHIC, V21, P330, DOI 10.1145/566570.566585
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Reinhardt J. M., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P125, DOI 10.1109/ICASSP.1993.319763
   Shelton CR, 2000, INT J COMPUT VISION, V38, P75, DOI 10.1023/A:1008170818506
   Steinke F, 2005, COMPUT GRAPH FORUM, V24, P285, DOI 10.1111/j.1467-8659.2005.00853.x
   Taflanidis AA, 2012, PROBABILIST ENG MECH, V28, P216, DOI 10.1016/j.probengmech.2011.07.003
   Vemulapalli R, 2013, PROC CVPR IEEE, P1782, DOI 10.1109/CVPR.2013.233
   Walder C.J., 2003, INT C ADV PATT REC I, V1, P387
   Wang W., 2016, COMPUTER VISION PATT
   Wang W, 2016, IEEE T IMAGE PROCESS, V25, P1465, DOI 10.1109/TIP.2016.2523340
   Wang XL, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P309, DOI 10.1109/ICMLA.2013.141
   Zagorchev L.G., 2012, IEEE T VIS COMPUT GR, V28, P216
NR 35
TC 8
Z9 8
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 852
EP 860
DI 10.1016/j.jvcir.2016.08.014
PN B
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600039
DA 2024-07-18
ER

PT J
AU Qian, ZX
   Dai, S
   Jiang, F
   Zhang, XP
AF Qian, Zhenxing
   Dai, Shu
   Jiang, Fei
   Zhang, Xinpeng
TI Improved joint reversible data hiding in encrypted images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Image encryption; Image recovery
AB This paper proposes an improved method of reversible data hiding in encrypted images (RDH-EI). Three parties constitute the proposed system: the image owner, the remote server and the recipient. To preserve privacy, an image owner encrypts the original image using a stream cipher algorithm and uploads the ciphertext to a remote server. On server side, a data-hider is allowed to embed additional message into the encrypted image using a swapping/shifting based algorithm. After downloading the marked encrypted image from the server and implementing the decryption, a recipient can extract the hidden messages and losslessly recover the original image. Experimental results show that the proposed method achieves a larger payload than the related works. Meanwhile, a limitation in the related works that few bits can be embedded into the encrypted medical images is also eliminated in the proposed method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Qian, Zhenxing] NUIST, Nanjing, Jiangsu, Peoples R China.
   [Qian, Zhenxing; Dai, Shu; Jiang, Fei; Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
   [Zhang, Xinpeng] Shanghai Univ, Key Lab Specialty Fiber Opt & Opt Access, Shanghai, Peoples R China.
C3 Nanjing University of Information Science & Technology; Shanghai
   University; Shanghai University
RP Qian, ZX (corresponding author), NUIST, Nanjing, Jiangsu, Peoples R China.
EM zxqian@shu.edu.cn
RI Qian, Zhenxing/AHC-9176-2022
FU Natural Science Foundation of China [61572308, 61232016, U1405254,
   U1536108, 61525203, 61472235, 61402279]; Shanghai Key Laboratory of
   Intelligent Information Processing [IIPL-2014-006]; Shanghai University
   Filmology Summit Research Grant; Shanghai Nature Science Foundation
   [14ZR1415900]; Open Project Program of the State Key Lab of CADCG
   [A1502]; PAPD
FX This work was supported by Natural Science Foundation of China (Grant
   61572308, Grant 61232016, Grant U1405254, Grant U1536108, Grant
   61525203, and Grant 61472235), Shanghai Key Laboratory of Intelligent
   Information Processing under Grant IIPL-2014-006, 2015 Shanghai
   University Filmology Summit Research Grant, the National Science
   Foundation China under Grant 61402279, the Shanghai Nature Science
   Foundation under Grant 14ZR1415900, the Open Project Program of the
   State Key Lab of CAD&CG under Grant A1502, and the PAPD fund.
CR Cao X., IEEE T CYBERNETICS
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Qian Z., 2014, IEEE T MULTIMEDIA, V15, P316
   Qian Z., IEEE SIGNAL PROCESS
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 16
TC 20
Z9 23
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 732
EP 738
DI 10.1016/j.jvcir.2016.08.020
PN B
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600027
OA Bronze
DA 2024-07-18
ER

PT J
AU Tran, TA
   Tran, HT
   Na, IS
   Lee, GS
   Yang, HJ
   Kim, SH
AF Tuan Anh Tran
   Hong Tai Tran
   Na, In Seop
   Lee, Guee Sang
   Yang, Hyung Jeong
   Kim, Soo Hyung
TI A mixture model using Random Rotation Bounding Box to detect table
   region in document image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Table detection; Random Rotation Bounding Box; Page segmentation;
   Document layout analysis; OCR
ID PARALLEL FRAMEWORK
AB Table detection in the document image is still a challenging problem due to the variety of table structures and the complexity of document layout. In this paper, we propose a novel method for detecting table regions by using a new shape which is called Random Rotation Bounding Box. This shape is used for illustration and description of the table regions. Based on it, our system performs the following three fundamental steps to detect the table zones: classification of the text and non-text elements in the document image, detection of the ruling-line tables, and identification of the non-ruling-line tables. Different from other methods, our approach can detect most kinds of tables with high precision even when it is skewed. Besides, the proposed method is also designed to fit in the document layout analysis system. Our algorithm has been tested on the two well-known, and a commercial datasets: ICDAR2013 table competition, UNLV, and Diotek. Experimental results on these databases show that our method is more robust and efficient than previous systems. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tuan Anh Tran; Hong Tai Tran; Na, In Seop; Lee, Guee Sang; Yang, Hyung Jeong; Kim, Soo Hyung] Chonnam Natl Univ, Sch Elect & Comp Engn, 77 Yongbong Ro, Kwangju 500757, South Korea.
C3 Chonnam National University
RP Kim, SH (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, 77 Yongbong Ro, Kwangju 500757, South Korea.
EM shkim@jnu.ac.kr
RI Na, In Seop/K-2508-2018; TUAN, ANH TRAN/AAU-7881-2020; Yang,
   Hyung-Jeong/GXV-4819-2022; Tran, Hong Tai/AAF-8383-2019
OI Na, In Seop/0000-0001-6471-043X; Tran, Hong Tai/0000-0001-7261-9855
FU National Research Foundation of Korea [NRF-2015R1D1A3A01018993,
   NRF-2015R1C1A1A02036495]; Chonnam National University in Korea
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF-2015R1D1A3A01018993 and
   NRF-2015R1C1A1A02036495). This study was also financially supported by
   Chonnam National University in Korea, 2016.
CR Antonacopoulos A, 2015, PROC INT CONF DOC, P1151, DOI 10.1109/ICDAR.2015.7333941
   Cesarini F, 2002, INT C PATT RECOG, P236, DOI 10.1109/ICPR.2002.1047838
   Costa e Silva A, 2006, INT J DOC ANAL RECOG, V8, P144, DOI 10.1007/s10032-005-0001-x
   Silva ACE, 2011, INT J DOC ANAL RECOG, V14, P101, DOI 10.1007/s10032-010-0144-2
   e Silva Ana Costa, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P843, DOI 10.1109/ICDAR.2009.185
   Fang J, 2011, PROC INT CONF DOC, P779, DOI 10.1109/ICDAR.2011.304
   Gatos B., 2005, P INT C ADV PATT REC, P612
   Gobel M., 2012, P 2012 ACM S DOC ENG, P45, DOI DOI 10.1145/2361354.2361365
   Göbel M, 2013, PROC INT CONF DOC, P1449, DOI 10.1109/ICDAR.2013.292
   Harit G., 2012, P 8 IND C COMP VIS G
   Hu JY, 2000, PROC SPIE, V3967, P291, DOI 10.1117/12.381605
   Jing Fang, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P445, DOI 10.1109/DAS.2012.29
   Kasar T, 2013, PROC INT CONF DOC, P1185, DOI 10.1109/ICDAR.2013.240
   Kieninger T, 2005, PROC INT CONF DOC, P1232, DOI 10.1109/ICDAR.2005.47
   Kieninger T., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P518, DOI 10.1109/ICDAR.2001.953843
   LAURENTINI A, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P405, DOI 10.1109/ICPR.1992.201803
   Liu Y, 2007, ACM-IEEE J CONF DIG, P91, DOI 10.1145/1255175.1255193
   Mandal S, 2006, INT J DOC ANAL RECOG, V8, P172, DOI 10.1007/s10032-005-0006-5
   Ramel JY, 2003, PROC INT CONF DOC, P374
   Rice S., 1995, The Fourth Annual Test of OCR Accuracy
   Shafait F., 2010, P 9 IAPR INT WORKSH, P65, DOI DOI 10.1145/1815330.1815339
   Smith Raymond W., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P241, DOI 10.1109/ICDAR.2009.257
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Stoffel A., 2010, P 2010 ACM S APPL CO, P8, DOI [10.1145/1774088.1774091, DOI 10.1145/1774088.1774091]
   Strobelt H, 2009, IEEE T VIS COMPUT GR, V15, P1145, DOI 10.1109/TVCG.2009.139
   Tran Dieu Ni, 2015, International Journal of Contents, V11, P77
   Tran T.A., 2016, INT J DOC ANAL RECOG
   Tran TA, 2015, KSII T INTERNET INF, V9, P4072, DOI 10.3837/tiis.2015.10.017
   Wang YL, 2004, PATTERN RECOGN, V37, P1479, DOI 10.1016/j.patcog.2004.01.012
   Wang YL, 2001, PROC INT CONF DOC, P528, DOI 10.1109/ICDAR.2001.953845
   Watanabe T., 1991, P 1 ICDAR, P638
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yildiz B., 2005, IICAI, P1773
   Ying Liu, 2008, P C INFORM KNOWLEDGE, P1311, DOI [10.1145/1458082.1458255, DOI 10.1145/1458082.1458255]
   Zanibbi R., 2004, International Journal on Document Analysis and Recognition, V7, P1, DOI 10.1007/s10032-004-0120-9
NR 36
TC 14
Z9 15
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 196
EP 208
DI 10.1016/j.jvcir.2016.05.023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900019
DA 2024-07-18
ER

PT J
AU Moraes, D
   Wainer, J
   Rocha, A
AF Moraes, Daniel
   Wainer, Jacques
   Rocha, Anderson
TI Low false positive learning with support vector machines
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Support vector machines; k-nearest neighbors; Low false positive
   learning
ID CLASSIFICATION
AB Most machine learning systems for binary classification are trained using algorithms that maximize the accuracy and assume that false positives and false negatives are equally bad. However, in many applications, these two types of errors may have very different costs. In this paper, we consider the problem of controlling the false positive rate on SVMs, since its traditional formulation does not'offer such assurance. To solve this problem, we define a feature space sensitive area, where the probability of having false positives is higher, and use a second classifier (unanimity k-NN) in this area to better filter errors and improve the decision-making process. We call this method Risk Area SVM (RA-SVM). We compare the RA-SVM to other state-of-the-art methods for low false positive classification using 33 standard datasets in the literature. The solution we propose shows better performance in the vast majority of the cases using the standard Neyman-Pearson measure. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Moraes, Daniel; Wainer, Jacques; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1251, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Moraes, D (corresponding author), Univ Estadual Campinas, Inst Comp, Av Albert Einstein 1251, BR-13083852 Campinas, SP, Brazil.
EM daniel.moraes@students.ic.unicamp.br; wainer@ic.unicamp.br;
   anderson.rocha@ic.unicamp.br
RI Wainer, Jacques/B-4241-2012; Wainer, Jacques/AAQ-6029-2021; Rocha,
   Anderson/KHU-9621-2024
OI Wainer, Jacques/0000-0001-5201-1244; Wainer,
   Jacques/0000-0001-5201-1244; 
FU FAPESP [2010/05647-4]; CNPq [304352/2012-8, 477662/2013-7];
   CAPES/DeepEyes; Microsoft Research; Fundacao de Amparo a Pesquisa do
   Estado de Sao Paulo (FAPESP) [10/05647-4] Funding Source: FAPESP
FX We thank the Associate Editor and reviewers for their valuable comments.
   This work was supported by FAPESP (Grant #2010/05647-4), CNPq (Grants
   #304352/2012-8, and #477662/2013-7), CAPES/DeepEyes, and Microsoft
   Research.
CR Andre AB, 2013, APPL ARTIF INTELL, V27, P36, DOI 10.1080/08839514.2013.747370
   Androutsopoulos I., P 23 ANN INT ACM SIG, P160
   [Anonymous], 1997, 1602 AI MIT
   [Anonymous], 2001, Adv. Neural Inf. Process.Syst.
   Ben-Hur A., 2002, Journal of Machine Learning Research, V2, P125, DOI 10.1162/15324430260185565
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bratko A, 2006, J MACH LEARN RES, V7, P2673
   Carreras X., 2001, P 4 INT C RECENT ADV, P58
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Costa FD, 2014, PATTERN RECOGN LETT, V39, P92, DOI 10.1016/j.patrec.2013.09.006
   Davenport M.A., 2006, IEEE International Conferenceon Acoustics,Speech, and Signal Processing, 2006,Proceedings (ICASSP'06), VV, P589
   Davenport MA, 2010, IEEE T PATTERN ANAL, V32, P1888, DOI 10.1109/TPAMI.2010.29
   de F., 25 C GRAPH PATT IM S, P71
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Hastie T., 2009, The Elements of Statistical Learning
   Karakoulas G, 1999, ADV NEUR IN, V11, P253
   Li Y.-F., AAAI, P500
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu TL, 2014, INT CONF INFO SCI, P100, DOI 10.1109/ICIST.2014.6920341
   Lynam T.R., PROCEEDINGS OF THE 2, P123
   Masnadi-Shirazi H., P 24 INT C MACH LEAR, P609
   Qi ZQ, 2013, PROCEDIA COMPUT SCI, V18, P1684, DOI 10.1016/j.procs.2013.05.336
   Qu HN, 2010, PATTERN RECOGN, V43, P3448, DOI 10.1016/j.patcog.2010.05.002
   Samet H, 2006, FDN MULTIDIMENSIONAL
   Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
   Schneider K.-M., P 10 C EUR CHAPT ASS, V1, P307
   Scholkopf B., 2002, Learning with Kernels
   Scott C, 2005, IEEE T INFORM THEORY, V51, P3806, DOI 10.1109/TIT.2005.856955
   Scott C, 2007, IEEE T INFORM THEORY, V53, P2852, DOI 10.1109/TIT.2007.901152
   Shawe-Taylor J, 1998, ALGORITHMICA, V22, P157, DOI 10.1007/PL00013827
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Wu J., P 22 INT C MACH LEAR, P988
   Wu SH, 2013, IEEE T KNOWL DATA EN, V25, P1083, DOI 10.1109/TKDE.2012.46
   Yih W.-t., P 3 C EMAIL ANT, P1
   Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17
NR 38
TC 9
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 340
EP 350
DI 10.1016/j.jvcir.2016.03.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100029
DA 2024-07-18
ER

PT J
AU Zalik, B
   Mongus, D
   Liu, YK
   Lukac, N
AF Zalik, Borut
   Mongus, Domen
   Liu, Yong-Kui
   Lukac, Niko
TI Unsigned Manhattan chain code
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Boundary of the rasterised shape; Pixel's neighbourhood of
   8-connectivity; Chain code properties; Monotonic parts; Compressibility
ID LOSSLESS COMPRESSION; ALGORITHM
AB This paper introduces a new chain code named Unsigned Manhattan Chain Code - UMCC. Although it exploits a pixel's neighbourhood of 8-connectivity, only two coding symbols are used for navigating through the geometric shape's boundary pixels. For this, the movements in the x- and y-coordinate direction are separated, whilst the sign of the moving direction is controlled by two flags - one for each coordinate direction. UMCC is insensitive to rotation and mirroring and enables shape magnification. However, the more unique property is the UMCC's ability to explicitly separate the monotonic parts of the geometric shape. UMCC's properties have been compared against the properties of other chain codes including the Freeman chain code in eight and four directions, the Vertex Chain Code, and the Three OrThogonal chain code. It has been shown that the UMCC has superior properties in regards to the up-to-date chain codes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zalik, Borut; Mongus, Domen; Lukac, Niko] Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SI-2000 Maribor, Slovenia.
   [Liu, Yong-Kui] Dalian Nationalities Univ, Dept Comp Sci, Dalian 116600, Peoples R China.
C3 University of Maribor; Dalian Minzu University
RP Lukac, N (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SI-2000 Maribor, Slovenia.
EM niko.lukac@um.si
RI Lukač, Niko/B-7524-2014; Lukač, Niko/IVV-5895-2023; Žalik,
   Borut/X-1320-2019
OI Lukač, Niko/0000-0002-9517-1157; 
FU Slovenian Research Agency [J2-5479, J2-6764, 1000-13-0552];
   Slovenian-Chinese bilateral project [BI-CN/14-15-007]
FX This work was supported by the Slovenian Research Agency under Grants
   J2-5479, J2-6764, 1000-13-0552 and Slovenian-Chinese bilateral project
   BI-CN/14-15-007.
CR Ballard D.H., 1982, Computer Vision
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   Chen A, 2011, APPL MATH RES EXPRES, P182, DOI 10.1093/amrx/abr002
   Dai XL, 1999, IEEE T GEOSCI REMOTE, V37, P2351, DOI 10.1109/36.789634
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Ge N, 2011, IEEE T PLASMA SCI, V39, P2884, DOI 10.1109/TPS.2011.2159132
   Globacnik T, 2010, PATTERN RECOGN, V43, P4137, DOI 10.1016/j.patcog.2010.07.018
   Gupta RK, 2012, COMPUT AIDED DESIGN, V44, P99, DOI 10.1016/j.cad.2011.09.012
   Jain J., 2012, ADV COMPUTER SCI INF, P611
   LANGDON GG, 1982, IEEE T INFORM THEORY, V28, P800, DOI 10.1109/TIT.1982.1056559
   Li K, 2013, PETROL SCI, V10, P347, DOI 10.1007/s12182-013-0283-4
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Liu YK, 2012, SIGNAL PROCESS-IMAGE, V27, P973, DOI 10.1016/j.image.2012.07.008
   NOLL AM, 1971, COMMUN ACM, V14, P143, DOI 10.1145/362566.362567
   Nunes P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P114, DOI 10.1109/ICIP.1997.632008
   PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029
   Ren M, 2009, T GIS, V13, P197, DOI 10.1111/j.1467-9671.2009.01147.x
   Salomon D., 2010, Handbook of Data Compression, V5th
   Sánchez-Cruz H, 2005, OPT ENG, V44, DOI 10.1117/1.2052793
   Sanchez-Cruz H., 2008, CGIM 08 P COMP GRAPH, P6
   Sánchez-Cruz H, 2009, LECT NOTES COMPUT SC, V5856, P45, DOI 10.1007/978-3-642-10268-4_5
   Sun H, 2005, PATTERN RECOGN LETT, V26, P1266, DOI 10.1016/j.patrec.2004.11.007
   Wang CQ, 2012, APPL SOFT COMPUT, V12, P423, DOI 10.1016/j.asoc.2011.08.028
   Zalik B, 2015, IMAGE VIS COMPUT
   Zalik B, 2014, SIGNAL PROCESS-IMAGE, V29, P96, DOI 10.1016/j.image.2013.09.002
NR 25
TC 12
Z9 13
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 186
EP 194
DI 10.1016/j.jvcir.2016.03.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100016
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Li, YJ
   Blum, RS
   Xiang, P
AF Zhang, Qiang
   Li, Yajun
   Blum, Rick S.
   Xiang, Peng
TI Matching of images with projective distortion using transform invariant
   low-rank textures
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image matching; Projective distortion; Transform invariant low-rank
   textures (TILT); Automatic low-rank texture region detection; Geometric
   shape descriptor
ID SPORTS VIDEO; RECONSTRUCTION; REGISTRATION; RECTIFICATION; STEREO
AB A matching method is presented for images with projective distortion based on transform invariant low rank textures (TILT). In the method, the problem of matching images with projective distortion is first reduced to a problem of matching two rectified images just with scaling and translation distortions via TILT. Then a point-feature based matching method is employed to establish the corresponding points between the two rectified images. This is different from some traditional methods that try to directly seek local affine or projective invariants from input images. Moreover, no prior knowledge on the epipolar geometry is required in the proposed method. An automatic low-rank texture region detection method is presented to make the method more applicable in practice. Additionally, a new descriptor is constructed by combining a proposed geometric shape descriptor and the traditional SIFT descriptor to further improve the correct matching rate. Experimental results demonstrate the validity of the proposed method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Qiang] Xidian Univ, Key Lab Elect Equipment Struct Design, Minist Educ, POB 183,2 South TaiBai Rd, Xian 710071, Shaanxi, Peoples R China.
   [Zhang, Qiang; Li, Yajun; Xiang, Peng] Xidian Univ, Sch Mechano Elect Engn, Ctr Complex Syst, POB 183,2 South TaiBai Rd, Xian 710071, Shaanxi, Peoples R China.
   [Blum, Rick S.] Lehigh Univ, Dept Elect & Comp Engn, Bethlehem, PA 18015 USA.
C3 Xidian University; Xidian University; Lehigh University
RP Zhang, Q (corresponding author), Xidian Univ, Dept Automat Control, POB 183,2 South TaiBai Rd, Xian 710071, Shaanxi, Peoples R China.
EM qzhang@xidian.edu.cn
OI Blum, Rick S/0000-0002-1024-6771
FU National Natural Science Foundation of China [61104212]; Fundamental
   Research Funds for the Central Universities [NSIY211416]; National
   Science Foundation [ECCS-1405579]; Div Of Electrical, Commun & Cyber
   Sys; Directorate For Engineering [1405579] Funding Source: National
   Science Foundation
FX This work of the first two and the last authors is supported by the
   National Natural Science Foundation of China under Grant No. 61104212
   and by the Fundamental Research Funds for the Central Universities under
   Grant No. NSIY211416. The work of R. S. Blum is supported by the
   National Science Foundation under Grant No. ECCS-1405579.
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BROWN M., 2002, BRIT MACHINE VISION, P656, DOI [10.5244/C.16.23, DOI 10.5244/C.16.23]
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cheng LA, 2011, PHOTOGRAMM ENG REM S, V77, P125, DOI 10.14358/PERS.77.2.125
   Denton JA, 2007, PATTERN RECOGN, V40, P586, DOI 10.1016/j.patcog.2006.04.031
   Fan B, 2012, PATTERN RECOGN, V45, P794, DOI 10.1016/j.patcog.2011.08.004
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Gonzales R.C., 2011, Digital Image Processing, V3
   Han JG, 2008, IEEE T CIRC SYST VID, V18, P1628, DOI 10.1109/TCSVT.2008.2005611
   Han JG, 2013, PATTERN RECOGN LETT, V34, P42, DOI 10.1016/j.patrec.2012.03.022
   Han JG, 2011, IEEE MULTIMEDIA, V18, P72, DOI 10.1109/MMUL.2010.24
   Hartley R., 2006, Multiple view geometry in computer vision, V2nd
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Ishii J, 2012, IEEE IMAGE PROC, P2977, DOI 10.1109/ICIP.2012.6467525
   Kratochvil BE, 2010, J MICROSC-OXFORD, V237, P122, DOI 10.1111/j.1365-2818.2009.03313.x
   Liang JN, 2012, PATTERN RECOGN, V45, P3825, DOI 10.1016/j.patcog.2012.03.026
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallon J, 2005, IMAGE VISION COMPUT, V23, P643, DOI 10.1016/j.imavis.2005.03.002
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Papachristou C, 2014, COMPUT VIS IMAGE UND, V119, P81, DOI 10.1016/j.cviu.2013.12.004
   Peng X., 2016, 2016 IEEE International Conference on Prognostics and Health Management (ICPHM), P1, DOI DOI 10.1109/ICPHM.2016.7542844
   Peng X, 2015, AAAI CONF ARTIF INTE, P3827
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Podbreznik P, 2010, ADV ENG INFORM, V24, P367, DOI 10.1016/j.aei.2010.03.001
   Srestasathiern P, 2011, COMPUT VIS IMAGE UND, V115, P1525, DOI 10.1016/j.cviu.2011.07.004
   Suk T, 2000, PATTERN RECOGN, V33, P251, DOI 10.1016/S0031-3203(99)00049-7
   Wang K, 2013, J VIS COMMUN IMAGE R, V24, P615, DOI 10.1016/j.jvcir.2013.04.010
   Wang SH, 2012, IEEE GEOSCI REMOTE S, V9, P649, DOI 10.1109/LGRS.2011.2177437
   Yang S, 2013, NEUROCOMPUTING, V120, P268, DOI 10.1016/j.neucom.2012.08.055
   [姚国标 Yao Guobiao], 2013, [测绘科学, Science of Surveying and Mapping], V38, P154
   Yudong Cao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P519, DOI 10.1109/ICPR.2010.132
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zhang A., 2014, P IEEE C COMP VIS PA, P2321
   Zhang Q, 2015, IMAGE VISION COMPUT, V36, P23, DOI 10.1016/j.imavis.2015.01.008
   Zhang X, 2013, PROC INT CONF DOC, P393, DOI 10.1109/ICDAR.2013.86
   Zhang X, 2014, VISUAL COMPUT, V30, P401, DOI 10.1007/s00371-013-0864-7
   Zhang Z., 2010, Proceedings of ACCV, P314
   Zhu YX, 2013, J VIS COMMUN IMAGE R, V24, P448, DOI 10.1016/j.jvcir.2013.02.005
NR 41
TC 8
Z9 9
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 602
EP 613
DI 10.1016/j.jvcir.2016.04.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100052
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, SS
   Luo, FL
   Ma, SW
   Zhang, X
   Wang, SQ
   Zhao, DB
   Gao, W
AF Wang, Shanshe
   Luo, Falei
   Ma, Siwei
   Zhang, Xiang
   Wang, Shiqi
   Zhao, Debin
   Gao, Wen
TI Low complexity encoder optimization for HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC; Low complexity; Intra mode decision; CU splitting; Reference frame
   selection; Rate distortion optimization; Video coding; Encoder
   optimization
ID RATE-DISTORTION OPTIMIZATION; INTRA MODE DECISION; VIDEO; EFFICIENCY;
   ALGORITHM
AB High Efficiency Video Coding (HEVC) improved the coding efficiency significantly. Compared to its predecessor H.264/AVC, it can provide equivalent subjective quality with more than 57% bit rate reduction. However, the improvement on coding efficiency is obtained at the expense of much more intensive computation complexity. In this paper, based on an overall analysis of computation complexity at the HEVC encoder, a low complexity encoder optimization scheme is proposed by reducing the number of available candidates for evaluation in terms of the intra prediction mode decision, early termination of coding unit (CU) splitting and adaptive reference frame selection. With the proposed scheme, the rate distortion optimization (RDO) technique of HEVC can be implemented in a low-complexity way for complexity constrained encoders. Experimental results demonstrate that, compared with the original HEVC reference encoder implementation, the proposed optimization scheme can achieve more than 40% complexity reduction on average with coding performance degradation as only 0.43% which can be ignorable. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Shanshe; Ma, Siwei; Zhang, Xiang; Wang, Shiqi; Gao, Wen] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
   [Wang, Shanshe; Ma, Siwei; Zhang, Xiang; Wang, Shiqi; Gao, Wen] Peking Univ, Cooperat Medianet Innovat Ctr, Beijing 100871, Peoples R China.
   [Zhao, Debin] Harbin Inst Technol, Dept Comp Sci & Technol, Harbin 150006, Peoples R China.
   [Luo, Falei] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
C3 Peking University; Peking University; Harbin Institute of Technology;
   Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Wang, SS (corresponding author), Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.; Wang, SS (corresponding author), Peking Univ, Cooperat Medianet Innovat Ctr, Beijing 100871, Peoples R China.
RI Zhao, Debin/JEP-0204-2023; Zhang, Xiang/U-1576-2019
OI Wang, Shiqi/0000-0002-3583-959X
FU National High-tech R&D Program of China (863 Program) [2015AA015903];
   National Natural Science Foundation of China [61322106, 61571017,
   61421062]; Shenzhen Peacock Plan
FX This work was supported in part by the National High-tech R&D Program of
   China (863 Program, 2015AA015903), National Natural Science Foundation
   of China (61322106, 61571017, 61421062), Shenzhen Peacock Plan, which
   are gratefully acknowledged.
CR Ahn S, 2013, PICT COD SYMP, P113, DOI 10.1109/PCS.2013.6737696
   [Anonymous], 2012, P 20 INT C SOFTW TEL
   Bjontegaard G., 2001, VCEGM33
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Bross B., 2012, JCTVC K1003
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Choi K, 2012, ELECTRON LETT, V48, P689, DOI 10.1049/el.2012.0277
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Corrêa G, 2011, IEEE T CONSUM ELECTR, V57, P1866, DOI 10.1109/TCE.2011.6131165
   Hsu Wei-Jhe., 2013, Proceedings of Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA), P1, DOI 10.1109/APSIPA.2013.6694353
   JCT-VC, 2011, JCTVC F045 JCT VC M
   JCT-VC, 2011, JCTVC F092
   Jiang W., 2012, CECNET
   Khan MUK, 2013, IEEE IMAGE PROC, P1578, DOI 10.1109/ICIP.2013.6738325
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kostas E., 2015, J REAL TIME IMAGE PR
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Ma SW, 2013, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC.2013.15
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Piao Y, 2010, JCTVC C207
   Psannis K, 2009, IEICE ELECTRON EXPR, V6, P1497, DOI [10.1587/elex.6.1497, 10.1587/elex.6.1437]
   Psannis K, 2008, IEICE ELECTRON EXPR, V5, P827, DOI 10.1587/elex.5.827
   Schierl T, 2012, IEEE T CIRC SYST VID, V22, P1871, DOI 10.1109/TCSVT.2012.2223054
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shi YF, 2013, IEEE INT WORKSH MULT, P429, DOI 10.1109/MMSP.2013.6659327
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Wang SS, 2013, IEEE IMAGE PROC, P2005, DOI 10.1109/ICIP.2013.6738413
   Yu Q., 2012, 2012 S PHOT OPT SHAN, P1, DOI [DOI 10.1109/SOPO.2012.6271111, DOI 10.1109/VCIP.2012.6410775, 10.1109/SOPO.2012.6271111]
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
   Zhao L., 2011, JCTVC D283
NR 33
TC 14
Z9 15
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 120
EP 131
DI 10.1016/j.jvcir.2015.12.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600011
DA 2024-07-18
ER

PT J
AU Xian, Y
   Tian, YL
AF Xian, Yang
   Tian, Yingli
TI Single image super-resolution via internal gradient similarity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image super-resolution; Image quality enhancement; Patch similarity;
   Self-redundancy; Across scale; Gradient similarity; Optimization;
   Gradient descent algorithm
ID QUALITY ASSESSMENT
AB Image super-resolution aims to reconstruct a high-resolution image from one or multiple low-resolution images which is an essential operation in a variety of applications. Due to the inherent ambiguity for super-resolution, it is a challenging task to reconstruct clear, artifacts-free edges while still preserving rich and natural textures. In this paper, we propose a novel, straightforward, and effective single image super-resolution method based on internal across-scale gradient similarity. The low-resolution gradients are first upsampled and then fed into an optimization framework to construct the final high-resolution output. The proposed approach is able to synthesize natural high-frequency texture details and maintain clean edges even under large scaling factors. Experimental results demonstrate that out method outperforms existing single image super-resolution techniques. We further evaluate the super-resolution performance when both internal statistics and external statistics are adopted. It is demonstrated that generally, internal statistics are sufficient for single image super-resolution. (C) 2015 Elsevier Inc. All rights reserved.
C1 CUNY, Grad Ctr, New York, NY 10016 USA.
   CUNY City Coll, New York, NY 10016 USA.
C3 City University of New York (CUNY) System; City University of New York
   (CUNY) System; City College of New York (CUNY)
RP Tian, YL (corresponding author), CUNY City Coll, Dept Elect Engn, Convent Ave & 140th St, New York, NY 10031 USA.
EM yxian@gradcenter.cuny.edu; ytian@ccny.cuny.edu
RI TIAN, YI/KHU-9704-2024
OI Tian, Yingli/0000-0003-4458-360X
FU ONR [N000141310450]; NSF [EFRI-1137172, IIP-1343402]; Emerging Frontiers
   & Multidisciplinary Activities; Directorate For Engineering [1137172]
   Funding Source: National Science Foundation
FX This work was supported in part by ONR Grant N000141310450 and NSF
   Grants EFRI-1137172 and IIP-1343402.
CR [Anonymous], CVPR
   [Anonymous], 2011, CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], 2012, BMVC
   [Anonymous], ACM SIGGRAPH
   [Anonymous], 2013, CVPR
   [Anonymous], 2014, ECCV
   [Anonymous], 2014, P EUR C COMP VIS ZUR
   [Anonymous], 2001, ICCV
   [Anonymous], 2008, CVPR
   [Anonymous], 2013, ICCV
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Boulanger J, 2007, IEEE T PATTERN ANAL, V29, P1096, DOI 10.1109/TPAMI.2007.1064
   Chang H., 2004, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004, V1, P1063
   Cui Y., 2010, CVPR
   Cui Z., 2014, ECCV
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Fransens R, 2007, COMPUT VIS IMAGE UND, V106, P106, DOI 10.1016/j.cviu.2005.09.011
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Huang Jinggang., 1999, CVPR
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Kiechle M., 2013, ICCV
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lee H., 2013, CVPR
   Li J., 2014, CVPR
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Schuon S., 2009, CVPR
   Shan Q, 2008, ACM SIGGRAPH ASIA
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shi B., 2014, ECCV
   Su D, 2004, COMPUT GRAPH FORUM, V23, P189, DOI 10.1111/j.1467-8659.2004.00752.x
   SUN J, 2008, CVPR, P2471
   Tai Y.W., 2010, CVPR
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang C.-Y., 2013, ICCV
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhu Y., 2014, CVPR
NR 42
TC 8
Z9 11
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 91
EP 102
DI 10.1016/j.jvcir.2015.11.015
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600008
OA Bronze
DA 2024-07-18
ER

PT J
AU Xue, BD
   Cao, L
   Han, DH
   Bai, XZ
   Zhou, FG
   Jiang, ZG
AF Xue, Bindang
   Cao, Lei
   Han, Donghai
   Bai, Xiangzhi
   Zhou, Fugen
   Jiang, Zhiguo
TI A DAISY descriptor based multi-view stereo method for large-scale scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; 3D reconstruction; Multi-view stereo; Large-scale;
   DAISY descriptor; Photometric discrepancy function; Feature matching;
   Feature point growing
ID RECONSTRUCTION
AB Normalized cross-correlation (NCC) has been widely used as the matching cost function in multi-view stereo methods. However, NCC is vulnerable in the occlusion area and edge region of large-scale scenes because of color distortion and illumination changes. To alleviate the above problems, we present an improved patch based multi-view stereo method by introducing a photometric discrepancy function based on DAISY descriptor. In the patch extraction stage, a new corresponding point matching method based on the DAISY descriptor is proposed and the epipolar constraint is used to filter mismatched points. In the patch optimization stage, a photometric discrepancy function based on DAISY descriptor is proposed to measure the photo-consistency among reconstructed patches to identify reliable patches. Finally, dense patches are obtained by expanding sparse patches with global visibility information and patch optimization. Experimental results show that the proposed algorithm obtains better reconstruction results in occlusion and edge regions of large-scale scenes. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Xue, Bindang; Cao, Lei; Han, Donghai; Bai, Xiangzhi; Zhou, Fugen; Jiang, Zhiguo] Beihang Univ, Image Proc Ctr, Beijing 100191, Peoples R China.
C3 Beihang University
RP Xue, BD (corresponding author), Beihang Univ, Image Proc Ctr, Beijing 100191, Peoples R China.
EM xuebd@buaa.edu.cn
FU Innovation Foundation of AVIC [CXY2012BH02]; Innovation Funds of Beihang
   University for PhD Students; Scholarship Award for Excellent Doctor
   Student granted by Ministry of Education; Weishi Foundation of BUAA
   [YWF-11-03-Q-070]
FX This work is partly supported by the Innovation Foundation of AVIC (No.
   CXY2012BH02), the Innovation Funds of Beihang University for PhD
   Students, the Scholarship Award for Excellent Doctor Student granted by
   Ministry of Education, the Weishi Foundation of BUAA (YWF-11-03-Q-070).
CR Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Campbell Neill DF, 2008, EUR C COMP VIS, P766
   Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Goesele M, 2007, IEEE I CONF COMP VIS, P825, DOI 10.1109/iccv.2007.4408933
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   Seitz SM, 1999, INT J COMPUT VISION, V35, P151, DOI 10.1023/A:1008176507526
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Shi L.M., 2011, ACTA AUTOM SINICA, V37, P561
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   STARCK J., 2006, BMVC
   Tola E, 2008, PROC CVPR IEEE, P2578
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Vogiatzis G, 2005, PROC CVPR IEEE, P391
   Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712
   Wu TP, 2010, PROC CVPR IEEE, P1482, DOI 10.1109/CVPR.2010.5539796
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
NR 29
TC 4
Z9 4
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 15
EP 24
DI 10.1016/j.jvcir.2015.11.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600002
DA 2024-07-18
ER

PT J
AU Ghosh, D
   Kaabouch, N
AF Ghosh, Debabrata
   Kaabouch, Naima
TI A survey on image mosaicing techniques
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image mosaicing; Registration; Blending; Geometric transformation;
   Homography; Low-level feature; Transition smoothening; Optimal seam
ID REGISTRATION
AB Image mosaicing, the process of obtaining a wider field-of-view of a scene from a sequence of partial views, has been an attractive research area because of its wide range of applications, including motion detection, resolution enhancement, monitoring global land usage, and medical imaging. A number of image mosaicing algorithms have been proposed over the last two decades. This paper provides an in-depth survey of the existing image mosaicing algorithms by classifying them into several groups. For each group, the fundamental concepts are first explained and then the modifications made to the basic concepts by different researchers are explained. Furthermore, this paper also discusses the advantages and disadvantages of all the mosaicing groups. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ghosh, Debabrata; Kaabouch, Naima] Univ N Dakota, Dept Elect Engn, Grand Forks, ND 58201 USA.
C3 University of North Dakota Grand Forks
RP Ghosh, D (corresponding author), Univ N Dakota, Dept Elect Engn, Grand Forks, ND 58201 USA.
EM debabrata.ghosh@my.und.edu
OI Ghosh, Debabrata/0000-0002-4603-1238
CR Abraham R, 2013, INT C ADV COMPUT COM, P63, DOI 10.1109/ACCT.2013.47
   [Anonymous], 2012, P 42 AIAA FLUID DYNA
   [Anonymous], 2009, TENCON 2009-2009 IEEE Region 10 Conference
   Azzari P, 2008, LECT NOTES COMPUT SC, V5099, P413, DOI 10.1007/978-3-540-69905-7_47
   Azzari P, 2008, LECT NOTES COMPUT SC, V5259, P89, DOI 10.1007/978-3-540-88458-3_9
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Behrens A, 2010, I S BIOMED IMAGING, P1305, DOI 10.1109/ISBI.2010.5490236
   Berberidis K., 2002, SIGN PROC C 11 2002, P1
   Bevilacqua A, 2007, LECT NOTES COMPUT SC, V4633, P501
   Bhat KS, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1577, DOI 10.1109/ICME.2000.871070
   Bind V. S., 2013, PROC INT J ADV COMPU, P263
   Bind V. S., 2013, ROBUST TECHNIQUES
   Botterill T., 2010, IM VIS COMP NZ IVCNZ, DOI DOI 10.1109/IVCNZ.2010.6148850
   Choi YH, 2002, 2002 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P74, DOI 10.1109/ICCE.2002.1013933
   Dame A, 2011, IEEE IMAGE PROC, P1493, DOI 10.1109/ICIP.2011.6115726
   de Cesare C., 2008, OCEANS, V2008, P1
   Deshmukh M., 2011, International Journal of Image Processing, V5, P245
   Dou Liqian, 2010, Proceedings of the 2010 International Conference on Computer and Information Application (ICCIA 2010), P29, DOI 10.1109/ICCIA.2010.6141528
   El-Saban M, 2011, IEEE IMAGE PROC, P1481, DOI 10.1109/ICIP.2011.6115723
   Fitzpatrick JM, 2000, HDB MED IMAGING, V2, P447, DOI DOI 10.1117/3.831079.CH8
   GAO G, 2007, 2 INT C INN COMP INF, P471
   Geng N., 2012, TELKOMNIKA Indonesian Journal of Electrical Engineering, V10, P2183, DOI [DOI 10.11591/TELKOMNIKA.V10I8.1658, 10.11591/telkomnika.v10i8.1658]
   Ghannam S, 2013, INT J ADV COMPUT SC, V4, P94
   Ghosh D., 2014, COMPUT INFORM SCI, V7, P68, DOI [10.5539/cis.v7n2p68, DOI 10.5539/cis.v7n2p68]
   Ghosh Debabrata, 2013, INT J SCI ENG RES, V4
   Gong JH, 2012, 2012 INTERNATIONAL CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (LCWAMTIP), P432, DOI 10.1109/ICWAMTIP.2012.6413530
   Gracias N, 2009, IMAGE VISION COMPUT, V27, P597, DOI 10.1016/j.imavis.2008.04.014
   Gutierrez R. Prados, 2014, IMAGE BLENDING TECHN
   Hu S., 2006, WORLD C INT CONTR AU, P10361
   IRANI M, 1995, SIGNAL PROCESS-IMAGE, V7, P529, DOI 10.1016/0923-5965(95)00022-1
   Islam M., 2013, COMPUTER TECHNOLOGY, V4, P79
   Jain D. K., 2012, Proceedings of the 2012 International Conference on Communication Systems and Network Technologies (CSNT 2012), P79, DOI 10.1109/CSNT.2012.27
   Jain P., 2013, INT J COMPUT ENG RES, V3
   Jeon S., 2007, PROC 6 IEEE ACM INT, P265, DOI [10.1109/ISMAR.2007.4538859, DOI 10.1109/ISMAR.2007.4538859]
   Jichao Jiao, 2011, 2011 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P160, DOI 10.1109/CSAE.2011.5952825
   Joshi H., 2013, INT C COMP SCI INF T
   Joshi H., 2013, INT JN ADV RES COMPU, V2
   Kovalsky SZ, 2007, 2007 IEEE/SP 14TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P561, DOI 10.1109/SSP.2007.4301321
   Lapel D. P., 2004, IMAGE MOSISACING
   Lei Yang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P846, DOI 10.1109/CISP.2011.6100279
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Li YF, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P568, DOI 10.1109/ICALIP.2008.4589984
   Liang Pei, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P978, DOI 10.1109/CISP.2010.5646931
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas A, 2010, PROC IEEE INT SYMP, P3545, DOI 10.1109/ISIE.2010.5637453
   Miao Ligang, 2011, Proceedings of the 2011 2nd International Conference on Intelligent Control and Information Processing (ICICIP), P1094, DOI 10.1109/ICICIP.2011.6008422
   Miranda-Luna R, 2008, IEEE T BIO-MED ENG, V55, P541, DOI 10.1109/TBME.2007.903520
   Nemra A, 2009, INT S MECHATR APPLIC, P529
   Okumura KI, 2013, IEEE INT C INT ROBOT, P2665, DOI 10.1109/IROS.2013.6696732
   Pandey A., 2013, India Conference (INDICON), 2013 Annual IEEE, P1
   Park S., 2012, IS T SPIE ELECT IMAG
   Patel M.H.M., 2012, INT J ENG RES TECHNO
   Peng Kang, 2011, 2011 International Conference on Multimedia Technology, P155
   Prescott J, 2006, I S BIOMED IMAGING, P1284
   Ramachandran M, 2006, IEEE IMAGE PROC, P345, DOI 10.1109/ICIP.2006.313164
   Rong W, 2009, 2009 24TH INTERNATIONAL CONFERENCE IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2009), P271, DOI 10.1109/IVCNZ.2009.5378399
   Sreyas S. T., 2012, P 8 IND C COMP VIS, P53
   Suzuki T., 2010, Proceedings of the SICE 2010 - 49th Annual Conference of the Society of Instrument and Control Engineers of Japan, P2960
   Szeliski R., 2011, 2011 IEEE INT C COMP, P1
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Vaghela D., 2014, INT J ADV RES COMPUT, V2
   Vercauteren T, 2005, LECT NOTES COMPUT SC, V3749, P753
   Vercauteren T., 2008, BIOMEDICAL OPTICA
   Vivet M., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P577, DOI 10.1109/ISM.2011.102
   Vivet M, 2009, LECT NOTES COMPUT SC, V5524, P144, DOI 10.1007/978-3-642-02172-5_20
   Wang C., 2009, Ensuring data storage security in Cloud Computing, P1
   Wang X., 2012, RECENT ADV COMPUTER, P757
   Wen HY, 2008, ISISE 2008: INTERNATIONAL SYMPOSIUM ON INFORMATION SCIENCE AND ENGINEERING, VOL 1, P497, DOI 10.1109/ISISE.2008.293
   Xiao Jiangjian., 2005, WACV MOTION, V2, P215
   Xie HJ, 2003, COMPUT GEOSCI-UK, V29, P1045, DOI 10.1016/S0098-3004(03)00104-3
   Xiong YE, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P432, DOI 10.1109/ISM.2009.92
   Xiong YL, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P69, DOI 10.1109/ACV.1998.732860
   YANG Fan, 2012, J COMPUTATIONAL INFO, p[8, 2647]
   Yao L, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P848, DOI 10.1109/KAMW.2008.4810624
   Zagrouba E, 2009, MACH VISION APPL, V20, P139, DOI 10.1007/s00138-007-0114-y
   Zhao Feng., 2006, 2006 IEEE INT C ACOU, V2, DOI 10.1109/ICASSP.2006.1660446
   Zhu J, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/926312
NR 77
TC 117
Z9 132
U1 6
U2 62
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 1
EP 11
DI 10.1016/j.jvcir.2015.10.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400001
DA 2024-07-18
ER

PT J
AU Chang, RI
   Su, CY
AF Chang, Ray-I
   Su, Chung-Yuan
TI Color gradient vectorization for SVG compression of comic image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SVG; Vector image; Comic compression; Color gradient; Color gradient
   vectorization; Color clustering; Improved vector contour searching;
   Middle point detection
AB In past years, different raster-to-vector methods were proposed to convert bitmap images to SVG format. However, they did not consider the color gradient (CG) that frequently appears in the comic image. Their results needed multiple divided color regions to represent a single CG region. It produced poor perceptual quality and large SVG size. In this paper, we propose the CGV (CG vectorization) method to resolve this problem. CGV first applies a linear-time algorithm to identify the CG vector for representing the color and the direction of CG in each region. Then, we merge neighboring regions those have the same CG vector as a large CG region and represent it by a single path of SVG with linear gradient syntax. Experimental results show that our method outperforms other state-of-the-art SVG vectorization systems in terms of not only SVG size but also perceptual quality. For example, the averages SSIM are 0.85 by Autotrace, 0.92 by Autotrace+Merge, 0.88 by SWaterG, 0.91 by Vector Magic and 0.94 by our method. It is about 57.23% for our average space saving. Moreover, comparing with other systems' results, our SVG files take the shortest time (about 0.12 s in average) of rendering on handheld devices. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chang, Ray-I; Su, Chung-Yuan] Natl Taiwan Univ, Dept Engn Sci & Ocean Engn, Taipei 106, Taiwan.
C3 National Taiwan University
RP Su, CY (corresponding author), Natl Taiwan Univ, Dept Engn Sci & Ocean Engn, 1,Roosevelt Rd,Sec 4, Taipei 106, Taiwan.
EM rayichang@ntu.edu.tw; d98525007@ntu.edu.tw
RI Chang, Ray-I/A-6197-2009
OI Chang, Ray-I/0000-0002-8737-7227
FU NSC Taiwan [102-2410-H-002-170-MY3]
FX This work was partially supported by NSC Taiwan under grant
   102-2410-H-002-170-MY3. The authors wish to express the appreciation to
   Mr. Po-Yen Pan for his help with the experiments.
CR Battiato S, 2005, PROC SPIE, V5670, P23, DOI 10.1117/12.586687
   Battiato S., 2004, P 20 SPRING C COMP G, P185
   Chang RI, 2008, LECT NOTES COMPUT SC, V5353, P563, DOI 10.1007/978-3-540-89796-5_58
   Chen HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P593
   Kansal R, 2015, VISUAL COMPUT, V31, P717, DOI 10.1007/s00371-014-0997-3
   Kawamura K, 2005, IEEE IMAGE PROC, P2845
   Kawamura K, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P335, DOI 10.1109/ICME.2004.1394197
   Lecot G., 2006, P EUR S REND EGSR, P349
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Shiao YH, 2007, J DIGIT IMAGING, V20, P149, DOI 10.1007/s10278-007-9013-z
   Skora D., 2004, P 3 INT S NONPH AN R, P121, DOI DOI 10.1145/987657.987677
   Sun J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239462
   Sykora D, 2005, IMAGE VISION COMPUT, V23, P767, DOI 10.1016/j.imavis.2005.05.010
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Zhang SH, 2009, IEEE T VIS COMPUT GR, V15, P618, DOI 10.1109/TVCG.2009.9
NR 16
TC 4
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 235
EP 246
DI 10.1016/j.jvcir.2015.09.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700021
DA 2024-07-18
ER

PT J
AU Liu, Z
   Zhu, JK
   Bu, JJ
   Chen, C
AF Liu, Zhao
   Zhu, Jianke
   Bu, Jiajun
   Chen, Chun
TI A survey of human pose estimation: The body parts parsing based methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human pose estimation; Articulated object detection; Survey; Body parts
   parsing; Motion capture; Feature Extraction; Appearance models;
   Structure models
ID FLEXIBLE MIXTURES; HUMAN MOTION; RECOGNITION; MODEL; SHAPE
AB Estimating human pose from videos and image sequences is not only an important computer vision problem, but also plays very critical role in many real-world applications. Main challenges for human pose estimation are variation of body poses, complicated background and depth ambiguities. To solve these problems, considerable research efforts have been devoted to the related fields. In this survey, we focus our attention on the recent advances in vision-based human pose estimation. We first present a general framework of human pose estimation, and then go through the latest technical progress on each stage. Finally, we discuss the limitations of the existing approaches and foresee the future directions to be explored. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liu, Zhao; Zhu, Jianke; Bu, Jiajun; Chen, Chun] Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Liu, Z (corresponding author), Zhejiang Univ, Coll Comp Sci, Hangzhou 310027, Zhejiang, Peoples R China.
EM liuzhao@zju.edu.cn; jkzhu@zju.edu.cn; bjj@zju.edu.cn; chenc@zju.edu.cn
RI liu, zhao/GXV-6141-2022
FU National Natural Science Foundation of China [61103105]; National High
   Technology Research and Development Program of China [2013AA040601]
FX The authors appreciate the reviewers for their extensive and informative
   comments for the improvement of this manuscript. This work was supported
   in part by National Natural Science Foundation of China under the Grant
   (61103105), National High Technology Research and Development Program of
   China (2013AA040601).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Anderson F, 2010, ANN REV CYBERTHERAPY, V8, P181
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2013 IEEE C COMP VIS
   [Anonymous], BRIT MACH VIS C
   [Anonymous], VISUAL ANAL HUMAN LO
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2012, EUR C COMP VIS
   [Anonymous], BRIT MACH VIS C
   [Anonymous], BRIT MACH VIS C
   [Anonymous], EUR C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], MOBILE UBIQUITOUS SY
   [Anonymous], P IREP S BULK POW SY
   [Anonymous], EUR C COMP VIS
   [Anonymous], P INT C ROB AUT
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2014, CVPR
   [Anonymous], 2010, INT J COMPUT VISION, DOI DOI 10.1007/s11263-008-0204-y
   [Anonymous], P INT C COMP VIS
   [Anonymous], ACM SIGGRAPH C
   [Anonymous], BRIT MACH VIS C
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Burenius M, 2013, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2013.464
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   Chen C, 2011, IEEE T VIS COMPUT GR, V17, P1676, DOI 10.1109/TVCG.2010.272
   Chen X., 2014, ARTICULATED POSE EST
   Chen Y, 2010, LECT NOTES COMPUT SC, V6313, P300
   Cherian A, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.302
   Cho NG, 2013, PATTERN RECOGN, V46, P649, DOI 10.1016/j.patcog.2012.09.006
   Dantone M, 2013, PROC CVPR IEEE, P3041, DOI 10.1109/CVPR.2013.391
   Eichner M, 2012, INT J COMPUT VISION, V99, P190, DOI 10.1007/s11263-012-0524-9
   Eichner M, 2010, LECT NOTES COMPUT SC, V6311, P228, DOI 10.1007/978-3-642-15549-9_17
   Eichner Marcin., 2009, BMVC
   Ennis C, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778828
   Fathi A, 2007, IEEE I CONF COMP VIS, P1917
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Gall J, 2010, LECT NOTES COMPUT SC, V6313, P425
   Ganapathi V, 2012, LECT NOTES COMPUT SC, V7577, P738, DOI 10.1007/978-3-642-33783-3_53
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Gkioxari G, 2013, PROC CVPR IEEE, P3342, DOI 10.1109/CVPR.2013.429
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Guan P, 2010, LECT NOTES COMPUT SC, V6311, P285, DOI 10.1007/978-3-642-15549-9_21
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Helten Thomas, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P188, DOI 10.1007/978-3-642-44964-2_9
   Helten T, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P279, DOI 10.1109/3DV.2013.44
   Huayan Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2433, DOI 10.1109/CVPR.2011.5995722
   Ionescu C, 2011, IEEE I CONF COMP VIS, P2220, DOI 10.1109/ICCV.2011.6126500
   Jiu MY, 2014, PATTERN RECOGN LETT, V50, P122, DOI 10.1016/j.patrec.2013.09.021
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Jonathan Tompson, 2014, P C NEUR INF PROC SY
   Kaliamoorthi P, 2013, PATTERN RECOGN, V46, P1501, DOI 10.1016/j.patcog.2012.11.005
   Karlinsky L, 2012, LECT NOTES COMPUT SC, V7574, P326, DOI 10.1007/978-3-642-33712-3_24
   Kim J, 2011, PROC CVPR IEEE, P1553, DOI 10.1109/CVPR.2011.5995526
   Klette R, 2008, COMPUT IMAGING VIS, V36, P1
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4
   Palacios JM, 2013, SENSORS-BASEL, V13, P11842, DOI 10.3390/s130911842
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Micusik B, 2010, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2010.5539786
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Ouyang WL, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.299
   Pishchulin L, 2013, IEEE INT C COMPUTER, P1
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramanan D., 2006, NIPS
   Salzmann M., 2010, Adv. Neural Inf. Process. Syst., V23, P2065
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607
   Sapp B, 2010, PROC CVPR IEEE, P422, DOI 10.1109/CVPR.2010.5540182
   Sapp B, 2010, LECT NOTES COMPUT SC, V6312, P406, DOI 10.1007/978-3-642-15552-9_30
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Sminchisescu C., 2006, AVSBS06, P76
   Srinivasan P, 2007, LECT NOTES COMPUT SC, V4679, P153
   Stavens D, 2010, PROC CVPR IEEE, P1649, DOI 10.1109/CVPR.2010.5539773
   Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Taylor J, 2012, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.2012.6247664
   Tokola R, 2013, IEEE I CONF COMP VIS, P2424, DOI 10.1109/ICCV.2013.301
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17
   Trankner D., 2014, Proceedings of the National Academy of Sciences of the United States of America, P1
   Wang F, 2013, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2013.83
   Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519
   Wei XLK, 2009, IEEE I CONF COMP VIS, P1873, DOI 10.1109/ICCV.2009.5459415
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weiss DavidJ., 2013, Advances in Neural Information Processing Systems, P953
   Werghi N, 2007, IEEE T SYST MAN CY C, V37, P1122, DOI 10.1109/TSMCC.2007.905808
   Wool H. Y., 2009, INT C TECHNICAL POST, P1
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yang Y, 2012, PROC CVPR IEEE, P3522, DOI 10.1109/CVPR.2012.6248095
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235
   Zuffi S, 2013, IEEE I CONF COMP VIS, P3312, DOI 10.1109/ICCV.2013.411
NR 101
TC 74
Z9 84
U1 4
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 10
EP 19
DI 10.1016/j.jvcir.2015.06.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300002
DA 2024-07-18
ER

PT J
AU Li, L
   Yan, CC
   Ji, W
   Chen, BW
   Jiang, SQ
   Huang, QM
AF Li, Liang
   Yan, Chenggang Clarence
   Ji, Wen
   Chen, Bo-Wei
   Jiang, Shuqiang
   Huang, Qingming
TI LSH-based semantic dictionary learning for large scale image
   understanding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Locality sensitive hashing; Online dictionary learning; Spatial pyramid
   matching; Image understanding
ID PARALLEL FRAMEWORK; HEVC
AB Large scale image understanding is a challenging but significant task to comprehend image contents on the internet. The de-facto standard methods based on machine learning or computer vision still suffer from a phenomenon of visual polysemia and concept polymorphism (VPCP). To resolve the VPCP, semantic dictionary has been proposed to characterize the membership distribution between visual appearances and semantic concepts. In this paper, we propose an online semantic dictionary learning algorithm on the base of both locality sensitive hashing (LSH) and stochastic approximations, which can scale up to large scale datasets with millions of training samples and speedup the efficiency of follow-up processing. With the help of the LSH-based semantic dictionary, we develop an extension of the spatial pyramid matching (SPM) kernel method by generalizing the dictionary as a basic semantic description. The efficiency of our approach is validated in the experiments of web-scale semantic image search and image classification on the ImageNet dataset and Caltech-256 dataset. (C) 2015 Published by Elsevier Inc.
C1 [Li, Liang; Huang, Qingming] Chinese Acad Sci, Key Lab Big Data Min & Knowledge Management, Beijing, Peoples R China.
   [Yan, Chenggang Clarence] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Ji, Wen; Jiang, Shuqiang; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Chen, Bo-Wei] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
C3 Chinese Academy of Sciences; Tsinghua University; Chinese Academy of
   Sciences; Institute of Computing Technology, CAS; Princeton University
RP Yan, CC (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
EM andy.cg.yan@gmail.com
OI Li, Liang/0000-0002-1943-8219
FU National Basic Research Program of China (973 Program) [2012CB316400,
   2015CB351802]; National 275 Natural Science Foundation of China
   [61332016, 61025011, 61402431, 61472203]; China Postdoctoral Science
   Foundation
FX This work was supported in part by National Basic Research Program of
   China (973 Program): 2012CB316400 and 2015CB351802, in part by National
   275 Natural Science Foundation of China: 61332016, 61025011, 61402431,
   and 61472203, in part by Project Funded by China Postdoctoral Science
   Foundation.
CR [Anonymous], 2008, NIPS
   [Anonymous], 2009, NIPS
   [Anonymous], P ECCV HER CRET GREE
   [Anonymous], ICCV
   [Anonymous], P NIPS
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bronstein AM, 2010, LECT NOTES COMPUT SC, V6312, P197, DOI 10.1007/978-3-642-15552-9_15
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li L., 2011, CVPR
   Li L., 2014, P INT ICST C GAM THE
   Li L, 2013, IEEE MULTIMEDIA, V20, P13, DOI 10.1109/MMUL.2013.15
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Norouzi M.E., 2011, ICML
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Qi GJ, 2011, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.2011.5995312
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Torralba A., 2008, PROC CVPR 08, P1
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang J., TPAMI
   Weinberger K.Q., 2008, Proceedings of the 25th international conference on Machine learning, P1160, DOI DOI 10.1145/1390156.1390302
   Wu Z., 2010, ACM MULTIMEDIA
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
NR 40
TC 7
Z9 7
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 231
EP 236
DI 10.1016/j.jvcir.2015.06.008
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600021
DA 2024-07-18
ER

PT J
AU Yang, B
   Yu, HM
   Hu, R
AF Yang, Bai
   Yu, Huimin
   Hu, Roland
TI Unsupervised regions based segmentation using object discovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cosegmentation; Segmentation; Regions based; Object discovery; Saliency;
   Maximal spanning tree; Structural constraint; Combinatorial optimization
ID IMAGE; COSEGMENTATION
AB We present a new unsupervised algorithm to discovery and segment out common objects from multiple images. Compared with previous cosegmentation methods, our algorithm performs well even when the appearance variations in the foregrounds are more substantial than those in some areas of the backgrounds. Our algorithm mainly includes two parts: the foreground object discovery scheme and the iterative region allocation algorithm. Two terms, a region-saliency prior and a region-repeatness measure, are introduced in the foreground object discovery scheme to detect the foregrounds without any supervisory information. The iterative region allocation algorithm searches the optimal solution for the final segmentation with the constraints from a maximal spanning tree, and an effective color-based model is utilized during this process. The comparative experimental results show that the proposed algorithm matches or outperforms several previous methods on several standard datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Yang, Bai; Yu, Huimin; Hu, Roland] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yu, Huimin] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Yu, HM (corresponding author), Zhejiang Univ, Inst Informat & Commun Engn, Dept Informat Sci & Elect Engn, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM yangbai@zju.edu.cn; yhm2005@zju.edu.cn; haoji_hu@zju.edu.cn
FU NSFC [61471321]; National Key Basic Research Project of China (973
   Program) [2012CB316400]; Zhejiang Province Science and Technology Plan
   Project [2013C310035]
FX This work was supported by NSFC under Grant No. 61471321, a National Key
   Basic Research Project of China (973 Program No. 2012CB316400) and
   Zhejiang Province Science and Technology Plan Project (Program No.
   2013C310035).
CR [Anonymous], 2010, CALTECH UCSD BIRDS 2
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x
   Bhardwaj A, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1321
   Bhattacharyya A, 1946, SANKHYA, V7, P401
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Cour T, 2005, PROC CVPR IEEE, P1124
   Cui J., 2008, Proc. of the IEEE Conference on Computer Vision and Pattern Recognition CVPR, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Joulin A, 2012, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2012.6247719
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Lampert CH, 2009, IEEE T PATTERN ANAL, V31, P2129, DOI 10.1109/TPAMI.2009.144
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Meyer F, 2001, LECT NOTES COMPUT SC, V2106, P161
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Russakovsky O, 2010, PROC CVPR IEEE, P1070, DOI 10.1109/CVPR.2010.5540097
   Sandholm T, 2003, ARTIF INTELL, V145, P33, DOI 10.1016/S0004-3702(03)00015-8
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Vicente S, 2010, LECT NOTES COMPUT SC, V6312, P465, DOI 10.1007/978-3-642-15552-9_34
   Vijayanarasimhan S, 2011, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2011.5995545
NR 37
TC 8
Z9 8
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 125
EP 137
DI 10.1016/j.jvcir.2015.06.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600011
DA 2024-07-18
ER

PT J
AU Zhu, JY
   Wang, ZY
   Zhong, R
   Qu, SM
AF Zhu, Jing-Ya
   Wang, Zhong-Yuan
   Zhong, Rui
   Qu, Shen-Ming
TI Dictionary based surveillance image compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video surveillance; Image compression; Dictionary learning; Sparse
   representation; DCF transform; Still images; JPEG; JPEG2000
AB Common image compression techniques suitable for general purpose may be less effective for such specific applications as video surveillance. Since a stationed surveillance camera always targets at a fixed scene, its captured images exhibit high consistency in content or structure. In this paper, we propose a surveillance image compression technique via dictionary learning to fully exploit the constant characteristics of a target scene. This method transforms images over sparsely tailored over-complete dictionaries learned directly from image samples rather than a fixed one, and thus can approximate an image with fewer coefficients. A set of dictionaries trained off-line is applied for sparse representation. An adaptive image blocking method is developed so that the encoder can represent an image in a texture-aware way. Experimental results show that the proposed algorithm significantly outperforms JPEG and JPEG 2000 in terms of both quality of reconstructed images and compression ratio as well. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zhu, Jing-Ya; Wang, Zhong-Yuan; Zhong, Rui; Qu, Shen-Ming] Wuhan Univ, Sch Comp, NERCMS, Wuhan 430072, Peoples R China.
C3 Wuhan University
RP Wang, ZY (corresponding author), Wuhan Univ, Sch Comp, NERCMS, Wuhan 430072, Peoples R China.
EM wzy_hope@163.com
RI Wang, Zhongyuan/ABD-2189-2020; zhong, rui/HSZ-2549-2023
FU National Natural Science Foundation of China [61070080, 61170023,
   61172173, 61231015, 61303114, U1404618]; Natural Science Fund of Hubei
   Province [2015CE13406]; Fundamental Research Funds for the Central
   Universities [2042014kf0286, 2042014kf0212, 2042014kf0025,
   2042014kf0250]
FX The research was supported by the National Natural Science Foundation of
   China (61070080, 61170023, 61172173, 61231015, 61303114 and U1404618),
   the Natural Science Fund of Hubei Province (2015CE13406) and the
   Fundamental Research Funds for the Central Universities (2042014kf0286,
   2042014kf0212, 2042014kf0025, 2042014kf0250).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Duan L., 2012, ADV SCI LETT, V6, P646, DOI DOI 10.1166/ASL.2012.2279
   Horev I., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P592
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Skretting K, 2011, INT CONF ACOUST SPEE, P1517
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zepeda J, 2011, INT CONF ACOUST SPEE, P793
NR 10
TC 13
Z9 15
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 225
EP 230
DI 10.1016/j.jvcir.2015.07.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600020
DA 2024-07-18
ER

PT J
AU Qu, DH
   Ye, LL
   Sun, W
AF Qu, Duanhao
   Ye, Lili
   Sun, Wei
TI User-friendly secret image sharing scheme with verification ability
   based on block truncation coding and error diffusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Block truncation coding; Error diffusion;
   Meaningful shares; Loss less reconstruction; Verification ability; Low
   computation complexity; XOR operation
ID STEGANOGRAPHY
AB Conventional secret image sharing schemes, which are constructed based on Shamir's method, often suffer from random-liked shares, lossy reconstruction and high computation complexity. In addition, their generated shares are generally in original image format which may lead to more storage and suspicion from invaders. In this paper, we propose a user-friendly secret image sharing scheme based on block truncation coding (BTC) and error diffusion, where meaningful shares can be directly generated without any extra process. The meaningful shares by the proposed scheme are in BTC-compressed format which can reduce the capacity of transfer and storage. In the reconstructing phase, the secret image can be loss-lessly reconstructed by performing XOR operations on bit planes of sufficient BTC-compressed shares. Further, the proposed scheme provides extra verification ability to identify cheaters and check false shares. Theoretical analysis and simulation results demonstrate the feasibility of the proposed scheme. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Qu, Duanhao] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
   [Ye, Lili] Sun Yat Sen Univ, Sch Informat Management, Guangzhou 510006, Guangdong, Peoples R China.
   [Sun, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University; Sun Yat Sen University;
   Chinese Academy of Sciences; Institute of Information Engineering, CAS
RP Sun, W (corresponding author), Sun Yat Sen Univ, Sch Software, Guangzhou 510006, Guangdong, Peoples R China.
EM ouduanhao@163.com; 794499691@qq.com; sunwei@mail.sysu.edu.cn
FU Natural Science Foundation of Guangdong Province, China [S2013010013728]
FX This work was supported by Natural Science Foundation of Guangdong
   Province, China (Grant No. S2013010013728).
CR Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chen SK, 2012, J VIS COMMUN IMAGE R, V23, P677, DOI 10.1016/j.jvcir.2012.03.004
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chen WK, 2013, J SYST SOFTWARE, V86, P581, DOI 10.1016/j.jss.2012.09.040
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Dhara BC, 2012, J VIS COMMUN IMAGE R, V23, P313, DOI 10.1016/j.jvcir.2011.11.005
   Floyd R.W., 1976, An adaptive algorithm for spatial gray scale
   Gary M. R., 1979, COMPUTERS INTRACTABI
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Guo JM, 2008, ELECTRON LETT, V44, P462, DOI 10.1049/el:20080136
   Guo JM, 2014, IEEE T IMAGE PROCESS, V23, P1269, DOI 10.1109/TIP.2013.2257812
   Guo JM, 2012, IEEE T IMAGE PROCESS, V21, P4808, DOI 10.1109/TIP.2012.2210236
   Guo JM, 2010, IEEE T IMAGE PROCESS, V19, P2056, DOI 10.1109/TIP.2010.2045709
   Guo JM, 2010, IEEE T COMMUN, V58, P1667, DOI 10.1109/TCOMM.2010.06.090303
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hinek M. J., 2010, CRYPTANALYSIS RSA IT, V3
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Lee CF, 2010, J SYST SOFTWARE, V83, P832, DOI 10.1016/j.jss.2009.12.018
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ou DH, 2014, J VIS COMMUN IMAGE R, V25, P1222, DOI 10.1016/j.jvcir.2013.12.018
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Ulichney R., 1987, DIGITAL HALFTONING
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Wu YS, 2004, PATTERN RECOGN, V37, P1377, DOI 10.1016/j.patcog.2004.01.002
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Zhao R, 2009, COMPUT STAND INTER, V31, P252, DOI 10.1016/j.csi.2007.10.012
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 35
TC 8
Z9 8
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 46
EP 60
DI 10.1016/j.jvcir.2015.01.017
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100005
DA 2024-07-18
ER

PT J
AU Fan, ZZ
   Ni, M
   Zhu, Q
   Sun, CL
   Kang, LP
AF Fan, Zizhu
   Ni, Ming
   Zhu, Qi
   Sun, Chengli
   Kang, Lipan
TI L<sub>0</sub>-norm sparse representation based on modified genetic
   algorithm for face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Classification; Genetic algorithm; Face
   recognition; L-0-norm minimization; L-1-norm minimization; Modified GA
   (MGA); Optimization methods
ID EIGENFACES; PCA
AB The typical sparse representation for classification (SRC) exploits the training samples to represent the test samples, and classifies the test samples based on the representation results. SRC is essentially an L-0-norm minimization problem which can theoretically yield the sparsest representation and lead to the promising classification performance. We know that it is difficult to directly resolve L-0-norm minimization problem by applying usual optimization method. To effectively address this problem, we propose the L-0-norm based SRC by exploiting a modified genetic algorithm (GA), termed GASRC, in this paper. The basic idea of GASRC is that it modifies the traditional genetic algorithm and then uses the modified GA (MGA) to select a part of the training samples to represent a test sample. Compared with the conventional SRC based on L-1-norm optimization, GASRC can achieve better classification performance. Experiments on several popular real-world databases show the good classification effectiveness of our approach. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Fan, Zizhu; Ni, Ming; Kang, Lipan] East China Jiaotong Univ, Sch Basic Sci, Nanchang, Peoples R China.
   [Zhu, Qi] Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Technol, Nanjing 210016, Jiangsu, Peoples R China.
   [Sun, Chengli] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang, Peoples R China.
C3 East China Jiaotong University; Nanjing University of Aeronautics &
   Astronautics; Nanchang Hangkong University
RP Fan, ZZ (corresponding author), East China Jiaotong Univ, Sch Basic Sci, Nanchang, Peoples R China.
EM zzfan3@163.com
FU National Natural Science Foundation of China [61472138, 61263032,
   71262011, 11061014, 61300032, 61202276]; Science and Technology
   Foundation of Jiangxi Educational Committee of China [GJJ14375,
   KJLD12067]; China Postdoctoral Science Foundation [2012M520428]
FX This article is partly supported by National Natural Science Foundation
   of China under Grants Nos. 61472138, 61263032, 71262011, 11061014,
   61300032 and 61202276, Science and Technology Foundation of Jiangxi
   Educational Committee of China (GJJ14375, KJLD12067), as well as China
   Postdoctoral Science Foundation funded project (2012M520428).
CR [Anonymous], ICCV 2011 BARC SPAIN
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beveridge JR, 2009, IEEE T PATTERN ANAL, V31, P351, DOI 10.1109/TPAMI.2008.200
   Chen X., 2011, P 25 AAAI C ART INT, P313
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Estévez PA, 2009, IEEE T NEURAL NETWOR, V20, P189, DOI 10.1109/TNN.2008.2005601
   Fan ZZ, 2014, IEEE T NEUR NET LEAR, V25, P1538, DOI 10.1109/TNNLS.2013.2294492
   Fan ZZ, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033027
   Fan ZZ, 2011, IEEE T NEURAL NETWOR, V22, P1119, DOI 10.1109/TNN.2011.2152852
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Huang K., 2007, ADV NEURAL INFORM PR, V19
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Raymer ML, 2000, IEEE T EVOLUT COMPUT, V4, P164, DOI 10.1109/4235.850656
   Russell S., 2016, Artificial intelligence a modern approach
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2004, PATTERN RECOGN, V37, P1299, DOI 10.1016/j.patcog.2003.10.006
   Xu Y, 2007, NEUROCOMPUTING, V70, P1056, DOI 10.1016/j.neucom.2006.09.005
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang SQ, 2014, J VIS COMMUN IMAGE R, V25, P1878, DOI 10.1016/j.jvcir.2014.09.011
NR 31
TC 20
Z9 21
U1 1
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 15
EP 20
DI 10.1016/j.jvcir.2015.01.001
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000002
DA 2024-07-18
ER

PT J
AU Chen, WB
   Guo, GD
AF Chen, Wenbin
   Guo, Guodong
TI TriViews: A general framework to use 3D depth data effectively for
   action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; 3D depth data; RGB-D sensor; Kinect; TriViews
   framework; Fusion; PFA; Public databases
AB We present an effective framework to utilize 3D depth data for action recognition, called TriViews. It projects the 3D depth maps into three views, i.e., front, side, and top views. Under this framework, features can be extracted from each view, separately. Then the three views are combined to derive a complete description of the 3D data. To study the effectiveness and usefulness of the TriViews framework, we extract five different features, i.e., spatiotemporal interest points (STIP), dense trajectory shape (DT-Shape), dense trajectory motion boundary histograms (DT-MBH), skeleton trajectory shape (ST-Shape), and skeleton trajectory motion boundary histograms (ST-MBH). The first three features are representative for actions in intensity data but adapted to depth sequences. The last two are proposed by us, termed as skeleton-based features unique for 3D depth data. The RGB-D sensors, e.g., the Kinect, provide 3D positions of 20 skeleton joints and the evolution of each skeleton joint over time corresponds to one skeleton trajectory. Features aligned with the skeleton trajectory include shape descriptor (ST-Shape) and motion boundary histograms (ST-MBH), extracted to characterize the actions with sparse trajectories. The five features characterize action patterns from different aspects, among which the top three best features are selected and fused based on a probabilistic fusion approach (PFA). We evaluate the proposed framework on three challenging depth action datasets. The experimental results show that the proposed TriViews framework achieves the most accurate results for depth-based action recognition, better than the state-of-the-art methods on all three databases. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Chen, Wenbin; Guo, Guodong] W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Guo, GD (corresponding author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM guodong.guo@mail.wvu.edu
RI Guo, Guodong/M-5066-2015
OI Guo, Guodong/0000-0001-9583-0055
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], 2012, INT JOINT C NEURAL N, DOI [DOI 10.1109/IJCNN.2012.6252504, 10.1109/IJCNN.2012.6252504]
   [Anonymous], THESIS DELFT U TECHN
   [Anonymous], BRIT MACH VIS C
   [Anonymous], RECOGNIZING ACTIONS
   [Anonymous], JOINT ANGLES SIMILAR
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], 2009, BMVC 2009 BRIT MACH
   Azary S, 2013, IEEE COMPUT SOC CONF, P492, DOI 10.1109/CVPRW.2013.79
   Bingbing Ni, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1147, DOI 10.1109/ICCVW.2011.6130379
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Guo G. -D., 2008, IEEE COMPUTER SOC C, P1
   Harris C., 1988, ALVEY VISION C, P147151
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jia XF, 2012, INT C PATT RECOG, P3001
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Joshi Shantanu H, 2007, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2007, P1
   Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu L., 2013, 23 INT JOINT C ART I
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Miranda L., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P268, DOI 10.1109/SIBGRAPI.2012.44
   Ni BB, 2013, IEEE I CONF COMP VIS, P1361, DOI 10.1109/ICCV.2013.172
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Shabani A. H., 2012, 2012 Canadian Conference on Computer and Robot Vision, P468, DOI 10.1109/CRV.2012.69
   Shotton J., 2011, IEEE C COMPUTER VISI, P1
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Theodorakopoulos I, 2014, J VIS COMMUN IMAGE R, V25, P12, DOI 10.1016/j.jvcir.2013.03.008
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zhang H., 2011, P 2011 IEEE RSJ INT, P2044, DOI [DOI 10.1109/IROS.2011.6094489, 10.1109/IROS.2011.6094489]
   Zhao YX, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-15
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 51
TC 23
Z9 27
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 182
EP 191
DI 10.1016/j.jvcir.2014.11.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000016
DA 2024-07-18
ER

PT J
AU Guo, DY
   Tang, JH
   Cui, Y
   Ding, JD
   Zhao, CX
AF Guo, Dongyan
   Tang, Jinhui
   Cui, Ying
   Ding, Jundi
   Zhao, Chunxia
TI Saliency-based content-aware lifestyle image mosaics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image mosaic; Image saliency; Image resizing; Image retrieval; Image
   rendering; Image cropping; Feature extraction; Face segmentation
AB In this paper, a novel content-aware lifestyle image mosaic technique is proposed based on image saliency. The image saliency is used in the whole process of creating mosaics. Firstly, a novel energy map for variable-size tile decomposition is proposed by combining Neighborhood Inhomogeneity Factor and Graph-Based Visual Saliency. The target image is divided into small tiles with variable sizes based on the energy map. Secondly, saliency-weighted image retrieval is introduced to choose the tile images from a certain image database. Different aspect ratio between the tile and the corresponding tile image may lead to obvious distortion. Therefore, before filled into the tile, the chosen tile image is resized by seam carving to change its aspect ratio. At last, color correction is done on the mosaic result to improve the color similarity. Compared with other mosaic methods, the proposed technique creates much better mosaics in visual aspect. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Guo, Dongyan; Tang, Jinhui; Cui, Ying; Ding, Jundi; Zhao, Chunxia] Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Tang, JH (corresponding author), Nanjing Univ Sci & Technol, Sch Engn & Comp Sci, Nanjing 210094, Jiangsu, Peoples R China.
EM jinhuitang@mail.njust.edu.cn
RI Tang, Jinhui/KBR-0891-2024
OI Tang, Jinhui/0000-0001-9008-222X
FU 973 Program [2012CB316304]; NSFC [61103058, 61103059, 61173104,
   61272220]; NSF of Jiangsu Province [BK2011700, BK2012399]; Open Project
   Program of the National Laboratory of Pattern Recognition (NLPR)
FX This work is supported in part by 973 Program under Grant 2012CB316304,
   in part by the NSFC under Grants 61103058, 61103059, 61173104 and
   61272220, in part by the NSF of Jiangsu Province under Grants BK2011700,
   BK2012399 and Open Project Program of the National Laboratory of Pattern
   Recognition (NLPR).
CR Achanta R., 2009, ACM SIGGRAPH AS
   Achanta R., 2009, IEEE C IM PROC
   [Anonymous], 2006, NIPS
   [Anonymous], P 2 INT C INT SCI
   [Anonymous], WORKSH COMP ATT APPL
   [Anonymous], 2009, CVPR
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Cui Y, 2012, INT J ADV ROBOT SYST, V9, DOI 10.5772/52207
   de Bruijn O., 2000, Proceedings of the Working Conference on Advanced Visual Interfaces (AVI '00), P189, DOI DOI 10.1145/345513.345309
   Ding J., 2009, AS C COMP VIS
   Finkelstein A., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P11, DOI 10.1007/BFb0053259
   Guo D., 2013, ADV MULTIMEDIA MODEL, V7732, P436
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Nishiyama M., 2009, P 17 ACM INT C MULTI, P669
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Silvers R., 1997, Photomosaics
   Tran N., 1999, P S APPL COMP
   Williams C.K.I., PASCAL VISUAL OBJECT
NR 19
TC 5
Z9 7
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 192
EP 199
DI 10.1016/j.jvcir.2014.11.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000017
DA 2024-07-18
ER

PT J
AU Faria, FA
   Perre, P
   Zucchi, RA
   Jorge, LR
   Lewinsohn, TM
   Rocha, A
   Torres, RD
AF Faria, F. A.
   Perre, P.
   Zucchi, R. A.
   Jorge, L. R.
   Lewinsohn, T. M.
   Rocha, A.
   Torres, R. da S.
TI Automatic identification of fruit flies (Diptera: Tephritidae)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anastrepha; Multimodal fusion; Machine learning; Fraterculus group;
   Automatic identification; Classifier selection; Fruit flies; Wing and
   aculeus images
ID FRATERCULUS COMPLEX DIPTERA; TEXTURE FEATURES; IMAGE; COLOR; RETRIEVAL;
   CLASSIFICATION; RECOGNITION; FRAMEWORK; SELECTION; WHEAT
AB Fruit flies are pests of major economic importance in agriculture. Among these pests it is possible to highlight some species of genus Anastrepha, which attack a wide range of fruits, and are widely distributed in the American tropics and subtropics. Researchers seek to identify fruit flies in order to implement management and control programs as well as quarantine restrictions. However, fruit fly identification is manually performed by scarce specialists through analysis of morphological features of the mesonotum, wing, and aculeus. Our objective is to find solid knowledge that can serve as a basis for the development of a sounding automatic identification system of the Anastrepha fraterculus group, which is of high economic importance in Brazil. Wing and aculeus images datasets from three specimens have been used in this work. The experiments using a classifier multimodal fusion approach shows promising effectiveness results for identification of these fruit flies, with more than 98% classification accuracy, a remarkable result for this difficult problem. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Faria, F. A.; Rocha, A.; Torres, R. da S.] Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
   [Perre, P.] Univ Sao Paulo, Dept Genet & Evolutionary Biol, BR-05508 Sao Paulo, Brazil.
   [Zucchi, R. A.] Univ Sao Paulo, Luiz de Queiroz Coll Agr, BR-05508 Sao Paulo, Brazil.
   [Jorge, L. R.; Lewinsohn, T. M.] Univ Estadual Campinas, Inst Biol, Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas; Universidade de Sao Paulo;
   Universidade de Sao Paulo; Universidade de Sao Paulo; Universidade
   Estadual de Campinas
RP Faria, FA (corresponding author), Univ Estadual Campinas, Inst Comp, Campinas, SP, Brazil.
EM ffaria@ic.unicamp.br; pperre01@gmail.com; razucchi@usp.br;
   leonardorejorge@gmail.com; thomasl@unicamp.br;
   anderson.rocha@ic.unicamp.br; rtorres@ic.unicamp.br
RI Lewinsohn, Thomas M/D-5880-2012; Zucchi, Roberto A/D-7738-2012; Rocha,
   Anderson/KHU-9621-2024; Jorge, Leonardo Ré/A-1528-2009
OI Lewinsohn, Thomas M/0000-0001-5950-5343; Jorge, Leonardo
   Ré/0000-0003-4518-4328; Faria, Fabio/0000-0003-2956-6326
FU FAPESP [2010/14910-0, 2010/05647-4, 2009/54806-0, 98/05085-2]; CNPq
   [303726/2009-1, 550890/2007-6, 309618/2010-0, 304352/2012-8]; CAPES
   [1260-12-0]; AMD; Microsoft; Fundacao de Amparo a Pesquisa do Estado de
   Sao Paulo (FAPESP) [10/14910-0, 10/05647-4, 98/05085-2] Funding Source:
   FAPESP
FX We thank the financial support of the FAPESP (Grants 2010/14910-0,
   2010/05647-4, 2009/54806-0, and 98/05085-2), CNPq (Grants 303726/2009-1,
   550890/2007-6, 309618/2010-0, and 304352/2012-8), CAPES (Grant
   1260-12-0), AMD and Microsoft. We also thank Miguel Francisco Souza
   Filho for the samples of Anastrepha, and Heraldo Negri de Oliveira for
   the fruit fly photo.
CR ALUJA M, 1994, ANNU REV ENTOMOL, V39, P155, DOI 10.1146/annurev.en.39.010194.001103
   [Anonymous], 2006, Handbook of Multibiometrics
   Arbuckle T., 2001, Sustainability in the Information Society. 15th International Symposium Informatics for Environmental Protection, P425
   Benediktsson JA, 1997, IEEE T NEURAL NETWOR, V8, P54, DOI 10.1109/72.554191
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   dos Santos JA, 2012, INT C PATT RECOG, P3090
   Duda R., 1973, Pattern Classification and Scene Analysis
   Faria FA, 2014, PATTERN RECOGN LETT, V39, P52, DOI 10.1016/j.patrec.2013.07.014
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   HAMPSHIRE JB, 1992, IEEE T PATTERN ANAL, V14, P751, DOI 10.1109/34.142911
   Hernández-Ortiz V, 2004, B ENTOMOL RES, V94, P487, DOI 10.1079/BER2004325
   Hernández-Ortiz V, 2012, ANN ENTOMOL SOC AM, V105, P305, DOI 10.1603/AN11123
   Huang CB, 2007, INT C COMMUN CIRCUIT, P772
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Arribas JI, 2011, COMPUT ELECTRON AGR, V78, P9, DOI 10.1016/j.compag.2011.05.007
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Li Z, 2010, INT ARCH PHOTOGRAMM, V38, P122
   Liu Y., 2006, MULT MOD C P 2006 12
   Lomax S, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2431211.2431215
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Norrbom AL, 2000, FRUIT FLIES (TEPHRITIDAE): PHYLOGENY AND EVOLUTION OF BEHAVIOR, P299
   Norrbom AL, 2012, Anastrepha and Toxotrypana: descriptions, illustrations, and interactive keys
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Pedronette DCG, 2011, ACM INT C MULT RETR
   Penatti OAB, 2012, J VIS COMMUN IMAGE R, V23, P359, DOI 10.1016/j.jvcir.2011.11.002
   Perrone M.P., 1993, NETWORKS DISAGREE EN
   Plantwise, EMP FARM POW RES DEL
   Pourreza A, 2012, COMPUT ELECTRON AGR, V83, P102, DOI 10.1016/j.compag.2012.02.005
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Rocha A, 2010, COMPUT ELECTRON AGR, V70, P96, DOI 10.1016/j.compag.2009.09.002
   Rocha A, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412610010
   Russell KN, 2007, SYST ASSOC SPEC VOL, V74, P131
   Selivon D, 2005, ANN ENTOMOL SOC AM, V98, P367, DOI 10.1603/0013-8746(2005)098[0367:AGCOTC]2.0.CO;2
   Smith-Caldas M. R. B., 2004, NEOTROP ENTOMOL, V30, P565
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan P. N., 2005, Introduction to Data Mining
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Tibshirani Robert, 2009, SPRINGER SERIES STAT, V2
   Torres RD, 2009, PATTERN RECOGN, V42, P283, DOI 10.1016/j.patcog.2008.04.010
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Watson Anna T., 2003, Systematics and Biodiversity, V1, P287
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Wiwart M, 2012, COMPUT ELECTRON AGR, V83, P68, DOI 10.1016/j.compag.2012.01.015
   Wooten JR, 2011, COMPUT ELECTRON AGR, V79, P13, DOI 10.1016/j.compag.2011.08.005
   Xia XW, 2003, PATTERN RECOGN, V36, P361, DOI 10.1016/S0031-3203(02)00036-5
   Zucchi R A., 2008, Fruit flies in Brazil - Anastrepha species their host plants and parasitoids
NR 56
TC 30
Z9 33
U1 2
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1516
EP 1527
DI 10.1016/j.jvcir.2014.06.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100003
DA 2024-07-18
ER

PT J
AU Yan, CC
   Li, L
   Wang, Z
   Yin, J
   Shi, HL
   Jiang, SQ
   Huang, QM
AF Yan, Chenggang Clarence
   Li, Liang
   Wang, Zhan
   Yin, Jian
   Shi, Hailong
   Jiang, Shuqiang
   Huang, Qingming
TI Fusing multi-cues description for partial-duplicate image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-cues; Local Self-Similarity Descriptor; Spatial pyramid;
   Partial-duplicate image retrieval
ID PARALLEL FRAMEWORK; SCALE
AB In traditional image retrieval, images are commonly represented using Bag-of-visual-Words (BOW) built from image local features. However, the lack of spatial and structural information suppresses its performance in applications. In this paper, we introduce a multi-cues description by fusing structural, content and spatial information for partial-duplicate image retrieval. Firstly, we propose a rotation-invariant Local Self-Similarity Descriptor (LSSD), which captures the internal structural layouts in the local textural self-similar regions around interest points. Then, based on the spatial pyramid model, we make use of both LSSD and SIFT to construct an image representation with multi-cues. Finally, we formulate the Semi-Relative Entropy as the distance metric. Comparison experiments with state-of-the-art methods on four popular databases show the efficiency and effectiveness of our approach. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yan, Chenggang Clarence; Shi, Hailong; Jiang, Shuqiang; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Li, Liang; Huang, Qingming] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Zhan] Chinese Acad Sci, Inst Informat Engn, DCS Ctr, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Yin, Jian] Shandong Univ, Dept Comp, Weihai, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Information Engineering,
   CAS; Shandong University
RP Li, L (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM liang.li@vipl.ict.ac.cn
OI Li, Liang/0000-0002-1943-8219
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61025011, 61332016,
   61322212]; National Hi-Tech Development Program (863 Program) of China
   [2014AA015202]
FX This work was supported in part by National Basic Research Program of
   China (973 Program): 2012CB316400, in part by National Natural Science
   Foundation of China: 61025011, 61332016 and 61322212, in part by
   National Hi-Tech Development Program (863 Program) of China:
   2014AA015202.
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Bronstein AM, 2010, LECT NOTES COMPUT SC, V6312, P197, DOI 10.1007/978-3-642-15552-9_15
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Griffin G., 2007, CALTECH 256 OBJECT C
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   KULLBACK S, 1987, AM STAT, V41, P340
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perronnin F., 2007, P IEEE CVPR, P1
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Philbin J., 2008, P CVPR, P1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839
   Wu Z, 2009, PROC CVPR IEEE, P25, DOI 10.1109/CVPRW.2009.5206566
   Xie HT, 2011, IEEE T MULTIMEDIA, V13, P1319, DOI 10.1109/TMM.2011.2167224
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
   Zhipeng Wu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P842, DOI 10.1109/ICPR.2010.212
NR 22
TC 0
Z9 0
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1726
EP 1731
DI 10.1016/j.jvcir.2014.06.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100021
DA 2024-07-18
ER

PT J
AU Zheng, N
   Qi, L
   Guan, L
AF Zheng, Ning
   Qi, Lin
   Guan, Ling
TI Generalized multiple maximum scatter difference feature extraction using
   QR decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature extraction; Linear discriminant criterion; Multiple maximum
   scatter difference (MMSD); Generalized MMSD (GMMSD); QR; Dimensionality
   reduction; Face recognition; Facial expression recognition
ID RECOGNITION; CLASSIFICATION
AB Multiple maximum scatter difference (MMSD) discriminant criterion is an effective feature extraction method that computes the discriminant vectors from both the range of the between-class scatter matrix and the null space of the within-class scatter matrix. However, singular value decomposition (SVD) of two times is involved in MMSD, rendering this method impractical for high dimensional data. In this paper, we propose a generalized MMSD (GMMSD) criterion for feature extraction and classification. GMMSD allows relatively-free selection of a suitable transformation matrix to reduce dimensions. Based on GMMSD criterion, we demonstrate that the same discriminant information can be extracted by QR decomposition, which is more efficient than SVD. Next, GMMSD is compared with several classical feature extraction methods to justify the validity of the proposed method. Our experiments on three face databases and two facial expression databases demonstrate that GMMSD provides favorable recognition performance with high computational efficiency. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zheng, Ning; Qi, Lin] Zhengzhou Univ, Sch Informat & Engn, Zhengzhou 450052, Peoples R China.
   [Guan, Ling] Ryerson Univ, Toronto, ON, Canada.
C3 Zhengzhou University; Toronto Metropolitan University
RP Zheng, N (corresponding author), Zhengzhou Univ, Sch Informat & Engn, Zhengzhou 450052, Peoples R China.
EM zhengning34@hotmail.com; ielqi@zzu.edu.cn; lguan@ee.ryerson.ca
RI Ning, Zheng/AGZ-2040-2022
FU National Natural Science Foundation of China [61331021, 61071211];
   Canada Research Chair Program
FX The authors would like to thank Xin Guo for her help finalize the
   revision of the manuscript. The work is partially supported by the
   National Natural Science Foundation of China under Grant Nos. 61331021,
   61071211, and the Canada Research Chair Program.
CR [Anonymous], 2012, MATRIX COMPUTATIONS
   [Anonymous], P 19 INT C PATT REC
   [Anonymous], 1990, Multicriteria Design Optimization
   [Anonymous], 2003, ADV NEURAL INFORM PR
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bosner N., 2006, THESIS U ZAGREB
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chu DL, 2010, PATTERN RECOGN, V43, P1373, DOI 10.1016/j.patcog.2009.10.004
   de Ridder D., 2002, PH200201 DELFT U TEC
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Feng XY, 2004, LECT NOTES COMPUT SC, V3212, P668
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   He LH, 2005, P ANN INT IEEE EMBS, P3300
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Horikawa Y, 2007, ICCSA 2007: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND APPLICATIONS, P489, DOI [10.1109/ICCSA.2007.41, 10.1109/ICCSA.2007.78]
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   Kouropteva O., 2002, FSKD
   Kyperountas M, 2010, PATTERN RECOGN, V43, P972, DOI 10.1016/j.patcog.2009.07.007
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lu GF, 2010, PATTERN RECOGN, V43, P3572, DOI 10.1016/j.patcog.2010.04.007
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Martinez R., 1998, CVC Tech. Rep.
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Samko O, 2006, PATTERN RECOGN LETT, V27, P968, DOI 10.1016/j.patrec.2005.11.017
   Shinohara Y, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P499, DOI 10.1109/AFGR.2004.1301582
   Song FX, 2007, IEEE T SYST MAN CY B, V37, P1599, DOI 10.1109/TSMCB.2007.906579
   Song F, 2007, PATTERN ANAL APPL, V10, P165, DOI 10.1007/s10044-006-0057-3
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tao YT, 2010, NEUROCOMPUTING, V73, P1808, DOI 10.1016/j.neucom.2009.10.026
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang YJ, 2008, IEEE T MULTIMEDIA, V10, P936, DOI 10.1109/TMM.2008.927665
   Xue G., 2006, 2006 8 INT C SIGN PR, V3
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang WK, 2009, PATTERN RECOGN, V42, P2327, DOI 10.1016/j.patcog.2009.03.017
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhang TH, 2009, IEEE T KNOWL DATA EN, V21, P1299, DOI 10.1109/TKDE.2008.212
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhou TY, 2013, IEEE T IMAGE PROCESS, V22, P244, DOI 10.1109/TIP.2012.2202678
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
NR 48
TC 4
Z9 5
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1460
EP 1471
DI 10.1016/j.jvcir.2014.04.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100015
DA 2024-07-18
ER

PT J
AU Lee, CP
   Tan, AWC
   Tan, SC
AF Lee, Chin Poo
   Tan, Alan W. C.
   Tan, Shing Chiang
TI Time-sliced averaged motion history image for gait recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait; Gait recognition; Gait analysis; Motion; Motion history image;
   Gait energy image; Histograms of oriented gradients; Histograms
ID ENERGY IMAGE; REPRESENTATION
AB In this paper, we propose a time-sliced averaged motion history image (TAMHI) alongside the histograms of oriented gradients (HOG) to generate gait signatures in a gait recognition problem. Building on the motion history image (MHI), TAMHI divides the gait cycle into several regular time windows to generate the same number of TAMHI composite images. HOG descriptors are then calculated on these composite images to obtain the gait signature. The time-slicing procedure to produce multi-composite images preserve more detailed transient information of gait cycles. Additionally, time-normalization also introduces gait length invariancy into the representation, hence, offering a better recognition rate to slight changes in walking speed. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lee, Chin Poo; Tan, Shing Chiang] Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
   [Tan, Alan W. C.] Multimedia Univ, Fac Engn & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
C3 Multimedia University; Multimedia University
RP Lee, CP (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
EM cplee@mmu.edu.my; wctan@mmu.edu.my; sctan@mmu.edu.my
RI Tan, SC/E-6463-2010; /AGV-9105-2022
OI Tan, SC/0000-0002-1267-1894; Lee, Chin Poo/0000-0003-3679-8977
CR [Anonymous], HUM GAIT REC COMP VI
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], INT SER BIOMETRICS
   [Anonymous], 2001, Cmu Ri Tr 01-18
   [Anonymous], 4 UK COMP VIS STUD W
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], P 2 INT C BIOINF BIO
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Chin-Pan Huang, 2011, Proceedings of the 2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control (IMCCC 2011), P353, DOI 10.1109/IMCCC.2011.95
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Mowbray SD, 2003, LECT NOTES COMPUT SC, V2688, P566
   Mu Y, 2010, NEUROCOMPUTING, V73, P895, DOI 10.1016/j.neucom.2009.09.017
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Wang M, 2011, LECT NOTES COMPUT SC, V6838, P257, DOI 10.1007/978-3-642-24728-6_34
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   Yang XC, 2008, SIGNAL PROCESS, V88, P2350, DOI 10.1016/j.sigpro.2008.03.006
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 35
TC 21
Z9 24
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 822
EP 826
DI 10.1016/j.jvcir.2014.01.012
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200011
DA 2024-07-18
ER

PT J
AU Wang, J
   Wang, YH
   Jiang, M
   Yan, XY
   Song, MM
AF Wang, Jun
   Wang, Yuehuan
   Jiang, Man
   Yan, Xiaoyun
   Song, Mengmeng
TI Moving cast shadow detection using online sub-scene shadow modeling and
   object inner-edges analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving cast shadow detection; Video surveillance; Foreground extraction;
   Sub-scene shadow modeling; Graph-cut; Object inner-edges analysis; Local
   color constancy; Shadow expanding
AB In this paper, we propose an adaptive and accurate moving cast shadow detection method employing online sub-scene shadow modeling and object inner-edges analysis for applications of static-camera video surveillance. To describe shadow appearance more accurately, the proposed method builds adaptive online shadow models for sub-scenes with different conditions of irradiance and reflectance. The online shadow models are learned by utilizing Gaussian functions to fit the significant peaks of accumulating histograms, which are calculated from Hue, Saturation and Intensity (HSI) difference of moving objects between background and foreground. Additionally, object inner-edges analysis is adopted to reject camouflages, which are misclassified foreground regions that are highly similar to shadows. Finally, the main shadow regions are expanded to recycle the misclassified shadow pixels based on local color constancy. The proposed algorithm can adaptively handle the shadow appearance changes and camouflages without prior information about illuminations and scenarios. Experimental results demonstrate that the proposed method outperforms state-of-the-art methods. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Jun; Wang, Yuehuan; Yan, Xiaoyun] Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Hubei, Peoples R China.
   [Wang, Jun; Wang, Yuehuan; Jiang, Man; Yan, Xiaoyun; Song, Mengmeng] Huazhong Univ Sci & Technol, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Wang, YH (corresponding author), Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Hubei, Peoples R China.
EM junwong@hust.edu.cn; yuehwang@hust.edu.cn
FU Chinese advanced research project [51301040201]; Chinese advanced
   research foundation [9140A01010411-JW0503, 9140A01060113JW05016]
FX This research is partially supported by Chinese advanced research
   project No. 51301040201, Chinese advanced research foundation Nos.
   9140A01010411-JW0503 and 9140A01060113JW05016. The authors are also
   grateful for the valuable and constructive comments from the reviewers.
CR Amato A, 2011, IEEE T IMAGE PROCESS, V20, P2954, DOI 10.1109/TIP.2011.2132728
   [Anonymous], 2010, Chinese Conference on Pattern Recognition, DOI DOI 10.1109/CCPR.2010.5659321
   Bunyak F, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P510
   Chia-Chih Chen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2407, DOI 10.1109/ICPR.2010.589
   Chun-Ting Chen, 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P679, DOI 10.1109/ICGCS.2010.5542975
   Chung-Hsien Huang, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P145, DOI 10.1109/PSIVT.2010.31
   Cucchiara R, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P334, DOI 10.1109/ITSC.2001.948679
   Dai JY, 2013, OPT LASER TECHNOL, V54, P232, DOI 10.1016/j.optlastec.2013.05.033
   Dong X, 2005, PATTERN RECOGN LETT, V26, P91, DOI 10.1016/j.patrec.2004.09.005
   El-Zahhar M. M., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P348, DOI 10.1109/ICSIPA.2011.6144084
   Fung GSK, 2002, OPT ENG, V41, P1425, DOI 10.1117/1.1473638
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Huber P., 1981, Robust Statistics
   Javed O, 2002, LECT NOTES COMPUT SC, V2353, P343
   Joshi AJ, 2008, IEEE T PATTERN ANAL, V30, P2055, DOI 10.1109/TPAMI.2008.150
   Joshi AJ, 2008, IEEE INT CONF ROBOT, P987, DOI 10.1109/ROBOT.2008.4543333
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Sanin Andres, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P141, DOI 10.1109/ICPR.2010.43
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Shan Y, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P496, DOI 10.1109/ICIG.2007.54
   STAUDER J, 1995, SIGNAL PROCESS-IMAGE, V7, P355, DOI 10.1016/0923-5965(95)00008-7
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Watt A., 1993, 3D COMPUTER GRAPHICS
NR 26
TC 11
Z9 14
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 978
EP 993
DI 10.1016/j.jvcir.2014.02.015
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200026
DA 2024-07-18
ER

PT J
AU Zhang, LL
   Koch, R
AF Zhang, Lilian
   Koch, Reinhard
TI Structure and motion from line correspondences: Representation,
   projection, initialization and sparse bundle adjustment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Structure and motion; Line representation; Cayley representation; Line
   projection; Closed-form solution; Incremental initialization; Sparse
   bundle adjustment; Unconstrained optimization
ID DESCRIPTOR
AB We address the problem of structure and motion from line correspondences, which ranges from the representation of lines, their projections and the initialization procedure to the final adjustment. The Cayley representation of spatial lines is developed, which is a nonlinear minimal parametrization circumventing the tiresome Plucker constraint. The relationships between different line representations are given. Based on these relationships, we derive a novel line projection function which is consistent with the previous results. After building the line observation model, we employ a closed-form solution for the first image triplet, then develop an incremental initialization approach to initialize the motion and structure parameters. Finally, the sparse bundle adjustment (SBA) is applied to refine the parameters, which updates the spatial lines by using the Cayley representation with an unconstrained optimization engine. The experiments show that the proposed algorithm outperforms the previous works both in efficiency and accuracy. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Lilian] Natl Univ Def Technol, Coll Mechatron & Automat, Dept Automat Control, Changsha, Hunan, Peoples R China.
   [Zhang, Lilian; Koch, Reinhard] Univ Kiel, Inst Comp Sci, D-24098 Kiel, Germany.
C3 National University of Defense Technology - China; University of Kiel
RP Zhang, LL (corresponding author), Univ Kiel, Inst Comp Sci, D-24098 Kiel, Germany.
EM lz@mip.informatik.uni-kiel.de; rk@mip.informatik.uni-kiel.de
OI Koch, Reinhard/0000-0003-4398-1569
FU China Scholarship Council [2009611008]
FX This work was supported by China Scholarship Council (No. 2009611008).
   The authors thank the anonymous reviewers for their valuable comments
   that helped to improve the paper. Special thanks to Markus Franke whose
   work was valuable in improving the presentation of this paper.
CR Andrew G., ISVC, P354
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001
   Bartoli A, 2004, INT J COMPUT VISION, V57, P159, DOI 10.1023/B:VISI.0000013092.07433.82
   CROWLEY JL, 1992, INT J COMPUT VISION, V8, P29, DOI 10.1007/BF00126399
   Eade E., BMVC, P7
   Fan B., CVPR, P390
   Farenzena M., ICCV WORKSH, P1489
   Faugeras O.D., ICCV, P951
   Goddard J.S., 1997, THESIS U TENNESSEE
   Gupta M., CVPR, P1
   Habib AF, 2002, PHOTOGRAMM REC, V17, P635, DOI 10.1111/0031-868X.00211
   Hartley R, 2013, INT J COMPUT VISION, V103, P267, DOI 10.1007/s11263-012-0601-0
   Klein G., ISMAR, P225
   Krantz S.G., 1999, Handbook of Complex Variables
   Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41
   Liu JZ, 2011, IEEE T PATTERN ANAL, V33, P3, DOI 10.1109/TPAMI.2010.49
   Liu Y., ICPR, P213
   LIU YC, 1988, COMPUT VISION GRAPH, V43, P37, DOI 10.1016/0734-189X(88)90041-2
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Martinec D., CVPR, P497
   Mirzaei F.M., ICRA, P5581
   Montiel JMM, 2000, PATTERN RECOGN, V33, P1295, DOI 10.1016/S0031-3203(99)00117-X
   Morris D., ICCV, P696
   Ohwovoriole M. S., 1980, THESIS STANFORD U
   Pottmann H., ECCV, P297
   Roberts K., CVPR, P635
   Schindler G., 3DPVT, P846
   Seo Y., ICPR, P503
   Smith P., BMVC, P17
   Solà J, 2012, INT J COMPUT VISION, V97, P339, DOI 10.1007/s11263-011-0492-5
   SPETSAKIS ME, 1990, INT J COMPUT VISION, V4, P171, DOI 10.1007/BF00054994
   TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228
   Triggs B., CVPR, P845
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Vieville T., ICCV, P517
   Wang L., ICCV, P1311
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327
   Wu YX, 2005, IEEE T AERO ELEC SYS, V41, P110, DOI 10.1109/TAES.2005.1413751
   Xue T., CVPR, P302
   Yen B., ICASSP, P118
   Zhang L., ACCV, P217
   Zhang L., IMVIP, P8
   Zhang LL, 2013, J VIS COMMUN IMAGE R, V24, P794, DOI 10.1016/j.jvcir.2013.05.006
NR 45
TC 46
Z9 56
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 904
EP 915
DI 10.1016/j.jvcir.2014.02.013
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200019
DA 2024-07-18
ER

PT J
AU Ben Aoun, N
   Mejdoub, M
   Ben Amar, C
AF Ben Aoun, Najib
   Mejdoub, Mahmoud
   Ben Amar, Chokri
TI Graph-based approach for human action recognition using spatio-temporal
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Spatio-temporal features; Graph-based video
   modeling; Bag-of-sub-Graphs Frequent sub-graphs; Support Vector
   Machines; Spatio-temporal Interest Points; gSpan algorithm
AB Due to the exponential growth of the video data stored and uploaded in the Internet websites especially YouTube, an effective analysis of video actions has become very necessary. In this paper, we tackle the challenging problem of human action recognition in realistic video sequences. The proposed system combines the efficiency of the Bag-of-visual-Words strategy and the power of graphs for structural representation of features. It is built upon the commonly used Space-Time Interest Points (STIP) local features followed by a graph-based video representation which models the spatio-temporal relations among these features. The experiments are realized on two challenging datasets: Hollywood2 and UCF YouTube Action. The experimental results show the effectiveness of the proposed method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Ben Aoun, Najib; Mejdoub, Mahmoud; Ben Amar, Chokri] Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Lab REs Grp Intelligent Machines, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Ben Aoun, N (corresponding author), Univ Sfax, Natl Engn Sch Sfax ENIS, REGIM Lab REs Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM najib.benaoun@ieee.org; mah.mejdoub@gmail.com; chokri.benamar@ieee.org
RI BEN AOUN, Najib/Q-6414-2019; Cataldi, Antonio/AAM-7411-2021; Chokri, BEN
   AMAR/K-5237-2012
OI BEN AOUN, Najib/0000-0001-9444-8209; Mejdoub,
   Mahmoud/0000-0002-9442-5784
CR Acosta-Mendoza N, 2012, KNOWL-BASED SYST, V27, P381, DOI 10.1016/j.knosys.2011.12.002
   Anh-Phuong Ta, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3224, DOI 10.1109/ICPR.2010.788
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], 2010, P EUROPEAN C COMPUTE
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Ben Aoun Najib, 2011, 2011 International Conference on Innovations in Information Technology (IIT), P114, DOI 10.1109/INNOVATIONS.2011.5893799
   Ben Aoun N, 2011, LECT NOTES COMPUT SC, V6855, P324, DOI 10.1007/978-3-642-23678-5_38
   Brendel W, 2010, LECT NOTES COMPUT SC, V6312, P721, DOI 10.1007/978-3-642-15552-9_52
   Celiktutan Oya, 2012, Human Behavior Understanding. Proceedings of the Third International Workshop, HBU 2012, P17, DOI 10.1007/978-3-642-34014-7_2
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Dammak M, 2012, ICAART: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 1, P394, DOI 10.5220/0003775803940399
   Elghazel H, 2011, LECT NOTES COMPUT SC, V6658, P92, DOI 10.1007/978-3-642-20844-7_10
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Gilbert Arthur J., 2011, Insecta Mundi, V0200, P1
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huan J, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P549
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Kuramochi M, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P313, DOI 10.1109/ICDM.2001.989534
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Mejdoub Mahmoud, 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P365, DOI 10.1109/CBMI.2008.4564970
   Mejdoub M, 2013, MULTIMED TOOLS APPL, V64, P197, DOI 10.1007/s11042-011-0900-4
   Sekma Manel, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P563, DOI 10.1007/978-3-642-40246-3_70
   Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Ullah M., 2010, P BRIT MACH VIS C BM, P951
   Wali A, 2010, LECT NOTES COMPUT SC, V6475, P110, DOI 10.1007/978-3-642-17691-3_11
   Wang H., 2009, BMVC
   Wang H, 2011, PROTECTING PRIVACY IN CHINA: A RESEARCH ON CHINAS PRIVACY STANDARDS AND THE POSSIBILITY OF ESTABLISHING THE RIGHT TO PRIVACY AND THE INFORMATION PRIVACY PROTECTION LEGISLATION IN MODERN CHINA, P1, DOI 10.1007/978-3-642-21750-0_1
   Yan XF, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P721, DOI 10.1109/ICDM.2002.1184038
NR 36
TC 47
Z9 49
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 329
EP 338
DI 10.1016/j.jvcir.2013.11.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300010
DA 2024-07-18
ER

PT J
AU Shiau, YH
   Chen, PY
   Yang, HY
   Chen, CH
   Wang, SS
AF Shiau, Y. -H.
   Chen, P. -Y.
   Yang, H. -Y.
   Chen, C. -H.
   Wang, S-S
TI Weighted haze removal method with halo prevention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dehaze; Haze removal method; Atmospheric scattering model; Dark channel
   prior; Illumination adjustment; Contrast enhancement; Halo artifact;
   Real-time image processing
ID VISION
AB In this paper, we propose an efficient method to remove haze from a signal image based on the atmospheric scattering model and dark channel prior. Our approach applies a weighted technique that automatically finds the possible atmospheric lights, and mixes these candidates to refine the atmospheric light. Then, difference prior, a novel prior processing method, is employed for the estimation of the transmission that mitigates the halo artifact around the sharp edges. This method requires a low computational cost and is suitable for real-time applications. The experimental results show that our approach obtains the comparable results as compared with previous methods. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Shiau, Y. -H.] Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Douliu City, Taiwan.
   [Chen, P. -Y.; Yang, H. -Y.; Wang, S-S] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
   [Chen, C. -H.] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.
C3 National Yunlin University Science & Technology; National Cheng Kung
   University; National Kaohsiung University of Science & Technology
RP Chen, PY (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
EM shiauyh@yuntech.edu.tw; pychen@csie.ncku.edu.tw; yang.hungyu@gmail.com;
   thouho@cc.kuas.edu.tw; hahaandgavin@gmail.com
RI Chen, Pei Yin/AFT-4918-2022
OI Chen, Pei-Yin/0000-0002-5104-6055
FU National Science Council, Taiwan [NSC 102-2221-E-224-078]
FX This work was supported in part by the National Science Council, Taiwan,
   under Grant NSC 102-2221-E-224-078.
CR [Anonymous], 1952, VISION ATMOSPHERE
   Da-Jinn Wang, 2009, 2009 Fourth International Conference on Innovative Computing, Information and Control (ICICIC 2009), P342, DOI 10.1109/ICICIC.2009.380
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Narasimhan SG, 2001, PROC CVPR IEEE, P186
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Oakley JP, 2007, IEEE T IMAGE PROCESS, V16, P511, DOI 10.1109/TIP.2006.887736
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Pei SC, 2012, IEEE INT SYMP CIRC S, P2777, DOI 10.1109/ISCAS.2012.6271886
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Tan R. T., 2008, PROC IEEE C COMPUT V, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Yoon I, 2012, IEEE T CONSUM ELECTR, V58, P111, DOI 10.1109/TCE.2012.6170062
NR 18
TC 42
Z9 43
U1 0
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 445
EP 453
DI 10.1016/j.jvcir.2013.12.011
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300020
DA 2024-07-18
ER

PT J
AU Koga, T
   Suetake, N
AF Koga, Takanori
   Suetake, Noriaki
TI Image coarsening by using space-filling curve for decomposition-based
   image enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edge-preserving smoothing; Image coarsening; Minimum spanning tree;
   Space-filling curve; Vector epsilon-filter; Image abstraction; Selective
   diffusion
ID ALGORITHM; EDGE
AB We propose a novel space-filling curve based image coarsening method, which automatically extracts a base-layer from an input image while still preserving its structural context, meaningful details, et cetera. In the proposed method, specifically, a one-dimensional edge-preserving smoothing filter, which is called a vector epsilon-filter, is applied to an input image along a space-filling curve. In this regard, the space-filling curve is constructed by using a minimum spanning tree which extracts the structural context of the input image. This novel image coarsening approach is completely different from all conventional approaches employing any kind of two-dimensional filter window. Furthermore, this coarsening method can effectively produce an aggregation of texture details as well as enhance sharp edges, while preserving structural contexts such as thin lines and sharp corners. The main benefit of the coarsened image by the proposed method is its suitability for extracting fine features of an input image for decomposition-based image enhancement. In this paper, the structural-context-preserving image coarsening capability of the proposed method is verified by some results from experiments and examples. Then we show our new method's characteristics in practical application to decomposition-based image enhancement by using some other examples. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Koga, Takanori] Tokuyama Coll Technol, Dept Comp Sci & Elect Engn, Gakuendai, Shunan 7458585, Japan.
   [Suetake, Noriaki] Yamaguchi Univ, Grad Sch Sci & Engn, Yamaguchi 7538512, Japan.
C3 Yamaguchi University
RP Koga, T (corresponding author), Tokuyama Coll Technol, Dept Comp Sci & Elect Engn, Gakuendai, Shunan 7458585, Japan.
EM koga@tokuyama.ac.jp
CR [Anonymous], ACM T GRAPHICS
   [Anonymous], 1890, Math. Ann.
   [Anonymous], 2005, P IEEE INT C MULT EX
   Asano T, 1999, IEICE T FUND ELECTR, VE82A, P553
   Bandoh Y, 2000, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2000.901064
   Breshears C., 2009, ART CONCURRENCY
   Dafner R, 2000, COMPUT GRAPH FORUM, V19, pC209, DOI 10.1111/1467-8659.00413
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Fattal R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531328
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Harashima H., ELECT COMMUNICATIONS, V65
   Hashim H, 2010, UKSIM INT CONF COMP, P25, DOI 10.1109/ISMS.2010.16
   Hilbert David, 1891, MATH ANN, V38, P459, DOI [DOI 10.1007/BF01199431, 10.1007/bf01199431]
   Kamata S, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P895, DOI 10.1109/ICIP.2000.899858
   Kamata S, 1999, IEEE T IMAGE PROCESS, V8, P964, DOI 10.1109/83.772242
   Kamata S, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P707, DOI 10.1109/ICIP.1997.648017
   Kass M., 2010, P SIGGRAPH 2010
   Koga T, 2011, IEEE IMAGE PROC, P1465, DOI 10.1109/ICIP.2011.6115719
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Sagan H., 1994, SPACE FILLING CURVES
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
NR 25
TC 4
Z9 4
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 806
EP 818
DI 10.1016/j.jvcir.2013.05.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700007
DA 2024-07-18
ER

PT J
AU Yazid, H
   Arof, H
AF Yazid, Haniza
   Arof, Hamzah
TI Gradient based adaptive thresholding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Adaptive thresholding; Gradient based thresholding;
   Diabetic retinopathy; Handwritten document images; Medical image
   analysis; Exudate detection; Binarization
AB For images with poor and non-uniform illumination, adaptive thresholding is required to separate the objects of interest from the background. In this paper a new approach to create an adaptive threshold surface is proposed to segment an image. The technique is inspired by the Yanowitz's method and is improved upon by the introduction of a simpler and more accurate threshold surface. The method is tested on several images of different patterns with varying illumination and the results are compared to the ones produced by a number of adaptive thresholding algorithms. In order to demonstrate the effectiveness, the proposed method had been implemented in medical and document images. The proposed method compares favorably against those using watershed and morphology in medical image and favorably against variable threshold and adaptive Otsu's N-thresholding for document image. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yazid, Haniza] Univ Malaya, Sch Mechatron Engn, Arau 02600, Perlis, Malaysia.
   [Arof, Hamzah] Univ Malaya, Fac Engn, Dept Elect Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya; Universiti Malaya
RP Yazid, H (corresponding author), Univ Malaya, Sch Mechatron Engn, Arau 02600, Perlis, Malaysia.
EM haniza.yazid@gmail.com
RI Ahmed, Mahmoud/JEO-9229-2023; AROF, HAMZAH/ABI-1052-2020; Yazid,
   Haniza/D-3830-2015
OI Ahmed, Mahmoud/0000-0003-4720-3588; 
FU Ministry of Higher Education Malaysia [9018-00010]
FX This work was supported by Ministry of Higher Education Malaysia under
   Research Acculturation Grant Scheme (9018-00010).
CR Alaknanda, 2009, NDT&E INT, V42, P2, DOI 10.1016/j.ndteint.2008.06.005
   Benjlaiel Mohamed, REGIM ENIS
   Blayvas I, 2006, PATTERN RECOGN, V39, P89, DOI 10.1016/j.patcog.2005.08.011
   Chan FHY, 1998, IEEE T IMAGE PROCESS, V7, P468, DOI 10.1109/83.661196
   Chen Q, 2008, PATTERN RECOGN, V41, P1254, DOI 10.1016/j.patcog.2007.09.007
   CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5
   Eikvil L., 1991, Proceedings of the 1st International Conference on Document Analaysis and Recognition, P435
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Kim DY, 2005, IMAGE VISION COMPUT, V23, P1277, DOI 10.1016/j.imavis.2005.09.005
   Kim IK, 2002, PATTERN RECOGN, V35, P265, DOI 10.1016/S0031-3203(01)00027-9
   Kom G, 2007, COMPUT BIOL MED, V37, P37, DOI 10.1016/j.compbiomed.2005.12.004
   Lelore Thibault, 6168 LSIS UMR CNRS S
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   Pratikakis I., 2012, H DIBCO 2012 HANDWRI
   Pratikakis I, 2012, INT CONF FRONT HAND, P817, DOI 10.1109/ICFHR.2012.216
   Reza AW, 2009, J MED SYST, V33, P73, DOI 10.1007/s10916-008-9166-4
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Stathis P, 2008, J UNIVERS COMPUT SCI, V14, P3011
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197
   Wang Y., 2008, NDT&E INT, V21, p5 524
   Welfer D, 2010, COMPUT MED IMAG GRAP, V34, P228, DOI 10.1016/j.compmedimag.2009.10.001
   Yanowitz S.D., 1988, 9 INT C PATT REC
   Zaghden Nizar, REGIM ENIS SFAX TUNI
   1979, IEEE T SYSTEMS MAN C, V9, P62
NR 26
TC 22
Z9 25
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 926
EP 936
DI 10.1016/j.jvcir.2013.06.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700017
DA 2024-07-18
ER

PT J
AU Sun, SW
   Wang, YCF
   Huang, F
   Liao, HYM
AF Sun, Shih-Wei
   Wang, Yu-Chiang Frank
   Huang, Fay
   Liao, Hong-Yuan Mark
TI Moving foreground object detection via robust SIFT trajectories
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Template matching; Object tracking; Video object segmentation;
   Foreground segmentation; Background subtraction
ID VIDEO
AB In this paper, we present an automatic foreground object detection method for videos captured by freely moving cameras. While we focus on extracting a single foreground object of interest throughout a video sequence, our approach does not require any training data nor the interaction by the users. Based on the SIFT correspondence across video frames, we construct robust SIFT trajectories in terms of the calculated foreground feature point probability. Our foreground feature point probability is able to determine candidate foreground feature points in each frame, without the need of user interaction such as parameter or threshold tuning. Furthermore, we propose a probabilistic consensus foreground object template (CFOT), which is directly applied to the input video for moving object detection via template matching. Our CFOT can be used to detect the foreground object in videos captured by a fast moving camera, even if the contrast between the foreground and background regions is low. Moreover, our proposed method can be generalized to foreground object detection in dynamic backgrounds, and is robust to viewpoint changes across video frames. The contribution of this paper is trifold: (1) we provide a robust decision process to detect the foreground object of interest in videos with contrast and viewpoint variations; (2) our proposed method builds longer SIFT trajectories, and this is shown to be robust and effective for object detection tasks; and (3) the construction of our CFOT is not sensitive to the initial estimation of the foreground region of interest, while its use can achieve excellent foreground object detection results on real-world video data. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Sun, Shih-Wei] Taipei Natl Univ Arts, Dept New Media Art, Taipei, Taiwan.
   [Sun, Shih-Wei] Taipei Natl Univ Arts, Ctr Art & Technol, Taipei, Taiwan.
   [Wang, Yu-Chiang Frank] Acad Sinica, Res Ctr IT Innovat, Taipei 115, Taiwan.
   [Wang, Yu-Chiang Frank; Liao, Hong-Yuan Mark] Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
   [Huang, Fay] Natl Ilan Univ, Inst Comp Sci & Info Engn, Yi Lan, Taiwan.
   [Liao, Hong-Yuan Mark] Natl Chiao Tung Univ, Dept Comp Sci & Info Engn, Hsinchu, Taiwan.
C3 Academia Sinica - Taiwan; Academia Sinica - Taiwan; National Ilan
   University; National Yang Ming Chiao Tung University
RP Wang, YCF (corresponding author), Acad Sinica, Res Ctr IT Innovat, Taipei 115, Taiwan.
EM swsun@newmedia.tnua.edu.tw; ycwang@citi.sinica.edu.tw; fay@niu.edu.tw;
   liao@iis.sinica.edu.tw
RI Liao, Hong-Yuan Mark/AAQ-5514-2021
OI Sun, Shih-Wei/0000-0003-2761-7484
CR Bugeau A., 2007, IEEE C COMPUTER VISI, P1, DOI [DOI 10.1109/CVPR.2007.383244, 10.1109/CVPR.2007.383244]
   Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123
   Felip RL, 2008, IEEE T CIRC SYST VID, V18, P12, DOI 10.1109/TCSVT.2007.903804
   Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770
   JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Meng J., 1996, P 4 INT C MULT BOST, P43
   Patwardhan KA, 2008, IEEE T PATTERN ANAL, V30, P746, DOI 10.1109/TPAMI.2007.70843
   Sand Peter, 2008, International Journal of Computer Vision, V80, P72, DOI 10.1007/s11263-008-0136-6
   Senior A., 2002, PROC IEEE INT WORKSH, P48
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Shi Y.Q., 1999, IMAGE VIDEO COMPRESS, P407
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Su CW, 2007, IEEE T MULTIMEDIA, V9, P1193, DOI 10.1109/TMM.2007.902875
   Tan Y., 1995, P IEEE INT C IMAGE P, V1, P23
   Wang R, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P21, DOI 10.1109/ISCAS.2000.857353
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhao Yijia, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P309, DOI 10.1109/AVSS.2008.30
NR 19
TC 21
Z9 22
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 232
EP 243
DI 10.1016/j.jvcir.2012.12.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200003
DA 2024-07-18
ER

PT J
AU Yang, SY
   Zhao, LF
   Wang, M
   Zhang, YY
   Jiao, LC
AF Yang, Shuyuan
   Zhao, Linfang
   Wang, Min
   Zhang, Yueyuan
   Jiao, Licheng
TI Dictionary learning and similarity regularization based image noise
   reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Sparse learning; Image patches; Dictionary learning;
   Self-similarity; Non-local means; KSVD; Non-parametric Bayesian
ID SPARSE; TRANSFORM
AB Redundant dictionary learning based image noise reduction methods explore the sparse prior of patches and have proved to lead to state-of-the-art results; however, they do not explore the non-local similarity of image patches. In this paper we exploit both the structural similarities and sparse prior of image patches and propose a new dictionary learning and similarity regularization based image noise reduction method. By formulating the image noise reduction as a multiple variables optimization problem, we alternately optimize the variables to obtain the denoised image. Some experiments are taken on comparing the performance of our proposed method with its counterparts on some benchmark natural images, and the superiorities of our proposed method to its counterparts can be observed in both the visual results and some numerical guidelines. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Yang, Shuyuan; Zhao, Linfang; Zhang, Yueyuan; Jiao, Licheng] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Dept Elect Engn, Xian 710071, Peoples R China.
   [Wang, Min] Xidian Univ, Dept Elect Engn, Natl Key Lab Radar Signal Proc, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Yang, SY (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Minist Educ, Dept Elect Engn, Xian 710071, Peoples R China.
EM syyang@xidian.edu.cn
RI Jiao, Licheng/JOZ-0842-2023
OI Jiao, Licheng/0000-0003-3354-9617
FU Foreign Scholars in University Research and Teaching Programs [B07048];
   National Science Foundation of China [61072108, 60971112, 61173090]; 
   [NCET-10-0668.]
FX The authors would like to thank the anonymous reviewers for their
   constructive comments, which resulting much improvement of the clarity
   of this paper. This work was supported by the Foreign Scholars in
   University Research and Teaching Programs (No. B07048), National Science
   Foundation of China under Grant No. 61072108, 60971112, 61173090, and
   China program NCET-10-0668.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2009, INT C COMP VIS
   [Anonymous], 2011, CVPR
   [Anonymous], 2007, IEEE C COMP VIS PATT
   Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Chatterjee P, 2009, IEEE T IMAGE PROCESS, V18, P1438, DOI 10.1109/TIP.2009.2018575
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Do M., 2002, P IEEE INT C IM PROC
   Elad M., 2006, IEEE COMPUTER SOC C, V1, P895, DOI 10.1109/CVPR.2006.142
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elad Michael, 2006, CVPR, P1924
   Friedrich F., 2005, P SPIE WAVELETSXI SA, V5914, P1
   Lang M, 1996, IEEE SIGNAL PROC LET, V3, P10, DOI 10.1109/97.475823
   Paisley J., 2010, P INT C IM PROC ICIP
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P27, DOI 10.1109/TIP.2008.2008065
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Turek Javier, 2010, ABS10033984 CORR
   Zhang WG, 2010, IEEE GEOSCI REMOTE S, V7, P131, DOI 10.1109/LGRS.2009.2028588
   Zhou M., 2009, Neural Information Processing Systems (NIPS)
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
NR 21
TC 8
Z9 10
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 181
EP 186
DI 10.1016/j.jvcir.2012.07.011
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000011
DA 2024-07-18
ER

PT J
AU Huang, XQ
   Zhang, Q
   Liu, WB
AF Huang Xiaoqing
   Zhang Qin
   Liu Wenbo
TI A new method for image retrieval based on analyzing fractal coding
   characters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fractal coding; Kernel density estimation; Image retrieval; Texture
   Image; Fractal coding parameters; Orthogonal Fractal Coding; Statistical
   Characteristics; Collage Error
AB It has been effectively proved that histogram of image fractal coding parameters can be used for image retrieval. In recent years, many researchers have paid more and more attention to this application of image fractal coding. In this paper, a new statistical method, based on kernel density estimation, is used for analyzing fractal coding parameters. The fractal signatures are then extracted for texture image retrieval. Experimental results show that the proposed method not only has higher retrieval rate but also faster retrieval speed than existing method. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Huang Xiaoqing; Zhang Qin; Liu Wenbo] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Huang, XQ (corresponding author), 29 Yudao St, Nanjing, Jiangsu, Peoples R China.
EM sunnynuaa@163.com
FU Fundamental Research Funds for the Central Universities [NS2012093]
FX This paper is supported by the Fundamental Research Funds for the
   Central Universities No. NS2012093.
CR Akakin HC, 2012, IEEE T INF TECHNOL B, V16, P758, DOI 10.1109/TITB.2012.2185829
   [陈星星 Chen Xing-xing], 2009, [电子与信息学报, Journal of Electronics & Information Technology], V31, P1193
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Feng Y, 2011, ELECTRON LETT, V47, P97, DOI 10.1049/el.2010.3267
   Gu Jiandong, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P223
   [郝玉保 HAO Yubao], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P670
   Jia Jingping, 2009, J TSINGHUA U SCI TEC, V49
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Lasfar A, 2000, INT C PATT RECOG, P1031, DOI 10.1109/ICPR.2000.905647
   OIEN GE, 1994, SIGNAL PROCESS, V40, P105, DOI 10.1016/0165-1684(94)90024-8
   Pi M, 2008, IET IMAGE PROCESS, V2, P218, DOI 10.1049/iet-ipr:20070055
   Pi MH, 2005, IEEE T MULTIMEDIA, V7, P597, DOI 10.1109/TMM.2005.846796
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Schouten BAM, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P534, DOI 10.1109/ICIP.2000.899474
   SLOAN AD, 1994, ADV IMAGING, V9, P5
   Wang Shou-jue, 2010, Acta Electronica Sinica, V38, P993
   [徐艳 Xu Yan], 2006, [电子与信息学报, Journal of electronics & information technology], V28, P603
   Zhou Ning, 2010, Computer Engineering, V36, P198
NR 18
TC 12
Z9 14
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 42
EP 47
DI 10.1016/j.jvcir.2012.10.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600005
DA 2024-07-18
ER

PT J
AU Chang, CC
   Nguyen, TS
   Lin, CC
AF Chang, Chin-Chen
   Thai Son Nguyen
   Lin, Chia-Chen
TI A reversible data hiding scheme for VQ indices using locally adaptive
   coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Image compression; Locally adaptive coding; Reversible data
   hiding; High embedding rate; Steganography; VQ compression; Hiding
   capacity
ID DIGITAL WATERMARKING; STEGANOGRAPHY; ALGORITHM
AB Data hiding is designed to solve the problem of secure information exchange through public networks such as Internet. In this paper, we present an improved reversible data hiding scheme that can recover original VQ indices after data extraction. As with Chang et al.'s scheme, our proposed scheme also depends on the locally adaptive coding scheme. However, experimental results confirm that the hiding capacity of our proposed scheme is around 1.36 bpi in most digital images, which is typically higher than that of Chang et al.'s [17]. Moreover, the average compression rate that can be achieved with our proposed scheme is 0.49 bpp, which outperforms both Lin and Chang's scheme (0.50 bpp), Tsai (0.50 bpp), Chang et al.'s scheme (0.53 bpp), and Yang and Lin's scheme (0.53 bpp). (C) 2011 Elsevier Inc. All rights reserved.
C1 [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
   [Chang, Chin-Chen; Thai Son Nguyen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 Providence University - Taiwan; Feng Chia University; National Chung
   Cheng University
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd, Taichung 43301, Taiwan.
EM ccc@cs.ccu.edu.tw; thaison@tvu.edu.vn; mhlin3@pu.edu.tw
RI Nguyen, Thai-Son/AGD-3594-2022; Chang, Ching-Chun/JAN-6210-2023
OI Nguyen, Thai-Son/0000-0001-7008-0462; Lin, Chia-Chen/0000-0003-4480-7351
CR BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P947
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fridrich J, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P223, DOI 10.1109/ITCC.2001.918795
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Huang HC, 2002, IEICE T FUND ELECTR, VE85A, P1719
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Iwata M, 2004, IEICE T FUND ELECTR, VE87A, P929
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Lin Chih Yang, 2006, J COMPUT, V17, P3
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pan JS, 2004, IEICE T FUND ELECTR, VE87A, P1839
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Wang John, 2008, International Journal of Information and Decision Sciences, V1, P1
   Wu YT, 2007, PATTERN RECOGN, V40, P3753, DOI 10.1016/j.patcog.2007.04.013
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   Zhang XD, 2006, IEEE COMMUN LETT, V10, P7, DOI 10.1109/LCOMM.2006.01019
NR 26
TC 42
Z9 43
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 664
EP 672
DI 10.1016/j.jvcir.2011.06.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800009
DA 2024-07-18
ER

PT J
AU Chuang, JC
   Hu, YC
AF Chuang, Jun-Chou
   Hu, Yu-Chen
TI An adaptive image authentication scheme for vector quantization
   compressed image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tamper detection; Image authentication; Watermark; Image compression;
   Vector quantization; Index table; Random values; Random seed
ID CODEBOOK SEARCH ALGORITHM; OWNERSHIP; WATERMARK
AB This paper proposes an image authentication scheme which detects illegal modifications for image vector quantization (VQ). In the proposed scheme, the index table is divided into non-overlapping index blocks. The authentication data is generated by using the pseudo random sequence. Our scheme can adaptively determine both the size of the authentication data and the number of the indices in each index block. Then, the selected indices are used to embed the secret data to generate the embedded image.
   To authenticate the given VQ compressed image, two sets of the authentication data are needed to perform the tamper detection process. One set is generated by using the pseudo random number sequence. The other set is extracted from the compressed image. The experimental results demonstrate that the proposed scheme achieves acceptable image quality of the embedded image while keeping good detecting accuracy. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 43301, Taiwan.
   [Chuang, Jun-Chou] Providence Univ, Dept Comp Sci & Commun Engn, Taichung 43301, Taiwan.
C3 Providence University - Taiwan; Providence University - Taiwan
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200 Chung Chi Rd, Taichung 43301, Taiwan.
EM lzchung@pu.edu.tw; ychu@pu.edu.tw
RI Hui, Yu/JOZ-3598-2023; Hu, Yu-Chen/AAT-5264-2020
OI Hu, Yu-Chen/0000-0002-5055-3645
FU Providence University, Taichung, Taiwan under National Science Council,
   Taipei, ROC [NSC 99-2221-E-126-004-MY2, NSC 99-2632-E-126-001-MY3]
FX This research was supported by Providence University, Taichung, Taiwan
   under Contract the National Science Council, Taipei, ROC under Contract
   NSC 99-2221-E-126-004-MY2 and NSC 99-2632-E-126-001-MY3.
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Bartolini F, 2001, P IEEE, V89, P1403, DOI 10.1109/5.959338
   Chan CS, 2007, PATTERN RECOGN, V40, P681, DOI 10.1016/j.patcog.2006.05.018
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chang CC, 1998, IEEE T CONSUM ELECTR, V44, P1201
   Chen WC, 2009, EXPERT SYST APPL, V36, P1300, DOI 10.1016/j.eswa.2007.11.018
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Hu YC, 2011, OPTO-ELECTRON REV, V19, P104, DOI 10.2478/s11772-010-0073-0
   Hu YC, 2003, IMAGING SCI J, V51, P221, DOI 10.1080/13682199.2003.11784428
   Hu YC, 2008, IMAGE VISION COMPUT, V26, P657, DOI 10.1016/j.imavis.2007.08.001
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lie WN, 2006, IEEE T INF FOREN SEC, V1, P330, DOI 10.1109/TIFS.2006.879297
   Lin CY, 2001, IEEE T CIRC SYST VID, V11, P153, DOI 10.1109/76.905982
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lou DC, 2000, IEEE T CONSUM ELECTR, V46, P31, DOI 10.1109/30.826378
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Phan RCW, 2008, PATTERN RECOGN, V41, P3493, DOI 10.1016/j.patcog.2008.05.009
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sang J, 2008, IEEE T INSTRUM MEAS, V57, P595, DOI 10.1109/TIM.2007.911585
   Tsai P, 2005, IMAGING SCI J, V53, P149, DOI 10.1179/136821905X50406
   Tsai P, 2008, FUND INFORM, V87, P447
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Xie LH, 2001, IEEE T MULTIMEDIA, V3, P242, DOI 10.1109/6046.923823
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
NR 26
TC 48
Z9 50
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 440
EP 449
DI 10.1016/j.jvcir.2011.03.011
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800008
DA 2024-07-18
ER

PT J
AU Dokládal, P
   Dokládalová, E
AF Dokladal, Petr
   Dokladalova, Eva
TI Computationally efficient, one-pass algorithm for morphological filters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mathematical morphology; Serial filters; Nonlinear filters; Real-time
   implementation; Streaming; Algorithm
ID STRUCTURING ELEMENTS; MATHEMATICAL MORPHOLOGY; MAX FILTERS; IMAGE; MIN;
   DECOMPOSITION; OPERATIONS; EROSIONS; MINIMUM
AB Many useful morphological filters are built as long concatenations of erosions and dilations: openings, closings, size distributions, sequential filters, etc. This paper proposes a new algorithm implementing morphological dilation and erosion of functions. It supports rectangular structuring element, runs in linear time w.r.t. the image size and constant time w.r.t. the structuring element size, and has minimal memory usage.
   It has zero algorithm latency and processes data in stream. These properties are inherited by operators composed by concatenation, and allow their efficient implementation. We show how to compute in one pass an Alternate Sequential Filter (ASF(n)) regardless the number of stages n.
   This algorithm opens the way to such time-critical applications where the complexity and memory requirements of serial morphological operators represented a bottleneck limiting their usability. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Dokladal, Petr] Mines PARISTECH, Ctr Math Morphol, Dept Math & Syst, F-77300 Fontainebleau, France.
   [Dokladalova, Eva] Univ Paris Est, Unite Mixte Rech, CNRS UMLV ESIEE, UMR 8049, F-93162 Noisy Le Grand, France.
C3 Universite PSL; MINES ParisTech; Universite Gustave-Eiffel; ESIEE Paris;
   Centre National de la Recherche Scientifique (CNRS); Ecole des Ponts
   ParisTech
RP Dokládal, P (corresponding author), Mines PARISTECH, Ctr Math Morphol, Dept Math & Syst, 35 Rue St Honore, F-77300 Fontainebleau, France.
EM petr.dokladal@mines-paristech.fr; eva.dokladalova@esiee.fr
RI DOKLADALOVA, Eva/L-4374-2019; Dokladalova, Eva/AAO-4175-2020
OI Dokladalova, Eva/0000-0003-1765-7394; Dokladal, Petr/0000-0002-6502-7461
CR Anelli G, 1998, IEEE T PATTERN ANAL, V20, P217, DOI 10.1109/34.659943
   CHAUDHURI BB, 1990, PATTERN RECOGN LETT, V11, P77, DOI 10.1016/0167-8655(90)90116-J
   CLIENTI C, 2008, ADV CONCEPTS INTELLI
   Coltuc D, 1997, IEEE T CIRCUITS-II, V44, P660, DOI 10.1109/82.618040
   Cord A., 2007, P INT S MATH MORPH I, P387
   DARDENNE R, LIBMORPHO LIB
   DOKLADAL P, 2008, ADV CONC INT VIS SYS
   DOKLADAL P, 2008, EUR SIGN PROC C 2008
   Dougherty E., 1992, Mathematical Morphology in Image Processing
   Gevorkian DZ, 1997, IEEE T PATTERN ANAL, V19, P526, DOI 10.1109/34.589214
   Gil J, 2002, IEEE T PATTERN ANAL, V24, P1606, DOI 10.1109/TPAMI.2002.1114852
   GIL J, 1993, IEEE T PATTERN ANAL, V15, P504, DOI 10.1109/34.211471
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Hedberg H, 2009, IEEE T IMAGE PROCESS, V18, P562, DOI 10.1109/TIP.2008.2010108
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Lemire D., 2006, Nordic Journal of Computing, V13, P328
   Lemire D, 2009, PATTERN RECOGN, V42, P2169, DOI 10.1016/j.patcog.2008.11.030
   LEMONNIER F, 1995, IEEE INT WORKSH NONL
   Mara B, 2007, COMPUT GEOSCI-UK, V33, P151, DOI 10.1016/j.cageo.2006.07.004
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   Matheron G., 1975, Random sets and integral geometry
   Miyatake T, 1996, SYST COMPUT JPN, V27, P74
   Mukhopadhyay S, 2002, SIGNAL PROCESS, V82, P527, DOI 10.1016/S0165-1684(01)00143-8
   PECHT J, 1985, PATTERN RECOGN LETT, V3, P113, DOI 10.1016/0167-8655(85)90017-0
   Sabourin R, 1997, IEEE T PATTERN ANAL, V19, P976, DOI 10.1109/34.615447
   Salembier P, 1996, IEEE T IMAGE PROCESS, V5, P881, DOI 10.1109/83.503906
   SERRA J, 1994, SIGNAL PROCESS, V38, P3, DOI 10.1016/0165-1684(94)90052-3
   Serra J., 1988, IMAGE ANAL MATH MORP, P2
   Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646
   Soille P, 2002, IEEE T GEOSCI REMOTE, V40, P2042, DOI 10.1109/TGRS.2002.804618
   STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6
   Urbach ER, 2008, IEEE T IMAGE PROCESS, V17, P1, DOI 10.1109/TIP.2007.912582
   Van Droogenbroeck M, 2005, J MATH IMAGING VIS, V22, P121, DOI 10.1007/s10851-005-4886-2
   VANDENBOOMGAARD R, 1994, ASPECTS VISUAL FORM, P552
   VanDroogenbroeck M, 1996, PATTERN RECOGN LETT, V17, P1451, DOI 10.1016/S0167-8655(96)00113-4
   VANHERK M, 1992, PATTERN RECOGN LETT, V13, P517, DOI 10.1016/0167-8655(92)90069-C
   Vincent L., 2000, Fundamenta Informaticae, V41, P57
   Wilkinson M.H., 2009, P 9 INT S MATH MORPH
   ZHUANG X, 1994, J MATH IMAGING VIS, V4, P5
   ZHUANG XH, 1986, COMPUT VISION GRAPH, V35, P370, DOI 10.1016/0734-189X(86)90006-X
NR 40
TC 28
Z9 30
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 411
EP 420
DI 10.1016/j.jvcir.2011.03.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fu, R
   Gao, XB
   Li, XL
   Tao, DC
   Jian, YJ
   Li, J
   Hu, HQ
   Yang, HG
AF Fu, Rong
   Gao, Xinbo
   Li, Xuelong
   Tao, Dacheng
   Jian, Yongjun
   Li, Jie
   Hu, Hongqiao
   Yang, Huigen
TI An integrated aurora image retrieval system: AuroraEye
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Aurora; Adaptive LBP; Gabor; Image
   texture analysis; Database; Feature extraction; Local binary pattern
ID SUPPORT VECTOR MACHINES; RELEVANCE FEEDBACK; SELECTION; SUBSPACE; TENSOR
AB With the digital all-sky imager (ASI) emergence in aurora research, millions of images are captured annually. However, only a fraction of which can be actually used. To address the problem incurred by low efficient manual processing, an integrated image analysis and retrieval system is developed. For precisely representing aurora image, macroscopic and microscopic features are combined to describe aurora texture. To reduce the feature dimensionality of the huge dataset, a modified local binary pattern (LBP) called ALBP is proposed to depict the microscopic texture, and scale-invariant Gabor and orientation-invariant Gabor are employed to extract the macroscopic texture. A physical property of aurora is inducted as region features to bridge the gap between the low-level visual features and high-level semantic description. The experiments results demonstrate that the ALBP method achieves high classification rate and low computational complexity. The retrieval simulation results show that the developed retrieval system is efficient for huge dataset. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Tao, Dacheng] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Fu, Rong; Gao, Xinbo; Jian, Yongjun; Li, Jie] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Li, Xuelong] Chinese Acad Sci, Ctr OPT IMagery Anal & Learning OPTIMAL, State Key Lab Transient Opt & Photon, Xian Inst Opt & Precis Mech, Xian 710779, Peoples R China.
   [Hu, Hongqiao; Yang, Huigen] Polar Res Inst China, SOA Key Lab Polar Sci, Shanghai 200136, Peoples R China.
C3 Nanyang Technological University; Xidian University; Chinese Academy of
   Sciences; Xi'an Institute of Optics & Precision Mechanics, CAS; State
   Key Laboratory of Transient Optics & Photonics; Polar Research Institute
   of China
RP Tao, DC (corresponding author), Nanyang Technol Univ, Sch Comp Engn, 50 Nanyang Ave,Blk N4, Singapore 639798, Singapore.
EM dacheng.tao@ieee.org
RI Li, jie/GXG-4583-2022; Tao, Dacheng/A-5449-2012; Li,
   Xuelong/ABF-3381-2020; li, xiang/GWM-6319-2022; Li, Xuelong/Z-3785-2019
OI Tao, Dacheng/0000-0001-7225-5449; Li, Xuelong/0000-0002-0019-4197
FU R&D Special Fund for Public Welfare Industry (meteorology)
   [GYHY200706043]; Ph.D. Programs Foundation of Ministry of Education of
   China [20090203110002]; Natural Science Basic Research Plane in Shaanxi
   Province of China [2009JM8004]
FX This research was supported by the R&D Special Fund for Public Welfare
   Industry (meteorology) (GYHY200706043), the Ph.D. Programs Foundation of
   Ministry of Education of China (No. 20090203110002), the Natural Science
   Basic Research Plane in Shaanxi Province of China (2009JM8004). We also
   would like to thank YRS for providing labeled samples of aurora.
CR AKASOFU SI, 1964, SCIENCE, V12, P273
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Gao XB, 2009, PATTERN RECOGN LETT, V30, P140, DOI 10.1016/j.patrec.2008.02.009
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hu H., 1999, ANTARCTICA CHINESE J, V11, P8
   Hu ZJ, 2009, J ATMOS SOL-TERR PHY, V71, P794, DOI 10.1016/j.jastp.2009.02.010
   Jiang W, 2005, INT CONF ACOUST SPEE, P509
   Li XL, 2003, PATTERN RECOGN LETT, V24, P2431, DOI 10.1016/S0167-8655(03)00072-2
   Li XL, 2003, PATTERN RECOGN LETT, V24, P1935, DOI 10.1016/S0167-8655(03)00032-1
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qin XJ, 2005, IEEE I CONF COMP VIS, P128
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Si S, 2010, IEEE T IMAGE PROCESS, V19, P1075, DOI 10.1109/TIP.2009.2035867
   Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939
   Stormer C., 1955, The Polar Aurora
   SYRJASUO KT, 2007, 8 INT C SUBST ICS8 U, P309
   Syrjäsuo MT, 2005, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, P420
   Syrjäsuo MT, 2004, Proceedings of the Fourth IASTED International Conference on Visualization, Imaging, and Image Processing, P224
   Syrjäsuo MT, 2004, ANN GEOPHYS-GERMANY, V22, P1103, DOI 10.5194/angeo-22-1103-2004
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P3, DOI 10.1109/TCSVT.2007.906936
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Tefas A, 2001, IEEE T PATTERN ANAL, V23, P735, DOI 10.1109/34.935847
   Tian XM, 2010, IEEE T IMAGE PROCESS, V19, P805, DOI 10.1109/TIP.2009.2035866
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang MH, 2010, INT J COMPUT MATH, V87, P1289, DOI 10.1080/00207160802275977
   Yang H, 2000, J ATMOS SOL-TERR PHY, V62, P787, DOI 10.1016/S1364-6826(00)00054-7
   YANG HG, 2005, CHINESE J POLAR RES, V17, P107
   Yuan Y, 2009, IEEE T CIRC SYST VID, V19, P772, DOI 10.1109/TCSVT.2009.2017306
   Zhu B, 2000, IEEE T IMAGE PROCESS, V9, P163, DOI 10.1109/83.817609
NR 34
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 787
EP 797
DI 10.1016/j.jvcir.2010.06.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500003
DA 2024-07-18
ER

PT J
AU Li, ZX
   Shi, ZP
   Liu, X
   Li, ZQ
   Shi, ZZ
AF Li, Zhixin
   Shi, Zhiping
   Liu, Xi
   Li, Zhiqing
   Shi, Zhongzhi
TI Fusing semantic aspects for image annotation and retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Automatic image annotation; Latent aspect model; PLSA; Adaptive
   asymmetric learning; Image retrieval; Semantic gap; Visual feature;
   Textual word
AB In this paper, we present an approach based on probabilistic latent semantic analysis (PLSA) to achieve the task of automatic image annotation and retrieval. In order to model training data precisely, each image is represented as a bag of visual words. Then a probabilistic framework is designed to capture semantic aspects from visual and textual modalities, respectively. Furthermore, an adaptive asymmetric learning algorithm is proposed to fuse these aspects. For each image document, the aspect distributions of different modalities are fused by multiplying different weights, which are determined by the visual representations of images. Consequently, the probabilistic framework can predict semantic annotation precisely for unseen images because it associates visual and textual modalities properly. We compare our approach with several state-of-the-art approaches on a standard Corel dataset. The experimental results show that our approach performs more effectively and accurately. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Li, Zhixin; Shi, Zhiping; Liu, Xi; Li, Zhiqing; Shi, Zhongzhi] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Li, Zhixin] Guangxi Normal Univ, Coll Comp Sci & Informat Technol, Guilin 541004, Peoples R China.
   [Shi, Zhiping] Capital Normal Univ, Informat Engn Coll, Beijing 100048, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Guangxi Normal University; Capital Normal University
RP Li, ZX (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
EM lizx@ics.ict.ac.cn; shizp@ics.ict.ac.cn; liux@ics.ict.ac.cn;
   lizq@ics.ict.ac.cn; shizz@ics.ict.ac.cn
RI Li, Zhixin/ABI-9264-2022; shi, zhiping/J-9594-2012
OI Li, Zhixin/0000-0002-5313-6134; Shi, Zhiping/0000-0002-3562-8602
FU National Basic Research Priorities Programme [2007CB311004]; National
   Science and Technology Support Plan [2006BAC08B06]; National Natural
   Science Foundation of China [60775035, 60933004, 60903141, 60970088,
   60903079]
FX This work is supported by the National Basic Research Priorities
   Programme (No. 2007CB311004), the National Science and Technology
   Support Plan (No. 2006BAC08B06) and the National Natural Science
   Foundation of China (Nos. 60775035, 60933004, 60903141, 60970088,
   60903079).
CR Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Bosch A, 2007, IMAGE VISION COMPUT, V25, P778, DOI 10.1016/j.imavis.2006.07.015
   Brants T, 2005, INFORM RETRIEVAL, V8, P181, DOI 10.1007/s10791-005-5658-8
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chang E, 2003, IEEE T CIRC SYST VID, V13, P26, DOI 10.1109/TCSVT.2002.808079
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jeon J., 2003, P 26 ANN INT ACM SIG
   LAVRENKO V, 2003, ADV NEURAL INFORM PR, V16, P553
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li ZX, 2009, IEEE IMAGE PROC, P1857, DOI 10.1109/ICIP.2009.5413595
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Mori Y., 1999, MISRM
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
NR 24
TC 14
Z9 16
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 798
EP 805
DI 10.1016/j.jvcir.2010.06.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500004
DA 2024-07-18
ER

PT J
AU Lam, PM
   Leung, CS
   Wong, TT
   Fu, CW
AF Lam, Ping-Man
   Leung, Chi-Sing
   Wong, Tien-Tsin
   Fu, Chi-Wing
TI Uniformly sampling multi-resolution analysis for image-based relighting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spherical wavelet; Image compression; Global Lighting; Multi-resolution
   analysis; Image-based relighting; Plenoptic function; Spherical basis;
   Spherical harmonics
ID DATA-COMPRESSION; WAVELETS
AB Image-based relighting allows us to efficiently light a scene under complicated illumination conditions. However, the traditional cubemap based multi-resolution analysis unevenly samples the spherical surface, with a higher sampling rate near the face corners and a lower one near the face centers. The nonuniformity penalizes the efficiency of data representation. This paper presents a uniformly sampling multi-resolution analysis approach, namely the icosahedron spherical wavelets (ISW), for image-based relighting under time-varying distant environment. Since the proposed ISW approach provides a highly uniform sampling distribution over the spherical domain, we thus can efficiently handle high frequency variations locally in the illumination changes as well as reduce the number of wavelet coefficients needed in the renderings. Furthermore, visual artifacts are demonstrated to be better suppressed in the proposed ISW approach. Compared with the traditional cubemap based multi-resolution analysis approach, we show that our approach can effectively produce higher quality image sequences that are closer to the ground truth in terms of percentage square errors. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lam, Ping-Man; Leung, Chi-Sing] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
   [Wong, Tien-Tsin] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Fu, Chi-Wing] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
C3 City University of Hong Kong; Chinese University of Hong Kong; Nanyang
   Technological University
RP Leung, CS (corresponding author), City Univ Hong Kong, Dept Elect Engn, Kowloon Tong, Hong Kong, Peoples R China.
EM eeleungc@cityu.edu.hk
RI FU, Chi-Wing/A-3716-2011; Fu, Chi-Wing/X-4703-2019
OI Fu, Chi Wing/0000-0002-5238-593X; LEUNG, Chi Sing
   Andrew/0000-0003-0962-6723
FU Hong Kong Government [CityU 116508, CUHK417107]
FX This work was supported by General Research Funds from Hong Kong
   Government (Project No.: CityU 116508) and (Project No. CUHK417107).
CR Adelson E.H., 1991, Computational Models of Visual Processing, P3
   Bajaj C, 2001, ACM T GRAPHIC, V20, P10, DOI 10.1145/383745.383747
   Chen SN, 1995, SWIMMING THROUGH TROUBLED WATER, P29
   CHEN WC, 2002, SIGGRAPH 2002, P447
   CHOUDHURY B, 2000, GRAPP2006, P176
   Debevec P, 2002, IEEE COMPUT GRAPH, V22, P26, DOI 10.1109/38.988744
   Dragotti PL, 2000, IEEE T GEOSCI REMOTE, V38, P416, DOI 10.1109/36.823937
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   KAUTZ J, 2002, P 13 EUR WORKSH REND, P291
   Kim BJ, 2000, IEEE T CIRC SYST VID, V10, P1374, DOI 10.1109/76.889025
   Lessig C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330515
   Leung CS, 2006, IEEE T IMAGE PROCESS, V15, P1031, DOI 10.1109/TIP.2005.863936
   LIU X, 2004, P EUR S REND, P337
   Magnor M, 2000, IEEE T CIRC SYST VID, V10, P338, DOI 10.1109/76.836278
   Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280
   Pastor L., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P70, DOI 10.1109/ICIAP.1999.797573
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   RAMAMOORTHI R, 2002, SIGGRAPH 02, P517
   Schroder P., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P161, DOI 10.1145/218380.218439
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Sloan PP, 2003, ACM T GRAPHIC, V22, P370, DOI 10.1145/882262.882279
   STOLLNITZ EJ, 1995, IEEE COMPUT GRAPH, V15, P76, DOI 10.1109/38.376616
   Tsai YT, 2006, ACM T GRAPHIC, V25, P967, DOI 10.1145/1141911.1141981
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang Z, 2004, COMPUT VIS IMAGE UND, V96, P327, DOI 10.1016/j.cviu.2004.03.017
   Wong TT, 2003, IEEE T CIRC SYST VID, V13, P1107, DOI 10.1109/TCSVT.2003.817628
   Wong TT, 2002, IEEE T MULTIMEDIA, V4, P361, DOI 10.1109/TMM.2002.802835
   Wong TT, 2001, IEEE COMPUT GRAPH, V21, P32, DOI 10.1109/38.909013
   WONG TT, 1997, P 8 EUR WORKSH REND, P13
   YU Y, 1998, SIGGRAPH 98, P207
NR 31
TC 1
Z9 1
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 693
EP 706
DI 10.1016/j.jvcir.2010.05.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400009
DA 2024-07-18
ER

PT J
AU Zhang, W
   Wu, QMJ
   Wang, GH
   You, XG
   Wang, YF
AF Zhang, Wei
   Wu, Q. M. Jonathan
   Wang, Guanghui
   You, Xinge
   Wang, Yongfang
TI Image matching using enclosed region detector
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Enclosed region; Affine-invariance; Image matching; Scale invariance;
   Stereo vision; Feature detection; External enclosing region; Internal
   enclosed region
ID AFFINE; RECOGNITION; SCALE
AB Affine-invariant region detection is the basic technique for visual matching and has been widely applied in many areas. In this paper, we propose a simple yet effective method to detect the affine-invariant regions from gray image, which is called enclosed region. The enclosed region is detected based on the observation that one physical object is enclosed by the same region before and after affine transformation. The proposed method is a three-step method. Firstly, we segment the initial regions by using thresholds on the image. Secondly, external enclosing region (EER) and internal enclosed region (IER) are defined for each initial region, and we select the enclosed regions from the initial regions through applying histogram constraints on EER and IER. Thirdly, the largely overlapping regions are removed. Experiments on typical images exhibit the robustness of the proposed enclosed region detector. Extensively quantitative evaluation and comparison demonstrate that the proposed method outperforms state-of-the-art methods. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Zhang, Wei; Wu, Q. M. Jonathan; Wang, Guanghui] Univ Windsor, Dept Elect & Comp Engn, CVSSL, Windsor, ON N9B 3P4, Canada.
   [Zhang, Wei; You, Xinge] Huazhong Univ Sci & Technol, Dept Elect & Informat Engn, Wuhan 430074, Peoples R China.
   [Wang, Yongfang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 University of Windsor; Huazhong University of Science & Technology;
   Shanghai University
RP Zhang, W (corresponding author), Univ Windsor, Dept Elect & Comp Engn, CVSSL, Windsor, ON N9B 3P4, Canada.
EM weizhang1216@hotmail.com
RI cai, bo/G-1491-2010; Wu, Q.M.Jonathan/O-3234-2017; xin,
   liang/JFS-5770-2023; Wang, Guanghui/AAV-4605-2021
OI Wang, Guanghui/0000-0001-6213-0693
FU Natural Sciences and Engineering Research Council of Canada; Chinese
   NSFC [60972137]
FX The work was supported in part by Natural Sciences and Engineering
   Research Council of Canada. The work was also granted in part by Chinese
   NSFC 60972137.
CR [Anonymous], P 28 WORKSH AAPR
   [Anonymous], C COMP VIS PATT REC
   CAI H, 2007, IEEE INT C TOOLS ART, V1, P540
   Cheng LA, 2008, IEEE GEOSCI REMOTE S, V5, P246, DOI 10.1109/LGRS.2008.915599
   DONOSER M, 2006, IEEE C COMPUTER VISI, V1, P553
   Fraundorfer F, 2005, LECT NOTES COMPUT SC, V3540, P45
   Goedemé T, 2004, PROC CVPR IEEE, P24
   Guerrero JJ, 2008, IEEE T ROBOT, V24, P494, DOI 10.1109/TRO.2008.918043
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kadir T., 2004, PROC 8 EUROPEAN C CO, P345
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Ling HB, 2005, IEEE I CONF COMP VIS, P1466
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K., 2002, P 7 EUR C COMP VIS E
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   PLATEL B, 2006, P 9 EUR C COMP VIS G, P418
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Shao L, 2007, INFORM SCIENCES, V177, P1088, DOI 10.1016/j.ins.2006.09.003
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Wakahara T, 2001, IEEE T PATTERN ANAL, V23, P384, DOI 10.1109/34.917573
   Xiao JJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P603, DOI 10.1109/ICCV.2003.1238403
   Yang ZW, 1999, IEEE T IMAGE PROCESS, V8, P934, DOI 10.1109/83.772236
NR 28
TC 5
Z9 7
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 271
EP 282
DI 10.1016/j.jvcir.2009.11.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800001
DA 2024-07-18
ER

PT J
AU Cai, HY
   Zheng, JY
AF Cai, Hongyuan
   Zheng, Jiang Yu
TI Key views for visualizing large spaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Key view; Panorama; Image indexing; Virtual environments; Camera
   placement; Visibility; Significance; LiDAR data
AB Image is a dominant medium among video, 3D model, and other media for visualizing environment and creating virtual access on the Internet. The location of image capture is, however, subjective and has relied on the esthetic sense of photographers up until this point. In this paper, we will not only visualize areas with images, but also propose a general framework to determine where the most distinct viewpoints should be located. Starting from elevation data, we present spatial and content information in ground-based images such that (1) a given number of images can have maximum coverage on informative scenes; (2) a set of key views can be selected with certain continuity for representing the most distinct views. According to the scene visibility, continuity, and data redundancy, we evaluate viewpoints numerically with an object-emitting illumination model. Our key view exploration may eventually reduce the visual data to transmit, facilitate image acquisition, indexing and interaction, and enhance perception of spaces. Real sample images are captured based on planned positions to form a visual network to index the area. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Cai, Hongyuan; Zheng, Jiang Yu] Indiana Univ Purdue Univ, Dept Comp Sci, Indianapolis, IN 46202 USA.
C3 Indiana University System; Indiana University Indianapolis
RP Cai, HY (corresponding author), Indiana Univ Purdue Univ, Dept Comp Sci, 723 W Michigan St, Indianapolis, IN 46202 USA.
EM hocai@cs.iupui.edu; jzheng@cs.iupui.edu
CR AGARWALA A, 2006, SIGGRAPH 2006 JUL, P853
   Aliaga DG, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P331, DOI 10.1109/VISUAL.2002.1183792
   Aliaga DG, 2003, IEEE COMPUT GRAPH, V23, P22, DOI 10.1109/MCG.2003.1242379
   Chen BQ, 2001, SPRING EUROGRAP, P279
   Chen SN, 1995, SWIMMING THROUGH TROUBLED WATER, P29
   COORG S, 1999, IEEE COMP SOC C COMP, P625
   Coorg S., 1998, IEEE C COMPUTER VISI, P23
   Hu JH, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P184
   Jiang Yu Zheng, 2005, 13th Annual ACM International Conference on Multimedia, P986, DOI 10.1145/1101149.1101354
   Kennedy Lyndon., 2007, Proceedings of the 15th International Conference on Multimedia, P631, DOI DOI 10.1145/1291233.1291384
   Li SG, 2004, P IEEE VIRT REAL ANN, P235, DOI 10.1109/VR.2004.1310086
   Nayar S. K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P217, DOI 10.1109/CVPR.1999.784632
   Nayar SK, 2000, PROC CVPR IEEE, P388
   Rav-Acha A, 2008, INT J COMPUT VISION, V78, P187, DOI 10.1007/s11263-007-0101-9
   ROMAN A, 2004, IEEE VISUALIZATION
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Szeliski R, 1997, P 24 ANN C COMP GRAP, P251
   Teller S, 1998, PACIFIC GRAPHICS '98, PROCEEDINGS, P45, DOI 10.1109/PCCGA.1998.731997
   Uyttendaele M., 2004, IEEE CGA, V24
   Yagi Y, 2004, INT J COMPUT VISION, V58, P173, DOI 10.1023/B:VISI.0000019684.35147.fc
   Yagi Y, 2005, IEEE T PATTERN ANAL, V27, P78, DOI 10.1109/TPAMI.2005.11
   Zheng JY, 2006, IEEE T VIS COMPUT GR, V12, P155, DOI 10.1109/TVCG.2006.37
   ZHENG JY, 1992, INT J COMPUT VISION, V9, P55
NR 24
TC 2
Z9 3
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 420
EP 427
DI 10.1016/j.jvcir.2009.04.005
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nikolova, M
AF Nikolova, Mila
TI One-iteration dejittering of digital video images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Error measures; Fast algorithms; Image modeling; Image restoration;
   Jitter; Matching; Non-convex data-fitting; Non-smooth data-fitting;
   Restoration; Video
AB We propose several very fast algorithms to dejitter digital video images in one iteration. They are based on an essential disproportion of the magnitude of the second-order differences along the columns of a real-world image and all its jittered versions. The optimal row positions are found using non-smooth and possibly non-convex local criteria, applied on the second-order differences between consecutive rows. The dejittering iteration involves a number of steps equal to the number of the rows of the image. These algorithms are designed for gray-value and color natural images, as well as to noisy images. A reasonable version of these algorithms can be considered as parameter-free. We propose specific error measures to assess the success of dejittering. We provide experiments with random and structured jitter. The obtained results outperform by far the existing methods both in quality and in speed (the ours need around 1 second for a 512 x 512 image on Matlab). Our algorithms are a crucial step towards real-time dejittering of digital video sequences. (C) 2009 Elsevier Inc. All rights reserved.
C1 PRES UniverSud, CNRS, CMLA, ENS Cachan, F-94230 Cachan, France.
C3 Universite Paris Saclay; Centre National de la Recherche Scientifique
   (CNRS)
RP Nikolova, M (corresponding author), PRES UniverSud, CNRS, CMLA, ENS Cachan, 61 Av President Wilson, F-94230 Cachan, France.
EM nikolova@cmla.ens-cachan.fr
CR Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Durand S, 2003, SIAM J SCI COMPUT, V24, P1754, DOI 10.1137/S1064827501397792
   Durand S, 2007, MULTISCALE MODEL SIM, V6, P547, DOI 10.1137/06065828X
   Kang SH, 2006, IMAGE VISION COMPUT, V24, P143, DOI 10.1016/j.imavis.2005.09.022
   KANG SH, 2007, SPRINGER SERIES MATH, P35
   Kokaram A, 1997, INT CONF ACOUST SPEE, P2553, DOI 10.1109/ICASSP.1997.595309
   Kokaram A., 1998, Motion Picture Restoration
   Laborelli L, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P331
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Nikolova M, 2005, MULTISCALE MODEL SIM, V4, P960, DOI 10.1137/040619582
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Nikolova M, 2000, SIAM J APPL MATH, V61, P633, DOI 10.1137/S0036139997327794
   Shen JH, 2004, SIAM J APPL MATH, V64, P1691, DOI 10.1137/S0036139902418699
   Ten Daubechies I., 1992, lecture on wavelets
   TORROBA PL, 1994, OPT ENG, V33, P528, DOI 10.1117/12.152006
   WELK M, 2008, THESIS U SAARBRUECKE
   Welk M, 2007, SIGNAL PROCESS, V87, P291, DOI 10.1016/j.sigpro.2005.12.013
   WINKLER G, 1999, PATTERN ANAL MACHINE, V9, P479
NR 18
TC 5
Z9 5
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2009
VL 20
IS 4
BP 254
EP 274
DI 10.1016/j.jvcir.2009.03.004
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 447EV
UT WOS:000266175300003
DA 2024-07-18
ER

PT J
AU Song, D
   Cao, L
   Chen, CW
AF Song, Daewon
   Cao, Lei
   Chen, Chang Wen
TI Robust multiple description image coding over wireless networks based on
   wavelet tree coding, error resilient entropy coding, and error
   concealment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilience; MDSQ; wavelet tree coding; EREC; robust multiple
   description image coding; wireless networks; error concealment SPIHT
ID QUANTIZATION; TRANSMISSION; CHANNELS
AB In this paper, we propose an integrated robust multiple description coding (MDC) scheme for compressed still images over error-prone channels with both packet loss and random bit errors. Multiple descriptions are first generated independently by using multiple description scalar quantizer (MDSQ). To achieve an excellent error resilient capability for each description, multiple bitstreams are then generated based on wavelet trees along the spatial orientations. The spatial orientation trees in the wavelet domain are individually encoded using SPIHT. Error propagation is thus limited within each bitstreams. However, synchronization words are usually needed to avoid error propagation across multiple independent bitstreams. In order to maintain high compression efficiency robust synchronization, we adopt error resilient entropy coding (EREC) to re-organize these variable-length bitstreams into fixed-length data slots before multiplexing and transmission. Therefore, the synchronization of the start of each bitstream can be automatically obtained at the receiver. Finally, to alleviate the devastating image degradation resulted from errors in the beginning of the bitstreams, we propose an error concealment technique to both constrain the EREC/MDC decoding and post-process the decoded wavelet coefficients. With analysis and experimental results, we have demonstrated how each of these components has contributed to the overall robustness of the proposed transmission of compressed images over wireless channels. (c) 2008 Published by Elsevier Inc.
C1 [Chen, Chang Wen] SUNY Buffalo, Buffalo, NY 14260 USA.
   [Song, Daewon] LG Dacom, Res Inst Technol, IPTV Team, Taejon 303350, South Korea.
   [Cao, Lei] Univ Mississippi, Dept EE, University, MS 38677 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo; University of Mississippi
RP Chen, CW (corresponding author), SUNY Buffalo, 201 Bell Hall Box 602000, Buffalo, NY 14260 USA.
EM dsong@lgdacom.net; lcao@olemiss.edu; chencw@buffalo.edu
CR Chandramouli R, 1998, IEEE T CIRC SYST VID, V8, P411, DOI 10.1109/76.709408
   Chen Q, 1998, IEEE T IMAGE PROCESS, V7, P496, DOI 10.1109/83.663494
   Creusere CD, 1997, IEEE T IMAGE PROCESS, V6, P1436, DOI 10.1109/83.624967
   Doufexi A, 2002, IEEE COMMUN MAG, V40, P172, DOI 10.1109/35.1000232
   Goyal VK, 1998, IEEE DATA COMPR CONF, P388, DOI 10.1109/DCC.1998.672173
   Goyal VK, 1998, 1998 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY - PROCEEDINGS, P408, DOI 10.1109/ISIT.1998.709013
   Goyal VK, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P674, DOI 10.1109/ICIP.1998.723588
   Jafarkhani H, 1999, IEEE T COMMUN, V47, P799, DOI 10.1109/26.771331
   Jiang W., 1999, P SPIE VIS COMM IM P
   LIN S, 1984, IEEE COMMUN MAG, V22, P5, DOI 10.1109/MCOM.1984.1091865
   Liu H, 1997, IEEE J SEL AREA COMM, V15, P1775, DOI 10.1109/49.650050
   Martucci SA, 1997, IEEE T CIRC SYST VID, V7, P109, DOI 10.1109/76.554422
   Mohr A. E., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P411, DOI 10.1109/ICIP.1999.821641
   Mohr AE, 1999, IEEE DATA COMPR CONF, P92, DOI 10.1109/DCC.1999.755658
   ORCHARD M, 1997, P IEEE ICIP
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   Ruf MJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB77
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Servetto SD, 2000, IEEE T IMAGE PROCESS, V9, P813, DOI 10.1109/83.841528
   Servetto SD, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P659, DOI 10.1109/ICIP.1998.723585
   Sherwood PG, 1997, IEEE SIGNAL PROC LET, V4, P189, DOI 10.1109/97.596882
   Sherwood PG, 1998, IEEE T COMMUN, V46, P1555, DOI 10.1109/26.737389
   Srinivasan M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P684, DOI 10.1109/ICIP.1998.723590
   TANABE N, 1992, IEEE J SEL AREA COMM, V10, P926, DOI 10.1109/49.138998
   VAISHAMPAYAN VA, 1993, IEEE T INFORM THEORY, V39, P821, DOI 10.1109/18.256491
   Wang Y, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.1997.602671
   Wang Y, 2001, IEEE T IMAGE PROCESS, V10, P351, DOI 10.1109/83.908500
   WHITEHOUSE S, 1999, P IEEE 3 WORKSH MULT, P425
NR 28
TC 5
Z9 7
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2008
VL 19
IS 5
BP 311
EP 319
DI 10.1016/j.jvcir.2008.03.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 318LO
UT WOS:000257093400003
DA 2024-07-18
ER

PT J
AU Samal, A
   Subramani, V
   Marx, D
AF Samal, Ashok
   Subramani, Vanitha
   Marx, David
TI Analysis of sexual dimorphism in human face
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE face recognition; sexual dimorphism; gender classification; face
   classification; human face
ID RECOGNITION
AB Human beings can easily distinguish between a male and a female face without much difficulty. The science of recognizing and differentiating different faces by humans is not completely understood and is still under research. Sexual dimorphism is common in humans and indeed in other species of animals as well. Significant differences between males and females exist in many aspects like size, color, body shapes, and weight. In this research, we characterize and analyze the sexual dimorphism in human face as a function of age and of face features. Features are grouped into six categories: head, eyes, orbits, nose, lips, and mouth, and ears. We demonstrate that the face of adult males is significantly different from adult females. We also identify the features that significantly contribute to the dimorphism of the face. This provides a basis for gender-based classification of faces. (C) 2007 Elsevier Inc. All rights reserved.
C1 [Samal, Ashok; Subramani, Vanitha; Marx, David] Univ Nebraska, Lincoln, NE 68588 USA.
C3 University of Nebraska System; University of Nebraska Lincoln
RP Samal, A (corresponding author), Univ Nebraska, Lincoln, NE 68588 USA.
EM samal@cse.unl.edu
CR [Anonymous], 1987, ANTHROPOMETRIC FACIA
   [Anonymous], 2019, SAS STAT US GUID REL
   Farkas LG, 2000, AESTHET PLAST SURG, V24, P179, DOI 10.1007/s002660010029
   FARKAS LG, 1995, AM SOC PLASTIC RECON, V75, P328
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   FERRARIO VF, 1993, J ANAT, V183, P593
   GILL G, 2002, UNPUB SEXUAL DIMORPH
   Gross R., 2002, P GERM S PATT REC DA
   Larsen CS, 2003, P NATL ACAD SCI USA, V100, P9103, DOI 10.1073/pnas.1633678100
   MARTINEZ AM, 1998, 24 CVC PURD U DEP CO
   Pascalis O, 2002, SCIENCE, V296, P1321, DOI 10.1126/science.1070223
   RICHARD SJ, 1999, J HUM EVOL, V26, P423
   SAMAL A, 1992, PATTERN RECOGN, V25, P65, DOI 10.1016/0031-3203(92)90007-6
   Stockburger D.W., 1996, INTRO STAT CONCEPTS
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 16
TC 41
Z9 45
U1 1
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2007
VL 18
IS 6
BP 453
EP 463
DI 10.1016/j.jvcir.2007.04.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 243NA
UT WOS:000251803400001
OA Green Published
DA 2024-07-18
ER

PT J
AU Park, SH
   Montag, ED
AF Park, Sung Ho
   Montag, Ethan D.
TI Evaluating tone mapping algorithms for rendering non-pictorial
   (scientific) high-dynamic-range images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE high-dynamic-range image; rendering; psychophysics
ID ADAPTATION; CONTRAST
AB Nine algorithms were implemented to overcome the problem associated with rendering high-dynamic-range scientific imagery to low-dynamic-range display devices. The algorithms were evaluated using two paired-comparison psychophysical experiments judging preference and "scientific usefulness". The results showed that, on average, the Zone System algorithm performed best and the Local Color Correction method performed the worst. However, the performance of the algorithms depended on the type of data being visualized. The low correlation between the preference and scientific usefulness judgments (R-2 = 0.31) indicated that observers used different criteria when judging the image preference versus scientific usefulness. The experiment was repeated using expert observers (radiologists) for an MR scan (Medical image). The results showed that the radiologists used similar criteria as the non-expert observers when judging the usefulness of the rendered images. A target detection experiment was conducted to measure the delectability of an embedded target in the Medical image. The result of the target detection experiment illustrated that the delectability of targets in the image is greatly influenced by the rendering algorithms due to the inherent difference in tone mapping among the algorithms. (C) 2007 Elsevier Inc. All rights reserved.
C1 Leuze Elect Inc, Fairport, NY 14450 USA.
   Samsung Informat Syst Amer, SAIT, San Jose, CA 95134 USA.
C3 Samsung
RP Montag, ED (corresponding author), Leuze Elect Inc, 465 Willow Brook Off Pk, Fairport, NY 14450 USA.
EM park.sung@samsung.com; emontag@mac.com
CR [Anonymous], 1996, P 23 ANN C COMP GRAP, DOI DOI 10.1145/237170.237262
   [Anonymous], 2000, Psychometric scaling, a toolkit for imaging systems development
   [Anonymous], 2000, WILEY SERIES PURE AP
   [Anonymous], 2002, PROC ACM T GRAPH SIG, DOI DOI 10.1145/566570.566574
   BARTEN PGJ, 1992, P SOC PHOTO-OPT INS, V1666, P57, DOI 10.1117/12.135956
   Braun GJ, 1999, J ELECTRON IMAGING, V8, P380, DOI 10.1117/1.482706
   Cowan M, 2004, SMPTE MOTION IMAG J, V113, P281, DOI 10.5594/J11549
   Day EA, 2004, COLOR RES APPL, V29, P365, DOI 10.1002/col.20046
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   Devlin K., 2002, State of the Art Reports, Eurographics, P101
   FLYNN MJ, 2001, P SOC PHOTO-OPT INS, V1666, P298
   FOLEY JM, 1993, VISION RES, V33, P959, DOI 10.1016/0042-6989(93)90079-C
   HAYHOE MM, 1992, VISION RES, V32, P323, DOI 10.1016/0042-6989(92)90142-6
   HOOD D, 1986, SENSITIVITY LIGHTHAN, V1
   Hood DC, 1997, VISION RES, V37, P1177, DOI 10.1016/S0042-6989(96)00228-3
   Hornak J.P., 2005, BASIC MRI
   Johnson GM, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P36
   KORTUM PT, 1995, VISION RES, V35, P1595, DOI 10.1016/0042-6989(94)00206-2
   Kuang JT, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P315
   McNamara A, 2001, COMPUT GRAPH FORUM, V20, P211, DOI 10.1111/1467-8659.00550
   Montag ED, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P222
   Montag ED, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2181547
   Moroney N, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P108
   Muka E, 2002, P SOC PHOTO-OPT INS, V4686, P169, DOI 10.1117/12.462676
   MUKA E, 2002, P SOC PHOTO-OPT INS, P177
   *NAT EL MAN ASS, 2004, 3142004 PS NAT EL MA
   NAYAR S, 2000, P IEEE CVPR, P1472
   PARK SH, 2004, THESIS ROCHESTER I T
   Pattanaik S.N., 1998, P SIGGRAPH 98, P287
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Shapley R, 1997, CURR BIOL, V7, pR421, DOI 10.1016/S0960-9822(06)00207-7
   Shapley R., 1984, Prog Retin Res, V3, P263, DOI [10.1016/0278-4327(84)90011-7, DOI 10.1016/0278-4327(84)90011~7]
   Victor JD, 1997, VISUAL NEUROSCI, V14, P577, DOI 10.1017/S0952523800012232
   Walraven J., 1990, Visual Perception: The Neurophysiological Foundations, P53
   XIAO F, 2002, IS T SID 10 COL IM C, P337
   Yeh TY, 1996, VISION RES, V36, P913, DOI 10.1016/0042-6989(95)00332-0
NR 36
TC 22
Z9 22
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 415
EP 428
DI 10.1016/j.jvcir.2007.06.008
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000008
DA 2024-07-18
ER

PT J
AU De Schrijver, D
   De Neve, W
   De Wolf, K
   De Sutter, R
   Van de Walle, R
AF De Schrijver, Davy
   De Neve, Wesley
   De Wolf, Koen
   De Sutter, Robbie
   Van de Walle, Rik
TI An optimized MPEG-21 BSDL framework for the adaptation of scalable
   bitstreams
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE bitstream syntax descriptions; content adaptation; context-related
   attributes; H.264/MPEG-4 AVC; MPEG-21 BSDL; scalable video coding
ID RESOURCE ADAPTATION; SYNTAX DESCRIPTION; VIDEO
AB A format-agnostic framework for content adaptation allows reaching a maximum number of users in heterogeneous multimedia environments. Such a framework typically relies on the use of scalable bitstreams. In this paper, we investigate the use of bitstreams compliant with the scalable extension of the H.264/MPEG-4 AVC standard in a format-independent framework for content adaptation. These bitstreams are scalable along the temporal, spatial, and SNR axis. To adapt these bitstreams, a format-independent adaptation engine is employed, driven by the MPEG-21 Bitstream Syntax Description Language (BSDL). MPEG-21 BSDL is a specification that allows generating high-level XML descriptions of the structure of a scalable bitstream. As such, the complexity of the adaptation of scalable bitstreams can be moved to the XML domain. Unfortunately, the current version of MPEG-21 BSDL cannot be used to describe the structure of large video bitstreams because the bitstream parsing process is characterized by an increasing memory consumption and a decreasing description generation speed. Therefore, in this paper, we describe a number of extensions to the MPEG-21 BSDL specification that make it possible to optimize the processing of bitstreams. Moreover, we also introduce a number of additional extensions necessary to describe the structure of scalable H.264/AVC bitstreams. Our performance analysis demonstrates that our extensions enable the bitstream parsing process to translate the structure of the scalable bitstreams into an XML document multiple times faster. Further, a constant and low memory consumption is obtained during the bitstream parsing process. (c) 2007 Elsevier Inc. All rights reserved.
C1 Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, B-9050 Ledeberg Ghent, Belgium.
C3 Ghent University
RP De Schrijver, D (corresponding author), Univ Ghent, Dept Elect & Informat Syst, Multimedia Lab, IBBT, Gaston Crommenlaan 8 Bus 201, B-9050 Ledeberg Ghent, Belgium.
EM davy.deschrijver@ugent.be
RI De Neve, Wesley Marcel/C-6480-2008
OI De Neve, Wesley Marcel/0000-0002-8190-3839
CR [Anonymous], 210007 ISOIEC
   [Anonymous], 2005, 1449610 ISOIEC
   [Anonymous], 2004, 154441 ISOIEC
   BECKER O, 2003, P XML EUR
   BURNETT I, 2006, MPEG21 BOOK
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Cimprich Petr, STREAMING TRANSFORMA
   De Neve W, 2004, P SOC PHOTO-OPT INS, V5558, P555, DOI 10.1117/12.564822
   De Neve W, 2006, SIGNAL PROCESS-IMAGE, V21, P862, DOI 10.1016/j.image.2006.08.005
   De Schrijver D, 2005, IEEE INT SYM MULTIM, P79
   De Schrijver D, 2006, MULTIMEDIA SYST, V11, P403, DOI 10.1007/s00530-006-0021-5
   DESCHRIJVER D, 2006, P 2006 IEEE INT C IN, V3, P213
   Devillers S, 2005, IEEE T MULTIMEDIA, V7, P463, DOI 10.1109/TMM.2005.846794
   Eleftheriadis A, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P1
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Hong D, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P773, DOI 10.1109/ICME.2002.1035896
   *ISO IEC, 2006, 210008 ISOIEC
   *ISO IEC, 2006, 210007 ISOIEC
   *ISOIEC, 2004, 144962 ISOIEC
   Kay Michael, 2001, XSLT Programmer's Reference
   Lambert P, 2006, LECT NOTES COMPUT SC, V4179, P442
   Mukherjee D, 2005, IEEE T MULTIMEDIA, V7, P454, DOI 10.1109/TMM.2005.846798
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Panis G, 2003, SIGNAL PROCESS-IMAGE, V18, P721, DOI 10.1016/S0923-5965(03)00061-4
   Perkis A, 2001, CIRC SYST SIGNAL PR, V20, P387, DOI 10.1007/BF01201409
   REICHEL J, JVTS202
   RIDGE J, 2005, P 8 INT S SIGN PROC, V1, P247
   *SAX, XSLT XQUERY PROC
   Sun XM, 2005, J VIS COMMUN IMAGE R, V16, P589, DOI 10.1016/j.jvcir.2005.03.007
   Tian D, 2005, IEEE INT SYMP CIRC S, P6074
   TIMMERER C, 2003, P SPIE INT S ITCOM 2, V4, P92
   VANDEURSEN D, 2006, P 25 PICT COD S BEIJ, P6
   WIEGAND T, JVTS201
   ZGALJIC T, 2005, P EUR WORKSH INT KNO, P173
NR 34
TC 12
Z9 12
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 217
EP 239
DI 10.1016/j.jvcir.2007.02.003
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300003
DA 2024-07-18
ER

PT J
AU Gan, X
   Liew, AWC
   Yan, H
AF Gan, Xiangchao
   Liew, Alan Wee-Chung
   Yan, Hong
TI A POCS-based constrained total least squares algorithm for image
   restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image restoration; constrained total least squares algorithm; projection
   onto convex sets algorithm
ID ARTIFACT REDUCTION; IDENTIFICATION; BLURS
AB In image restoration, the region of support of the point spread function is often much smaller than the size of the observed degraded image and this property is utilized in many image deconvolution algorithms. For the constrained total least squares (CTLS)-based algorithm, it means that the solution of the CTLS algorithm should retain the block-circulant and sparse structure of the degradation matrix simultaneously. In real image restoration problems, the CTLS method often involves large-scale computation and is often solved using Mesarovic et al.'s algorithm. However, there is concern about whether their algorithm preserves the sparse structure of the degradation matrix. In this paper, we prove that by imposing an extra constraint, the sparse structure in their algorithm can be preserved. Then, we use the projection onto convex sets algorithm to find a solution to this extended formulation. Our experimental study indicates that the proposed method performs competitively, and often better, in terms of visual and objective evaluations. (c) 2006 Elsevier Inc. All rights reserved.
C1 City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
   Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
C3 City University of Hong Kong; Chinese University of Hong Kong;
   University of Sydney
RP Gan, X (corresponding author), City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
EM gan.xiangchao@student.cityu.edu.hk
RI Liew, Alan Wee-Chung/F-6988-2011
OI Liew, Alan Wee-Chung/0000-0001-6718-7584; YAN, Hong/0000-0001-9661-3095
CR ABATZOGLOU TJ, 1991, IEEE T SIGNAL PROCES, V39, P1070, DOI 10.1109/78.80955
   ABATZOGLOU TJ, 1987, P 1987 IEEE ICASSP, P984
   [Anonymous], VECTOR SPACE PROJECT
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   COMBETTES PL, 1989, IEEE T ACOUST SPEECH, V37, P393, DOI 10.1109/29.21706
   COMBETTES PL, 1991, IEEE T SIGNAL PROCES, V39, P1630, DOI 10.1109/78.134400
   Fan X, 1996, IEEE T CIRCUITS-II, V43, P140, DOI 10.1109/82.486461
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Galatsanos NP, 2000, IEEE T IMAGE PROCESS, V9, P1784, DOI 10.1109/83.869189
   Gan XC, 2003, J VIS COMMUN IMAGE R, V14, P492, DOI 10.1016/S1047-3203(03)00044-0
   Giannakis GB, 2000, IEEE T IMAGE PROCESS, V9, P1877, DOI 10.1109/83.877210
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Huffel S.V., 1991, The Total Least Squares Problem: Computational Aspects and Analysis
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Lun DPK, 2004, IEEE T IMAGE PROCESS, V13, P188, DOI 10.1109/TIP.2004.823820
   MESAROVIC VZ, 1995, IEEE T IMAGE PROCESS, V4, P1096, DOI 10.1109/83.403444
   Mesarovic VZ, 2000, J OPT SOC AM A, V17, P711, DOI 10.1364/JOSAA.17.000711
   Perry SW, 2000, IEEE T NEURAL NETWOR, V11, P156, DOI 10.1109/72.822518
   TRUSSELL HJ, 1984, IEEE T ACOUST SPEECH, V32, P201, DOI 10.1109/TASSP.1984.1164297
   Weerasinghe C, 2002, IEEE T CIRC SYST VID, V12, P891, DOI 10.1109/TCSVT.2002.804881
   Yan H., 2002, SIGNAL PROCESSING MA
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P416, DOI 10.1109/83.491316
   Younes L, 1998, IEEE T PATTERN ANAL, V20, P380, DOI 10.1109/34.677263
NR 23
TC 8
Z9 13
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 986
EP 1003
DI 10.1016/j.jvcir.2006.02.002
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700004
DA 2024-07-18
ER

PT J
AU Gao, XW
   Podladchikova, L
   Shaposhnikov, D
   Hong, K
   Shevtsova, N
AF Gao, X. W.
   Podladchikova, L.
   Shaposhnikov, D.
   Hong, K.
   Shevtsova, N.
TI Recognition of traffic signs based on their colour and shape features
   extracted using human vision models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE transformation invariant recognition; traffic signs recognition; feature
   extraction
AB Colour and shape are basic characteristics of traffic signs which are used both by the driver and to develop artificial traffic sign recognition systems. However, these sign features have not been represented robustly in the earlier developed recognition systems, especially in disturbed viewing conditions. In this study, this information is represented by using a human vision colour appearance model and by further developing existing behaviour model of visions. Colour appearance model CIECAM97 has been applied to extract colour information and to segment and classify traffic signs. Whilst shape features are extracted by the development of FOSTS model, the extension of behaviour model of visions. Recognition rate is very high for signs under artificial transformations that imitate possible real world sign distortion (up to 50% for noise level, 50 in for distances to signs, and 5 degrees for perspective disturbances) for still images. For British traffic signs (n = 98) obtained under various viewing conditions, the recognition rate is up to 95%. (C) 2005 Elsevier Inc. All rights reserved.
C1 Middlesex Univ, Sch Comp Sci, London 11 2NQ, England.
   Rostov State Univ, AB Kogan Res Inst Neurocybernet, Lab Neuroinformat Sensory & Motor Syst, Rostov Na Donu 344006, Russia.
C3 Middlesex University; Southern Federal University
RP Gao, XW (corresponding author), Middlesex Univ, Sch Comp Sci, Bounds Green, London 11 2NQ, England.
EM x.gao@mdx.ac.uk
RI Podladchikova, Lubov/AAF-7855-2019; Shaposhnikov, Dmitry/L-1060-2016
OI Podladchikova, Lubov/0000-0002-5557-6045; Shaposhnikov,
   Dmitry/0000-0002-1797-6232; Gao, Xiaohong/0000-0002-8103-6624
CR BANDERA C, 1989, 1989 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-3, P596, DOI 10.1109/ICSMC.1989.71367
   *CIE, 1998, TCI34 CIE
   *CRIM, 1995, REP SUB PROJ 1 2 GEO
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   DUPPLAW D, 1999, P CHALL IM RETR NEWC
   Fang CY, 2003, IEEE T VEH TECHNOL, V52, P1329, DOI 10.1109/TVT.2003.810999
   Gang W., 1999, INTELLIGENT ENG SYST, V9, P821
   Gao X, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P47
   GAO X, 2005, P 14 INT C NEUR RUSS, V2, P223
   GAO XW, 2002, P C NEUR MOSC, P63
   GAVRILA DM, 1999, P 21 DAGM S MUST, P86
   HSIEN JC, 2003, 14 WORKSH OOTA, P529
   JUDD DB, 1964, J OPT SOC AM, V54, P1031, DOI 10.1364/JOSA.54.001031
   Luo MR, 1998, COLOR RES APPL, V23, P138, DOI 10.1002/(SICI)1520-6378(199806)23:3<138::AID-COL5>3.0.CO;2-R
   Miura J, 2002, IEICE T INF SYST, VE85D, P1784
   OHLANDER R, 1978, COMPUT GRAPH IMAGE P, V13, P224
   Piccioli G, 1996, IMAGE VISION COMPUT, V14, P209, DOI 10.1016/0262-8856(95)01057-2
   Podladchikova LN, 1997, P SOC PHOTO-OPT INS, V3208, P418, DOI 10.1117/12.290313
   Rybak IA, 1998, VISION RES, V38, P2387, DOI 10.1016/S0042-6989(98)00020-0
   Schwartz EL, 1995, NEURAL NETWORKS, V8, P1297, DOI 10.1016/0893-6080(95)00092-5
   Sonka M., 1996, IMAGE PROCESSING ANA
   Tominaga S., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P628
   Yang HM, 2003, LECT NOTES ARTIF INT, V2871, P252
NR 23
TC 124
Z9 154
U1 2
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 675
EP 685
DI 10.1016/j.jvcir.2005.10.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500001
DA 2024-07-18
ER

PT J
AU Amer, I
   Badawy, W
   Jullien, G
AF Amer, Ihab
   Badawy, Wael
   Jullien, Graham
TI A proposed hardware reference model for spatial transformation and
   quantization in H.264
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; advanced video coding; DCT; Hadamard; hardware; VLSI; FPGA; ASIC;
   transform; quantization; video coding
AB This paper presents three Very Large Scale Integration prototypes to exploit spatial redundancy in the H.264 standard. The proposed architectures are: (1) forward 4 x 4 integer approximation of DCT transform and quantization, which is applied to all blocks of a frame, (2) the 4 x 4 Hadamard transform and quantization that is applied to the DC coefficients of the luma component when the macroblock is encoded in 16 x 16 intra prediction mode, and (3) the 2 x 2 Hadamard transform and quantization that is applied to the DC coefficients of the chroma component as a second level in the transformation hierarchy. The developed algorithms are adopted by the H.264 standard. A performance analysis shows that the architectures satisfy the real-time constraints required by different digital video applications. (c) 2005 Elsevier Inc. All rights reserved.
C1 ATIPS, Calgary, AB T2N 1N4, Canada.
RP Amer, I (corresponding author), ATIPS, 2500 Univ Dr,NW, Calgary, AB T2N 1N4, Canada.
EM iamer@ucalgary.ca; badawy@atips.ca; jullien@atips.ca
RI Badawy, Wael/HPG-4014-2023; badawy, Wael/AAH-3461-2019
OI Badawy, Wael/0000-0003-0251-9124; 
CR Amer I, 2004, 2004 IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS DESIGN AND IMPLEMENTATION, PROCEEDINGS, P275
   Amer I, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P77
   AMER I, 2004, M11414 ISOIEC JTC1SC
   AMER I, 2004, P IEEE INT C MULT EX
   AMER I, 2004, M11415 ISOIEC JTC1SC
   AMER I, 2004, M11412 ISOIEC JTC1SC
   AMER I, 2005, IN PRESS IEEE INT C
   AMER I, 2004, M11413 ISOIEC JTC1SC
   AMER I, 2004, M11417 ISOIEC JTC1SC
   AMER I, 2004, M11416 ISOIEC JTC1SC
   AMER I, 2004, IN PRESS INT COMP EN
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   *EM H 264 STAND, 2002, OV TMS320DM642 BAS S
   HALLAPURO A, 2002, JVTB039R2 ISOIEC MPE
   MALVAR H, 2002, IEEE INT C IM PROC R
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Richardson I. E. G., H 264 MPEG 4 10
   Schafer R., 2003, EBU TECHNICAL REV
   TAMHANKAR A, 2003, 4 EURASIP C FOC VID, V1
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 21
TC 8
Z9 9
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 533
EP 552
DI 10.1016/j.jvcir.2005.05.011
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000018
DA 2024-07-18
ER

PT J
AU Kuo, CH
   Shen, M
   Kuo, CCJ
AF Kuo, Chih-Hung
   Shen, Meiyin
   Kuo, C. -C. Jay
TI Fast motion search with efficient inter-prediction mode decision for
   H.264
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; motion estimation; fast motion search; video coding
ID ALGORITHM
AB A fast inter-prediction mode decision and motion search algorithm is proposed for the H.264 video coding standard. The multi-resolution motion estimation scheme and an adaptive rate-distortion model are employed with early termination rules to accelerate the search process. With the new algorithm, the amount of computation involved in the motion search can be substantially reduced. Experimental results show that the proposed algorithm can achieve a speed-up factor ranging from 60 to 150 times as compared to the full-search algorithm with little quality degradation. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
   Univ So Calif, Integrated Media Syst Ctr, Los Angeles, CA 90089 USA.
   Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
C3 University of Southern California; University of Southern California;
   National Cheng Kung University
RP Kuo, CCJ (corresponding author), Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
EM chkuo@ee.ncku.edu.tw; meiyinsh@sipi.use.edu; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR Ahmad A, 2004, ELECTRON LETT, V40, P19, DOI 10.1049/el:20040068
   Chalidabhongse J, 1997, IEEE T CIRC SYST VID, V7, P477, DOI 10.1109/76.585927
   CHANG A, 2004, P IEEE INT S CIRC SY, V3, P817
   Choi WI, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P371
   Hang HM, 1997, IEEE T CIRC SYST VID, V7, P287
   *ISO IEC JTC1 SC29, 2001, N4344 ISOIEC JTC1SC2
   Jing X, 2004, ELECTRON LETT, V40, P1050, DOI 10.1049/el:20045243
   KOGA T, 1981, IEEE P NAT TEL C DEC, V4
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Li XM, 1996, IEEE T CIRC SYST VID, V6, P118, DOI 10.1109/76.486427
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   TOURAPIS AM, 2001, SPIE P VIS COMM IM P
   TOURAPIS AM, 2002, SPIE P VIS COMM IM P
   Tourapis HYC, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P517
   Wu D, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P181
   XU JF, 2004, P IEEE INT C AC SPEE, V3, P181
   Yin P, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P853
   Yu AC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P169
   Zhou Z, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P725
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   [No title captured]
NR 27
TC 3
Z9 5
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 217
EP 242
DI 10.1016/j.jvcir.2005.05.001
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000003
DA 2024-07-18
ER

PT J
AU Kwon, SK
   Tamhankar, A
   Rao, KR
AF Kwon, Soon-kak
   Tamhankar, A.
   Rao, K. R.
TI Overview of H.264/MPEG-4 part 10
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE intra-prediction; multiple reference inter-prediction; integer
   transform; CAVLC; CABAC
ID H.264/AVC
AB The video coding standards are being developed to satisfy the requirements of applications for various purposes, better picture quality, higher coding efficiency, and more error robustness. The new international video coding standard H.264/MPEG-4 part 10 aims at having significant improvements in coding efficiency, and error robustness in comparison with the previous standards such as MPEG-2, H.263, MPEG-4 part 2. This paper describes an overview of H.264/MPEG-4 part 10. We focus on the detailed features like coding algorithm and error resilience of new standard, and compare the coding schemes with the other standards. The performance comparisons show that H.264 can achieve a coding efficiency improvement of about 1.5 times or greater for each test sequence related to multimedia, SDTV and HDTV. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.
   T Mobile USA, Bellevue, WA USA.
C3 University of Texas System; University of Texas Arlington
RP Rao, KR (corresponding author), Univ Texas, Dept Elect Engn, Arlington, TX 76019 USA.
EM rao@uta.edu
RI Rao, Kola Koteswara/ABE-7163-2021
OI Rao, Kola Koteswara/0000-0001-6176-7828; Rao, K. R./0000-0002-8513-3114
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   DIETZ M, 2002, EBU TECHNICAL RE JUL
   *ETSI TS, 2001, 101980 ETSI TS
   Flierl M, 2003, IEEE T CIRC SYST VID, V13, P587, DOI 10.1109/TCSVT.2003.814963
   Gao W., 2004, AVS CHINESE NEXT GEN
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   *ISO IEC JTC1 SC29, 2000, 1449620002 ISOIEC JT
   *ISO IEC JTC1 SC29, 2003, MPEG2003N6231 ISOIEC
   Joch A, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P501
   Karczewicz M, 2003, IEEE T CIRC SYST VID, V13, P637, DOI 10.1109/TCSVT.2003.814969
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   MELTZER S, 2002, 112 AES CONV MUN MAY
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Srinivasan S, 2004, SIGNAL PROCESS-IMAGE, V19, P851, DOI 10.1016/j.image.2004.06.005
   STOCKHAMMER T, 2002, ICIP 2002, V2, P485
   Sullivan G. J., 2004, SPIE C APPL DIG IM P
   Wedi T., 2004, JVTL033
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   ZIEGLER T, 2002, 112 AES CONV MUN MAY
NR 23
TC 71
Z9 127
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 186
EP 216
DI 10.1016/j.jvcir.2005.05.010
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000002
DA 2024-07-18
ER

PT J
AU Xenos, M
   Hantzara, K
   Mitsou, E
   Kostopoulos, I
AF Xenos, Michalis
   Hantzara, Katerina
   Mitsou, Evanthia
   Kostopoulos, Ioannis
TI A model for the assessment of watermark quality with regard to fidelity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE information hiding; watermarks; watermark quality
ID DIGITAL WATERMARKING; VISUAL-ATTENTION; IMAGES
AB This paper presents a model for assessing watermark quality with regard to fidelity. The model can be applied for assessing the quality of watermarks as well as investigating the effect of attacks on watermarked images. The proposed model is based on image properties as perceived by the human eye and attempts to provide algorithmic measurements that correspond to human-perceived watermark fidelity. Emphasis has been placed on the analysis of the model and the determination of the weights used to derive the final result. Experiments are presented to illustrate the applicability of the model on still images, using examples of watermarked images as well as examples of attacks on watermarked images. (c) 2005 Elsevier Inc. All rights reserved.
C1 Hellen Open Univ, Sch Sci & Technol, GR-26223 Patras, Greece.
   Inst Comp Technol, GR-26221 Patras, Greece.
   Univ Patras, Comp Engn & Informat Dep, GR-26500 Rion, Greece.
C3 Hellenic Open University; University of Patras
RP Xenos, M (corresponding author), Hellen Open Univ, Sch Sci & Technol, 23 Saxtouri St, GR-26223 Patras, Greece.
EM xenos@eap.gr; hantzara@ceid.upatras.gr; emitsou@ceid.upatras.gr;
   kostopoulos@optionsnet.gr
CR ARMENI S, 2000, P IEEE 1 BALK C SIGN
   BROWN J, 1997, PLAYMATE MEETS GEEKS
   Chahir Y, 2000, J VIS COMMUN IMAGE R, V11, P302, DOI [10.1006/jvci.1999.0428, 10.1006/jvic.1999.0428]
   Chan HC, 2004, J VIS COMMUN IMAGE R, V15, P113, DOI 10.1016/j.jvcir.2003.09.001
   Cox I. J., 2002, Digital Watermarking
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   FOTOPOULOS V, 2000, P 10 EUR SIGN PROC C
   GERI GA, 1995, J OPT SOC AM A, V12, P2367, DOI 10.1364/JOSAA.12.002367
   KHEONG YC, 1995, HUMAN VISUAL SYSTEM
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kortum P, 1996, P SOC PHOTO-OPT INS, V2657, P350, DOI 10.1117/12.238732
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   LIN CY, 2000, THESIS COLUMBIA U
   Lin PL, 2001, J VIS COMMUN IMAGE R, V12, P136, DOI 10.1006/jvci.2000.0454
   Lubin J., 1995, Vision Models for Target Detection and Recognition, P245
   Mc Call J. A., 1977, FACTORS SOFTWARE QUA, VI
   McCall J.A., 1977, Factors in Software Quality, Vols I, II, III, AD/A-049-014/ 015/055, VII
   McCall J.A., 1977, Factors in Software Quality, Volumes I, II, and III, VIII
   Moulin P, 2000, INT CONF ACOUST SPEE, P3630, DOI 10.1109/ICASSP.2000.860188
   NIEBUR E, 1997, ATTENTIVE BRAIN
   OBERGER W, 1997, P DICTA 97, P337
   Osberger W, 1998, INT C PATT RECOG, P701, DOI 10.1109/ICPR.1998.711240
   OSBERGER W, 1996, P ICIP, V1, P897
   Panjwani D. K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P776, DOI 10.1109/CVPR.1993.341170
   ROHALI A, 1997, VISION RES
   SCHETTINI R, 1993, PATTERN RECOGN LETT, V14, P499, DOI 10.1016/0167-8655(93)90030-H
   Senders JW, 1997, P SOC PHOTO-OPT INS, V3016, P186, DOI 10.1117/12.274513
   SHEIKH HR, 2002, IEEE AS C SIGN SYST
   SKARBEK W, 1994, 9432 TU BERL DEP COM
   TSENG DC, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P228, DOI 10.1109/ICPR.1992.201967
   TSOSTOS JK, 1997, ROBOT AUTON SYST
   VOLOSHYNOVSKIY S, 2002, P EUR SIGN PROC C EU
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WANG Z, 2004, P SPIE, V5292
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
   Watson AB, 1997, P SOC PHOTO-OPT INS, V3016, P2, DOI 10.1117/12.274501
   WESTEN SJP, 1995, INT CONF ACOUST SPEE, P2351, DOI 10.1109/ICASSP.1995.479964
   Yarbus A. L., 1967, Eye Movements and Vision
NR 38
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2005
VL 16
IS 6
BP 621
EP 642
DI 10.1016/j.jvcir.2005.03.006
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JQ
UT WOS:000242026600001
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Jing, HY
   Wei, S
   Chen, JX
   Shang, XN
   Chen, AD
AF Zhang, Chenyang
   Jing, Hongyuan
   Wei, Shuang
   Chen, Jiaxing
   Shang, Xinna
   Chen, Aidong
TI DPAFD-net: A dual-path adaptive fusion dehazing network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Dual-path network; Adaptive fusion; Scale-invariant
   subnetwork; Structure extraction subnetwork
AB Image dehazing is an ill-posed problem that has been extensively studied in recent years. Unfortunately, most existing deep dehazing models have high computational complexity and lack the dynamic adjustment of details, which hinders their application to high-resolution images in computational vision tasks. In this paper, we propose an efficient dual-path adaptive fusion dehazing network (DPAFD-Net) to directly restore a clear image from a hazy input. Moreover, we propose a pure subnetwork with encoder and decoder structures to further extract the structural information and progressively restore the haze-free image. To evaluate the effectiveness of the proposed method, we validate our approach on synthetic and real hazy images, where our method performs favourably against the state-of-the-art dehazing approaches.
C1 [Jing, Hongyuan] Beijing Union Univ, Beijing Key Lab Informat Serv Engn, 97 Beisihuan East Rd, Beijing 100101, Peoples R China.
   [Shang, Xinna; Chen, Aidong] Beijing Union Univ, Multiagent Syst Res Ctr, 97 Beisihuan East Rd, Beijing 100101, Peoples R China.
   [Zhang, Chenyang; Jing, Hongyuan; Wei, Shuang; Chen, Jiaxing; Shang, Xinna; Chen, Aidong] Beijing Union Univ, Coll Robot, 4 Gongti North Rd, Beijing, Peoples R China.
   [Jing, Hongyuan] Beijing Union Univ, Coll Robot, Beijing 100101, Peoples R China.
C3 Beijing Union University; Beijing Union University; Beijing Union
   University; Beijing Union University
RP Jing, HY (corresponding author), Beijing Union Univ, Coll Robot, Beijing 100101, Peoples R China.
EM jqrhongyuan@buu.edu.cn
OI jing, hongyuan/0000-0002-5613-1216
FU Beijing Municipal Education Commission Research Foundation
   [KM202111417008]; Beiing NovaProgram [20230484477]; National key
   research and development plan [2022YFB2804402]; Academic Research
   Projects of Beijing Union University [ZK90202104, ZKZD202301, JK202309];
   Beijing Union University students' science and technology innovation
   project [20232020]
FX 1 These authors contributed equally to this work. This work is mainly
   supported by the Beijing Municipal Education Commission Research
   Foundation under Grant KM202111417008; Sponsored by Beiing NovaProgram
   under Grant 20230484477 supported by National key research and
   development plan under Grant 2022YFB2804402; which is also supported by
   the Academic Research Projects of Beijing Union University No.
   ZK90202104, No. ZKZD202301, No. JK202309, and partly support by Beijing
   Union University students' science and technology innovation project No.
   20232020.
CR  PA, 2020, Arxiv, DOI arXiv:2008.10325
   Ancuti C., 2018, ADV CONCEPTS INTELLI
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], 2017, Benchmarking Single Image Dehazing and beyond
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen ZH, 2020, VISUAL COMPUT, V36, P2189, DOI 10.1007/s00371-020-01929-y
   Dai YM, 2021, IEEE WINT CONF APPL, P3559, DOI 10.1109/WACV48630.2021.00360
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dong PW, 2022, MULTIDIM SYST SIGN P, V33, P1119, DOI 10.1007/s11045-022-00835-x
   Ebert T, 2010, LECT NOTES ARTIF INT, V6319, P414, DOI 10.1007/978-3-642-16530-6_49
   Feng T, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2020.106884
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo CL, 2022, PROC CVPR IEEE, P5802, DOI 10.1109/CVPR52688.2022.00572
   Guo Y., 2023, P IEEECVF C COMPUTER
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jing H., 2022, SPIE
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li YA, 2019, IEEE I CONF COMP VIS, P3275, DOI 10.1109/ICCV.2019.00337
   Li ZG, 2022, IEEE T IMAGE PROCESS, V31, P6213, DOI 10.1109/TIP.2022.3207571
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y., 2021, From Synthetic to Real: Image Dehazing Collaborating with Unlabeled Real Data
   Liu Ye., 2021, P 29 ACM INT C MULT
   McCartney E.J., 1976, Phys. Today
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Pirahansiah F., 2013, J. Theor. Appl. Informat. Technol., V57
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tran Le-Anh, 2022, Procedia Computer Science, P682, DOI 10.1016/j.procs.2022.08.082
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wazwaz AM, 2005, APPL MATH COMPUT, V167, P1196, DOI 10.1016/j.amc.2004.08.005
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang AP, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4627
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P72, DOI 10.1109/TIP.2019.2922837
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao SY, 2021, IEEE T IMAGE PROCESS, V30, P3391, DOI 10.1109/TIP.2021.3060873
   Zhou Y, 2021, COMPUT ANIMAT VIRT W, V32, DOI 10.1002/cav.2011
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 54
TC 0
Z9 0
U1 6
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104018
DI 10.1016/j.jvcir.2023.104018
EA DEC 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EL2S0
UT WOS:001139021700001
OA Bronze
DA 2024-07-18
ER

PT J
AU Rathod, B
   Vanzara, R
   Pandya, D
AF Rathod, Bhoomika
   Vanzara, Rakeshkumar
   Pandya, Devang
TI A recent survey on perceived group sentiment analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE Group emotion recognition; Machine learning; Deep learning; Fusion
   methods; Sentiment analysis
ID EMOTION RECOGNITION; ANOMALY DETECTION
AB Group sentiment analysis in today's era is influencing many applications. Sentiment recognition is applicable for individuals, and group as well as crowd. This paper aims to highlight the ongoing present research scenario on perceived group sentiment analysis. The paper provides a brief overview of the strengths and weaknesses of well-known group sentiment analysis approaches. These approaches are broadly split into two basic categories: top-down and bottom-up approaches. A combination of top-down and bottom-up approaches is found superior in performance. This comprehensive review also discusses the available dataset with taxonomic representation and the importance of fusion techniques in group emotion recognition. This paper also narrates the novel attempt to demarcate the group emotion recognition approaches into the categories evolved by the influence of machine learning and deep learning at the feature extraction level and at the classification level. The multi-modality based group sentiment analysis has a great scope to overcome the challenges and improve the performance on real time applications.
C1 [Rathod, Bhoomika; Vanzara, Rakeshkumar; Pandya, Devang] Ganpat Univ, UV Patel Coll Engn, Kherva 384012, India.
C3 Ganpat University
RP Rathod, B (corresponding author), Ganpat Univ, UV Patel Coll Engn, Kherva 384012, India.
EM bmr01@ganpatuniversity.ac.in
RI Vanzara, Rakeshkumar/AAZ-2320-2020
CR Abbas A., 2017, P 19 ACM INT C MULT, P561, DOI [10.1145/3136755.3143010, DOI 10.1145/3136755.3143010]
   Ahsan U, 2017, IEEE WINT CONF APPL, P669, DOI 10.1109/WACV.2017.80
   Alvarez VM, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN INTELLIGENT AND COMPUTING IN ENGINEERING (RICE III)
   [Anonymous], 2017, P 19 ACM INT C MULT
   Baig MW, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P703, DOI 10.1109/ICDSP.2015.7251966
   Baig MW, 2014, LECT NOTES ARTIF INT, V8575, P328, DOI 10.1007/978-3-319-08864-8_32
   Bawa VS, 2019, NEURAL COMPUT APPL, V31, P9061, DOI 10.1007/s00521-018-3867-5
   Bin Zhu, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P841, DOI 10.1145/3382507.3417965
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Candra Kirana Kartika, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P406, DOI 10.1109/ISEMANTIC.2018.8549735
   Canedo D, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214678
   Chen JL, 2017, INT CONF ORANGE TECH, P115, DOI 10.1109/ICOT.2017.8336102
   Chuanhe Liu, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P807, DOI 10.1145/3382507.3417968
   Dai Y, 2019, IEEE ACCESS, V7, P111617, DOI 10.1109/ACCESS.2019.2932797
   Dammak M., 2011, 2011 International Conference on Innovations in Information Technology (IIT), P110, DOI 10.1109/INNOVATIONS.2011.5893798
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhall Abhinav, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P784, DOI 10.1145/3382507.3417973
   Dhall Abhinav, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163151
   Dhall Abhinav, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P613, DOI 10.1007/978-3-642-37444-9_48
   Dhall A., 2017, P 19 ACM INT C MULT, P524, DOI [10.1145/3136755.3143004, DOI 10.1145/3136755.3143004]
   Dhall A., 2021, Automatic group level affect and cohesion prediction in videos
   Dhall A, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P653
   Dhall A, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P427, DOI 10.1145/2993148.2997638
   Dhall A, 2015, INT CONF AFFECT, P255, DOI 10.1109/ACII.2015.7344580
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   Fan YR, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P584, DOI 10.1145/3242969.3264978
   Favaretto RM, 2019, MACH VISION APPL, V30, P999, DOI 10.1007/s00138-018-0979-y
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Fradi H, 2014, INT C PATT RECOG, P4116, DOI 10.1109/ICPR.2014.705
   Fujii Katsuya, 2019, 2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019), DOI 10.1109/FG.2019.8756573
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Ghosh S, 2018, IEEE IMAGE PROC, P1967, DOI 10.1109/ICIP.2018.8451242
   Gonen M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1425, DOI 10.1109/ICPR.2010.352
   Gonen M., 2008, ICML, P352, DOI DOI 10.1145/1390156.1390201
   Gong VX, 2019, TRANSPORT RES REC, V2673, P836, DOI 10.1177/0361198119846461
   Guanming Lu, 2019, 2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE). Proceedings, P1707, DOI 10.1109/EITCE47263.2019.9094832
   Guo X, 2020, IEEE WINT CONF APPL, P2910, DOI [10.1109/WACV45572.2020.9093547, 10.1109/wacv45572.2020.9093547]
   Guo X, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P635, DOI 10.1145/3242969.3264990
   Guo Xin., 2017, P 19 ACM INT C MULTI, P603
   Gupta A, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P611, DOI 10.1145/3242969.3264985
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Hayamizu T, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2012), P177, DOI 10.1109/ICCSCE.2012.6487137
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holder R.P., 2017, PAC RIM S IM VID TEC, P463
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X., 2015, BMVC, P31
   Huang X., 2019, IEEE Trans. Affect. Comput., V13, P713
   Huang XH, 2018, IEEE T MULTIMEDIA, V20, P2706, DOI 10.1109/TMM.2018.2818015
   Colque RVHM, 2017, IEEE T CIRC SYST VID, V27, P673, DOI 10.1109/TCSVT.2016.2637778
   Jain A., 2010, Adv. Neural Inf. Process. Syst., V23
   Jin Boyang Tom, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P798, DOI 10.1145/3382507.3417966
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kaviya P., 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P643, DOI 10.1109/ICOEI48184.2020.9143037
   Kelly JR, 2001, ORGAN BEHAV HUM DEC, V86, P99, DOI 10.1006/obhd.2001.2974
   Keshari Tanya, 2019, 2019 International Conference on Communication and Electronics Systems (ICCES), P1184, DOI 10.1109/ICCES45898.2019.9002175
   Khan AS, 2021, IEEE WINT CONF APPL, P1149, DOI 10.1109/WACV48630.2021.00119
   Khan AS, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P623, DOI 10.1145/3242969.3264987
   Kim KH, 2015, INT CONF SOFT COMPUT, P303, DOI 10.1109/SOCPAR.2015.7492826
   Ko KE, 2010, INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS 2010), P1436
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lakshmy V, 2018, L N COMPUT VIS BIOME, V28, P1032, DOI 10.1007/978-3-319-71767-8_88
   Lamba S., 2016, Int. J. Urban Des. Ubiquitous Comput., V4, P9
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Liu NJ, 2018, LECT NOTES COMPUT SC, V11165, P24, DOI 10.1007/978-3-030-00767-6_3
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Mao Y, 2019, IEEE ACCESS, V7, P140010, DOI 10.1109/ACCESS.2019.2943603
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mo Sun, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P835, DOI 10.1145/3382507.3417971
   Mohammad SM, 2015, COMPUT INTELL-US, V31, P301, DOI 10.1111/coin.12024
   Mostafa A, 2018, PROCEEDINGS OF 2018 13TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P417, DOI 10.1109/ICCES.2018.8639182
   Mou WX, 2016, IEEE COMPUT SOC CONF, P1478, DOI 10.1109/CVPRW.2016.185
   Mou WX, 2015, IEEE INT CONF AUTOMA
   Nagarajan B, 2019, IEEE INT CONF AUTOMA, P621
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ortony A, 2022, COGNITIVE STRUCTURE OF EMOTIONS, 2 EDITION, P1, DOI 10.1017/9781108934053
   Palmberg R, 2017, INT CONF GAMES VIRTU, P157, DOI 10.1109/VS-GAMES.2017.8056588
   Pandey SK, 2019, 2019 29TH INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P197
   Park SB, 2015, MULTIMED TOOLS APPL, V74, P6431, DOI 10.1007/s11042-014-2088-x
   Petrova Anastasia, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P813, DOI 10.1145/3382507.3417969
   Pranav E, 2020, INT CONF ADVAN COMPU, P317, DOI [10.1109/icaccs48705.2020.9074302, 10.1109/ICACCS48705.2020.9074302]
   Qi SB, 2023, PATTERN ANAL APPL, V26, P1493, DOI 10.1007/s10044-023-01178-4
   Qing LB, 2021, IEEE INT CONF COMP V, P3611, DOI 10.1109/ICCVW54120.2021.00404
   Quach K.G., 2018, Non-volume preserving-based feature fusion approach to group-level expression recognition on crowd videos
   Ngo MQ, 2016, Arxiv, DOI arXiv:1606.00751
   Rabiee H, 2016, Arxiv, DOI arXiv:1607.07646
   Rabiee H, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P95, DOI 10.1109/AVSS.2016.7738074
   Rabiee H, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2786-0
   Rassadin A., 2017, ACM INT C MULTIMODAL, P544
   Setti F, 2017, COMPUT VIS IMAGE UND, V159, P47, DOI 10.1016/j.cviu.2017.01.003
   Shamsi SN, 2018, IEEE WINT CONF APPL, P77, DOI 10.1109/WACVW.2018.00015
   Sharma A., 2019, Int. J. Innov. Technol. Explor. Eng., V8, P4902
   Sharma G, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), P161, DOI 10.1109/ACIIW.2019.8925231
   Sharma Garima, 2021, IEEE Transactions on Affective Computing
   Sikka K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P517, DOI 10.1145/2522848.2531741
   Spitzley LA., 2022, IEEE Transactions on Affective Computing
   Sreenivas V, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00326-5
   Sun B, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P451, DOI 10.1145/2993148.2997640
   Surace Luca, 2017, P 19 ACM INT C MULT, P593
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan Lianzhi., 2017, P 19 ACM INT C MULT, P549
   Tarasov Alexander V., 2018, Analysis of Images, Social Networks and Texts. 7th International Conference, AIST 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11179), P191, DOI 10.1007/978-3-030-11027-7_19
   Tien DX, 2021, IEEE ACCESS, V9, P84356, DOI 10.1109/ACCESS.2021.3088340
   Tripathi Gaurav, 2020, 2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT), P969, DOI 10.1109/ICSSIT48917.2020.9214208
   Urizar O.J., 2017, Emotion Estimation in Crowds: A Survey
   Varghese Elizabeth B., 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P296, DOI 10.1007/978-3-030-04375-9_25
   Veltmeijer EA, 2023, IEEE T AFFECT COMPUT, V14, P89, DOI 10.1109/TAFFC.2021.3065726
   Vonikakis V, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P479, DOI 10.1145/2993148.2997633
   Wang K, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P640, DOI 10.1145/3242969.3264991
   Wang XZ, 2023, IEEE T COMPUT SOC SY, V10, P458, DOI 10.1109/TCSS.2022.3202249
   Wei Q., 2017, ACM INT C MULTIMODAL, P587, DOI DOI 10.1145/3136755.3143014
   Wu JL, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P464, DOI 10.1145/2993148.2997631
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Yaddaden Y., 2022, An efficient facial expression recognition system with appearance-based fused descriptors
   Yuan Y, 2015, IEEE T CYBERNETICS, V45, P562, DOI 10.1109/TCYB.2014.2330853
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
   Zhang JY, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11233990
   Zhang K., 2021, IEEE Trans. Affect. Comput.
   Zhang V, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS AND OTHER AFFILIATED EVENTS (PERCOM WORKSHOPS), DOI 10.1109/PerComWorkshops53856.2022.9767488
   Zhang YH, 2017, IEEE T CIRC SYST VID, V27, P635, DOI 10.1109/TCSVT.2016.2593609
   Zhang ZP, 2015, IEEE I CONF COMP VIS, P3631, DOI 10.1109/ICCV.2015.414
   Zito-Wolf R.J., 1991, AI Mag., V12, P97
NR 129
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103988
DI 10.1016/j.jvcir.2023.103988
EA NOV 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4U5
UT WOS:001130088600001
DA 2024-07-18
ER

PT J
AU Ma, YD
   Jing, N
AF Ma, Yingdong
   Jing, Nan
TI Semantic segmentation with cross convolution and multi-layer feature
   refinement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Cross convolution; Multi-scale context; Feature
   fusion
ID NETWORK
AB Multi-level features and contextual information have been proven effective in semantic segmentation. As a common solution, dilated convolution with multiple dilation rates is widely adopted by various computer vision tasks. However, since a large number of pixels are not involved in convolutional calculation, dilated convolution suffers from the information loss problem. Another important aspect for image segmentation is that most feature fusion methods combine different level features directly, which ignores the semantic gap between shallow layer features and deep layer features. In this work, we propose the multi-scale cross convolution to alleviate the information loss problem. Cross convolution conducts convolutional operations in horizontal and vertical di-rection with different kernels. By combining cross convolution with dilated convolutions using different convolution kernels, more pixels are engaged in convolutional operation to capture multi-scale features. To address the issue of semantic gap between multi-layer features, a feature fusion scheme is developed in which a dual attention mechanism is applied to conduct feature refinement in both spatial and channel dimensions. Comprehensive experiments are conducted to evaluate the proposed method on Cityscapes and ADE20K datasets. Experimental results demonstrate that the cross convolution and feature fusion method improve segmentation performance significantly and achieve competitive performance over state-of-the-art approaches.
C1 [Ma, Yingdong; Jing, Nan] Inner Mongolia Univ, Coll Comp Sci, 235,West Daxue Rd, Hohhot, Peoples R China.
C3 Inner Mongolia University
RP Ma, YD (corresponding author), Inner Mongolia Univ, Coll Comp Sci, 235,West Daxue Rd, Hohhot, Peoples R China.
EM csmyd@imu.edu.cn; 178386804@qq.com
RI 马, 马颖东/ISA-2042-2023
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen LC, 2018, Arxiv, DOI arXiv:1802.02611
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Cheng B, 2021, ADV NEUR IN, V34
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2019, IEEE I CONF COMP VIS, P6818, DOI 10.1109/ICCV.2019.00692
   Ding HH, 2020, IEEE T IMAGE PROCESS, V29, P3520, DOI 10.1109/TIP.2019.2962685
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu Jun, 2019, IEEE Trans Image Process, DOI 10.1109/TIP.2019.2895460
   Geng QC, 2021, IEEE T IMAGE PROCESS, V30, P2436, DOI 10.1109/TIP.2020.3046921
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jianbo Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P769, DOI 10.1007/978-3-030-58595-2_46
   Jing LL, 2020, IEEE T IMAGE PROCESS, V29, P225, DOI 10.1109/TIP.2019.2926748
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li HC, 2018, Arxiv, DOI [arXiv:1805.10180, DOI 10.48550/ARXIV.1805.10180]
   Li XT, 2020, Arxiv, DOI arXiv:1904.01803
   Li ZC, 2022, IEEE T PATTERN ANAL, V44, P9904, DOI 10.1109/TPAMI.2021.3132068
   Liang XD, 2018, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2018.00085
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu SA, 2022, PROC CVPR IEEE, P16815, DOI 10.1109/CVPR52688.2022.01633
   Mingmin Zhen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13663, DOI 10.1109/CVPR42600.2020.01368
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wanli Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P52, DOI 10.1007/978-3-030-58520-4_4
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xie E.Z., 2021, P 35 C NEUR INF PROC
   Xier Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P617, DOI 10.1007/978-3-030-58583-9_37
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Ye MC, 2021, INT C PATT RECOG, P3209, DOI 10.1109/ICPR48806.2021.9413224
   Yu CQ, 2018, Arxiv, DOI arXiv:1804.09337
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu F., 2015, ARXIV
   Yuan YH, 2021, Arxiv, DOI arXiv:1809.00916
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P173, DOI 10.1007/978-3-030-58539-6_11
   Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhang R, 2017, IEEE I CONF COMP VIS, P2050, DOI 10.1109/ICCV.2017.224
   Zhang X, 2021, PROC CVPR IEEE, P13951, DOI 10.1109/CVPR46437.2021.01374
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11213, P270, DOI 10.1007/978-3-030-01240-3_17
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhu LY, 2021, PROC CVPR IEEE, P12532, DOI 10.1109/CVPR46437.2021.01235
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 57
TC 0
Z9 0
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103971
DI 10.1016/j.jvcir.2023.103971
EA NOV 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z2JM3
UT WOS:001110391900001
DA 2024-07-18
ER

PT J
AU Wang, XH
   Yang, J
   Hu, M
   Ren, FJ
AF Wang, Xiaohua
   Yang, Jie
   Hu, Min
   Ren, Fuji
TI EERCA-ViT: Enhanced Effective Region and Context-Aware Vision
   Transformers for image sentiment analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual sentiment analysis; Enhanced Effective Region; Context-aware;
   Vision transformer; Double branch
ID PREDICTION; EMOTIONS; NETWORK
AB Different parts of an image have a strong or weak guiding effect on emotions. The key to emotion recognition of images is to fully exploit the regions associated with emotions. Therefore, this paper proposes a visual sentiment classification model with two branches based on visual transformer, termed as Enhanced Effective Region and Context-Aware Vision Transformers (EERCA-ViT). This model includes a primary branch and an auxiliary branch. The primary branch simulates interdependencies between patches by squeezing and stimulating patches (P-SE), thereby highlighting effective region features in the global feature. The auxiliary branch removes feature patches that have been tagged by the primary branch through the context-aware module (CAM), forcing the network to discover different sentiment discriminative regions. At the same time, a two-part loss function is constructed to improve the robustness of the model. Finally, extensive experiments on six benchmark datasets show that the proposed method outperforms the state-of-the-art image sentiment analysis methods. Furthermore, the effectiveness of the different modules of the framework (P-SE and CAM) has been well demonstrated through extensive comparative experiments.
C1 [Wang, Xiaohua; Yang, Jie; Hu, Min] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230601, Peoples R China.
   [Wang, Xiaohua; Yang, Jie; Hu, Min] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Anhui Prov Key Lab Affect Comp & Adv Intelligent M, Hefei 230601, Peoples R China.
   [Ren, Fuji] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610056, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology;
   University of Electronic Science & Technology of China
RP Hu, M (corresponding author), Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230601, Peoples R China.
EM jsjxhumin@hfut.edu.cn
FU National Natural Science Foundation of China [62176084]; Funda-mental
   Research Funds for the Central Universities of China [PA2022GDSK0065]
FX <B>Acknowledgments</B> This research has been partially supported by
   National Natural Science Foundation of China (Grant No. 62176084) , and
   the Funda-mental Research Funds for the Central Universities of China
   (Grant No. PA2022GDSK0065) .
CR Akbari H, 2021, Arxiv, DOI arXiv:2104.11178
   [Anonymous], 2016, Beyond Object Recognition: Visual Sentiment Analysis with Deep Coupled Adjective and Noun Neural Networks
   [Anonymous], 2014, Comput. Sci.
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Carion N, 2020, Arxiv, DOI [arXiv:2005.12872, DOI 10.48550/ARXIV.2005.12872]
   Chen C.-F., 2021, arXiv
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chu B, 2016, LECT NOTES COMPUT SC, V9915, P435, DOI 10.1007/978-3-319-49409-8_34
   Dai ZG, 2021, Arxiv, DOI arXiv:2011.09094
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   He J, 2021, Arxiv, DOI arXiv:2103.07976
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ST, 2021, Arxiv, DOI arXiv:2102.04378
   He X., 2019, IEEE IJCNN, P1, DOI DOI 10.1109/ijcnn.2019.8852317
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiang Y, 2021, arXiv, DOI DOI 10.48550/ARXIV.2102.07074
   Joshi D, 2011, IEEE SIGNAL PROC MAG, V28, P94, DOI 10.1109/MSP.2011.941851
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Lu X., 2015, On Shape and Computability of Emotions
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Michel P, 2019, ADV NEUR IN, V32
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Ou HC, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062136
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P2008, DOI 10.1109/TMM.2015.2482228
   Park J, 2018, BMVC
   Peng KC, 2016, IEEE IMAGE PROC, P614, DOI 10.1109/ICIP.2016.7532430
   Truong QT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1274, DOI 10.1145/3123266.3123374
   Rao TR, 2020, NEURAL PROCESS LETT, V51, P2043, DOI 10.1007/s11063-019-10033-9
   Rao TR, 2019, NEUROCOMPUTING, V333, P429, DOI 10.1016/j.neucom.2018.12.053
   Rao TR, 2016, IEEE IMAGE PROC, P634, DOI 10.1109/ICIP.2016.7532434
   Sartori A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P311, DOI 10.1145/2733373.2806250
   She D., 2019, IEEE Trans. Multimed., VPP, P1
   Siersdorfer S., 2010, ACM MULTIMEDIA 2010
   Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104
   Sun Z., 2020, Rethinking Transformer-based Set Prediction for Object Detection
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu LF, 2022, LECT NOTES COMPUT SC, V13188, P501, DOI 10.1007/978-3-031-02375-0_37
   Wu LF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11041404
   Xue LY, 2020, FRONT INFORM TECH EL, V21, P1321, DOI 10.1631/FITEE.1900618
   Yadav A, 2020, MULTIMEDIA SYST, V26, P431, DOI 10.1007/s00530-020-00656-7
   Yang JF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3266
   Yang JF, 2018, IEEE T MULTIMEDIA, V20, P2513, DOI 10.1109/TMM.2018.2803520
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   You QZ, 2017, AAAI CONF ARTIF INTE, P231
   You QZ, 2016, AAAI CONF ARTIF INTE, P308
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu Q., 2021, arXiv
   Yuan J., 1993, High. Educ. Res. Dev., V12, P131
   Yuan J., 2013, 2 INT WORKSH ISS SEN, P11
   Yuan L, 2021, Arxiv, DOI arXiv:2101.11986
   Zhang HM, 2021, IEEE T MULTIMEDIA, V23, P2033, DOI 10.1109/TMM.2020.3007352
   Zhang K, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106803
   Zhao B, 2017, IEEE T MULTIMEDIA, V19, P1245, DOI 10.1109/TMM.2017.2648498
   Zhao S., 2019, P 27 ACM INT C MULTI
   Zhao SC, 2022, IEEE T PATTERN ANAL, V44, P6729, DOI 10.1109/TPAMI.2021.3094362
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P47, DOI 10.1145/2647868.2654930
   Zhu XG, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3595
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 64
TC 1
Z9 1
U1 6
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103968
DI 10.1016/j.jvcir.2023.103968
EA NOV 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y5CF5
UT WOS:001105428700001
DA 2024-07-18
ER

PT J
AU Islam, Z
   Ben Hamza, A
AF Islam, Zaedul
   Ben Hamza, A.
TI Iterative graph filtering network for 3D human pose estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human pose estimation; Graph regularization; Gauss-Seidel; Modulation;
   Skip connection
ID NEURAL-NETWORKS
AB Graph convolutional networks (GCNs) have proven to be an effective approach for 3D human pose estimation. By naturally modeling the skeleton structure of the human body as a graph, GCNs are able to capture the spatial relationships between joints and learn an efficient representation of the underlying pose. However, most GCN-based methods use a shared weight matrix, making it challenging to accurately capture the different and complex relationships between joints. In this paper, we introduce an iterative graph filtering framework for 3D human pose estimation, which aims to predict the 3D joint positions given a set of 2D joint locations in images. Our approach builds upon the idea of iteratively solving graph filtering with Laplacian regularization via the Gauss-Seidel iterative method. Motivated by this iterative solution, we design a Gauss-Seidel network (GS-Net) architecture, which makes use of weight and adjacency modulation, skip connection, and a pure convolutional block with layer normalization. Adjacency modulation facilitates the learning of edges that go beyond the inherent connections of body joints, resulting in an adjusted graph structure that reflects the human skeleton, while skip connections help maintain crucial information from the input layer's initial features as the network depth increases. We evaluate our proposed model on two standard benchmark datasets, and compare it with a comprehensive set of strong baseline methods for 3D human pose estimation. Our experimental results demonstrate that our approach outperforms the baseline methods on both datasets, achieving state-of-the-art performance. Furthermore, we conduct ablation studies to analyze the contributions of different components of our model architecture and show that the skip connection and adjacency modulation help improve the model performance.
C1 [Islam, Zaedul; Ben Hamza, A.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ben Hamza, A (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM hamza@ciise.concordia.ca
CR Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   Banik S, 2021, IEEE IMAGE PROC, P924, DOI 10.1109/ICIP42928.2021.9506736
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Chen CH, 2017, PROC CVPR IEEE, P5759, DOI 10.1109/CVPR.2017.610
   Chen M, 2020, PR MACH LEARN RES, V119
   Chen TL, 2023, IEEE T PATTERN ANAL, V45, P2769, DOI 10.1109/TPAMI.2022.3174515
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Habibie I, 2019, PROC CVPR IEEE, P10897, DOI 10.1109/CVPR.2019.01116
   He Y., 2020, P IEEE C COMP VIS PA, P7779
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Jingbo Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P764, DOI 10.1007/978-3-030-58601-0_45
   Kenkun Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P318, DOI 10.1007/978-3-030-58607-2_19
   Klicpera J., 2018, P INT C LEARN REPR
   Lee J.Y., 2022, PROC BRIT MACHINE VI
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li C, 2020, PROC BRIT MACHINE VI
   Li C, 2019, PROC CVPR IEEE, P9879, DOI 10.1109/CVPR.2019.01012
   Li WH, 2022, PROC CVPR IEEE, P13137, DOI 10.1109/CVPR52688.2022.01280
   Lin K, 2021, PROC CVPR IEEE, P1954, DOI 10.1109/CVPR46437.2021.00199
   Liu K., 2020, PROC IEEE ASIAN C CO, P89
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Liu W, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3524497
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZG, 2021, PROC CVPR IEEE, P525, DOI 10.1109/CVPR46437.2021.00059
   Liu Zhenguang, 2022, P IEEE CVF C COMP VI, P11006
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Park S, 2016, LECT NOTES COMPUT SC, V9915, P156, DOI 10.1007/978-3-319-49409-8_15
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Qiu HB, 2019, IEEE I CONF COMP VIS, P4341, DOI 10.1109/ICCV.2019.00444
   Quan J., 2021, PROC BRIT MACHINE VI
   Rougier Caroline, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P6384
   Saad Yousef, 2003, SIAM, P23, DOI DOI 10.1137/1.9780898718003
   Sharma S, 2019, IEEE I CONF COMP VIS, P2325, DOI 10.1109/ICCV.2019.00241
   Song LC, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103055
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Sun Y, 2019, IEEE I CONF COMP VIS, P5348, DOI 10.1109/ICCV.2019.00545
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Wang J, 2019, IEEE I CONF COMP VIS, P7770, DOI 10.1109/ICCV.2019.00786
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wu HP, 2020, AAAI CONF ARTIF INTE, V34, P12378
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Xu YL, 2022, IEEE T PATTERN ANAL, V44, P6327, DOI 10.1109/TPAMI.2021.3087695
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Zeng AL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11416, DOI 10.1109/ICCV48922.2021.01124
   Zerui Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P715, DOI 10.1007/978-3-030-58580-8_42
   Zhang Z., 2022, PROC BRIT MACHINE VI
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhao W., 2022, P IEEECVF C COMPUTER, P20438
   Zhao Y, 2020, IEEE T IMAGE PROCESS, V29, P1591, DOI 10.1109/TIP.2019.2942686
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhou K, 2019, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2019.00243
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
   Zhou XY, 2016, LECT NOTES COMPUT SC, V9915, P186, DOI 10.1007/978-3-319-49409-8_17
   Zhu X., 2021, INT C LEARNING REPRE
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou Z., 2020, P BRIT MACH VIS C
   Zou ZM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11457, DOI 10.1109/ICCV48922.2021.01128
   Zou ZM, 2021, IEEE INT CONF AUTOMA
NR 72
TC 1
Z9 1
U1 3
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103908
DI 10.1016/j.jvcir.2023.103908
EA AUG 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P7NH4
UT WOS:001052499300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, ZL
   Zhang, CG
   Wu, YP
   Zhang, CC
AF Liu, Zhilei
   Zhang, Chenggong
   Wu, Yunpeng
   Zhang, Cuicui
TI Joint face completion and super-resolution using multi-scale feature
   relation learning?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face restoration; Multi-scale feature; Graph convolution
ID IMAGE; NETWORKS
AB Previous research on face restoration often focused on repairing specific types of low-quality facial images such as low-resolution (LR) or occluded facial images. However, in the real world, both the above-mentioned forms of image degradation often coexist. Therefore, it is important to design a model that can repair images that are LR and occluded simultaneously. This paper proposes a multi-scale feature graph generative adversarial network (MFG-GAN) to carry out face restoration in contexts in which both LR and occluded degradation modes coexist, and also to repair images with a single type of degradation. Based on the GAN, the MFG-GAN integrates the graph convolution and feature pyramid networks to restore occluded low-resolution face images to non-occluded high-resolution face images. The MFG-GAN uses a set of customized losses to ensure that high-quality images are generated. In addition, we designed the network in an end-to-end format. We conduct experiments on general face image restoration and facial expression restoration. Experimental results on the public-domain databases show that the proposed approach outperforms state-of-the-art methods in performing face super resolution (up to 4x or 8x) and face completion simultaneously and can recover better facial expression details.
C1 [Liu, Zhilei; Zhang, Chenggong; Wu, Yunpeng] Tianjin Univ, Coll Intelligence & Comp, Tianjin, Peoples R China.
   [Zhang, Cuicui] Tianjin Univ, Sch Marine Sci & Technol, Tianjin, Peoples R China.
C3 Tianjin University; Tianjin University
RP Zhang, CC (corresponding author), Tianjin Univ, Sch Marine Sci & Technol, Tianjin, Peoples R China.
EM zhileiliu@tju.edu.cn; zhangchenggong@tju.edu.cn; wuyunpeng@tju.edu.cn;
   zhangchenggong@tju.edu.cn
RI Liu, Zhilei/B-3733-2015; wu, yunpeng/CAH-2270-2022
OI Liu, Zhilei/0000-0003-1447-6256; wu, yunpeng/0000-0002-8094-7610
FU National Natural Science Foundation of China [41806116, 61503277];
   National Key Research and Development Program of China [2022YFC3104600,
   2019YFE0198600]
FX This work is supported by National Natural Science Foundation of China
   (No. 41806116 and No. 61503277) and the National Key Research and
   Development Program of China (No. 2022YFC3104600 and No. 2019YFE0198600)
   .
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Cao QX, 2017, PROC CVPR IEEE, P1656, DOI 10.1109/CVPR.2017.180
   Chan KCK, 2021, PROC CVPR IEEE, P14240, DOI 10.1109/CVPR46437.2021.01402
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Cheng XJ, 2020, IEEE T CIRC SYST VID, V30, P4796, DOI 10.1109/TCSVT.2019.2961629
   Defferrard M, 2016, ADV NEUR IN, V29
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dou H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1891, DOI 10.1145/3394171.3413590
   Duan YQ, 2019, PROC CVPR IEEE, P949, DOI 10.1109/CVPR.2019.00104
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Y, 2019, IEEE T MULTIMEDIA, V21, P2726, DOI 10.1109/TMM.2019.2908352
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Jiancheng Cai, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P109, DOI 10.1109/TBIOM.2019.2951063
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khorrami P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P19, DOI 10.1109/ICCVW.2015.12
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li F, 2020, IEEE T CIRC SYST VID, V30, P1511, DOI 10.1109/TCSVT.2019.2906428
   Li LRH, 2018, PROC CVPR IEEE, P6616, DOI 10.1109/CVPR.2018.00692
   Li W, 2017, IEEE INT CONF AUTOMA, P103, DOI 10.1109/FG.2017.136
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu J, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103380
   Liu Z., Large-scale celebfaces attributes (celeba) dataset
   Liu ZL, 2020, LECT NOTES COMPUT SC, V11962, P527, DOI 10.1007/978-3-030-37734-2_43
   Lu T, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5501, DOI 10.1145/3474085.3475682
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Muhammad N, 2018, PATTERN ANAL APPL, V21, P1013, DOI 10.1007/s10044-017-0617-8
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng GZ, 2018, PROC CVPR IEEE, P2188, DOI 10.1109/CVPR.2018.00233
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santoro A, 2017, ADV NEUR IN, V30
   Shao H, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103231
   Shao Z., 2020, INT J COMPUT VISION, P1
   Shi Y, 2017, IEEE T MULTIMEDIA, V19, P2804, DOI 10.1109/TMM.2017.2711263
   Shuman DI, 2013, IEEE SIGNAL PROC MAG, V30, P83, DOI 10.1109/MSP.2012.2235192
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LS, 2019, AAAI CONF ARTIF INTE, P2506
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Song YB, 2017, Arxiv, DOI arXiv:1708.00223
   Taheri S, 2014, IEEE T IMAGE PROCESS, V23, P3590, DOI 10.1109/TIP.2014.2331141
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P56, DOI 10.1007/978-3-030-01225-0_4
   Wang JF, 2018, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2018.00192
   Wang Q, 2021, IEEE T MULTIMEDIA, V23, P429, DOI 10.1109/TMM.2020.2978633
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wang YT, 2018, Arxiv, DOI arXiv:1808.08545
   Wang YF, 2019, IEEE T CIRC SYST VID, V29, P1259, DOI 10.1109/TCSVT.2018.2839879
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HP, 2021, IEEE T CIRC SYST VID, V31, P512, DOI 10.1109/TCSVT.2020.2988895
   Xiaobin Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P763, DOI 10.1007/978-3-030-58548-8_44
   Xiong W, 2019, PROC CVPR IEEE, P5833, DOI 10.1109/CVPR.2019.00599
   Xu SX, 2021, IEEE T CIRC SYST VID, V31, P1308, DOI 10.1109/TCSVT.2020.3001267
   Yang L., 2018, arXiv
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P2545, DOI 10.1109/TMM.2019.2908375
   Yang X, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103019
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang Shi-Xue, 2020, IEEE C COMPUTER VISI, P9699
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369
   Zhao KL, 2016, IEEE T IMAGE PROCESS, V25, P3931, DOI 10.1109/TIP.2016.2570550
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001
   Zhou T., 2020, IEEECVF C COMPUTER V, P7680
   Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37
   Zou M, 2005, BIOINFORMATICS, V21, P71, DOI 10.1093/bioinformatics/bth463
NR 83
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103806
DI 10.1016/j.jvcir.2023.103806
EA MAR 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA D1PS3
UT WOS:000966516200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, XY
   Ma, RT
   Shen, YX
   Niu, PP
AF Wang, Xiangyang
   Ma, Runtong
   Shen, Yixuan
   Niu, Panpan
TI Image watermarking using DNST-PHFMs magnitude domain vector AGGM-HMT
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Statistical image watermarking; DNST-PHFMs magnitudes; Vector AGGM-HMT;
   LCGEM estimation; ML watermark decoder
ID HIDDEN MARKOV MODEL; DECODER; DETECTOR; SCHEME
AB Invisibility, robustness and payload are three indispensable and contradictory properties for any image water-marking systems. Therefore, in this paper a novel statistical image watermark decoder based on robust discrete nonseparable Shearlet transform (DNST)-polar harmonic Fourier moments (PHFMs) magnitude and effective vector anisotropic generalized Gaussian mixtures (AGGM)-hidden Markov tree (HMT). We begin with a detailed study on the robustness and statistical characteristics of local DNST-PHFMs magnitudes of natural images. This study reveals the excellent robustness, highly non-Gaussian marginal statistics and strong dependencies of local DNST-PHFMs magnitudes. We also find that conditioned on their generalized neighborhoods, the local DNST-PHFMs magnitudes can be approximately modeled as anisotropic generalized Gaussian variables. Based on these findings, we model local DNST-PHFMs magnitudes using a vector AGGM-HMT that can capture all interscale, interdirection, and interlocation dependencies. Meanwhile, model parameters can be estimated effectively by using localization clues guided expectation-maximization (LCGEM) approach. Finally, we develop a new statistical image watermark decoder using the vector AGGM-HMT and maximum likelihood (ML) decision rule. Extensive experimental results show the superiority of the proposed watermark decoder over several state-of-the-art statistical watermarking methods and some approaches based on convolutional neural networks.
C1 [Wang, Xiangyang; Ma, Runtong; Shen, Yixuan; Niu, Panpan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Niu, Panpan/Q-9953-2017
FU National Natural Science Foundation of China [61472171, 61701212]; Key
   Scientific Research Project of Liaoning Provincial Education Department
   [LJKZZ20220115]; Scientific Research Project of Liaoning Provincial
   Education Department [LJKMZ20221420]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61472171 & 61701212) , Key Scientific Research
   Project of Liaoning Provincial Education Department (No. LJKZZ20220115)
   , and Scientific Research Project of Liaoning Provincial Education
   Department (No. LJKMZ20221420) .
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Aminanto M.E., 2017, PROC S CRYPTOGR INF, P1
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Amirmazlaghani M, 2019, IET COMPUT VIS, V13, P249, DOI 10.1049/iet-cvi.2018.5254
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P755, DOI 10.1109/83.918568
   Bhinder P, 2020, MULTIMED TOOLS APPL, V79, P183, DOI 10.1007/s11042-019-07941-2
   Bhinder P, 2018, MULTIMED TOOLS APPL, V77, P10303, DOI 10.1007/s11042-018-5635-z
   Bi HB, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/4065215
   Bian Y, 2013, IET IMAGE PROCESS, V7, P281, DOI 10.1049/iet-ipr.2012.0345
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Boubchir L, 2005, ISSPA 2005: The 8th International Symposium on Signal Processing and its Applications, Vols 1 and 2, Proceedings, P747
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Fang H, 2021, IEEE T CIRC SYST VID, V31, P1436, DOI 10.1109/TCSVT.2020.3009349
   Hatoum MW, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116019
   Hosny KM, 2022, MULTIMED TOOLS APPL, V81, P24347, DOI 10.1007/s11042-022-12282-8
   Hosny KM, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103007
   Hosny KM, 2021, CIRC SYST SIGNAL PR, V40, P6121, DOI 10.1007/s00034-021-01756-z
   Hosny KM, 2021, IEEE ACCESS, V9, P47425, DOI 10.1109/ACCESS.2021.3068211
   Kalantari NK, 2010, IEEE T CIRC SYST VID, V20, P396, DOI 10.1109/TCSVT.2009.2035842
   Khalilian H, 2013, IEEE T IMAGE PROCESS, V22, P4825, DOI 10.1109/TIP.2013.2278463
   Li Y, 2018, NEUROCOMPUTING, V275, P2574, DOI 10.1016/j.neucom.2017.11.029
   Lim WQ, 2013, IEEE T IMAGE PROCESS, V22, P2056, DOI 10.1109/TIP.2013.2244223
   Liu JH, 2019, KSII T INTERNET INF, V13, P452, DOI 10.3837/tiis.2019.01.025
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Mairgiotis A., 2017, 2017 IEEE INT C IMAG, P2381
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P33071, DOI 10.1007/s11042-020-09621-y
   Niu PP, 2020, IEEE ACCESS, V8, P46624, DOI 10.1109/ACCESS.2020.2978119
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Santhi V, 2017, STUD COMPUT INTELL, V660, P453, DOI 10.1007/978-3-319-44790-2_20
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang XY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103123
   Wang XY, 2020, INFORM SCIENCES, V535, P81, DOI 10.1016/j.ins.2020.05.034
   Wang XY, 2019, INFORM SCIENCES, V503, P274, DOI 10.1016/j.ins.2019.06.059
   Wang XC, 2021, J INF SECUR APPL, V59, DOI 10.1016/j.jisa.2021.102820
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zong TR, 2015, IEEE T CIRC SYST VID, V25, P717, DOI 10.1109/TCSVT.2014.2363743
NR 46
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103779
DI 10.1016/j.jvcir.2023.103779
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9I6DY
UT WOS:000939599900001
DA 2024-07-18
ER

PT J
AU Chen, YT
   Xia, RL
   Zou, K
   Yang, K
AF Chen, Yuantao
   Xia, Runlong
   Zou, Ke
   Yang, Kai
TI FFTI: Image inpainting algorithm via features fusion and two-steps
   inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Deep learning; Two-steps inpainting; Attention
   mechanism; Features fusion
AB In view of the faultiness that the existing image inpainting methods fail to make full use of the complete region to predict the missing region features when the object features are seriously missing, resulting in discontinuous features and fuzzy detail texture of the inpainting results, a fine inpainting method of incomplete image based on features fusion and two-steps inpainting (FFTI) is proposed in this paper. Firstly, the dynamic memory networks (DMN+) are used to fuse the external features and internal features of the incomplete image to generate the incomplete image optimization map. Secondly, a generation countermeasure generative network with gradient penalty constraints is constructed to guide the generator to rough repair the optimized incomplete image and obtain the rough repair map of the target to be repaired. Finally, the coarse repair graph is further optimized by the idea of coherence of relevant features to obtain the final fine repair graph. It is verified by simulation on three image data sets with different complexity, and compared with the existing dominant repair model for visual effect and objective data. The experimental results show that the results of the model repair in this paper are more reasonable in texture structure, better than other models in visual effect and objective data, and the Peak Signal-to-Noise Ratio of the proposed algorithm in the most challenging underwater targe dataset is 27.01, the highest Structural Similarity Index is 0.949.
C1 [Chen, Yuantao] Hunan Univ Informat Technol, Sch Comp Sci & Engn, Changsha, Hunan, Peoples R China.
   [Xia, Runlong] Mt Yuelu Breeding Innovat Ctr, Changsha, Peoples R China.
   [Xia, Runlong] Hunan Prov Sci & Technol Affairs Ctr, Changsha, Peoples R China.
   [Zou, Ke] Hunan WUJO High Tech Mat Corp Ltd, Loudi, Peoples R China.
   [Yang, Kai] Hunan ZOOML Intelligent Technol Corp Ltd, Changsha, Peoples R China.
RP Chen, YT (corresponding author), Hunan Univ Informat Technol, Sch Comp Sci & Engn, Changsha, Hunan, Peoples R China.
EM chenyt@hnuit.edu.cn; xiarunlong@vip.qq.com; zouk@hnwjgk.cn;
   yangkai@zoomlion.com
RI Chen, Yuantao/AAC-7165-2019
OI Chen, Yuantao/0000-0003-2277-1765
FU Natural Science Foundation of Hunan Province of China [2020JJ4623];
   Changsha Major Science and Technology Projects [KQ2102007, KQ1703018,
   KQ1706064]; Scientific Research Fund of Hunan Provincial Education
   Department [22A0701]; Scientific Research Project of Hunan University of
   Information Technology [XXY02ZD01]; College Students' Innovative
   Entrepreneurial Training Plan Program of Hunan University of Information
   Technology [X202213836002]; Smart Manufacturing Barcode Traceability
   Management System [20224301020010, CON202204070272]; University-Industry
   Collaborative Edu-cation Program [202102536008, 2022BL055]; Teaching
   Reform Research Fund of Hunan Province General Higher Education Schools
   [HNJG-2022-1335]; Changsha Science and Technology Bureau
FX This work is supported by the Natural Science Foundation of Hunan
   Province of China under Grant 2020JJ4623, Changsha Major Science and
   Technology Projects under Grant KQ2102007, KQ1703018, KQ1706064, A
   Project Supported by Scientific Research Fund of Hunan Provincial
   Education Department under Grant 22A0701, Scientific Research Project of
   Hunan University of Information Technology under Grant XXY02ZD01,
   College Students' Innovative Entrepreneurial Training Plan Program of
   Hunan University of Information Technology under Grant X202213836002,
   Smart Manufacturing Barcode Traceability Management System under Grant
   20224301020010 and CON202204070272 (Hunan WUJO High-Tech Material
   Corporation Limited) , University-Industry Collaborative Edu-cation
   Program under Grant 202102536008, China University Innovation
   Funding-Beslin Smart Education Project under Grant 2022BL055, A Project
   Supported by Teaching Reform Research Fund of Hunan Province General
   Higher Education Schools under Grant HNJG-2022-1335 and 2022 Part-time
   Vice President of Science and Technology of Changsha Enterprises from
   Changsha Science and Technology Bureau.
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Fang YC, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115664
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ioffe S., 2015, P INT C LEARN REPR S
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiao SM, 2017, OPT LETT, V42, P482, DOI 10.1364/OL.42.000482
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kingma D, 2014, C LEARNING REPRESENT, P12
   Korhonen J, 2012, INT WORK QUAL MULTIM, P37, DOI 10.1109/QoMEX.2012.6263880
   Kumar A., 2015, P INT C MACH LEARN, P2068
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu RS, 2020, IEEE T CIRC SYST VID, V30, P4861, DOI 10.1109/TCSVT.2019.2963772
   Liu WW, 2019, IEEE T PATTERN ANAL, V41, P408, DOI 10.1109/TPAMI.2018.2794976
   Liu Xiaodong., 2015, Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, P912
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Nazeri K., 2019, arXiv
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Wang N, 2021, IEEE T IMAGE PROCESS, V30, P1784, DOI 10.1109/TIP.2020.3048629
   Wang N, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Wang Y, 2018, ADV NEUR IN, V31
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Xia HT, 2017, OPT LETT, V42, P322, DOI 10.1364/OL.42.000322
   Xie CH, 2019, IEEE I CONF COMP VIS, P8857, DOI 10.1109/ICCV.2019.00895
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yu F., 2015, ARXIV
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu T, 2020, AAAI CONF ARTIF INTE, V34, P12733
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 41
TC 71
Z9 71
U1 29
U2 64
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103776
DI 10.1016/j.jvcir.2023.103776
EA FEB 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA H0FG2
UT WOS:000992801900001
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Hutamaputra, W
   Utaminingrum, F
   Budi, AS
   Ogata, K
AF Hutamaputra, William
   Utaminingrum, Fitri
   Budi, Agung Setia
   Ogata, Kohichi
TI Eyes gaze detection based on multiprocess of ratio parameters for smart
   wheelchair menu selection in different screen size
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eye gaze; Face detection; Facial landmark; Haar cascade; Midpoint;
   Threshold
ID MOVEMENT
AB Smart wheelchairs support paralysis disability people, especially paralysis of the hands and feet. Paralysis disability cannot operate menu selection with a touch screen. This research proposes a menu selection to select features in a smart wheelchair using the eye's gaze and execute the menu by blinking the left eye. Multiprocess of ratio parameter is the methodology used and expanded in this research. The proposed method compared the ratio between the midpoint on the iris contour and registered midpoint on the selection step. This research is conducted under two conditions: the screen size being started in 14 and 17 inches. This research resulted in 91.48% and 90.68% accuracy in 14 and 17-inch screens for users without glasses. Meanwhile, 89.55% and 86.99% were obtained for wearing glasses users. The experiments were conducted where the position of a user is 30-39, 40-49, and 50-59 cm from the camera.
C1 [Hutamaputra, William; Utaminingrum, Fitri] Brawijaya Univ, Fac Comp Sci, Comp Vis Res Grp, Malang 65145, Indonesia.
   [Budi, Agung Setia] Brawijaya Univ, Fac Comp Sci, Malang 65145, Indonesia.
   [Ogata, Kohichi] Kumamoto Univ, Fac Adv Sci & Technol, Kurokami 2-39-1,Chuo ku, Kumamoto 8608555, Japan.
C3 Brawijaya University; Brawijaya University; Kumamoto University
RP Utaminingrum, F (corresponding author), Brawijaya Univ, Fac Comp Sci, Comp Vis Res Grp, Malang 65145, Indonesia.
EM f3_ningrum@ub.ac.id
RI Budi, Agung Setia/JLM-5436-2023
OI Budi, Agung Setia/0000-0002-0115-1754
CR Akinyelu AA, 2020, IEEE ACCESS, V8, P142581, DOI 10.1109/ACCESS.2020.3013540
   Aziz F, 2014, J NEURAL ENG, V11, DOI 10.1088/1741-2560/11/5/056018
   Cheung YM, 2015, IEEE T HUM-MACH SYST, V45, P419, DOI 10.1109/THMS.2015.2400442
   Cristanti RY, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON KNOWLEDGE CREATION AND INTELLIGENT COMPUTING (IES-KCIC), P89, DOI 10.1109/KCIC.2017.8228569
   Fabregat H, 2020, IEEE ACCESS, V8, P155399, DOI 10.1109/ACCESS.2020.3019178
   Gao H, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102506
   Han JH, 2011, IEEE T IMAGE PROCESS, V20, P506, DOI 10.1109/TIP.2010.2068555
   Han SY, 2020, IEEE ACCESS, V8, P64739, DOI 10.1109/ACCESS.2020.2985095
   Hyder R, 2016, IEEE EMBS CONF BIO, P784, DOI 10.1109/IECBES.2016.7843557
   Kaur Amanpreet, 2021, Journal of Medical Engineering & Technology, V45, P61, DOI 10.1080/03091902.2020.1853838
   Liu M, 2020, IEEE T FUZZY SYST, V28, P92, DOI 10.1109/TFUZZ.2019.2912576
   Manabe H, 2015, IEEE T BIO-MED ENG, V62, P1553, DOI 10.1109/TBME.2015.2394409
   Minati L, 2016, IEEE ACCESS, V4, P9528, DOI 10.1109/ACCESS.2017.2647851
   Murata A, 2019, IEEE T HUM-MACH SYST, V49, P259, DOI 10.1109/THMS.2018.2884737
   Ngo HT, 2014, IEEE T CONSUM ELECTR, V60, P485, DOI 10.1109/TCE.2014.6937334
   Pangestu G., 2019, INT J INTELL ENG SYS
   Pangestu G., 2019, INT J ADV SOFT COMPU, V11, P1
   Patil A.V., 2017, SOLAR POWERED TOUCH, P8
   Paulus YT, 2021, DISPLAYS, V67, DOI 10.1016/j.displa.2021.101997
   Reddy KS, 2021, Mater Today Proc.
   Reddy P.Y., 2018, 2018 3 IEEE INT C RE, P1210
   Subur J, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P699, DOI 10.1109/ICEEI.2015.7352588
   Trujillo-León A, 2018, IEEE T NEUR SYS REH, V26, P1381, DOI 10.1109/TNSRE.2018.2838326
   Utaminingrum F, 2016, P 2016 INT C COMMUNI, P1
   Utaminingrum F, 2021, INT J INNOV COMPUT I, V17, P1287, DOI 10.24507/ijicic.17.04.1287
   Zaremba L.S., 2001, INT J COMPUT VISION, V43, P7
NR 26
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103756
DI 10.1016/j.jvcir.2023.103756
EA JAN 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8P9BV
UT WOS:000926812400001
DA 2024-07-18
ER

PT J
AU Zhang, ZC
   Sun, W
   Wu, W
   Cheng, Y
   Min, XK
   Zhai, GT
AF Zhang, Zicheng
   Sun, Wei
   Wu, Wei
   Cheng, Ying
   Min, Xiongkuo
   Zhai, Guangtao
TI Perceptual quality assessment for fine-grained compressed images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image compression; Full-reference; Image quality assessment;
   Fine-grained
ID INDEX
AB Recent years have witnessed the rapid development of image storage and transmission systems, in which image compression plays an important role. Generally speaking, image compression algorithms are developed to en-sure good visual quality at limited bit rates. However, due to the different compression optimization methods, the compressed images may have different levels of quality, which needs to be evaluated quantificationally. Nowadays, the mainstream full-reference (FR) metrics are effective to predict the quality of compressed images at coarse-grained levels (the bit rates differences of compressed images are obvious), however, they may perform poorly for fine-grained compressed images whose bit rates differences are quite subtle. Therefore, to better improve the Quality of Experience (QoE) and provide useful guidance for compression algorithms, we propose a full-reference image quality assessment (FR-IQA) method for compressed images of fine-grained levels. Specifically, the reference images and compressed images are first converted to YCbCr color space. The gradient features are extracted from regions that are sensitive to compression artifacts. Then we employ the Log-Gabor transformation to further analyze the texture difference. Finally, the obtained features are fused into a quality score. The proposed method is validated on the fine-grained compression image quality assessment (FGIQA) database, which is especially constructed for assessing the quality of compressed images with close bit rates. The experimental results show that our metric outperforms mainstream FR-IQA metrics on the FGIQA database. We also test our method on other commonly used compression IQA databases and the results show that our method obtains competitive performance on the coarse-grained compression IQA databases as well.
C1 [Zhang, Zicheng; Sun, Wei; Min, Xiongkuo; Zhai, Guangtao] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
   [Wu, Wei; Cheng, Ying] Alibaba Grp, Hangzhou 310052, Peoples R China.
C3 Shanghai Jiao Tong University; Alibaba Group
RP Zhai, GT (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
EM zhaiguangtao@sjtu.edu.cn
RI Zhai, Guangtao/X-5949-2019; Sun, Weijie/GLU-8735-2022
OI Zhai, Guangtao/0000-0001-8165-9322; Sun, Weijie/0000-0003-0112-0461;
   Zhang, Zicheng/0000-0002-7247-7938
FU Natural Science Foundation of China; National Key R&D Program of China;
   Shanghai Municipal Science and Technology Major Project;  [62225112]; 
   [61831015];  [2021YFE0206700];  [2021SHZDZX0102]
FX Acknowledgments This work was supported in part by he Natural Science
   Foundation of China No. 62225112, No. 61831015; the National Key R&D
   Program of China No. 2021YFE0206700; and the Shanghai Municipal Science
   and Technology Major Project No. 2021SHZDZX0102.
CR [Anonymous], 2021, LIBJPEG
   [Anonymous], 2010, CATEGORICAL SUBJECTI
   Channappayya SS, 2008, IEEE T IMAGE PROCESS, V17, P1624, DOI 10.1109/TIP.2008.2001400
   Chen ZZ, 2010, IEEE INT CON MULTI, P784, DOI 10.1109/ICME.2010.5582549
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Guerin Jr N.D., 2022, IMAGE COMMUN, V101
   Hudson G, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.040901
   Hunter DR, 2004, ANN STAT, V32, P384
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Keyan Ding, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2483, DOI 10.1145/3474085.3475419
   Li C., 2021, IMAGE COMMUN, V91
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lu Wei, 2022, Digital TV and Wireless Multimedia Communications: 18th International Forum, IFTC 2021, Revised Selected Papers. Communications in Computer and Information Science (1560), P164, DOI 10.1007/978-981-19-2266-4_13
   Ma SW, 2016, IEEE MULTIMEDIA, V23, P16, DOI 10.1109/MMUL.2016.16
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P6054, DOI 10.1109/TIP.2020.2988148
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Papadopoulos MA, 2015, IEEE IMAGE PROC, P2781, DOI 10.1109/ICIP.2015.7351309
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194
   Ratnakar V, 2000, IEEE T IMAGE PROCESS, V9, P267, DOI 10.1109/83.821739
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sun W., 2020, IEEE Trans. Mob. Comput.
   Sun W, 2023, Arxiv, DOI arXiv:2105.14550
   Sun W, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455999
   Sun W, 2020, IEEE J-STSP, V14, P64, DOI 10.1109/JSTSP.2019.2955024
   WALLACE GK, 1992, IEEE T CONSUM ELECTR, V38, pR18, DOI 10.1109/30.125072
   Wang SQ, 2018, IEEE T CIRC SYST VID, V28, P1, DOI 10.1109/TCSVT.2016.2602764
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang T, 2022, Arxiv, DOI arXiv:2206.05008
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2003, P 37 AS C SIGN SYST, P1398, DOI [DOI 10.1109/ACSSC.2003.1292216, 10.1109/ACSSC.2003.1292216]
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wei Sun, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P856, DOI 10.1145/3503161.3548329
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang EH, 2009, IEEE T IMAGE PROCESS, V18, P63, DOI 10.1109/TIP.2008.2007609
   Zhai GT, 2008, SIGNAL PROCESS-IMAGE, V23, P417, DOI 10.1016/j.image.2008.04.007
   Zhai GT, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3457905
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhai GT, 2010, IEEE T CIRC SYST VID, V20, P1224, DOI 10.1109/TCSVT.2010.2057019
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang XF, 2019, IEEE T IMAGE PROCESS, V28, P1163, DOI 10.1109/TIP.2018.2874283
   Zhang XF, 2017, IEEE SIGNAL PROC LET, V24, P96, DOI 10.1109/LSP.2016.2641456
   Zhang XF, 2017, IEEE T CIRC SYST VID, V27, P2177, DOI 10.1109/TCSVT.2016.2581618
   Zhang XF, 2013, IEEE T IMAGE PROCESS, V22, P4613, DOI 10.1109/TIP.2013.2274386
   Zhang Z., 2021, 2021 IEEE INT C MULT, P1
   Zhang ZC, 2022, Arxiv, DOI arXiv:2206.04289
   Zhang ZC, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455963
   Zhang Zicheng, 2022, IEEE T CIRC SYST VID
NR 52
TC 3
Z9 3
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103696
DI 10.1016/j.jvcir.2022.103696
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, QY
   Song, Y
   Zou, R
   Shu, XB
AF Wang, Qingyun
   Song, Yan
   Zou, Rong
   Shu, Xiangbo
TI Progressive enhancement network with pseudo labels for weakly supervised
   temporal action localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Temporal action localization; Weak supervision; Pseudo label; Video
   understanding
AB Weakly supervised temporal action localization (WSTAL) is crucial for real world applications, as it relieves the huge burden of frame-level annotations for fully supervised action detection. Most existing WSTAL methods focused on classifying video snippets, or detecting action boundaries. However, the predictions from these well-designed models have not been fully utilized. Accordingly, we propose a weakly-supervised framework called the progressive enhancement network (PEN), which takes full advantages of the predictions generated by the preceding models to enhance the subsequent models. Specifically, snippet-level pseudo labels are generated from the preceding predictions by considering the similarity and temporal distance between action snippets. Then subsequent models are progressively enhanced by using pseudo labels as a supervision, and utilizing their underlying semantics to make the feature representation more qualified for the temporal localization task. Extensive experiments which are carried out on two popular benchmarks, THUMOS'14 and ActivityNet v1.2, demonstrate the effectiveness of our method.
C1 [Wang, Qingyun; Song, Yan; Zou, Rong; Shu, Xiangbo] Nanjing Univ Sci & Technol, 200 Xiaoling Wei St, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Song, Y (corresponding author), Nanjing Univ Sci & Technol, 200 Xiaoling Wei St, Nanjing 210094, Peoples R China.
EM songyan@njust.edu.cn
RI Zou, Rong/JJC-7186-2023
OI Song, Yan/0000-0001-8431-7037
FU National Natural Science Foundation of China [61672285, 61702265];
   National Key Research and Development Program of China [2018AAA0102002];
   Natural Science Foundation of Jiangsu Province [BK20170856]
FX This work was supported by the National Natural Science Foundation of
   China under Grant (No. 61672285, No. 61702265), the National Key
   Research and Development Program of China (2018AAA0102002) and the
   Natural Science Foundation of Jiangsu Province under Grant (No.
   BK20170856).
CR Sigurdsson GA, 2016, Arxiv, DOI [arXiv:1607.07429, DOI 10.48550/ARXIV.1607.07429]
   [Anonymous], 2016, P INT JOINT C ARTIFI
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Buch S, 2017, PROC CVPR IEEE, P6373, DOI 10.1109/CVPR.2017.675
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Gao JY, 2017, Arxiv, DOI arXiv:1705.01180
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Kantorov V, 2016, LECT NOTES COMPUT SC, V9909, P350, DOI 10.1007/978-3-319-46454-1_22
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kingma D. P., 2014, arXiv
   Lee PLY, 2019, Arxiv, DOI arXiv:1911.09963
   Li CL, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102628
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ZY, 2019, IEEE I CONF COMP VIS, P3898, DOI 10.1109/ICCV.2019.00400
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Narayan S, 2019, IEEE I CONF COMP VIS, P8678, DOI 10.1109/ICCV.2019.00877
   Oneata D, 2014, PROC CVPR IEEE, P2545, DOI 10.1109/CVPR.2014.326
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Pardo A, 2020, Arxiv, DOI arXiv:1904.00227
   Paszke Adam, 2017, NIPS 2017 WORKSH AUT
   Paul S, 2018, LECT NOTES COMPUT SC, V11208, P588, DOI 10.1007/978-3-030-01225-0_35
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Nguyen PX, 2019, IEEE I CONF COMP VIS, P5501, DOI 10.1109/ICCV.2019.00560
   Rolnick D, 2018, Arxiv, DOI arXiv:1705.10694
   Shen YH, 2018, PROC CVPR IEEE, P5764, DOI 10.1109/CVPR.2018.00604
   Shou Z, 2018, LECT NOTES COMPUT SC, V11220, P162, DOI 10.1007/978-3-030-01270-0_10
   Shou Z, 2017, PROC CVPR IEEE, P1417, DOI 10.1109/CVPR.2017.155
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381
   Son J., 2018, AS C COMP VIS, P632
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang P, 2017, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2017.326
   Wang L, 2014, IEEE INT CONF VLSI
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Xiong YJ, 2017, Arxiv, DOI arXiv:1703.02716
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu MM, 2020, Arxiv, DOI arXiv:1911.11462
   Yang K, 2019, J VIS COMMUN IMAGE R, V61, P296, DOI 10.1016/j.jvcir.2019.02.003
   Yuanhao Zhai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P37, DOI 10.1007/978-3-030-58539-6_3
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang CW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P738, DOI 10.1145/3343031.3351044
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhekun Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P729, DOI 10.1007/978-3-030-58526-6_43
   Zhong JX, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P35, DOI 10.1145/3240508.3240511
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 56
TC 1
Z9 1
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103590
DI 10.1016/j.jvcir.2022.103590
EA AUG 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4U2UR
UT WOS:000858655700003
DA 2024-07-18
ER

PT J
AU Wang, L
   Xu, LZ
   Tian, W
   Zhang, YF
   Feng, H
   Chen, Z
AF Wang, Li
   Xu, Lizhong
   Tian, Wei
   Zhang, Yunfei
   Feng, Hui
   Chen, Zhe
TI Underwater image super-resolution and enhancement via progressive
   frequency-interleaved network?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image; Super-resolution; Enhancement; Deep learning;
   Frequency domain
AB Underwater images usually contain severely blurred details, color distortion, and low contrast, warranting efficient methods to obtain clean images. However, most convolutional neural network-based approaches involve high computational cost, numerous model parameters, and even poor performance. Besides, the mapping from input to output is learned using a single path, ignoring the frequency domain information. To solve these challenges, we propose a novel progressive frequency-interleaved network (PFIN) for underwater imagery super-resolution and enhancement. Specifically, progressive frequency-domain module (PFDM) and convolution-guided module (CGM) constitute PFIN for effective color deviation correction and detail enhancement. PFDM that possesses global spatial attention, multi-scale residual, and frequency information modulation blocks gradually learn frequency features and explicitly compensate for detail loss. Furthermore, CGM comprising a series of convolution blocks generates discriminative characteristics to modulate in PFDM for better accommodating degraded representations. Extensive experiments demonstrate the superiority of our PFIN regarding quantitative evaluations and visual quality.
C1 [Wang, Li; Xu, Lizhong; Tian, Wei; Zhang, Yunfei; Feng, Hui; Chen, Zhe] Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
   [Feng, Hui] Jiangsu Vocat Coll Finance & Econ, Dept Intelligent Engn Technol, Huai'an, Peoples R China.
C3 Hohai University
RP Xu, LZ (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
EM wang_and_li@hhu.edu.cn; lzhxu@hhu.edu.cn
RI Zhang, Yunfei/ABE-2273-2020
OI Wang, Li/0000-0003-2054-1392
FU National Natural Science Foundation of China [62073120]; Natural Science
   Foundation of Jiangsu Province, China [SBK2020022539]
FX Acknowledgments This work was supported by National Natural Science
   Foundation of China under Grant (No. 62073120) and Natural Science
   Foundation of Jiangsu Province, China (No. SBK2020022539) .
CR Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Blau Y, 2019, LECT NOTES COMPUT SC, V11133, P334, DOI 10.1007/978-3-030-11021-5_21
   Cai JR, 2019, IEEE I CONF COMP VIS, P3086, DOI 10.1109/ICCV.2019.00318
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen XL, 2020, LECT NOTES ARTIF INT, V12595, P233, DOI 10.1007/978-3-030-66645-3_20
   Chen YP, 2019, IEEE I CONF COMP VIS, P3434, DOI 10.1109/ICCV.2019.00353
   Chen YZ, 2020, IEEE ACCESS, V8, P117759, DOI 10.1109/ACCESS.2020.3004141
   Cherian AK, 2021, CMC-COMPUT MATER CON, V69, P1537, DOI 10.32604/cmc.2021.018213
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu B, 2021, INT J COMPUT INT SYS, V14, P88, DOI 10.2991/ijcis.d.201102.001
   Fu XY, 2017, I S INTELL SIG PROC, P789, DOI 10.1109/ISPACS.2017.8266583
   Islam MJ, 2020, IEEE INT CONF ROBOT, P900, DOI [10.1109/ICRA40945.2020.9197213, 10.1109/icra40945.2020.9197213]
   Islam MJ, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li Y, 2021, IET IMAGE PROCESS, V15, P774, DOI 10.1049/ipr2.12061
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu P, 2019, IEEE ACCESS, V7, P94614, DOI 10.1109/ACCESS.2019.2928976
   Liu XD, 2021, NEUROCOMPUTING, V453, P538, DOI 10.1016/j.neucom.2020.07.130
   Lu T, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5501, DOI 10.1145/3474085.3475682
   Lu T, 2021, IEEE SIGNAL PROC LET, V28, P1305, DOI 10.1109/LSP.2021.3084522
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Mao X.-J., 2016, ARXIV160608921
   Ni KS, 2009, IEEE T IMAGE PROCESS, V18, P1976, DOI 10.1109/TIP.2009.2023706
   Ouyang DQ, 2020, NEURAL NETWORKS, V128, P158, DOI 10.1016/j.neunet.2020.05.016
   Ouyang DQ, 2019, PATTERN RECOGN LETT, V117, P153, DOI 10.1016/j.patrec.2018.05.009
   Pang Y., 2020, ARXIV200914547
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sharma P.K., 2022, arXiv
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang H, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103136
   Wang JM, 2021, NEURAL NETWORKS, V143, P400, DOI 10.1016/j.neunet.2021.06.005
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Xiaotong Luo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P272, DOI 10.1007/978-3-030-58542-6_17
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu J., 2018, P IEEE C COMPUTER VI
   Zhang DY, 2021, IEEE T CIRC SYST VID, V31, P3954, DOI 10.1109/TCSVT.2020.3044451
   Zhang DY, 2021, IEEE T MULTIMEDIA, V23, P2172, DOI 10.1109/TMM.2020.3008041
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhang Y, 2022, SIGNAL IMAGE VIDEO P, V16, P155, DOI 10.1007/s11760-021-01969-4
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhou Y., 2020, DOMAIN ADAPTIVE ADVE
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 53
TC 13
Z9 13
U1 1
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2022
VL 86
AR 103545
DI 10.1016/j.jvcir.2022.103545
EA MAY 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2H3MB
UT WOS:000814201400002
DA 2024-07-18
ER

PT J
AU Liu, YY
   Pan, CC
   Bie, ML
   Li, J
AF Liu, Yanyan
   Pan, Changcheng
   Bie, Minglin
   Li, Jin
TI An efficient real-time target tracking algorithm using adaptive feature
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature fusion; Target tracking; Real time
ID OBJECT TRACKING; COLOR HISTOGRAM; STAPLE
AB Visual-based target tracking is easily influenced by multiple factors, such as background clutter, targets' fast-moving, illumination variation, object shape change, occlusion, etc. These factors influence the tracking accuracy of a target tracking task. To address this issue, an efficient real-time target tracking method based on a low-dimension adaptive feature fusion is proposed to allow us the simultaneous implementation of the high-accuracy and real-time target tracking. First, the adaptive fusion of a histogram of oriented gradient (HOG) feature and color feature is utilized to improve the tracking accuracy. Second, a convolution dimension reduction method applies to the fusion between the HOG feature and color feature to reduce the over-fitting caused by their high -dimension fusions. Third, an average correlation energy estimation method is used to extract the relative con-fidence adaptive coefficients to ensure tracking accuracy. We experimentally confirm the proposed method on an OTB100 data set. Compared with nine popular target tracking algorithms, the proposed algorithm gains the highest tracking accuracy and success tracking rate. Compared with the traditional Sum of Template and Pixel-wise LEarners (STAPLE) algorithm, the proposed algorithm can obtain a higher success rate and accuracy, improving by 2.3% and 1.9%, respectively. The experimental results also demonstrate that the proposed algo-rithm can reach the real-time target tracking with 50+fps. The proposed method paves a more promising way for real-time target tracking tasks under a complex environment, such as appearance deformation, illumination change, motion blur, background, similarity, scale change, and occlusion.
C1 [Liu, Yanyan; Pan, Changcheng; Bie, Minglin] Changchun Univ Sci & Technol, Dept Elect & Informat Engn, Changchun 130022, Jilin, Peoples R China.
   [Li, Jin] Univ Complutense, Fac Fis, Dept Opt, Madrid 28040, Spain.
   [Pan, Changcheng] Zhejiang Saisi Elect Technol Co Ltd, JST 314000, Zhejiang, Peoples R China.
C3 Changchun University of Science & Technology; Complutense University of
   Madrid
RP Li, J (corresponding author), Univ Complutense, Fac Fis, Dept Opt, Madrid 28040, Spain.
EM jinli02@ucm.es
RI liu, yan/HGV-1365-2022
FU Innovation Foundation of Changchun University of Science and Technology
   [XJJLG-2018-07]; Education Department of Jilin Province, China
   [JJKH20210838KJ]; Marie Sklodowska Curie Fellowship
   [H2020-MSCA-IF-2020-101022219]
FX Yanyan Liu would like to thank the Innovation Foundation of Changchun
   University of Science and Technology (XJJLG-2018-07) and the Education
   Department of Jilin Province, China (JJKH20210838KJ) . J. L. is grateful
   for financial support through a Marie Sklodowska Curie Fellowship,
   H2020-MSCA-IF-2020-101022219.
CR Adam A., 2006, COMPUTER VISION PATT, V1, P17
   Akhondi-Asl A, 2014, IEEE T MED IMAGING, V33, P1997, DOI 10.1109/TMI.2014.2329603
   Akhondi-Asl A, 2012, LECT NOTES COMPUT SC, V7510, P593, DOI 10.1007/978-3-642-33415-3_73
   Bal A, 2004, APPL OPTICS, V43, P4874, DOI 10.1364/AO.43.004874
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bidon S, 2014, IEEE T AERO ELEC SYS, V50, P871, DOI 10.1109/TAES.2013.120533
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Buzzi S, 2008, IEEE T AERO ELEC SYS, V44, P1135, DOI 10.1109/TAES.2008.4655369
   Cen M, 2010, APPL OPTICS, V49, P5384, DOI 10.1364/AO.49.005384
   Çetin M, 2014, IEEE SIGNAL PROC MAG, V31, P27, DOI 10.1109/MSP.2014.2312834
   Chakravarti R, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P1323, DOI 10.1109/ITNG.2009.126
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Jeung BS, 2019, CURR OPT PHOTONICS, V3, P154, DOI 10.3807/COPP.2019.3.2.154
   Kaawaase K. S., 2011, Information Technology Journal, V10, P691, DOI 10.3923/itj.2011.691.702
   Li J, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00742-7
   Li Y, 2014, APPL OPTICS, V53, P6518, DOI 10.1364/AO.53.006518
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Mihaylova L, 2014, DIGIT SIGNAL PROCESS, V25, P1, DOI 10.1016/j.dsp.2013.11.006
   Newstadt G, 2014, IEEE T AERO ELEC SYS, V50, P2004, DOI 10.1109/TAES.2013.130123
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Praveenkumar P, 2015, SECUR COMMUN NETW, V8, P3335, DOI 10.1002/sec.1257
   Savazzi S, 2014, IEEE J-STSP, V8, P16, DOI 10.1109/JSTSP.2013.2286772
   Türetken E, 2017, IEEE T MED IMAGING, V36, P942, DOI 10.1109/TMI.2016.2640859
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wang YZ, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P235, DOI 10.1109/FSKD.2007.319
   Wang ZL, 2012, APPL OPTICS, V51, P5051, DOI 10.1364/AO.51.005051
   Warfield SK, 2004, IEEE T MED IMAGING, V23, P903, DOI 10.1109/TMI.2004.828354
   Weerakkody S, 2015, IEEE DECIS CONTR P, P5820, DOI 10.1109/CDC.2015.7403134
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan LB, 2017, IEEE ACCESS, V5, P2798, DOI 10.1109/ACCESS.2017.2677480
   Zhou Y, 2013, OPT EXPRESS, V21, P11294, DOI 10.1364/OE.21.011294
NR 41
TC 5
Z9 5
U1 5
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103505
DI 10.1016/j.jvcir.2022.103505
EA APR 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, N
   Zhou, HY
   Liu, AA
   Huang, XD
   Zhang, SY
   Jin, GQ
   Guo, JB
   Li, XY
AF Hu, Nian
   Zhou, Heyu
   Liu, An-An
   Huang, Xiangdong
   Zhang, Shenyuan
   Jin, Guoqing
   Guo, Junbo
   Li, Xuanya
TI Collaborative Distribution Alignment for 2D image-based 3D shape
   retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D shape retrieval; Cross-domain retrieval; Multi-view learning
AB Retrieving 3D shapes with 2D images has become a popular research area nowadays, and a great deal of work has been devoted to reducing the discrepancy between 3D shapes and 2D images to improve retrieval performance. However, most approaches ignore the semantic information and decision boundaries of the two domains, and cannot achieve both domain alignment and category alignment in one module. In this paper, a novel Collaborative Distribution Alignment (CDA) model is developed to address the above existing challenges. Specifically, we first adopt a dual-stream CNN, following a similarity guided constraint module, to generate discriminative embeddings for input 2D images and 3D shapes (described as multiple views). Subsequently, we explicitly introduce a joint domain-class alignment module to dynamically learn a class-discriminative and domain-agnostic feature space, which can narrow the distance between 2D image and 3D shape instances of the same underlying category, while pushing apart the instances from different categories. Furthermore, we apply a decision boundary refinement module to avoid generating class-ambiguity embeddings by dynamically adjusting inconsistencies between two discriminators. Extensive experiments and evaluations on two challenging benchmarks, MI3DOR and MI3DOR-2, demonstrate the superiority of the proposed CDA method for 2D image-based 3D shape retrieval task.
C1 [Hu, Nian; Zhou, Heyu; Liu, An-An; Huang, Xiangdong] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Hu, Nian; Liu, An-An] Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei 230088, Peoples R China.
   [Jin, Guoqing; Guo, Junbo] State Key Lab Commun Content Cognit, Beijing 100733, Peoples R China.
   [Li, Xuanya] Baidu Inc, Beijing 100105, Peoples R China.
C3 Tianjin University; Baidu
RP Liu, AA (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.; Li, XY (corresponding author), Baidu Inc, Beijing 100105, Peoples R China.
EM anan0422@gmail.com; lixuanya@baidu.com
OI , Heyu Zhou/0000-0001-9451-5600; Hu, Nian/0000-0002-3174-6919
FU National Nature Sci-ence Foundation of China [U21B2024, 61772359];
   Tianjin New Generation Artificial Intelligence Major Program, China
   [19ZXZNGX00110]
FX Acknowledgments This work was supported in part by the National Nature
   Sci-ence Foundation of China (U21B2024, 61772359) , and the grant of
   Tianjin New Generation Artificial Intelligence Major Program, China
   (19ZXZNGX00110) .
CR Blitzer J., 2006, PROC C EMPIRICAL MET, P120, DOI DOI 10.3115/1610075.1610094
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen JX, 2018, LECT NOTES COMPUT SC, V11217, P624, DOI 10.1007/978-3-030-01261-8_37
   Cicek S, 2019, IEEE I CONF COMP VIS, P1416, DOI 10.1109/ICCV.2019.00150
   Dai GX, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P670
   Dai GX, 2018, IEEE T IMAGE PROCESS, V27, P3374, DOI 10.1109/TIP.2018.2817042
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du Y. T., 2020, Dual Adversarial Domain Adaptation
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Jiang Y., 2021, SIMGAN HYBRID SIMULA
   Jiaxin Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P105, DOI 10.1007/978-3-030-58555-6_7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee T, 2018, INT CONF 3D VISION, P258, DOI 10.1109/3DV.2018.00038
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu Ming Yu, 2016, ADV NEURAL INF PROCE, P469
   Long MS, 2017, PR MACH LEARN RES, V70
   Lu X, 2021, IEEE T MULTIMEDIA, V23, P4541, DOI 10.1109/TMM.2020.3044473
   Ma Y., 2019, FRONT DATA COMPUT, V1
   Meagher M, 2007, IEEE INT CONF INF VI, P601
   Nie WZ, 2019, MULTIMEDIA SYST, V25, P655, DOI 10.1007/s00530-018-0600-2
   Paddlepaddle, 2020, PADDL EAS TO US EAS
   Pan SJ, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1187
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Peng XC, 2019, IEEE I CONF COMP VIS, P1406, DOI 10.1109/ICCV.2019.00149
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang C, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1273
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang JH, 2019, IEEE I CONF COMP VIS, P3374, DOI 10.1109/ICCV.2019.00347
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Xinpeng Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P498, DOI 10.1007/978-3-030-58565-5_30
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Ye M., 2020, Deep learning for person re-identification: A survey and outlook
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhou H., 2020, P 28 ACM INT C MULT, P925
   Zhou HY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P839
   Zhou HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1667, DOI 10.1145/3343031.3351011
NR 48
TC 9
Z9 9
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103426
DI 10.1016/j.jvcir.2021.103426
EA FEB 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0H9PG
UT WOS:000779059800001
DA 2024-07-18
ER

PT J
AU Ye, WJ
   Zhu, XK
   Xu, ZT
   Liu, YJ
   Chang, CC
AF Ye, Wujian
   Zhu, Xueke
   Xu, Zuoteng
   Liu, Yijun
   Chang, Chin-Chen
TI A comprehensive framework of multiple semantics preservation in neural
   style transfer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neural style transfer; Multiple semantic preservation; Comprehensive
   framework; Stylized artistic quality
AB Recently neural style transfer has achieved great development, but there is still a big gap compared with manual creation. Most of the existing methods ignore the comprehensive consideration of preserving various semantic information of original content images, resulting in distortion or loss of original content features of the generated works, which are dull and difficult to convey the original themes and emotions. In this paper, we analyze the ability of the existing methods to maintain single semantic information and propose a fast style transfer framework with multi-semantic preservation. The experiments indicate that our method can effectively retain the original semantic information including salience and depth features, so that the final artwork has better visual effect by highlighting its regional focus and depth information. Compared with existing methods, our method has better ability in semantic preservation and can generate more artworks with distinct regions, controllable semantics, diverse contents and rich emotions.
C1 [Ye, Wujian; Zhu, Xueke; Xu, Zuoteng; Liu, Yijun] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 407802, Taiwan.
C3 Guangdong University of Technology
RP Liu, YJ (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM 371785144@qq.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Key Area R&D Program of Guangdong Province [2018B030338001,
   2018B0101150-02, 2018B010107003]; Guangdong Education Depart-ment
   [220413548]; Guangdong University of Technology
FX This work was supported in part by Key Area R&D Program of Guangdong
   Province with grant Nos. 2018B030338001, 2018B0101150-02 and
   2018B010107003, in part by the Guangdong Education Depart-ment, and in
   part by the Guangdong University of Technology under Grant 220413548.
CR [Anonymous], 2016, ARXIV160104568
   [Anonymous], 2016, 2016 23 INT C MECH M
   [Anonymous], 2017, ARXIV170309210
   [Anonymous], 2016, INSTANCE NORMALIZATI
   Artsiom S., 2018, ARXIV180710201
   Cao WP, 2018, NEUROCOMPUTING, V275, P278, DOI 10.1016/j.neucom.2017.08.040
   Champandard AJ, ARXIV160301768
   Chen D., 2017, 2017 IEEE INT C COMP
   Chen DD, 2018, PROC CVPR IEEE, P6654, DOI 10.1109/CVPR.2018.00696
   Chen W, 2016, ADV NEUR IN, V29
   Chen Y., APPL INTELL, V51, P4367
   Chen Y., J AMB INTEL HUM COMP, P1
   Chen Y., 2020, VISUAL COMPUT, P1691
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Cheng MM, 2020, IEEE T IMAGE PROCESS, V29, P909, DOI 10.1109/TIP.2019.2936746
   Deng Yingying, 2021, ABS210514576 CORR
   Dumoulin V, 2016, GUIDE CONVOLUTION AR, DOI DOI 10.48550/ARXIV.1603.07285
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gatys LA, 2017, PROC CVPR IEEE, P3730, DOI 10.1109/CVPR.2017.397
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Huang HZ, 2017, PROC CVPR IEEE, P7044, DOI 10.1109/CVPR.2017.745
   [黄华 HUANG Hua], 2011, [计算机科学, Computer Science], V38, P1
   Jing YC, 2020, IEEE T VIS COMPUT GR, V26, P3365, DOI 10.1109/TVCG.2019.2921336
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Li C., 2016, 2016 IEEE C COMPUTER
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li W., 2019, EVOLVEMENT CONSTRAIN
   Li YJ, 2017, ADV NEUR IN, V30
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu D., 2018, STYLE TRANSFER CONTE, P783
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu X.C., 2017, Proceedings of the Symposium on Non-Photorealistic Animation and Rendering, page, P1
   Liu YJ, 2019, IEEE ACCESS, V7, P40027, DOI 10.1109/ACCESS.2019.2891576
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Sheng L, 2018, PROC CVPR IEEE, P8242, DOI 10.1109/CVPR.2018.00860
   Tanno R, 2017, LECT NOTES COMPUT SC, V10133, P446, DOI 10.1007/978-3-319-51814-5_39
   Wang XZ, 2018, SOFT COMPUT, V22, P3473, DOI 10.1007/s00500-018-3203-0
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu K, 2021, IEEE T IMAGE PROCESS, V30, P2501, DOI 10.1109/TIP.2021.3052709
   Zhang H, 2019, LECT NOTES COMPUT SC, V11132, P349, DOI 10.1007/978-3-030-11018-5_32
   Zhao B., 2019, ABS190410709 CORR
   Zhizhong Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7786, DOI 10.1109/CVPR42600.2020.00781
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 45
TC 6
Z9 6
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103378
DI 10.1016/j.jvcir.2021.103378
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0Z2GF
UT WOS:000790895000001
DA 2024-07-18
ER

PT J
AU Liu, BN
   Zhao, Y
   Jiang, XM
   Wang, SG
   Wei, J
AF Liu, Boning
   Zhao, Yan
   Jiang, Xiaomeng
   Wang, Shigang
   Wei, Jian
TI 3-D Epanechnikov Mixture Regression in integral imaging compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3-D Epanechnikov Kernel; 3-D Epanechnikov Mixture Regression; 3D
   holoscopic image compression; Integral imaging compression; Image
   modeling
ID HEVC
AB Integral imaging is a kind of 3D display with no glasses, which represents the future developments. Elementary image array (EIA) is an essential component of integral imaging. Our coding framework includes pre -processing, modeling, and reconstruction. We acquire the sub-EIA from the original EIA and get the offsets between adjacent elementary images (EIs) through pre-processing. As for modeling, we get the optimal combination of 3-D Epanechnikov Mixture Regression (3-D EMR) or 3-D Gaussian Mixture Regression (3-D GMR) by Elementary Image Adaptive Model Selection (EI-AMLS) algorithm to achieve the best modeling of sub-EIA. Finally, the linear-based reconstruction is completed according to the correlation between adjacent EIs. Our decoded images realize a clearer outline reconstruction and more superior coding efficiency than HEVC and JPEG2000 below about 0.05bpp. Furthermore, the proposed method can achieve the same visual effect as HEVC with only 15% to 80% time consumed.
C1 [Liu, Boning; Zhao, Yan; Wang, Shigang; Wei, Jian] Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.
   [Jiang, Xiaomeng] Jilin Univ, Coll Math, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Zhao, Y (corresponding author), Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.
EM liuboning_jlu@sina.com; zhao_y@jlu.edu.cn; jxmlucy@sina.com;
   wangshigang@vip.sina.com; weijian@jlu.edu.cn
RI Liu, Boning/AAK-7643-2021; wang, shigang/F-3718-2011; Zhao,
   Yan/AAF-8988-2019; Xiaomeng, Jiang/AAM-3015-2020
OI Liu, Boning/0000-0002-3014-6049; 
CR Belhi A, 2019, SIGNAL PROCESS-IMAGE, V75, P188, DOI 10.1016/j.image.2019.04.005
   Chen J, 2020, IEEE T SYST MAN CY-S, V50, P2198, DOI 10.1109/TSMC.2018.2810277
   Conti C, 2020, IEEE ACCESS, V8, P49244, DOI 10.1109/ACCESS.2020.2977767
   Conti C, 2016, SIGNAL PROCESS-IMAGE, V42, P59, DOI 10.1016/j.image.2016.01.008
   Cuevas E, 2021, APPL MATH MODEL, V90, P742, DOI 10.1016/j.apm.2020.09.008
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fernández-Duque B, 2019, STOCH ENV RES RISK A, V33, P915, DOI 10.1007/s00477-019-01655-5
   Georgiev T., 2013, T GEORGIEV GALLERY L
   Hosseini S, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P325, DOI 10.1109/SPIN.2017.8049968
   Kubo Yuki, 2020, 2020 IEEE 2nd Global Conference on Life Sciences and Technologies (LifeTech), P5, DOI 10.1109/LifeTech48969.2020.1570619195
   Liu BN, 2021, SIGNAL PROCESS, V185, DOI 10.1016/j.sigpro.2021.108090
   Liu BN, 2019, INT CONF ACOUST SPEE, P1807, DOI 10.1109/ICASSP.2019.8682374
   Liu DY, 2020, IEEE T MULTIMEDIA, V22, P846, DOI 10.1109/TMM.2019.2934426
   Liu DY, 2016, SIGNAL PROCESS-IMAGE, V47, P438, DOI 10.1016/j.image.2016.08.004
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Santos JM, 2020, IEEE I C VI COM I PR, P112, DOI 10.1109/vcip49819.2020.9301829
   Verhack R., 2019, IEEE T MULTIMED, P1
   Verhack R, 2017, IEEE INT CON MULTI, P1183, DOI 10.1109/ICME.2017.8019442
   Verhack R, 2016, IEEE IMAGE PROC, P2142, DOI 10.1109/ICIP.2016.7532737
   Wang YL, 2020, IEEE T COMPUT IMAG, V6, P830, DOI 10.1109/TCI.2020.2986092
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Yuksel SE, 2012, IEEE T NEUR NET LEAR, V23, P1177, DOI 10.1109/TNNLS.2012.2200299
   Zhang M, 2013, INT C WAVEL ANAL PAT, P128, DOI 10.1109/ICWAPR.2013.6599304
NR 24
TC 0
Z9 0
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103332
DI 10.1016/j.jvcir.2021.103332
EA OCT 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7HN
UT WOS:000709894700002
DA 2024-07-18
ER

PT J
AU Wang, XF
   Zhang, Q
   Jiang, CT
   Xue, JR
AF Wang, Xiaofeng
   Zhang, Qian
   Jiang, Chuntao
   Xue, Jianru
TI Perceptual hash-based coarse-to-fine grained image tampering forensics
   method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Perceptual image hash; Simple linear iterative clustering; Image forging
   detection; Image tempering localization
ID DIGITAL SIGNATURE; RING PARTITION; ROBUST HASH; AUTHENTICATION; SECURE
AB As an active forensic technology, perceptual image hash has important application in image content authenticity detection and integrity authentication. In this paper, we propose a hybrid-feature-based perceptual image hash method that can be used for image tampering detection and tampering localization. In the proposed method, we use the color features of image as global features, use point-based features and block-based features as local features, and combine with the structural features to generate intermediate hash code. Then we encrypt and randomize to generate the final hash code. Using this hash code, we present a coarse-to-fine grained forensics method for image tampering detection. The proposed method can realize object-level tampering localization. Abundant experimental results show that the proposed method is sensitive to content changes caused by malicious attacks, and the tampering localization precision achieves pixel level, and it is robust to a wide range of geometric distortions and content-preserving manipulations. Compared with the state-of-the-art schemes, the proposed scheme yields superior performance.
C1 [Wang, Xiaofeng; Zhang, Qian; Jiang, Chuntao] Xian Univ Technol, Xian 710048, Shaanxi, Peoples R China.
   [Xue, Jianru] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an University of Technology; Xi'an Jiaotong University
RP Wang, XF (corresponding author), Xian Univ Technol, Xian 710048, Shaanxi, Peoples R China.
EM xfwang66@sina.com.cn
FU National Natural Science Foundation of China [61772416]; National Major
   Research and Development Plan Program of China [2016YFB1001004]; Key
   Laboratory Project of the Education Department of Shaanxi Province
   [17JS098]; Shaanxi province technology innovation guiding project
FX This work was supported by the National Natural Science Foundation of
   China under Grant No.61772416; the National Major Research and
   Development Plan Program of China under Grant No.2016YFB1001004; the Key
   Laboratory Project of the Education Department of Shaanxi Province under
   Grant No.17JS098; Shaanxi province technology innovation guiding
   project, No.2018XNCG-G-02.
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Davarzani R, 2016, MULTIMED TOOLS APPL, V75, P4639, DOI 10.1007/s11042-015-2496-6
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Gorisse D, 2012, IEEE T PATTERN ANAL, V34, P402, DOI 10.1109/TPAMI.2011.193
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Khavare SA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P289, DOI 10.1109/INFOP.2015.7489395
   Khelifi F, 2010, IEEE T IMAGE PROCESS, V19, P981, DOI 10.1109/TIP.2009.2038637
   L'ecuyer P, 1999, MATH COMPUT, V68, P249, DOI 10.1090/S0025-5718-99-00996-5
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lu W., 2010, P MEDIA FORENSICS SE, VI, P18
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Nason Guy P, 1995, Wavelets and Statistics, P281, DOI [DOI 10.1007/978-1-4612-2544-7_17, 10.1007/978-1-4612-2544-7_17]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pun CM, 2018, MULTIMED TOOLS APPL, V77, P11609, DOI 10.1007/s11042-017-4809-4
   Pun CM, 2017, IEEE T INF FOREN SEC, V12, P377, DOI 10.1109/TIFS.2016.2615272
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sumalatha L., 2012, International Journal of Image, Graphics and Signal Processing, V4, P30, DOI 10.5815/ijigsp.2012.09.05
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Tang Zhenjun., 2008, Journal of ubiquitous convergence technology, V2, P18, DOI DOI 10.1109/INF0P.2015.7489395
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Yan C.P., 2016, IEEE T INF FORENSICS, V11
   Yan C.P., 2017, IEEE T INF FORENSICS, V12
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Zhang YD, 2007, J COMPUT SCI TECH-CH, V22, P618, DOI 10.1007/s11390-007-9079-6
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
NR 31
TC 5
Z9 5
U1 2
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103124
DI 10.1016/j.jvcir.2021.103124
EA MAY 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1MD
UT WOS:000674618200003
DA 2024-07-18
ER

PT J
AU Wang, F
   Peng, GH
AF Wang, Fan
   Peng, Guohua
TI Saliency detection via coarse-to-fine diffusion-based compactness with
   weighted learning affinity matrix
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Diffusion-based compactness; Multi-view graphs;
   Weighted learning affinity matrix
ID OBJECT DETECTION; REGION DETECTION
AB Diffusion-based compactness is an effective method for foreground-based saliency detection, in which one key is the conventional graph construction. However, the conventional graph only displays the local structure but not preserves global relevance information. Therefore, diffusion-based compactness cannot highlight complete salient object which contains multiple areas with different features, and the extracted salient regions with weak homogeneous. Aiming to address these problems, we propose a saliency detection method via coarse-to-fine diffusion-based compactness with a weighted learning affinity matrix. Firstly, we construct multi-view conventional graphs to calculate the rough compactness cue. Secondly, we build a two-stage multi view weighted graphs using a weighted learning affinity matrix and compute the coarse-to-fine compactness cue. Extensive experiments tested on three benchmark datasets, demonstrating the superior against several state-of-the-art methods.
C1 [Wang, Fan; Peng, Guohua] Northwestern Polytech Univ, Sch Math & Stat, Xian, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Wang, F (corresponding author), Northwestern Polytech Univ, Sch Math & Stat, Xian, Shaanxi, Peoples R China.
EM wf03126666@mail.nwpu.edu.cn
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2013, IEEE ICC
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CLZ, 2018, IEEE T MULTIMEDIA, V20, P3324, DOI 10.1109/TMM.2018.2839523
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen CLZ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2403232
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Cong RM, 2019, IEEE T MULTIMEDIA, V21, P1660, DOI 10.1109/TMM.2018.2884481
   Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Cong RM, 2019, IEEE T CYBERNETICS, V49, P233, DOI 10.1109/TCYB.2017.2771488
   Du H., 2014, LECT NOTES ELECT ENG, V309, P397, DOI [10.1007/978-3-642-55038-6_61, DOI 10.1007/978-3-642-55038-6_61]
   Duan L., 2012, J COMPUTAT THEORETIC, V6, P385
   Elder J, 2010, DESIGN PERCEPTUAL VA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fu KR, 2018, NEUROCOMPUTING, V275, P788, DOI 10.1016/j.neucom.2017.09.028
   Gao HC, 2015, IEEE I CONF COMP VIS, P4238, DOI 10.1109/ICCV.2015.482
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Lan RS, 2016, IEEE T IMAGE PROCESS, V25, P566, DOI 10.1109/TIP.2015.2507404
   Lee CY, 2012, SIGNAL PROCESS, V92, P1, DOI 10.1016/j.sigpro.2011.04.026
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li CY, 2019, IEEE T GEOSCI REMOTE, V57, P9156, DOI 10.1109/TGRS.2019.2925070
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li W., 2018, KNOWL-BASED SYST, V145
   Li YX, 2020, IEEE T MULTIMEDIA, V22, P1153, DOI 10.1109/TMM.2019.2940851
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu W, 2015, NEUROCOMPUTING, V152
   Ma GX, 2020, IEEE T MULTIMEDIA, V22, P324, DOI 10.1109/TMM.2019.2929943
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Peng G, MULTIMEDIA TOOLS APP
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tang-You Chang, 2016, 2016 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P1, DOI 10.1109/ICCE-TW.2016.7520976
   Tian J, 2018, NEUROCOMPUTING, V312
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang J, 2015, IEEE T IMAGE PROCESS, V25
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xiao Y, 2019, NEUROCOMPUTING, V351, P156, DOI 10.1016/j.neucom.2019.03.066
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang J, 2015, NEUROCOMPUTING, V175
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Yang Z., 2019, J VIS COMMUN IMAGE R
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang M, 2018, J VIS COMMUN IMAGE R, V52, P131, DOI 10.1016/j.jvcir.2018.01.004
   Zhang YY, 2020, IEEE T IMAGE PROCESS, V29, P1536, DOI 10.1109/TIP.2019.2942796
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zheng N, 2016, INT J COMPUT VISION, V123
   Zheng Q, 2020, NEUROCOMPUTING, V376, P232, DOI 10.1016/j.neucom.2019.08.091
   Zhou L, 2017, IEEE T IMAGE PROCESS, V26, P5882, DOI 10.1109/TIP.2017.2738839
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 66
TC 1
Z9 1
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103151
DI 10.1016/j.jvcir.2021.103151
EA MAY 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200004
DA 2024-07-18
ER

PT J
AU Ning, LY
   Wang, AH
   Zhao, LJ
   Xue, WM
   Bu, DH
AF Ning, Luyao
   Wang, Anhong
   Zhao, Lijun
   Xue, Weimin
   Bu, Donghan
TI MRANet: Multi-atrous residual attention Network for stereo image
   super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo cameras; Stereo image super-resolution; Discriminative ability;
   Parallax extraction; Attention mechanism
AB In recent years, stereo cameras have been widely used in various fields. Due to the limited resolution of real equipments, stereo image super-resolution (SR) is a very important and hot topic. Recent studies have shown that deep network structures can directly affect feature expression and extraction and thus influence the final results. In this paper, we propose a multi-atrous residual attention stereo super-resolution network (MRANet) with parallax extraction and strong discriminative ability. Specifically, we propose a multi-scale atrous residual attention (MARA) block to obtain receptive fields of different scales through a multi-scale atrous convolution and then combine them with attention mechanisms to extract more diverse and meaningful information. Moreover, we propose a stereo feature fusion unit for stereo parallax extraction and single viewpoint feature refinement and integration. Experiments on benchmark datasets show that MRANet achieves state-of-the-art performance in terms of quantitative metrics and visual quality compared with several SR methods.
C1 [Ning, Luyao; Wang, Anhong; Zhao, Lijun; Xue, Weimin; Bu, Donghan] Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
C3 Taiyuan University of Science & Technology
RP Wang, AH (corresponding author), Taiyuan Univ Sci & Technol, Sch Elect Informat Engn, 66 Waliu Rd, Taiyuan 030024, Peoples R China.
EM 951429812@qq.com; wah_ty@163.com; zlj_ty@163.com; xue.weimin@qq.com;
   budonghan@qq.com
RI Zhao, Lijun/S-7237-2019
OI Zhao, Lijun/0000-0002-2305-1914
FU National Natural Science Foundation of China [62072325]; Shanxi ST Major
   Project [20191102010]; Shanxi University S&T Achievements Transformation
   Cultivation Project [20191042]; Shanxi S&T Achievements Transformation
   Project [201804D131035]; Shanxi Key Core Technology & Common Technology
   Research and Development Project [20201102011]; Shanxi S&T Innovation
   Team [201705D131025]; Funding Awards for Outstanding Doctors
   Volunteering to Work in Shanxi Province [20192055]; Shanxi "1331
   Project" Key Innovation Research Team; Shanxi Collaborative Innovation
   Center of Internet+3D Printing; Doctoral Scientific Research Starting
   Foundation of Taiyuan University of Science and Technology [20192023]
FX This work has been supported in part by National Natural Science
   Foundation of China (62072325) , Shanxi S&T Major Project (20191102010)
   , Shanxi University S&T Achievements Transformation Cultivation Project
   (20191042) , Shanxi S&T Achievements Transformation Project
   (201804D131035) , Shanxi Key Core Technology & Common Technology
   Research and Development Project (20201102011) , Shanxi S&T Innovation
   Team (201705D131025) , Shanxi "1331 Project" Key Innovation Research
   Team, Shanxi Collaborative Innovation Center of Internet+3D Printing,
   Doctoral Scientific Research Starting Foundation of Taiyuan University
   of Science and Technology (No. 20192023) , and Funding Awards for
   Outstanding Doctors Volunteering to Work in Shanxi Province (No.
   20192055)
CR Ahuja N., 2006, 2006 IEEE COMPUTER S, V2, P2316
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2008, P 2008 19 INT C PATT
   Bhavsar AV, 2010, LECT NOTES COMPUT SC, V6376, P172
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Garcia DC, 2012, IEEE T CIRC SYST VID, V22, P1249, DOI 10.1109/TCSVT.2012.2198134
   Hu Z, 2014, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2014.370
   Jeon DS, 2018, PROC CVPR IEEE, P1721, DOI 10.1109/CVPR.2018.00185
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Kim J., 2016, CVPR, P1646, DOI DOI 10.1109/CVPR.2016.181
   Li F., 2019, IEEE T CIRC SYST VID
   Li Q., 2019, ARXIV PREPRINT ARXIV
   Liao RJ, 2015, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2015.68
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2014, IEEE T PATTERN ANAL, V36, P346, DOI 10.1109/TPAMI.2013.127
   Ma C., 2020, PROC IEEECVF C CONTP, P7769
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017
   Yang J, 2008, PROC CVPR IEEE, P173
   Yu J., 2018, ARXIV PREPRINT ARXIV
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 43
TC 3
Z9 3
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103115
DI 10.1016/j.jvcir.2021.103115
EA APR 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700014
DA 2024-07-18
ER

PT J
AU Zalik, B
   Mongus, D
   Zalik, KR
   Podgorelec, D
   Lukac, N
AF Zalik, Borut
   Mongus, Domen
   Zalik, Krista Rizman
   Podgorelec, David
   Lukac, Niko
TI Lossless chain code compression with an improved Binary Adaptive
   Sequential Coding of zero-runs?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lossless data compression; Run-Length Encoding; Integer coding; Golomb
   coding
AB A new method for encoding a sequence of integers, named Binary Adaptive Sequential Coding with Return to Bias, is proposed in this paper. It extends the compressing pipeline for chain codes? compression consisting of Burrows Wheeler Transform, Move-To-Front Transform, and Adaptive Arithmetic Coding. We also explain when to include the Zero-Run Transform into the above-mentioned pipeline. The Zero-Run Transform generates a sequence of integers corresponding to the number of zero-runs. This sequence is encoded by Golomb coding, Binary Adaptive Sequential Coding, and the new Binary Adaptive Sequential Coding with Return to Bias. Finally, a comparison is performed with the two state-of-the-art methods. The proposed method achieved similar compression efficiency for the Freeman chain code in eight directions. However, for the chain codes with shorter alphabets (Freeman chain code in four directions, Vertex Chain Code, and Three-OrThogonal chain code), the introduced method outperforms the referenced ones.
C1 [Zalik, Borut; Mongus, Domen; Zalik, Krista Rizman; Podgorelec, David; Lukac, Niko] Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, SI-2000 Maribor, Slovenia.
C3 University of Maribor
RP Zalik, B (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, SI-2000 Maribor, Slovenia.
EM borut.zalik@um.si
RI ; Lukac, Niko/B-7524-2014
OI Zalik, Borut/0000-0003-4372-5020; Lukac, Niko/0000-0002-9517-1157;
   Podgorelec, David/0000-0002-0701-9201
FU Slovenian Research Agency [P2-0041, J2-8176]
FX The authors acknowledge the financial support from the Slovenian
   Research Agency (Research Core Funding No. P2-0041, as well as Research
   Project No. J2-8176).
CR Abel J, 2010, SOFTWARE PRACT EXPER, V40, P751, DOI 10.1002/spe.982
   Adjeroh A., 2008, BURROWS WHEELER TRAN
   Akimov A, 2007, PATTERN RECOGN, V40, P944, DOI 10.1016/j.patcog.2006.08.005
   Albers S, 1998, LECT NOTES COMPUT SC, V1442, P13, DOI 10.1007/BFb0029563
   Bodden E., 2007, TECH REP
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   Burrows Michael, 1994, P DIG SRC RES REP CI
   Dunkelberger K., 1985, P IEEE INT C ROB AUT, V2, P22
   Fano R.M, 1949, TECH REP NO 65
   FENWICK PM, 1994, SOFTWARE PRACT EXPER, V24, P327, DOI 10.1002/spe.4380240306
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Ganster H., 1995, Theory and Applications of Image Analysis II. Selected Paper from the 9th Scandinavian Conference on Image Analysis, P343
   Globacnik T, 2010, PATTERN RECOGN, V43, P4137, DOI 10.1016/j.patcog.2010.07.018
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Howard P. G., 1993, DCC '93. Data Compression Conference (Cat. No.93TH0536-3), P351, DOI 10.1109/DCC.1993.253114
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Jain J., 2012, ADV COMPUTER SCI INF, P611
   Jeromel A, 2020, MULTIMED TOOLS APPL, V79, P433, DOI 10.1007/s11042-019-08126-7
   Kabir Sohag, 2015, International Journal of Image, Graphics and Signal Processing, V7, P11, DOI 10.5815/ijigsp.2015.10.02
   Kärkkäinen J, 2006, J ACM, V53, P918, DOI 10.1145/1217856.1217858
   Kiely A, 2004, IPNPROGRESS REPORT 4
   Kulla F, 2007, PARALLEL COMPUT, V33, P605, DOI 10.1016/j.parco.2007.06.004
   LANGDON GG, 1982, IEEE T INFORM THEORY, V28, P800, DOI 10.1109/TIT.1982.1056559
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Liu YK, 2012, SIGNAL PROCESS-IMAGE, V27, P973, DOI 10.1016/j.image.2012.07.008
   LU CC, 1991, IEEE T COMMUN, V39, P1511, DOI 10.1109/26.103046
   Moffat A, 2005, INFORM PROCESS MANAG, V41, P1175, DOI 10.1016/j.ipm.2004.08.009
   Moffat A, 2000, INFORM RETRIEVAL, V3, P25, DOI 10.1023/A:1013002601898
   Moffat A, 2006, INFORM PROCESS LETT, V99, P175, DOI 10.1016/j.ipl.2006.04.014
   Nong G, 2011, IEEE T COMPUT, V60, P1471, DOI 10.1109/TC.2010.188
   Nunes P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P114, DOI 10.1109/ICIP.1997.632008
   Nunes P, 2000, SIGNAL PROCESS-IMAGE, V15, P585, DOI 10.1016/S0923-5965(99)00041-7
   RISSANEN J, 1983, IEEE T INFORM THEORY, V29, P656, DOI 10.1109/TIT.1983.1056741
   Ryabko B. Ya., 1980, Problems of Information Transmission, V16, P265
   Salomon D., 2010, HANDOOK DATA COMPRES
   Sánchez-Cruz H, 2005, OPT ENG, V44, DOI 10.1117/1.2052793
   Seward J., 2000, CISC VIS NETW IND GL
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Weinberger M.J., 1999, TECH REP HPL 1999 3
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Zalik B, 2019, COMPUT ELECTR ENG, V77, P27, DOI 10.1016/j.compeleceng.2019.05.001
   Zalik B, 2018, INFORM SCIENCES, V439, P39, DOI 10.1016/j.ins.2018.01.045
   Zalik B, 2016, J VIS COMMUN IMAGE R, V38, P186, DOI 10.1016/j.jvcir.2016.03.001
   Zalik B, 2016, DIGIT SIGNAL PROCESS, V53, P1, DOI 10.1016/j.dsp.2016.03.002
   Zalik B, 2015, J VIS COMMUN IMAGE R, V29, P8, DOI 10.1016/j.jvcir.2015.01.013
   Zalik B, 2014, SIGNAL PROCESS-IMAGE, V29, P96, DOI 10.1016/j.image.2013.09.002
NR 48
TC 0
Z9 0
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103050
DI 10.1016/j.jvcir.2021.103050
EA FEB 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600003
OA hybrid
DA 2024-07-18
ER

PT J
AU Sun, H
   Ning, GH
   Zhao, ZQ
   Huang, ZC
   He, ZH
AF Sun, Hao
   Ning, Guanghan
   Zhao, Zhiqun
   Huang, Zhongchao
   He, Zhihai
TI Automated work efficiency analysis for smart manufacturing using human
   pose tracking and temporal action localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Smart manufacturing; Deep learning; Human pose estimation; Dynamic time
   warping; Temporal activity localization; Generative adversarial networks
AB In this paper, we aim to develop an automatic system to monitor and evaluate worker's efficiency for smart manufacturing based on human pose tracking and temporal action localization. First, we explore the generative adversarial networks (GANs) to achieve significantly improved estimation of human body joints. Second, we formulate the automated worker efficiency analysis into a temporal action localization problem in which the action video performed by the worker is matched against a reference video performed by a teacher. We extract invariant spatio-temporal features from the human body pose sequences and perform cross-video matching using dynamic time warping. Our proposed human pose estimation method achieves state-of-the-art performance on the benchmark dataset. Our automated work efficiency analysis is able to achieve action localization with an average IoU (intersection over union) score large than 0.9. This represents one of the first systems to provide automated worker efficiency evaluation.
C1 [Sun, Hao; Ning, Guanghan; Zhao, Zhiqun; He, Zhihai] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
   [Huang, Zhongchao] Cent South Univ, Dept Biomed Engn, Sch Basic Med Sci, Changsha, Hunan, Peoples R China.
C3 University of Missouri System; University of Missouri Columbia; Central
   South University
RP Huang, ZC (corresponding author), Cent South Univ, Dept Biomed Engn, Sch Basic Med Sci, Changsha, Hunan, Peoples R China.
EM bme_hzc@csu.edu.cn
RI sun, hao/GRS-7732-2022; sun, hao/HMD-2991-2023; Sun,
   Haoyang/KHD-3534-2024
FU National Science Foundation [CMMI-1646065]
FX This research work is supported by the National Science Foundation grant
   CMMI-1646065. Any opinions, findings, and conclusions or recommendations
   expressed in this material are those of the authors and do not
   necessarily reflect the views of the National Science Foundation.
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   [Anonymous], 2014, P ADV NEUR INF PROC
   Belagiannis V., 2016, CoRR
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Chen X., 2014, Advances in neural information processing systems, P1736, DOI DOI 10.1109/CVPR.2018.00742
   Chen Y., 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.137
   Chen YC, 2020, COMPUT VIS IMAGE UND, V192, DOI 10.1016/j.cviu.2019.102897
   Cheng A., 2008, COMP VIS PATT REC 20, P1
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M., 2010, BMVC, V2, P5
   Fu LR, 2017, IEEE T IMAGE PROCESS, V26, P927, DOI 10.1109/TIP.2016.2639441
   Gkioxari G, 2016, LECT NOTES COMPUT SC, V9908, P728, DOI 10.1007/978-3-319-46493-0_44
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jeschke S, 2017, SP SER WIRELESS TECH, P3, DOI 10.1007/978-3-319-42559-7_1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Karaman S, 2014, ECCV THUMOS Workshop, V1, P5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lifshitz I, 2016, LECT NOTES COMPUT SC, V9906, P246, DOI 10.1007/978-3-319-46475-6_16
   Luvizon DC, 2019, COMPUT GRAPH-UK, V85, P15, DOI 10.1016/j.cag.2019.09.002
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Nibali A., 2018, CORR
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Rafi U., 2016, BMVC
   Simonyan K, 2014, ADV NEUR IN, V27
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang W, 2019, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2019.00120
   Tang Z., 2018, ARXIV PREPRINT ARXIV
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   van Gemert Jan C., 2015, BMVC, V2, P4
   Walker J, 2017, IEEE I CONF COMP VIS, P3352, DOI 10.1109/ICCV.2017.361
   Wang LC, 2018, AAAI CONF ARTIF INTE, P4195
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang Sen, 2019, ARXIV190907068
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Zhang F, 2019, PROC CVPR IEEE, P3512, DOI 10.1109/CVPR.2019.00363
   Zhang Yan., 2018, BMVC, P269
NR 48
TC 4
Z9 4
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102948
DI 10.1016/j.jvcir.2020.102948
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000001
OA Bronze
DA 2024-07-18
ER

PT J
AU Liao, JW
   Qi, C
   Cao, JZ
   Ren, L
   Zhang, GP
AF Liao, Jiawen
   Qi, Chun
   Cao, Jianzhong
   Ren, Long
   Zhang, Gaopeng
TI Real-time long-term tracker with
   tracking-verification-detection-refinement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Correlation filter; Occlusion; Long-term; Detector; Real-time
ID OBJECT TRACKING; ROBUST TRACKING; GRADIENTS
AB Long-term tracking is one of the most challenging problems in computer vision. In this paper, we make full use of the Discriminative Correlation Filter (DCF), and propose a real-time long-term tracker by exploiting a joint tracking-verification-detection-refinement framework. We utilize a DCF which is updated aggressively to estimate translation and scale variation of the target. Subsequently, a passively updated DCF checks the reliability of the tracking result. Once the result is not reliable, we evoke the proposed optimized candidate detector to generate a small number of relatively high quality candidates. Finally, one DCF with an adaptive online learning rate is adopted to refine the predictions that the sparse candidates inferred. In addition, we employ a selection mechanism for the correlation responses to maintain reliable samples effectively. Extensive experiments show that the proposed method performs favorably against lots of state-of-the-art methods while running more than 30 frames per second on single CPU.
C1 [Liao, Jiawen; Cao, Jianzhong; Ren, Long; Zhang, Gaopeng] Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.
   [Liao, Jiawen; Qi, Chun; Ren, Long] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Liao, Jiawen; Ren, Long] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Xi'an Institute of Optics & Precision
   Mechanics, CAS; Xi'an Jiaotong University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS
RP Liao, JW (corresponding author), Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.; Qi, C (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM liojiawen@stu.xjtu.edu.cn; qichun@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61572395, 61675161,
   51905529]; Shaanxi province natural science basic research program
   [2019JQ-295]
FX This work was supported in part by the National Natural Science
   Foundation of China [61572395, 61675161, 51905529]; and in part by
   Shaanxi province natural science basic research program [2019JQ-295].
CR [Anonymous], 2015, CORR
   [Anonymous], 2018, CORR
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gan W., 2016, SIGNAL PROCESS IMAGE, V47
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54
   Li D., 2018, J VIS COMMUN IMAGE R, V58
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang NX, 2018, IEEE T MULTIMEDIA, V20, P2289, DOI 10.1109/TMM.2018.2803518
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu C, 2018, IEEE T MULTIMEDIA, V20, P889, DOI 10.1109/TMM.2017.2760633
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nebehay G, 2015, PROC CVPR IEEE, P2784, DOI 10.1109/CVPR.2015.7298895
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Sun C, 2018, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2018.00058
   Sun X, 2015, IEEE T IMAGE PROCESS, V24, P3386, DOI 10.1109/TIP.2015.2447213
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang N, 2019, IEEE T CIRC SYST VID, V29, P730, DOI 10.1109/TCSVT.2018.2816570
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang XQ, 2015, INT J COMPUT VISION, V115, P279, DOI 10.1007/s11263-015-0819-8
   Zhang ZM, 2018, IEEE T PATTERN ANAL, V40, P1209, DOI 10.1109/TPAMI.2017.2707492
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 49
TC 2
Z9 2
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102896
DI 10.1016/j.jvcir.2020.102896
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400012
DA 2024-07-18
ER

PT J
AU de Sousa, DJ
   Cardoso, MA
   Bisch, PM
   Lopes, FJP
   Travençolo, BAN
AF de Sousa, Daniela Justiniano
   Cardoso, Maira Arruda
   Bisch, Paulo Mascarello
   Pereira Lopes, Francisco Jose
   Nassif Travencolo, Bruno Augusto
TI Automated standardization of images of <i>Drosophila</i> embryos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Embryo standardization; Anterior-posterior orientation; Dorsal-ventral
   orientation; Automatic embryo positioning; Drosophila
ID GENE-EXPRESSION PATTERNS; SEGMENTATION; MELANOGASTER; FLY; ANNOTATION;
   EXTRACTION; STABILITY; DYNAMICS; DISEASE
AB Modeling expression patterns of Drosophila, in space and time, plays a critical role to understand the development of multicellular organisms. In confocal microscopy, to produce precise quantitative data it is frequently necessary to process and analyze large amounts of digital images. Automatic preprocessing is a crucial step in this scenario, essential to standardize significant features such as orientation, size, position, direction, lighting condition and texture of embryo images. Even though a lot of efforts have been made, a robust embryo standardization strategy is still needed. In this paper, we propose the method Embrystandar. It is designed to remove background artifacts and standardize the direction and orientation of a Drosophila embryo through a sequence of automatic operations. To test its potential for large-scale image processing, Embrystandar was applied in different databases. It showed to be robust and precise, reaching more than 90% success rate. (c) 2020 Elsevier Inc. All rights reserved.
C1 [de Sousa, Daniela Justiniano; Nassif Travencolo, Bruno Augusto] Univ Fed Uberlandia, Fac Comp, Av Joao Naves de Avila 2-121, BR-38400902 Uberlandia, MG, Brazil.
   [Cardoso, Maira Arruda] Univ Fed Rio de Janeiro UFRJ, Inst Ciencias Biomed, Ave Carlos Chagas Filho 373, BR-21941902 Rio De Janeiro, RJ, Brazil.
   [Bisch, Paulo Mascarello] Univ Fed Rio de Janeiro UFRJ, Inst Biofis Carlos Chagas Filho IBCCF, Ave Carlos Chagas Filho 373, BR-21941902 Rio De Janeiro, RJ, Brazil.
   [Pereira Lopes, Francisco Jose] Univ Fed Rio de Janeiro UFRJ, Campus Duque de Caxias Prof Geraldo Cidade, BR-25265970 Duque De Caxias, RJ, Brazil.
C3 Universidade Federal de Uberlandia; Universidade Federal do Rio de
   Janeiro; Universidade Federal do Rio de Janeiro; Universidade Federal do
   Rio de Janeiro
RP Travençolo, BAN (corresponding author), Univ Fed Uberlandia, Fac Comp, Av Joao Naves de Avila 2-121, BR-38400902 Uberlandia, MG, Brazil.
EM travencolo@gmail.com
RI Lopes, Francisco/AAX-9256-2021; Mascarello Bisch, Paulo/GRF-5572-2022;
   Travençolo, Bruno/F-6752-2010; Cardoso, Maira A/R-1601-2017
OI Lopes, Francisco/0000-0002-2715-2341; Travençolo,
   Bruno/0000-0001-7690-301X; Mascarello Bisch, Paulo/0000-0002-3136-3520;
   Justiniano de Sousa, Daniela/0000-0001-9010-0707
FU FAPERJ Fundacao de Amparo a Pesquisa do Estado do Estado do Rio de
   Janeiro [E-26 010.001877/2015]; Fundacao de Amparo a Pesquisa do Estado
   de Minas Gerais - FAPEMIG [APQ-01345-13, REONCO-52-11, APQ-03437-15]
FX The authors would like to thank CAPES - Coordenacao de Aperfeicoamento
   de Pessoal de Nivel Superior; Inmetro - Instituto Nacional de
   Metrologia, Qualidade e Tecnologia; CNPq - Conselho Nacional de
   Desenvolvimento Cientifico e Tecnologico; FAPERJ Fundacao de Amparo a
   Pesquisa do Estado do Estado do Rio de Janeiro [Grant no. E-26
   010.001877/2015]; and Fundacao de Amparo a Pesquisa do Estado de Minas
   Gerais - FAPEMIG [Grant Nos. APQ-01345-13, REONCO-52-11, APQ-03437-15].
CR Auer M, 2007, BMC CELL BIOL, V8, DOI 10.1186/1471-2121-8-S1-S1
   Bagatini PB, 2011, INVERTEBR NEUROSCI, V11, P43, DOI 10.1007/s10158-011-0116-3
   Bessinger Z, 2012, IEEE IMAGE PROC, P497, DOI 10.1109/ICIP.2012.6466905
   Campos-Ortega JA., 1997, EMBRYONIC DEV DROSOP, DOI [10.1007/978-3-662-22489-2, DOI 10.1007/978-3-662-22489-2]
   de Sousa DJ, 2013, WSCG 2013, FULL PAPERS PROCEEDINGS, P133
   Deignan L, 2016, PLOS GENET, V12, DOI 10.1371/journal.pgen.1006164
   Guo F, 2008, PROC VLDB ENDOW, V1, P1508, DOI 10.14778/1454159.1454214
   Fang CF, 2010, 26TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2010), P69
   Ferrero E, 2014, GENOME BIOL, V15, DOI 10.1186/gb-2014-15-5-r74
   Foe V.E., 1993, MITOSIS MORPHOGENESI, P149
   Gargesha M, 2005, PROC SPIE, V5960, P576, DOI 10.1117/12.631575
   Gregor T, 2007, CELL, V130, P153, DOI 10.1016/j.cell.2007.05.025
   Gregor T, 2007, CELL, V130, P141, DOI 10.1016/j.cell.2007.05.026
   He F, 2018, METHODS MOL BIOL, V1863, P19, DOI 10.1007/978-1-4939-8772-6_2
   He F, 2010, BMC DEV BIOL, V10, DOI 10.1186/1471-213X-10-80
   Holloway DM, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1001069
   Jia DY, 2016, SCI REP-UK, V6, DOI 10.1038/srep18850
   Jug F, 2014, METHODS, V68, P60, DOI 10.1016/j.ymeth.2014.04.004
   Karaiskos N, 2017, SCIENCE, V358, P194, DOI 10.1126/science.aan3235
   Kazmar T, 2013, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2013.139
   Konikoff CE, 2012, DEV DYNAM, V241, P150, DOI 10.1002/dvdy.22749
   Kosman D., 1999, P 1998 PAC S BIOC, P6
   Kumar S, 2002, GENETICS, V162, P2037
   Kumar S, 2011, BIOINFORMATICS, V27, P3319, DOI 10.1093/bioinformatics/btr567
   Lai EC, 2003, GENOME BIOL, V4, DOI 10.1186/gb-2003-4-7-r42
   Lecuyer Eric, 2008, V420, P289, DOI 10.1007/978-1-59745-583-1_18
   Lécuyer E, 2007, CELL, V131, P174, DOI 10.1016/j.cell.2007.08.003
   Li Q, 2017, BMC SYST BIOL, V11, DOI 10.1186/s12918-017-0478-1
   Little SC, 2013, CELL, V154, P789, DOI 10.1016/j.cell.2013.07.025
   Little SC, 2011, PLOS BIOL, V9, DOI 10.1371/journal.pbio.1000596
   Lott SE, 2007, P NATL ACAD SCI USA, V104, P10926, DOI 10.1073/pnas.0701359104
   Mace DL, 2010, BIOINFORMATICS, V26, P761, DOI 10.1093/bioinformatics/btp658
   McCorkindale AL, 2019, DEVELOPMENT, V146, DOI 10.1242/dev.175265
   Moulton MJ, 2016, DIS MODEL MECH, V9, P253, DOI 10.1242/dmm.023564
   Myasnikova E, 2001, BIOINFORMATICS, V17, P3, DOI 10.1093/bioinformatics/17.1.3
   Pan Jia-Yu., 2006, KDD 06 P 12 ACM SIGK, P693, DOI [DOI 10.1145/1150402.1150489, 10.1145/1150402.1150489]
   Pandey UB, 2011, PHARMACOL REV, V63, P411, DOI 10.1124/pr.110.003293
   Pende M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07192-z
   Pisarev A, 2009, NUCLEIC ACIDS RES, V37, pD560, DOI 10.1093/nar/gkn717
   Poustelnikova E, 2004, BIOINFORMATICS, V20, P2212, DOI 10.1093/bioinformatics/bth222
   Puah WC, 2017, BIOL OPEN, V6, P390, DOI 10.1242/bio.022079
   Puniyani K, 2010, BIOINFORMATICS, V26, pi47, DOI 10.1093/bioinformatics/btq172
   Reeves GT, 2009, CSH PERSPECT BIOL, V1, DOI 10.1101/cshperspect.a000836
   Reeves GT, 2012, DEV CELL, V22, P544, DOI 10.1016/j.devcel.2011.12.007
   Sousa D.J., 2014, 7 C GRAPH PATT IM SI
   Surkova S, 2008, FLY, V2, P58, DOI 10.4161/fly.6060
   Tomancak P, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-7-r145
   Turner TL, 2011, PLOS GENET, V7, DOI 10.1371/journal.pgen.1001336
   Wu SQ, 2016, P NATL ACAD SCI USA, V113, P4290, DOI 10.1073/pnas.1521171113
   Xing YL, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8058
   Yuan L, 2014, BIOINFORMATICS, V30, P266, DOI 10.1093/bioinformatics/btt648
NR 51
TC 0
Z9 0
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102758
DI 10.1016/j.jvcir.2020.102758
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900003
DA 2024-07-18
ER

PT J
AU Li, HF
   Liu, J
   Cui, L
   Huang, HY
   Tai, XC
AF Li, Haifeng
   Liu, Jun
   Cui, Li
   Huang, Haiyang
   Tai, Xue-Cheng
TI Volume preserving image segmentation with entropy regularized optimal
   transport and its applications in deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; DCNN; Volume preserving; Optimal transport; Entropic
   regularization; TV regularization
ID ALGORITHM
AB Image segmentation with a volume constraint is an important prior for many real applications. In this work, we present a novel volume preserving image segmentation algorithm, which is based on the entropy and Total Variation (TV) regularized optimal transport theory. The volume and classification constraints can be regarded as two measures preserving constraints in the optimal transport. By studying the dual problem, we develop a simple but efficient dual algorithm for our model. Moreover, to be different from many variational based image segmentation algorithms, the proposed algorithm can be directly unrolled to a new Volume Preserving and TV regularized softmax (VPTV-softmax) layer for semantic segmentation in the popular Deep Convolution Neural Network (DCNN). The experiment results show that our proposed model is very competitive and can improve the performance of many semantic segmentation networks such as the popular U-net and DeepLabv3+. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Haifeng; Liu, Jun; Cui, Li; Huang, Haiyang] Beijing Noma Univ, Sch Math Sci, Minist Educ China, Lab Math & Complex Syst, Beijing 100875, Peoples R China.
   [Tai, Xue-Cheng] Hong Kong Baptist Univ, Dept Math, Kowloon Tong, Hong Kong, Peoples R China.
C3 Hong Kong Baptist University
RP Liu, J; Cui, L (corresponding author), Beijing Noma Univ, Sch Math Sci, Minist Educ China, Lab Math & Complex Syst, Beijing 100875, Peoples R China.
EM jliu@bnu.edu.cn; licui@bnu.edu.cn
RI tai, xuecheng/L-9821-2013; Tai, Xue-Cheng/JDV-5122-2023; Liu,
   Jun/GZL-2263-2022
OI tai, xuecheng/0000-0003-3359-9104; Tai, Xue-Cheng/0000-0003-3359-9104; 
FU National Key Research and Development Program of China [2017YFA0604903];
   National Natural Science Foundation of China [11871035]; Hong Kong
   Baptist University [RG(R)-RC/17-18/02-MATH, HKBU 12300819,
   RC-FNRA-IG/19-20/SCI/01]; NSF/RGC [NHKBU214-19]
FX Liu and Huang were partly supported by The National Key Research and
   Development Program of China (No. 2017YFA0604903). Liu was also partly
   supported by The National Natural Science Foundation of China (No.
   11871035). Tai was supported by Hong Kong Baptist University through
   grants RG(R)-RC/17-18/02-MATH, HKBU 12300819, RC-FNRA-IG/19-20/SCI/01
   and NSF/RGC grant NHKBU214-19.
CR [Anonymous], 1989, Journal of Applied statistics, DOI DOI 10.1080/02664768900000049
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Bertsekas D.P., 1979, A distributed algorithm for the assignment problem
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   COMINETTI R, 1994, MATH PROGRAM, V67, P169, DOI 10.1007/BF01582220
   Cuturi M., 2013, ADV NEURAL INFORM PR, P2292, DOI DOI 10.48550/ARXIV.1306.0895
   Cuturi M, 2016, SIAM J IMAGING SCI, V9, P320, DOI 10.1137/15M1032600
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Esedoglu S, 2015, COMMUN PUR APPL MATH, V68, P808, DOI 10.1002/cpa.21527
   FRANKLIN J, 1989, LINEAR ALGEBRA APPL, V114, P717, DOI 10.1016/0024-3795(89)90490-4
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Jacob M, 2018, J COMPUT PHYS, V354, P288, DOI 10.1016/j.jcp.2017.10.036
   Jia F, 2021, ANAL APPL, V19, P147, DOI 10.1142/S0219530519410148
   Liu J, 2013, IEEE T IMAGE PROCESS, V22, P1108, DOI 10.1109/TIP.2012.2227766
   Liu J, 2012, J VIS COMMUN IMAGE R, V23, P1234, DOI 10.1016/j.jvcir.2012.09.002
   Liu J, 2012, LECT NOTES COMPUT SC, V6667, P218, DOI 10.1007/978-3-642-24785-9_19
   Liu J, 2011, PATTERN RECOGN, V44, P2093, DOI 10.1016/j.patcog.2011.02.022
   MERRIMAN B, 1994, J COMPUT PHYS, V112, P334, DOI 10.1006/jcph.1994.1105
   Merriman B., 1992, P GEOM CTR WORKSH
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0
   Papadakis N, 2017, J MATH IMAGING VIS, V59, P161, DOI 10.1007/s10851-017-0725-5
   Permuter H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P569
   Peyré G, 2012, IEEE IMAGE PROC, P2541, DOI 10.1109/ICIP.2012.6467416
   POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419
   Rabin Julien, 2015, Scale Space and Variational Methods in Computer Vision. 5th International Conference, SSVM 2015. Proceedings: LNCS 9087, P256, DOI 10.1007/978-3-319-18461-6_21
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Teboulle M, 2007, J MACH LEARN RES, V8, P65
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang D, 2017, J COMPUT PHYS, V350, P657, DOI 10.1016/j.jcp.2017.08.020
   Yildizoglu Romain, 2013, Energy Minimization Methods in Computer Vision and Pattern Recognition. 9th International Conference, EMMCVPR 2013. Proceedings. LNCS 8081, P335, DOI 10.1007/978-3-642-40395-8_25
   Zheng X, 2018, MICRON, V107, P55, DOI 10.1016/j.micron.2018.01.010
NR 37
TC 5
Z9 5
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102845
DI 10.1016/j.jvcir.2020.102845
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400012
DA 2024-07-18
ER

PT J
AU Peng, XS
   Zhang, XM
   Li, YP
   Liu, BQ
AF Peng, Xushan
   Zhang, Xiaoming
   Li, Yongping
   Liu, Bangquan
TI Research on image feature extraction and retrieval algorithms based on
   convolutional neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; In-depth learning; Feature extraction; Convolutional
   neural network
ID OBJECT DETECTION; SEARCH; AGGREGATION
AB With the rapid development of mobile Internet and digital technology, people are more and more keen to share pictures on social networks, and online pictures have exploded. How to retrieve similar images from large-scale images has always been a hot issue in the field of image retrieval, and the selection of image features largely affects the performance of image retrieval. The Convolutional Neural Networks (CNN), which contains more hidden layers, has more complex network structure and stronger ability of feature learning and expression compared with traditional feature extraction methods. By analyzing the disadvantage that global CNN features cannot effectively describe local details when they act on image retrieval tasks, a strategy of aggregating low-level CNN feature maps to generate local features is proposed. The high-level features of CNN model pay more attention to semantic information, but the low-level features pay more attention to local details. Using the increasingly abstract characteristics of CNN model from low to high. This paper presents a probabilistic semantic retrieval algorithm, proposes a probabilistic semantic hash retrieval method based on CNN, and designs a new end-to-end supervised learning framework, which can simultaneously learn semantic features and hash features to achieve fast image retrieval. Using convolution network, the error rate is reduced to 14.41% in this test set. In three open image libraries, namely Oxford, Holidays and ImageNet, the performance of traditional SIFT-based retrieval algorithms and other CNN-based image retrieval algorithms in tasks are compared and analyzed. The experimental results show that the proposed algorithm is superior to other contrast algorithms in terms of comprehensive retrieval effect and retrieval time. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Peng, Xushan; Zhang, Xiaoming; Li, Yongping; Liu, Bangquan] Ningbo Univ Finance & Econ, Coll Informat Engn, Ningbo 315175, Peoples R China.
C3 Ningbo University of Finance & Economics
RP Peng, XS (corresponding author), Ningbo Univ Finance & Econ, Coll Informat Engn, Ningbo 315175, Peoples R China.
EM dhypengxushan@126.com; 84797272@qq.com; liyoongping@qq.com;
   87859136@qq.com
RI ZHANG, XIAOMING/JCE-4569-2023
OI ZHANG, XIAOMING/0009-0000-3986-885X
FU National Natural Science Foundation of China [51474072]; Zhejiang
   Provincial Natural Science Foundation [LY19F020001]; Ningbo Soft Science
   Projects [2017A10062]
FX The authors gratefully acknowledge the National Natural Science
   Foundation of China (Grant no. 51474072), Zhejiang Provincial Natural
   Science Foundation (Grant no. LY19F020001), Ningbo Soft Science Projects
   (Grant no. 2017A10062).
CR [Anonymous], 2015, COMPUTER SCI
   [Anonymous], J JINGDEZHEN U
   [Anonymous], SPIE SPIE C SERIES
   [Anonymous], INT J COMPUT TECHNOL
   [Anonymous], COMPUT SCI
   [Anonymous], J REM SENS
   [Anonymous], INT J COMPUT APPL
   Bertasius G, 2015, IEEE I CONF COMP VIS, P504, DOI 10.1109/ICCV.2015.65
   Chen C, 2017, COMM COM INF SC, V729, P376, DOI 10.1007/978-981-10-6442-5_34
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Hollink V, 2011, J AM SOC INF SCI TEC, V62, P691, DOI 10.1002/asi.21484
   Hsu YHE, 2014, METHOD INFORM MED, V53, P446, DOI 10.3414/ME14-01-0022
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Karimi N, 2018, J VIS COMMUN IMAGE R, V55, P853, DOI 10.1016/j.jvcir.2018.04.001
   Li A, 2017, PROC CVPR IEEE, P1942, DOI 10.1109/CVPR.2017.210
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1606, DOI 10.1109/TIP.2014.2305072
   Lu D, 2016, IEEE T MULTIMEDIA, V18, P1628, DOI 10.1109/TMM.2016.2568099
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Samet N, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1321, DOI 10.1109/SIU.2016.7495991
   Takarli F, 2016, SIGNAL IMAGE VIDEO P, V10, P93, DOI 10.1007/s11760-014-0706-8
   Tolias G, 2016, INT J COMPUT VISION, V116, P247, DOI 10.1007/s11263-015-0810-4
   Nguyen VA, 2016, IEEE INT CON MULTI
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Xie LX, 2014, COMPUT VIS IMAGE UND, V124, P31, DOI 10.1016/j.cviu.2013.12.011
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Yang W, 2015, IEEE T GEOSCI REMOTE, V53, P4472, DOI 10.1109/TGRS.2015.2400449
NR 30
TC 18
Z9 22
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2020
VL 69
AR 102705
DI 10.1016/j.jvcir.2019.102705
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LZ3UM
UT WOS:000541153600001
DA 2024-07-18
ER

PT J
AU Li, JH
   Yan, HX
   Gao, JB
   Kong, DH
   Wang, LC
   Wang, SF
   Yin, BC
AF Li, Jinghua
   Yan, Huixia
   Gao, Junbin
   Kong, Dehui
   Wang, Lichun
   Wang, Shaofan
   Yin, Baocai
TI Matrix-variate variational auto-encoder with applications to image
   process
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Variational autoencoder; Matrix Gaussian distribution; Variational
   inference; Face completion; Image denoising
AB Variational Auto-Encoder (VAE) is an important probabilistic technology to model 1D vectorial data. However, when applying VAE model to 2D image, vectorization is necessary. Vectorization process may lead to dimension curse and lose valuable spatial information. To avoid these problems, we propose a novel VAE model based on matrix variables named as Matrix-variate Variational Auto-Encoder (MVVAE). In this model, input, hidden and latent variables are all in matrix form, therefore inherent spatial structure of 2D images can be maintained and utilized better. Especially, the latent variable is assumed to follow matrix Gaussian distribution which is more suitable for describing 2D images. To solve the weights and the posterior of latent variable, the variational inference process is given. The experiments are designed for three real-world application: reconstruction, denoising and completion. The experimental results demonstrate that MVVAE shows better performance than VAE and other probabilistic methods for modeling and processing 2D data. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Jinghua; Yan, Huixia; Kong, Dehui; Wang, Lichun; Wang, Shaofan; Yin, Baocai] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
   [Gao, Junbin] Univ Sydney, Univ Sydney Business School, Discipline Business Analyt, Sydney, NSW 2006, Australia.
   [Yin, Baocai] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Peoples R China.
C3 Beijing University of Technology; University of Sydney; Dalian
   University of Technology
RP Li, JH (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Multimedia & Intelligent Software, Beijing, Peoples R China.
EM lijinghua@bjut.edu.cn
RI Gao, Junbin/C-6566-2008; Gao, Junbin/A-1766-2009
OI Gao, Junbin/0000-0001-9803-0256
FU National Science Foundation of China (NSFC) [61632006, 61772049,
   61876012, 61602486]; Beijing Educational Committee [KM20171 0005022];
   Beijing Key Laboratory of Computational Intelligence and Intelligent
   System
FX This work is supported by the National Science Foundation of China
   (NSFC) under Grant No. 61632006, 61772049, 61876012 and 61602486,
   Beijing Educational Committee (KM20171 0005022), and Beijing Key
   Laboratory of Computational Intelligence and Intelligent System.
CR Abbasnejad ME, 2017, PROC CVPR IEEE, P781, DOI 10.1109/CVPR.2017.90
   Burda Yuri, 2015, IMPORTANCE WEIGHTED
   Chen X, 2017, INT C LEARN REPR, P1
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Doersch Carl, 2016, ARXIV160605908
   Gao JB, 2008, NEURAL COMPUT, V20, P555, DOI 10.1162/neco.2007.11-06-397
   Gulrajani I, 2017, INT C LEARN REPR ICL, P1
   GUPTA AK, 1992, J MULTIVARIATE ANAL, V41, P80, DOI 10.1016/0047-259X(92)90058-N
   Gupta Arjun K, 1999, MATRIX VARIATE DISTR, V104
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton Geoffrey E., 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P599, DOI 10.1007/978-3-642-35289-8_32
   Horn R., 1985, Matrix Analysis, DOI [10.1017/CBO9780511810817, 10.1017/CBO9781139020411]
   Hou XX, 2017, IEEE WINT CONF APPL, P1133, DOI 10.1109/WACV.2017.131
   HU X, 2018, 32 AAAI C ART INT
   Im DJ, 2017, AAAI CONF ARTIF INTE, P2059
   Ju FJ, 2015, IEEE T IMAGE PROCESS, V24, P4834, DOI 10.1109/TIP.2015.2469136
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, ARXIV13126114
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Lu ZQ, 2017, IEEE INT CONF ELECTR, P312, DOI 10.1109/ICEIEC.2017.8076570
   LUCAS T., 2018, Joint European Conference on Machine Learning and Knowledge Discovery in Databases, P443
   Paisley J., 2012, P 29 INT C MACH LEAR
   Qi GL, 2016, IEEE IJCNN, P389, DOI 10.1109/IJCNN.2016.7727225
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhao JH, 2012, IEEE T NEUR NET LEAR, V23, P492, DOI 10.1109/TNNLS.2012.2183006
NR 28
TC 2
Z9 2
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102750
DI 10.1016/j.jvcir.2019.102750
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800010
DA 2024-07-18
ER

PT J
AU He, T
   Li, XF
AF He, Tao
   Li, Xiaofeng
TI Image quality recognition technology based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low quality image; Deep learning; Image recognition; Support vector
   machines(SVM)
ID CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; TRACKING; REMOVAL; VIDEO
AB Image plays an important role in today's society and is an important information carrier. However, due to the problems in shooting or processing, image quality is often difficult to be guaranteed, and low-quality images are often difficult to identify, which results in the waste of information. How to effectively identify low-quality images has become a hot research topic in today's society. Deep learning has a good application in image recognition. In this paper, it is applied to low-quality image recognition. An image quality recognition technology based on deep learning is studied to effectively realize low-quality image recognition. Firstly, in the stage of image preprocessing, a low-quality image enhancement method is proposed, which uses non-linear transformation to enhance image contrast image, restore image details and enhance image quality. Secondly, the convolutional neural network is used to extract image features, and the L2 regularization method is introduced to optimize the over-fitting problem. Finally, SVM is used to recognize the output of convolutional neural network to realize low quality image recognition. Through simulation analysis, it is found that the image enhancement method proposed in the preprocessing stage can effectively enhance the image quality, and deep learning can effectively realize the recognition of the enhanced image and improve the recognition accuracy. (C) 2019 Published by Elsevier Inc.
C1 [He, Tao] Shenzhen Inst Informat Technol, Shenzhen, Guangdong, Peoples R China.
   [Li, Xiaofeng] Heilongjiang Int Univ, Dept Informat Engn, Harbin 150025, Heilongjiang, Peoples R China.
C3 Shenzhen Institute of Information Technology; Heilongjiang International
   University
RP Li, XF (corresponding author), Heilongjiang Int Univ, Dept Informat Engn, Harbin 150025, Heilongjiang, Peoples R China.
EM het@sziit.edu.cn; xiaofenglixy@sina.com
RI Li, Xiaofeng/AEO-1188-2022
OI Li, Xiaofeng/0000-0002-8447-9279
FU Shenzhen Science and Technology Program [JCYJ20170306095849825,
   JCYJ20170306095735097]; Cultivation Project of Shenzhen Institute of
   Information Technology [ZY201715]; Ministry of Education Science and
   Technology Development Center Industry-University Research Innovation
   Fund [2018A01002]
FX This work was supported by Shenzhen Science and Technology Program
   (JCYJ20170306095849825, JCYJ20170306095735097), Cultivation Project of
   Shenzhen Institute of Information Technology (ZY201715), Ministry of
   Education Science and Technology Development Center Industry-University
   Research Innovation Fund (No. 2018A01002).
CR Aranda LA, 2017, IEEE T NUCL SCI, V64, P2219, DOI 10.1109/TNS.2017.2666843
   Barrena N, 2018, MACH VISION APPL, V29, P573, DOI 10.1007/s00138-018-0914-2
   Chen W, 2017, BEIJING CONSENSUS?: HOW CHINA HAS CHANGED WESTERN IDEAS OF LAW AND ECONOMIC DEVELOPMENT, P1, DOI 10.1007/s10064-017-1010-y
   dos Santos FP, 2019, J VIS COMMUN IMAGE R, V60, P407, DOI 10.1016/j.jvcir.2019.02.035
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Ham B, 2018, IEEE T PATTERN ANAL, V40, P192, DOI 10.1109/TPAMI.2017.2669034
   Hamker FH, 2004, NEUROCOMPUTING, V56, P329, DOI 10.1016/j.neucom.2003.09.006
   Hayou S., 2018, J FUZHOU U, V1050, P7
   Hou Y, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S021800141850043X
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Jin KH, 2017, IEEE T IMAGE PROCESS, V26, P4509, DOI 10.1109/TIP.2017.2713099
   Kobayashi M, 2018, IEEE T NEUR NET LEAR, V29, P1900, DOI 10.1109/TNNLS.2017.2688322
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li C, 2017, PHOTOGRAMM ENG REM S, V83, P621, DOI 10.14358/PERS.83.9.621
   Liu XP, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418500337
   Liu YH, 2018, IET IMAGE PROCESS, V12, P880, DOI 10.1049/iet-ipr.2017.0171
   Mekata K., 2017, J JPN SOC COMPUT AID, V19, P83
   Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464
   Phan H, 2017, IEEE-ACM T AUDIO SPE, V25, P1278, DOI 10.1109/TASLP.2017.2690564
   Ray KS, 2019, J VIS COMMUN IMAGE R, V58, P662, DOI 10.1016/j.jvcir.2018.12.002
   Roy A, 2017, IET IMAGE PROCESS, V11, P352, DOI 10.1049/iet-ipr.2016.0320
   Shan PF, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0322-6
   Sriman B, 2019, J VIS COMMUN IMAGE R, V62, P23, DOI 10.1016/j.jvcir.2019.04.007
   Tao F, 2017, SOFT COMPUT, V22, P1, DOI DOI 10.1007/s00500-017-2813-2
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   [王治丹 Wang Zhidan], 2017, [电子学报, Acta Electronica Sinica], V45, P704
   Wu DR, 2018, IEEE T FUZZY SYST, V26, P771, DOI 10.1109/TFUZZ.2017.2688423
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Yang D, 2018, IEEE SIGNAL PROC LET, V25, P55, DOI 10.1109/LSP.2017.2768660
   Yang L, 2015, IEEE T SUSTAIN ENERG, V6, P791, DOI 10.1109/TSTE.2015.2406814
   Zhang HK, 2017, REMOTE SENS LETT, V8, P438, DOI 10.1080/2150704X.2017.1280200
   Zhang JF, 2018, J PHASE EQUILIB DIFF, V39, P109, DOI 10.1007/s11669-017-0611-2
   Zhang XB, 2017, ELECTR POW SYST RES, V146, P270, DOI 10.1016/j.epsr.2017.01.035
   Zheng DL, 2017, OPT EXPRESS, V25, P4700, DOI 10.1364/OE.25.004700
NR 37
TC 18
Z9 18
U1 5
U2 80
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102654
DI 10.1016/j.jvcir.2019.102654
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700006
DA 2024-07-18
ER

PT J
AU Liu, JW
   Hu, LQ
   Cai, ZQ
   Xing, LN
   Tan, X
AF Liu, Jiang-Wen
   Hu, Li-Qiang
   Cai, Zhao-Quan
   Xing, Li-Ning
   Tan, Xu
TI Large-scale and adaptive service composition based on deep reinforcement
   learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Service composition; Deep reinforcement learning; QoS; Behavior strategy
AB Service composition is a research hotspot with practical value. With the development of Web service, many Web services with the same functional attributes emerge. However, service composition optimization is still a big challenge since the complex and unstable composition environment. To solve this problem, we propose an adaptive service composition based on deep reinforcement learning, where recurrent neural network (RNN) is utilized for predicting the objective function, improving its expression and generalization ability, and effectively solving the shortcomings of traditional reinforcement learning in the face of large-scale or continuous state space problems. We leverage heuristic behavior selection strategy to divide the state set into hidden state and fully visible state. Effective simulation of hidden state space and fully visible state of the evaluation function can further improve the accuracy and efficiency of the combined results. We conduct comprehensive experiment and experimental results have shown the effectiveness of our method. (C) 2019 Published by Elsevier Inc.
C1 [Liu, Jiang-Wen] Jiangsu Vocat Inst Architectural Technol, Coll Mech & Elect Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Hu, Li-Qiang] Shijiazhuang Tiedao Univ, Sch Elect & Elect Engn, Shijiazhuang 050043, Hebei, Peoples R China.
   [Cai, Zhao-Quan] Huizhou Univ, Dept Informat Sci & Technol, Huizhou 516007, Peoples R China.
   [Xing, Li-Ning; Tan, Xu] Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen 518172, Guangdong, Peoples R China.
C3 Jiangsu Vocational Institute of Architectural Technology; Shijiazhuang
   Tiedao University; Huizhou University; Shenzhen Institute of Information
   Technology
RP Cai, ZQ (corresponding author), Huizhou Univ, Dept Informat Sci & Technol, Huizhou 516007, Peoples R China.; Tan, X (corresponding author), Shenzhen Inst Informat Technol, Sch Software Engn, Shenzhen 518172, Guangdong, Peoples R China.
EM 13502279833@126.com; tanxu_nudt@yahoo.com
RI XING, Lining/GRO-1108-2022
FU National Natural Science Foundation of China [61773120, 61772225];
   scientific project of mining machinery control and parts engineering
   center in Jiangsu province [JYAPT17-05]; Xuzhou science and technology
   project [KH17003]; Youth project of science and Technology of Department
   of Education in Hebei provincial [QN2016237]; National Natural Science
   Foundation of Guangdong [2018B030311046]; Guangdong University Key
   Platforms and Research Projects [2018KZDXM066, 2017KZDXM081,
   2015KQNCX153]
FX This paper was supported by the National Natural Science Foundation of
   China (61773120, 61772225), the scientific project of mining machinery
   control and parts engineering center in Jiangsu province (JYAPT17-05),
   Xuzhou science and technology project (KH17003), the Youth project of
   science and Technology of Department of Education in Hebei provincial
   (QN2016237), the National Natural Science Foundation of Guangdong
   (2018B030311046), and the Guangdong University Key Platforms and
   Research Projects (2018KZDXM066, 2017KZDXM081, 2015KQNCX153).
CR Ankolekar A., 2002, P 1 INT SEM WEB C SE
   [Anonymous], 2013, Speech recognition with deep recurrent neural networks
   Ardagna B, 2007, IEEE SOFTWARE, V24, P39, DOI 10.1109/MS.2007.174
   Beauche S., 2008, INT C SERV OR COMP
   Cai ZQ, 2019, J VIS COMMUN IMAGE R, V59, P433, DOI 10.1016/j.jvcir.2018.11.002
   Foster H., 2003, IEEE INT C AUT SOFTW
   Goller Christoph, 1996, P INT C NEUR NETW IC
   Graves A., 2013, GENERATING SEQUENCES
   Jiao B, 2019, INFORM SCIENCES, V481, P574, DOI 10.1016/j.ins.2018.12.073
   Jureta IJ, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P304
   Lanchantin J., 2016, Proc. Pacific Symposium on Biocomputing, P254
   Liu Y., 2004, INT C WORLD WID WEB
   Maei H.R., 2009, INT C NEUR INF PROC
   Majithia S, 2004, IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P514, DOI 10.1109/ICWS.2004.1314777
   Maximilien IM, 2002, SIGMOD REC, V31, P36, DOI 10.1145/637411.637417
   Menascé DA, 2002, IEEE INTERNET COMPUT, V6, P72, DOI 10.1109/MIC.2002.1067740
   Mnih V, 2013, ARXIV
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ren T, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/9278056
   Ren T, 2017, BOUND VALUE PROBL, DOI 10.1186/s13661-017-0849-y
   Souza L.M.S.D., 2008, INT C INT THINGS
   Sutton R.S., 2009, FAST GRADIENT DESCEN
   Wang H., 2010, ADAPTIVE SERVICE COM
   Wang H., 2014, P 2014 IEEE INT C WE
   Wang R, 2018, INFORM SCIENCES, V450, P128, DOI 10.1016/j.ins.2018.03.047
   Wu GH, 2019, SWARM EVOL COMPUT, V44, P695, DOI 10.1016/j.swevo.2018.08.015
   Wu GH, 2018, INFORM SCIENCES, V423, P172, DOI 10.1016/j.ins.2017.09.053
   Wu GH, 2016, IEEE T SYST MAN CY-S, V46, P109, DOI 10.1109/TSMC.2015.2431643
   Xiang S, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9728-x
   Yan Y., 2010, IEEE INT C WEB SERV
   Yi JH, 2020, INFORM SCIENCES, V509, P470, DOI 10.1016/j.ins.2018.10.005
   Zhang C., 2017, SEQUENCE TO POINT LE
   Zhang JW, 2019, J COMB OPTIM, V37, P385, DOI 10.1007/s10878-017-0246-6
   Zheng ZB, 2011, IEEE T SERV COMPUT, V4, P140, DOI 10.1109/TSC.2010.52
NR 34
TC 10
Z9 10
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102687
DI 10.1016/j.jvcir.2019.102687
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700024
DA 2024-07-18
ER

PT J
AU Claro, M
   Veras, R
   Santana, A
   Araújo, F
   Silva, R
   Almeida, J
   Leite, D
AF Claro, Maila
   Veras, Rodrigo
   Santana, Andre
   Araujo, Flavio
   Silva, Romuere
   Almeida, Joao
   Leite, Daniel
TI An hybrid feature space from texture information and transfer learning
   for glaucoma classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Glaucoma detection; Feature selection; Pre-trained CNNs; Transfer
   learning
ID CONVOLUTIONAL NEURAL-NETWORKS; FUNDUS IMAGES; DIAGNOSIS; SEGMENTATION;
   AGREEMENT; CUP
AB Glaucoma is a progressive eye disease due to the increase in intraocular pressure. Accurate early detection may prevent vision loss. Most algorithms in the literature are not feasible for use in screening programs since they are not able to handle a wide diversity of images. We conducted an extensive study to determine the best set of features for image representation. Our feature extraction methodology included the following descriptors: LBP, GLCM, HOG, Tamura, GLRLM, morphology, and seven CNN architectures, that results in 30.682 features. Then, we used the gain ratio to order the features by importance and select the best set for glaucoma classification. Our tests were performed using 1675 images of DRISHTI, RIM-ONE, HRF, JSIEC, and ACRIMA databases. We concluded that a combination of the GLCM and pretrained CNN's has the potential to be used in a computer aid system for glaucoma detection. Our approach achieved an accuracy of 93.61%. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Claro, Maila; Veras, Rodrigo; Santana, Andre; Leite, Daniel] Univ Fed Piaui, Teresina, PI, Brazil.
   [Almeida, Joao] Univ Fed Maranhno, Sao Luis, MA, Brazil.
   [Araujo, Flavio; Silva, Romuere] Univ Fed Piaui, Picos, PI, Brazil.
C3 Universidade Federal do Piaui; Universidade Federal do Piaui
RP Claro, M (corresponding author), Univ Fed Piaui, Teresina, PI, Brazil.
EM claromaila@gmail.com
RI de Araújo, Flávio H Duarte/C-9541-2015; Veras, Rodrigo M S/D-7358-2015;
   Silva, Romuere/AFW-0349-2022
OI Veras, Rodrigo M S/0000-0001-8180-4032; Silva,
   Romuere/0000-0002-7163-7469; Almeida, Joao Dallyson Sousa de
   Almeida/0000-0001-7013-9700; Araujo, Flavio/0000-0003-2824-2645
FU Foundation for Research Support of the State of Piaui (FAPEPI)
FX The authors would like to thank the Foundation for Research Support of
   the State of Piaui (FAPEPI) for sponsoring our research.
CR Acharya UR, 2011, IEEE T INF TECHNOL B, V15, P449, DOI 10.1109/TITB.2011.2119322
   Ahn JM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0207982
   Al-Bander B, 2017, INT MULTICONF SYST, P207, DOI 10.1109/SSD.2017.8166974
   [Anonymous], 2018, 25 INT C SYST SIGN I
   [Anonymous], PROC CVPR IEEE
   [Anonymous], CORR
   [Anonymous], 2017, J ADV TRANSPORT, DOI DOI 10.1155/2017/8608032
   [Anonymous], 2016, INT J ENG RES SCI EN
   [Anonymous], 2016, CLEI ELECT J
   [Anonymous], 2008, ASSESSING ACCURACY R, DOI DOI 10.1201/9781420055139
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 1985, CALIFORNIA U SAN DIE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], 2014, INT C INF COMM EMB S
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   Breiman L., 2001, Mach. Learn., V45, P5
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Cerentini A, 2017, STUD HEALTH TECHNOL, V245, P318, DOI 10.3233/978-1-61499-830-3-318
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Christopher M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35044-9
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DASARATHY BV, 1991, PATTERN RECOGN LETT, V12, P497, DOI 10.1016/0167-8655(91)80014-2
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Fumero F, 2011, COMP MED SY
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Gómez-Valverde JJ, 2019, BIOMED OPT EXPRESS, V10, P892, DOI 10.1364/BOE.10.000892
   Grewal PS, 2018, CAN J OPHTHALMOL, V53, P309, DOI 10.1016/j.jcjo.2018.04.019
   Hagiwara Y, 2018, COMPUT METH PROG BIO, V165, P1, DOI 10.1016/j.cmpb.2018.07.012
   Haleem MS, 2013, COMPUT MED IMAG GRAP, V37, P581, DOI 10.1016/j.compmedimag.2013.09.005
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hastie T., 2009, ELEMENTS STAT LEARNI, P485, DOI DOI 10.1007/978-0-387-84858-7_7
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Orlando JI, 2017, PROC SPIE, V10160, DOI 10.1117/12.2255740
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kotyk T, 2016, ADV INTELL SYST, V427, P653, DOI 10.1007/978-3-319-29504-6_60
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Liu SD, 2018, OPHTHALMOL GLAUCOMA, V1, P15, DOI 10.1016/j.ogla.2018.04.002
   Mittapalli PS, 2016, BIOMED SIGNAL PROCES, V24, P34, DOI 10.1016/j.bspc.2015.09.003
   Ojala T., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P311
   Powers D.M.W., 2007, Technical Report, V2, P37
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   ROSENFIELD GH, 1986, PHOTOGRAMM ENG REM S, V52, P223
   Salam AA, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3175-4
   Shibata N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33013-w
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K., 2014, 14091556 ARXIV
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Sng CC, 2012, OPHTHALMOLOGY, V119, P1143, DOI 10.1016/j.ophtha.2012.01.011
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Vogado LHS, 2018, ENG APPL ARTIF INTEL, V72, P415, DOI 10.1016/j.engappai.2018.04.024
   Zhang YD, 2018, MULTIMED TOOLS APPL, V77, P22821, DOI 10.1007/s11042-018-5765-3
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
NR 62
TC 27
Z9 28
U1 4
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102597
DI 10.1016/j.jvcir.2019.102597
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600036
DA 2024-07-18
ER

PT J
AU He, DY
   Liu, L
   Miao, S
   Tong, XL
   Sheng, MJ
AF He, Dongyun
   Liu, Li
   Miao, Sheng
   Tong, Xiaoli
   Sheng, Minjia
TI Probabilistic guided polycystic ovary syndrome recognition using learned
   quality kernel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Probabilistic model; Image quality assessment; Image recognition
ID PCOS; FAILURE; SYSTEMS; IMPACT; FLUID; WOMEN
AB Image recognition aims to automatically search special objects in an image, such as human faces, vehicles, or buildings. In medical research, image recognition technique can also be applied for disease diagnosis and disease classification. Aiming at disadvantages of traditional methods in polycystic ovary syndrome (PCOS) recognition, we propose a probabilistic model for disease recognition using a deeply-learned image quality kernel. Specifically, we first segment training images into several equal-size grids for better cues discovery. Then, each grid within an image is quantitatively represented by a quality score according to grayscale and texture features. In this way, each image can be represented by a score matrix. Then, we leverage statistic based method to generate a long feature vector according to the score matrix. Afterward, we propose a probabilistic model to learn the distribution of obtained feature vector, which will be further fed into a SVM kernel for PCOS recognition. Experimental results show the effectiveness of our proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [He, Dongyun; Liu, Li; Miao, Sheng; Tong, Xiaoli; Sheng, Minjia] Jilin Univ, Chian Japan Union Hosp, Dept Gynecol & Obstet, Changchun, Jilin, Peoples R China.
C3 Jilin University
RP Sheng, MJ (corresponding author), Jilin Univ, Chian Japan Union Hosp, Dept Gynecol & Obstet, Changchun, Jilin, Peoples R China.
EM hdy@jlu.edu.cn; liuli304@jlu.edu.cn; miaosheng@jlu.edu.cn;
   Shengmj@jlu.edu.cn
FU research project of Health Commission of Jilin province [2015Z034]
FX This work was supported by the research project of Health Commission of
   Jilin province (No. 2015Z034).
CR Amato MC, 2015, J ENDOCRINOL INVEST, V38, P1319, DOI 10.1007/s40618-015-0372-x
   Anderson AD, 2014, SEMIN REPROD MED, V32, P202, DOI 10.1055/s-0034-1371092
   Asadi M, 2014, ARCH GYNECOL OBSTET, V289, P865, DOI 10.1007/s00404-013-3055-x
   Carmina E, 2006, EUR J ENDOCRINOL, V154, P141, DOI 10.1530/eje.1.02058
   Chen CF, 2015, NEUROCOMPUTING, V168, P941, DOI 10.1016/j.neucom.2015.05.031
   Chen CF, 2012, COMPUT GEOSCI-UK, V48, P9, DOI 10.1016/j.cageo.2012.05.018
   Cirik DA, 2014, J TURK-GER GYNECOL A, V15, P49, DOI 10.5152/jtgga.2014.95776
   Genazzani AD, 2014, GYNECOL ENDOCRINOL, V30, P438, DOI 10.3109/09513590.2014.897321
   Hosseinpanah F, 2014, CLIN ENDOCRINOL, V81, P93, DOI 10.1111/cen.12406
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Li X, 2014, J BIOMED SCI, V21, DOI 10.1186/1423-0127-21-2
   Lin HY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0091796
   Ma LF, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9169-4
   Moran LJ, 2015, TRENDS ENDOCRIN MET, V26, P136, DOI 10.1016/j.tem.2014.12.003
   Orio F, 2014, NAT REV ENDOCRINOL, V10, P130, DOI 10.1038/nrendo.2013.248
   Pang ZH, 2016, IEEE T CYBERNETICS, V46, P1400, DOI 10.1109/TCYB.2015.2448031
   Rasgon N. L., 2015, BIPOLAR DISORD, V7, P246
   Renato P, 2015, ENDOCRINE, V48, P422, DOI 10.1007/s12020-014-0311-1
   Rosenfield R. L., 2016, ENDOCR REV, V37
   Rutkowska A, 2014, GYNECOL ENDOCRINOL, V30, P260, DOI 10.3109/09513590.2013.871517
   Schmidt J, 2014, MOL HUM REPROD, V20, P49, DOI 10.1093/molehr/gat051
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Sorensen AE, 2014, GENES-BASEL, V5, P684, DOI 10.3390/genes5030684
   Tian G, 2017, INFORM SYST FRONT, V19, P75, DOI 10.1007/s10796-015-9590-1
   Unfer V, 2014, REPROD SCI, V21, P854, DOI 10.1177/1933719113518985
   Verrotti A, 2011, EPILEPSIA, V52, P199, DOI 10.1111/j.1528-1167.2010.02897.x
   Wang F, 2016, INFORM SCIENCES, V370, P385, DOI 10.1016/j.ins.2016.07.070
   Wang ZG, 2015, NEUROCOMPUTING, V149, P100, DOI 10.1016/j.neucom.2014.03.072
   Wissing ML, 2014, REPROD BIOMED ONLINE, V28, P508, DOI 10.1016/j.rbmo.2013.11.017
   Zhang S, 2017, NEUROCOMPUTING, V245, P1, DOI 10.1016/j.neucom.2017.03.029
   Zhang WP, 2017, SAUDI J BIOL SCI, V24, P563, DOI 10.1016/j.sjbs.2017.01.027
   Zhang XM, 2017, NEUROCOMPUTING, V235, P182, DOI 10.1016/j.neucom.2017.01.011
   Zhang YL, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/8950794
   Zou L, 2017, IEEE T CYBERNETICS, V47, P1830, DOI 10.1109/TCYB.2017.2685425
NR 34
TC 0
Z9 0
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102587
DI 10.1016/j.jvcir.2019.102587
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200019
DA 2024-07-18
ER

PT J
AU Srivastava, G
   Srivastava, R
AF Srivastava, Gargi
   Srivastava, Rajeev
TI Salient object detection using background subtraction, Gabor filters,
   objectness and minimum directional backgroundness
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Background subtraction; Gabor filters; Minimum directional
   backgroundness
AB Salient object detection is the process of identifying essential objects in an image. This paper solves this problem using background subtraction, Gabor filters, minimum directional backgroundness, and objectness. The first step is to calculate a backgroundness score for each region by calculating the difference between the feature vector of image boundary and image regions. This backgroundness map is then used for calculating the minimum directional background difference. The image is segmented using Gabor filters, and then the objectness criterion is used to choose the segment containing the salient object. The normalized foreground saliency map is then used to refine the selected segment.
   Further enhancement of this intermediate output is done using morphological operations, and boundary correction is done using the method of lazy snapping. The algorithm is tested on eight publicly available datasets and is compared against five algorithms. The performance is evaluated by PR-curve, F-Measure curve, and Mean Absolute Error. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Srivastava, Gargi; Srivastava, Rajeev] Indian Inst Technol BHU Varanasi, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Srivastava, G (corresponding author), Indian Inst Technol BHU Varanasi, Varanasi 221005, Uttar Pradesh, India.
EM gargis.rs.cse16@iitbhu.ac.in
RI Srivastava, Gargi/AAC-4052-2019; Srivastava, Rajeev/C-7906-2016
OI Srivastava, Gargi/0000-0001-6770-561X; Srivastava,
   Rajeev/0000-0002-0165-1556
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], ABS14105926 CORR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2019, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2018.2840724
   [Anonymous], 2012, Technical Report
   [Anonymous], ABS171100322 CORR
   [Anonymous], ABS14062807 CORR
   Aytekin Ç, 2015, IEEE IMAGE PROC, P1692, DOI 10.1109/ICIP.2015.7351089
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Guo F, 2018, IEEE T CYBERNETICS, V48, P3159, DOI 10.1109/TCYB.2017.2761361
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Huang XM, 2017, IEEE T IMAGE PROCESS, V26, P4243, DOI 10.1109/TIP.2017.2710636
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Quan R, 2018, IEEE T MULTIMEDIA, V20, P1101, DOI 10.1109/TMM.2017.2763780
   Srivastava G., 2018, MATH COMPUTING, P74
   Sun XS, 2012, PROC CVPR IEEE, P1552, DOI 10.1109/CVPR.2012.6247846
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang WG, 2017, IEEE T VIS COMPUT GR, V23, P2014, DOI 10.1109/TVCG.2016.2600594
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
NR 30
TC 8
Z9 10
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 330
EP 339
DI 10.1016/j.jvcir.2019.06.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600031
DA 2024-07-18
ER

PT J
AU Wen, HF
   Zhou, XF
   Sun, YQ
   Zhang, JY
   Yan, CG
AF Wen, Hongfa
   Zhou, Xiaofei
   Sun, Yaoqi
   Zhang, Jiyong
   Yan, Chenggang
TI Deep fusion based video saliency detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video saliency; Convolutional network; Feature integration; Boundary
ID OBJECT DETECTION; QUALITY ASSESSMENT; SEGMENTATION; MODEL
AB This paper introduces a novel video saliency model for salient object detection in videos. Firstly, we generate multi-level deep features via a symmetrical convolutional neural network, in which the inputs are the current frame and the optical flow image. Then, the multi-level deep features are integrated in a hierarchical manner using a fusion network, which deploys attention module to make a selection for deep features. Lastly, the integrated deep feature is combined with the boundary information originated from shallow layer of the feature extraction networks, and the saliency map is generated by the saliency prediction step. The key advantages of our model lie on the attention module, the hierarchical integration and the boundary information, in which the former one acts as weight filter and is used to select the most salient regions in deep features, the middle one gives an effective integration manner for features from different layers and the last one provides well-defined boundaries for saliency map. Extensive experiments are performed on two challenging video dataset, and the experimental results show that our model consistently outperforms the state-of-the-art saliency models in a large margin. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wen, Hongfa; Zhou, Xiaofei; Sun, Yaoqi; Zhang, Jiyong; Yan, Chenggang] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhou, XF (corresponding author), Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou, Zhejiang, Peoples R China.
RI Xiaofei, Zhou/AAE-8347-2020
OI Zhang, Jiyong/0000-0001-9600-8477
FU National Natural Science Foundation of China [61671196, 61525206,
   61701149]; Natural Science Foundation of Zhejiang Province
   [LR17F030006]; National Key Research and Development Program of China
   [2017YFC0820600]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61671196, Grant 61525206 and Grant
   61701149, in part by the Natural Science Foundation of Zhejiang Province
   under Grant LR17F030006, in part by the National Key Research and
   Development Program of China under Grant 2017YFC0820600.
CR [Anonymous], 2015, IEEE C COMPUT VIS PA, DOI 10.1109/CVPR.2015.7298961
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Chen L, 2015, IEEE T MULTIMEDIA, V17, P2225, DOI 10.1109/TMM.2015.2481711
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Guan JW, 2017, IEEE T MULTIMEDIA, V19, P2505, DOI 10.1109/TMM.2017.2703148
   Guo J, 2016, IEEE T MULTIMEDIA, V18, P1297, DOI 10.1109/TMM.2016.2564100
   Guo YR, 2019, J OCEANOL LIMNOL, V37, P1, DOI 10.1007/s00343-019-7336-5
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1336, DOI 10.1109/TCSVT.2014.2308652
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Lv CG, 2009, ADV INTEL SYS RES, P681
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Ren ZX, 2013, IEEE T IMAGE PROCESS, V22, P3120, DOI 10.1109/TIP.2013.2259837
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Le TN, 2018, IEEE T IMAGE PROCESS, V27, P5002, DOI 10.1109/TIP.2018.2849860
   Wang SQ, 2017, IEEE T MULTIMEDIA, V19, P660, DOI 10.1109/TMM.2016.2625276
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wu T, 2018, MULTIMED TOOLS APPL, V77, P19481, DOI 10.1007/s11042-017-5334-1
   Yan B, 2014, IEEE T MULTIMEDIA, V16, P272, DOI 10.1109/TMM.2013.2286112
   Zhang PP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1149
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhong S.-h., 2013, AAAI Conference on Artificial Intelligence, P1063
   Zhou XF, 2018, IEEE T MULTIMEDIA, V20, P2993, DOI 10.1109/TMM.2018.2829605
   Zhou XF, 2018, J VIS COMMUN IMAGE R, V51, P131, DOI 10.1016/j.jvcir.2018.01.014
NR 48
TC 13
Z9 13
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 279
EP 285
DI 10.1016/j.jvcir.2019.05.018
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600027
DA 2024-07-18
ER

PT J
AU Huang, ZD
   Wei, ZZ
   Zhang, GJ
AF Huang, Zhoudi
   Wei, Zhenzhong
   Zhang, Guangjun
TI BALG: An alternative for fast and robust feature matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature matching; Binary descriptor; Affine invariant; Sequence order;
   Local geometric check
AB Robust feature matcher is usually inapplicable to real time computer vision applications as its high computational complexity, while fast feature matcher is short of robustness to geometric transformations. By studying the sampling pattern of binary descriptor and local geometric statistics of features, this paper proposes a fast and robust feature matching method with binary affine invariant descriptor and local geometric consistency check (BALG). The sampling pattern is adaptively adjusted according local affine transformation that can be effectively estimated from the local intensity moments. The affine sampling pattern improves the affine invariance of binary descriptor while enable fast processing. Furthermore, candidate matches are sorted into local groups along different orientations with sequence order constraint, and then followed by local geometric consistency check. False matches are efficiently filtered out with high recall. Extensive experiments on four publicly benchmark datasets prove the proposed method to be an alternative for time critical feature matcher. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wei, Zhenzhong] Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing, Peoples R China.
   [Huang, Zhoudi; Zhang, Guangjun] Minist Educ, Key Lab Precis Optomechatron Technol, Beijing, Peoples R China.
C3 Beihang University
RP Wei, ZZ (corresponding author), Beihang Univ, Sch Instrumentat & Optoelect Engn, Beijing, Peoples R China.
EM zhenzhongwei@buaa.edu.cn
RI Huang, Zhoudi/AAA-3626-2019
OI Huang, Zhoudi/0000-0003-2899-4548
FU National Science Fund for Distinguished Young Scholars of China
   [51625501]
FX This work is supported by the National Science Fund for Distinguished
   Young Scholars of China under Grant 51625501.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   [Anonymous], 2003, 260 COMP VIS LAB SWI
   [Anonymous], 2011, P 2 ANN ACM C MULTIM
   Arnfred Jonas T., 2017, IEEE SIGPORT
   Balntas V, 2015, PROC CVPR IEEE, P2367, DOI 10.1109/CVPR.2015.7298850
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bazargani Hamid, 2015, J REAL TIME IMAGE PR
   Benseddik H. E., 2014, J. Image Graph., V2, P70
   Bian J, 2017, PROCEEDINGS OF 2017 CHINA INTERNATIONAL ELECTRICAL AND ENERGY CONFERENCE (CIEEC 2017), P1, DOI 10.1109/CIEEC.2017.8388410
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Chan Jacob, 2016, AS C COMP VIS, P385
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277
   Fischler M, 1981, COMMUN ASS COMP MACH, V24, P81, DOI DOI 10.1145/358669.358692
   Fragoso V, 2013, IEEE I CONF COMP VIS, P2472, DOI 10.1109/ICCV.2013.307
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Levi G, 2016, IEEE WINT CONF APPL
   Lin WY, 2016, LECT NOTES COMPUT SC, V9905, P562, DOI 10.1007/978-3-319-46448-0_34
   Lin WYD, 2014, LECT NOTES COMPUT SC, V8692, P341, DOI 10.1007/978-3-319-10593-2_23
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4492
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Maier J, 2016, LECT NOTES COMPUT SC, V9911, P101, DOI 10.1007/978-3-319-46478-7_7
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mishkin D, 2015, COMPUT VIS IMAGE UND, V141, P81, DOI 10.1016/j.cviu.2015.08.005
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Moulon Pierre, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P257, DOI 10.1007/978-3-642-37447-0_20
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Wang C, 2015, IEEE T IMAGE PROCESS, V24, P2110, DOI 10.1109/TIP.2015.2416639
   Wang Zhenhua, 2014, P C CVPR
   Yi K. M., 2016, P IEEE INT C EUR C C
   Yu YN, 2012, IEEE T IMAGE PROCESS, V21, P229, DOI 10.1109/TIP.2011.2160271
NR 38
TC 3
Z9 3
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 129
EP 139
DI 10.1016/j.jvcir.2019.02.017
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000016
DA 2024-07-18
ER

PT J
AU Yang, Y
   Shen, LQ
   Yang, H
   An, P
AF Yang, Yang
   Shen, Liquan
   Yang, Hao
   An, Ping
TI A content-based rate control algorithm for screen content video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Screen content video; Rate control; Parameter update; Bit allocation
ID MODEL; HEVC
AB The popularity of 3D screen content videos like 3D animations calls for better coding performance of screen content videos. The exiting R-lambda rate control model is designed to enable the coding performance of conventional nature videos, which can not accurately describe the Rate-Distortion (R-D) relationships of the screen content videos, especially for videos containing limited colors and sharper edges. This paper proposes a new rate control (RC) scheme which takes the divergent characteristics of text contents, screen images and nature images in screen content videos into consideration. In particular, the content-based rate control algorithm is developed at Coding Tree Unit (CTU) level, where CTUs are divided into three categories including Text-CTUs (T-CTUs), Screen Image-CTUs (SI-CTUs) and Nature Image-CTUs (NI-CTUs). Three R-lambda models reflecting different R-D relationships of different CTUs are established, and the model parameters are updated on the basis of their own models. Furthermore, in view of the fact that continuity and mutability simultaneously exist in screen content videos, two bit allocation schemes for regions containing only one content are determined in this paper. Experimental results show that the proposed RC scheme achieves 0.749 dB BDPSNR increase under the Low Delay configuration and 0.637 dB BDPSNR increase under the Random Access configuration on average, compared to the default R-lambda model in HEVC Screen Content Coding extension (HEVC-SCC) reference software. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yang, Yang; Yang, Hao; An, Ping] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
   [Shen, Liquan] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Joint Int Res Lab Specialty Fiber Opt & Adv Commu, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University
RP Shen, LQ (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Joint Int Res Lab Specialty Fiber Opt & Adv Commu, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai, Peoples R China.
EM judithyang@shu.edu.cn; jsslq@163.com; aidoneus@shu.edu.cn;
   anping@shu.edu.cn
RI Shen, Liquan/D-4832-2012
OI Shen, Liquan/0000-0002-2148-6279
FU National Natural Science Foundation of China [61671282, 61373151,
   61601278, 61525305]; Shanghai Pujiang Program [15pjd015]; Shanghai
   Science and Technology Innovation Plan [18010500200]; Shanghai Shuguang
   Program [17SG37]
FX This work is supported by the National Natural Science Foundation of
   China under grants No. 61671282, 61373151, 61601278 and 61525305 and
   sponsored by Shanghai Pujiang Program (15pjd015), Shanghai Science and
   Technology Innovation Plan (18010500200) and Shanghai Shuguang Program
   (17SG37).
CR [Anonymous], 2018, 2018 IEEE Power Energy Society General Meeting (PESGM)
   [Anonymous], JCTVCS0100
   Dai M, 2004, IEEE IMAGE PROC, P1093
   Gao W, 2017, IEEE T IMAGE PROCESS, V26, P6074, DOI 10.1109/TIP.2017.2745099
   Guo YY, 2015, IEEE INT SYMP CIRC S, P1118, DOI 10.1109/ISCAS.2015.7168834
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   ITU-T and I. JTCI, 2010, N11113 ITUT ISOIEC
   Karczewicz M., 2013, JCTVCM0257 ITUTISOIE
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Li B, 2012, JCTVCK0103 ITUTISOIE
   Li B., 2013, JCTVCL0033 ITUTISOIE
   Li B., 2014, document JCTVC-S0085
   Li B, 2013, JCTVCM0036 ITUTISOIE
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li B, 2013, IEEE INT SYMP CIRC S, P477, DOI 10.1109/ISCAS.2013.6571884
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Liu M, 2010, IEEE IMAGE PROC, P1277, DOI 10.1109/ICIP.2010.5653340
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   Meddeb Marwa, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7338, DOI 10.1109/ICASSP.2014.6855025
   Pang C., 2015, JCTVCT0094
   Peng WH, 2016, IEEE J EM SEL TOP C, V6, P393, DOI 10.1109/JETCAS.2016.2608971
   Pu W, 2016, IEEE J EM SEL TOP C, V6, P420, DOI 10.1109/JETCAS.2016.2605661
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Wen JT, 2015, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2015.35
   Xiaohua Jian, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8091746
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Xu M, 2014, IEEE J-STSP, V8, P475, DOI 10.1109/JSTSP.2014.2314864
   Yang H, 2015, IEEE T CYBERNETICS, V45, P533, DOI 10.1109/TCYB.2014.2330657
   Yaoyao Guo, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457809
   Yu H., 2014, JCTVCQ1015 ITUTISOIE
   Zhang ZW, 2017, IEEE ACCESS, V5, P13677, DOI 10.1109/ACCESS.2017.2676125
NR 32
TC 9
Z9 10
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 328
EP 338
DI 10.1016/j.jvcir.2019.02.031
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000036
DA 2024-07-18
ER

PT J
AU Huang, FH
   Yu, Y
   Feng, TH
AF Huang, Fenghua
   Yu, Ying
   Feng, Tinghao
TI Automatic extraction of impervious surfaces from high resolution remote
   sensing images based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High-resolution remote sensing images; Impervious surfaces extraction;
   Bilateral filtering; Convolutional neural network; Improved watershed
   algorithm
ID VEGETATION INDEX
AB Due to the complexity of urban surface, the differences in impervious surface materials, the mutual interference between the spectra of ground objects and the huge impact of ground object shadows in high-resolution remote sensing (HRRS) images, it is improper to directly use shallow machine learning algorithms and conventional object-oriented segmentation methods to extract urban impervious surfaces from HRRS images. Therefore, a method for automatic extraction of impervious surfaces from HRRS images based on deep learning (AEISHIDL) is proposed to address this problem. Firstly, the original HRRS images are pre-processed and the Gram-Schmidt algorithm is employed for the fusion of panchromatic and multi-spectral bands in HRRS images. In addition, an enhanced bilateral filtering method considering edge characteristics (EBFCEC) is designed and adopted to remove noises and enhance edges of man-made objects in original HRRS images. Secondly, the EBFCEC filtered images are partitioned into multi-layer object sets by using improved marker watershed based on LAB color space (IMWLCS), and the related objects in different sets are re-segmented to have the same edges through edge integration, after which we extract spectral feature averages and shape feature values of all objects while the convolutional neural network (CNN) is used to calculate the CNN feature averages of all pixel neighborhoods in each object. Finally, the fuzzy c-means clustering (FCM) algorithm is employed jointly considering the spectrum, shape and CNN features of the segmented objects in HRRS images to judge whether the objects belong to impervious surfaces, thereby effectively increasing the accuracy of automatically extracting impervious surfaces. Two different experimental regions are selected from two different types of HRRS images (WorldView 2 and Pleiades-1A) respectively (4 experimental regions in all). The experimental results show that AEISHIDL has higher accuracy and automation level compared with other four representative methods in urban impervious surfaces extraction from HRRS images. (C) 2018 Published by Elsevier Inc.
C1 [Huang, Fenghua; Yu, Ying] Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Fenghua; Yu, Ying] Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
   [Feng, Tinghao] Univ North Carolina Charlotte, Coll Comp & Informat, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Huang, FH (corresponding author), Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
EM fenghuait@sina.com
RI Feng, Tinghao/JWO-1400-2024
OI Feng, Tinghao/0000-0003-2765-2765
FU National Natural Science Foundation of China (NSFC) [41501451]; Program
   for New Century Excellent Talents in Fujian Province Universities
   (MinJiaoKe) [MinJiaoKe[2016]23]; Program for Outstanding Youth
   Scientific Research Talents in Fujian Province Universities
   [MinjiaoKe[2015]54]
FX This work was funded by the National Natural Science Foundation of China
   (NSFC, 41501451), the Program for New Century Excellent Talents in
   Fujian Province Universities (MinJiaoKe[2016]23) and the Program for
   Outstanding Youth Scientific Research Talents in Fujian Province
   Universities (MinjiaoKe[2015]54). The authors would like to thank
   Zhengyuan Mao and Yinan He for their assistance, suggestions, and
   discussions.
CR [Anonymous], TERRITORY NAT RESOUR
   [Anonymous], J REMOTE SENS
   [Anonymous], 2014, Comput. Modern
   [Anonymous], COMPUT SCI A
   [Anonymous], COMPUT ENG APPL
   [Anonymous], J REMOTE SENS
   [Anonymous], J HEILONGJIANG I TEC
   [Anonymous], 2012, J SOOCHOW U NAT SCI
   Arnold CL, 1996, J AM PLANN ASSOC, V62, P243, DOI 10.1080/01944369608975688
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chen Xiao-hung, 2012, Computer Engineering, V38, P183, DOI 10.3969/j.issn.1000-3428.2012.22.045
   Deng CB, 2015, REMOTE SENS-BASEL, V7, P9205, DOI 10.3390/rs70709205
   Deng CB, 2013, REMOTE SENS ENVIRON, V133, P62, DOI 10.1016/j.rse.2013.02.005
   Duan Baobin, 2014, Computer Engineering and Applications, V50, P176, DOI 10.3778/j.issn.1002-8331.1312-0134
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   HUETE A R, 1988, Remote Sensing of Environment, V25, P295, DOI 10.1016/0034-4257(88)90106-X
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   [李彩丽 LI Cai-li], 2009, [遥感信息, Remote Sensing Information], P36
   [李红平 Li Hongping], 2014, [云南大学学报. 自然科学版, Journal of Yunnan University. Natural Science], V36, P341
   Li M, 2015, ADV SPACE RES, V55, P1307, DOI 10.1016/j.asr.2014.12.015
   Li S. J, 2009, THESIS
   Li Zhifei, 2014, Journal of Computer Applications, V34, P2231, DOI 10.11772/j.issn.1001-9081.2014.08.2231
   Lu DS, 2011, INT J REMOTE SENS, V32, P2519, DOI 10.1080/01431161003698393
   [任晓娟 Ren Xiaojuan], 2011, [计算机应用与软件, Computer Applications and Software], V28, P249
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   [田元 Tian Yuan], 2010, [工程图学学报, Journal of Engineering Graphics], V31, P123
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wu CS, 2003, REMOTE SENS ENVIRON, V84, P493, DOI 10.1016/S0034-4257(02)00136-0
   [吴孟凡 Wu Mengfan], 2017, [遥感信息, Remote Sensing Information], V32, P79
   Wu Xiuyun, 2010, Water Resources and Power, V28, P72
   [夏俊士 XIA Junshi], 2011, [中国矿业大学学报. 自然科学版, Journal of China University of Mining & Technology], V40, P660
   [徐涵秋 Xu Hanqiu], 2005, [遥感学报, Journal of Remote Sensing], V9, P589
   Yin Bao-cai, 2015, Journal of Beijing University of Technology, V41, P48, DOI 10.11936/bjutxb2014100026
   Yuan F, 2007, REMOTE SENS ENVIRON, V106, P375, DOI 10.1016/j.rse.2006.09.003
   [岳文泽 YUE Wenze], 2007, [遥感学报, Journal of Remote Sensing], V11, P914
   Zhao WZ, 2016, ISPRS J PHOTOGRAMM, V113, P155, DOI 10.1016/j.isprsjprs.2016.01.004
   [周子闵 Zhou Zimin], 2016, [华东师范大学学报. 自然科学版, Journal of East China Normal University. Natural Science], P150
NR 39
TC 29
Z9 34
U1 1
U2 59
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 453
EP 461
DI 10.1016/j.jvcir.2018.11.041
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100044
DA 2024-07-18
ER

PT J
AU Huang, WD
   Kim, S
   Billinghurst, M
   Alem, L
AF Huang, Weidong
   Kim, Seungwon
   Billinghurst, Mark
   Alem, Leila
TI Sharing hand gesture and sketch cues in remote collaboration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand gestures; Multimodal communication; Remote collaboration; Physical
   task; Sketches
ID COMMUNICATION; SPACE
AB Many systems have been developed to support remote guidance, where a local worker manipulates objects under guidance of a remote expert helper. These systems typically use speech and visual cues between the local worker and the remote helper, where the visual cues could be pointers, hand gestures, or sketches. However, the effects of combining visual cues together in remote collaboration has not been fully explored. We conducted a user study comparing remote collaboration with an interface that combined hand gestures and sketching (the HandslnTouch interface) to one that only used hand gestures, when solving two tasks: Lego assembly and repairing a laptop. In the user study, we found that (1) adding sketch cues improved the task completion time, only with the repairing task as this had complex object manipulation but (2) using gesture and sketching together created a higher task load for the user. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Huang, Weidong] Swinburne Univ Technol, Sch Software & Elect Engn, Hawthorn, Vic, Australia.
   [Kim, Seungwon; Billinghurst, Mark] Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
   [Alem, Leila] ArcSense Sydney, Sydney, NSW, Australia.
C3 Swinburne University of Technology; University of South Australia
RP Kim, S (corresponding author), Univ South Australia, Sch Informat Technol & Math Sci, Adelaide, SA, Australia.
EM seungkimkr@gmail.com
RI Huang, Weidong/B-7504-2011; Billinghurst, Mark/AAJ-4236-2020
OI Billinghurst, Mark/0000-0003-4172-6759; Kim,
   Seungwon/0000-0003-4221-3058; Huang, Weidong/0000-0002-5190-7839
CR Alem L., 2011, RECENT TRENDS MOBILE, P171
   Chen IJ, 2009, ELECTRON J RES EDUC, V7, P729
   Chen S., 2013, 4 AUGM HUM INT C STU, P69, DOI DOI 10.1145/2459236.2459249
   Conway D, 2013, LECT NOTES COMPUT SC, V8120, P659
   Di Stasi LL, 2013, EUR J NEUROSCI, V38, P2389, DOI 10.1111/ejn.12248
   Fakourfar O, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1548, DOI 10.1145/2858036.2858171
   Fussell S.R., 2000, P CSCW 2000, P21, DOI DOI 10.1145/358916.358947
   Fussell SR, 2004, HUM-COMPUT INTERACT, V19, P273, DOI 10.1207/s15327051hci1903_3
   Gauglitz S., 2014, P 20 ACM S VIRT REAL, P197, DOI DOI 10.1145/2671015.2671016
   Goldin-Meadow S, 1999, TRENDS COGN SCI, V3, P419, DOI 10.1016/S1364-6613(99)01397-2
   Gupta K, 2016, IEEE T VIS COMPUT GR, V22, P2413, DOI 10.1109/TVCG.2016.2593778
   Gurevich P., 2012, P SIGCHI C HUM FACT, P619
   HART S G, 1988, P139
   Higuch K, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2383, DOI 10.1145/2702123.2702160
   Higuch K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5180, DOI 10.1145/2858036.2858438
   Huang W., 2011, RECENT TRENDS MOBILE, P127
   Huang W, 2013, P 2013 C COMP SUPP C, P153, DOI DOI 10.1145/2441955.2441994
   Huang WD, 2013, LECT NOTES COMPUT SC, V8117, P70
   Huang WD, 2013, J UNIVERS COMPUT SCI, V19, P1158
   ISHII H, 1993, ACM T INFORM SYST, V11, P349, DOI 10.1145/159764.159762
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kim S, 2013, SCI WORLD J, DOI 10.1155/2013/175702
   Kim S, 2018, COMPUT SUPP COOP W J, V27, P569, DOI 10.1007/s10606-018-9324-2
   Kim S, 2014, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2014.6948412
   Kim Seungwon., 2015, Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems, P1669, DOI [10.1145/2702613.2732838, DOI 10.1145/2702613.2732838]
   Kirk D, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P1039
   Kunz A, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P430, DOI 10.1109/CW.2010.17
   Kuzuoka H., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P35, DOI 10.1145/192844.192866
   Lee G.A., 2017, ICAT EGVE 2017 INT C, P197, DOI DOI 10.2312/EGVE.20171359
   Lee G. A., 2018 IEEE INT S MIX
   Lee GA, 2017, SA'17: SIGGRAPH ASIA 2017 MOBILE GRAPHICS & INTERACTIVE APPLICATIONS, DOI 10.1145/3132787.3139203
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Sakata N, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P53, DOI 10.1109/ISWC.2003.1241393
   Siegenthaler E, 2014, EUR J NEUROSCI, V39, P287, DOI 10.1111/ejn.12395
   Sodhi R. S., 2013, P SIGCHI C HUMAN FAC, P179
   Tang A, 2007, PEOPLE AND COMPUTERS XX - ENGAGE, P85, DOI 10.1007/978-1-84628-664-3_8
   Tang J.C., 1991, ACM T INFORM SYST, V9, P170, DOI [DOI 10.1145/123078.128729, DOI 10.1145/97243.97302]
NR 39
TC 33
Z9 35
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 428
EP 438
DI 10.1016/j.jvcir.2018.12.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100042
DA 2024-07-18
ER

PT J
AU Zhu, XB
   Zhang, XM
   Zhang, XY
   Xue, ZY
   Wang, L
AF Zhu, Xiaobin
   Zhang, Xinming
   Zhang, Xiao-Yu
   Xue, Ziyu
   Wang, Lei
TI A novel framework for semantic segmentation with generative adversarial
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semantic segmentation; Generative adversarial network (GAN); Wasserstein
   distance; Auxiliary higher-order potential loss
AB Semantic segmentation plays an important role in a series of high-level computer vision applications. In the state-of-the-art semantic segmentation methods based on fully convolutional neural networks, all label variables are predicted independently from each other, and the restricted field-of-views of the convolutional filters are difficult to capture the long-range information. In this paper, a novel post-processing method based on GAN (Generative Adversarial Network) is explored to reinforce spatial contiguity in the output label maps. With the help of fully connected layers in the discriminator, the GAN can capture the long-range information, and provide an auxiliary higher-order potential loss to the segmentation model, thus the segmentation model has the ability of correcting higher order inconsistencies. Furthermore, the optimization scheme in Wasserstein GAN (WGAN) is adopted to the training process of our model to get better performance and stability. Extensive experiments on public benchmarking database demonstrate the effectiveness of the proposed method. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhu, Xiaobin] Univ Sci & Technol, Beijing, Peoples R China.
   [Zhu, Xiaobin; Zhang, Xinming] Beijing Technol & Business Univ, Beijing, Peoples R China.
   [Zhang, Xiao-Yu] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
   [Xue, Ziyu; Wang, Lei] Acad Broadcasting Sci, Informat Technol Inst, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; Beijing Technology &
   Business University; Chinese Academy of Sciences; Institute of
   Information Engineering, CAS
RP Zhang, XY (corresponding author), Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
EM zhangxiaoyu@iie.ac.cn
RI Wang, Zixuan/HZJ-2348-2023; xiaoyu, zhang/JXY-7226-2024; Zhang,
   xiaoyu/HTM-3222-2023; Zhang, xiaoyu/GXA-3206-2022; zhang,
   xiaoyu/HJI-4374-2023; Zhang, Xiaoyu/ISV-0984-2023
OI Xue, Ziyu/0000-0001-7035-7089
FU National Key R&D Program of China [2017YFB1401000]; National Natural
   Science Foundation of China [61871378, 61602517]; Open Project Program
   of National Laboratory of Pattern Recognition [201800018]
FX This work was supported by National Key R&D Program of China
   (2017YFB1401000), National Natural Science Foundation of China
   (61871378, 61602517), and Open Project Program of National Laboratory of
   Pattern Recognition (201800018). The corresponding author is Xiao-Yu
   Zhang, Xiaobin Zhu and Xinming Zhang are joint-first authors, who
   contribute equally to this paper.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], CORR
   [Anonymous], ARXIV180500313
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   [Anonymous], ARXIV170107875
   Badrinarayanan V., Segnet: A deep convolutional encoder-decoder architecture for image segmentation
   Badrinarayanan Vijay, CORR
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen L, CORR
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Ciresan D., 2012, NIPS, P2843
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gadde R., IEEE T PATTERN ANAL
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   He H., JOINT BINARY NEURAL
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hung W., CORR
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jampani V, 2015, IEEE WINT CONF APPL, P1038, DOI 10.1109/WACV.2015.143
   Jing  P., IEEE T CIRC SYST VID
   Jing P., IEEE T KNOWL DATA EN
   Jing PG, 2018, NEUROCOMPUTING, V274, P50, DOI 10.1016/j.neucom.2016.05.085
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Ladicky L'ubor, 2010, Computer Vision - ECCV 2010. Proceedings 11th European Conference on Computer Vision, P424, DOI 10.1007/978-3-642-15561-1_31
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luc P., ARXIV161108408
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pinheiro PO, 2014, PR MACH LEARN RES, V32
   Qi SH, 2018, NEUROCOMPUTING, V274, P29, DOI 10.1016/j.neucom.2016.06.097
   Shotton J., 2008, 2008 IEEE COMP SOC C
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song X., PERSONAL PRIVACY PRE
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Souly N, 2017, IEEE I CONF COMP VIS, P5689, DOI 10.1109/ICCV.2017.606
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tensorfiow, 2018, DEEPL DEEP LAB SEM I
   TyleEek R., 2013, P GCPR SAARBR GERM
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang P., CoRR
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yu F., CoRR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X. Z. E. Xinming, 2018, NOVEL FRAMEWORK SEMA
   Zhao H., CORR
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou Bolei, 2017, PROC CVPR IEEE, P633, DOI DOI 10.1109/CVPR.2017.544
NR 58
TC 40
Z9 43
U1 1
U2 41
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 532
EP 543
DI 10.1016/j.jvcir.2018.11.020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100052
DA 2024-07-18
ER

PT J
AU Hu, ZT
   Zhou, L
   Yang, YN
   Liu, XX
   Jin, Y
AF Hu, Zhen-tao
   Zhou, Lin
   Yang, Ya-nan
   Liu, Xian-xing
   Jin, Yong
TI Anti-occlusion tracking algorithm of video target based on prediction
   and re-matching strategy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anti-occlusion; Mean Shift algorithm; Kalman filter; Normalized cross
   correlation matching
ID MEAN-SHIFT
AB Accurately locating the video target in the process of occlusion and recurrence will be very important for effective follow-up of the target For the problem of poor applicability of Mean Shift and its improved algorithm when the target is heavily occluded, this paper proposes an anti-occlusion video target tracking algorithm based on prediction and re-matching strategy. Firstly, dynamically combining the Mean Shift algorithm with the Kalman filter, this paper achieves stable tracking of un-occluded target. Secondly, when the target is occluded, Kalman filter is combined with the target prior information to predict the position of the occluded target. Finally, in the recurrence process of occluded targets, the target is re- matched through the normalized cross-correlation method to obtain target optimal position, and then the target can be quickly and accurately located. The simulation results show that the proposed method has strong anti-occlusion and reliability tracking in the video target tracking process. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Hu, Zhen-tao; Zhou, Lin; Yang, Ya-nan; Liu, Xian-xing; Jin, Yong] Henan Univ, Coll Comp & Informat Engn, Kaifeng 475004, Peoples R China.
C3 Henan University
RP Zhou, L (corresponding author), Henan Univ, Coll Comp & Informat Engn, Kaifeng 475004, Peoples R China.
EM hzt@henu.edu.cn; zhoulin@henu.edu.cn; 1049980081@qq.com;
   liuxianxing@henu.edu.cn; jy@henu.edu.cn
RI Lin, Zhou/HNP-4376-2023
FU National Science Foundation Council of China [61771006]; Programs for
   Science and Technology Development of He'nan Province, China
   [162102210401, 162102210022]; Open Fund Project of Key Laboratory of
   Spectral Imaging Technology of Chinese Academy of Sciences [LSIT201711D]
FX This work was supported by the National Science Foundation Council of
   China (nos. 61771006), the Programs for Science and Technology
   Development of He'nan Province, China (nos. 162102210401, 162102210022),
   the Open Fund Project of Key Laboratory of Spectral Imaging Technology
   of Chinese Academy of Sciences (nos. LSIT201711D).
CR Ali A., 2007, IEEE INT C EM TECHN, P174
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Benlefld T., 2016, INT C IM SIGN PROC, P41
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 2002, IEEE C COMP VIS PATT, P142
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Jeong J, 2017, EXPERT SYST APPL, V79, P194, DOI 10.1016/j.eswa.2017.02.043
   Liu ZG, 2017, IEEE T SYST MAN CY-S, V47, P2783, DOI 10.1109/TSMC.2016.2622247
   Sriharsha KV, 2015, 2015 6 INT C COMPUTI, P1
   Talha M, 2014, IEEE SENS J, V14, P159, DOI 10.1109/JSEN.2013.2271561
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P520, DOI 10.1109/JOE.2004.839933
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Yuan Y, 2014, IEEE T CIRC SYST VID, V24, P1898, DOI 10.1109/TCSVT.2014.2319632
   Zhang Xue-jing, 2013, Transactions of Beijing Institute of Technology, V33, P1056
   Zhou T, 2014, P INT CONF NAT COMPU, P980, DOI 10.1109/ICNC.2014.6975973
NR 15
TC 1
Z9 1
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 176
EP 182
DI 10.1016/j.jvcir.2018.10.019
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400021
DA 2024-07-18
ER

PT J
AU Li, GJ
   Peng, MM
   Nai, K
   Li, ZY
   Li, KQ
AF Li, Guiji
   Peng, Manman
   Nai, Ke
   Li, Zhiyong
   Li, Keqin
TI Visual tracking via context-aware local sparse appearance model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Local sparse representation; Spatial-temporal context;
   Dictionary update
ID ROBUST OBJECT TRACKING
AB Most existing local sparse trackers are prone to drifting away as they do not make use of discriminative information of local patches. In this paper, we propose an effective context-aware local sparse appearance model to alleviate the drift problem caused by background clutter and occlusions. First, considering that different local patches should have different impacts on the likelihood computation, we present a novel Impact Allocation Strategy (IAS) with integration of the spatial-temporal context. Varying positive impact factors are adaptively assigned to different local patches based on their ability distinguishing the spatial context, which provides discriminative information to prevent the tracker from drifting. Furthermore, we exploit temporal context to introduce some historical information for more accurate locating. Second, we present a new patch-based dictionary update method being able to update each patch independently with the validation of effectiveness. On the one hand, we introduce sparsity concentration index to check whether the local patch to be updated is a valid local patch from the target object. On the other hand, spatial context is further employed to eliminate the effect of the background. Experimental results show the superiority and competitiveness of the proposed method on the benchmark data set compared to other state-of-the-art algorithms. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Li, Guiji; Peng, Manman; Nai, Ke; Li, Zhiyong; Li, Keqin] Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
   [Li, Keqin] SUNY Coll New Paltz, Dept Comp Sci, New Paltz, NY 12561 USA.
C3 Hunan University; State University of New York (SUNY) System; SUNY New
   Paltz
RP Peng, MM (corresponding author), Hunan Univ, Coll Informat Sci & Engn, Changsha 410082, Hunan, Peoples R China.
EM guiji.li@hnu.edu.cn; pengmanman@hnu.edu.cn; naike_hnu@hnu.edu.cn;
   zhiyong.li@hnu.edu.cn; lik@newpaltz.edu
RI li, zy/HZM-1892-2023
FU National key R&D Program of China [2017YFB0202901, 2017YFB0202905];
   National Natural Science Foundation of China [61672215, 91320103];
   Special Project on the Integration of Industry, Education and Research
   of Guangdong Province, China [2012A090300003]; Science and Technology
   Planning Project of Guangdong Province, China [2013B090700003]
FX This work was supported by the National key R&D Program of China (Grant
   2017YFB0202901, 2017YFB0202905). This work was partially supported by
   the National Natural Science Foundation of China (No.61672215,
   No.91320103), the Special Project on the Integration of Industry,
   Education and Research of Guangdong Province, China (No.2012A090300003)
   and the Science and Technology Planning Project of Guangdong Province,
   China (No.2013B090700003). The corresponding author of this paper is
   Manman Peng (pengmanman@hnu.edu.cn).
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chen DP, 2017, IEEE T PATTERN ANAL, V39, P141, DOI 10.1109/TPAMI.2016.2539956
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Feng P, 2017, NEUROCOMPUTING, V225, P92, DOI 10.1016/j.neucom.2016.11.009
   Gao JY, 2017, IEEE T IMAGE PROCESS, V26, P1845, DOI 10.1109/TIP.2017.2656628
   Gao L, 2018, J VIS COMMUN IMAGE R, V50, P74, DOI 10.1016/j.jvcir.2017.11.008
   Gao X., IEEE T IMAGE PROCESS, V24
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2013, IEEE I CONF COMP VIS, P649, DOI 10.1109/ICCV.2013.86
   Huang HT, 2015, PATTERN RECOGN LETT, V56, P52, DOI 10.1016/j.patrec.2015.01.014
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kuai YL, 2018, J VIS COMMUN IMAGE R, V51, P104, DOI 10.1016/j.jvcir.2018.01.008
   Li F, 2017, IMAGE VISION COMPUT, V60, P124, DOI 10.1016/j.imavis.2017.01.003
   Li X., 2018, IEEE T PATTERN ANAL, P1
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li ZY, 2017, J VIS COMMUN IMAGE R, V44, P1, DOI [10.1016/j.jvcir.2017.01.012, 10.16339/j.cnki.hdxbzkb.2017.11.001]
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma B, 2016, IEEE T CYBERNETICS, V46, P2411, DOI 10.1109/TCYB.2015.2477879
   Ma B, 2015, IEEE I CONF COMP VIS, P4400, DOI 10.1109/ICCV.2015.500
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Qi YK, 2018, IEEE T IMAGE PROCESS, V27, P3857, DOI 10.1109/TIP.2018.2797482
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sui Y, 2015, IEEE I CONF COMP VIS, P3002, DOI 10.1109/ICCV.2015.344
   Tang D., 2018, MULTIMEDIA TOOLS APP, V77, P1
   Wang D, 2015, IEEE T IMAGE PROCESS, V24, P2646, DOI 10.1109/TIP.2015.2427518
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wen LY, 2014, IEEE T IMAGE PROCESS, V23, P785, DOI 10.1109/TIP.2013.2293430
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang F, 2014, IEEE T CIRC SYST VID, V24, P242, DOI 10.1109/TCSVT.2013.2276145
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yang YH, 2017, IEEE T CYBERNETICS, V47, P485, DOI 10.1109/TCYB.2016.2519532
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang TZ, 2016, IEEE T CYBERNETICS, V46, P51, DOI 10.1109/TCYB.2015.2393307
   Zhang TZ, 2015, PROC CVPR IEEE, P150, DOI 10.1109/CVPR.2015.7298610
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhang T, 2019, INT J COMPUT MATH, V96, P594, DOI 10.1080/00207160.2018.1455092
   Zhao ZQ, 2017, NEUROCOMPUTING, V237, P101, DOI 10.1016/j.neucom.2016.09.031
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou T., 2017, IEEE T CYBERN PP, P1
   Zhou T, 2017, NEUROCOMPUTING, V226, P221, DOI 10.1016/j.neucom.2016.11.055
   Zhou Y, 2017, IEEE T MULTIMEDIA, V19, P1798, DOI 10.1109/TMM.2017.2689918
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 55
TC 11
Z9 11
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 92
EP 105
DI 10.1016/j.jvcir.2018.09.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500008
DA 2024-07-18
ER

PT J
AU Baisa, NL
   Bhowmik, D
   Wallace, A
AF Baisa, Nathanael L.
   Bhowmik, Deepayan
   Wallace, Andrew
TI Long-term correlation tracking using multi-layer hybrid features in
   sparse and dense environments
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Correlation filter; CNN features; Hybrid features;
   Online learning; GM-PHD filter
ID VISUAL TRACKING; OBJECT TRACKING; SYSTEM
AB Tracking a target of interest in both sparse and crowded environments is a challenging problem, not yet successfully addressed in the literature. In this paper, we propose a new long-term visual tracking algorithm, learning discriminative correlation filters and using an online classifier, to track a target of interest in both sparse and crowded video sequences. First, we learn a translation correlation filter using a multi-layer hybrid of convolutional neural networks (CNN) and traditional hand-crafted features. Second, we include a re-detection module for overcoming tracking failures due to long-term occlusions using online SVM and Gaussian mixture probability hypothesis density (GM-PHD) filter. Finally, we learn a scale correlation filter for estimating the scale of a target by constructing a target pyramid around the estimated or re-detected position using the HOG features. We carry out extensive experiments on both sparse and dense data sets which show that our method significantly outperforms state-of-the-art methods.
C1 [Baisa, Nathanael L.; Wallace, Andrew] Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh, Midlothian, Scotland.
   [Bhowmik, Deepayan] Sheffield Hallam Univ, Dept Comp, Sheffield, S Yorkshire, England.
C3 Heriot Watt University; Sheffield Hallam University
RP Baisa, NL (corresponding author), Heriot Watt Univ, Sch Engn & Phys Sci, Edinburgh, Midlothian, Scotland.
EM nb30@hw.ac.uk
OI Wallace, Andrew/0000-0003-4425-8591
FU Engineering and Physical Sciences Research Council (EPSRC) [EP/
   K009931]; James Watt Scholarship; EPSRC [EP/K009931/1] Funding Source:
   UKRI
FX We would like to acknowledge the support of the Engineering and Physical
   Sciences Research Council (EPSRC), grant references EP/ K009931 and a
   James Watt Scholarship.
CR Alfalou A, 2015, PROG OPTICS, V60, P119, DOI 10.1016/bs.po.2015.02.002
   [Anonymous], P 25 ANN ACM INT C M
   [Anonymous], DENSITY AWARE PERSON
   [Anonymous], 2014, P EUR C COMP VIS ECC
   [Anonymous], 2014, P IEEE C COMP VIS PA
   [Anonymous], 2014, P BMVC
   [Anonymous], VERY DEEP CONVOLUTIO
   [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   [Anonymous], 2015, P 32 INT C MACH LEAR
   [Anonymous], 2012, MACHINE LEARNING PRO
   [Anonymous], 2005, TECH REP
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Baisa N. L., 2017, P 12 INT C COMP VIS
   Baisa N. L., ARXIV170504757
   Benarab D, 2017, OPT LASER ENG, V89, P195, DOI 10.1016/j.optlaseng.2016.05.013
   Bouzidi F, 2016, OPT COMMUN, V358, P132, DOI 10.1016/j.optcom.2015.09.022
   Chen Z., CORR
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diehl CP, 2003, IEEE IJCNN, P2685
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques J. F., IEEE T PATTERN ANAL
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Idrees H, 2014, IMAGE VISION COMPUT, V32, P14, DOI 10.1016/j.imavis.2013.10.006
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Nam H., CoRR
   Napoléon T, 2017, OPT LASER ENG, V89, P150, DOI 10.1016/j.optlaseng.2016.06.019
   Ouerhani Y, 2017, OPT LASER ENG, V89, P184, DOI 10.1016/j.optlaseng.2016.05.020
   Rifkin R., 2003, Computer and Systems Sciences, V190, P131
   Ristic B, 2012, IEEE T AERO ELEC SYS, V48, P1656, DOI 10.1109/TAES.2012.6178085
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Dinh TB, 2014, COMPUT VIS IMAGE UND, V119, P41, DOI 10.1016/j.cviu.2013.11.003
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vo BN, 2006, IEEE T SIGNAL PROCES, V54, P4091, DOI 10.1109/TSP.2006.881190
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang Q, 2017, ADV OPT PHOTONICS, V9, P1, DOI 10.1364/AOP.9.000001
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 52
TC 13
Z9 13
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 464
EP 476
DI 10.1016/j.jvcir.2018.06.027
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100041
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Barros, W
   Nascimento, ER
   Barbosa, WV
   Campos, MFM
AF Barros, Wagner
   Nascimento, Erickson R.
   Barbosa, Walysson, V
   Campos, Mario F. M.
TI Single-shot underwater image restoration: A visual quality-aware method
   based on light propagation model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image restoration; Underwater vision; Feature-preserving; Visibility;
   Inverse problem
AB In this paper, we present a novel method to restore the visual quality of images from scenes immersed in participating media, in particular water. Our method builds upon existing physics-based model and estimates the scene radiance by removing the medium interference on light propagation. Our approach requires a single image as input and, by combining a physics-based model for light propagation and a set of quality metrics, reduces the artifacts and degradation imposed by the attenuation, forward scattering, and backscattering effects. We show that the resulting images produced by our technique from underwater images are amenable to be directly used as input to algorithms which do not assume disturbances from the media. Our experiments demonstrate that, as far as visual image quality is concerned, our methodology outperforms both traditional image based restoration approaches and the state-of-the-art methods. Our approach brings advantages regarding descriptor distinctiveness which enables the use of underwater images in legacy non-participating media algorithms such as keypoint detection and description.
C1 [Barros, Wagner] Inst Fed Educ Ciencia & Tecnol Norte Minas Gerais, Montes Claros, Brazil.
   [Nascimento, Erickson R.; Barbosa, Walysson, V; Campos, Mario F. M.] Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil.
C3 Instituto Federal do Norte de Minas Gerais (IFNMG); Universidade Federal
   de Minas Gerais
RP Nascimento, ER (corresponding author), Univ Fed Minas Gerais, Belo Horizonte, MG, Brazil.
EM erickson@dcc.ufmg.br; walyb@dcc.ufmg.br; mario@dcc.ufmg.br
RI Nascimento, Erickson R./G-5374-2014; Campos, Mario/AAU-1799-2020;
   Campos, Mario/C-4647-2013
OI Nascimento, Erickson R./0000-0003-2973-2232; Campos,
   Mario/0000-0002-8336-9190
FU CNPq [456166/2014-9]; CAPES; FAPEMIG [APQ-00783-14]
FX This work is supported by grants from CNPq, CAPES, and FAPEMIG; CNPq
   under Proc. 456166/2014-9 and FAPEMIG under Proc. APQ-00783-14.
CR Ancuti C, 2016, INT C PATT RECOG, P4202, DOI 10.1109/ICPR.2016.7900293
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], INT ARCH PHOTOGRAMME
   [Anonymous], CVPR
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Bazeille I. Q. S., 2006, CARACTERISATION MILI
   Boudhane M, 2016, J VIS COMMUN IMAGE R, V39, P226, DOI 10.1016/j.jvcir.2016.05.017
   Chambah M, 2004, PROC SPIE, V5293, P157
   Cheng CY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (ICSIPA), P110, DOI 10.1109/ICSIPA.2015.7412173
   Chiang JY, 2011, LECT NOTES COMPUT SC, V6915, P372, DOI 10.1007/978-3-642-23687-7_34
   Coleman D.F., 2000, MARINE TECHNOLOGY SO, V1
   Neto VFD, 2009, SIBGRAPI, P307, DOI 10.1109/SIBGRAPI.2009.24
   do Nascimento E.R., 2009, P SIBGRAPI
   Drews P, 2015, IEEE INT C INT ROBOT, P1058, DOI 10.1109/IROS.2015.7353501
   Drews P, 2014, INT C PATT RECOG, P3999, DOI 10.1109/ICPR.2014.685
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Drews-Jr P., 2013, INT C COMP VIS ICCV
   Foresti GL, 2001, IEEE T SYST MAN CY B, V31, P691, DOI 10.1109/3477.956031
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gembicki F., 1974, Vector Optimization for control with Performance and Parameter Sensitivity Indices" Ph.D. Dissertation, Case Western Reserve Univ., Cleveland
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou W, 2007, INT GEOSCI REMOTE SE, P1889, DOI 10.1109/IGARSS.2007.4423193
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   JAFFE JS, 1990, IEEE J OCEANIC ENG, V15, P101, DOI 10.1109/48.50695
   Johnsen S, 2004, BIOL BULL-US, V207, P1, DOI 10.2307/1543624
   Kocak DM, 2008, MAR TECHNOL SOC J, V42, P52, DOI 10.4031/002533208786861209
   Li X., 2002, INT C IM PROC ICIP, pI, DOI 10.1109/ICIP.2002.1038057
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Narasimhan SG, 2005, IEEE I CONF COMP VIS, P420
   Narasimhan SG, 2002, LECT NOTES COMPUT SC, V2352, P148
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   QIU S, 2015, OCEANS 15 MTS IEEE W, P1
   Queiroz-Neto JP, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P170, DOI 10.1109/SIBGRA.2004.1352958
   Sánchez-Ferreira C, 2015, IEEE C EVOL COMPUTAT, P243, DOI 10.1109/CEC.2015.7256898
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Trucco E, 2006, IEEE J OCEANIC ENG, V31, P511, DOI 10.1109/JOE.2004.836395
   Wang X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P467, DOI 10.1109/CISP.2008.371
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
NR 40
TC 17
Z9 19
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 363
EP 373
DI 10.1016/j.jvcir.2018.06.018
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100030
DA 2024-07-18
ER

PT J
AU Nikan, S
   Ahmadi, M
AF Nikan, Soodeh
   Ahmadi, Majid
TI A modified technique for face recognition under degraded conditions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Global based; Block based; Decision fusion
ID ILLUMINATION-INVARIANT; PARALLEL FRAMEWORK; BINARY PATTERNS; ROBUST;
   IMAGE; SUPERRESOLUTION; REPRESENTATION; CLASSIFICATION; NORMALIZATION;
   COMPENSATION
AB In this paper an improved face recognition algorithm under degrading conditions is proposed. The proposed algorithm uses a combination of preprocessing techniques coupled with discriminative feature extractors to obtain the best distinctive features for classification. Preprocessing approach is the fusion of multi-scale Weber and enhanced complex wavelet transform. Combination of multiple feature extraction based on Gabor filters, block-based local phase quantization (LPQ) coupled with principal component analysis (PCA) proved to be very effective to improve correct rate of recognition. We have also used two known classifiers, extreme learning machine (ELM), and sparse classifier (SC), and fused their outputs to obtain best recognition rate. Experimental results show improved performance of proposed algorithm under poor illumination, partial occlusion and low-quality images in uncontrolled conditions. Our best recognition results using second version of face recognition grand challenge (FRGC 2.0.4) which is the most challenging database, indicated more than 28% improvement over previous works. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Nikan, Soodeh; Ahmadi, Majid] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 University of Windsor
RP Nikan, S (corresponding author), Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
EM nikan@uwindsor.ca; ahmadi@uwindsor.ca
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2005, P IEEE INT C IM PROC
   [Anonymous], 2007, 0749 U MASS
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Baradarani A, 2013, PATTERN RECOGN, V46, P57, DOI 10.1016/j.patcog.2012.06.007
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   Charoenpong T., 2010, INT C KNOWL SMART TE, P24
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Choi DY, 2017, J VIS COMMUN IMAGE R, V48, P1, DOI 10.1016/j.jvcir.2017.05.013
   Derrac J, 2014, INFORM SCIENCES, V260, P98, DOI 10.1016/j.ins.2013.10.038
   El Aroussi M, 2011, SIGNAL PROCESS, V91, P38, DOI 10.1016/j.sigpro.2010.06.005
   Emadi M, 2012, PROCEDIA ENGINEER, V41, P854, DOI 10.1016/j.proeng.2012.07.254
   Fathi A, 2016, J VIS COMMUN IMAGE R, V38, P65, DOI 10.1016/j.jvcir.2016.02.010
   Fookes C, 2012, J VIS COMMUN IMAGE R, V23, P75, DOI 10.1016/j.jvcir.2011.06.004
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jain A.K., 1988, Fundamentals of Digital Image Processing, V1st
   Jayaraman S., 2009, DIGITAL IMAGE PROCES
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Kanan HR, 2008, PATTERN RECOGN, V41, P3799, DOI 10.1016/j.patcog.2008.05.024
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Lai J, 2013, INT CONF ACOUST SPEE, P2979, DOI 10.1109/ICASSP.2013.6638204
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lee PH, 2012, IEEE T IMAGE PROCESS, V21, P4280, DOI 10.1109/TIP.2012.2202670
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Li J.B., 2014, Business Media, P19
   Li XX, 2013, IEEE T IMAGE PROCESS, V22, P1889, DOI 10.1109/TIP.2013.2237920
   Lian ZC, 2011, LECT NOTES COMPUT SC, V6855, P89, DOI 10.1007/978-3-642-23678-5_9
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu L, 2016, INFORM SCIENCES, V358, P56, DOI 10.1016/j.ins.2016.04.021
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Luan X, 2014, PATTERN RECOGN, V47, P495, DOI 10.1016/j.patcog.2013.06.031
   Ma AJ, 2014, INT J COMPUT VISION, V109, P233, DOI 10.1007/s11263-014-0723-7
   Martinez A., 1998, AR FACE DATABASE
   Mehdipour G.M., 2016, P P IEEE C COMP VIS, P34
   Mehta R, 2014, PATTERN RECOGN, V47, P1846, DOI 10.1016/j.patcog.2013.11.013
   Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8
   Nabatchian A, 2011, PATTERN RECOGN, V44, P2576, DOI 10.1016/j.patcog.2011.03.012
   Nikan S, 2015, IET IMAGE PROCESS, V9, P12, DOI 10.1049/iet-ipr.2013.0792
   Nikan S, 2012, INT C PATT RECOG, P1695
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Peng X, 2014, PATTERN RECOGN, V47, P2794, DOI 10.1016/j.patcog.2014.03.013
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pong KH, 2014, PATTERN RECOGN, V47, P556, DOI 10.1016/j.patcog.2013.08.023
   Roy H, 2016, IEEE T INF FOREN SEC, V11, P1412, DOI 10.1109/TIFS.2016.2530043
   Selesnick IW, 2004, IEEE T SIGNAL PROCES, V52, P1304, DOI 10.1109/TSP.2004.826174
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tzimiropoulos G, 2012, IEEE T PATTERN ANAL, V34, P2454, DOI 10.1109/TPAMI.2012.40
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2014, NEUROCOMPUTING, V136, P262, DOI 10.1016/j.neucom.2014.01.006
   Xian Y, 2016, J VIS COMMUN IMAGE R, V35, P91, DOI 10.1016/j.jvcir.2015.11.015
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan Y, 2014, PATTERN RECOGN, V47, P3487, DOI 10.1016/j.patcog.2014.05.004
   Yang H, 2010, INT GEOSCI REMOTE SE, P3656, DOI 10.1109/IGARSS.2010.5649032
   Yang M, 2014, PATTERN RECOGN, V47, P535, DOI 10.1016/j.patcog.2013.08.003
   Yang M, 2013, PATTERN RECOGN, V46, P1865, DOI 10.1016/j.patcog.2012.06.022
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Zang D, 2010, IEEE IMAGE PROC, P357, DOI 10.1109/ICIP.2010.5651716
   Zhang HZ, 2016, J VIS COMMUN IMAGE R, V39, P93, DOI 10.1016/j.jvcir.2016.05.013
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LG, 2014, NEUROCOMPUTING, V145, P451, DOI 10.1016/j.neucom.2014.05.008
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang WC, 2007, IEEE SIGNAL PROC LET, V14, P875, DOI 10.1109/LSP.2007.903260
NR 75
TC 6
Z9 7
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 742
EP 755
DI 10.1016/j.jvcir.2018.08.007
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100064
DA 2024-07-18
ER

PT J
AU Zhang, J
   Maniatis, C
   Horna, L
   Fisher, RB
AF Zhang, Jie
   Maniatis, Christos
   Horna, Luis
   Fisher, Robert B.
TI Dynamic 3D reconstruction improvement via intensity video guided 4D
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High-speed 3D video sensor; Multi-frame 4D fusion; Intensity tracking;
   Dynamic object; Noise reduction
ID KINECT; RECOGNITION; RESOLUTION; ALGORITHM; ACCURACY; FIELD
AB The availability of high-speed 3D video sensors has greatly facilitated 3D shape acquisition of dynamic and deformable objects, but high frame rate 3D reconstruction is always degraded by spatial noise and temporal fluctuations. This paper presents a simple yet powerful dynamic 3D reconstruction improvement algorithm based on intensity video guided multi-frame 4D fusion. Temporal tracking of intensity image points (of moving and deforming objects) allows registration of the corresponding 3D model points, whose 3D noise and fluctuations are then reduced by spatio-temporal multi-frame 4D fusion. We conducted simulated noise tests and real experiments on four 3D objects using a 1000 fps 3D video sensor. The results demonstrate that the proposed algorithm is effective at reducing 3D noise and is robust against intensity noise. It outperforms existing algorithms with good scalability on both stationary and dynamic objects.
C1 [Zhang, Jie] Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Beijing 100191, Peoples R China.
   [Zhang, Jie; Horna, Luis; Fisher, Robert B.] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland.
   [Maniatis, Christos] Univ Edinburgh, Sch Math, Edinburgh EH8 9AB, Midlothian, Scotland.
C3 Beihang University; University of Edinburgh; University of Edinburgh
RP Zhang, J (corresponding author), Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Beijing 100191, Peoples R China.
EM zhangjie09@buaa.edu.cn; rbf@inf.ed.ac.uk
RI Zhang, Jie/W-4106-2019
OI Zhang, Jie/0000-0002-5305-7911; Maniatis, Christos/0000-0002-9410-1309
FU China Scholarship Council [201606020087]; National Council for Science
   and Technology (CONACyT) of Mexico
FX This work is supported by the China Scholarship Council (No.
   201606020087), National Council for Science and Technology (CONACyT) of
   Mexico.
CR [Anonymous], 2012, AS C COMP VIS
   Garduño-Ramón MA, 2017, J VIS COMMUN IMAGE R, V47, P36, DOI 10.1016/j.jvcir.2017.05.003
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Camplani M, 2013, IEEE T CYBERNETICS, V43, P1560, DOI 10.1109/TCYB.2013.2271112
   Chen L, 2012, INT C PATT RECOG, P3070
   Dou MS, 2015, PROC CVPR IEEE, P493, DOI 10.1109/CVPR.2015.7298647
   Essmaeel K, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P47, DOI 10.1109/SITIS.2012.18
   Fu JJ, 2012, IEEE INT SYMP CIRC S, P512, DOI 10.1109/ISCAS.2012.6272078
   Guo D, 2017, J VIS COMMUN IMAGE R, V48, P491, DOI 10.1016/j.jvcir.2016.12.016
   Hasinoff SW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980254
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Mallick T, 2014, IEEE SENS J, V14, P1731, DOI 10.1109/JSEN.2014.2309987
   Matyunin S., 2011, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, P1
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Nguyen CV, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P524, DOI 10.1109/3DIMPVT.2012.84
   Park JH, 2012, SENSORS-BASEL, V12, P8640, DOI 10.3390/s120708640
   Tabata S, 2015, IEEE INT C INT ROBOT, P3900, DOI 10.1109/IROS.2015.7353926
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Urquhart C. W., 1993, ACTIVE ANIMATE STERE, P1
   Wang J, 2013, SIGNAL PROCESS, V93, P2151, DOI 10.1016/j.sigpro.2012.06.009
   Wasza J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1221, DOI 10.1109/ICCVW.2011.6130390
   Xiang J, 2015, SIGNAL PROCESS, V110, P82, DOI 10.1016/j.sigpro.2014.08.020
   Xiao Y, 2011, MACH VISION APPL, V22, P535, DOI 10.1007/s00138-010-0265-0
   Yang L, 2015, IEEE SENS J, V15, P4275, DOI 10.1109/JSEN.2015.2416651
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
NR 27
TC 5
Z9 6
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 540
EP 547
DI 10.1016/j.jvcir.2018.07.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100047
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Li, L
   Feng, XY
   Xia, ZQ
   Jiang, XY
   Hadid, A
AF Li, Lei
   Feng, Xiaoyi
   Xia, Zhaoqiang
   Jiang, Xiaoyue
   Hadid, Abdenour
TI Face spoofing detection with local binary pattern network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face spoofing detection; Deep learning; Local binary pattern
ID LIVENESS DETECTION; IMAGE; RECOGNITION; SCALE
AB Nowadays, face biometric based access control systems are becoming ubiquitous in our daily life while they are still vulnerable to spoofing attacks. So developing robust and reliable methods to prevent such frauds is unavoidable. As deep learning techniques have achieved satisfactory performances in computer vision, they have also been applied to face spoofing detection. However, the numerous parameters in these deep learning based detection methods cannot be updated to optimum due to limited data. Local Binary Pattern (LBP), effective features for face recognition, have been employed in face spoofing detection and obtained promising results. Considering the similarities between LBP extraction and convolutional neural network (CNN) that the former can be accomplished by using fixed convolutional filters, we propose a novel end-to-end learnable LBP network for face spoofing detection. Our network can significantly reduce the number of network parameters by combing learnable convolutional layers with fixed-parameter LBP layers that are comprised of sparse binary filters and derivable simulated gate functions. Compared with existing deep leaning based detection methods, the parameters in our fully connected layers are up to 64x savings. Conducting extensive experiments on two standard spoofing databases, i.e., Relay-Attack and CASIA-FA, our proposed LBP network substantially outperforms the state-of-the-art methods.
C1 [Li, Lei; Feng, Xiaoyi; Xia, Zhaoqiang; Jiang, Xiaoyue; Hadid, Abdenour] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
   [Hadid, Abdenour] Univ Oulu, Ctr Machine Vis & Signal Anal CMVS, Oulu, Finland.
C3 Northwestern Polytechnical University; University of Oulu
RP Li, L (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
EM lilei_npu@mail.nwpu.edu.cn
RI Xia, Zhaoqiang/AAC-4021-2019
OI Xia, Zhaoqiang/0000-0003-0630-3339; Li, Lei/0000-0003-4498-6126
FU National Aerospace Science and Technology Foundation; National Nature
   Science Foundation of China [61702419]
FX This work is partly supported by the National Aerospace Science and
   Technology Foundation and the National Nature Science Foundation of
   China (No. 61702419).
CR Abdur R., 2013, Global Journal of Computer Science and Technology, V13, P1
   Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Agarwal A., 2016, 2016 IEEE 8 INT C BI, P1, DOI DOI 10.1109/BTAS.2016.7791171
   Akhtar Z., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P283, DOI 10.1109/BTAS.2012.6374590
   Anjos Andre, 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], AS C PATT REC
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2015, BRIT MACH VIS C BMVC
   [Anonymous], 2015, ACM INT C MULT, DOI DOI 10.1145/2733373.2807412
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 1995, Backpropagation: theory, architectures, and applications
   [Anonymous], ABS14091556 COMP RES
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Boulkenafet Z, 2016, INT CONF BIOMETR
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chingovska Ivana, 2012, BIOSIG
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Courbariaux M, 2015, ADV NEUR IN, V28
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hubara I, 2016, ADV NEUR IN, V29
   Ji Z, 2016, IEEE IMAGE PROC, P1474, DOI 10.1109/ICIP.2016.7532603
   Juefei-Xu F, 2017, PROC CVPR IEEE, P4284, DOI 10.1109/CVPR.2017.456
   KARSON CN, 1983, BRAIN, V106, P643, DOI 10.1093/brain/106.3.643
   Kim S, 2014, SENSORS-BASEL, V14, P22471, DOI 10.3390/s141222471
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Komulainen J, 2013, INT CONF BIOMETR
   Kose N, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1027, DOI 10.1109/ICIEV.2012.6317336
   Li H., 2016, IEEE, P1, DOI DOI 10.1109/IPTA.2016.7821027
   Li L, 2016, INT CONF IMAG PROC
   Li Y., 2014, P 9 ACM S INFORM COM, P413
   Li Y., 2009, STUDY LEAVES PHENOLO, P1, DOI [10.1109/CCPR.2009.5344092., DOI 10.1109/CCPR.2009.5344092]
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P2352, DOI 10.1109/TIP.2017.2678163
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Nesli Erdogmus, 2013, IEEE 6 INT C BIOM TH, P1, DOI 10.1109/BTAS.2013.6712688
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Omar L., 2015, 7 UK BRIT MACHINE VI, V5, P1, DOI DOI 10.5244/C.29.BMVW.5
   Pan G, 2011, TELECOMMUN SYST, V47, P215, DOI 10.1007/s11235-010-9313-3
   Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Phan QT, 2016, IEEE IMAGE PROC, P404, DOI 10.1109/ICIP.2016.7532388
   Sepas-Moghaddam A, 2017, IEEE IMAGE PROC, P3815, DOI 10.1109/ICIP.2017.8296996
   Smith DF, 2015, IEEE T INF FOREN SEC, V10, P736, DOI 10.1109/TIFS.2015.2398819
   Smith S.W., 1997, SCI ENG GUIDE DIGITA
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Xia ZQ, 2018, IET BIOMETRICS, V7, P56, DOI 10.1049/iet-bmt.2017.0193
   Xia ZQ, 2017, SIGNAL PROCESS-IMAGE, V59, P109, DOI 10.1016/j.image.2017.06.008
   Yang J, 2014, ADV MATER RES-SWITZ, V850-851, P373, DOI 10.4028/www.scientific.net/AMR.850-851.373
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 66
TC 42
Z9 45
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 182
EP 192
DI 10.1016/j.jvcir.2018.05.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800016
DA 2024-07-18
ER

PT J
AU Pagés, R
   Amplianitis, K
   Monaghan, D
   Ondrej, J
   Smolic, A
AF Pages, R.
   Amplianitis, K.
   Monaghan, D.
   Ondrej, J.
   Smolic, A.
TI Affordable content creation for free-viewpoint video and VR/AR
   applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Free-viewpoint video; 3D reconstruction; Texturing; View synthesis;
   Augmented reality; Virtual reality
ID IMAGE; ERROR; SPACE
AB We present a scalable pipeline for Free-Viewpoint Video (FVV) content creation, considering also visualisation in Augmented Reality (AR) and Virtual Reality (VR). We support a range of scenarios where there may be a limited number of handheld consumer cameras, but also demonstrate how our method can be applied in professional multi-camera setups. Our novel pipeline extends many state-of-the-art techniques (such as structure-from-motion, shape-from-silhouette and multi-view stereo) and incorporates bio-mechanical constraints through 3D skeletal information as well as efficient camera pose estimation algorithms. We introduce multi-source shape-from-silhouette (MS-SfS) combined with fusion of different geometry data as crucial components for accurate reconstruction in sparse camera settings. Our approach is highly flexible and our results indicate suitability either for affordable content creation for VR/AR or for interactive FVV visualisation where a user can choose an arbitrary viewpoint or sweep between known views using view synthesis.
C1 [Pages, R.; Amplianitis, K.; Monaghan, D.; Ondrej, J.; Smolic, A.] Trinity Coll Dublin, Sch Comp Sci & Stat, V SENSE, Dublin, Ireland.
C3 Trinity College Dublin
RP Amplianitis, K (corresponding author), Trinity Coll Dublin, Sch Comp Sci & Stat, V SENSE, Dublin, Ireland.
EM kostampl@gmail.com
RI Pages, Rafael/AGP-5586-2022; Ondrej, Jan/N-1947-2016
OI Pages, Rafael/0000-0002-5691-9580; Ondrej, Jan/0000-0002-5409-1521;
   Smolic, Aljosa/0000-0001-7033-3335
FU Science Foundation Ireland (SFI) [15/RP/2776]
FX This publication has emanated from research conducted with the financial
   support of Science Foundation Ireland (SFI) under the Grant No.
   15/RP/2776.
CR Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Angehrn F, 2014, IEEE IMAGE PROC, P3474, DOI 10.1109/ICIP.2014.7025705
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Ballan Luca, 2010, ACM SIGGRAPH 2010 papers
   Botsch M., 2010, Polygon Mesh Processing
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Collet A, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766945
   Croci S., 2013, VISION MODELING VISU
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Grogan M., 2017, ARXIV E PRINTS
   Grognot M., 2015, 2015 40th International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), P1, DOI 10.1109/IRMMW-THz.2015.7327838
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Hayashi K., 2006, INT C COMPUTER GRAPH, P220
   Hengshuang Z., 2017, P IEEE C COMP VIS PA
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kang SB, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P13, DOI 10.1109/ICIP.2000.899212
   Kazhdan M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487237
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lepetit Vincent., 2008, International Journal of Computer Vision
   Lipski C, 2010, COMPUT GRAPH FORUM, V29, P2555, DOI 10.1111/j.1467-8659.2010.01824.x
   Lipski C, 2014, IEEE T CIRC SYST VID, V24, P942, DOI 10.1109/TCSVT.2014.2302379
   Liu YB, 2010, IEEE T VIS COMPUT GR, V16, P407, DOI 10.1109/TVCG.2009.88
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maerki N., 2016, IEEE C COMP VIS PATT
   Moran F., 2016, FAST FEATURE MATCHIN, P1, DOI DOI 10.1109/IPTA.2016.7820978
   Mouton P., 2016, REPR RES PATT REC 1, P60
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Mustafa A, 2016, PROC CVPR IEEE, P4660, DOI 10.1109/CVPR.2016.504
   Pagés R, 2015, COMPUT GRAPH FORUM, V34, P228, DOI 10.1111/cgf.12508
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Popa T., 2014, COMPUTER VISION SPOR, P133
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   Slabaugh GG, 2003, REAL-TIME IMAGING, V9, P347, DOI 10.1016/j.rti.2003.08.004
   Smolic A, 2011, PATTERN RECOGN, V44, P1958, DOI 10.1016/j.patcog.2010.09.005
   Starck Jonathan, 2006, P BRIT MACH VIS C, P1189
   Teichman Alex., 2013, IEEE Transactions on Automation Science and Engineering
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 45
TC 32
Z9 33
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 192
EP 201
DI 10.1016/j.jvcir.2018.03.012
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800018
DA 2024-07-18
ER

PT J
AU Jiang, GY
   Liu, SS
   Yu, M
   Shao, F
   Peng, ZJ
   Chen, F
AF Jiang, Gangyi
   Liu, Shanshan
   Yu, Mei
   Shao, Feng
   Peng, Zongju
   Chen, Fen
TI No reference stereo video quality assessment based on motion feature in
   tensor decomposition domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No reference stereo video quality assessment; Tensor decomposition;
   Motion feature; Entropy; Random forest
AB A no reference stereo video quality assessment method based on motion features extracted in tensor decomposition domain is proposed. Tensor decomposition is used to reduce dimension of color, view and time of stereo video, and motion information maps containing time-varying information of inter-views and intra-views are obtained. Statistical features such as generalized Gaussian distribution (GGD), asymmetric GGD, spatial entropy, spectral entropy associated with two views, and spectral entropy related to depth perception of stereo video, are extracted. Random forest is utilized to establish relationship between stereo video quality and the extracted features. Experimental results on NAM.A3DS1-COSPAD1 database demonstrate that the proposed method achieves good performance on JP2K, resolution reduction, sharpening and their combination distortions, Pearson linear correlation coefficient (PLCC) values of these types of distortions are higher than 0.97, while for H.264 distortion the PLCC value is 0.8850, which means that the proposed metric is consistent with human visual perception.
C1 [Jiang, Gangyi; Liu, Shanshan; Yu, Mei; Shao, Feng; Peng, Zongju; Chen, Fen] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
   [Jiang, Gangyi; Yu, Mei] Nanjing Univ, Natl Key Lab Software New Technol, Nanjing, Jiangsu, Peoples R China.
C3 Ningbo University; Nanjing University
RP Jiang, GY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
EM jianggangyi@126.com
RI Chen, Fen/ABG-7013-2021; jiang, gang/KII-8233-2024; Wang,
   Shan/JPX-1098-2023; Wang, Yunwen/KBR-2884-2024; liu,
   shanshan/JPA-0852-2023; Peng, Zongju/AAA-2914-2020
OI Wang, Yunwen/0009-0008-3083-7799; Peng, Zongju/0000-0001-8286-538X
FU Natural Science Foundation of China [U1301257, 61671258, 61620106012];
   National High-tech R&D Program of China [2015AA015901]; Natural Science
   Foundation of Zhejiang Province [LY15F010005, LY16F010002]; K.C. Wong
   Magna Fund in Ningbo University
FX This work was supported by the Natural Science Foundation of China under
   Grant nos. U1301257 and 61671258, and 61620106012, the National
   High-tech R&D Program of China under Grant no. 2015AA015901, and the
   Natural Science Foundation of Zhejiang Province under Grant nos.
   LY15F010005 and LY16F010002. It is also sponsored by K.C. Wong Magna
   Fund in Ningbo University.
CR [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 16 INT WORKSH MULT S
   Broberg DK, 2011, P IEEE, V99, P684, DOI 10.1109/JPROC.2010.2092390
   Cong FY, 2015, J NEUROSCI METH, V248, P59, DOI 10.1016/j.jneumeth.2015.03.018
   Cui GC, 2016, IEEE INT FUZZY SYST, P2170, DOI 10.1109/FUZZ-IEEE.2016.7737961
   Galkandage C, 2017, IEEE J-STSP, V11, P102, DOI 10.1109/JSTSP.2016.2632045
   Han Y, 2014, IEEE INT SYM BROADB
   Han Y, 2016, IEEE T BROADCAST, V62, P654, DOI 10.1109/TBC.2016.2529294
   Kaya O, 2016, PROC INT CONF PARAL, P103, DOI 10.1109/ICPP.2016.19
   Lee M, 2014, IEEE T IMAGE PROCESS, V23, P4255, DOI 10.1109/TIP.2014.2346012
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Mittal A, 2016, IEEE T IMAGE PROCESS, V25, P289, DOI 10.1109/TIP.2015.2502725
   Mittal A, 2012, CONF REC ASILOMAR C, P1718, DOI 10.1109/ACSSC.2012.6489326
   Mittal A, 2011, CONF REC ASILOMAR C, P723, DOI 10.1109/ACSSC.2011.6190099
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Qiao LB, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON ADVANCED CLOUD AND BIG DATA (CBD 2016), P283, DOI [10.1109/CBD.2016.14, 10.1109/CBD.2016.056]
   Saad MA, 2012, CONF REC ASILOMAR C, P332, DOI 10.1109/ACSSC.2012.6489018
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Soundararajan R, 2013, IEEE T CIRC SYST VID, V23, P684, DOI 10.1109/TCSVT.2012.2214933
   Urvoy M, 2012, INT WORK QUAL MULTIM, P109, DOI 10.1109/QoMEX.2012.6263847
   Winkler S, 2013, SIGNAL PROCESS-IMAGE, V28, P1358, DOI 10.1016/j.image.2013.07.008
   Yu M, 2016, J VIS COMMUN IMAGE R, V38, P246, DOI 10.1016/j.jvcir.2016.03.010
   Zhang F, 2016, IEEE T CIRC SYST VID, V26, P1017, DOI 10.1109/TCSVT.2015.2428551
   Zhang J, 2016, IEEE SIGNAL PROC LET, V23, P1246, DOI 10.1109/LSP.2016.2577601
   Zhao W, 2015, 2015 IEEE ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), P523, DOI 10.1109/IAEAC.2015.7428608
NR 25
TC 25
Z9 26
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 247
EP 262
DI 10.1016/j.jvcir.2017.12.001
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700025
DA 2024-07-18
ER

PT J
AU Martínez-Rach, MO
   Peral, PP
   López-Granada, OM
   Malumbres, MP
AF Martinez-Rach, Miguel O.
   Pinol Peral, Pablo
   Lopez-Granada, Otoniel M.
   Malumbres, Manuel P.
TI Optimizing the image R/D coding performance by tuning quantization
   parameters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dead zone quantization; Image coding; Wavelet encoders; Rate distortion
   performance; Contrast Sensitivity Function; Quality assessment metrics
AB Uniform quantization schemas with dead zone are widely used in image and video codecs. The design of these quantizers affects to the final R/D performance, being two of the quantizer parameters the responsible for that variations: the dead zone size and the reconstruction point location inside each quantization step. In this work we tune the quantizer to obtain the optimum quantization parameters that provide the best R/D behavior for different quality metrics and rate ranges. Based on a representative image set, we provide the quantization parameters to encode general imagery, with a R/D performance close to the optimum one. The same study was done including the Contrast Sensitivity Function in the quantization stage. After an exhaustive experimental test, the results show that the estimated quantization parameters are able to provide bit rate savings up to 11% at low and moderate bit rates without additional computational cost.
C1 [Martinez-Rach, Miguel O.; Pinol Peral, Pablo; Lopez-Granada, Otoniel M.; Malumbres, Manuel P.] Miguel Hernandez Univ, Dept Phys & Comp Engn, Avda Univ Sn, Alicante 03202, Spain.
C3 Universidad Miguel Hernandez de Elche
RP Martínez-Rach, MO (corresponding author), Miguel Hernandez Univ, Dept Phys & Comp Engn, Avda Univ Sn, Alicante 03202, Spain.
EM mmrach@umh.es; pablop@umh.es; otoniel@umh.es; mels@umh.es
RI Malumbres, Manuel Perez/D-2669-2009; Martinez-Rach, Miguel
   Onofre/C-8339-2012; Lopez Granado, Otoniel Mario/B-2121-2012; Pinol,
   Pablo/E-9100-2015
OI Malumbres, Manuel Perez/0000-0001-6493-5057; Martinez-Rach, Miguel
   Onofre/0000-0001-7071-8921; Lopez Granado, Otoniel
   Mario/0000-0002-6968-061X; Pinol, Pablo/0000-0003-3510-1891
FU Spanish Ministry of Economy and Competitiveness [TIN2015-66972-C5-4-R];
   FEDER funds (MINECO-/FEDER/UE)
FX This research was supported by the Spanish Ministry of Economy and
   Competitiveness under Grant TIN2015-66972-C5-4-R, co-financed by FEDER
   funds. (MINECO-/FEDER/UE)
CR [Anonymous], 2007, P 3 INT WORKSH VID P
   [Anonymous], 4 INT WORKSH VID PRO
   Beegan AP, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P88, DOI 10.1109/DSPWS.2002.1231082
   Bjontegaard G., 2001, VCEG M ITUT SG16 Q 6
   Bjontegaard G., 2008, VCEG M BERL GERM JUL
   Chikkerur S, 2011, IEEE T BROADCAST, V57, P165, DOI 10.1109/TBC.2011.2104671
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Girod Bernd, 1993, P207
   M.V.P. Group, 2013, VQMT VID QUAL MEAS T
   Machiraju R., 1997, COMPUT GRAPH FORUM, P241
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Marcellin M. W., 2002, JPEG2000 IMAGE COMPR, V1
   Marcellin MW, 2002, SIGNAL PROCESS-IMAGE, V17, P73, DOI 10.1016/S0923-5965(01)00027-3
   Martinez-Rach M., 2006, 8 IEEE INT S MULT ST, V1, P517
   Martinez-Rach M.O., 2017, P DAT COMPR C DCC
   Martnez-Rach M.O., 2014, THESIS
   Moumkine N., 2006, P 2 INT S COM CONTR
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   Notebaert S., 2009, 2009 PICT COD S, P1
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Tao B, 2001, IEEE T CIRC SYST VID, V11, P560, DOI 10.1109/76.915362
   Taubman D.S., 2001, JPEG 2000: Image Compression Fundamentals, Standards and Practice
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wedi T, 2005, IEEE INT SYMP CIRC S, P324, DOI 10.1109/ISCAS.2005.1464590
   Ya JH, 2004, 2004 INTERNATIONAL CONFERENCE ON COMMUNICATION, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P805, DOI 10.1109/ICCCAS.2004.1346303
NR 25
TC 1
Z9 2
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 274
EP 282
DI 10.1016/j.jvcir.2017.09.015
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800022
DA 2024-07-18
ER

PT J
AU Safavi, SH
   Torkamani-Azar, F
AF Safavi, Seyed Hamid
   Torkamani-Azar, Farah
TI Cube-based perceptual weighted Kronecker Compressive Sensing: Can we
   avoid non-visible redundancies acquisition?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multidimensional signal; Kronecker Compressive Sensing; Weighted
   Compressive Sensing; Perceptual compressive sensing
ID IMAGE QUALITY ASSESSMENT; SPARSE DECOMPOSITION; FIDELITY-CRITERION;
   INFORMATION
AB Compressive sensing approach directly avoids the acquisition of statistical redundancies of a signal. However, perceptual redundancies of images and videos due to the human eye sensitivity are not considered so far. Besides, an effective sampling scheme is needed to multidimensional signal reconstruction using a low number of measurements to avoid all redundancies. In this paper, along with the Kronecker structure of the sampling matrix we design various weighting matrices based on the spatio-temporal contrast sensitivity function to avoid acquisition of non-visible redundancies. Moreover, inspired by the block-based compressive sensing, we divide a group of pictures in a video sequence into cubes. Hence, the size of measurement and sparsifying basis matrices are reduced and the reconstruction algorithm can be implemented in parallel. We further show that our simple linear sampling approach can be competitive with motion compensation method. Simulation results verify that our proposed method notably outperforms the other state-of-the-art methods. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Safavi, Seyed Hamid; Torkamani-Azar, Farah] Shahid Beheshti Univ, Dept Elect Engn, Cognit Commun Res Grp, Tehran, Iran.
C3 Shahid Beheshti University
RP Torkamani-Azar, F (corresponding author), Shahid Beheshti Univ, Dept Elect Engn, Cognit Commun Res Grp, Tehran, Iran.
EM h_safavi@sbu.ac.ir; f-torkamani@sbu.ac.ir
RI Hamid, Seyed/B-7187-2014
OI Hamid, Seyed/0000-0001-7833-7381
CR Abaei N., 2017, IEEE INT C AC SPEECH
   [Anonymous], BT50011 ITUR
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chartrand R, 2008, INT CONF ACOUST SPEE, P3869, DOI 10.1109/ICASSP.2008.4518498
   Chen G, 2016, SIGNAL PROCESS, V119, P1, DOI 10.1016/j.sigpro.2015.06.027
   CHITPRASERT B, 1990, IEEE T COMMUN, V38, P1040, DOI 10.1109/26.57501
   Ciocoiu IB, 2015, CIRC SYST SIGNAL PR, V34, P1001, DOI 10.1007/s00034-014-9878-2
   Daly S, 1998, P SOC PHOTO-OPT INS, V3299, P180, DOI 10.1117/12.320110
   Daly Scott, 1993, P179
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Duarte MF, 2011, IEEE T SIGNAL PROCES, V59, P4053, DOI 10.1109/TSP.2011.2161982
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Friedland S, 2014, IEEE T IMAGE PROCESS, V23, P4438, DOI 10.1109/TIP.2014.2348796
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Ghaffari A, 2009, INT CONF ACOUST SPEE, P3157, DOI 10.1109/ICASSP.2009.4960294
   Jokar S, 2009, LINEAR ALGEBRA APPL, V431, P2437, DOI 10.1016/j.laa.2009.08.005
   Dinh KQ, 2015, IEEE IMAGE PROC, P2065, DOI 10.1109/ICIP.2015.7351164
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Ngan K. N., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V707, P165, DOI 10.1117/12.937262
   NILL NB, 1985, IEEE T COMMUN, V33, P551, DOI 10.1109/TCOM.1985.1096337
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Safavi S.H., 2017, 42 IEEE INT IN PRESS
   Safavi S.H., 2017, 25 IR C EL IN PRESS
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sidiropoulos ND, 2012, IEEE SIGNAL PROC LET, V19, P757, DOI 10.1109/LSP.2012.2210872
   Wang CY, 2001, SIGNAL PROCESS-IMAGE, V16, P501, DOI 10.1016/S0923-5965(00)00012-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson A.B., 1993, SID INT S, V24, P946
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Yang J., 2016, MULTIMED TOOLS APPL, P1
   Yang Y, 2009, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2009.5202443
NR 41
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 338
EP 350
DI 10.1016/j.jvcir.2017.08.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800028
DA 2024-07-18
ER

PT J
AU Shu, X
   Qiu, J
AF Shu, Xin
   Qiu, Jing
TI Speed up kernel dependence maximization for multi-label feature
   extraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-label dimensionality reduction; Dependence maximization; Least
   squares; Hilbert-Schmidt independence criterion
ID LEAST-SQUARES FORMULATION; DISCRIMINANT-ANALYSIS; CLASSIFICATION;
   ALGORITHMS; FAMILY; SCENE
AB Kernel dependence maximization for multi-label dimensionality reduction (kMDDM) has been proposed recently to cope with high-dimensional multi-label data. In order to produce discriminant projection vectors, kMDDM utilize the Hilbert-Schmidt independence criterion to capture the dependence between the feature description and the associated labels. However, the computation of kMDDM involves dense matrices eigen-decomposition that is known to be computationally expensive for large scale problems. In this paper, we reformulate the original kMDDM as a least-squares problem, so as to significantly lessen computational burden by utilizing the conjugate gradient algorithms. Further, appealing regularization techniques can be incorporated into the least-squares model to boost the generalization performance. Extensive experiments conducted on benchmark data collections verify the effectiveness of our proposed model.
C1 [Shu, Xin] Nanjing Agr Univ, Coll Informat Sci & Technol, Nanjing 210095, Jiangsu, Peoples R China.
   [Qiu, Jing] Suzhou Univ Sci & Technol, Suzhou, Peoples R China.
C3 Nanjing Agricultural University; Suzhou University of Science &
   Technology
RP Shu, X (corresponding author), Nanjing Agr Univ, Coll Informat Sci & Technol, Nanjing 210095, Jiangsu, Peoples R China.
EM xinshu@outlook.com
FU National Natural Science Foundation of China [61602248]; Natural Science
   Foundation of Jiangsu Province [BK20160741]; Fundamental Research Funds
   for the Central Universities [KYZ201549]
FX This work was supported by the National Natural Science Foundation of
   China (Grants No. 61602248), the Natural Science Foundation of Jiangsu
   Province (Grant No. BK20160741) and the Fundamental Research Funds for
   the Central Universities (No. KYZ201549).
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   [Anonymous], 2014, INT C MACH LEARN
   [Anonymous], 2007, INT J DATA WAREHOUSI
   [Anonymous], 2009, NIPS
   [Anonymous], P 22 ACM SIGKDD INT
   [Anonymous], 2016, ARXIV160405449
   [Anonymous], MULTILABEL LINEAR DI
   [Anonymous], RANDOM K LABELSETS E
   Bach FR, 2003, J MACH LEARN RES, V3, P1, DOI 10.1162/153244303768966085
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Barutcuoglu Z, 2006, BIOINFORMATICS, V22, P830, DOI 10.1093/bioinformatics/btk048
   Bhatia K, 2015, 29 ANN C NEURAL INFO, V28
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Crammer K, 2003, J MACH LEARN RES, V3, P1025, DOI 10.1162/153244303322533188
   De Comité F, 2003, LECT NOTES ARTIF INT, V2734, P35
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Elisseeff A, 2002, ADV NEUR IN, V14, P681
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fürnkranz J, 2002, J MACH LEARN RES, V2, P721, DOI 10.1162/153244302320884605
   Gretton A, 2005, LECT NOTES ARTIF INT, V3734, P63
   Guillaumin M, 2010, PROC CVPR IEEE, P902, DOI 10.1109/CVPR.2010.5540120
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Luo Y, 2013, IEEE T NEUR NET LEAR, V24, P709, DOI 10.1109/TNNLS.2013.2238682
   Madjarov G, 2012, PATTERN RECOGN, V45, P3084, DOI 10.1016/j.patcog.2012.03.004
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Money JH, 2005, ACM T MATH SOFTWARE, V31, P270, DOI 10.1145/1067967.1067973
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   PAIGE CC, 1982, ACM T MATH SOFTWARE, V8, P43, DOI 10.1145/355984.355989
   Park CH, 2008, PATTERN RECOGN LETT, V29, P878, DOI 10.1016/j.patrec.2008.01.003
   Park S, 2013, PATTERN RECOGN LETT, V34, P292, DOI 10.1016/j.patrec.2012.10.016
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Roth V, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-S2-S12
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Shu X, 2015, NEUROCOMPUTING, V168, P356, DOI 10.1016/j.neucom.2015.05.090
   Shu X, 2015, NEUROCOMPUTING, V156, P221, DOI 10.1016/j.neucom.2014.12.057
   Spyromitros E, 2008, LECT NOTES ARTIF INT, V5138, P401, DOI 10.1007/978-3-540-87881-0_40
   Stewart G. W., 1998, MATRIX ALGORITHMS, V1
   STEWART G. W., 2001, Eigensystems, VII
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun LA, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1230
   Sun Liang., 2009, Proceedings o f the Twenty-Sixth International Conference on Machine Learning (ICML 2009), P977, DOI DOI 10.1145/1553374.1553499
   Tai F, 2012, NEURAL COMPUT, V24, P2508, DOI 10.1162/NECO_a_00320
   Tang L., 2009, P 18 INT C WORLD WID, P211
   Ueda N., 2002, ADV NEURAL INFORMATI, P721
   Wen ZW, 2013, MATH PROGRAM, V142, P397, DOI 10.1007/s10107-012-0584-1
   Wieczorkowska A, 2006, ADV SOFT COMP, P307
   Wold H., 1985, Partial least squares
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Ye JP, 2005, J MACH LEARN RES, V6, P483
   You S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3336
   Yu K., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P258, DOI 10.1145/1076034.1076080
   Zha ZJ, 2009, J VIS COMMUN IMAGE R, V20, P97, DOI 10.1016/j.jvcir.2008.11.009
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhang ML, 2006, IEEE T KNOWL DATA EN, V18, P1338, DOI 10.1109/TKDE.2006.162
   Zhang Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1839490.1839495
NR 58
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 361
EP 370
DI 10.1016/j.jvcir.2017.10.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800030
DA 2024-07-18
ER

PT J
AU Sangnoree, A
   Chamnongthai, K
AF Sangnoree, Apiwat
   Chamnongthai, Kosin
TI Thermal-image processing and statistical analysis for vehicle category
   in nighttime traffic
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Thermal imaging; Vehicle category; Nighttime traffic; Traffic
   monitoring; ITS
ID TRACKING
AB The automatic tollgate at highway entrance and exit needs to categorize vehicle in order to collect highway passing fee especially at night time. This paper proposes a method of vehicle categorization in nighttime traffic using thermal-image processing and statistical analysis. To recognize the vehicular types, statistical relation between thermal features of engine heat, windscreen and others are utilized in this method. Firstly, appropriate threshold values for classifying the thermal features are automatically determined, entire area of the thermal image is then divided into blocks, and thermal features classified in all blocks by the threshold values are finally integrated for vehicle type categorization. To evaluate the performance of proposed method, experiments with 2937 samples of cars, vans and trucks are categorized, and the results approximately reveal 95.51% accuracy. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Sangnoree, Apiwat; Chamnongthai, Kosin] King Mongkuts Univ Technol Thonburi, Fac Engn, Dept Elect & Telecommun Engn, 126 Pracha Uthit Rd, Bangkok 10140, Thailand.
C3 King Mongkuts University of Technology Thonburi
RP Chamnongthai, K (corresponding author), King Mongkuts Univ Technol Thonburi, Fac Engn, Dept Elect & Telecommun Engn, 126 Pracha Uthit Rd, Bangkok 10140, Thailand.
EM apiwat_san@utcc.ac.th; kosin.cha@kmutt.ac.th
RI Chamnongthai, Kosin/AEX-9479-2022
OI Chamnongthai, Kosin/0000-0003-1509-5754
CR [Anonymous], 2009, MATLAB 7 8 0 R2009A
   [Anonymous], 2006, 22 INT C DAT ENG WOR
   Astapov S, 2013, INT J ELECTRON TELEC, V59, P151, DOI 10.2478/eletel-2013-0018
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Bi LZ, 2009, IEEE T INTELL TRANSP, V10, P155, DOI 10.1109/TITS.2008.2011719
   Boyd J. E., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P163, DOI 10.1109/ICCV.1999.791213
   Chen YL, 2006, INT C PATT RECOG, P687
   Cucchiara R., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P119, DOI 10.1109/6979.880969
   Daiheng N., 2008, IEEE T INTELL TRANSP, V8, P181
   Faitih P., 2004, IEEE INT VEH S GOLD, P188
   Fan ZM, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P625, DOI 10.1109/ICIP.2002.1039048
   Fan ZM, 2002, IEEE 5TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, PROCEEDINGS, P84, DOI 10.1109/ITSC.2002.1041193
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Kanai H., 2005, P IEEE INSTR MEAS TE, V3, P1680
   Ko H, 2003, IEICE T INF SYST, VE86D, P1887
   Kung S. Y., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P430, DOI 10.1109/ICIP.1995.529738
   Lai AHS, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P201, DOI 10.1109/ITSC.2001.948656
   Lee I, 2002, INT CONF ACOUST SPEE, P3712
   Lin HY, 2008, IMAGE VISION COMPUT, V26, P1327, DOI 10.1016/j.imavis.2007.04.004
   Oh C, 2007, IEEE T INTELL TRANSP, V8, P460, DOI 10.1109/TITS.2007.899720
   Pang CCC, 2007, IEEE T INTELL TRANSP, V8, P441, DOI 10.1109/TITS.2007.902647
   Paragios N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P688, DOI 10.1109/ICCV.1999.791292
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Ramachandran RP, 2002, INT CONF ACOUST SPEE, P3840
   Sangnoree A., 2009, NICOGRAPH INT C, P131
   Sangnoree A., 2010, NICOGRAPH INT C, P124
   Sangnoree A., 2008, NICOGRAPH INT C, P133
   Sangnoree A, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P467, DOI 10.1109/ICCIT.2009.186
   Sarignoree A, 2008, 2008 8TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS, PROCEEDINGS, P150
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Thi TH, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P422, DOI 10.1109/CISP.2008.424
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang C.C.R, 2005, 18 IPPR C COMP VIS G, P1813
   Xia YJ, 2015, NEUROCOMPUTING, V151, P700, DOI 10.1016/j.neucom.2014.05.091
   Yoshida T, 2002, IEICE T INF SYST, VE85D, P1745
   Zhao N, 2016, J VIS COMMUN IMAGE R, V37, P25, DOI 10.1016/j.jvcir.2015.04.011
NR 37
TC 11
Z9 12
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 88
EP 109
DI 10.1016/j.jvcir.2017.06.006
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700008
DA 2024-07-18
ER

PT J
AU Tang, MF
   Nie, FP
   Pongpaichet, S
   Jain, R
AF Tang, Mengfan
   Nie, Feiping
   Pongpaichet, Siripen
   Jain, Ramesh
TI Semi-supervised learning on large-scale geotagged photos for situation
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Evolving situations; Semi-supervised learning; New label discovery;
   l(1)-norm; Capped norm; Outlier elimination
AB Photos are becoming spontaneous, objective, and universal sources of information. This paper explores evolving situation recognition using photo streams coming from disparate sources combined with the advances of deep learning. Using visual concepts in photos together with space and time information, we formulate the situation detection into a semi-supervised learning framework and propose new graph-based models to solve the problem. To extend the method for unknown situations, we introduce a soft label method that enables the traditional semi-supervised learning framework to accurately predict predefined labels as well as effectively form new clusters. To overcome the noisy data which degrades graph quality, leading to poor recognition results, we take advantage of two kinds of noise-robust norms which can eliminate the adverse effects of outliers in visual concepts and improve the accuracy of situation recognition. Finally, we demonstrate the idea and the effectiveness of the proposed models on Yahoo Flickr Creative Commons 100 Million. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Tang, Mengfan; Jain, Ramesh] Univ Calif Irvine, Dept Comp Sci, Irvine, CA USA.
   [Nie, Feiping] Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.
   [Nie, Feiping] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian, Shaanxi, Peoples R China.
   [Pongpaichet, Siripen] Mahidol Univ, Fac Informat & Commun Technol, Phutthamonthon, Thailand.
C3 University of California System; University of California Irvine;
   Northwestern Polytechnical University; Northwestern Polytechnical
   University; Mahidol University
RP Nie, FP (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian, Shaanxi, Peoples R China.; Nie, FP (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian, Shaanxi, Peoples R China.
EM mengfant@uci.edu; feipingnie@gmail.com; siripen.pon@mahidol.ac.th;
   jain@ics.uci.edu
RI Nie, Feiping/B-3039-2012
OI Nie, Feiping/0000-0002-0871-6519
CR [Anonymous], WWW
   [Anonymous], 1 MONDAY
   [Anonymous], 2003, ICML
   [Anonymous], ICML
   [Anonymous], IEEE AER EL C
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   Chang S.-F., 2007, P INT WORKSHOP WORKS, P255, DOI DOI 10.1145/1290082.1290118
   Jain R, 2015, IEEE MULTIMEDIA, V22, P66, DOI 10.1109/MMUL.2015.60
   Jin X., 2010, ACM Multimedia
   Lu XQ, 2017, IEEE T CYBERNETICS, V47, P884, DOI 10.1109/TCYB.2016.2531179
   Lu XQ, 2017, IEEE T IMAGE PROCESS, V26, P355, DOI 10.1109/TIP.2016.2627801
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Lu XQ, 2014, IEEE T CYBERNETICS, V44, P149, DOI 10.1109/TCYB.2013.2286496
   Lu XQ, 2013, IEEE T CIRC SYST VID, V23, P2022, DOI 10.1109/TCSVT.2013.2244798
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2010, NEURAL COMPUT APPL, V19, P549, DOI 10.1007/s00521-009-0305-8
   Pongpaichet S., 2016, ICMR
   Tang HY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS 2016), P1, DOI 10.1109/QRS.2016.11
   Tang M., 2016, ACM MULTIMEDIA
   Tang M., 2016, Proceedings of the 2016 ACM on Multimedia Conference, P938, DOI DOI 10.1145/2964284.2976761
   Tang MF, 2017, IEEE T MULTIMEDIA, V19, P408, DOI 10.1109/TMM.2016.2613639
   Tang MF, 2017, NEUROCOMPUTING, V225, P58, DOI 10.1016/j.neucom.2016.11.012
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Wang M, 2017, IEEE T KNOWL DATA EN, V29, P1101, DOI 10.1109/TKDE.2017.2654445
   Wang M, 2016, IEEE T KNOWL DATA EN, V28, P1864, DOI 10.1109/TKDE.2016.2535367
   Yang M., 2011, CVPR
   Ye GB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082146
NR 27
TC 5
Z9 5
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 310
EP 316
DI 10.1016/j.jvcir.2017.07.005
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700024
DA 2024-07-18
ER

PT J
AU Huang, DY
   Chen, CH
   Chen, TY
   Hu, WC
   Feng, KW
AF Huang, Deng-Yuan
   Chen, Chao-Ho
   Chen, Tsong-Yi
   Hu, Wu-Chih
   Feng, Kai-Wei
TI Vehicle detection and inter-vehicle distance estimation using
   single-lens video camera on urban/suburb roads
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vehicle detection; Inter-vehicle distance estimation; Background
   subtraction; Histogram of oriented gradient (HOG); Support vector
   machine (SVM)
ID TRACKING; SYSTEM
AB This paper presents a driver assistance system for vehicle detection and inter-vehicle distance estimation using a single-lens video camera on urban/suburb roads. The task of vehicle detection on urban/suburb roads is more challenging due to their high scene complexity. In this work, the still area of frame inside the host vehicle is first removed using temporal differencing, followed by detecting vanishing point. Segmentation of road regions is then conducted using vanishing point and road's edge lines. Shadow regions at the bottoms of vehicles verified using the HOG feature and an SVM classifier are utilized to detect vehicle positions. The distances between the host and its front vehicles are estimated based on the locations of detected vehicles and vanishing point. Experimental results show varied performance of vehicle detection with different scenes of urban/suburb roads and the detection rate can achieve up to 94.08%, indicating the feasibility of the proposed method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, 168 Univ Rd, Changhua 515, Taiwan.
   [Chen, Chao-Ho; Chen, Tsong-Yi; Feng, Kai-Wei] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.
   [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Makung 880, Penghu, Taiwan.
C3 Da Yeh University; National Kaohsiung University of Science &
   Technology; National Penghu University of Science & Technology
RP Chen, CH (corresponding author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, 415 Chien Kung Rd, Kaohsiung 807, Taiwan.
EM kevin@mail.dyu.edu.tw; thouho@cc.kuas.edu.tw; chentso@cc.kuas.edu.tw;
   wchu@npu.edu.tw; 1100305149@cc.kuas.edu.tw
FU Ministry of Science and Technology, Taiwan [MOST 104-2622-E-151-015-CC3]
FX This work was partially supported by the Ministry of Science and
   Technology, Taiwan under grant MOST 104-2622-E-151-015-CC3.
CR [Anonymous], P 10 INT C AC DC POW
   Bui T. H., 2013, P 2013 ANN C SOC INS, P14
   Chang WC, 2008, IEEE SYS MAN CYBERN, P3369
   Chen CH, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON ROBOT, VISION AND SIGNAL PROCESSING (RVSP), P14, DOI 10.1109/RVSP.2015.12
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Chih-Kuo Tseng, 2012, 2012 IEEE 9th International Conference on Group IV Photonics (GFP), P1, DOI 10.1109/GROUP4.2012.6324188
   Chun C, 2013, IEEE IMAGE PROC, P3358, DOI 10.1109/ICIP.2013.6738692
   Duan-Yu Chen, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1632, DOI 10.1109/ICMLC.2012.6359610
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fang CR, 2014, SOFTWARE QUAL J, V22, P335, DOI 10.1007/s11219-013-9224-0
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Huang DY, 2012, J VIS COMMUN IMAGE R, V23, P648, DOI 10.1016/j.jvcir.2012.03.002
   Kim G., 2012, P IEEE INT C CONTR A, P17
   Kong H., 2012, P 2009 IEEE COMP VIS, P20
   Kong H, 2010, IEEE T IMAGE PROCESS, V19, P2211, DOI 10.1109/TIP.2010.2045715
   Li X., 2013, P IEEE INT HUM MACH, P26
   Lu KY, 2013, CHIN AUTOM CONGR, P415, DOI 10.1109/CAC.2013.6775770
   Negri P, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/782432
   Satzoda R.K., 2014, P IEEE COMP VIS PATT, P23
   Siogkas GK, 2013, IEEE T INTELL TRANSP, V14, P527, DOI 10.1109/TITS.2012.2223686
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sivaraman S, 2012, IEEE INT C INTELL TR, P1519, DOI 10.1109/ITSC.2012.6338886
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Vapnik V. N., 1998, STAT LEARNING THEORY, P423
   Wang B., 2014, P 2014 IEEE INT VEH, P8
   Wang CCR, 2008, IEEE T INTELL TRANSP, V9, P83, DOI 10.1109/TITS.2007.908572
   Wang XY, 2012, PROCEEDINGS OF 2012 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2012), P772, DOI 10.1109/ICCSNT.2012.6526046
   Wijnhoven R. G. J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2077, DOI 10.1109/ICCVW.2011.6130504
   Wu C. F., 2011, IEEE MAN CYBERNETI C, V42, P577
   Yang F, 2013, GLOB CONGRESS INTELL, P269, DOI 10.1109/GCIS.2013.49
   Yeh CH, 2014, INFORM SCIENCES, V269, P106, DOI 10.1016/j.ins.2013.08.014
   Zhang Yan., 2006, 2006 IEEE Intelligent Transportation Systems Conference, P1185
NR 32
TC 30
Z9 32
U1 0
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 250
EP 259
DI 10.1016/j.jvcir.2017.04.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500022
DA 2024-07-18
ER

PT J
AU Jung, C
   Yu, ST
   Kim, J
AF Jung, Cheolkon
   Yu, Shengtao
   Kim, Joongkyu
TI Intensity-guided edge-preserving depth upsampling through weighted
   L<sub>0</sub> gradient minimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth upsampling; Edge-preserving; Weighted L-0 sparsity; Alternating
   minimization; Half-quadratic splitting
ID SUPERRESOLUTION
AB Depth is an important visual cue to perceive real-world scenes. Although a time-of-flight (ToF) depth camera can provide depth information in dynamic scenes, captured depth images are often noisy and of low resolution. In this paper, we propose an intensity-guided edge-preserving depth upsampling method through weighted L-0 gradient minimization to enhance both resolution and visual quality of depth images. Guided by the high-resolution intensity image, we perform optimization to preserve boundaries of objects. We apply L-0 gradient to the regularization term, and compute its weight from both intensity and depth images. We optimize the objective function using alternating minimization and half-quadratic splitting. Experimental results on Middlebury 2005, 2014, and real-world scene datasets demonstrate that the proposed method produces boundary-preserving depth upsampling results and outperforms state-of-the-art ones in terms of accuracy. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Jung, Cheolkon; Yu, Shengtao] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Kim, Joongkyu] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
C3 Xidian University; Sungkyunkwan University (SKKU)
RP Jung, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM zhengzk@xidian.edu.cn; yu_st@stu.xidian.edu.cn; jkkim@skku.edu
RI Yu, Shengtao/K-3600-2015
FU National Natural Science Foundation of China [61271298]; International
   S&T Cooperation Program of China [2014DFG12780]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61271298) and the International S&T Cooperation Program of
   China (No. 2014DFG12780).
CR [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], P IEEE ICIP
   [Anonymous], 2008, WORKSH MULT MULT SEN
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2009, P VIS COMMUN IMAGE P
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], ACM T GRAPH
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P VIS COMM IM PROC V
   Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   Choi O, 2014, IEEE T IMAGE PROCESS, V23, P3321, DOI 10.1109/TIP.2014.2329766
   Choudhury P., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P186
   Dai LQ, 2015, IEEE SIGNAL PROC LET, V22, P623, DOI 10.1109/LSP.2014.2365527
   Dai LQ, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P90, DOI 10.1109/ACPR.2013.11
   Diebel J., 2005, P 18 INT C NEUR INF, V18, P291
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Garcia F., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P42, DOI 10.1109/AVSS.2011.6027291
   Gokturk S. B., 2004, 2004 C COMPUTER VISI, V2004, P35
   Gong XJ, 2014, IEEE COMPUT SOC CONF, P738, DOI 10.1109/CVPRW.2014.114
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guo K, 2012, IET IMAGE PROCESS, V6, P337, DOI 10.1049/iet-ipr.2010.0430
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Kopf J., 2007, ACM T GRAPHIC, V26
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29
   Lu JB, 2011, INT CONF ACOUST SPEE, P985
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Mac Aodha O, 2012, LECT NOTES COMPUT SC, V7574, P71, DOI 10.1007/978-3-642-33712-3_6
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qingxiong Yang, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P69, DOI 10.1109/MMSP.2010.5661996
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D., 2007, P CVPR
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schuon Sebastian, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563171
   Schwarz S, 2014, IEEE T IMAGE PROCESS, V23, P214, DOI 10.1109/TIP.2013.2287613
   Thanusutiyabhorn Pimrapat, 2011, 8th Electrical Engineering/ Electronics, Computer, Telecommunications and Information Technology (ECTI) Association of Thailand - Conference 2011, P975
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Xie J, 2016, IEEE T IMAGE PROCESS, V25, P428, DOI 10.1109/TIP.2015.2501749
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang Q., 2007, P IEEE CVPR, P1
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yang QX, 2013, IEEE T IMAGE PROCESS, V22, P4841, DOI 10.1109/TIP.2013.2278917
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68
   Zomet A, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P27, DOI 10.1109/ACV.2002.1182150
   Zuo XX, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P138, DOI 10.1109/ICVRV.2013.30
NR 57
TC 8
Z9 8
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 132
EP 144
DI 10.1016/j.jvcir.2016.11.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200011
DA 2024-07-18
ER

PT J
AU Kuo, TY
   Su, PC
   Tsai, CM
AF Kuo, Tien-Ying
   Su, Po-Chyi
   Tsai, Cheng-Mou
TI Improved visual information fidelity based on sensitivity
   characteristics of digital images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Log-Gabor filter; Visual information fidelity;
   Visual sensitivity
ID QUALITY ASSESSMENT; SCALE MIXTURES; STATISTICS; GAUSSIANS
AB Digital images may lose certain information during transmission or transcoding processes. Since the lost information can influence the visual quality perceived by the human eyes, several quality assessment metrics have been proposed. The structural similarity index (SSIM) and visual information fidelity (VIF) are two of the most common methods that take characteristics of the human perceptual system into account. Although many improved metrics based on SSIM have been developed, the methods related to VIF, which outperforms SSIM-based approaches in certain image databases, have rarely been discussed. This research aims at improving VIF to increase the effectiveness and reduce its computational complexity. The enhanced VIF employs the Haar wavelet transform, log-Gabor filter, and spectral residual approach to emphasize the visual sensitivity in image quality assessment. The experimental results demonstrate the superior performance of the proposed method, when compared to various popular or latest assessment indices. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kuo, Tien-Ying; Tsai, Cheng-Mou] Natl Taipei Univ Technol, Dept Elect Engn, Taipei 106, Taiwan.
   [Su, Po-Chyi] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 National Taipei University of Technology; National Central University
RP Su, PC (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
EM pochyisu@csie.ncu.edu.tw
RI SU, PO-CHYI/GWC-9682-2022; Kuo, Tien-Ying/B-6702-2013
OI Kuo, Tien-Ying/0000-0001-9831-5622
FU Ministry of Science and Technologies of the Republic of China [MOST
   103-2221-E-027-039-, MOST 104-2221-E-008-075]
FX This research was supported by the Ministry of Science and Technologies
   of the Republic of China under the Grants MOST 103-2221-E-027-039- and
   MOST 104-2221-E-008-075.
CR Anan Guo, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3297, DOI 10.1109/ICIP.2011.6116375
   [Anonymous], 2006, MODERN IMAGE QUALITY
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2005, SUBJECTIVE QUALITY A
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Chandler D.M., 2007, A57 DATABASE
   CORRIVEAU P, 2000, SPIE VISUAL COMMUNIC, V4067
   Engelke U, 2009, SIGNAL PROCESS-IMAGE, V24, P525, DOI 10.1016/j.image.2009.06.005
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2014, IEEE IMAGE PROC, P506, DOI 10.1109/ICIP.2014.7025101
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE SIGNAL PROC LET, V22, P1552, DOI 10.1109/LSP.2015.2413944
   Horita Y., 2000, MICT Image Quality Evaluation Database
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Larson E C, 2009, Categorical Image Quality (CSIQ) database [EB/OL]
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu T.-J., 2013, APSIPA T SIGNAL  JUL
   Ma Q, 2008, INT C PATT RECOG, P2783
   Pappas TN, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P939, DOI 10.1016/B978-012119792-6/50118-2
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Preiss J, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2302684
   Sheikh H.R., IEEE T IMAGE PROCESS, P15
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Simoncelli EP, 2001, ANNU REV NEUROSCI, V24, P1193, DOI 10.1146/annurev.neuro.24.1.1193
   Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350
   Wainwright MJ, 2000, ADV NEUR IN, V12, P855
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu C.-Y., 2013, APSIPA T SIGNAL  MAY
   Wu CY, 2014, IEEE T CIRC SYST VID, V24, P113, DOI 10.1109/TCSVT.2013.2273656
   Xenos M., J VIS COMMUN IMAGE R, P16
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
NR 40
TC 13
Z9 16
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 76
EP 84
DI 10.1016/j.jvcir.2016.06.010
PN A
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500009
DA 2024-07-18
ER

PT J
AU Li, J
   Lu, W
AF Li, Jie
   Lu, Wei
TI Blind image motion deblurring with <i>L</i><sub>0</sub>-regularized
   priors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind motion deblurring; L-0-regularized method; Kernel estimation;
   Alternating minimizing
ID SPARSE REPRESENTATION; PARALLEL FRAMEWORK; RESTORATION; CAMERA
AB Blind motion deblurring from a single image has always been a challenging problem. This paper proposes a blind image motion deblurring method which adopts L-0-regularized priors both in kernel and latent image estimation. A sparse and noiseless kernel and reliable intermediate latent images are generated with this prior constraint. An alternating minimization method is adopted to ensure that latent image and kernel estimation converge at an acceptable time. The proposed method is easy to implement since it does not require any complex filtering strategies to select salient edges which are critical to the explicit salient edges selection methods. The experimental results demonstrate that the proposed method is superior because of the better performance when compared with other state-of-the-art methods and the encouraging results obtained on some challenging examples. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Li, Jie; Lu, Wei] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM leejaysysu@qq.com; luwei3@mail.sysu.edu.cn
FU Natural Science Foundation of Guangdong [2016A030313350]; Science and
   Technology Program of Guangdong; Fundamental Research Funds for Central
   Universities; National Natural Science Foundation of China
FX This work is supported by National Natural Science Foundation of China,
   Natural Science Foundation of Guangdong (No. 2016A030313350), Science
   and Technology Program of Guangdong, and Fundamental Research Funds for
   the Central Universities.
CR ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   FIELD DJ, 1994, NEURAL COMPUT, V6, P559, DOI 10.1162/neco.1994.6.4.559
   Gou S., 2013, PLOS ONE, V8, P12
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Jiang M, 2003, IEEE T MED IMAGING, V22, P837, DOI 10.1109/TMI.2003.815075
   Jinshan Pan, 2013, IEEE Signal Processing Letters, V20, P841, DOI 10.1109/LSP.2013.2261986
   Köhler R, 2012, LECT NOTES COMPUT SC, V7578, P27, DOI 10.1007/978-3-642-33786-4_3
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Liao YH, 2005, IEEE T IMAGE PROCESS, V14, P1766, DOI 10.1109/TIP.2005.857274
   Liu SG, 2016, IEEE T CIRC SYST VID, V26, P1012, DOI 10.1109/TCSVT.2015.2418585
   Money JH, 2008, IMAGE VISION COMPUT, V26, P302, DOI 10.1016/j.imavis.2007.06.005
   Pan JS, 2014, PROC CVPR IEEE, P2901, DOI 10.1109/CVPR.2014.371
   Pan JS, 2014, LECT NOTES COMPUT SC, V8695, P47, DOI 10.1007/978-3-319-10584-0_4
   Pan JS, 2013, SIGNAL PROCESS-IMAGE, V28, P1156, DOI 10.1016/j.image.2013.05.001
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Sulong G., 2012, INT J BIO SCI BIO TE, V4, P9
   Wang J, 2005, J X-RAY SCI TECHNOL, V13, P49
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Xiao L, 2015, IEEE T IMAGE PROCESS, V24, P3071, DOI 10.1109/TIP.2015.2432716
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315
NR 30
TC 27
Z9 27
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 14
EP 23
DI 10.1016/j.jvcir.2016.06.003
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500002
DA 2024-07-18
ER

PT J
AU Lasang, P
   Kumwilaisak, W
   Liu, YZ
   Shen, SM
AF Lasang, Pongsak
   Kumwilaisak, Wuttipong
   Liu, Yazhou
   Shen, Sheng Mei
TI Optimal depth recovery using image guided TGV with depth confidence for
   high-quality view synthesis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D sensors; Depth confidence; Depth recovery; Depth Image Based
   Rendering (DIBR); View synthesis; Hole filling
ID ENHANCEMENT; GENERATION; ACCURACY; REMOVAL; FUSION; FILTER
AB This paper presents a new depth image recovery method for RGB-D sensors giving a complete, sharp, and accurate object shape from a noisy boundary depth map. The proposed method uses the image guided Total Generalized Variation (TGV) with the depth confidence. A new directional hole filling method of view synthesis is also investigated to produce natural texture in hole regions whereas reducing blurring effect and preventing distortion. Thus, a high-quality image view can be achieved. Experimental results show that the proposed method yields higher quality recovered depth maps and synthesized image views than other previous methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Lasang, Pongsak; Shen, Sheng Mei] Panason R&D Ctr Singapore, Core Technol Grp, Singapore, Singapore.
   [Lasang, Pongsak] King Mongkuts Univ Technol Thonburi, Dept Comp Engn, Bangkok, Thailand.
   [Kumwilaisak, Wuttipong] King Mongkuts Univ Technol Thonburi, Dept Elect & Telecommun Engn, Bangkok, Thailand.
   [Liu, Yazhou] Nanjing Univ Sci & Technol, Dept Comp Sci & Engn, Nanjing 210048, Jiangsu, Peoples R China.
C3 King Mongkuts University of Technology Thonburi; King Mongkuts
   University of Technology Thonburi; Nanjing University of Science &
   Technology
RP Lasang, P (corresponding author), Panason R&D Ctr Singapore, Core Technol Grp, Singapore, Singapore.
EM pongsak.lasang@sg.panasonic.com; wuttipong.kum@kmutt.ac.th;
   yazhouliu@njust.edu.cn; shengmei.shen@sg.panasonic.com
FU Higher Education Research Promotion and National Research University
   Project of Thailand, Office of the Higher Education Commission
FX This work was supported by the Higher Education Research Promotion and
   National Research University Project of Thailand, Office of the Higher
   Education Commission.
CR Le AV, 2014, SENSORS-BASEL, V14, P11362, DOI 10.3390/s140711362
   [Anonymous], APSIPA ASC
   [Anonymous], P SPIE 8290 3 DIMENS
   [Anonymous], 2015, MICROSOFT KINECT XBO
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Blum M, 2012, IEEE INT CONF ROBOT, P1298, DOI 10.1109/ICRA.2012.6225188
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Freedman B., 2010, Primesense LTD patent, Patent No. [US 2010/0118123 Al, 20100118123, 20100118123 A1]
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Gong XJ, 2013, IMAGE VISION COMPUT, V31, P695, DOI 10.1016/j.imavis.2013.07.006
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Henry P, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P398, DOI 10.1109/3DV.2013.59
   Hiriart-Urruty JB, 2003, J MATH ANAL APPL, V288, P544, DOI 10.1016/j.jmaa.2003.09.012
   Horng YR, 2010, IEEE INT SYMP CIRC S, P2650, DOI 10.1109/ISCAS.2010.5537052
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Kim SY, 2013, IEEE T CONSUM ELECTR, V59, P681, DOI 10.1109/TCE.2013.6626256
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lee GC, 2014, J ELECTR ENG TECHNOL, V9, P1016, DOI 10.5370/JEET.2014.9.3.1016
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Lindner M, 2010, COMPUT VIS IMAGE UND, V114, P1318, DOI 10.1016/j.cviu.2009.11.002
   Lu S, 2014, PROC CVPR IEEE, P3390, DOI 10.1109/CVPR.2014.433
   Maier R, 2014, LECT NOTES COMPUT SC, V8753, P54, DOI 10.1007/978-3-319-11752-2_5
   Matyunin S., 2011, 3DTV Conference: The True Vision-Capture, Transmission and Display of 3D Video, P1
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Nair R, 2012, LECT NOTES COMPUT SC, V7584, P1, DOI 10.1007/978-3-642-33868-7_1
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   Park YK, 2009, SIGNAL PROCESS-IMAGE, V24, P122, DOI 10.1016/j.image.2008.10.008
   Po LM, 2011, IEEE IMAGE PROC
   PoLin Lai, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P9, DOI 10.1109/PCS.2010.5702589
   Qi F, 2013, PATTERN RECOGN LETT, V34, P70, DOI 10.1016/j.patrec.2012.06.003
   Ranftl R, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P401, DOI 10.1109/IVS.2012.6232171
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Song XB, 2014, VISUAL COMPUT, V30, P855, DOI 10.1007/s00371-014-0965-y
   Stückler J, 2014, J VIS COMMUN IMAGE R, V25, P137, DOI 10.1016/j.jvcir.2013.02.008
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tian D., 2009, P SPIE APPL DIGITAL
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Vázquez C, 2006, PROC SPIE, V6392, DOI 10.1117/12.685047
   Vijayanagar KR, 2014, MOBILE NETW APPL, V19, P414, DOI 10.1007/s11036-013-0458-7
   Whelan T, 2013, IEEE INT CONF ROBOT, P5724, DOI 10.1109/ICRA.2013.6631400
   Xu XY, 2013, IEEE INT SYMP CIRC S, P2840, DOI 10.1109/ISCAS.2013.6572470
   Xu XY, 2013, SIGNAL PROCESS-IMAGE, V28, P1023, DOI 10.1016/j.image.2013.04.003
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Ye XC, 2014, IEEE T BROADCAST, V60, P540, DOI 10.1109/TBC.2014.2345931
   Zalevsky Z., 2010, U.S. Patent Application, Patent No. [2010/0177164, 20100177164]
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhou QY, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461919
NR 62
TC 5
Z9 8
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 24
EP 39
DI 10.1016/j.jvcir.2016.05.006
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900003
DA 2024-07-18
ER

PT J
AU Fathi, A
   Alirezazadeh, P
   Abdali-Mohammadi, F
AF Fathi, Abdoihossein
   Alirezazadeh, Pendar
   Abdali-Mohammadi, Fardin
TI A new Global-Gabor-Zernike feature descriptor and its application to
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Gabor wavelet; Zernike moment; Histogram of oriented
   gradients (HOG); Feature extraction; Local feature descriptor; Global
   feature descriptor; Global gabor zernike descriptor
ID FEATURE-EXTRACTION; TEXTURE; PATTERN; FUSION; FILTER; LBP
AB Face recognition is an important subject in computer vision and authentication systems. Feature extraction is one of the main steps in the face recognition systems, which greatly affects recognition accuracy. In the most of the existing methods, only local features in the facial area are extracted and employed in recognizing the person's face. In this article, at first a novel multi-scale and rotation invariant global feature descriptor is introduced by applying the Zernike moment on the outputs of Gabor filters. Then the proposed global feature along with an efficient local feature, the histogram of oriented gradient (HOG), is employed to propose a new face recognition system. The proposed system was tested on three famous face recognition databases, namely ORL, Yale and AR and face recognition rates of 98%, 97.8% and 97.1% were obtained respectively. These rates are higher than other state-of-the-art methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Fathi, Abdoihossein; Alirezazadeh, Pendar; Abdali-Mohammadi, Fardin] Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.
C3 Razi University
RP Fathi, A (corresponding author), Razi Univ, Dept Comp Engn & Informat Technol, Kermanshah, Iran.
EM a.fathi@razi.ac.ir; a.pendar@pgs.razi.ac.ir; fardin.abdali@razi.ac.ir
RI Abdali-Mohammadi, Fardin/M-7644-2017; Fathi, Abdolhossein/ABH-8117-2020;
   Abdali-Mohammadi, Fardin/D-6558-2011
OI Abdali-Mohammadi, Fardin/0000-0002-6691-680X; Fathi,
   Abdolhossein/0000-0003-0387-5518; Abdali-Mohammadi,
   Fardin/0000-0002-6691-680X
CR Abhishree TM, 2015, PROCEDIA COMPUT SCI, V45, P312, DOI 10.1016/j.procs.2015.03.149
   Ahonen T., 2008, 19th Intl. Conf. on Pattern Recognition, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Benavente R, 1998, 24 COMP VIS CTR
   Bereta M, 2013, J VIS COMMUN IMAGE R, V24, P1213, DOI 10.1016/j.jvcir.2013.08.004
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   Cavalcanti GDC, 2013, EXPERT SYST APPL, V40, P4971, DOI 10.1016/j.eswa.2013.03.003
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Dornaika F., 2012, IEEE TRANS SYST MAN, V43, P1
   Du S, 2009, IEEE T SYST MAN CY B, V39, P1408, DOI 10.1109/TSMCB.2009.2018137
   El Aroussi M, 2011, SIGNAL PROCESS, V91, P38, DOI 10.1016/j.sigpro.2010.06.005
   Farajzadeh N, 2010, IET COMPUT VIS, V4, P272, DOI 10.1049/iet-cvi.2009.0140
   Girish GN, 2014, INT CONF COMP COMMUN
   Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406
   Huang GH, 2010, APPL MATH COMPUT, V216, P3195, DOI 10.1016/j.amc.2010.04.042
   Huang P, 2014, NEUROCOMPUTING, V140, P104, DOI 10.1016/j.neucom.2014.03.031
   Huang ZH, 2015, IMAGE VISION COMPUT, V37, P12, DOI 10.1016/j.imavis.2014.12.005
   Huang ZH, 2015, INFORM FUSION, V22, P95, DOI 10.1016/j.inffus.2014.06.001
   Hwang SK, 2006, PATTERN RECOGN, V39, P2065, DOI 10.1016/j.patcog.2006.03.004
   Jianke Li, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P1240, DOI 10.1109/ICISE.2009.581
   Lu GF, 2012, KNOWL-BASED SYST, V31, P119, DOI 10.1016/j.knosys.2012.02.014
   Lu GF, 2012, PATTERN RECOGN, V45, P2510, DOI 10.1016/j.patcog.2012.01.018
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Ludwig O, 2009, 2009 12TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC 2009), P432
   Mandal T, 2009, SIGNAL PROCESS, V89, P2345, DOI 10.1016/j.sigpro.2009.03.007
   Peng Y, 2015, NEUROCOMPUTING, V149, P340, DOI 10.1016/j.neucom.2013.12.065
   Ren HR, 2014, OPTIK, V125, P1922, DOI 10.1016/j.ijleo.2013.09.079
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Secchi P., 2013, COMPUT STAT DATA AN, V67, P236
   Shahamat H, 2014, J VIS COMMUN IMAGE R, V25, P970, DOI 10.1016/j.jvcir.2014.02.007
   Singh Chandan, 2011, Pattern Recognition and Image Analysis, V21, P71, DOI 10.1134/S1054661811010044
   Tahmasbi A, 2011, COMPUT BIOL MED, V41, P726, DOI 10.1016/j.compbiomed.2011.06.009
   Tan HL, 2014, IET COMPUT VIS, V8, P224, DOI 10.1049/iet-cvi.2012.0302
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Wen Y, 2012, DIGIT SIGNAL PROCESS, V22, P140, DOI 10.1016/j.dsp.2011.08.004
   Yu L, 2010, IMAGE VISION COMPUT, V28, P177, DOI 10.1016/j.imavis.2009.05.012
   Yu W, 2014, SIGNAL IMAGE VIDEO P, V8, pS155, DOI 10.1007/s11760-014-0652-5
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou SR, 2013, NEUROCOMPUTING, V116, P260, DOI 10.1016/j.neucom.2012.05.036
   Zhu YH, 2009, IMAGE VISION COMPUT, V27, P1358, DOI 10.1016/j.imavis.2008.12.009
NR 45
TC 29
Z9 30
U1 0
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 65
EP 72
DI 10.1016/j.jvcir.2016.02.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100007
DA 2024-07-18
ER

PT J
AU Feng, LT
   Po, LM
   Li, YM
   Xu, XY
   Yuan, F
   Cheung, TCH
   Cheung, KW
AF Feng, Litong
   Po, Lai-Man
   Li, Yuming
   Xu, Xuyuan
   Yuan, Fang
   Cheung, Terence Chun-Ho
   Cheung, Kwok-Wai
TI Integration of image quality and motion cues for face anti-spoofing: A
   neural network approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face anti-spoofing; Neural network; Feature fusion; Shearlet; Dense
   optical flow
ID RECOGNITION; IRIS
AB Many trait-specific countermeasures to face spoofing attacks have been developed for security of face authentication. However, there is no superior face anti-spoofing technique to deal with every kind of spoofing attack in varying scenarios. In order to improve the generalization ability of face anti-spoofing approaches, an extendable multi-cues integration framework for face anti-spoofing using a hierarchical neural network is proposed, which can fuse image quality cues and motion cues for liveness detection. Shearlet is utilized to develop an image quality-based liveness feature. Dense optical flow is utilized to extract motion-based liveness features. A bottleneck feature fusion strategy can integrate different liveness features effectively. The proposed approach was evaluated on three public face anti spoofing databases. A half total error rate (HTER) of 0% and an equal error rate (EER) of 0% were achieved on both REPLAY-ATTACK database and 3D-MAD database. An EER of 5.83% was achieved on CASIA-FASD database. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Feng, Litong; Po, Lai-Man; Li, Yuming; Xu, Xuyuan; Yuan, Fang] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Cheung, Terence Chun-Ho] City Univ Hong Kong, Dept Informat Syst, Hong Kong, Hong Kong, Peoples R China.
   [Cheung, Kwok-Wai] Chu Hai Coll Higher Educ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong
RP Feng, LT (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM lightedfeng@gmail.com
RI wang, yi/HOF-6668-2023
OI Po, Lai Man/0000-0002-5185-1492
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   [Anonymous], 2012, Shearlets
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2009, BLACK HAT C DEC
   [Anonymous], 2013, 2013 INT C BIOMETRIC, DOI DOI 10.1109/ICB.2013.6612968
   [Anonymous], BIOM FOR IWBF 2013 I
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Chen GG, 2015, INT CONF ACOUST SPEE, P5236, DOI 10.1109/ICASSP.2015.7178970
   Chingovska I, 2013, INT CONF BIOMETR
   Chingovska Ivana, 2012, BIOSIG
   De Marsico M, 2014, IMAGE VISION COMPUT, V32, P1161, DOI 10.1016/j.imavis.2013.12.014
   Ding RX, 2015, J VIS COMMUN IMAGE R, V30, P35, DOI 10.1016/j.jvcir.2015.03.001
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Erdogmus N., 2013, PROC IEEE INT C BIOM, P1
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Kim DJ, 2010, IEEE T CONSUM ELECTR, V56, P2678, DOI 10.1109/TCE.2010.5681156
   Kim Y, 2011, IEEE T CONSUM ELECTR, V57, P756, DOI 10.1109/TCE.2011.5955219
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Li YM, 2014, SIGNAL PROCESS-IMAGE, V29, P748, DOI 10.1016/j.image.2014.05.007
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Menotti David, 2015, IEEE Transactions on Information Forensics and Security, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Sun L, 2011, LECT NOTES COMPUT SC, V6855, P114, DOI 10.1007/978-3-642-23678-5_12
   Sun Y, 2014, ADV NEUR IN, V27
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JS, 2013, IEEE GLOB COMM CONF, P1, DOI 10.1109/GLOCOM.2013.6831038
   Yu D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P244
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 38
TC 166
Z9 192
U1 0
U2 48
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 451
EP 460
DI 10.1016/j.jvcir.2016.03.019
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100039
DA 2024-07-18
ER

PT J
AU Mardones, T
   Allende, H
   Moraga, C
AF Mardones, Tomas
   Allende, Hector
   Moraga, Claudio
TI Leveraging similarities and structure for dense representations
   combination in image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Fisher Vector; Global dense
   representation; Image search; Graph based combination; Re-ranking;
   Product Quantization
ID QUANTIZATION
AB This paper addresses the problem of content-based image retrieval in a large-scale setting. Recently several graph-based image retrieval systems have been proposed to fuse different representations, with excellent results. However, most of them use one very precise representation, which does not scale as well as global dense representations with an increasing number of images, hurting time and memory requirements as the database grows. We researched how to attain a comparable precision, while greatly reducing the memory and time requirements by avoiding the use of a main precise representation. To accomplish this objective, we proposed a novel graph-based query fusion approach where we combined several compact representations based on aggregating local descriptors such as Fisher Vectors using distance and neighborhood information jointly to evaluate the individual importance of each element in a query adaptive manner. The performance was analyzed in different time and memory constrained scenarios, ranging from less than a second to several seconds for the complete search process while needing only a fraction of the memory compared to other similar performing methods. Experiments were performed on 4 public datasets, namely UKBench, Holidays, Core1-5K and MIRFLICKR-1M, obtaining state-of-the-art effectiveness. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Mardones, Tomas; Allende, Hector] Univ Tecn Federico Santa Maria, Av Espana 1680,CP 110-V, Valparaiso, Chile.
   [Moraga, Claudio] TU Dortmund Univ, Dept Comp Sci, Dortmund, Germany.
C3 Universidad Tecnica Federico Santa Maria; Dortmund University of
   Technology
RP Mardones, T (corresponding author), Univ Tecn Federico Santa Maria, Av Espana 1680,CP 110-V, Valparaiso, Chile.
EM tomas.mardones@alumnos.usm.cl
OI Allende, Hector/0000-0002-9899-0051
FU Basal Project [FB-0821]; DGIP-UTFSM; DGIP-PIIC; CONICYT; MECESUP; 
   [FONDECYT-1110854]
FX This work was supported by the following research and fellowship grants:
   FONDECYT-1110854, Basal Project FB-0821, DGIP-UTFSM, DGIP-PIIC, CONICYT
   and MECESUP.
CR [Anonymous], 2010, PROC ACM SIGMM INT C
   [Anonymous], 2013, P 21 ACM INT C MULT, DOI 10.1145/2502081.2502171
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Delvinioti A, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P321
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Douze M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P687, DOI 10.1145/2647868.2654892
   Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gordo A, 2012, PROC CVPR IEEE, P3045, DOI 10.1109/CVPR.2012.6248035
   Pedronette DCG, 2014, IMAGE VISION COMPUT, V32, P120, DOI 10.1016/j.imavis.2013.12.009
   Jegou H., 2011, 7656 INRIA
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mardones Tomas, 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P128
   Nister David, 2006, CVPR
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Safadi B, 2013, INT WORK CONTENT MUL, P65, DOI 10.1109/CBMI.2013.6576554
   Shen XH, 2014, IEEE T PATTERN ANAL, V36, P1229, DOI 10.1109/TPAMI.2013.237
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Wakatani A, 2014, IEEE INT SYMP PARAL, P248, DOI 10.1109/ISPA.2014.42
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [DOI 10.1145/2072298.2072034, 10.1145/2072298.2072034]
   Yang F, 2015, IEEE WINT CONF APPL, P572, DOI 10.1109/WACV.2015.82
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zhang SL, 2015, IEEE T PATTERN ANAL, V37, P2573, DOI 10.1109/TPAMI.2015.2417573
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zheng L, 2014, PROC CVPR IEEE, P1963, DOI 10.1109/CVPR.2014.252
NR 48
TC 2
Z9 3
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 641
EP 657
DI 10.1016/j.jvcir.2016.04.012
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100055
DA 2024-07-18
ER

PT J
AU Thomas, SS
   Gupta, S
   Subramanian, VK
AF Thomas, Sinnu Susan
   Gupta, Sumana
   Subramanian, Venkatesh K.
TI Perceptual synoptic view of pixel, object and semantic based attributes
   of video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Surveillance; Attention; Perceptual feature; Synoptic view; Object and
   semantic attributes; Modeling
ID PARALLEL FRAMEWORK; VISUAL-ATTENTION; MODEL; SHAPE; SELECTION; SYNOPSIS
AB For a scene, what are the object and semantic based attributes, other than the pixel based attributes, and how do they affect our attentional selection are some of the questions we need to address. We studied the effects of various attributes on our attentional perspective. We described a new saliency prediction model that accounts for different pixel-level attributes as color, contrast and intensity; object level attributes such as size, shape of objects and semantic level attributes as motion and speed of objects. We quantified these attributes based on motion contrast, motion energy and motion chromism. With this in view, we examined the problem of information prioritizing and filtering with emphasis on directing this exercise using object and semantic based attributes of the human attention model. We have evaluated proposed approach on different types of videos for their quantitative and qualitative comparison. The promising results create a gateway for synopsis view. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Thomas, Sinnu Susan; Gupta, Sumana; Subramanian, Venkatesh K.] Indian Inst Technol, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Thomas, SS (corresponding author), Indian Inst Technol, Dept Elect Engn, Kanpur 208016, Uttar Pradesh, India.
EM sinnu@iitk.ac.in; sumana@iitk.ac.in; venkats@iitk.ac.in
CR Altmann CF, 2004, J COGNITIVE NEUROSCI, V16, P794, DOI 10.1162/089892904970825
   Assa J, 2005, ACM T GRAPHIC, V24, P667, DOI 10.1145/1073204.1073246
   BEVERLEY KI, 1979, VISION RES, V19, P1093, DOI 10.1016/0042-6989(79)90004-X
   Carmi R, 2006, VISION RES, V46, P4333, DOI 10.1016/j.visres.2006.08.019
   Chen X, 2016, SCI REP-UK, V6, DOI 10.1038/srep21106
   CORBETTA M, 1991, J NEUROSCI, V11, P2383
   Dessing JC, 2005, J COGNITIVE NEUROSCI, V17, P668, DOI 10.1162/0898929053467604
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Huber DE, 2005, IEEE VISUALIZATION 2005, PROCEEDINGS, P527
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   Kim H, 2014, IEEE T IMAGE PROCESS, V23, P1476, DOI 10.1109/TIP.2014.2303640
   KOVACS I, 1993, P NATL ACAD SCI USA, V90, P7495, DOI 10.1073/pnas.90.16.7495
   Krieger G, 2000, SPATIAL VISION, V13, P201, DOI 10.1163/156856800741216
   LOFTUS GR, 1978, J EXP PSYCHOL HUMAN, V4, P565, DOI 10.1037/0096-1523.4.4.565
   Lopez M.T., IMAGE VIS COMPUT, V25
   Ma Y.-F., IEEE T MULTIMEDIA, V7
   Massey M, 1996, IBM SYST J, V35, P557, DOI 10.1147/sj.353.0557
   Peschel AO, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00902
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304
   Shah R., IEEE T CIRC SYST VID, V23
   Shih HC, 2009, IEEE T MULTIMEDIA, V11, P244, DOI 10.1109/TMM.2008.2009682
   Sunkavalli K, 2012, IEEE T VIS COMPUT GR, V18, P1868, DOI 10.1109/TVCG.2012.72
   Tek S, 2012, COGNITIVE DEV, V27, P28, DOI 10.1016/j.cogdev.2011.09.009
   Thomas SS, 2014, INT CONF DIGIT SIG, P286, DOI 10.1109/ICDSP.2014.6900672
   Tsai CM, 2013, IEEE T CIRC SYST VID, V23, P1927, DOI 10.1109/TCSVT.2013.2269186
   Walther D., 2004, WORKSHOP ATTENTION P, P96
   Wexler M, 2008, CURR BIOL, V18, P1872, DOI 10.1016/j.cub.2008.10.059
   WILLIAMS LG, 1967, ACTA PSYCHOL, V27, P355, DOI 10.1016/0001-6918(67)90080-7
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang LF, 2008, IEEE INT SYM MULTIM, P667, DOI 10.1109/ISM.2008.117
NR 35
TC 12
Z9 13
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 367
EP 377
DI 10.1016/j.jvcir.2016.03.015
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100031
DA 2024-07-18
ER

PT J
AU Wang, W
   Chen, C
   Ng, MK
AF Wang, Wei
   Chen, Chuan
   Ng, Michael K.
TI An image pixel based variational model for histogram equalization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Histogram equalization; Contrast enhancement; Variational approach;
   Energy functional; Histogram transfer; Euler Lagrange equation;
   Alternating minimization; Algorithm
ID CONTRAST ENHANCEMENT; SPECIFICATION
AB In this paper, we develop an image pixel based histogram equalization model for image contrast enhancement. The approach is to propose a variational model containing an energy functional to adjust the pixel values of an input image directly so that the resulting histogram can be redistributed to be uniform. This idea is different from existing histogram equalization algorithms where a histogram based on the input image is constructed, a mapping is determined to output a uniform histogram and then the pixel values of the input image are adjusted based on the mapping. In the variational model, a mean brightness term is incorporated to preserve the brightness of the input image, and a geometry constraint can also be added to keep the geometry structure of the input image. Theoretically, the existence of the minimizer of the proposed model, and the convergence of the proposed algorithm are given. Experimental results are reported to demonstrate that the performance of the proposed model are competitive with the other testing histogram equalization methods for several testing images. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wang, Wei] Tongji Univ, Dept Math, Shanghai 200092, Peoples R China.
   [Chen, Chuan; Ng, Michael K.] Hong Kong Baptist Univ, Ctr Math Imaging & Vis, Kowloon Tong, Hong Kong, Peoples R China.
   [Chen, Chuan; Ng, Michael K.] Hong Kong Baptist Univ, Dept Math, Kowloon Tong, Hong Kong, Peoples R China.
C3 Tongji University; Hong Kong Baptist University; Hong Kong Baptist
   University
RP Wang, W (corresponding author), Tongji Univ, Dept Math, Shanghai 200092, Peoples R China.
EM wangw@tongji.edu.cn; 12466220@life.hkbu.edu.hk; mng@math.hkbu.edu.hk
RI NG, Michael/AAG-9117-2020; Ng, Michael/B-7189-2009
OI Ng, Michael/0000-0001-6833-5227
FU National Natural Science Foundation of China [11201341]; RGC GRF
   [202013, 12301214]; HKBU FRG [FRG2/13-14/079]
FX Research of Wei Wang is supported by National Natural Science Foundation
   of China (Grant No. 11201341). Research of Michael K. Ng is supported by
   RGC GRF Grant Nos. 202013, 12301214 and HKBU FRG Grant No.
   FRG2/13-14/079.
CR ALTAS I, 1995, IEEE T IMAGE PROCESS, V4, P845, DOI 10.1109/83.388088
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Celik T, 2012, PATTERN RECOGN, V45, P3810, DOI 10.1016/j.patcog.2012.03.019
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   DELON J, 2004, THESIS ECOLE NORMALE
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Grundland M, 2005, PROC SPIE, P610, DOI 10.1117/12.596953
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Jafar I, 2008, INTEGR COMPUT-AID E, V15, P131
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kwok N. M., 2010, 2010 IEEE International Conference on Automation Science and Engineering (CASE 2010), P568, DOI 10.1109/COASE.2010.5584719
   Liu B, 2011, IEEE T CONSUM ELECTR, V57, P583, DOI 10.1109/TCE.2011.5955195
   Matz SC, 2006, IEEE T IMAGE PROCESS, V15, P900, DOI 10.1109/TIP.2005.863935
   Menotti D, 2007, IEEE T CONSUM ELECTR, V53, P1186, DOI 10.1109/TCE.2007.4341603
   Papadakis N, 2011, IEEE T IMAGE PROCESS, V20, P1682, DOI 10.1109/TIP.2010.2095869
   Pichon E, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P117
   Piti'e F., 2007, PROC 4 IEEE EUROPEAN, P1
   Russ J.C., 1995, The Image Processing Handbook, Vsecond
   Sapiro G, 1997, J DIFFER EQUATIONS, V135, P238, DOI 10.1006/jdeq.1996.3237
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang C, 2008, IET IMAGE PROCESS, V2, P249, DOI 10.1049/iet-ipr:20070198
   Wang W, 2013, SIAM J IMAGING SCI, V6, P1823, DOI 10.1137/130909196
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
NR 27
TC 8
Z9 9
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 118
EP 134
DI 10.1016/j.jvcir.2015.10.019
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400011
DA 2024-07-18
ER

PT J
AU Jung, C
   Sun, T
   Gu, AG
AF Jung, Cheolkon
   Sun, Tian
   Gu, Aiguo
TI Content adaptive video denoising based on human visual perception
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content adaptive; Adaptive noise filtering; Human visual perception;
   Noisy frame detection; Motion detection; Nonlocal mean filtering;
   Perceptual video denoising; Temporal similarity
ID NOISE-REDUCTION; IMAGE; SCALE
AB In this paper, we propose content adaptive denoising in highly corrupted videos based on human visual perception. We introduce the human visual perception in video denoising to achieve good performance. In general, smooth regions corrupted by noise are much more annoying to human observers than complex regions. Moreover, human eyes are more interested in complex regions with image details and more sensitive to luminance than chrominance. Based on the human visual perception, we perform perceptual video denoising to effectively preserve image details and remove annoying noise. To successfully remove noise and recover the image details, we extend nonlocal mean filtering to the spatiotemporal domain. With the guidance of content adaptive segmentation and motion detection, we conduct content adaptive filtering in the YUV color space to consider context in images and obtain perceptually pleasant results. Extensive experiments on various video sequences demonstrate that the proposed method reconstructs natural-looking results even in highly corrupted images and achieves good performance in terms of both visual quality and quantitative measures. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Jung, Cheolkon; Sun, Tian; Gu, Aiguo] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 Xidian University
RP Jung, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM zhengzk@xidian.edu.cn
FU National Natural Science Foundation of China [61271298]; International S
   & T Cooperation Program of China [2014DFG12780]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments that have led to improvements in the quality and
   presentation of the paper. This work was supported by the National
   Natural Science Foundation of China (No. 61271298) and the International
   S & T Cooperation Program of China (No. 2014DFG12780).
CR [Anonymous], 2004, IMAGE DENOISING METH
   Bae E, 2011, IEEE T IMAGE PROCESS, V20, P1199, DOI 10.1109/TIP.2010.2090533
   Boyce J. M., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P461, DOI 10.1109/ICASSP.1992.226176
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Chunting Yang, 2009, 2009 Asia-Pacific Conference on Computational Intelligence and Industrial Applications (PACIIA 2009), P176, DOI 10.1109/PACIIA.2009.5406626
   Dabov Kostadin, 2006, P SPIE
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Guerrero-Colon J., 2005, P IEEE INT C IM PROC
   Hinton GE, 1999, IEE CONF PUBL, P1, DOI 10.1049/cp:19991075
   Hsia S.C., 2012, J REAL TIME IMAGE PR
   Miyata K, 2002, INT CONF ACOUST SPEE, P3696
   Pizurica A, 2002, IEEE T IMAGE PROCESS, V11, P545, DOI 10.1109/TIP.2002.1006401
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rajpoot N, 2012, PATTERN RECOGN, V45, P2938, DOI 10.1016/j.patcog.2012.01.023
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Sadeghi S, 2012, AEU-INT J ELECTRON C, V66, P772, DOI 10.1016/j.aeue.2012.01.010
   Sanches JM, 2008, IEEE T IMAGE PROCESS, V17, P1522, DOI 10.1109/TIP.2008.2001398
   Sanches JM, 2006, LECT NOTES COMPUT SC, V4141, P351
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Thaipanich T, 2010, IEEE T CONSUM ELECTR, V56, P2623, DOI 10.1109/TCE.2010.5681149
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan L., 2006, ISCIT, P1031
   Zhang L, 2011, IET IMAGE PROCESS, V6, P273
   Zlokolica V, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P571, DOI 10.1109/ICDSP.2002.1028154
NR 25
TC 1
Z9 1
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 14
EP 25
DI 10.1016/j.jvcir.2015.04.015
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600002
DA 2024-07-18
ER

PT J
AU Lin, CH
   Chung, KL
   Chen, JJ
   Chiu, YH
   Chen, YN
AF Lin, Chien-Hsiung
   Chung, Kuo-Liang
   Chen, Jiann-Jone
   Chiu, Yung-Hsiang
   Chen, Yan-Nan
TI Fast and quality-efficient scheme for asymmetric multi-view video plus
   depth coding under the bitrate constraint
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D video; 3D multi-view video plus depth coding; Adaptive weighted mode
   in-loop filter; Asymmetric video coding; Bitrate-constrained video
   coding; Depth image-based rendering; JMVM; Texture image-assisted inter
   prediction
ID COMPRESSION; PREDICTION
AB Recently, multi-view video plus depth based 3D video (3D-MVD) coding has been studied extensively. This paper presents a fast and efficient asymmetric 3D-MVD coding scheme under specified bitrate constraints. To efficiently encode depth images, a texture image-assisted inter prediction strategy is proposed to determine whether to use a direct copy of the co-located block as the inter prediction so as to skip the normal encoding process. In addition, an adaptive weighted mode in-loop filter strategy is proposed to refine the reconstructed depth image quality. Both strategies help to significantly reduce the encoding time and improve the reconstructed depth image quality under the bitrate constraint. Experiment results showed that the proposed asymmetric 3D-MVD coding scheme does achieve better quality of the reconstructed depth videos and the rendered virtual views at a less encoding-time requirement when compared with the state-of-the-art scheme by Shao et al. and the traditional 5:1 bitrate allocation scheme. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lin, Chien-Hsiung; Chung, Kuo-Liang; Chiu, Yung-Hsiang; Chen, Yan-Nan] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Chen, Jiann-Jone] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM klchung01@gmail.com
RI Chen, Jiann-Jone/IVU-6945-2023
FU Ministry of Science and Technology of Taiwan [MOST
   101-2221-E-011-139-MY3, MOST 102-2221-E-011-055-MY3, NSC
   102-2221-E-011-036]
FX The work of C.-H. Lin and K.-L. Chung was supported by the Ministry of
   Science and Technology of Taiwan, under the Contracts MOST
   101-2221-E-011-139-MY3 and MOST 102-2221-E-011-055-MY3. The work of
   J.-J. Chen was supported by the Ministry of Science and Technology of
   Taiwan, under the Contract NSC 102-2221-E-011-036.
CR [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], JTC1SC29WG11 ISOIEC
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Grewatsch S, 2004, IEEE IMAGE PROC, P3271
   Huang XX, 2014, SIGNAL PROCESS-IMAGE, V29, P667, DOI 10.1016/j.image.2014.03.005
   *ISO IEC MPEG, 2007, JVTW100 ISOIEC MPEG
   Julesz B., 1971, Foundation of Cyclopean Perception
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Lai P., 2009, P SOC PHOTO-OPT INS
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Lee JY, 2011, IEEE T CIRC SYST VID, V21, P1859, DOI 10.1109/TCSVT.2011.2154730
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Magnor M, 2003, IEEE T CIRC SYST VID, V13, P1092, DOI 10.1109/TCSVT.2003.817630
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Morvan Y., 2007, P PICT COD S PCS 200, V10, P43
   Morvan Y, 2008, IEEE T CONSUM ELECTR, V54, P925, DOI 10.1109/TCE.2008.4560180
   Oh H, 2006, LECT NOTES COMPUT SC, V4319, P898
   Rarnanathan P, 2006, SIGNAL PROCESS-IMAGE, V21, P462, DOI 10.1016/j.image.2006.03.002
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Shen LQ, 2012, IEEE T CONSUM ELECTR, V58, P926, DOI 10.1109/TCE.2012.6311338
   Shen LQ, 2009, IEEE T BROADCAST, V55, P761, DOI 10.1109/TBC.2009.2030453
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Nguyen VA, 2013, IEEE T CIRC SYST VID, V23, P189, DOI 10.1109/TCSVT.2012.2203212
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
NR 31
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 350
EP 362
DI 10.1016/j.jvcir.2015.04.016
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900031
DA 2024-07-18
ER

PT J
AU Murakami, T
   Kageyama, Y
   Nishida, M
AF Murakami, Tatsuki
   Kageyama, Yoichi
   Nishida, Makoto
TI Background replacement using chromatic adaptation transform for visual
   communication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual communication; Background replacement; Chromatic adaptation
   transform; Illuminant color estimation; Gray world assumption;
   Dichromatic reflection model; Video chat; Subjective evaluation
ID COLOR
AB Replacing a video chat background with a landscape image can generate the realism of a user actually being in the landscape. To enhance this realism, we proposed in our previous study a background replacement method that uses a chromatic adaptation transform. This method can enhance the realism of video chat by fitting the color of the foreground image to an illuminant color of a landscape, which is used as the new background image. However, if an incorrect color of the landscape illuminant is obtained through this method, which estimates the illuminant color on the basis of a gray world assumption, the method might not enhance the realism. This is because it converts the foreground color to an incorrect color. In this paper, we therefore propose a method to estimate illuminant color on the basis of the dichromatic reflection model, which improves background replacement using the chromatic adaptation transform. We perform a subjective evaluation using 13 subjects to examine the effects of the proposed method. The results indicate that the proposed method can effectively enhance the realism of the background replacement video. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Murakami, Tatsuki; Kageyama, Yoichi; Nishida, Makoto] Akita Univ, Akita 0108502, Japan.
C3 Akita University
RP Murakami, T (corresponding author), Akita Univ, 1-1 Tegata Gakuen Machi, Akita 0108502, Japan.
EM kageyama@ie.akita-u.ac.jp
RI Kageyama, Yoichi/GQS-9197-2022
OI Kageyama, Yoichi/0000-0001-9958-1228
CR [Anonymous], 2013, Colour Appearance Models
   Borg I., 2005, Modern Multidimensional Scaling: Theory and Applications
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   *JIS, 1999, Z8725 JIS
   Morita S., 2005, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ88-D-II, P864
   Murakami T., 2013, 7 INT C MAT ENG RES, P262
   Murakami T., 2013, J JPN SOC FUZZY THEO, V25, P806
   Murakami T, 2013, IEEE SYS MAN CYBERN, P273, DOI 10.1109/SMC.2013.53
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   The color science association of Japan, 2011, HDB COL SCI
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   Yun T., YUN FREE STACK PHOTO
NR 13
TC 2
Z9 2
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 242
EP 251
DI 10.1016/j.jvcir.2015.04.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900022
DA 2024-07-18
ER

PT J
AU Qi, XJ
   Xin, X
AF Qi, Xiaojun
   Xin, Xing
TI A singular-value-based semi-fragile watermarking scheme for image
   content authentication with tamper localization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive quantization; Authentication measures; Tampered error map;
   Semi-fragile watermarking; Singular value decomposition; Wavelet
   transform; Content-dependent watermark; Strongly tampered error map;
   Mildly tampered error map
ID RECOVERY
AB This paper presents a singular-value-based semi-fragile watermarking scheme for image content authentication. The proposed scheme generates secure watermark by performing a logical operation on content-dependent watermark generated by a singular-value-based sequence and content-independent watermark generated by a private-key-based sequence. It next employs the adaptive quantization method to embed secure watermark in approximation subband of each 4 x 4 block to generate the watermarked image. The watermark extraction process then extracts watermark using the parity of quantization results from the probe image. The authentication process starts with regenerating secure watermark following the same process. It then constructs error maps to compute five authentication measures and performs a three-level process to authenticate image content and localize tampered areas. Extensive experimental results show that the proposed scheme outperforms five peer schemes and its two variant systems and is capable of identifying intentional tampering, incidental modification, and localizing tampered regions under mild to severe content-preserving modifications. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Qi, Xiaojun; Xin, Xing] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
C3 Utah System of Higher Education; Utah State University
RP Qi, XJ (corresponding author), Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
EM Xiaojun.Qi@usu.edu
CR Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Che SB, 2007, INT C WAVEL ANAL PAT, P382
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chunlei Li, 2012, Advances in Multimedia Information Processing - PCM 2012. 13th Pacific-Rim Conference on Multimedia. Proceedings, P327, DOI 10.1007/978-3-642-34778-8_30
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Cruz C, 2008, MIDWEST SYMP CIRCUIT, P306, DOI 10.1109/MWSCAS.2008.4616797
   Ho CK, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 1, PROCEEDINGS, P7
   HONG ZQ, 1991, PATTERN RECOGN, V24, P211, DOI 10.1016/0031-3203(91)90063-B
   Hu YP, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5484
   Huo YR, 2014, LECT NOTES COMPUT SC, V8389, P393, DOI 10.1007/978-3-662-43886-2_28
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Liu T, 2002, 2002 6TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I AND II, P1556, DOI 10.1109/ICOSP.2002.1180093
   Maeno K, 2006, IEEE T MULTIMEDIA, V8, P32, DOI 10.1109/TMM.2005.861293
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Ming-Shing Hsieh, 2004, Electronic Commerce Research, V4, P157, DOI 10.1023/B:ELEC.0000009286.58045.dd
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qi XJ, 2007, SIGNAL PROCESS, V87, P1264, DOI 10.1016/j.sigpro.2006.11.002
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qin C, 2013, SIGNAL PROCESS, V93, P933, DOI 10.1016/j.sigpro.2012.11.013
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Rey C., 2002, EURASIP Journal on Applied Signal Processing, V2002, P613, DOI 10.1155/S1110865702204047
   Tsai MJ, 2008, OPT ENG, V47, DOI 10.1117/1.2947580
   Yan Zhu, 2007, 2007 3rd International Symposium on Information Assurance and Security, P478
   Yang HF, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P1112
   Zhang X., 2012, PROCEEDING SENSOR SI, P1
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2010, SIGNAL PROCESS, V90, P3026, DOI 10.1016/j.sigpro.2010.04.027
   Zhou X, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P374
NR 29
TC 65
Z9 70
U1 2
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 312
EP 327
DI 10.1016/j.jvcir.2015.05.006
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900028
DA 2024-07-18
ER

PT J
AU Sun, KR
   Wu, DP
AF Sun, Kairan
   Wu, Dapeng
TI Video rate control strategies for cloud gaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cloud gaming; Rate control; ROI; Quality of experience; Video on demand;
   H.264/AVC; Video game; Low-complexity algorithm
ID H.264 RATE CONTROL; COMMUNICATION; ALLOCATION; ALGORITHM
AB Cloud gaming, also called gaming on demand, is a new kind of service that provides real-time video game experience to the players over the Internet. Although cloud gaming services are getting more and more popular recently, its performance is highly limited by the network bandwidth and latency. This work makes use of the unique characteristics of human visual system (HVS) of video game players to improve bandwidth efficiency. In this work, discussions about the characteristics of game players' HVS are conducted. The discussions can be further extended to all interactive video on demand systems. Then, some schemes of extracting region of interest and key frames from gaming videos are raised. Based on that, a Macro-block level rate control scheme is proposed based on region of interest and scene-change detection. The simulation results show that, under the same bandwidth constraint, the video quality of proposed method outperforms other methods. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Sun, Kairan; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Sun, KR (corresponding author), 1064 Ctr Dr,Room NEB 413, Gainesville, FL 32611 USA.
EM ksun@ufl.edu
RI Sun, Kairan/C-6087-2017
OI Sun, Kairan/0000-0003-0448-7541; Wu, Dapeng/0000-0003-1755-0183
FU Div Of Electrical, Commun & Cyber Sys; Directorate For Engineering
   [1509212] Funding Source: National Science Foundation
CR Chen FC, 2011, IEEE T CONSUM ELECTR, V57, P1264, DOI 10.1109/TCE.2011.6018883
   Chen K.-T., 2011, P 19 ACM INT C MULT, P1269
   Chen ZF, 2012, IEEE T CIRC SYST VID, V22, P352, DOI 10.1109/TCSVT.2011.2162763
   Choi H.-J., 2012, SEMICONDUCTOR NANOST, P1, DOI DOI 10.1007/978-3-642-22480-5
   Hossfeld T, 2012, IEEE COMMUN MAG, V50, P28, DOI 10.1109/MCOM.2012.6178831
   Jarschel M., 2011, Proceedings of the 2011 Fifth International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing (IMIS), P330, DOI 10.1109/IMIS.2011.92
   Kim JY, 2010, IEEE T CONSUM ELECTR, V56, P951, DOI 10.1109/TCE.2010.5506025
   Lee C, 2007, IEEE T CONSUM ELECTR, V53, P1084, DOI 10.1109/TCE.2007.4341589
   Lee JH, 2011, IEEE T CONSUM ELECTR, V57, P882, DOI 10.1109/TCE.2011.5955236
   Li H., 2006, 2006 8 INT C SIGN PR, V2
   Li Z., 2003, P JOINT VID TEAM JVT
   Liu Y., 2006, P IEEE INT C AC SPEE, V2, pII
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Sun KR, 2011, IEEE IMAGE PROC, P1669, DOI 10.1109/ICIP.2011.6115776
   Sun Y, 2006, IEEE T MULTIMEDIA, V8, P1, DOI 10.1109/TMM.2005.861296
   Yan B, 2012, IEEE T CIRC SYST VID, V22, P790, DOI 10.1109/TCSVT.2011.2180949
NR 19
TC 14
Z9 14
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 234
EP 241
DI 10.1016/j.jvcir.2015.03.012
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900021
DA 2024-07-18
ER

PT J
AU Huynh, NT
   Bharanitharan, K
   Chang, CC
AF Ngoc-Tu Huynh
   Bharanitharan, K.
   Chang, Chin-Chen
TI Quadri-directional searching algorithm for secret image sharing using
   meaningful shadows
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret image sharing; Meaningful shadows; Sudoku matrix; Searching
   algorithm; Visual secret sharing; Low-complexity; Pixel expansion; High
   quality
ID ERROR DIFFUSION; VISUAL QUALITY
AB Contrary to conventional protecting data such as cryptographic techniques which encrypt the data with a secret key, secret sharing takes an approach to ensure well protection of transmitted information by allowing a secret message M to be divided into n pieces. Secret message M can be held by n participants to avoid the secret from incidentally or intentionally being lost. In a secret sharing scheme, secret information leaks from shadows, attack on shadow image, and large shadow image issues which has arisen when developing an algorithm. Although existing algorithms provide remedies for such problems, the computational complexity of existing algorithms is still questionable. Therefore, we propose a low computational complexity Quadri-Directional Searching Algorithm (QDSA) for secret image sharing. Experiment results show that the proposed algorithm ensures that generated shares are of high quality and no secret information is leaked from these shares, thus it guarantees high security of our scheme. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ngoc-Tu Huynh; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Bharanitharan, K.] Feng Chia Univ, Dept Commun Engn, Taichung 40724, Taiwan.
   [Bharanitharan, K.] Univ Auckland, Dept Management & Int Business, Auckland 1, New Zealand.
   [Ngoc-Tu Huynh] Univ Da Nang, Coll Informat & Technol, Da Nang City, Vietnam.
C3 Feng Chia University; Feng Chia University; University of Auckland;
   University of Danang
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM ngoctu84vn@gmail.com; dharan@ieee.org; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
OI Brown, Darren K/0000-0003-1246-1974
CR Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2009, IEEE T INF FOREN SEC, V4, P790, DOI 10.1109/TIFS.2009.2034203
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Chin-Chen Chang, 2010, Journal of Communications, V5, P5, DOI 10.4304/jcm.5.1.5-12
   Chung KL, 2005, IEEE T IMAGE PROCESS, V14, P1583, DOI 10.1109/TIP.2005.854494
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Kieu T.D., 2009, INT J SMART HOME, V3
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Maji AK, 2013, PROC TECH, V10, P392, DOI 10.1016/j.protcy.2013.12.375
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Zhi-Hui Wang, 2013, Journal of Electronic Science and Technology, V11, P44, DOI 10.3969/j.issn.1674-862X.2013.01.009
NR 19
TC 18
Z9 20
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 105
EP 112
DI 10.1016/j.jvcir.2015.01.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000012
DA 2024-07-18
ER

PT J
AU Stommel, M
   Herzog, O
   Xu, WL
AF Stommel, M.
   Herzog, O.
   Xu, W. L.
TI A quantitative evaluation of the conceptual consistency of visual words
   and visual vocabularies
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer vision; Pattern recognition; Bag of visual words; Codebook;
   SIFT; SURF; Image classification; Text image analogy
ID IMAGE; CLASSIFICATION; RECOGNITION
AB Codebooks are a widely accepted technique to recognise objects by sets of local features. The method has been applied to many classes of objects, even very abstract ones. But although state of the art recognition rates have been reported, the method is still far away from being reliable in any sense that is related to human vision. The literature on this topic emphasises detailed descriptions of statistical estimators over a basic analysis of the data. A deeper understanding of the data is however needed to achieve a further development of the field. In this paper, we therefore present a set of quantitative experiments on codebooks of the popular SIFT descriptors. The results discourage the use of illustrative but overly simplifying descriptions of the visual words approach. It is in particular demonstrated that (1) there are more visually distinct patterns than can be listed in a codebook, (2) one element of a codebook represents a set of many, visually distinct patterns, and (3) there are no single, selective SIFT descriptors to serve as codebook elements. This makes us wonder why the method works after all. We discuss several options. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Stommel, M.] Auckland Univ Technol, Sch Engn, Auckland, New Zealand.
   [Herzog, O.] Univ Bremen, Artificial Intelligence Grp, D-28359 Bremen, Germany.
   [Herzog, O.] Jacobs Univ Bremen, Visual Informat Technol, D-28759 Bremen, Germany.
   [Xu, W. L.] Univ Auckland, Mechatron Grp, Auckland 1, New Zealand.
C3 Auckland University of Technology; University of Bremen; Jacobs
   University; University of Auckland
RP Stommel, M (corresponding author), Auckland Univ Technol, Sch Engn, Auckland, New Zealand.
EM mstommel@aut.ac.nz
RI Herzog, Otthein/ABD-1774-2020; xu, wei/HHD-2891-2022; Xu,
   Weiliang/L-3953-2019
OI Xu, Weiliang/0000-0002-1960-0992
CR [Anonymous], 2011, Visual Object Recognition
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], 2012, IEEE C COMP VIS PATT
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bettadapura V., 2013, INT CCOMP VIS PATT R
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   CHANG NS, 1979, PATTERN RECOGN, V11, P213, DOI 10.1016/0031-3203(79)90008-6
   Crandall D, 2005, PROC CVPR IEEE, P10
   Diephuis M, 2011, INT SYMP IMAGE SIG, P460
   Edelkamp Stefan, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P175, DOI 10.1007/978-3-642-33460-3_17
   Fergus R, 2006, LECT NOTES COMPUT SC, V4170, P443
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Grauman K., 2006, ADV NEURAL INFORM PR
   Han F, 2005, IEEE I CONF COMP VIS, P1778
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li W., 2013, INT C COMP VIS PATT
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Messerschmidt H., 2011, J. Autom. Lang. Comb., V16, P165
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mironica I, 2013, INT WORK CONTENT MUL, P11, DOI 10.1109/CBMI.2013.6576545
   Muller J., 2010, ALGORITHMS POWER KEY, V3, P46
   Nedovic V, 2010, IEEE T PATTERN ANAL, V32, P1673, DOI 10.1109/TPAMI.2009.174
   Nister David, 2006, CVPR
   Opelt A, 2004, LECT NOTES COMPUT SC, V3022, P71
   Safadi B, 2013, INT WORK CONTENT MUL, P65, DOI 10.1109/CBMI.2013.6576554
   Sethi Ricky J., 2013, ACM MULTIMEDIA, P813
   Shen J, 2011, IEEE INT CON MULTI
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Stommel M., 2014, PATTERN ANAL APPL
   Stommel M., 2010, INT C IM VIS COMP NZ
   Stommel M, 2009, LECT NOTES COMPUT SC, V5337, P410, DOI 10.1007/978-3-642-02345-3_40
   Stommel Martin., 2010, International Journal of Signal Processing, Image Processing and Pattern Recognition, V3, P25
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Tudor Ionescu R, 2013, ICML 2013 WORKSH REP
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang G, 2010, LECT NOTES COMPUT SC, V6315, P169, DOI 10.1007/978-3-642-15555-0_13
   Wang S, 2012, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2012.6247823
   Yang Y, 2011, IEEE I CONF COMP VIS, P1465, DOI 10.1109/ICCV.2011.6126403
   Zamir Amir Roshan., 2013, ACM Multimedia, P665
   Zhang C., 2013, ACM MULTIMEDIA, P497
   Zhang E, 2010, INT C IM VIS COMP NZ
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 46
TC 0
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 120
EP 129
DI 10.1016/j.jvcir.2014.11.015
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000014
DA 2024-07-18
ER

PT J
AU Lin, TL
   Chang, TE
   Huang, GX
   Chou, CC
   Thakur, US
AF Lin, Ting-Lan
   Chang, Tsung-En
   Huang, Gui-Xiang
   Chou, Chi-Chan
   Thakur, Uday Singh
TI Improved interview video error concealment on whole frame packet loss
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview video with depth; Error concealment; Illumination
   compensation; Whole frame loss; DIBR (Depth image based rendering); Lost
   motion estimation; Hole filling; Reference view selection
ID VECTOR RECOVERY ALGORITHM
AB An improved DIBR-based (Depth image based rendering) whole frame error concealment method for multiview video with depth is designed. An optimal reference view selection is first proposed. The paper further includes three modified parts for the DIBRed pixels. First, the missing 1-to-1 pixels are concealed by the pixels from another view. The light differences between views are taken care of by the information of the motion vector of the projected coordination and a reverse DIBR procedure. Second, the generation of the many-to-1 pixels is improved via their depth information. Third, the hole pixels are found using the estimated motion vectors derived efficiently from a weighted function of the neighboring available motion vectors and their distance to the target hole pixel. The experimental results show that, compared to the state-of-the-art method, the combined system of the four proposed methods is superior and improves the performance by 5.53 dB at maximum. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Lin, Ting-Lan; Chang, Tsung-En; Huang, Gui-Xiang; Chou, Chi-Chan] Chung Yuan Christian Univ, Dept Elect Engn, Zhongli City, Taoyuan County, Taiwan.
   [Thakur, Uday Singh] Rhein Westfal TH Aachen, Institut Nachrichtentech, Aachen, Germany.
C3 Chung Yuan Christian University; RWTH Aachen University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City, Taoyuan County, Taiwan.
EM tinglan@cycu.edu.tw; g10179007@cycu.edu.tw; g10176032@cycu.edu.tw;
   g10276011@cycu.edu.tw; Thakur@ient.rwth-aachen.de
FU National Science Council Taiwan [NSC 101-2221-E-033-036, NSC
   102-2221-E-033-018]; Ministry of Science and Technology, Taiwan [MOST
   103-2221-E-033-020]
FX This research is supported by the National Science Council Taiwan under
   Grant NSC 101-2221-E-033-036 and NSC 102-2221-E-033-018, and by the
   Ministry of Science and Technology, Taiwan under Grant MOST
   103-2221-E-033-020.
CR Chen C, 2008, IEEE T CONSUM ELECTR, V54, P1422, DOI 10.1109/TCE.2008.4637636
   Chen XM, 2010, IEEE T CONSUM ELECTR, V56, P2694, DOI 10.1109/TCE.2010.5681158
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   Chien JT, 2010, IEEE T CONSUM ELECTR, V56, P1689, DOI 10.1109/TCE.2010.5606314
   Chung TY, 2011, IEEE T CONSUM ELECTR, V57, P1336, DOI 10.1109/TCE.2011.6018892
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1811, DOI 10.1109/TCE.2008.4711239
   Lin T.-L., 2013, IEEE INT S INT SIGN
   Liu YQ, 2010, IEEE T CIRC SYST VID, V20, P600, DOI 10.1109/TCSVT.2009.2035838
   Müller K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/438148
   Peng Q, 2002, 2002 INTERNATIONAL CONFERENCE ON COMMUNICATIONS, CIRCUITS AND SYSTEMS AND WEST SINO EXPOSITION PROCEEDINGS, VOLS 1-4, P10, DOI 10.1109/ICCCAS.2002.1180560
   Persson D, 2008, IEEE T IMAGE PROCESS, V17, P145, DOI 10.1109/TIP.2007.914151
   Persson D, 2009, IEEE T IMAGE PROCESS, V18, P1048, DOI 10.1109/TIP.2009.2014261
   Qian XM, 2009, IEEE T MULTIMEDIA, V11, P683, DOI 10.1109/TMM.2009.2017609
   Seth K, 2010, IEEE T BROADCAST, V56, P467, DOI 10.1109/TBC.2010.2058030
   Tröger T, 2011, IEEE T BROADCAST, V57, P777, DOI 10.1109/TBC.2011.2173813
   Valente S, 2001, IEEE T CONSUM ELECTR, V47, P568, DOI 10.1109/30.964147
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Xu YL, 2008, IEEE T CONSUM ELECTR, V54, P1846, DOI 10.1109/TCE.2008.4711244
   Yan B, 2007, IEEE T CONSUM ELECTR, V53, P1546, DOI 10.1109/TCE.2007.4429250
   Yan B, 2012, IEEE T MULTIMEDIA, V14, P936, DOI 10.1109/TMM.2012.2184743
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yang S, 2011, IEEE T CONSUM ELECTR, V57, P1907, DOI 10.1109/TCE.2011.6131170
   Zhang Y., 2012, IEEE Transactions on Circuits and Systems for Video Technology, V22, P12, DOI DOI 10.1109/TCSVT.2011.2130450
   Zheng JH, 2005, IEEE T MULTIMEDIA, V7, P507, DOI 10.1109/TMM.2005.843343
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
NR 25
TC 4
Z9 5
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1811
EP 1822
DI 10.1016/j.jvcir.2014.09.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300001
DA 2024-07-18
ER

PT J
AU Mosleh, A
   Bouguila, N
   Ben Hamza, A
AF Mosleh, Ali
   Bouguila, Nizar
   Ben Hamza, A.
TI Bandlet-based sparsity regularization in video inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Bandlets; Inpainting; Patch fusion; Regularization; Video completion;
   Spatio-temporal flows; Video sequence; Missing information
ID IMAGE; COMPLETION; RECONSTRUCTIONS
AB We present a bandlet-based framework for video inpainting in order to complete missing parts of a video sequence. The framework applies spatio-temporal geometric flows extracted by bandlets to reconstruct the missing data. First, a priority-based exemplar scheme enhanced by a bandlet-based patch fusion generates a preliminary inpainting result. Then, the inpainting task is completed by a 3D volume regularization algorithm which takes advantage of bandlet bases in exploiting the anisotropic regularities. The method does not need extra processes in order to satisfy visual consistency. The experimental results demonstrate the effectiveness of our proposed video completion technique. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Mosleh, Ali] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 2W1, Canada.
   [Bouguila, Nizar; Ben Hamza, A.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Bouguila, N (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Off EV 007 632, 1515 St Catherine St West,EV-007-632, Montreal, PQ H3G 2W1, Canada.
EM mos_ali@encs.concordia.ca; bouguila@ciise.concordia.ca;
   hamza@ciise.concordia.ca
RI Bouguila, Nizar/AGN-5929-2022; Hamza, Abdessamad Ben/G-4571-2013;
   Bouguila, Nizar/AAJ-2518-2020
OI Ben Hamza, Abdessamad/0000-0002-3778-8167; Mosleh,
   Ali/0000-0003-4298-0126
CR [Anonymous], PROC CVPR IEEE
   Bertalmío M, 2001, PROC CVPR IEEE, P355
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bertalmío M, 2006, IEEE T IMAGE PROCESS, V15, P1934, DOI 10.1109/TIP.2006.877067
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Ghoniem M, 2009, IEEE IMAGE PROC, P1349, DOI 10.1109/ICIP.2009.5413568
   Grossauer H, 2003, LECT NOTES COMPUT SC, V2695, P225
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P539, DOI 10.1109/TIP.2005.863057
   Guleryuz OG, 2006, IEEE T IMAGE PROCESS, V15, P555, DOI 10.1109/TIP.2005.863055
   Jia JY, 2006, IEEE T PATTERN ANAL, V28, P832, DOI 10.1109/TPAMI.2006.108
   Jia JY, 2003, PROC CVPR IEEE, P643
   Jia YT, 2005, VISUAL COMPUT, V21, P601, DOI 10.1007/s00371-005-0313-3
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Le Pennec E, 2005, MULTISCALE MODEL SIM, V4, P992, DOI 10.1137/040619454
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Li X, 2009, IEEE T CIRC SYST VID, V19, P27, DOI 10.1109/TCSVT.2008.2005805
   Mallat S, 2008, COMMUN PUR APPL MATH, V61, P1173
   Mallat S, 2007, NUMER ALGORITHMS, V44, P205, DOI 10.1007/s11075-007-9092-4
   Mosleh A., 2011, P IEEE INT C MULT EX, P1
   Mosleh A, 2012, IEEE T MULTIMEDIA, V14, P1591, DOI 10.1109/TMM.2012.2198802
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Patwardhan K., 2005, P IEEE INT C IM PROC, P1169
   Patwardhan KA, 2007, IEEE T IMAGE PROCESS, V16, P545, DOI 10.1109/TIP.2006.888343
   Peyré G, 2005, ACM T GRAPHIC, V24, P601, DOI 10.1145/1073204.1073236
   Qu XB, 2007, CHIN OPT LETT, V5, P569
   Shih T., 2006, Proceedings of ACM International Conference on Multimedia, P133
   Shih TK, 2009, IEEE T CIRC SYST VID, V19, P347, DOI 10.1109/TCSVT.2009.2013519
   Shiratori T., 2006, Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P411
   Starck JL, 2004, ADV IMAG ELECT PHYS, V132, P287, DOI 10.1016/S1076-5670(04)32006-9
   Tang NC, 2011, IEEE T MULTIMEDIA, V13, P602, DOI 10.1109/TMM.2011.2112642
   Vu P. V., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2505, DOI 10.1109/ICIP.2011.6116171
   Wexler Y, 2007, IEEE T PATTERN ANAL, V29, P463, DOI 10.1109/TPAMI.2007.60
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Zhang YJ, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P516
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 38
TC 5
Z9 6
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 855
EP 863
DI 10.1016/j.jvcir.2014.01.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200014
DA 2024-07-18
ER

PT J
AU Zhou, JJ
   Zhou, DJ
   Goto, S
AF Zhou, Jinjia
   Zhou, Dajiang
   Goto, Satoshi
TI Alternating asymmetric search range assignment for bidirectional motion
   estimation in H.265/HEVC and H.264/AVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion estimation; Bidirectional prediction; Hardware implementation;
   Search range; Complexity reduction; Coding efficiency; H.264/AVC; HEVC
ID ALGORITHM
AB Bidirectional motion estimation (ME) significantly enhances video coding efficiency, whereas its huge complexity is also a critical problem for implementation. This paper presents alternating asymmetric search range assignment (AASRA) schemes to reduce the complexity by switching the use of a large and a small search ranges (SR.L and SR.S). A temporal AASRA (T-AASRA) scheme performs search range switching between past and future reference directions. A temporal-spatial AASRA (TS-AASRA) scheme performs more aggressive switching on the two dimensions of reference direction and MB/CTB index. T-AASRA and TS-AASRA achieve 43.5% and 65.2% complexity reduction, respectively, with small coding efficiency drop. Even after removing the factor of coding efficiency drop, the two schemes still show 38.4% and 54.7% equivalent complexity reduction. AASRA can also be combined with existing fast algorithms for further complexity saving, which has been demonstrated on hierarchical ME and dynamic search range selection algorithms. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhou, Jinjia; Zhou, Dajiang; Goto, Satoshi] Waseda Univ, Grad Sch Informat Prod & Syst, Kitakyushu, Fukuoka 8080135, Japan.
C3 Waseda University
RP Zhou, DJ (corresponding author), Waseda Univ, Grad Sch Informat Prod & Syst, 2-7 Hibikino, Kitakyushu, Fukuoka 8080135, Japan.
EM zhou@ruri.waseda.jp; zhou@fuji.waseda.jp; goto@waseda.jp
RI Zhou, Jinjia/AAP-8566-2020
OI Zhou, Jinjia/0000-0002-5078-0522
FU STARC, Japan; Japan Society for the Promotion of Science; Grants-in-Aid
   for Scientific Research [25870816] Funding Source: KAKEN
FX This research was supported in part by the University Joint Research
   Project of STARC, Japan. The work of J. Zhou was supported by the Japan
   Society for the Promotion of Science.
CR [Anonymous], 2001, ITU T VCEG M
   [Anonymous], 2011, H 264 AVC REFERENCE
   Bao XN, 2012, IEEE T MULTIMEDIA, V14, P237, DOI 10.1109/TMM.2011.2171677
   Bossen F., 2012, Common test conditions and software reference configurations
   Bross B., 2012, High Efficiency Video Coding (HEVC) Text Specification Draft 9
   Chen C.-Y., 2006, IEEE T CIRCUITS SYST, V53, P1549
   Chen YH, 2008, IEEE INT SYMP CIRC S, P29, DOI 10.1109/ISCAS.2008.4541346
   Chen ZX, 2008, IEEE IMAGE PROC, P1988, DOI 10.1109/ICIP.2008.4712173
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Chong W.I., 2003, IEEE INT C IM PROC, P24
   Ding L.-F., 2009, 2009 IEEE INT SOLID, P154
   Ding LF, 2010, IEEE J SOLID-ST CIRC, V45, P46, DOI 10.1109/JSSC.2009.2031787
   Goel S., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1557
   Li GL, 2006, IEICE T COMMUN, VE89B, P250, DOI 10.1093/ietcom/e89-b.1.250
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lin YK, 2008, IEEE T CIRCUITS-I, V55, P1526, DOI 10.1109/TCSI.2008.916681
   Lou CC, 2010, IEEE T CIRC SYST VID, V20, P1903, DOI 10.1109/TCSVT.2010.2087551
   Ndili O, 2011, IEEE T CIRC SYST VID, V21, P1214, DOI 10.1109/TCSVT.2011.2133990
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Schwarz H, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1929, DOI 10.1109/ICME.2006.262934
   Tsai TH, 2011, IEEE T CIRC SYST VID, V21, P1646, DOI 10.1109/TCSVT.2011.2133230
   Wang YJ, 2007, IEEE T CIRC SYST VID, V17, P578, DOI 10.1109/TCSVT.2007.894050
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu BF, 2008, IEEE T VLSI SYST, V16, P1385, DOI 10.1109/TVLSI.2008.2000526
   Yu-Kun Lin, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P314
   Zhou J., 2013, S VLSI TECHN CIRC, P287
   Zhou JJ, 2012, IEEE IMAGE PROC, P1557, DOI 10.1109/ICIP.2012.6467170
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 29
TC 4
Z9 4
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1275
EP 1286
DI 10.1016/j.jvcir.2014.01.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200051
DA 2024-07-18
ER

PT J
AU Zhu, SS
   Yung, NHC
AF Zhu, Shan-shan
   Yung, Nelson H. C.
TI Sub-scene segmentation using constraints based on Gestalt principles
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Unsupervised image segmentation; Semantic gap; Gestalt principles;
   Proximity grouping; Pattern clustering; Sub-scene segmentation;
   Sub-scene property; Mahalanobis distance
ID NATURAL IMAGES
AB In this paper, an unsupervised sub-scene segmentation method is proposed. It emphasizes on generating more integrated and semantically consistent regions instead of homogeneous but detailed over-segmented regions usually produced by conventional segmentation methods. Several properties of sub-scenes are explored such as proximity grouping, area of influence, similarity and harmony based on psychological principles. These properties are formulated into constraints that are used directly in the proposed sub-scene segmentation. A self-determined approach is conducted to get the optimal segmentation result based on the characteristics of each image in an unsupervised manner. The proposed method is evaluated over three datasets. For quantitative evaluation, the performance of the proposed method is on par with state-of-the-art unsupervised segmentation methods; for qualitative evaluation, the proposed method handles various sub-scenes well, and produces neater results. The sub-scenes segmented by the proposed method are generally consistent with natural scene categories. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Zhu, Shan-shan; Yung, Nelson H. C.] Univ Hong Kong, Dept Elect & Elect Engn, Lab Intelligent Transportat Syst Res, Hong Kong, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Zhu, SS (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Lab Intelligent Transportat Syst Res, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM sszhu@eee.hku.hk; nyung@eee.hku.hk
RI Zhu, Sybil/JSL-4924-2023; Yung, Nelson Hon Ching/C-1873-2009
CR [Anonymous], 2006, Conference on Computer Vision Pattern Recognition Workshop, DOI [DOI 10.1109/CVPRW.2006.48, 10.1109/CVPRW.2006.48]
   [Anonymous], COMPUTER VISION PATT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   BEAULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150, DOI 10.1109/34.16711
   Bertelli L, 2008, IEEE T PATTERN ANAL, V30, P1400, DOI 10.1109/TPAMI.2007.70785
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cour T, 2005, PROC CVPR IEEE, P1124
   Donoser M, 2009, IEEE I CONF COMP VIS, P817, DOI 10.1109/ICCV.2009.5459296
   Dunlop H., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), Computer Society Conference on, IEEE, P72
   Fan JP, 2008, IEEE T MULTIMEDIA, V10, P167, DOI 10.1109/TMM.2007.911775
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   He X, 2007, IASTED INT CONF SIGN, P7
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Ion A, 2011, IEEE I CONF COMP VIS, P2110, DOI 10.1109/ICCV.2011.6126486
   Kootstra Gert, 2011, IEEE International Conference on Robotics and Automation, P3423
   Kowalski R., 2009, Psychology, V5th
   Li-Jia L., 2007, INT C COMPUTER VISIO, P1
   Mairal J, 2008, LECT NOTES COMPUT SC, V5304, P43, DOI 10.1007/978-3-540-88690-7_4
   Malisiewicz T., 2007, Proceedings of the British Machine Vision Conference 2007, DOI DOI 10.5244/C.21.55
   Ming YS, 2012, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2012.6247755
   Mobahi H, 2011, INT J COMPUT VISION, V95, P86, DOI 10.1007/s11263-011-0444-0
   Peng B, 2013, PATTERN RECOGN, V46, P1020, DOI 10.1016/j.patcog.2012.09.015
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Song YZ, 2011, IEEE T IMAGE PROCESS, V20, P935, DOI 10.1109/TIP.2010.2087766
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Yu H, 2013, IEEE T GEOSCI REMOTE, V51, P995, DOI 10.1109/TGRS.2012.2203604
   Zhu S., 2011, 2011 IEEE Workshop on Microelectronics and Electron Devices, P1
NR 33
TC 6
Z9 8
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 994
EP 1005
DI 10.1016/j.jvcir.2014.02.017
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200027
DA 2024-07-18
ER

PT J
AU Quiroga, J
   Devernay, F
   Crowley, J
AF Quiroga, Julian
   Devernay, Frederic
   Crowley, James
TI Local scene flow by tracking in intensity and depth
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scene flow; 3D motion estimation; Image tracking; Brightness
   consistency; Depth data; Locally-rigid motion; Optical flow; Image
   warping
ID MOTION
AB The scene flow describes the motion of each 3D point between two time steps. With the arrival of new depth sensors, as the Microsoft Kinect, it is now possible to compute scene flow with a single camera, with promising repercussion in a wide range of computer vision scenarios. We propose a novel method to compute a local scene flow by tracking in a Lucas-Kanade framework. Scene flow is estimated using a pair of aligned intensity and depth images but rather than computing a dense scene flow as in most previous methods, we get a set of 3D motion vectors by tracking surface patches. Assuming a 3D local rigidity of the scene, we propose a rigid translation flow model that allows solving directly for the scene flow by constraining the 3D motion field both in intensity and depth data. In our experimentation we achieve very encouraging results. Since this approach solves simultaneously for the 2D tracking and for the scene flow, it can be used for motion analysis in existing 2D tracking based methods or to define scene flow descriptors. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Quiroga, Julian; Devernay, Frederic; Crowley, James] INRIA Grenoble Rhone Alpes, F-38334 Saint Ismier, France.
   [Quiroga, Julian] Pontificia Univ Javeriana, Dept Elect, Bogota, Colombia.
C3 Pontificia Universidad Javeriana
RP Quiroga, J (corresponding author), INRIA Grenoble Rhone Alpes, 655 Ave Europe, F-38334 Saint Ismier, France.
EM julian.quiroga@inria.fr; frederic.devernay@inria.fr;
   james.crowley@inria.fr
RI Devernay, Frédéric/B-4629-2009
OI Devernay, Frédéric/0000-0002-7061-4898
CR ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 1999, TECHNICAL REPORT
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], C COMP VIS PATT REC
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Basha T, 2010, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2010.5539791
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Bingbing Ni, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1147, DOI 10.1109/ICCVW.2011.6130379
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Devernay F., 2006, IEEE COMPUTER SOC C, V2, P2203
   GREEN PJ, 1984, J ROY STAT SOC B, V46, P149
   Hadfield S, 2011, IEEE I CONF COMP VIS, P2290, DOI 10.1109/ICCV.2011.6126509
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Herrera D, 2011, LECT NOTES COMPUT SC, V6855, P437, DOI 10.1007/978-3-642-23678-5_52
   HORN BKP, 1988, INT J COMPUT VISION, V2, P51, DOI 10.1007/BF00836281
   Huguet F., 2007, INT C COMPUTER VISIO, P1
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Letouzey A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.46
   Li R, 2008, COMPUT VIS IMAGE UND, V110, P75, DOI 10.1016/j.cviu.2007.04.002
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Neumann J, 2002, INT J COMPUT VISION, V47, P181, DOI 10.1023/A:1014597925429
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   QUIROGA J., 2012, Proc. IEEE Conf. Comput. Vision and Pattern Recognition Workshops, P50
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Scharstein D, 2003, PROC CVPR IEEE, P195
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Spies H, 2000, INT C PATT RECOG, P131, DOI 10.1109/ICPR.2000.905290
   Valgaerts L, 2010, LECT NOTES COMPUT SC, V6314, P568, DOI 10.1007/978-3-642-15561-1_41
   Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Vogel C, 2011, IEEE I CONF COMP VIS, P1291, DOI 10.1109/ICCV.2011.6126381
   Wedel A, 2008, LECT NOTES COMPUT SC, V5302, P739, DOI 10.1007/978-3-540-88682-2_56
   Zhang Y, 2001, PROC CVPR IEEE, P778
NR 41
TC 4
Z9 6
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 98
EP 107
DI 10.1016/j.jvcir.2013.03.018
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Park, CS
AF Park, Chun-Su
TI Level-set-based motion estimation algorithm for multiple reference frame
   motion estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion estimation; Level set; Multiple reference frames; Search space;
   Full search; H.264/AVC; Block matching; Exp-Golomb code
ID SUCCESSIVE ELIMINATION ALGORITHM; DIAMOND SEARCH ALGORITHM; H.264/AVC;
   STANDARD
AB Motion estimation (ME) has a variety of applications in image processing, pattern recognition, target tracking, and video compression. In modem video compression standards such as H.264/AVC and HEVC, multiple reference frame ME (MRFME) is adopted to reduce the temporal redundancy between successive frames in a video sequence. In MRFME, the motion search process is conducted using additional reference frames, thereby obtaining better prediction signal as compared to single reference frame ME (SRFME). However, its high computational complexity makes it difficult to be utilized in real-world applications. In order to reduce the computational complexity of MRFME, this paper proposes a level-set-based ME algorithm (LSME) without any penalty in the rate-distortion (RD) performance. First, the proposed algorithm partitions the motion search space into multiple level sets based on a rate constraint. The proposed algorithm then controls the ME process on the basis of the predetermined level sets. Experimental results show that the proposed algorithm reduces the ME time by up to 83.46% as compared to the conventional full search (FS) algorithm. (C) 2013 Elsevier Inc. All rights reserved.
C1 Sangmyung Univ, Informat & Telecommun Engn Dept, Cheonan, South Korea.
C3 Sangmyung University
RP Park, CS (corresponding author), Sangmyung Univ, Informat & Telecommun Engn Dept, Cheonan, South Korea.
EM cspark@smu.ac.kr
FU Sangmyung University
FX This research was supported by a 2013 Research Grant from Sangmyung
   University.
CR Ahn TG, 2004, IEEE T CIRC SYST VID, V14, P1265, DOI 10.1109/TCSVT.2004.835146
   [Anonymous], 2005, JVTN046
   [Anonymous], 2003, ITU T REC F IN PRESS
   Bardone D, 2008, IEEE INT SYMP SIGNAL, P287, DOI 10.1109/ISSPIT.2008.4775706
   BEI CD, 1985, IEEE T COMMUN, V33, P1132, DOI 10.1109/TCOM.1985.1096214
   Chen Z., 2003, JVTG016
   Chen Z., 2002, JVTF017
   Cheong H.Y., 2002, JVTE023
   Choi C, 2009, IEEE T CONSUM ELECTR, V55, P2335, DOI 10.1109/TCE.2009.5373807
   Coban MZ, 1998, IEEE T IMAGE PROCESS, V7, P769, DOI 10.1109/83.668031
   Di W., 2003, ASCI, V2, P910
   Kim JN, 2010, LECT NOTES COMPUT SC, V6111, P336
   Kwon SK, 2006, J VIS COMMUN IMAGE R, V17, P186, DOI 10.1016/j.jvcir.2005.05.010
   Li L, 2004, J ELECTRON TEST, V20, P667, DOI 10.1007/s10677-004-4254-0
   LI W, 1995, IEEE T IMAGE PROCESS, V4, P105, DOI 10.1109/83.350809
   Li YF, 2007, IEEE T CONSUM ELECTR, V53, P535, DOI 10.1109/TCE.2007.381726
   Lim HY, 2008, IEEE T CONSUM ELECTR, V54, P1938, DOI 10.1109/TCE.2008.4711256
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Ouyang WL, 2012, IEEE T PATTERN ANAL, V34, P127, DOI 10.1109/TPAMI.2011.106
   Sarwer MG, 2009, IEEE T CIRC SYST VID, V19, P1196, DOI 10.1109/TCSVT.2009.2020322
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tombari F, 2009, IEEE T PATTERN ANAL, V31, P129, DOI 10.1109/TPAMI.2008.46
   Xu XZ, 2008, IEEE T CIRC SYST VID, V18, P285, DOI 10.1109/TCSVT.2008.918122
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 25
TC 4
Z9 5
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1269
EP 1275
DI 10.1016/j.jvcir.2013.08.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700005
DA 2024-07-18
ER

PT J
AU Dolui, S
   Kuurstra, A
   Patarroyo, ICS
   Michailovich, OV
AF Dolui, Sudipto
   Kuurstra, Alan
   Patarroyo, Ivan C. Salgado
   Michailovich, Oleg V.
TI A new similarity measure for non-local means filtering of MRI images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Magnetic resonance imaging; Image denoising; Neighbourhood filtering;
   Non-local means; Similarity measure; Rician distribution; Non-central
   chi square distribution; Medical image processing
ID MAGNETIC-RESONANCE IMAGES; RICIAN NOISE; FILTRATION; SPACE; REDUCTION;
   REMOVAL
AB In this paper, the application of non-local means (NLM) filtering on MRI images is investigated. An essential component of any NLM-based algorithm is its similarity measure used to compare pixel intensities. Unfortunately, virtually all existing similarity measures used to denoise MRI images have been derived under the assumption of additive white Gaussian noise contamination. Since this assumption is known to fail at low values of signal-to-noise ratio (SNR), alternative formulations of these measures which take into account the correct (Rician) statistics of the noise are required. Accordingly, the main contribution of the present work is to introduce a new similarity measure for NLM filtering of MRI images, which is derived under bona fide statistical assumptions and proves to posses important theoretical advantages over alternative formulations. The utility and viability of the proposed method is demonstrated through a series of numerical experiments using both in silico and in vivo MRI data. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Dolui, Sudipto; Kuurstra, Alan; Patarroyo, Ivan C. Salgado; Michailovich, Oleg V.] Univ Waterloo, Dept Elect & Comp Engn, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Dolui, S (corresponding author), Univ Waterloo, Dept Elect & Comp Engn, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.
EM sdolui@uwaterloo.ca; akuurstr@uwaterloo.ca; icsalgad@uwaterloo.ca;
   olegm@uwaterloo.ca
RI Dolui, Sudipto/AFR-8723-2022
CR Abramowitz M., 1964, HDB MATH FUNCTIONS F
   Aja-Fernández S, 2008, IEEE T IMAGE PROCESS, V17, P1383, DOI 10.1109/TIP.2008.925382
   Anand CS, 2010, MAGN RESON IMAGING, V28, P842, DOI 10.1016/j.mri.2010.03.013
   Bao P, 2003, IEEE T MED IMAGING, V22, P1089, DOI 10.1109/TMI.2003.816958
   Basu S., 2006, MED IMAGE COMPUTING, ps117
   Boulanger J, 2007, IEEE T PATTERN ANAL, V29, P1096, DOI 10.1109/TPAMI.2007.1064
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Cocosco C.A., 1997, NeuroImage
   Coupé P, 2008, IEEE T MED IMAGING, V27, P425, DOI 10.1109/TMI.2007.906087
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle C.A., 2011, P INT C IM PROC
   Deledalle CA, 2012, INT J COMPUT VISION, V99, P86, DOI 10.1007/s11263-012-0519-6
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   Fan A, 2003, LECT NOTES COMPUT SC, V2732, P148
   Foi A, 2011, I S BIOMED IMAGING, P1809, DOI 10.1109/ISBI.2011.5872758
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   GLASSER ML, 1994, J MATH ANAL APPL, V183, P577, DOI 10.1006/jmaa.1994.1164
   Grimmett G., 2001, Probability and random processes, V3rd edn
   GUDBJARTSSON H, 1995, MAGNET RESON MED, V34, P910, DOI 10.1002/mrm.1910340618
   He LL, 2009, IEEE T MED IMAGING, V28, P165, DOI 10.1109/TMI.2008.927338
   HEALY DM, 1992, IEEE T INFORM THEORY, V38, P840, DOI 10.1109/18.119740
   HENKELMAN RM, 1985, MED PHYS, V12, P232, DOI 10.1118/1.595711
   Hilton M., 1996, WAVELETS MED BIOL, ps93
   Kervrann C, 2007, LECT NOTES COMPUT SC, V4485, P520
   Krissian K, 2009, IEEE T IMAGE PROCESS, V18, P2265, DOI 10.1109/TIP.2009.2025553
   Lin X., 2011, 4 INT C BIOM ENG INF, V1, ps233
   Liu H, 2010, MAGN RESON IMAGING, V28, P1485, DOI 10.1016/j.mri.2010.06.023
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Macovski A, 1996, MAGNET RESON MED, V36, P494, DOI 10.1002/mrm.1910360327
   Manjón JV, 2008, MED IMAGE ANAL, V12, P514, DOI 10.1016/j.media.2008.02.004
   Manjón JV, 2012, MED IMAGE ANAL, V16, P18, DOI 10.1016/j.media.2011.04.003
   Manjón JV, 2010, J MAGN RESON IMAGING, V31, P192, DOI 10.1002/jmri.22003
   MCVEIGH ER, 1985, MED PHYS, V12, P586, DOI 10.1118/1.595679
   Michailovich O., LECT NOTES COMPUTER, V6361, ps606
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Pizurica A, 2006, CURR MED IMAGING, V2, P247, DOI 10.2174/157340506776930665
   Polzehl J, 2006, PROBAB THEORY REL, V135, P335, DOI 10.1007/s00440-005-0464-1
   Rajan J, 2011, PHYS MED BIOL, V56, P5221, DOI 10.1088/0031-9155/56/16/009
   Seeger M, 2002, ADV NEUR IN, V14, P905
   Teuber T, 2012, COMPUT STAT DATA AN, V56, P3821, DOI 10.1016/j.csda.2012.05.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEAVER JB, 1991, MAGNET RESON MED, V21, P288, DOI 10.1002/mrm.1910210213
   Wiest-Daessle N., 2008, P 11 INT C MED IM CO
   Wiest-Daesslé N, 2007, LECT NOTES COMPUT SC, V4792, P344
   Wood JC, 1999, MAGNET RESON MED, V41, P631, DOI 10.1002/(SICI)1522-2594(199903)41:3<631::AID-MRM29>3.0.CO;2-Q
   Wright GA, 1997, IEEE SIGNAL PROC MAG, V14, P56, DOI 10.1109/79.560324
   XU YS, 1994, IEEE T IMAGE PROCESS, V3, P747, DOI 10.1109/83.336245
   Zaroubi S, 2000, MAGN RESON IMAGING, V18, P59, DOI 10.1016/S0730-725X(99)00100-9
NR 52
TC 24
Z9 24
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1040
EP 1054
DI 10.1016/j.jvcir.2013.06.011
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700028
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kwon, HJ
   Lee, SH
   Bae, TW
   Sohng, KI
AF Kwon, Hyuk-Ju
   Lee, Sung-Hak
   Bae, Tae-Wuk
   Sohng, Kyu-Ik
TI Compensation of de-saturation effect in HDR imaging using a real scene
   adaptation model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE iCAM06; Illuminant estimation; HDR; De-saturation; Chromatic adaptation;
   White point shift; Tone compression; Camera characterization
ID COLORIMETRIC CHARACTERIZATION; APPEARANCE MODEL; COLOR
AB The iCAM06, a high dynamic range rendering process, contains chromatic adaptation method based on the CIECAM02 model. The D factor, degree of adaptation, in the chromatic adaptation of the iCAM06 is the function of the adapting luminance level, but it does not consider the visual white point shift according to the variation of luminance level. The iCAM06 acquires a blurred illuminant image. So, each pixel has a different illuminant color. When some of the colors cover the entire image, a de-saturation effect appears around these colors. The simply modified D factor to reduce the de-saturation effect causes unsuitable changes in the degree of adaptation. Therefore, we propose a new method to find the global illuminant information and the D factor for the illuminant in the HDR image rendering process. Comparing the proposed with the conventional method, we confirm that the proposed method provides better illuminant estimation and color representation. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Kwon, Hyuk-Ju; Lee, Sung-Hak; Sohng, Kyu-Ik] Kyungpook Natl Univ, Sch Elect Engn & Comp Sci, Taegu 702701, South Korea.
   [Bae, Tae-Wuk] Stanford Univ, SCIEN Stanford Ctr Image Syst Engn, Stanford, CA 94305 USA.
C3 Kyungpook National University; Stanford University
RP Lee, SH (corresponding author), Kyungpook Natl Univ, Sch Elect Engn & Comp Sci, 1370 Sankyug Dong, Taegu 702701, South Korea.
EM shak2@ee.knu.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2010-0022136]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2010-0022136).
CR [Anonymous], 2000, WILEY SERIES PURE AP
   BERNS RS, 1995, J ELECTRON IMAGING, V4, P360, DOI 10.1117/12.218935
   CIE Pub. 15. 2 Colorimetry, 1986, CIE PUB 15 2 COL
   Fairchild M.D., 2005, Color Appearance Models, V2nd
   Hirakawa K., 2005, IEEE C IM PROC ICIP, P984
   Hong GW, 2001, COLOR RES APPL, V26, P76, DOI 10.1002/1520-6378(200102)26:1<76::AID-COL8>3.0.CO;2-3
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Hung P.C., 1993, J ELECTRON IMAGING, V2, P53
   Hunt R., 1987, REPROD COLOUR PHOTOG
   HUNT RWG, 1975, J PHOTOGR SCI, V23, P112
   Johnson GM, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P36
   Kang H. R., 1992, Journal of Electronic Imaging, V1, P125, DOI 10.1117/12.57526
   KANG HR, 1992, J IMAGING SCI TECHN, V36, P162
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Lee SH, 2008, IEICE T ELECTRON, VE91C, P1608, DOI 10.1093/ietele/e91-c.10.1608
   Lee SH, 2008, IEICE T FUND ELECTR, VE91A, P1438, DOI 10.1093/ietfec/e91-a.6.1438
   Luo MR, 1998, COLOR RES APPL, V23, P138, DOI 10.1002/(SICI)1520-6378(199806)23:3<138::AID-COL5>3.0.CO;2-R
   Moroney N., 2002, P COL IM C, P23
   Morvic J., 2008, COLOR GAMUT MAPPING
   Po-Chieh Hung, 1991, Proceedings of the SPIE - The International Society for Optical Engineering, V1448, P164, DOI 10.1117/12.45355
   SUZUKI S, 1990, APPL OPTICS, V29, P5187, DOI 10.1364/AO.29.005187
   VESA Display Metrology Committee, 2001, FLAT PAN DISPL MEAS
NR 22
TC 10
Z9 15
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 678
EP 685
DI 10.1016/j.jvcir.2012.03.001
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900005
DA 2024-07-18
ER

PT J
AU Kim, JH
   Jang, WD
   Sim, JY
   Kim, CS
AF Kim, Jin-Hwan
   Jang, Won-Dong
   Sim, Jae-Young
   Kim, Chang-Su
TI Optimized contrast enhancement for real-time image and video dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Video dehazing; Image restoration; Contrast enhancement;
   Temporal coherence; Image enhancement; Optimized dehazing; Atmospheric
   light estimation
AB A fast and optimized dehazing algorithm for hazy images and videos is proposed in this work. Based on the observation that a hazy image exhibits low contrast in general, we restore the hazy image by enhancing its contrast. However, the overcompensation of the degraded contrast may truncate pixel values and cause information loss. Therefore, we formulate a cost function that consists of the contrast term and the information loss term. By minimizing the cost function, the proposed algorithm enhances the contrast and preserves the information optimally. Moreover, we extend the static image dehazing algorithm to real-time video dehazing. We reduce flickering artifacts in a dehazed video sequence by making transmission values temporally coherent. Experimental results show that the proposed algorithm effectively removes haze and is sufficiently fast for real-time dehazing applications. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Kim, Jin-Hwan; Jang, Won-Dong; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Sim, Jae-Young] Ulsan Natl Inst Sci & Technol, Sch Elect & Comp Engn, Ulsan, South Korea.
C3 Korea University; Ulsan National Institute of Science & Technology
   (UNIST)
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM arite@korea.ac.kr; wdjang@mcl.korea.ac.kr; jysim@unist.ac.kr;
   changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
FU National Research Foundation of Korea (NRF); Korea government (MEST)
   [2012-011031]; Basic Science Research Program through the NRF of Korea;
   MEST [2012-0000916, 2010-0006595]
FX The work of J.-H. Kim, W.-D. Jang, and C.-S. Kim was supported partly by
   the National Research Foundation of Korea (NRF) grant funded by the
   Korea government (MEST) (No. 2012-011031), and partly by Basic Science
   Research Program through the NRF of Korea funded by the MEST (No.
   2012-0000916). The work of J.-Y. Sim was supported by Basic Science
   Research Program through the NRF of Korea funded by the MEST
   (2010-0006595).
CR Ancuti CO, 2011, LECT NOTES COMPUT SC, V6493, P501
   [Anonymous], 1995, Studies in Optics
   [Anonymous], 2007, Using OpenMP: Portable Shared Memory Parallel Programming
   [Anonymous], MORGAN KAUFMANN SERI
   [Anonymous], PHOT CS5
   Carr P, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P103, DOI 10.1109/DICTA.2009.25
   Dong XM, 2010, IEEE IMAGE PROC, P3593, DOI 10.1109/ICIP.2010.5651965
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hsu CY, 2011, IEEE T IMAGE PROCESS, V20, P2502, DOI 10.1109/TIP.2011.2131663
   Kim JH, 2012, IEEE IMAGE PROC, P969, DOI 10.1109/ICIP.2012.6467023
   Kim JH, 2011, INT CONF ACOUST SPEE, P1273
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Kratz L, 2009, IEEE I CONF COMP VIS, P1701, DOI 10.1109/ICCV.2009.5459382
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Oakley JP, 2007, IEEE T IMAGE PROCESS, V16, P511, DOI 10.1109/TIP.2006.887736
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Rovamo J, 2000, VISION RES, V40, P3841, DOI 10.1016/S0042-6989(00)00181-4
   Schaul L, 2009, IEEE IMAGE PROC, P1629, DOI 10.1109/ICIP.2009.5413700
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Szeliski R., 2010, TEXTS COMPUTER SCI
   Tan R., 2008, P IEEE CVPR, P1
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yu J, 2011, INT CONF ACOUST SPEE, P1245
   Zhang JW, 2011, VISUAL COMPUT, V27, P749, DOI 10.1007/s00371-011-0569-8
NR 34
TC 356
Z9 445
U1 4
U2 169
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2013
VL 24
IS 3
BP 410
EP 425
DI 10.1016/j.jvcir.2013.02.004
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 120CU
UT WOS:000317149200017
DA 2024-07-18
ER

PT J
AU Guo, Z
   Zhang, YN
   Xia, Y
   Lin, ZG
   Fan, YY
   Feng, DD
AF Guo, Zhe
   Zhang, Yan-Ning
   Xia, Yong
   Lin, Zeng-Gang
   Fan, Yang-Yu
   Feng, David Dagan
TI Multi-pose 3D face recognition based on 2D sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D face recognition; Sparse representation; Feature extraction; Discrete
   conformal mapping; Multi-pose; Intrinsic feature; 2D attribute image;
   Sparse coefficient
ID REGISTRATION; IMAGES
AB The increasing availability of 3D facial data offers the potential to overcome the difficulties inherent with 2D face recognition, including the sensitivity to illumination conditions and head pose variations. In spite of their rapid development, many 3D face recognition algorithms in the literature still suffer from the intrinsic complexity in representing and processing 3D facial data. In this paper, we propose the intrinsic 3D facial sparse representation (I3DFSR) algorithm for multi-pose 3D face recognition. In this algorithm, each 3D facial surface is first mapped homeomorphically onto a 2D lattice, where the value at each site is the depth of the corresponding vertex on the 3D surface. Each 2D lattice is then interpolated and converted into a 2D facial attribute image. Next, the sparse representation is applied to those attribute images. Finally, the identity of each query face can be obtained by using the corresponding sparse coefficients. The innovation of our approach lies in the strategy of converting irregular 3D facial surfaces into regular 2D attribute images such that 3D face recognition problem can be solved by using the sparse representation of those attribute images. We compare the proposed algorithm to three widely used 3D face recognition algorithms in the GavabDB database, to six state-of-the-art algorithms in the FRGC2.0 database, and to three baseline algorithms in the NPU3D database. Our results show that the proposed I3DFSR algorithm can substantially improve the accuracy and efficiency of multi-pose 3D face recognition. (C) 2012 Published by Elsevier Inc.
C1 [Guo, Zhe; Zhang, Yan-Ning; Xia, Yong; Lin, Zeng-Gang] Northwestern Polytech Univ, Sch Comp Sci, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China.
   [Guo, Zhe; Fan, Yang-Yu] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
   [Guo, Zhe; Xia, Yong; Feng, David Dagan] Univ Sydney, Sch Informat Technol, Biomed & Multimedia Informat Technol BMIT Res Grp, Sydney, NSW 2006, Australia.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; University of Sydney
RP Zhang, YN (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian 710072, Peoples R China.
EM ynzhangyjvci@gmail.com
RI Xia, Yong/C-6567-2008; Xia, Yong/J-4273-2013
OI Feng, Dagan/0000-0002-3381-214X
FU ARC; National Natural Science Foundation of China [60872145, 60903126];
   Foundation of Northwestern Polytechnical University [JC201122]
FX The authors would like to thanks the anonymous reviewers whose comments
   greatly improved the paper. This work was supported in part by ARC, in
   part by the National Natural Science Foundation of China under Grants
   60872145 and 60903126, and in part by the Foundation of Northwestern
   Polytechnical University under Grant JC201122.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Abate AF, 2006, INT C PATT RECOG, P1183
   Akarun L., 2005, P EUR SIGN PROC C EU
   [Anonymous], 2005, CVPR WORKSH
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Boehnen C, 2009, LECT NOTES COMPUT SC, V5558, P12, DOI 10.1007/978-3-642-01793-3_2
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Eck M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P173, DOI 10.1145/218380.218440
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Guan P, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P41, DOI 10.1109/ICME.2008.4607366
   Heseltine T, 2004, LECT NOTES COMPUT SC, V3212, P684
   Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850
   HORMANN K, 2001, THESIS U ERLANGEN
   Husken M., 2005, IEEE WORKSHOP FACE R, P174
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Li S.Z., 2005, Handbook of Face Recognition
   Liu CJ, 2000, IEEE T PATTERN ANAL, V22, P570, DOI 10.1109/34.862196
   Lu X., 2006, Proc. IEEE Conf. Computer Vision and Pattern Recognition, V2, P1377
   Mahoor MH, 2009, PATTERN RECOGN, V42, P445, DOI 10.1016/j.patcog.2008.08.012
   Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moreno A.B., 2004, WHITENING RACE ESSAY, P75
   Nagesh P, 2009, PROC CVPR IEEE, P1518, DOI 10.1109/CVPRW.2009.5206657
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 1999, ADV NEUR IN, V11, P803
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Scheenstra A, 2005, LECT NOTES COMPUT SC, V3546, P891
   Shaanxi Key Lab of Speech & Image Information Processing (SAIIP), 2010, NW POL U 3D NPU3D FA
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   Smeets D, 2010, FORENSIC SCI INT, V201, P125, DOI 10.1016/j.forsciint.2010.03.023
   Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2
   Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977
   Tang HL, 2010, IEEE INT CON MULTI, P334, DOI 10.1109/ICME.2010.5582586
   ter Haar FB, 2009, GRAPH MODELS, V71, P77, DOI 10.1016/j.gmod.2008.12.003
   Thevenaz P, 1997, P SOC PHOTO-OPT INS, V3169, P236, DOI 10.1117/12.292794
   Venkatesh YV, 2009, PATTERN RECOGN LETT, V30, P1128, DOI 10.1016/j.patrec.2009.04.007
   Wang S, 2007, IEEE T PATTERN ANAL, V29, P1209, DOI 10.1109/TPAMI.2007.1050
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Zhang GP, 2011, PATTERN RECOGN LETT, V32, P1009, DOI 10.1016/j.patrec.2011.02.004
   Zhang YN, 2012, PATTERN RECOGN LETT, V33, P530, DOI 10.1016/j.patrec.2011.12.006
NR 58
TC 10
Z9 13
U1 0
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 117
EP 126
DI 10.1016/j.jvcir.2012.08.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000005
DA 2024-07-18
ER

PT J
AU Zhu, SY
   Zeng, B
AF Zhu, Shuyuan
   Zeng, Bing
TI A novel enhancement for hierarchical image coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image coding; Hierarchical image coding; R-D coding performance;
   Constrained quantization
ID TRANSFORM; COMPRESSION; REPRESENTATION
AB Hierarchical image coding usually codes a down-sampled version of an original image and then the difference between the original image and a reconstructed version that is interpolated from the down-sampled layer. In this paper, we demonstrate, for the first time, that when the bit-rate used to code the residual layer falls into a critical region (which covers almost all typical bit-rates used in practice), it often happens that all pixels in the down-sampled layer would be deteriorated if the corresponding coded residuals are added into them. To avoid this problem, we first propose a "naive" solution: no coded residuals will be added back into the down-sampled layer; whereas coded residuals will be added only into the interpolated pixels. Then, we propose to apply a constrained quantization technique during the coding of the residual layer so that all residual pixels at the interpolated positions will end up with an improved quality. To verify its effectiveness, we conduct extensive tests to show that the gap between the hierarchical coding scheme and its single-level counterpart (which is typically around 2-3 dB in the 2-level hierarchy) will be filled up by a rather big percentage. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Zeng, Bing] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
   [Zhu, Shuyuan] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Sichuan, Peoples R China.
C3 Hong Kong University of Science & Technology; University of Electronic
   Science & Technology of China
RP Zeng, B (corresponding author), Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Kowloon, Hong Kong, Peoples R China.
EM eezeng@ece.ust.hk
CR Adelson E. H., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P50, DOI 10.1117/12.976485
   [Anonymous], CURVES SURFACES FITT
   [Anonymous], 109181ITUT ISOIEC IS
   [Anonymous], P PICT COD S CAMBR M
   BOURBAKIS NG, 1989, PATTERN RECOGN, V22, P317, DOI 10.1016/0031-3203(89)90079-4
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Ford W, 2015, NUMERICAL LINEAR ALGEBRA WITH APPLICATIONS: USING MATLAB, P379, DOI 10.1016/B978-0-12-394435-1.00018-1
   Illgner K, 1997, IEEE J SEL AREA COMM, V15, P1688, DOI 10.1109/49.650043
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   PARK SH, 1991, SIGNAL PROCESS, V22, P25, DOI 10.1016/0165-1684(91)90026-F
   Radha H, 1996, IEEE T IMAGE PROCESS, V5, P1610, DOI 10.1109/83.544569
   SAHINOGLOU H, 1991, P SOC PHOTO-OPT INS, V1605, P793, DOI 10.1117/12.50286
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Said A, 1996, IEEE T IMAGE PROCESS, V5, P1303, DOI 10.1109/83.535842
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   STILLER C, 1991, P SOC PHOTO-OPT INS, V1605, P47, DOI 10.1117/12.50291
   Strintzis MG, 1998, IEEE T IMAGE PROCESS, V7, P155, DOI 10.1109/83.660993
   Tanaka Y, 2009, IEEE T IMAGE PROCESS, V18, P269, DOI 10.1109/TIP.2008.2008078
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Tran TD, 1999, IEEE T IMAGE PROCESS, V8, P1493, DOI 10.1109/83.799878
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
   WU XL, 1995, IEEE T IMAGE PROCESS, V4, P34, DOI 10.1109/83.350815
   Zhu SY, 2010, IEEE T CIRC SYST VID, V20, P1385, DOI 10.1109/TCSVT.2010.2046051
NR 26
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 12
EP 22
DI 10.1016/j.jvcir.2012.10.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600002
DA 2024-07-18
ER

PT J
AU Hung, CH
   Hang, HM
AF Hung, Chao-Hsiung
   Hang, Hsueh-Ming
TI A reduced-complexity image coding scheme using decision-directed
   wavelet-based contourlet transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contourlet transform; Wavelet-based contourlet transform; Bit-plane
   coding; Directional filter bank; Directional transform; Wavelet
   transform; Image coding; Computational complexity reduction; Adaptive
   Directional Transform
ID FILTER BANKS; MEAN SHIFT; COMPRESSION; DESIGN
AB Recently the wavelet-based contourlet transform (WBCT) is adopted for image coding because it matches better image textures of different orientations. However, its computational complexity is very high. In this paper, we propose three tools to enhance the WBCT coding scheme, in particular, on reducing its computational complexity. First, we propose short-length 2-D filters for directional transform. Second, the directional transform is applied to only a few selected subbands and the selection is done by a mean-shift-based decision procedure. Third, we fine-tune the context tables used by the arithmetic coder in WBCT coding to improve coding efficiency and to reduce computation. Simulations show that, at comparable coded image quality, the proposed scheme saves over 92% computing time of the original WBCT scheme. Comparing to the conventional 2-D wavelet coding schemes, it produces clearly better subjective image quality. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Hung, Chao-Hsiung; Hang, Hsueh-Ming] Natl Chiao Tung Univ, Dept Elect Engn, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Hang, HM (corresponding author), Natl Chiao Tung Univ, Dept Elect Engn, Hsinchu, Taiwan.
EM hmhang@mail.nctu.edu.tw
RI Hang, Hsueh-Ming/K-7848-2012
FU NSC, Taiwan [98-2221-E-009-076]; MOEA, Taiwan [99-EC-17-A-01-11-0016];
   Intelligent Information Communications Research Center, NCTU
FX The first author would like to thank Dr. Jang-Jer Tsai for his valuable
   suggestions on improving the quality of this paper. This work was
   supported in parts by the NSC, Taiwan under Grant 98-2221-E-009-076, by
   the MOEA, Taiwan under Grant 99-EC-17-A-01-11-0016, and by the
   Intelligent Information Communications Research Center, NCTU.
CR [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chang CL, 2007, IEEE T IMAGE PROCESS, V16, P1289, DOI 10.1109/TIP.2007.894242
   Chappelier V, 2006, IEEE T IMAGE PROCESS, V15, P2892, DOI 10.1109/TIP.2006.877526
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Ding WP, 2007, IEEE T IMAGE PROCESS, V16, P416, DOI 10.1109/TIP.2006.888341
   Do M. N., 2001, THESIS SWISS FEDERAL
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Eslami R., 2004, P C INF SCI SYST PRI, P784
   Eslami R, 2007, IEEE T IMAGE PROCESS, V16, P1152, DOI 10.1109/TIP.2007.891791
   Hsiang ST, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL III, P662, DOI 10.1109/ISCAS.2000.856147
   Hung C.-H., 2008, IEEE INT C IM P ICIP
   Hung C.-H., 2009, IEEE INT S CIRC SYST
   Lin YP, 1996, MULTIDIM SYST SIGN P, V7, P263, DOI 10.1007/BF01826246
   Liu Z, 2005, IEEE T IMAGE PROCESS, V14, P411, DOI 10.1109/TIP.2004.841199
   Lu Y., 2005, IEEE INT C AC SPEECH
   Nguyen TT, 2007, IEEE T SIGNAL PROCES, V55, P949, DOI 10.1109/TSP.2006.887140
   Nguyen TT, 2005, IEEE T SIGNAL PROCES, V53, P3895, DOI 10.1109/TSP.2005.855410
   Oppenheim A. V., 1989, Discrete -Time Signal Processing
   PHOONG SM, 1995, IEEE T SIGNAL PROCES, V43, P649, DOI 10.1109/78.370620
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Shapiro J. M., 1993, DCC '93. Data Compression Conference (Cat. No.93TH0536-3), P214, DOI 10.1109/DCC.1993.253128
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P421, DOI 10.1109/83.298396
   Tian C, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P49
   Vetterli M, 2001, IEEE SIGNAL PROC MAG, V18, P59, DOI 10.1109/79.952805
   Wang DM, 2006, IEEE T IMAGE PROCESS, V15, P2413, DOI 10.1109/TIP.2006.875207
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu X., 1997, P 31 ASILOMAR C SIGN, V2, P1378, DOI DOI 10.1109/DCC.1997.582047
   Xu JZ, 2001, APPL COMPUT HARMON A, V10, P290, DOI 10.1006/acha.2000.0345
   Yang JY, 2008, IEEE T IMAGE PROCESS, V17, P1555, DOI 10.1109/TIP.2008.926159
NR 35
TC 6
Z9 11
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1128
EP 1143
DI 10.1016/j.jvcir.2012.06.008
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900015
DA 2024-07-18
ER

PT J
AU Ruiz-Hidalgo, J
   Morros, JR
   Aflaki, P
   Calderero, F
   Marqués, F
AF Ruiz-Hidalgo, J.
   Morros, J. R.
   Aflaki, P.
   Calderero, F.
   Marques, F.
TI Multiview depth coding based on combined color/depth segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth map; Virtual view; Multiview video coding; 3DTV;
   Segmentation-based video coding; Region-merging; Color-depth
   segmentation; Texture coding
ID SHORTEST SPANNING TREE; IMAGE SEGMENTATION
AB In this paper, a new coding method for multiview depth video is presented. Considering the smooth Structure and sharp edges of depth maps, a segmentation based approach is proposed. This allows further preserving the depth contours thus introducing fewer artifacts in the depth perception of the video. To reduce the cost associated with partition coding, an approximation of the depth partition is built using the decoded color view segmentation. This approximation is refined by sending some complementary information about the relevant differences between color and depth partitions. For coding the depth content of each region, a decomposition into orthogonal basis is used in this paper although similar decompositions may be also employed. Experimental results show that the proposed segmentation based depth coding method outperforms H.264/AVC and H.264/MVC by more than 2 dB at similar bitrates. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Ruiz-Hidalgo, J.; Morros, J. R.; Marques, F.] Univ Politecn Cataluna, Dept Signal Theory & Commun, ES-08034 Barcelona, Spain.
   [Aflaki, P.] Tampere Univ Technol, FIN-33101 Tampere, Finland.
   [Calderero, F.] Univ Pompeu Fabra, Barcelona 08018, Spain.
C3 Universitat Politecnica de Catalunya; Tampere University; Pompeu Fabra
   University
RP Ruiz-Hidalgo, J (corresponding author), Univ Politecn Cataluna, Dept Signal Theory & Commun, Jordi Girona 1-3, ES-08034 Barcelona, Spain.
EM j.ruiz@upc.edu; ramon.morros@upc.edu; payman.aflaki@tut.fi;
   felipe.calderero@upf.edu; ferran.marques@upc.edu
RI Morros, Josep Ramon/F-8227-2013; Ruiz-Hidalgo, Javier/F-8137-2013
OI Morros, Josep Ramon/0000-0002-1395-487X; Ruiz-Hidalgo,
   Javier/0000-0001-6774-685X
CR [Anonymous], 2005, H264 ITUT ISOIEC JTC
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Calderero F, 2010, IEEE T IMAGE PROCESS, V19, P1567, DOI 10.1109/TIP.2010.2043008
   COCQUEREZ JP, 1995, ANAL DGIMAGES FILTRA
   Gilge M., 1989, Signal Processing: Image Communication, V1, P153, DOI 10.1016/0923-5965(89)90007-6
   *INT VIS MED GROUP, 2005, MSR 3D VID DOWNL
   JUNG J, 2007, EXCEL ADD IN COMPUTI
   Kwok SH, 2004, IEEE T CIRC SYST VID, V14, P852, DOI 10.1109/TCSVT.2004.828334
   Kwok SH, 1997, IEEE T IMAGE PROCESS, V6, P328, DOI 10.1109/83.551705
   MAITRE M, 2010, J VISUAL COMMUN IMAG, V21
   Merkle P, 2009, SIGNAL PROCESS-IMAGE, V24, P73, DOI 10.1016/j.image.2008.10.010
   MERKLE P, 2007, IEEE T CSVT, P1461
   MORRIS OJ, 1986, IEE PROC-F, V133, P146, DOI 10.1049/ip-f-1.1986.0025
   Oh H, 2006, LECT NOTES COMPUT SC, V4319, P898
   Ozaktas H.M., 2007, 3 DIMENSIONAL TELEVI
   PHILIPPFOLIGUET S, 2008, J MULTIMED, V3
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Shen GW, 2010, IEEE IMAGE PROC, P3393, DOI 10.1109/ICIP.2010.5652792
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Torres L., 1996, VIDEO CODING 2 GENER
   Vilaplana V, 2008, IEEE T IMAGE PROCESS, V17, P2201, DOI 10.1109/TIP.2008.2002841
   WOOSHIK K, 2010, VIPC 2010
   Yoon SU, 2007, IEEE T CIRC SYST VID, V17, P1450, DOI 10.1109/TCSVT.2007.905363
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   ZHANG N, 2009, IIH MSP 09, P316
NR 25
TC 7
Z9 8
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 42
EP 52
DI 10.1016/j.jvcir.2011.08.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, YB
   Zhao, DB
   Liu, HB
   Li, YP
   Ma, SW
   Gao, W
AF Zhang, Yongbing
   Zhao, Debin
   Liu, Hongbin
   Li, Yongpeng
   Ma, Siwei
   Gao, Wen
TI Side information generation with auto regressive model for low-delay
   distributed video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding; Low delay; Auto regressive model; Side
   information; Wyner-Ziv; Probability based fusion; Centrosymmetric
   rearrangement; Least mean square
AB In this paper, we propose an auto regressive (AR) model to generate the high quality side information (SI) for Wyner-Ziv (WZ) frames in low-delay distributed video coding, where the future frames are not used for generating SI. In the proposed AR model, the SI of each pixel within the current WZ frame t is generated as a linear weighted summation of the pixels within a window in the previous reconstructed WZ/Key frame t - 1 along the motion trajectory. To obtain accurate SI, the AR model is used in both temporal directions in the reconstructed WZ/Key frames t - 1 and t - 2, and then the regression results are fused with traditional extrapolation result based on a probability model. In each temporal direction, a weighting coefficient set is computed by the least mean square method for each block in the current WZ frame t. In particular, due to the unavailability of future frames in low-delay distributed video coding, a centrosymmetric rearrangement is proposed for pixel generation in the backward direction. Various experimental results demonstrate that the proposed model is able to achieve a higher performance compared to the existing SI generation methods. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Zhang, Yongbing] Tsinghua Univ, Grad Sch Shenzhen, Beijing 100084, Peoples R China.
   [Zhang, Yongbing; Zhao, Debin; Liu, Hongbin] Harbin Inst Technol, Harbin 150006, Peoples R China.
   [Li, Yongpeng] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Ma, Siwei; Gao, Wen] Peking Univ, Beijing 100871, Peoples R China.
C3 Tsinghua Shenzhen International Graduate School; Tsinghua University;
   Harbin Institute of Technology; Chinese Academy of Sciences; Institute
   of Computing Technology, CAS; Peking University
RP Zhang, YB (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Beijing 100084, Peoples R China.
EM ybzhang@jdl.ac.cn; dbzhao@jdl.ac.cn; hbliu@jdl.ac.cn; ypli@jdl.ac.cn;
   swma@jdl.ac.cn; wgao@jdl.ac.cn
RI Zhao, Debin/JEP-0204-2023; fang, yu/KCK-2014-2024; zhang,
   yuyang/IVV-5089-2023; liu, shilong/JZD-8395-2024
FU National Science Foundations of China [60736043]; Major State Basic
   Research Development Program of China (973 Program) [2009CB320905]
FX This work was supported in part by the National Science Foundations of
   China: 60736043 and the Major State Basic Research Development Program
   of China (973 Program 2009CB320905).
CR Aaron A, 2004, PROC SPIE, V5308, P520, DOI 10.1117/12.527204
   AARON A, 2006, P INT PICT COD S BEI
   AARON A, 2002, IEEE INT DAT COMPR C
   Adikari ABB, 2006, ELECTRON LETT, V42, P398, DOI 10.1049/el:20060302
   [Anonymous], P AS C SIGN SYST PAC
   [Anonymous], IEEE INT C IM PROC A
   [Anonymous], 1963, LOW DENSITY PARITY C
   [Anonymous], P PICT COD S SAN FRA
   Ascenso J, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P593
   ASCENSO J, 2006, IEEE INT C IM PROC A
   BORCHERT S, 2007, P PICT COD S PCS 200
   Chien WJ, 2006, IEEE INT SYMP CIRC S, P5415
   Garcia-Frias J, 2001, IEEE COMMUN LETT, V5, P417, DOI 10.1109/4234.957380
   LI X, 2006, EURASIP J APPL SIGNA
   Li X, 2007, IEEE T CIRC SYST VID, V17, P953, DOI 10.1109/TCSVT.2007.896656
   Li Z, 2007, IEEE T IMAGE PROCESS, V16, P98, DOI 10.1109/TIP.2006.884934
   Li Z, 2006, IEEE T CIRC SYST VID, V16, P1430, DOI 10.1109/TCSVT.2006.883511
   Natrio L., 2005, P INT WORKSHOP VERY
   Pradhan SS, 2003, IEEE T INFORM THEORY, V49, P626, DOI 10.1109/TIT.2002.808103
   PURI R, 2002, ALL C COMM CONTR COM
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   TIAN T, 2003, IEEE INT DAT COMPR C
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zhang YM, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 2, PROCEEDINGS, P18, DOI 10.1109/MINES.2009.201
NR 24
TC 15
Z9 19
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 229
EP 236
DI 10.1016/j.jvcir.2011.10.001
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100022
DA 2024-07-18
ER

PT J
AU Dong, J
   Ngan, KN
AF Dong, Jie
   Ngan, King Ngi
TI Adaptive pre-interpolation filter for high efficiency video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Pre-interpolation; Adaptive interpolation filter; Adaptive loop filter;
   H.264; KTA; HEVC
AB The proposed interpolation filter comprises two concatenating filters, adaptive pre-interpolation filter (APIF) and the normative interpolation filter in H.264/AVC. The former is applied only to the integer pixels in the reference frames: the latter generates all the sub-position samples, supported by the output of APIF. The convolution of APIF and the standard filter minimizes the motion prediction error on a frame basis. APIF preserves the merits of the adaptive interpolation filter (AIF) and the adaptive loop filter (ALF) in the key technical area (KTA) software and at the same time overcomes their drawbacks. The experimental results show that APIF outperforms either AIF or ALF. Compared with the joint use of AIF and ALF, APIF provides comparable performance, but has much lower complexity. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Dong, Jie; Ngan, King Ngi] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Dong, J (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM jdong@ee.cuhk.edu.hk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
FU Chinese University of Hong Kong [1903003]
FX This work was partially supported by a grant from the Chinese University
   of Hong Kong under the Focused Investment Scheme (Project 1903003).
CR [Anonymous], 2010, VCEGAM91 ITUT
   [Anonymous], 2001, ITU T VCEG M AUST TE
   Dong J., 2009, IEEE INT C IM PROC 0
   DONG J, IEEE T CIRC IN PRESS
   *ISO IEC JTC1 SC29, 2009, N10361 ISOIECJTC1SC2
   *ITU T, 2009, COM16C181 ITUT
   *ITU T, 2008, VCEGA138 ITUT
   *ITU T, 2008, COM16C402 ITUT
   *ITU T, 2008, VCEGA118 ITUT
   *ITU T, 2008, COM16C437 ITUT
   Rusanovskyy D, 2009, IEEE T CIRC SYST VID, V19, P1239, DOI 10.1109/TCSVT.2009.2022708
   Vatis Y, 2009, IEEE T CIRC SYST VID, V19, P179, DOI 10.1109/TCSVT.2008.2009259
   Zhang L, 2009, SIGNAL PROCESS-IMAGE, V24, P263, DOI 10.1016/j.image.2008.12.001
   KEY TECHNICAL AREA K
   H 264 AVC TEST MODEL
NR 15
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2011
VL 22
IS 8
SI SI
BP 697
EP 703
DI 10.1016/j.jvcir.2010.12.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 837SJ
UT WOS:000296223200002
DA 2024-07-18
ER

PT J
AU Lou, JA
   Sun, MT
AF Lou, Jian
   Sun, Ming-Ting
TI Rate-distortion optimized rate-allocation for motion-compensated
   predictive video codecs using PixelRank
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; Encoder optimization; Rate-distortion optimization;
   PageRank; PixelRank; Rate-allocation
ID ALGORITHM
AB Inter-frame dependencies are usually ignored in video encoder coding parameter selection. This gives a non-optimal solution and degrades the compression performance. A mathematical model to estimate the importance of each pixel on the reconstructed video quality, called PixelRank, is developed in this paper. Theoretical analysis on the parameters used for PixelRank score calculation dealing with the video coding optimization problem is also given. The PixelRank algorithm tracks the importance of each pixel and distributes the PixelRank scores. With the PixelRank scores for all the pixels, MB-based quantization parameters are adjusted accordingly. Based on this technique, the rate can be allocated more accurately according to the importance of the pixels, thus achieving better overall rate-distortion performance. Compared to the non-optimized scheme in H.264/AVC, the proposed scheme can reduce 13.53% of the average bitrate and up to 25.17% of bitrate in the simulations. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lou, Jian] Motorola Inc, San Diego, CA 92121 USA.
   [Sun, Ming-Ting] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
C3 University of Washington; University of Washington Seattle
RP Lou, JA (corresponding author), Motorola Inc, 6450 Sequence Dr, San Diego, CA 92121 USA.
EM lou@motorola.com; sun@ee.washington.edu
CR [Anonymous], 1996, Interview
   [Anonymous], PAGERANK CITATION RA
   [Anonymous], 1964, Jacqueline Bernard to Stan Cohen
   [Anonymous], 1998, Computer Networks and ISDN Systems, DOI [DOI 10.1016/S0169-7552(98)00110-X, 10.1016/S0169-7552(98)00110-X]
   BJONTEGAARD D, 2001, VCEGM33
   BRINKMEIER M, 2006, ACM T INTERNET TECHN, P282
   Dong JP, 2008, IEEE INT SYMP CIRC S, P628, DOI 10.1109/ISCAS.2008.4541496
   EVERETT H, 1963, OPER RES, V11, P399, DOI 10.1287/opre.11.3.399
   Flierl M., 2011, Video coding with superimposed motion-compensted signals
   FLIERL M, 2003, IEEE T CIRCUITS SYST, P587
   Golub G. H., 1983, MATRIX COMPUTATIONS
   Grimmett G., 1989, PROBABILITY RANDOM P
   Huang J., 2007, P PICT COD S
   *ISO IEC, 1962, 138182 ISOIEC
   *ISO IEC, 2001, 111722 ISOIEC
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Merritt L., 2007, IEEE, 1-4244-1437-7/07, P309
   Que CS, 2006, INT C COMMUN CIRCUIT, P118, DOI 10.1109/ICCCAS.2006.284599
   Ribas-Corbera J, 2000, IEEE T CIRC SYST VID, V10, P1154, DOI 10.1109/76.875518
   Srinivasan S, 2004, SIGNAL PROCESS-IMAGE, V19, P851, DOI 10.1016/j.image.2004.06.005
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   TAN YH, 2009, IEEE REG 10 C, P1
   WANG H, 2007, IEEE INT C AC SPEECH, V1, P1149
   WEDI T, 2003, IEEE T CIRCUITS SYST, P577
   Westerink PH, 1999, IBM J RES DEV, V43, P471, DOI 10.1147/rd.434.0471
   Yu L, 2009, SIGNAL PROCESS-IMAGE, V24, P247, DOI 10.1016/j.image.2009.02.003
   Yu Y, 2001, IEEE T CIRC SYST VID, V11, P345, DOI 10.1109/76.911160
   Zhang DD, 2009, SIGNAL PROCESS-IMAGE, V24, P357, DOI 10.1016/j.image.2009.03.003
   Zhou SM, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P681, DOI 10.1109/ICME.2006.262537
   2000, VIDEO CODING
NR 31
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2011
VL 22
IS 2
SI SI
BP 107
EP 116
DI 10.1016/j.jvcir.2010.10.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 720GL
UT WOS:000287268600001
DA 2024-07-18
ER

PT J
AU Gai, JD
   Stevenson, RL
AF Gai, Jiading
   Stevenson, Robert L.
TI Robust contour tracking based on a coupling between geodesic active
   contours and conditional random fields
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contour tracking; 3D conditional random field; Geodesic active contours;
   Level set methods; Variational inference; Belief propagation; Motion
   detection; Markov random field
AB This paper presents a new general framework for contour tracking based on the synergy of two powerful segmentation tools, namely, spatial temporal conditional random fields (CRFs) and geodesic active contours (GACs). The contours of targets are modeled using a level set representation. The evolution of the level sets toward the target contours is formulated as one of the joint region-based (CRF) and boundary-based (GAC) segmentations under a unified Bayesian framework. A variational inference technique is used to solve this otherwise intractable inference problem, leading to approximate MAP solutions of both the new 3D spatial temporal CRF and the GAC model. The tracking result of the previous frame is used to initialize the curve in the current frame. Typical contour tracking problems are considered and experimental results are given to illustrate the robustness of the method against noise and its accurate performance in moving objects boundary localization. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Gai, Jiading; Stevenson, Robert L.] Univ Notre Dame, Dept Elect Engn, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Gai, JD (corresponding author), Univ Notre Dame, Dept Elect Engn, 275 Fitzpatrick Hall, Notre Dame, IN 46556 USA.
EM jgai@nd.edu; rls@nd.edu
CR ALI MM, 1979, BIOMETRIKA, V66, P513
   Aubert G., 2006, MATH PROBLEMS IMAGE, V147, P26, DOI DOI 10.1007/978-0-387-44588-5
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chen T, 2000, LECT NOTES COMPUT SC, V1935, P256
   CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841
   Huang R, 2006, I S BIOMED IMAGING, P426
   Jones TN, 1998, PROC CVPR IEEE, P330, DOI 10.1109/CVPR.1998.698627
   Jordan Michael Irwin, 1999, LEARNING GRAPHICAL M
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KHAN Z, 2004, ECCV, V4, P279
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Lafferty John, 2001, INT C MACH LEARN ICM
   Niethammer M, 2004, PROC CVPR IEEE, P660
   OSHER S, 1982, MATH COMPUT, V38, P339, DOI 10.2307/2007275
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   PARAGIOS N, 2000, ECCV, V2, P224
   PEARLY J, 1987, PROBABILISTIC REASON
   Rao S., 2002, APPL NUMERICAL METHO
   Rathi Y, 2005, PROC CVPR IEEE, P2
   Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   YILMAZ A, 2004, AS C COMP VIS ACCV 2
   Yin Z., 2007, IEEE Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383237
   Zhou X, 2007, LECT NOTES COMPUT SC, V4843, P832
NR 35
TC 6
Z9 8
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 33
EP 47
DI 10.1016/j.jvcir.2010.10.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300004
DA 2024-07-18
ER

PT J
AU Gao, SH
   Chia, LT
   Cheng, XG
AF Gao, Shenghua
   Chia, Liang-Tien
   Cheng, Xiangang
TI Web image concept annotation with better understanding of tags and
   visual features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Large-scale dataset; Concept prediction; Mid-level visual feature;
   Concept-tag co-occurrence matrix; K-nearest neighbor; Tag understanding;
   Precision and Recall; Grouping
AB This paper focuses on improving the semi-manual method for web image concept annotation. By sufficiently studying the characteristics of tag and visual feature, we propose the Grouping-Based-Precision & Recall-Aided (GBPRA) feature selection strategy for concept annotation. Specifically, for visual features, we construct a more robust middle level feature by concatenating the k-NN results for each type of visual feature. For tag, we construct a concept-tag co-occurrence matrix, based on which the probability of an image belonging to certain concept can be calculated. By understanding the tags' quality and groupings' semantic depth, we propose a grouping based feature selection method; by studying the tags' distribution, we adopt Precision and Recall as a complementary indicator for feature selection. In this way, the advantages of both tags and visual features are boosted. Experimental results show our method can achieve very high Average Precision, which greatly facilitates the annotation of large-scale web image dataset. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Gao, Shenghua; Chia, Liang-Tien; Cheng, Xiangang] Nanyang Technol Univ, Sch Comp Engn, CeMNet, Singapore, Singapore.
C3 Nanyang Technological University
RP Gao, SH (corresponding author), Nanyang Technol Univ, Sch Comp Engn, CeMNet, Singapore, Singapore.
EM gaos0004@ntu.edu.sg; asltchia@ntu.edu.sg; ch0061ng@ntu.edu.sg
RI Chia, Liang-Tien/A-9874-2008
CR ANIL AV, 1998, PATTERN RECOGN, V31, P1921
   [Anonymous], P 11 INT C COMP VIS
   [Anonymous], 1996, ACL, DOI [10.3115/981863.981904, DOI 10.3115/981863.981904]
   [Anonymous], P IEEE ICCV OCT
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   ESCALANTE HJ, 2007, BMVC
   Felzenszwalb P., 2008, IEEE INT C COMP VIS
   GAO S, 2009, ACM MM WORKSH WEB SC
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LI JL, 2007, P INT C COMP VIS
   LIU S, 2004, COOPIS DOA ODBASE, P1050
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Shapiro L.G., 2003, Computer Vision, Vsecond
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   WANG H, 2006, MULTIMEDIA 06 P 14 A, P109
   WANG M, MSRTR200930
   WEINBERGER KQ, 2008, MM 08, P111
   Yang Jianchao, 2009, IEEE COMP SOC C COMP
NR 22
TC 2
Z9 2
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 806
EP 814
DI 10.1016/j.jvcir.2010.08.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500005
DA 2024-07-18
ER

PT J
AU Xiang, XG
   Zhao, DB
   Wang, QA
   Ma, SW
   Gao, W
AF Xiang, Xinguang
   Zhao, Debin
   Wang, Qiang
   Ma, Siwei
   Gao, Wen
TI A joint encoder-decoder error control framework for stereoscopic video
   coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic video coding; Error concealment; Error resilience; Joint
   encoder-decoder error contra; Inter-view refreshment; End-to-end
   distortion model; Overlapped block motion and disparity; compensation;
   Rate-distortion
ID MODE SELECTION; CONCEALMENT; COMMUNICATION
AB Stereoscopic video coding (SSVC) plays an important role in various 3D video applications. In SSVC, robust stereoscopic video transmission over error-prone networks is still a challenge problem to be solved. In this paper, we propose a joint encoder-decoder error control framework for SSVC, where error-resilient source coding, transmission network conditions, and error concealment scheme are jointly considered to achieve better error robustness performance. The proposed joint encoder-decoder error control framework includes two parts: an error concealment algorithm at the decoder side and a rate-distortion optimized error resilience algorithm at the encoder side. For error concealment at the decoder side, an overlapped block motion and disparity compensation based error concealment scheme is proposed to adaptively utilize inter-view correlations and temporal correlations. For error resilience at the encoder side, first, the inter-view refreshment is proposed for SSVC to suppress error propagations. Then, an end-to-end distortion model for SSVC is derived, which jointly considers the transmission network conditions, inter-view refreshment, and error concealment tools at the decoder side. Finally, based on the derived end-to-end distortion model, the rate-distortion optimized error resilience algorithm is presented to adaptively select inter-view, inter- or intra-coding for SSVC. The experimental results show that the proposed joint encoder-decoder error control framework has superior error robustness performance for stereoscopic video transmission over error-prone networks. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Xiang, Xinguang; Zhao, Debin; Wang, Qiang] Harbin Inst Technol, Harbin 150006, Peoples R China.
   [Ma, Siwei; Gao, Wen] Peking Univ, Beijing 100871, Peoples R China.
   [Ma, Siwei] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Harbin Institute of Technology; Peking University; Beihang University
RP Xiang, XG (corresponding author), Harbin Inst Technol, Harbin 150006, Peoples R China.
EM xgxiang@jdl.ac.cn
RI Zhao, Debin/JEP-0204-2023; Wang, Qiang/AAV-7131-2021
FU National Science Foundation [60736043]; National Basic Research Program
   of China (973 Program) [2009CB320905]
FX This work was supported in part by National Science Foundation
   (60736043) and National Basic Research Program of China (973 Program,
   2009CB320905)
CR Aign S., 1995, IEEE INT C COMM, V3, P1778
   [Anonymous], H 264 AVC REFERENCE
   ARGYROPOULOS S, 2007, 3DTV C 2007 MAY
   Cai JF, 2005, J VIS COMMUN IMAGE R, V16, P412, DOI 10.1016/j.jvcir.2004.11.012
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Chen T, 2003, ITRE2003: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: RESEARCH AND EDUCATION, P55, DOI 10.1109/ITRE.2003.1270571
   Chen Y, 2008, IEEE T MULTIMEDIA, V10, P2, DOI 10.1109/TMM.2007.911223
   CHUNG TY, 2007, 8 PAC RIM C MULT DEC
   Côté G, 1999, SIGNAL PROCESS-IMAGE, V15, P25, DOI 10.1016/S0923-5965(99)00022-3
   Fecker U, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P267, DOI 10.1109/MMSP.2008.4665087
   Gao J, 2007, PROCEEDINGS OF 2007 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES, VOLS 1 AND 2, P1014
   HASKELL P, 1992, P ICASSP, V3, P545
   Knorr S, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P820
   Lam W. M., 1993, IEEE INT C AC SPEECH, pV417
   Liu SJ, 2008, IEEE INT SYMP CIRC S, P3470, DOI 10.1109/ISCAS.2008.4542206
   Lukacs M. E., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P521
   Pang LJ, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P1665, DOI 10.1109/ICCIAS.2006.295344
   Song K, 2009, J VIS COMMUN IMAGE R, V20, P281, DOI 10.1016/j.jvcir.2009.02.002
   Stockhammer T, 2002, P PACK VID WORKSH PI
   TAN AS, 2007, 3DTV C, P1
   Wenger S., 1999, SG16 ITUT
   Wu DP, 2000, IEEE J SEL AREA COMM, V18, P977, DOI 10.1109/49.848251
   XIANG X, 2009, P SPIE VISUAL COMMUN, V7257
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang Y, 2007, IEEE T MULTIMEDIA, V9, P445, DOI 10.1109/TMM.2006.887989
NR 25
TC 4
Z9 6
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 975
EP 985
DI 10.1016/j.jvcir.2010.07.002
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500020
DA 2024-07-18
ER

PT J
AU Li, QZ
   Wang, WJ
AF Li, Qing-Zhong
   Wang, Wen-Jin
TI Low-bit-rate coding of underwater color image using improved wavelet
   difference reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Wavelet difference reduction (WDR); Underwater image compression;
   Wavelet transform; Low-bit-rate coding; Underwater acoustic channel;
   Underwater color image; Underwater observation; Wavelet tree; Image
   transmission
ID COMPRESSION
AB Underwater image compression has been the key technology for transmitting massive amount of image data via underwater acoustic channel with limited bandwidth. According to the characteristics of underwater color images, an efficient underwater image compression method has been developed. The new coding scheme employs a wavelet-based preprocessing method to remove the visual redundancy, and adopts a Wavelet Tree-based Wavelet Difference Reduction (WTWDR) algorithm to remove the spatial redundancy of underwater color images. Instead of scanning whole transformed image like the WDR method, the difference reduction coding is used for each significant wavelet tree in the proposed WTWDR algorithm based on the correlation between the subbands of higher levels and lower levels of a transformed image. The experimental results show that for underwater color images the proposed method outperforms both WDR and SPIHT at very low bit rates in terms of compression ratio and reconstructed quality, while for natural images it has similar performance with WDR and SPIHT. Hence, the proposed approach is especially suitable for underwater color image compression at very low bit rates. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Li, Qing-Zhong; Wang, Wen-Jin] Ocean Univ China, Coll Engn, Qingdao 266100, Peoples R China.
C3 Ocean University of China
RP Li, QZ (corresponding author), Ocean Univ China, Coll Engn, 238 Song Ling Rd, Qingdao 266100, Peoples R China.
EM lqzhlz@yahoo.com.cn
RI Li, Zhongrui/AAB-9111-2019
OI Li, Zhongrui/0000-0001-5371-7628
FU China High Technology Program [2006AA09Z237]
FX This work is supported by the China High Technology Program under
   contract No. 2006AA09Z237.
CR Adams MD, 2000, IEEE T IMAGE PROCESS, V9, P1010, DOI 10.1109/83.846244
   Negahdaripour S, 2000, COMPUT VIS IMAGE UND, V79, P162, DOI 10.1006/cviu.2000.0845
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   TIAN J, 1998, WAVELET IMAGE VIDEO
   TIAN J, 1996, P DAT COMPR C SNOWB
   Walker JS, 2000, OPT ENG, V39, P1891, DOI 10.1117/1.602573
   WALKER JS, LOW POWER LOW MEMORY
   WALKER JS, 2000, P IEEE INT C IM PROC
   Yuan Y, 2005, IEE P-VIS IMAGE SIGN, V152, P9, DOI 10.1049/ip-vis:20051183
   YUAN Y, 2004, P IEEE INT C AC SPEE
NR 11
TC 18
Z9 20
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 762
EP 769
DI 10.1016/j.jvcir.2010.05.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400015
DA 2024-07-18
ER

PT J
AU Chung, TY
   Jung, IL
   Song, K
   Kim, CS
AF Chung, Tae-Young
   Jung, Il-Lyong
   Song, Kwanwoong
   Kim, Chang-Su
TI Multi-view video coding with view interpolation prediction for 2D camera
   arrays
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view video coding; Hierarchical B prediction; View interpolation;
   Bilateral criterion; 2D camera array; 3D-TV; H.264/AVC
AB An efficient compression algorithm for multi-view video sequences, which are captured by two-dimensional (2D) camera arrays, is proposed in this work. First, we propose a novel prediction structure, called three-dimensional hierarchical B prediction (3DHBP), which can efficiently reduce horizontal inter-view redundancies, vertical inter-view redundancies, and temporal redundancies in multi-view videos. Second, we develop a view interpolation scheme based on the bilateral disparity estimation. The interpolation scheme yields high quality view frames by adapting disparity estimation and compensation procedures using the information in neighboring frames. Simulation results demonstrate that the proposed multi-view video coding algorithm provides significantly better rate-distortion (R-D) performance than the conventional algorithm, by employing the 3DHBP structure and using interpolated view frames as additional reference frames. 2009 Elsevier Inc. All rights reserved.
C1 [Chung, Tae-Young; Jung, Il-Lyong; Song, Kwanwoong; Kim, Chang-Su] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University
RP Kim, CS (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM loveloo117@korea.ac.kr; illyong@korea.ac.kr; kwsong71@korea.ac.kr;
   changsukim@korea.ac.kr
OI Kim, Chang-Su/0000-0002-4276-1831
CR ALPARONE L, 1996, P ICASSP 96 ATL GA U
   [Anonymous], N6720 ISOIEC JTC1SC2
   [Anonymous], TR200122 MERL
   Bjotegaard G., 2001, VCEGM33
   Cao X, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/351452
   DROESE M, 2004, 3D IM C
   Fehn C., 2002, PROC INT BROADCAST C, P357
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   *ISO IEC JTC1 SC29, 2008, M15413 ISOIEC JTC1SC
   *ISO IEC JTC1 SC29, 2007, JVTW081 ISOIEC JTC1S
   *ISO IEC JTC1 SC29, 2007, JVTV207 ISOIEC JTC1S
   *ISO IEC JTC1 SC29, 2005, N6909 ISOIEC JTC1 SC
   *ISO IEC JTC1 SC29, 2007, JVTV080 ISOIEC JTC1S
   *ISO IEC JTC1 SC29, 2006, JVTV040 ISOIEC JTC1S
   *ISO IEC JTC1 SC29, 2006, JVTU211 ISOIEC JTC1S
   *ISO IEC JTC1 SC29, 2005, N7282 ISOIEC JTC1SC2
   *ISO IEC JTC1 SC29, 2005, M12338 ISOIEC JTC1SC
   *ISO IEC JTC1 SC29, 2007, JVTX208 ISOIEC JTC1S
   KIM H, 2003, P ICIP 03 BARC SPAIN
   KIMATA H, 2004, PICT COD S
   KITAHARA M, 2006, P INT C MULT EXP ICM
   LEVOY M, 2000, P ACM SIGGRAPH NEW O
   MARTINIAN E, 2006, P ICIP 06 ATL GA US
   MARTINIAN E, 2006, PICT COD S PCS BEIJ
   MERKLE P, 2006, P INT C MULT EXP ICM
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Onural L., 2004, EUR WORKSH INT KNOWL
   OZKALAYCI B, 2007, PICT COD S PCS
   OZKALAYCI B, 2007, 3DTV C
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Song K, 2009, J VIS COMMUN IMAGE R, V20, P281, DOI 10.1016/j.jvcir.2009.02.002
   Tourapis AM, 2005, IEEE T CIRC SYST VID, V15, P119, DOI 10.1109/TCSVT.2004.837021
   VETRO A, 2004, PICT COD S PCS
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Yamamoto K, 2007, IEEE T CIRC SYST VID, V17, P1436, DOI 10.1109/TCSVT.2007.903802
   YANG JC, 2002, P EUR WORKSH REND
   YEA S, 2008, 3DTV C
   YEA S, 2007, P ICIP 07 SAN ANT TX
   ZHANG C, 2004, P EUR S REND
NR 39
TC 11
Z9 13
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 474
EP 486
DI 10.1016/j.jvcir.2009.10.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600010
DA 2024-07-18
ER

PT J
AU Liu, XG
   Yoo, KY
AF Liu, Xingang
   Yoo, Kook-Yeol
TI Fast Interframe mode decision algorithm based on mode mapping and MB
   activity for MPEG-2 to H.264/AVC transcoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Transcoding; MPEG-2; H.264/AVC; Interframe; Mode decision (MD); Mode
   mapping; MB activity; RDCost
AB Recently the latest video coding standard H.264/AVC is widely used for the mobile and low bitrate video codec in the various multimedia terminals. On the other hand, the MPEG-2 MP@HL codec has become the center of digital video contents since it is the standard codec for the Digital TV (DTV). To provide the bridge between the contents in MPEG-2 and mobile terminals, the transcoding of MPEG-2 contents into H.264/AVC format is an inevitable technology in the digital video market. The main bottleneck in the process lies in the computational complexity. In H.264/AVC, the variable block size (VBS) mode decision (MID) is used in the Interframe for the improved performance in the motion compensated prediction. For the macroblock (MB) which cannot be accurately predicted with one motion vector (MV), it is partitioned into smaller blocks and predicted with different MVs. In addition, SKIP and Intra modes are also permitted in the Interframe MID of H.264/AVC to further ameliorate the encoding performance. With the VBS MD technology, the Inter prediction accuracy can be improved significantly. However, the incidental side-effect is the high computational complexity. In this paper, we propose a fast Interframe MID algorithm for MPEG-2 to H.264/AVC transcoding. The relationships between SKIP and Intra modes are detected at first to map these two kinds of modes directly from MPEG-2 to H.264/AVC. And then the MB activity will be scaled by the residual DCT energy obtained from the MPEG-2 decoding process to estimate the block sizes of the MB mode for H.264/AVC Interframe MD. In our proposed method, the original redundant candidate modes can be eliminated effectively, resulting in the reduction of the computational complexity. It can reduce about 85% Rate-to-Distortion Cost (RDCost) computing and 45% entire processing time compared with the well-known cascaded transcoder while maintaining the video quality. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Liu, Xingang; Yoo, Kook-Yeol] Yeungnam Univ, Dept Informat & Commun Engn, Kyungsan 712749, Kyungpook, South Korea.
C3 Yeungnam University
RP Yoo, KY (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, 214-1 Dae Dong, Kyungsan 712749, Kyungpook, South Korea.
EM kyoo@yu.ac.kr
FU Yeungnam University [208-A-235-162]
FX This research was supported by the Yeungnam University research grants
   in 2008 (208-A-235-162).
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], 2000, 14496C2 ISOIEC
   [Anonymous], 1996, REFERENCE SOFTWARE M
   DIAMOND GA, 1980, J CLIN INVEST, V65, P1210, DOI 10.1172/JCI109776
   Fernández-Escribano G, 2008, IEEE T CIRC SYST VID, V18, P172, DOI 10.1109/TCSVT.2008.918115
   *IMPL STUD GROUP, 2002, N4964 MPEG ISOIEC JT
   *ITU TEL, 1996, H263 ITUT
   Jing X, 2004, ELECTRON LETT, V40, P1050, DOI 10.1049/el:20045243
   *JVT, 2006, REF SOFTW COMM DRAFT
   *JVT, 2003, JOINT VID TEAM JVT I
   Lee JY, 2003, LECT NOTES COMPUT SC, V2899, P410
   LEE JY, 2004, IEEE INT C MULT EXP, V2
   LI S, 2007, IEICE T INFORM SYS D, V90
   Liu XZ, 2008, HEALTH POLICY PLANN, V23, P1, DOI 10.1093/heapol/czm042
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wu D, 2005, IEEE T CIRC SYST VID, V15, P953, DOI 10.1109/TCSVT.2005.848304
NR 17
TC 14
Z9 14
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 155
EP 166
DI 10.1016/j.jvcir.2009.05.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800009
DA 2024-07-18
ER

PT J
AU Angulo, J
AF Angulo, Jesus
TI Geometric algebra colour image representations and derived total
   orderings for morphological operators - Part I: Colour quaternions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Colour mathematical morphology; Colour quaternion; Quaternion total
   ordering; Nonlinear colour filtering; Colour feature extraction; Colour
   image representation; Hypercomplex representation; Colour potential
   function; Quaternion complete lattice
ID FOURIER-TRANSFORMS; HYPERCOMPLEX; ENHANCEMENT; INFORMATION
AB The definition of morphological operators for colour images requires a total ordering for colour points. A colour can be represented by different algebraic structures, in this paper we focus on real quaternions. The paper presents two main contributions. On the one hand, we have studied different alternatives to introduce the scalar part to obtain full colour quaternions. On the other hand, several total lexicographic orderings for quaternions have been defined, according to the various quaternion decompositions. The properties of these quaternionic orderings have been characterised to enable the identification of the most useful ones to define colour morphological operators. The theoretical results are illustrated with examples of processed images which show the usefulness of the proposed operators for real life complex problems. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Angulo, Jesus] MINES Paristech, CMM Ctr Morphol Math Math & Syst, F-77305 Fontainebleau, France.
C3 Universite PSL; MINES ParisTech
RP Angulo, J (corresponding author), MINES Paristech, CMM Ctr Morphol Math Math & Syst, 35 Rue St Honore, F-77305 Fontainebleau, France.
EM jesus.angulo@ensmp.fr
CR Ablamowicz R., 1996, CLIFFORD ALGEBRAS NU
   ANGULO J, 2003, IEEE P 7 INT S SIGN, V1, P69
   Angulo J, 2007, COMPUT VIS IMAGE UND, V107, P56, DOI 10.1016/j.cviu.2006.11.008
   Angulo J, 2006, INT J PATTERN RECOGN, V20, P1207, DOI 10.1142/S0218001406005204
   Angulo J, 2007, IMAGE VISION COMPUT, V25, P475, DOI 10.1016/j.imavis.2006.07.018
   [Anonymous], 2012, Clifford algebra to geometric calculus: a unified language for mathematics and physics
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], 1994, Morphological Image Operators
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   CARRE P, 2006, WAVELET APPL IND PRO, V6383
   Denis P, 2007, COMPUT VIS IMAGE UND, V107, P74, DOI 10.1016/j.cviu.2006.11.019
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Ell TA, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P792, DOI 10.1109/ICIP.2000.899828
   ELL TA, 2007, P IEEE C IM PROC ICI, V5, P245
   ELL TA, 2007, P IEEE C IM PROC ICI, V5, P249
   Ell TA, 2007, COMPUT MATH APPL, V53, P137, DOI 10.1016/j.camwa.2006.10.029
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   GOMILA C, 1999, P IEEE C IM PROC ICI
   GOUTSIAS J, 1995, COMPUT VIS IMAGE UND, V62, P326, DOI 10.1006/cviu.1995.1058
   HAMILTON WR, 1967, MATH PAPERS WR HAMIL, V3
   HANBURY A, 2001, P 12 BMVC BRIT MACH
   Hanbury AG, 2001, IEEE T IMAGE PROCESS, V10, P1842, DOI 10.1109/83.974569
   LABUNETS V, 2003, NATO SCI SERIES 2, V136
   LABUNETSRUNDBLA.E, 2003, NATO SCI SERIES 2, V136, P401
   LEBIHAN N, 2003, P INT C IM PROC ICIP, V1, P809
   MATHERON G, 1990, N2390G PAR SCH MIN
   Meyer F, 2001, INT J PATTERN RECOGN, V15, P1089, DOI 10.1142/S0218001401001337
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Pei SC, 2003, IEEE IMAGE PROC, P805
   Pei SC, 1999, IEEE T IMAGE PROCESS, V8, P614, DOI 10.1109/83.760310
   Rundblad-Labunets E, 2001, GEOMETRIC COMPUTING WITH CLIFFORD ALGEBRAS, P155
   Sangwine SJ, 1998, ELECTRON LETT, V34, P969, DOI 10.1049/el:19980697
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   SANGWINE SJ, 2002, P EUR C COL GRAPH IM, V348
   Serra J., 1992, MATH MORPHOLOGY IMAG, P483
   Serra J., 1988, IMAGE ANAL MATH MORP
   Shi LL, 2007, COMPUT VIS IMAGE UND, V107, P88, DOI 10.1016/j.cviu.2006.11.014
   Sochen N, 1998, IEEE T IMAGE PROCESS, V7, P310, DOI 10.1109/83.661181
   Sochen N, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P166, DOI 10.1109/ICIP.1998.723450
   Talbot H., 1998, MATH M ORPHOLOGY ITS, P27
   VEIT T, 2008, P 11 IEEE C INT TRAN
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   Wolf SG, 1998, J VIS COMMUN IMAGE R, V9, P25, DOI 10.1006/jvci.1998.0371
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
NR 47
TC 36
Z9 45
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 33
EP 48
DI 10.1016/j.jvcir.2009.10.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200005
DA 2024-07-18
ER

PT J
AU Larabi, S
AF Larabi, Slimane
TI Textual description of shapes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape; Outline shape; Part; Description; XML language; Similarity; Shape
   retrieval; Image coding
ID OBJECT RECOGNITION; REPRESENTATION; SEGMENTATION; SIMILARITY;
   APPEARANCE; INVARIANT; FORM
AB We propose in this paper a method for textual description of shape. In the first, we propose a part-based method for the decomposition of outline shape into parts and separating lines. These elements are described geometrically and written with a structured text. In the next we propose the representation of shape by a tree structure where nodes are the internal regions, and arcs correspond to the inclusion relation between these regions. The tree structure is translated to a structured text where is associated for each node a set of attributes such as the description of the outline region, its color and its position.
   A set of applications of this descriptor are proposed. We show how to decode and visualize the shape from its descriptor and how to retrieve a shape query using shapes database. To do this, a shape similarity is defined and extracted directly from the descriptor.
   Experiments conducted over real images of various silhouettes and shapes are presented and discussed. (C) 2009 Elsevier Inc. All rights reserved.
C1 USTHB Univ, Dept Comp Sci, Algiers 16000, Algeria.
C3 University Science & Technology Houari Boumediene
RP Larabi, S (corresponding author), USTHB Univ, Dept Comp Sci, BP 32 EL ALIA, Algiers 16000, Algeria.
EM slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI larabi, slimane/0000-0001-8994-5980
CR ABBASI S, 1997, SEARCH SIMILAR SHAPE
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   BADAWY OE, 2002, P 16 INT C PATT REC, V3, P461
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bernier T, 2003, PATTERN RECOGN, V36, P1711, DOI 10.1016/S0031-3203(02)00352-7
   BERRETTI S, 2000, T MULTIMEDIA, V2
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   CHETVERIKOV D, 2003, P 10 INT C CAIP 2003
   Cronin TM, 2003, PATTERN RECOGN LETT, V24, P429, DOI 10.1016/S0167-8655(02)00267-2
   Cyr CM, 2004, INT J COMPUT VISION, V57, P5, DOI 10.1023/B:VISI.0000013088.59081.4c
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Di Ruberto C, 2004, PATTERN RECOGN, V37, P21, DOI 10.1016/j.patcog.2003.07.004
   DIREKOGLU C, 2008, IEEE IND C COMP VIS
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Geiger D, 2003, IEEE T PATTERN ANAL, V25, P86, DOI 10.1109/TPAMI.2003.1159948
   GROSKY WI, 1990, COMPUT VISION GRAPH, V52, P416, DOI 10.1016/0734-189X(90)90085-A
   Kim DH, 2005, PATTERN RECOGN, V38, P673, DOI 10.1016/j.patcog.2004.10.003
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   KOENDERINK JJ, 1976, BIOL CYBERN, V32, P211
   Larabi S, 2003, LECT NOTES COMPUT SC, V2749, P1014
   Leibe B, 2003, PROC CVPR IEEE, P409
   LIU HC, 1990, PATTERN RECOGN, V23, P51, DOI 10.1016/0031-3203(90)90048-P
   LOURENS T, 1998, P ACCV 98, P193
   MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Nelson RC, 1998, VISION RES, V38, P2469, DOI 10.1016/S0042-6989(98)00030-3
   Orrite C, 2004, COMPUT VIS IMAGE UND, V93, P34, DOI 10.1016/j.cviu.2003.09.005
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   PITAS I, 1990, IEEE T PATTERN ANAL, V12, P38, DOI 10.1109/34.41382
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   ROMENY BMH, 4 INT C VIS BIOM COM
   ROSIN PL, 1999, P BRIT MACH VIS C NO, P633
   SCHNABEL JA, 1995, P 1995 BRIT C MACH V, V1, P197
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sethi A, 2004, INT J COMPUT VISION, V58, P73, DOI 10.1023/B:VISI.0000016148.08046.fc
   Shao Z, 1999, IMAGE VISION COMPUT, V17, P429, DOI 10.1016/S0262-8856(98)00131-0
   SIDDIQI K, 1995, IEEE T PATTERN ANAL, V17, P239, DOI 10.1109/34.368189
   Siddiqi K, 1996, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.1996.517119
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Yu L, 2005, PATTERN RECOGN LETT, V26, P1354, DOI 10.1016/j.patrec.2004.11.013
   YU MH, 2003, P VIS INF PROC WORKS, P109
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P465
NR 47
TC 1
Z9 2
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 563
EP 584
DI 10.1016/j.jvcir.2009.08.004
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400007
DA 2024-07-18
ER

PT J
AU Colbert, M
   Reinhard, E
   Hughes, CE
AF Colbert, M.
   Reinhard, E.
   Hughes, C. E.
TI Painting in high dynamic range
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
AB We present a novel approach that allows users to intuitively and interactively manipulate High Dynamic Range (HDR) images using commonly available Low Dynamic Range (LDR) displays. This solves the problem of how to draw with contrasts that are much larger than the monitor can display. Whereas commercial HDR-enabled drawing programs manipulate tone mapped representations of HDR images, we provide an intuitive brush interface that supports interaction with the unmapped HDR imagery. Our approach introduces two new brush constructs to a typical virtual painting interface, such as Adobe Photoshop. First, we present a brush that locally adjusts the display of the HDR image to. a dynamic range specified within a real-time, interactive, local histogram of the region around the cursor. This affords precise, quantitative control of the HDR contrast values produced by the brush. Second, we demonstrate a brush that uses the perception of glare as the underlying basis for determining the contrasts painted onto the HDR image, giving artistic control over the HDR contrasts. By maintaining an HDR image, the result is available for further manipulation and processing by algorithms, such as those used in image-based rendering, for which an LDR representation is inadequate. Finally, we use the Graphics Processing Unit to provide real-time visual feedback for the effects of each image manipulation. (C) 2007 Elsevier Inc. All rights reserved.
C1 Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
   Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
C3 State University System of Florida; University of Central Florida;
   University of Bristol
RP Colbert, M (corresponding author), Univ Cent Florida, Sch Elect Engn & Comp Sci, Orlando, FL 32816 USA.
EM colbert@cs.ucf.edu
OI Hughes, Charles/0000-0002-2528-3380; Reinhard, Erik/0000-0001-9079-6572
CR Aggarwal M, 2004, INT J COMPUT VISION, V58, P7, DOI 10.1023/B:VISI.0000016144.56397.1a
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], 2002, MPII20024002
   [Anonymous], 1997, SIGGRAPH, DOI DOI 10.1145/258734.258884
   ASHIKHMIN M, 2007, ACM T APPL PERCEPTIO, V4
   Colbert M, 2006, IEEE COMPUT GRAPH, V26, P30, DOI 10.1109/MCG.2006.13
   Debevec P, 2002, IEEE COMPUT GRAPH, V22, P26, DOI 10.1109/38.988744
   Ford A., 1998, COLOUR SPACE CONVERS
   Goodnight N., 2003, Eurographics Symposium on Rendering. 14th Eurographics Workshop on Rendering, P26
   Green S, 2005, IMAGE PROCESSING TRI
   Hearn DonaldD., 2003, COMPUTER GRAPHICS OP
   James D.Foley., 1990, COMPUTER GRAPHICS PR, V2nd
   Khan EA, 2006, ACM T GRAPHIC, V25, P654, DOI 10.1145/1141911.1141937
   Kuang JT, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P315
   Larson G. W., 1998, Journal of Graphics Tools, V3, P15, DOI 10.1080/10867651.1998.10487485
   Ledda P, 2005, ACM T GRAPHIC, V24, P640, DOI 10.1145/1073204.1073242
   MANN S, 1995, IS&T'S 48TH ANNUAL CONFERENCE - IMAGING ON THE INFORMATION SUPERHIGHWAY, FINAL PROGRAM AND PROCEEDINGS, P442
   Mantiuk R, 2004, ACM T GRAPHIC, V23, P733, DOI 10.1145/1015706.1015794
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   SPENCER G, 1995, SIGGRAPH 95, P325
   Vos J. J., 1984, CIE Journal, V3, P39
   Yoshida A, 2006, COMPUT GRAPH FORUM, V25, P415, DOI 10.1111/j.1467-8659.2006.00961.x
NR 23
TC 10
Z9 10
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 387
EP 396
DI 10.1016/j.jvcir.2007.03.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000005
DA 2024-07-18
ER

PT J
AU Lie, WN
   Lin, TCI
AF Lie, Wen-Nung
   Lin, Tom C. -I.
TI Prescription-based error concealment technique for video transmission on
   error-prone channels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID RESILIENCE
AB In this article, a prescription-based error concealment (PEC) technique, based on a three-stage (diagnosis, prescription, and remedy) process, is proposed for video transmission on error-prone channels. A prescription is meant to be the best error concealment scheme among several pre-chosen ones, which are evaluated at encoder side for each MB. The collection of prescriptions for each frame is compressed and transmitted through a reliable channel to provide flexible and better error-recovery performance at decoder side. Experimental results show that the proposed PEC method is capable of achieving a PSNR improvement of up to 1.5 dB, with respect to the best single-mode scheme, when video bit rate and PER (packet error rate) are up to 512 kbps and 20%, respectively, whereas only a small amount of overheads (i.e., the coded prescriptions) is generated for reliable transmission. 2007 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Lie, WN (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
EM wnlie@ee.ccu.edu.tw
RI Lie, Wen-Nung/AFP-1266-2022
CR ALMUALLA ME, 2002, VIDEO CODING MOBIL C
   Cen S, 2003, IEEE T MULTIMEDIA, V5, P1, DOI 10.1109/TMM.2003.808825
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   HUA Y, 2005, P IEEE INT C AC SPEE, V2, P173
   KWOK W, 1993, IEEE T CONSUM ELECTR, V39, P455, DOI 10.1109/30.234620
   LAM WM, 1993, P ICASSP, V5, P417
   Lie WN, 2006, IEEE T CIRC SYST VID, V16, P300, DOI 10.1109/TCSVT.2005.861948
   Lynch WE, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P258, DOI 10.1109/ITCC.2001.918802
   Okada H, 2002, IEICE T FUND ELECTR, VE85A, P1281
   Pei SC, 2004, IEEE T MULTIMEDIA, V6, P158, DOI 10.1109/TMM.2003.819749
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   Suh JW, 2002, ELECTRON LETT, V38, P1020, DOI 10.1049/el:20020733
   SUN HF, 1995, IEEE T IMAGE PROCESS, V4, P470, DOI 10.1109/83.370675
   SUN MT, 2001, COMPRESED VIDEO OVER
   Tang L, 2004, ELECTRON LETT, V40, P1049, DOI 10.1049/el:20045313
   Turaga DS, 2002, IEEE T CIRC SYST VID, V12, P483, DOI 10.1109/TCSVT.2002.800318
   Xiong H, 2004, IEEE T CONSUM ELECTR, V50, P715, DOI 10.1109/TCE.2004.1309453
   Zhang J., 1999, P IEEE INT C SPEECH, V2, P777
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 19
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2007
VL 18
IS 4
BP 310
EP 321
DI 10.1016/j.jvcir.2007.04.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 200NU
UT WOS:000248770900002
DA 2024-07-18
ER

PT J
AU Liu, YZ
   Yao, HX
   Gao, W
   Chen, XL
   Zhao, DB
AF Liu, Yazhou
   Yao, Hongxun
   Gao, Wen
   Chen, Xilin
   Zhao, Debin
TI Nonparametric background generation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE background subtraction; background generation; mean shift; effect
   components description; most reliable background mode; video
   surveillance
ID MEAN-SHIFT; SURVEILLANCE; TRACKING
AB A novel background generation method based on nonparametric background model is presented for background subtraction. We introduce a new model, named as effect components description (ECD), to model the variation of the background, by which we can relate the best estimate of the background to the modes (local maxima) of the underlying distribution. Based on ECD, an effective background generation method, most reliable background mode (MRBM), is developed. The basic computational module of the method is an old pattern recognition procedure, the mean shift, which can be used recursively to find the nearest stationary point of the underlying density function. The advantages of this method are threefold: first, backgrounds can be generated from image sequence with cluttered moving objects; second, backgrounds are very clear without blur effect; third, it is robust to noise and small vibration. Extensive experimental results illustrate its good performance. (c) 2007 Elsevier Inc. All rights reserved.
C1 Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
C3 Harbin Institute of Technology; Chinese Academy of Sciences; Institute
   of Computing Technology, CAS
RP Liu, YZ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM yzliu@vilab.hit.edu.cn
RI Zhao, Debin/JEP-0204-2023
CR [Anonymous], EUR WORKSH ADV VID B
   ASAKAR H, 2002, INT C COMMUN CIRC SY, V2, P982
   Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Collins RT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P346
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Debeir O, 2005, IEEE T MED IMAGING, V24, P697, DOI 10.1109/TMI.2005.846851
   Elgammal A, 2001, PROC CVPR IEEE, P563
   Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123
   ELGAMMAL A, 2002, THESIS STATE U NJ
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gu IYH, 2001, IEEE IMAGE PROC, P726, DOI 10.1109/ICIP.2001.959148
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   *IEEE, 2000, IEEE INT WORKSH PERF
   *IEEE, 2006, IEEE INT WORKSH PERF
   *IEEE, 2001, IEEE INT WORKSH PERF
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Li LY, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ACV.2002.1182193
   LIU T, 2003, NEURAL INFORM PROCES, P265
   Lo BPL, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P158, DOI 10.1109/ISIMP.2001.925356
   Rowe S, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P423
   Shen CH, 2005, IEEE I CONF COMP VIS, P1516
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Thirde D, 2004, INT C PATT RECOG, P636, DOI 10.1109/ICPR.2004.1334240
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yang L, 2005, IEEE T INF TECHNOL B, V9, P475, DOI 10.1109/TITB.2005.847515
NR 31
TC 35
Z9 39
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2007
VL 18
IS 3
BP 253
EP 263
DI 10.1016/j.jvcir.2007.01.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 179BC
UT WOS:000247263300005
DA 2024-07-18
ER

PT J
AU Zhu, ZF
   Lu, HQ
   Zhao, Y
AF Zhu, Zhenfeng
   Lu, Hanqing
   Zhao, Yao
TI Scale multiplication in odd Gabor transform domain for edge detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE edge detection; gabor transform; adaptive threshold; scale
   multiplication
AB In this paper, we propose an adaptive edge detection technique based on scale multiplication in odd Gabor transform domain (ESMG). With adjacent scale multiplication in odd Gabor transform domain, a sharpened edge response output is obtained, which can more effectively resist the inverse influence from noise contamination on the performance of edge detector. Based on odd Gabor filter with single scale, it is shown that Rayleigh distribution can be feasibly adopted to model the real pdf of edge response. Thus the pdf of sharpened edge response output can be approximately modeled by an exponential distribution since there exists strong correlation between two edge response outputs with two adjacent scale factors. In determining the threshold for the sharpened edge response, an adaptive strategy is applied, in which the nonlinear relation of the threshold with the mean and variance of exponential distribution is exploited. Moreover, an optimization problem is finally formulated to find the adaptive adjustment factor. The experimental results on both synthetic and real world natural images show that our scheme is robust and takes on good edge detection performance. (c) 2006 Elsevier Inc. All rights reserved.
C1 Beijing Jiaotong Univ, Inst Sci Informat, Beijing 100044, Peoples R China.
   Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Zhu, ZF (corresponding author), Beijing Jiaotong Univ, Inst Sci Informat, Beijing 100044, Peoples R China.
EM zfzhu@nlpr.ia.ac.cn; luhq@nlpr.ia.ac.cn; yzhao@center.njtu.edu.cn
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Ando S, 2000, IEEE T PATTERN ANAL, V22, P179, DOI 10.1109/34.825756
   [Anonymous], INT J PATTERN RECOGN
   Brown MA, 1998, PATTERN RECOGN, V31, P1479, DOI 10.1016/S0031-3203(97)00101-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587
   Lindeberg T., J APPL STAT, V21, P224, DOI DOI 10.1080/757582976
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   PARK DJ, 1995, PATTERN RECOGN, V28, P211, DOI 10.1016/0031-3203(94)00097-6
   Sadler BM, 1999, IEEE T INFORM THEORY, V45, P1043, DOI 10.1109/18.761341
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Voorhees H., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P250
   XU YS, 1994, IEEE T IMAGE PROCESS, V3, P747, DOI 10.1109/83.336245
   Zhang L, 2002, PATTERN RECOGN LETT, V23, P1771, DOI 10.1016/S0167-8655(02)00151-4
   [朱振峰 Zhu Zhenfeng], 2005, [中国图象图形学报. A, Journal of image and graphics], V10, P821
   ZIOU D, 1993, PATTERN RECOGN, V26, P1305, DOI 10.1016/0031-3203(93)90137-L
NR 20
TC 25
Z9 26
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 68
EP 80
DI 10.1016/j.jvcir.2006.10.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100006
DA 2024-07-18
ER

PT J
AU Kang, LW
   Leou, JJ
AF Kang, Li-Wei
   Leou, Jin-Jang
TI Two error resilient coding schemes for wavelet-based image transmission
   based on data embedding and genetic algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilient coding; error concealment; wavelet-based image;
   JPEG-2000 image; data embedding
ID CONCEALMENT; JPEG-2000; WATERMARKING; PROTECTION
AB For an entropy-coded wavelet-based image, such as a JPEG-2000 image, a transmission error in a codeword will not only affect the underlying codeword but may also affect subsequent codewords, resulting in a great degradation of the received image. In this study, two error resilient coding schemes for wavelet-based image transmission based on data embedding and genetic algorithms (GA's) are proposed.
   In this study, using JPEG-2000, an image is decomposed into six wavelet levels (levels 0-5). At the encoder, for levels 02, some important data useful for error concealment performed at the decoder are extracted and embedded into the compressed JPEG-2000 image bitstream. At the decoder, the important (embedded) data for each corrupted code block are extracted and used to facilitate error concealment. For levels 3-5, the wavelet coefficients of each corrupted code block are simply replaced by zeros.
   Based on the simulation results obtained in this study, the performances of the two proposed schemes are better than those of three comparison approaches, namely, the Zero-S, Mean-S, and Inter approaches. The proposed schemes can recover high-quality wavelet-based JPEG-2000 images from the corresponding corrupted images up to a bit error rate of 0.5%. (C) 2006 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
   Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
C3 National Chung Cheng University; Academia Sinica - Taiwan
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM jjleou@cs.ccu.edu.tw
CR Alatan AA, 2000, IEEE J SEL AREA COMM, V18, P814, DOI 10.1109/49.848235
   [Anonymous], 1996, GENETIC ALGORITHMS D, DOI DOI 10.1007/978-3-662-03315-9_4
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   Atzori L, 2001, INT CONF ACOUST SPEE, P1733, DOI 10.1109/ICASSP.2001.941274
   Banister BA, 2002, IEEE SIGNAL PROC LET, V9, P117, DOI 10.1109/97.1001646
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Cosman PC, 2000, IEEE T IMAGE PROCESS, V9, P982, DOI 10.1109/83.846241
   Grosbois R, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P339, DOI 10.1109/MMSP.2001.962757
   Hemami SS, 1997, IEEE T IMAGE PROCESS, V6, P523, DOI 10.1109/83.563318
   *ISOIEC, 2000, 154441 ISO IEC
   Kang LW, 2004, PROCEEDINGS OF THE 2004 IEEE ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, VOL 1 AND 2, P145
   Kang LW, 2005, REAL-TIME IMAGING, V11, P45, DOI 10.1016/j.rti.2005.01.003
   Kang LW, 2005, J VIS COMMUN IMAGE R, V16, P93, DOI 10.1016/j.jvcir.2004.04.003
   KANG LW, IN PRESS J VIS COMMU
   Kurosaki M, 2002, APCCAS 2002: ASIA-PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, VOL 1, PROCEEDINGS, P529, DOI 10.1109/APCCAS.2002.1115056
   Lee PJ, 2003, IEEE T CONSUM ELECTR, V49, P1395, DOI 10.1109/TCE.2003.1261246
   Lee PJ, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P149, DOI 10.1109/ICME.2002.1035740
   Lin CY, 2001, P SOC PHOTO-OPT INS, V4518, P267, DOI 10.1117/12.448212
   Lin SW, 2004, J VIS COMMUN IMAGE R, V15, P214, DOI 10.1016/j.jvcir.2003.10.002
   Lu CS, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P316
   Lu CS, 2002, IEEE T IMAGE PROCESS, V11, P280, DOI 10.1109/83.988961
   Man H, 1999, IEEE T CIRC SYST VID, V9, P95, DOI 10.1109/76.744278
   Moccagatta I, 2000, IEEE J SEL AREA COMM, V18, P899, DOI 10.1109/49.848245
   Servetto SD, 2000, IEEE T IMAGE PROCESS, V9, P813, DOI 10.1109/83.841528
   Shyu HC, 1999, IEEE T CIRC SYST VID, V9, P937, DOI 10.1109/76.785732
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   Stockhammer T, 2002, IEEE T CIRC SYST VID, V12, P465, DOI [10.1109/TCSVT.2002.800317, 10.1109/TCSVT.2002.806317]
   Suhail MA, 2001, ICECS 2001: 8TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND SYSTEMS, VOLS I-III, CONFERENCE PROCEEDINGS, P871, DOI 10.1109/ICECS.2001.957612
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   THOMOS N, 2002, P INT C DIG SIGN PRO, P717
   Wang J, 2001, IEEE T CONSUM ELECTR, V47, P257, DOI 10.1109/30.964107
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y., 2002, VIDEO PROCESSING COM
   Wu ZY, 2002, IEEE IMAGE PROC, P213
   YIN P, 2001, P IEEE INT C AC SPEE, V3, P1453
   Yu HH, 2000, GLOB TELECOMM CONF, P1344, DOI 10.1109/GLOCOM.2000.891850
NR 37
TC 5
Z9 6
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1127
EP 1144
DI 10.1016/j.jvcir.2006.08.003
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200001
DA 2024-07-18
ER

PT J
AU Song, IW
   Kim, CS
   Lee, SU
AF Song, In-Wook
   Kim, Chang-Su
   Lee, Sang-Uk
TI Progressive compression and transmission of PointTexture images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE PointTexture; 3D image coding; rate-distortion optimization;
   view-dependent optimization; MPEG-4
AB A progressive compression and transmission algorithm for PointTexture 3-D images is proposed in this work. The proposed algorithm represents a PointTexture image hierarchically using an octree, The geometry information in octree nodes is encoded by the predictive partial matching (PPM) method, while the color information is encoded using the discrete cosine transform (DCT). The encoder achieves the progressive transmission of the 3-D image by transmitting the octree nodes in a top-down manner. We develop two transmission schemes, based on the rate-distortion (R-D) optimization and the view-dependent optimization respectively, to maximize the image quality subject to a given bit budget. Extensive simulation results demonstrate that the proposed algorithm is an efficient method for progressive transmission of 3-D data. (c) 2005 Elsevier Inc. All rights reserved.
C1 Korea Univ, Dept Elect Engn, Seoul 136701, South Korea.
   Seoul Natl Univ, Sch Elect Engn & Comp Sci, Seoul 151, South Korea.
C3 Korea University; Seoul National University (SNU)
RP Kim, CS (corresponding author), Korea Univ, Dept Elect Engn, 5-1 Anam Dong, Seoul 136701, South Korea.
EM iwook@ipl.snu.ac.kr; cskim@ieee.org; sanguk@ipl.snu.ac.kr
CR ALLIEZ P, 2003, P S MULT GEOM MOD
   [Anonymous], 1994, INFORM TECHNOLOGY DI
   BOTSCH M, 2002, P 13 EUR WORKSH REND, P53
   Bourges-Sévenier M, 2004, IEEE T CIRC SYST VID, V14, P928, DOI 10.1109/TCSVT.2004.830662
   Chang ShuTing Chang ShuTing, 1999, International Journal of Medicinal Mushrooms, V1, P291
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Duan JG, 2001, IEEE DATA COMPR CONF, P331, DOI 10.1109/DCC.2001.917164
   GROSSMAN JP, 1998, THESIS MIT CAMBRIDGE
   HOWARD PG, 1994, P IEEE, V82, P857, DOI 10.1109/5.286189
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942
   Kim CS, 2002, IEEE T IMAGE PROCESS, V11, P932, DOI 10.1109/TIP.2002.800891
   KIM CS, 2004, P SPIE VCIP
   Lee H, 2003, ACM T GRAPHIC, V22, P471, DOI 10.1145/882262.882294
   Levkovich-Maslyuk L, 2004, IEEE T CIRC SYST VID, V14, P1032, DOI 10.1109/TCSVT.2004.830676
   LEVOY M, 1985, 85002 U N CAR
   OCHOTTA T, 2004, P S POINT BAS GRAPH, P1031
   Oliveira MM, 2000, COMP GRAPH, P359, DOI 10.1145/344779.344947
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   Pfister H, 2000, COMP GRAPH, P335, DOI 10.1145/344779.344936
   Roh BG, 2004, IEICE T FUND ELECTR, VE87A, P3334
   Rusinkiewicz S, 2000, COMP GRAPH, P343, DOI 10.1145/344779.344940
   Sayood K, 2017, Introduction to data compression
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   SIM JY, 2004, P SPIE VIS COMM IM P, P1031
   Stamminger M, 2001, SPRING EUROGRAP, P151
   WASCHBUSCH M., 2004, Proceedings of Eurographics Symposium on Point-Based Graphics 2004, P95
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
   2003, CODING AUDIO VISUAL
NR 30
TC 0
Z9 1
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1090
EP 1107
DI 10.1016/j.jvcir.2005.10.001
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700010
DA 2024-07-18
ER

PT J
AU Cagnazzo, M
   Delfino, F
   Vollero, L
   Zinicola, A
AF Cagnazzo, Marco
   Delfino, Francesco
   Vollero, Luca
   Zinicola, Andrea
TI Trading off quality and complexity for a HVQ-based video codec on
   portable devices
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE multimedia; coding techniques; palmtop devices; performance evaluation
AB Bandwidth and processing requirements of multimedia applications typically exceed capabilities of portable terminals with current technology. Applications should hence be able to accommodate their requirements to run on these devices. In this paper, we provide a performance characterization of a video codec based on techniques such as hierarchical vector quantization which trade off complexity and reproduction quality. Comparison with standard codecs shows a remarkable reduction of coding times, such that real-time coding/decoding of video becomes possible even on low-power devices. This complexity reduction is counterbalanced by reproduction quality impairment. Nevertheless, for application such as video-conference, subjective quality seems to be fairly acceptable. Our analysis also quantifies some limitations of low-power devices with current technology. (C) 2005 Elsevier Inc. All rights reserved.
C1 Univ Naples Federico II, Naples, Italy.
   LABCOM, Lab Nazl CNIT, Pisa, Italy.
C3 University of Naples Federico II
RP Vollero, L (corresponding author), Univ Naples Federico II, Naples, Italy.
EM vollero@ieee.org
RI Cagnazzo, Marco/AAZ-3881-2020
OI Cagnazzo, Marco/0000-0001-6731-3755
CR CAGNAZZO M, 2002, COIMBRA PORTUGAL, P166
   Chaddha N, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P1, DOI 10.1109/ICIP.1996.559417
   JOHANSON M, IMPLEMENTATION ISSUE
   Kohonen Teuvo., 1988, Self organization and associative memory, Vsecond
   OSTERMANN J, 2004, IEEE CIRCUITS SYSTEM, V1, P7
   POGGI G, 1993, EUR T TELECOMMUN, V4, P423, DOI 10.1002/ett.4460040408
   SHEIKH H, 2000, P TEX INSTR DSP ED C
NR 7
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 564
EP 572
DI 10.1016/j.jvcir.2005.12.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300003
DA 2024-07-18
ER

PT J
AU Li, J
   Zhao, CJ
   Ngan, KN
AF Li, J
   Zhao, CJ
   Ngan, KN
TI VLC/FLC data partitioning with intra AC prediction disabled
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video; video communication; error resilient video coding; data
   partitioning
ID TRANSMISSION; RESILIENCE
AB Compressed video bit stream is very sensitive to transmission errors, due to error propagation resulting from variable-length coding, differential coding, and motion compensated prediction. There exist many error-resilient techniques that can significantly improve the reconstructed video quality by reducing the spatial and temporal error propagation. In this paper, an error-resilient coding scheme that can limit the spatial error propagation with little overhead is proposed. It disables intra AC prediction and groups appropriate fixed length coded (FLC) syntaxes in a video packet (or slice) together to form a new partition. With intra AC prediction disabled, errors occurred in these FLC syntaxes will not cause spatial error propagation. This error resilient coding scheme essentially classifies the syntaxes into two categories according to whether that syntax will cause spatial error propagation when an error occurs. We evaluate the efficiency of the error-resilient coding scheme by comparing the reconstructed PSNR of the proposed coding scheme with that of the MPEG-4 coding scheme over the AWGN channel and the Rayleigh channel. Depending on the video sequence, channel coding rate and channel condition, our proposed data-partitioning scheme can achieve up to 1.8 dB PSNR gain. (c) 2005 Elsevier Inc. All rights reserved.
C1 Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
   Hongkong Appl Sci & Technol Res Inst, Kowloon, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM jieli@cc.cuhk.edu.hk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
CR BUDAGAVI M, 1997, P IEEE INT C IM PROC, V2, P89
   Chu WJ, 1998, IEEE T CIRC SYST VID, V8, P74, DOI 10.1109/76.660830
   FARBER N, 1999, P IEEE INT C IM PROC, V2, P550
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   *ISO IEC, 2000, 144962 ISOIEC
   Lee YC, 2002, IEEE T IMAGE PROCESS, V11, P1314, DOI 10.1109/TIR2002.804275
   Llados-Bernaus R, 1998, IEEE DATA COMPR CONF, P269, DOI 10.1109/DCC.1998.672155
   LLADOSBERNAUS R, 1998, IEEE T CIRCUITS SYST, V8
   MATOBA N, 1997, IEEE GLOB TEL C, V2, P1032
   Wang JT, 1999, IEEE T CIRC SYST VID, V9, P513, DOI 10.1109/76.754780
   WORRALL ST, 2001, P IEEE INT C AC SPEE, V3, P1389
   Yu Y, 2002, IEE P-VIS IMAGE SIGN, V149, P355, DOI 10.1049/ip-vis:20020673
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhao C, 2002, ELECTRON LETT, V38, P1337, DOI 10.1049/el:20020924
   ZHAO C, 2002, 2 INT S COMM INF THE, P202
NR 15
TC 0
Z9 0
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG-OCT
PY 2005
VL 16
IS 4-5
BP 544
EP 562
DI 10.1016/j.jvcir.2005.03.003
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 011WG
UT WOS:000235298600010
DA 2024-07-18
ER

PT J
AU Amador, JJ
AF Amador, JJ
TI Markov random field approach to region extraction using Tabu Search
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Markov random field; Gibbs distribution; Tabu Search; region extraction
ID HEURISTICS
AB This paper describes a region extraction algorithm based on the concept of Markov random fields. Markov random fields (MRFs) are characterized by using a Gibbs Distribution which equates back to the MRF. A heuristically developed energy functional is presented and used with the MRF in an efficient and accurate manner. Since the MRF used in this work is defined using the polar coordinate system, a very large search space exists for radial lengths and sites. To aid in pursuing these radial sites, a combinatorial optimization technique known as Tabu Search is exploited. Also provided is an extensive empirical study on aerial imagery and parts detection, in addition to a final discussion and description of future work. (c) 2004 Elsevier Inc. All rights reserved.
C1 John F Kennedy Space Ctr, NASA, Kennedy Space Ctr, FL 32899 USA.
C3 National Aeronautics & Space Administration (NASA); Kennedy Space Center
RP Amador, JJ (corresponding author), John F Kennedy Space Ctr, NASA, Kennedy Space Ctr, FL 32899 USA.
EM Jose.J.Amador@nasa.gov
CR AKSOY S, 1999, IEEE COMP SOC C COMP, V1, P63
   ALSULTAN KS, 1995, PATTERN RECOGN, V28, P1443, DOI 10.1016/0031-3203(95)00022-R
   [Anonymous], 1965, ISODATA NOVEL METHOD
   [Anonymous], 1986, COMPUTATIONAL APPROA, DOI DOI 10.1109/TPAMI.1986.4767851
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Blake Andrew., 2000, Active Contours
   Castleman K. R., 1996, Digital Image Processing
   Costa L., 2001, SHAPE ANAL CLASSIFIC
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   CRAMARIUC B, 1997, 13 INT C DIG SIGN PR, V2, P857
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   DELAGNES P, 1996, 13 INT C PATT REC, V2, P800
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GLOVER F, 1990, INTERFACES, V20, P74, DOI 10.1287/inte.20.4.74
   Glover F., 1998, Tabu Search
   Glover JA, 1989, EDUC PSYCHOL REV, V1, P1, DOI 10.1007/BF01326547
   GUNSEL B, 1994, 12 IAPR INT C VIS SI, V2, P173
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LI SZ, 1994, IEEE COMP SOC C COMP, P63
   MANIEZZO V, 1995, EUR J OPER RES, V81, P188, DOI 10.1016/0377-2217(93)E0128-K
   MARGALIT A, 1990, COMPUT VISION GRAPH, V51, P219, DOI 10.1016/0734-189X(90)90001-C
   MODESTINO JW, 1992, IEEE T PATTERN ANAL, V14, P606, DOI 10.1109/34.141552
   Nadabar SG, 1996, IEEE T PATTERN ANAL, V18, P326, DOI 10.1109/34.485560
   Pirlot M, 1996, EUR J OPER RES, V92, P493, DOI 10.1016/0377-2217(96)00007-0
   Roberts, 1965, MACHINE PERCEPTION 3
   Schlüter D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P100, DOI 10.1109/ICIP.2000.899237
   SINCLAIR M, 1993, COMPUT OPER RES, V20, P687, DOI 10.1016/0305-0548(93)90056-O
   Tomasi C, 1998, IEEE T PATTERN ANAL, V20, P333, DOI 10.1109/34.667890
NR 30
TC 2
Z9 2
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2005
VL 16
IS 2
BP 134
EP 158
DI 10.1016/j.jvcir.2004.06.002
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 915VY
UT WOS:000228340700002
DA 2024-07-18
ER

PT J
AU Vincent, E
   Laganière, R
AF Vincent, E
   Laganière, R
TI Detecting and matching feature points
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE feature point; corner detection; feature-based matching; widely
   separated view matching
AB This paper proposes a new feature point detector which uses a wedge model to characterize corners by their orientation and angular width. This detector is compared to two popular feature point detectors: the Harris and SUSAN detectors, on the basis of some defined quality attributes. It is also shown how feature points between widely separated views can be matched by using the information provided by the detector to approximate local affine transformations between them. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
EM evincent@site.uottawa.ca; laganier@site.uottawa.ca
RI Laganiere, Robert/H-9138-2013
CR Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Deriche R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P530, DOI 10.1109/CVPR.1993.341079
   DERICHE R, 1994, LECT NOTES COMPUTER, V800, P567
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GUIDUCCI A, 1988, PATTERN RECOGN LETT, V8, P311, DOI 10.1016/0167-8655(88)90080-3
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Jung IK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P538, DOI 10.1109/ICCV.2001.937672
   Laganiere R, 1998, PATTERN RECOGN, V31, P1643, DOI 10.1016/S0031-3203(98)00017-X
   MARR D, 1976, PHILOS T R SOC B, V275, P483, DOI 10.1098/rstb.1976.0090
   Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300
   Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802
   ROHR K, 1992, IMAGE VISION COMPUT, V10, P66, DOI 10.1016/0262-8856(92)90001-J
   ROTH G, 2000, P VIS INT, P225
   Schmid C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P230, DOI 10.1109/ICCV.1998.710723
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727, DOI 10.1109/ICCV.1998.710798
   Tuytelaars T, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1601, DOI 10.1109/ROBOT.1999.772588
   Vincent E., 2001, Machine Graphics & Vision, V10, P237
   Yu WC, 1998, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.1998.698635
   Zoghlami I, 1997, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.1997.609359
NR 23
TC 28
Z9 35
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2005
VL 16
IS 1
BP 38
EP 54
DI 10.1016/j.jvcir.2004.05.001
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 885SN
UT WOS:000226177300003
DA 2024-07-18
ER

PT J
AU Lin, SW
   Leou, JJ
   Kang, LW
AF Lin, SW
   Leou, JJ
   Kang, LW
TI An error resilient coding scheme for H.26L video transmission based on
   data embedding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilient coding; error concealment; H.26L video; transmission
   error; data embedding
ID CONCEALMENT; PROTECTION
AB For entropy-coded H.26L video frames, a transmission error in a codeword will not only affect the underlying codeword but also may affect subsequent codewords, resulting in a great degradation of the received video frames. In this study, an error resilient coding scheme for H.26L video transmission based on data embedding is proposed. At the encoder, for an H.26L intra-coded I frame, the important data for each macroblock are extracted and embedded into another macroblock(s) within the I frame and the next P frame by the proposed odd-even data embedding scheme. For an H.26L inter-coded P frame, the important data for each slice are extracted and embedded into the next frame by the proposed slice-based embedding scheme for P frames. At the decoder, for each corrupted macroblock. if the important data for a corrupted macroblock can be correctly extracted, the extracted important data will facilitate the employed error concealment scheme to conceal the corrupted macroblock. Otherwise, the employed error concealment scheme is used to conceal the corrupted macroblock. Based on the simulation results, the proposed scheme can recover high-quality H.26L video frames from the corresponding corrupted video frames up to a video packet loss rate of 30%, (C) 2004 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM jjleou@cs.ccu.edu.tw
CR [Anonymous], 2003, The SSIM index for image quality assessment
   Bartolini F, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P65, DOI 10.1109/MMSP.2001.962713
   Chen MJ, 1997, IEEE T CIRC SYST VID, V7, P560, DOI 10.1109/76.585936
   Côté G, 2000, IEEE J SEL AREA COMM, V18, P952, DOI 10.1109/49.848249
   Frossard P, 2001, IEEE T CIRC SYST VID, V11, P989, DOI 10.1109/76.946516
   Gallant M, 2001, IEEE T CIRC SYST VID, V11, P357, DOI 10.1109/76.911161
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hong MC, 1999, SIGNAL PROCESS-IMAGE, V14, P473, DOI 10.1016/S0923-5965(98)00061-7
   Ismaeil S, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P388, DOI 10.1109/ICIP.2000.899415
   *ITU VCEG, 2001, H 26L TEST MOD LONG
   Kang LW, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P532
   Kang LW, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P29
   KANG LW, 2002, P IEEE PAC RIM C MUL, P814
   KANG LW, 2003, P IEEE INT C IM PROC
   Lee YC, 2002, IEEE T IMAGE PROCESS, V11, P1314, DOI 10.1109/TIR2002.804275
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   Stockhammer T, 2002, IEEE T CIRC SYST VID, V12, P465, DOI [10.1109/TCSVT.2002.800317, 10.1109/TCSVT.2002.806317]
   TAKISHIMA Y, 1995, IEEE T COMMUN, V43, P158, DOI 10.1109/26.380026
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   Vass J, 2001, IEEE T CIRC SYST VID, V11, P833, DOI 10.1109/76.931110
   Wang Y, 2002, IEEE T SIGNAL PROCES, V50, P2843, DOI 10.1109/TSP.2002.804062
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y., 2002, VIDEO PROCESSING COM
   WANG YC, 2003, P IEEE INT C MULT EX, V3, P349
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wang Z, 1998, IEEE T IMAGE PROCESS, V7, P1056, DOI 10.1109/83.701166
   WANG Z, 2004, IN PRESS IEEE T IMAG, V13
   Yin P, 2001, INT CONF ACOUST SPEE, P1453, DOI 10.1109/ICASSP.2001.941204
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
NR 33
TC 7
Z9 8
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 214
EP 240
DI 10.1016/j.jvcir.2003.10.002
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800007
DA 2024-07-18
ER

PT J
AU Elad, M
   Kimmel, R
   Shaked, D
   Keshet, R
AF Elad, M
   Kimmel, R
   Shaked, D
   Keshet, R
TI Reduced complexity Retinex algorithm via the variational approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Retinex; illumination; quadratic programming; look-up-table; volterra
   filters; gamma correction
ID COLOR-VISION; VISUAL MODEL; IMAGE; COMPUTATION; RELAXATION; FRAMEWORK;
   LIGHTNESS
AB Retinex theory addresses the problem of separating the illumination from the reflectance in a given image, and thereby compensating for non-uniform lighting. In a previous paper (Kimmel et al., 2003), a variational model for the Retinex problem was introduced. This model was shown to unify previous methods, leading to a new illumination estimation algorithm. The main drawback with the above approach is its numerical implementation. The computational complexity of the illumination reconstruction algorithm is relatively high, since in the obtained Quadratic Programming (QP) problem, the whole image is the unknown. In addition, the process requirements for obtaining the optimal solution are not chosen a priori based on hardware/ software constraints. In this paper we propose a way to compromise between the full fledged solution of the theoretical model, and a variety of efficient yet limited computational methods for which we develop optimal solutions. For computational methods parameterized linearly by a small set of free parameters, it is shown that a reduced size QP problem is obtained with a unique solution. Several special cases of this general solution are presented and analyzed: a Look-Up-Table (LUT), linear or nonlinear Volterra filters, and expansion using a truncated set of basis functions. The proposed solutions are sub-optimal compared to the original Retinex algorithm, yet their numerical implementations are much more efficient. Results indicate that the proposed methodology can enhance images for a reduced computational effort. (C) 2003 Elsevier Inc. All rights reserved.
C1 Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
C3 Stanford University; Technion Israel Institute of Technology
RP Elad, M (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RI , Miki/AAH-4640-2019
CR [Anonymous], 1987, Visual Reconstruction
   Berthold KP, 1974, Comput. Graph. Image Process., V3, P277, DOI [DOI 10.1016/0146-664X(74)90022-7, 10.1016/0146-664X(74)90022-7]
   Bertsekas D. P., 1995, NONLINEAR PROGRAMMIN
   BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4
   BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651
   Durand F, 2002, ACM T GRAPHIC, V21, P257, DOI 10.1145/566570.566574
   FAUGERAS OD, 1979, IEEE T ACOUST SPEECH, V27, P380, DOI 10.1109/TASSP.1979.1163262
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   HOLM J, 1996, P IS T SID 4 COL IM, P194
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   JOBSON DJ, 1997, IEEE T IMAGE P 6
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Lagendijk R.L., 1991, ITERATIVE IDENTIFICA
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078
   Luenberger D.G., 1987, Linear and Nonlinear Programming, VSecond
   MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127
   McCann J., 1998, EXPT RETINEX
   STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767
NR 22
TC 32
Z9 42
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 369
EP 388
DI 10.1016/S1047-3203(03)00045-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800001
DA 2024-07-18
ER

PT J
AU Sun, J
   Li, YF
   Chen, LYF
   Chen, HJ
   Peng, WR
AF Sun, Jia
   Li, Yanfeng
   Chen, Luyifu
   Chen, Houjin
   Peng, Wanru
TI Multiple integration model for single-source domain generalizable person
   re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re -identification; Single -source domain generalization;
   Multiple integration
AB Domain generalizable (DG) person re-identification (re-ID) aims to train a model on labeled source domains which can perform well on invisible target domains. Because of the distribution shifts between different domains, it is a challenging task. Existing methods address this challenge by using multiple source domains to train a model which requires more data, manual labor, and computation. In contrast, we pay attention to the singlesource DG re-ID task, that is, only one source domain data is accessible for training. However, due to the limited availability of training data, this task is more difficult. In this paper, a novel MulTiple Integration (MTI) model is introduced for single-source DG person re-ID. By integrating multiple reliable perturbations, the generalization performance can be improved. Specifically, MTI model contains two types of integration modules, one is shallow-level compensation (SLC) and the other is deep-level integration (DLI). For SLC, according to the idea of continual learning, the shallow-level information of the ImageNet pre-trained ResNet-50 branch is introduced and fused with the shallow-level information of our backbone network. In this way, massive information in ImageNet can be used to prevent the disastrous forgetting of the pre-trained information, and information compensation can be provided for backbone network. Additionally, we propose a hybrid integrated normalization layer to fuse information and improve the model's generalization performance. For DLI, a wave transformer block is introduced in the deep layer of the backbone, which can integrate the information of a batch images and contain reliable disturbance, so that the robustness of the model can be promoted. Extensive experimental results demonstrate the superiority of our model.
C1 [Sun, Jia; Li, Yanfeng; Chen, Luyifu; Chen, Houjin; Peng, Wanru] Beijing Jiaotong Univ, Sch Elect Informat Engn, Beijing, Peoples R China.
   [Li, Yanfeng] Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Li, YF (corresponding author), Beijing Jiaotong Univ, Sch Elect & Informat Engn, Beijing 100044, Peoples R China.
EM yf.li@bjtu.edu.cn
OI Sun, Jia/0000-0002-9188-7000
FU Fundamental Research Funds for the Central Universities [2023JBRC009];
   National Nature Sci-ence Foundation of China [62172029]; Beijing Natural
   Science Foundation [4232012]
FX <B>Acknowledgments</B> This work was supported in part by the
   Fundamental Research Funds for the Central Universities (No.
   2023JBRC009) , National Nature Sci-ence Foundation of China (No.
   62172029) , Beijing Natural Science Foundation (No. 4232012) .
CR Chen F, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109369
   Choi S, 2021, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR46437.2021.00343
   Dai YX, 2021, PROC CVPR IEEE, P16140, DOI 10.1109/CVPR46437.2021.01588
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Divyam M., 2022, INT C LEARNING REPRE
   Dosovitskiy Alexey, 2021, 2021 INT C LEARN REP
   Ge Y.X., 2020, C NEURAL INFORM PROC
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou Z, 2022, PROC CVPR IEEE, P7246, DOI 10.1109/CVPR52688.2022.00711
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jain S., 2023, IEEE C COMPUTER VISI
   Jiao BL, 2022, LECT NOTES COMPUT SC, V13674, P285, DOI 10.1007/978-3-031-19781-9_17
   Jin X, 2020, PROC CVPR IEEE, P3140, DOI 10.1109/CVPR42600.2020.00321
   Jing YC, 2023, PROC CVPR IEEE, P24345, DOI 10.1109/CVPR52729.2023.02332
   Jing YC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5281, DOI 10.1109/ICCV48922.2021.00525
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Li JD, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3164163
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li X., 2022, INT C LEARNING REPRE
   Liao SC, 2022, PROC CVPR IEEE, P7349, DOI 10.1109/CVPR52688.2022.00721
   Liu J.W., 2022, AAAI C ARTIFICIAL IN
   Liu S.H., 2022, C NEURAL INFORM PROC
   Liu SH, 2023, PROC CVPR IEEE, P3759, DOI 10.1109/CVPR52729.2023.00366
   Liu YH, 2023, IEEE T PATTERN ANAL, V45, P5282, DOI 10.1109/TPAMI.2022.3196364
   Lu Wang, 2022, Transactions on Machine Learning Research
   Ni H, 2022, PROC CVPR IEEE, P2477, DOI 10.1109/CVPR52688.2022.00252
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Qu S.Q., 2023, IEEE C COMPUTER VISI
   Ragab M, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3154000
   Seonguk Seo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P68, DOI 10.1007/978-3-030-58542-6_5
   Sun J, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109162
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang DW, 2023, J VIS COMMUN IMAGE R, V93, DOI 10.1016/j.jvcir.2023.103822
   Wang HC, 2022, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR52688.2022.00715
   Wang LY, 2024, Arxiv, DOI arXiv:2302.00487
   Wang WH, 2022, IEEE T IMAGE PROCESS, V31, P1532, DOI 10.1109/TIP.2022.3140614
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu Y.H., 2023, AAAI C ARTIFICIAL IN
   Xiang J, 2023, PATTERN RECOGN, V135, DOI 10.1016/j.patcog.2022.109151
   Xu RY, 2023, J VIS COMMUN IMAGE R, V94, DOI 10.1016/j.jvcir.2023.103849
   Yang X, 2022, C NEURAL INFORM PROC
   Yang XY, 2023, PROC CVPR IEEE, P22552, DOI 10.1109/CVPR52729.2023.02160
   Yang XY, 2022, LECT NOTES COMPUT SC, V13694, P73, DOI 10.1007/978-3-031-19830-4_5
   Zhang L, 2023, IEEE T IMAGE PROCESS, V32, P2107, DOI 10.1109/TIP.2023.3263112
   Zhang YF, 2023, IEEE T IMAGE PROCESS, V32, P509, DOI 10.1109/TIP.2022.3229621
   Zhao YY, 2021, PROC CVPR IEEE, P6273, DOI 10.1109/CVPR46437.2021.00621
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou KY, 2022, IEEE T PATTERN ANAL, V44, P5056, DOI 10.1109/TPAMI.2021.3069237
NR 52
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104037
DI 10.1016/j.jvcir.2023.104037
EA DEC 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GP1B4
UT WOS:001153769600001
DA 2024-07-18
ER

PT J
AU Wang, SP
   An, P
   Yang, C
   Huang, KQ
   Huang, XP
AF Wang, Shipei
   An, Ping
   Yang, Chao
   Huang, Kunqiang
   Huang, Xinpeng
TI STSIC: Swin-transformer-based scalable image coding for human and
   machine
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable image coding; Multi -task network; Swin-transformer; Video
   coding for machine
AB Recently, as the visual data captured by smart terminal devices is mainly served for machine analysis, e.g., image classification, object detection, and sometimes also for human viewing in special scenarios, a new compression framework should be proposed to meet this demand. In this work, an image coding framework for machine analysis and human viewing simultaneously is proposed, termed STSIC. In order to leverage the relationship between the two tasks, STSIC is built upon a scalable structure, comprising a base layer for machine analysis and image preview at low quality, as well as an enhancement layer for high-quality image reconstruction. More specifically, features are extracted through the backbone and transmitted to the cloud side for tasks on the base layer. Different from the vast majority of existing works, we try to employ the Swin-Transformer as the backbone instead of a convolutional neural network (CNN). Additionally, due to the hierarchical structure of the Swin-Transformer, a feature fusion strategy is applied to generate a common feature that is more friendly to both human and machine tasks. The enhancement layer transfers the residuals between the original images and the reconstructed images from the base layer, thereby improving the quality of image reconstruction for human viewing. The experimental results show that STSIC outperforms relevant benchmarks on object detection, especially under low bitrates. As for image reconstruction, the advantage is weakened, but it still surpasses HEVC on the rate-distortion performance.
C1 [Wang, Shipei; An, Ping; Yang, Chao; Huang, Kunqiang; Huang, Xinpeng] Shanghai Univ, Sch Commun & Informat Sci, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai 200444, Peoples R China.
C3 Shanghai University
RP An, P (corresponding author), Shanghai Univ, Sch Commun & Informat Sci, Key Lab Specialty Fiber Opt & Opt Access Networks, Shanghai 200444, Peoples R China.
EM wang_shipei0824@shu.edu.cn; anping@shu.edu.cn
FU NSFC [62071287, 62020106011, 62171002, 62371279]; Science and Technology
   Commission of Shanghai Municipality [22ZR1424300, 20DZ2290100]
FX This work was supported in part by the NSFC under Grant 62071287,
   62020106011, 62171002, 62371279, and Science and Technology Commission
   of Shanghai Municipality under Grant 22ZR1424300, 20DZ2290100.
CR [Anonymous], 2020, ISO/IEC JTC 1/SC 29/WG 2
   [Anonymous], PhotoCD PCD0992
   [Anonymous], 2019, High efficiency video coding, ITU-T Recommendation H.265, DOI DOI 11.1002/1000/14107
   [Anonymous], 2020, Versatile Video Coding (VVC)
   Bai YC, 2022, AAAI CONF ARTIF INTE, P104
   Ball‚ J, 2017, Arxiv, DOI [arXiv:1611.01704, 10.48550/arXiv.1611.01704]
   Ball‚ J, 2018, Arxiv, DOI arXiv:1802.01436
   Bjontegaard G., 2001, Document VCEG-M33
   Chen Z, 2018, Arxiv, DOI arXiv:1809.06196
   Chen Z, 2020, IEEE T IMAGE PROCESS, V29, P2230, DOI 10.1109/TIP.2019.2941660
   Choi H, 2018, IEEE INT WORKSH MULT
   Choi H, 2022, IEEE T IMAGE PROCESS, V31, P2739, DOI 10.1109/TIP.2022.3160602
   Choi H, 2018, IEEE IMAGE PROC, P3743, DOI 10.1109/ICIP.2018.8451100
   Dosovitskiy A., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2010, 10.48550/arXiv.2010]
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao CS, 2023, IEEE T MULTIMEDIA, V25, P721, DOI 10.1109/TMM.2021.3130754
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Lee J., 2019, PROC 7 INT C LEARN R
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mentzer F., 2020, PROC NEURIPS 20, V33
   Minnen D, 2018, ADV NEUR IN, V31
   Pateux S., 2007, ITU-T SG16 Q, V6, P7
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Seppälä J, 2021, IEEE INT SYM MULTIM, P217, DOI 10.1109/ISM52913.2021.00044
   Suzuki S, 2022, IEEE T CIRC SYST VID, V32, P3934, DOI 10.1109/TCSVT.2021.3107716
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Wang SR, 2021, IEEE OPEN J CIRCUITS, V2, P675, DOI 10.1109/OJCAS.2021.3126061
   Wang SR, 2022, IEEE T MULTIMEDIA, V24, P3169, DOI 10.1109/TMM.2021.3094300
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Yan N, 2021, IEEE T IMAGE PROCESS, V30, P8939, DOI 10.1109/TIP.2021.3121131
   Yuan K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P559, DOI 10.1109/ICCV48922.2021.00062
   Zhang BW, 2022, PROC CVPR IEEE, P11294, DOI 10.1109/CVPR52688.2022.01102
   Zhang Z., 2021, 2021 IEEE INT C MULT, P1, DOI [10.1109/ICME51207.2021.9428258, DOI 10.1109/ICME51207.2021.9428258]
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
NR 37
TC 0
Z9 0
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104016
DI 10.1016/j.jvcir.2023.104016
EA DEC 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EP9K9
UT WOS:001140244200001
DA 2024-07-18
ER

PT J
AU Zhu, HC
   Cao, G
   Zhao, M
   Tian, HW
   Lin, WG
AF Zhu, Haochen
   Cao, Gang
   Zhao, Mo
   Tian, Huawei
   Lin, Weiguo
TI Effective image tampering localization with multi-scale ConvNeXt feature
   fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Tampering localization; Encoder and decoder; ConvNeXt;
   Multi-scale feature fusion
AB With the widespread use of powerful image editing tools, image tampering becomes easy and realistic. Existing image forensic methods still face challenges of low generalization performance and robustness. In this letter, we propose an effective image tampering localization scheme based on ConvNeXt encoder and multi-scale Feature Fusion (ConvNeXtFF). Stacked ConvNeXt blocks are utilized as an encoder to capture hierarchical multi-scale features, which are then fused in decoder for locating tampered pixels accurately. Combined loss function and effective data augmentation strategies are adopted to further improve the model performance. Extensive experimental results show that both localization accuracy and robustness of the ConvNeXtFF scheme outperform other state-of-the-art ones. The source code is available at https://github.com/multimediaFor/ConvNeXtFF.
C1 [Zhu, Haochen; Cao, Gang; Zhao, Mo; Lin, Weiguo] Commun Univ China, Sch Comp & Cyber Sci, Beijing 100024, Peoples R China.
   [Zhu, Haochen; Cao, Gang] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
   [Tian, Huawei] Peoples Publ Secur Univ China, Beijing 100038, Peoples R China.
C3 Communication University of China; Communication University of China;
   People's Public Security University of China
RP Cao, G (corresponding author), Commun Univ China, Sch Comp & Cyber Sci, Beijing 100024, Peoples R China.; Cao, G (corresponding author), Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
EM gangcao@cuc.edu.cn
RI Weiguo, Lin/JYP-9901-2024
FU National Natural Science Foundation of China [62071434, 61972405];
   Fundamental Research Funds for the Central Universities [CUC22GZ065];
   CUC Public Computing Cloud, Beijing Municipal Natural Science Foundation
   [M22002]
FX This work was supported in part by National Natural Science Foundation
   of China (62071434, 61972405) , Fundamental Research Funds for the
   Central Universities (CUC22GZ065) , CUC Public Computing Cloud, Beijing
   Municipal Natural Science Foundation (M22002) .
CR Bappy JH, 2019, IEEE T IMAGE PROCESS, V28, P3286, DOI 10.1109/TIP.2019.2895466
   Bappy JH, 2017, IEEE I CONF COMP VIS, P4980, DOI 10.1109/ICCV.2017.532
   Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Chen XR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14165, DOI 10.1109/ICCV48922.2021.01392
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   github, 2020, MMSegmentation: OpenMMLab semantic segmentation toolbox and benchmark
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Huh M, 2018, LECT NOTES COMPUT SC, V11215, P106, DOI 10.1007/978-3-030-01252-6_7
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kwon MJ, 2022, INT J COMPUT VISION, V130, P1875, DOI 10.1007/s11263-022-01617-5
   Lee Y., 2020, NIST Interagency/Internal Report
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu XH, 2022, IEEE T CIRC SYST VID, V32, P7505, DOI 10.1109/TCSVT.2022.3189545
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Mayer O, 2020, IEEE T INF FOREN SEC, V15, P1331, DOI 10.1109/TIFS.2019.2924552
   nist, Nimble-Challenge-2017-Evaluation
   Novozámsky A, 2020, IEEE WINT CONF APPL, P71, DOI [10.1109/WACVW50321.2020.9096940, 10.1109/wacvw50321.2020.9096940]
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Wu HW, 2022, PROC CVPR IEEE, P13430, DOI 10.1109/CVPR52688.2022.01308
   Wu HW, 2022, IEEE T INF FOREN SEC, V17, P443, DOI 10.1109/TIFS.2022.3144878
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao Q, 2020, INT CONF SIGN PROCES, P165, DOI 10.1109/ICSP48669.2020.9321086
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhuang PY, 2021, IEEE T INF FOREN SEC, V16, P2986, DOI 10.1109/TIFS.2021.3070444
   Zhuo L, 2022, IEEE T INF FOREN SEC, V17, P819, DOI 10.1109/TIFS.2022.3152362
NR 33
TC 6
Z9 6
U1 17
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 103981
DI 10.1016/j.jvcir.2023.103981
EA DEC 2023
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ9A3
UT WOS:001133634100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Babu, GH
   Odugu, VK
   Venkatram, N
   Satish, B
   Revathi, K
   Rao, BJ
AF Babu, G. Harish
   Odugu, Venkata Krishna
   Venkatram, N.
   Satish, B.
   Revathi, K.
   Rao, B. Janardhana
TI Development and performance evaluation of enhanced image dehazing method
   using deep learning networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Neural networks; CNN; Deep learning; PSNR; Dehazing
   network and discriminator network
ID SINGLE; RESTORATION
AB In this work, a deep learning-based high-performance image dehazing technique is proposed for image processing applications. The end-to-end network model is constructed and implemented using a dehazing network, discriminator network, and fine-tuning network models. These three methods are well-trained individually using appropriate datasets. The individual network models are integrated as an end-to-end network model to enhance the dehazing process. The applied input hazy image is processed by the dehazing network model using the estimation of transmission map and atmospheric light along with parallel convolution layers. A discriminated dehazing image was extracted from the discrimination network. Finally, fine-tuning is carried out based on the results of the discriminator network model. Various hazy images from different datasets are collected and applied to the proposed model, and performance metrics such as PSNR, SSIM, and MSE are evaluated. Qualitative, and quantitative comparison and analysis are carried out between the proposed learning-based image dehazing and existing dehazing methods. The average PSNR value of the proposed dehazing model is obtained by a maximum of 40.7 %, and a minimum of 1.34 %, when compared to the existing works. The average SSIM of the proposed work is increased by a maximum of 22.12 %, and a minimum of 3.38 % with respect to the existing works. The maximum average value of MSE for the proposed model is decreased by 72.6 % and the minimum decrease of MSE is 4.08 % when compared to the state-of-art-works.
C1 [Babu, G. Harish; Odugu, Venkata Krishna; Satish, B.; Rao, B. Janardhana] CVR Coll Engn, ECE Dept, Pocharam, Telangana, India.
   [Venkatram, N.] Koneru Lakshmaiah Educ Fdn, Guntur, India.
   [Revathi, K.] Sphoorthy Engn Coll, Hyderabad, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Babu, GH (corresponding author), CVR Coll Engn, ECE Dept, Pocharam, Telangana, India.
EM harish.sidhu12@gmail.com; venkatakrishna.odugu@gmail.com;
   venkatram@kluniversity.in; satishbojjawar@cvr.ac.in;
   revathi.kandula@gmail.com; janardhan.bitra@gmail.com
RI Odugu, Venkata Krishna/AAL-8750-2021; GADE, Dr HARISH BABU/AAU-8202-2020
OI Odugu, Venkata Krishna/0000-0002-7580-8130; GADE, Dr HARISH
   BABU/0000-0001-7496-5946
CR Al Sobbahi R, 2022, SIGNAL PROCESS-IMAGE, V109, DOI 10.1016/j.image.2022.116848
   Babu GH, 2023, ADV ENG SOFTW, V175, DOI 10.1016/j.advengsoft.2022.103341
   Babu GH, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jveir.2020.102912
   Babu GH, 2022, MULTIMED TOOLS APPL, V81, P43897, DOI 10.1007/s11042-022-13222-2
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen BH, 2018, IEEE T NEUR NET LEAR, V29, P3828, DOI 10.1109/TNNLS.2017.2741975
   Chen WT, 2020, IEEE T IMAGE PROCESS, V29, P6773, DOI 10.1109/TIP.2020.2993407
   Guo YN, 2020, IEEE T IMAGE PROCESS, V29, P9508, DOI 10.1109/TIP.2020.3029438
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Harish Babu G, 2019, Int. J. Innov. Technol. Expl. Eng., V8, P12
   Hassaballah M, 2021, IEEE T INTELL TRANSP, V22, P4230, DOI 10.1109/TITS.2020.3014013
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He LY, 2017, IEEE T IMAGE PROCESS, V26, P1063, DOI 10.1109/TIP.2016.2644267
   Hodges C, 2019, PATTERN RECOGN LETT, V128, P70, DOI 10.1016/j.patrec.2019.08.013
   Huang SQ, 2019, IEEE ACCESS, V7, P104179, DOI 10.1109/ACCESS.2019.2929591
   Liu Z, 2019, IEEE SIGNAL PROC LET, V26, P833, DOI 10.1109/LSP.2019.2910403
   Negru M, 2015, IEEE T INTELL TRANSP, V16, P2257, DOI 10.1109/TITS.2015.2405013
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Qiu YS, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23031347
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Tangsakul S, 2020, IEEE ACCESS, V8, P103181, DOI 10.1109/ACCESS.2020.2999076
   Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012
   Xu X, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3414839
   Yin SB, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108021
   Yin SB, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107255
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 29
TC 1
Z9 1
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103976
DI 10.1016/j.jvcir.2023.103976
EA NOV 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y7RE0
UT WOS:001107187400001
DA 2024-07-18
ER

PT J
AU Zhang, ZF
   Li, S
   Ji, Y
   Liu, CP
AF Zhang, Zefan
   Li, Shun
   Ji, Yi
   Liu, Chunping
TI Infer unseen from seen: Relation regularized zero-shot visual dialog
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual dialog; Zero-shot learning; Attention
AB The Visual Dialog task requires retrieving the correct answer based on detected objects, a current question, and history dialogs. However, in real-world scenarios, most existing models face the hard-positive problem and are unable to reason about unseen features, which limits their generalization ability. To address this issue, we propose two Relation Regularized Modules (RRM) in this article. The first is the Visual Relation Regularized Module (VRRM), which seeks known visual features that have semantic relations with unknown visual features and leverages these known features to assist in understanding the unknown features. The second is the Text Relation Regularized Module (TRRM), which enhances the keywords in the answers to strengthen the understanding of unknown text features. To evaluate the effectiveness of these modules, we propose two zero-shot Visual Dialog splits for verification: Visual Zero-shot VisDial with unseen visual features and Text Zero-shot VisDial with unseen answers. Experimental results demonstrate that our proposed modules achieve state-of-the-art performance in zero-shot Visual Dialog with unseen visual features and unseen answers, while also producing comparable results on the benchmark VisDial v1.0 test dataset.
C1 [Zhang, Zefan; Li, Shun; Ji, Yi; Liu, Chunping] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
C3 Soochow University - China
RP Ji, Y (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
EM zfzhang1997@stu.suda.edu.cn; 20205227116@stu.suda.edu.cn;
   jiyi@suda.edu.cn; cpliu@suda.edu.cn
FU National Natural Science Foundation of China [61972059, 61773272,
   61602332]; Natural Science Foundation of the Jiangsu Higher Education
   Institutions of China [19KJA230001]; Key Laboratory of Symbolic
   Computation and Knowledge Engineering of Ministry of Education, Jilin
   University, China [93K172016K08]; Priority Academic Program Development
   of Jiangsu Higher Education Institutions (PAPD) , China
FX This work was supported by National Natural Science Foundation of China
   Nos 61972059, 61773272, 61602332; Natural Science Foundation of the
   Jiangsu Higher Education Institutions of China No 19KJA230001, Key
   Laboratory of Symbolic Computation and Knowledge Engineering of Ministry
   of Education, Jilin University, China No 93K172016K08; the Priority
   Academic Program Development of Jiangsu Higher Education Institutions
   (PAPD) , China.
CR Agarwal S., 2020, P 58 ANN M ASS COMP, P8182
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Chen C, 2022, PROC CVPR IEEE, P18082, DOI 10.1109/CVPR52688.2022.01757
   Chen FL, 2022, INT CONF ACOUST SPEE, P7937, DOI 10.1109/ICASSP43922.2022.9747769
   Chen FL, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P230
   Chen J., 2021, P 30 INT JOINT C ART, P4366, DOI DOI 10.24963/IJCAI.2021/597
   Chen T., 2022, 2022 IEEE INT C MULT, P1, DOI [10.1109/ICME52920.2022.9859849, DOI 10.1109/ICME52920.2022.9859849]
   Chen Z, 2021, LECT NOTES COMPUT SC, V12922, P146, DOI 10.1007/978-3-030-88361-4_9
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Das R., 2022, Ph.D. thesis
   Fu XP, 2022, ENG APPL ARTIF INTEL, V107, DOI 10.1016/j.engappai.2021.104540
   Guo D, 2022, IEEE T PATTERN ANAL, V44, P6056, DOI 10.1109/TPAMI.2021.3085755
   Guo D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4989
   Jiang GQ, 2022, IEEE T CIRC SYST VID, V32, P5307, DOI 10.1109/TCSVT.2022.3143848
   Jiang TL, 2023, KNOWL-BASED SYST, V268, DOI 10.1016/j.knosys.2023.110427
   Jiang Tianling, 2020, P 28 INT C COMP LING, P1874, DOI DOI 10.18653/V1/2020.COLING-MAIN.170
   Jiang XZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1265, DOI 10.1145/3394171.3413826
   Kingma D. P., 2014, arXiv
   Nguyen V. Q., 2020, Efficient attention mechanism for visual dialog that can handle all the interactions between multiple inputs
   Niu YL, 2019, PROC CVPR IEEE, P6672, DOI 10.1109/CVPR.2019.00684
   Park S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073009
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Tang YC, 2023, ENG STRUCT, V274, DOI 10.1016/j.engstruct.2022.115158
   Tang YC, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118573
   Teney D., 2016, arXiv
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HB, 2023, IEEE T MULTIMEDIA, V25, P6629, DOI 10.1109/TMM.2022.3212270
   Wang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3325
   Wu FY, 2023, COMPUT ELECTRON AGR, V209, DOI 10.1016/j.compag.2023.107827
   Yang TH, 2019, IEEE I CONF COMP VIS, P2561, DOI 10.1109/ICCV.2019.00265
   Ye T, 2022, INT CONF ACOUST SPEE, P6687, DOI 10.1109/ICASSP43922.2022.9746098
   Yu L., 2023, FINDINGS ASS COMPUTA, P3422, DOI DOI 10.18653/V1/2023.FINDINGS-ACL.212
   Zhang HD, 2022, APPL INTELL, V52, P10116, DOI 10.1007/s10489-021-02981-4
   Zhang HW, 2023, APPL INTELL, V53, P4924, DOI 10.1007/s10489-022-03795-8
   Zhang SY, 2022, IEEE COMPUT SOC CONF, P4599, DOI 10.1109/CVPRW56347.2022.00506
   Zhang ZF, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2023, P253, DOI 10.1145/3591106.3592272
   Zhao L., 2021, 2021 IEEE INT C MULT, P1, DOI [10.1109/ICME51207.2021.9428279, DOI 10.1109/ICME51207.2021.9428279]
   Zhao L, 2023, IEEE T CIRC SYST VID, V33, P861, DOI 10.1109/TCSVT.2022.3207228
NR 40
TC 0
Z9 0
U1 8
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103961
DI 10.1016/j.jvcir.2023.103961
EA OCT 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X5DN8
UT WOS:001098655300001
DA 2024-07-18
ER

PT J
AU Peng, P
   Liu, Y
   Jing, ZL
   Pan, H
   Zhang, H
AF Peng, Pai
   Liu, Yang
   Jing, Zhongliang
   Pan, Han
   Zhang, Hao
TI DDFusion: An efficient multi-exposure fusion network with dense
   pyramidal convolution and de-correlation fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-exposure fusion; Dense-pyramidal convolution; De-correlation
   convolution
ID IMAGE FUSION; PERFORMANCE; SIFT
AB In this work, we propose DDFusion, a novel multi-exposure image fusion network. DDFusion addresses the limitations of existing methods by effectively recovering details near extremely bright regions and learning associations between non-contiguous regions. To achieve this, our network incorporates a dense pyramidal (DensePy) convolution block in the encoder for multi-scale feature extraction, and a de-correlation fusion (DF) block for enabling structurally coherent and edge-preserving multi-scale feature fusion. It facilitates a smoother transition from highlighted areas to adjacent regions in the fused image. Experimental results demonstrate the superiority of DDFusion over state-of-the-art deep methods in terms of both visual quality and quantitative evaluation. Moreover, DDFusion achieves stronger multi-scale feature extraction capability with smaller computational complexity.
C1 [Peng, Pai; Liu, Yang; Jing, Zhongliang; Pan, Han] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
   [Zhang, Hao] Wuhan Second Ship Design & Res Inst, Wuhan 430010, Peoples R China.
C3 Shanghai Jiao Tong University
RP Jing, ZL (corresponding author), Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai 200240, Peoples R China.
EM zljing@sjtu.edu.cn
OI Jing, Zhongliang/0000-0003-1759-8785; Peng, Pai/0000-0002-7790-6025
FU National Natural Science Foundation of China [61603249, 61673262]; Wuhan
   Second Ship Design and Research Institute, National GF Basic Research
   Program [JCKY2021110B134]; Fundamental Research Funds for the Central
   Universities, China
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant Nos. 61603249, 61673262), the Wuhan Second
   Ship Design and Research Institute, National GF Basic Research Program
   under JCKY2021110B134, and the Fundamental Research Funds for the
   Central Universities, China.
CR Afifi M, 2021, PROC CVPR IEEE, P9153, DOI 10.1109/CVPR46437.2021.00904
   Ancuti CO, 2017, IEEE T IMAGE PROCESS, V26, P65, DOI 10.1109/TIP.2016.2621674
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Duta I. Cosmin, 2020, arXiv preprint arXiv:200611538
   Hayat N, 2019, J VIS COMMUN IMAGE R, V62, P295, DOI 10.1016/j.jvcir.2019.06.002
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Hu JB, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103585
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Jiang QP, 2021, IEEE T IND INFORM, V17, P6062, DOI 10.1109/TII.2020.3035448
   Kou F, 2018, J VIS COMMUN IMAGE R, V53, P235, DOI 10.1016/j.jvcir.2018.03.020
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li ZG, 2012, IEEE T IMAGE PROCESS, V21, P4672, DOI 10.1109/TIP.2012.2207396
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Malik MH, 2008, LECT NOTES ENG COMP, P688
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Pan H, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9246-3
   Petrovic V, 2005, IEEE I CONF COMP VIS, P1866
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Qu L., 2021, arXiv
   Wang M, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2023.103752
   Wang Q, 2005, PHYSICA D, V200, P287, DOI 10.1016/j.physd.2004.11.001
   Wang QT, 2020, IEEE T CIRC SYST VID, V30, P2418, DOI 10.1109/TCSVT.2019.2919310
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xu H, 2020, IEEE T IMAGE PROCESS, V29, P7203, DOI 10.1109/TIP.2020.2999855
   Xu JW, 2022, DISPLAYS, V74, DOI 10.1016/j.displa.2022.102188
   Yu XY, 2021, NEUROCOMPUTING, V449, P146, DOI 10.1016/j.neucom.2021.04.002
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang XC, 2021, INFORM FUSION, V74, P111, DOI 10.1016/j.inffus.2021.02.005
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhou W., 2021, arXiv
   Zhou W, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401285
   Zhu MF, 2020, AAAI CONF ARTIF INTE, V34, P13106
NR 40
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103947
DI 10.1016/j.jvcir.2023.103947
EA OCT 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA X6UG4
UT WOS:001099773000001
DA 2024-07-18
ER

PT J
AU Lu, SQ
   Guan, FX
   Zhang, HY
   Lai, HT
AF Lu, Siqi
   Guan, Fengxu
   Zhang, Hanyu
   Lai, Haitao
TI Underwater image enhancement method based on denoising diffusion
   probabilistic model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image enhancement; Deep learning; Underwater image
   restoration; Denoising diffusion probabilistic model (DDPM)
AB Underwater images often suffer from severe distortion, which seriously affects the image quality and the application. Current underwater image enhancement methods have poor generalization capability and cannot be adapted to all types of underwater images. In recent years, the diffusion model based on the denoising diffusion probabilistic model (DDPM) has achieved excellent results in various fields of computer vision. Inspired by the DDPM, an underwater image enhancement method based on the DDPM (UW-DDPM) was proposed in this paper. The UW-DDPM trained on paired datasets and utilized two U-Net networks to complete image denoising as well as image distribution transformation, which effectively improved the quality of underwater images. By testing on real underwater image datasets, UW-DDPM achieved better improvement in visual effects and evaluation metrics than the existing model.
C1 [Lu, Siqi; Guan, Fengxu; Zhang, Hanyu; Lai, Haitao] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Guan, FX (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
EM guanfengxu@hrbeu.edu.cn
CR Akkaynak D, 2019, PROC CVPR IEEE, P1682, DOI 10.1109/CVPR.2019.00178
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   Berman D, 2021, IEEE T PATTERN ANAL, V43, P2822, DOI 10.1109/TPAMI.2020.2977624
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   He H.H. X., 2021, Comput. Technol. Automat., V40, P114
   Ho J., 2020, ADV NEUR IN, P1
   Hou GJ, 2020, IEEE ACCESS, V8, P122078, DOI 10.1109/ACCESS.2020.3006359
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jia P., 2020, Res. Explor. Lab., V39, P14
   Kar A, 2021, PROC CVPR IEEE, P16200, DOI 10.1109/CVPR46437.2021.01594
   Kocak DM, 2008, MAR TECHNOL SOC J, V42, P52, DOI 10.4031/002533208786861209
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li H., 2019, ARXIV, DOI 1905.09979
   Li HY, 2022, NEUROCOMPUTING, V479, P47, DOI 10.1016/j.neucom.2022.01.029
   Li Y, 2021, IET IMAGE PROCESS, V15, P774, DOI 10.1049/ipr2.12061
   Liu XD, 2020, IEEE GEOSCI REMOTE S, V17, P1488, DOI 10.1109/LGRS.2019.2950056
   Mandal D., 2012, 2012 IEEE Conference on Technologies for Practical Robot Applications (TePRA), P145, DOI 10.1109/TePRA.2012.6215669
   Meng C., 2021, arXiv
   Moghimi MK, 2021, J REAL-TIME IMAGE PR, V18, P1653, DOI 10.1007/s11554-020-01024-4
   Naik A, 2021, AAAI CONF ARTIF INTE, V35, P15853
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Sun X, 2019, IET IMAGE PROCESS, V13, P469, DOI 10.1049/iet-ipr.2018.5237
   Wang J.W. H. R., 2021, Electron. Opt. Control, V28, P4
   Wang JH, 2019, IEEE ACCESS, V7, P145199, DOI 10.1109/ACCESS.2019.2945576
   Wang Y, 2017, IEEE IMAGE PROC, P1382, DOI 10.1109/ICIP.2017.8296508
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
NR 29
TC 6
Z9 6
U1 49
U2 98
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103926
DI 10.1016/j.jvcir.2023.103926
EA AUG 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA R7UR4
UT WOS:001066374600001
DA 2024-07-18
ER

PT J
AU Li, X
   Zhang, Q
   Yan, WQ
   Dai, M
AF Li, Xiang
   Zhang, Qing
   Yan, Weiqi
   Dai, Meng
TI Depth cue enhancement and guidance network for RGB-D salient object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D salient object detection; Depth cue enhancement; Multi-modal
   feature fusion; Depth guidance
ID FUSION
AB Depth maps have been proven profitable to provide supplements for salient object detection in recent years. However, most RGB-D salient object detection approaches ignore that there are usually low-quality depth maps, which will inevitably result in unsatisfactory results. In this paper, we propose a depth cue enhancement and guidance network (DEGNet) for RGB-D salient object detection by exploring the depth quality enhancement and utilizing the depth cue guidance to generate predictions with highlighted objects and suppressed backgrounds. Specifically, a depth cue enhancement module is designed to generate high-quality depth maps by enhancing the contrast between the foreground and the background. Then considering the different characteristics of unimodal RGB and depth features, we use different feature enhancement strategies to strengthen the representation capability of side-output unimodal features. Moreover, we propose a depth-guided feature fusion module to excavate depth cues provided by the depth stream to guide the fusion of multi-modal features by fully making use of different modal properties, thus generating discriminative cross-modal features. Besides, we aggregate cross-modal features at different levels to obtain the final prediction by adopting a pyramid feature shrinking structure. Experimental results on six benchmark datasets demonstrate that the proposed network DEGNet outperforms 17 state-of-the-art methods.
C1 [Li, Xiang; Zhang, Qing; Yan, Weiqi; Dai, Meng] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
C3 Shanghai Institute of Technology
RP Zhang, Q (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM zhangqing0329@gmail.com
FU Natural Science Foundation of Shanghai [19ZR1455300, 21ZR1462600]
FX Acknowledgments This work is supported by Natural Science Foundation of
   Shanghai under Grant Nos. 19ZR1455300 and 21ZR1462600.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Barkoky A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103371
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2021, INT J COMPUT VISION, V129, P2076, DOI 10.1007/s11263-021-01452-0
   Chen H, 2020, IEEE T IMAGE PROCESS, V29, P8407, DOI 10.1109/TIP.2020.3014734
   Chen H, 2020, IEEE T CYBERNETICS, V50, P4808, DOI 10.1109/TCYB.2019.2934986
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen S., 2020, ECCV, P520, DOI DOI 10.1007/978-3-030-58598-3_31
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2017, J COMPUT SCI TECH-CH, V32, P110, DOI 10.1007/s11390-017-1681-7
   Cheng Y, 2014, IEEE INT CON MULTI
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Desingh K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.98
   Ding Y, 2019, J VIS COMMUN IMAGE R, V61, P1, DOI 10.1016/j.jvcir.2019.03.019
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Fu K, 2022, COMPUT VIS MEDIA, V8, P509, DOI 10.1007/s41095-021-0256-2
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Gongyang Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P665, DOI 10.1007/978-3-030-58520-4_39
   Guo JF, 2016, IEEE INT CON MULTI
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han YB, 2022, IEEE ACCESS, V10, P25435, DOI 10.1109/ACCESS.2022.3156935
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Huang NAC, 2022, IEEE T MULTIMEDIA, V24, P1651, DOI 10.1109/TMM.2021.3069297
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Ji W, 2021, PROC CVPR IEEE, P9466, DOI 10.1109/CVPR46437.2021.00935
   Jia X., 2022, COMPUT INTEL NEUROSC
   Jin WD, 2021, IEEE T IMAGE PROCESS, V30, P3376, DOI 10.1109/TIP.2021.3060167
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Kong J, 2019, J VIS COMMUN IMAGE R, V59, P537, DOI 10.1016/j.jvcir.2019.02.013
   Kong Y, 2016, IEEE T IMAGE PROCESS, V25, P2856, DOI 10.1109/TIP.2016.2556940
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li GY, 2021, IEEE T IMAGE PROCESS, V30, P3528, DOI 10.1109/TIP.2021.3062689
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu D, 2021, IEEE T MULTIMEDIA, V23, P967, DOI 10.1109/TMM.2020.2991523
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012
   Ma MC, 2021, AAAI CONF ARTIF INTE, V35, P2311
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Wang AZ, 2017, IEEE SIGNAL PROC LET, V24, P663, DOI 10.1109/LSP.2017.2688136
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wei Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P52, DOI 10.1007/978-3-030-58523-5_4
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu YH, 2022, IEEE T PATTERN ANAL, V44, P10261, DOI 10.1109/TPAMI.2021.3134684
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xiao XL, 2019, IEEE T IMAGE PROCESS, V28, P2126, DOI 10.1109/TIP.2018.2882156
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zhai YJ, 2021, IEEE T IMAGE PROCESS, V30, P8727, DOI 10.1109/TIP.2021.3116793
   Zhang GD, 2021, IEEE SIGNAL PROC LET, V28, P658, DOI 10.1109/LSP.2021.3066071
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4318, DOI 10.1109/ICCV48922.2021.00430
   Zhang M, 2020, PROC CVPR IEEE, P3469, DOI 10.1109/CVPR42600.2020.00353
   Zhang W., 2021, P IEEE INT C MULTIME, P1
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhou T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4661, DOI 10.1109/ICCV48922.2021.00464
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou WJ, 2022, IEEE T MULTIMEDIA, V24, P2192, DOI 10.1109/TMM.2021.3077767
   Zhou XF, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104001
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
NR 74
TC 1
Z9 1
U1 2
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103880
DI 10.1016/j.jvcir.2023.103880
EA JUN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N3SQ5
UT WOS:001036254600001
DA 2024-07-18
ER

PT J
AU Su, Z
   Liu, RZ
   Feng, YX
   Zhou, F
AF Su, Zhuo
   Liu, Ruizhi
   Feng, Yuxin
   Zhou, Fan
TI Attention-adaptive multi-scale feature aggregation dehazing network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single image dehazing; Feature attention; Residual aggregation
ID IMAGE; MODEL
AB In this paper, we propose an end-to-end Attention-adaptive Multi-scale Feature Aggregation Dehazing Network (AMA-Net). The AMA-Net is based on U-Net and designs with three attention-driven modules, Joint Attention Residual Block (JAB), Joint Attention Feature Aggregation Group (JAAG), and Layer Adaptive Attention Feature Aggregation Module (LAA). To be more specific, considering the unevenly distributed haze in images, we introduce the JAB, which adaptively assigns weights to make networks pay attention to important features; to fully utilize the residual features, we propose the residual aggregation (via three JABs) in JAAG; since most feature aggregation methods for dehazing networks do not filter and refine features at different layers, we add LAA to the decoder to weight the features at different layers for aggregation. Through the ablation studies, we verify the effectiveness of the JAB, JAAG, and LAA. Experimental results on synthetic and real-world datasets show that the proposed AMA-Net outperforms relevant state-of-the-art methods.
C1 [Su, Zhuo; Liu, Ruizhi; Feng, Yuxin; Zhou, Fan] Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
   [Zhou, Fan] Sun Yat Sen Univ Shenzhen, Res Inst, Shenzhen, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Zhou, F (corresponding author), Sun Yat Sen Univ, Natl Engn Res Ctr Digital Life, Sch Comp Sci & Engn, Guangzhou, Peoples R China.; Zhou, F (corresponding author), Sun Yat Sen Univ Shenzhen, Res Inst, Shenzhen, Peoples R China.
EM isszf@mail.sysu.edu.cn
RI Su, Zhuo/AAO-4506-2020; Zhou, fan/KIL-4066-2024
OI Su, Zhuo/0000-0002-6090-0110; Feng, Yuxin/0009-0001-7793-0957
FU Guangdong Basic and Applied Basic Research Foundation; Shenzhen Science
   and Technology Program;  [2021A1515012313];  [JCYJ20200109142612234]
FX Acknowledgments This research is supported by the Guangdong Basic and
   Applied Basic Research Foundation (No. 2021A1515012313) , and the
   Shenzhen Science and Technology Program (No. JCYJ20200109142612234) .
CR Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Bai HR, 2022, IEEE T IMAGE PROCESS, V31, P1217, DOI 10.1109/TIP.2022.3140609
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chaitanya BSNV, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103014
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Fan X, 2017, IEEE T CIRC SYST VID, V27, P2505, DOI 10.1109/TCSVT.2016.2592328
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hongyu Li, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P2577, DOI 10.1145/3474085.3475432
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Lai YH, 2015, IEEE T CIRC SYST VID, V25, P1, DOI 10.1109/TCSVT.2014.2329381
   Li BY, 2019, Arxiv, DOI [arXiv:1712.04143, DOI 10.1109/TIP.2018.2867951]
   Li BY, 2018, AAAI CONF ARTIF INTE, P7016
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Liu Y, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103434
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Mehra A, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103137
   Mei KF, 2019, LECT NOTES COMPUT SC, V11361, P203, DOI 10.1007/978-3-030-20887-5_13
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Romano Y, 2015, SIAM J IMAGING SCI, V8, P1187, DOI 10.1137/140990978
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sahu G, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103008
   Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42
   Shyam P, 2021, AAAI CONF ARTIF INTE, V35, P9657
   Wang JB, 2018, IEEE T CIRC SYST VID, V28, P2190, DOI 10.1109/TCSVT.2017.2728822
   Wang T, 2021, NEUROCOMPUTING, V439, P75, DOI 10.1016/j.neucom.2021.01.042
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yin JL, 2020, IEEE T CIRC SYST VID, V30, P3957, DOI 10.1109/TCSVT.2019.2917315
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang XQ, 2022, IEEE T CIRC SYST VID, V32, P510, DOI 10.1109/TCSVT.2021.3067062
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao D, 2021, IEEE T CIRC SYST VID, V31, P3037, DOI 10.1109/TCSVT.2020.3036992
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhou SC, 2019, PROC CVPR IEEE, P10988, DOI 10.1109/CVPR.2019.01125
   Zhou Y, 2023, IEEE T NEUR NET LEAR, V34, P7719, DOI 10.1109/TNNLS.2022.3146004
NR 54
TC 4
Z9 4
U1 6
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103706
DI 10.1016/j.jvcir.2022.103706
EA DEC 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200004
DA 2024-07-18
ER

PT J
AU Kong, LH
   Wang, YM
   Chang, DX
   Zhao, Y
AF Kong, Linhua
   Wang, Yiming
   Chang, Dongxia
   Zhao, Yao
TI Contour enhanced image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contour; Attention mechanism; Deep convolution neural network
AB Recently, very deep convolution neural network (CNN) has shown strong ability in single image superresolution (SISR) and has obtained remarkable performance. However, most of the existing CNN-based SISR methods rarely explicitly use the high-frequency information of the image to assist the image reconstruction, thus making the reconstructed image looks blurred. To address this problem, a novel contour enhanced Image Super-Resolution by High and Low Frequency Fusion Network (HLFN) is proposed in this paper. Specifically, a contour learning subnetwork is designed to learn the high-frequency information, which can better learn the texture of the image. In order to reduce the redundancy of the contour information learned by the contour learning subnetwork during fusion, the spatial channel attention block (SCAB) is introduced, which can select the required high-frequency information adaptively. Moreover, a contour loss is designed and it is used with the l1 loss to optimize the network jointly. Comprehensive experiments demonstrate the superiority of our HLFN over state-of-the-art SISR methods.
C1 [Chang, Dongxia] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   Network Technol, Beijing Key Lab Adv Informat Sci, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Chang, DX (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM dxchang@bjtu.edu.cn
RI kong, linhua/KFB-0107-2024
FU National Natural Science Foun-dation of China;  [62272035]
FX Acknowledgments This research was supported by the National Natural
   Science Foun-dation of China under Grant 62272035.
CR Agustsson Eirikur, 2017, IEEE CVF C COMP VIS, P126, DOI DOI 10.1109/CVPRW.2017.150
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen L, 2017, MULTIMED TOOLS APPL, V76, P2467, DOI 10.1007/s11042-015-3145-9
   Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Jing YC, 2021, PROC CVPR IEEE, P7768, DOI 10.1109/CVPR46437.2021.00768
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu SH, 2022, Arxiv, DOI arXiv:2207.06124
   Lu Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mei YQ, 2020, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR42600.2020.00573
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Shamsolmoali P, 2019, IMAGE VISION COMPUT, V88, P9, DOI 10.1016/j.imavis.2019.03.006
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Yan Q, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2414877
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Yang XY, 2022, Arxiv, DOI arXiv:2207.03337
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Yiding, 2020, ADV NEURAL INF PROCE, V33, P20286
   Yu JH, 2018, Arxiv, DOI arXiv:1808.08718
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2019, Arxiv, DOI arXiv:1903.10082
   Zhang YL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4258, DOI 10.1109/ICCV48922.2021.00424
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 48
TC 1
Z9 1
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103659
DI 10.1016/j.jvcir.2022.103659
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500003
DA 2024-07-18
ER

PT J
AU Khellat-Kihel, S
   Muhammad, J
   Sun, ZA
   Tistarelli, M
AF Khellat-Kihel, Souad
   Muhammad, Jawad
   Sun, Zhenan
   Tistarelli, Massimo
TI Gender and ethnicity recognition based on visual attention-driven deep
   architectures
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual-attention; Periocular regions; Gender prediction; Deep learning;
   Local description
ID FACE RECOGNITION; CLASSIFICATION; FEATURES
AB Most of the time, when people observe, interact or speak to each other, they focus the attention on the ocular parts of the face. This daily life experience has a strong impact on the analysis of periocular facial regions. These facial regions may be exploited in order to identify individuals for several applications, including access control and services such as telebanking and electronic transactions. In this paper we suggest studying the efficiency of the periocular regions on gender and race prediction. Most researchers propose a local texture description based on LBP (Local Binary Pattern) and HoG (Histogram of Oriented Gradients) for the purpose of predicting gender. On the other hand, Deep learning techniques were proposed to predict the gender. However, this requires a huge labeled periocular data for gender which is not available. Also, the expressivity of gender and race can be decreased on the final representation of the Deep architectures comparing to the earlier stages. To overcome these points and for the aim of predicting gender and race, considering also the high impact of DCNNs (Deep Convolutional Neural Networks) techniques to solve several aspects in biometrics, we suggest a Deep architecture based on visual attention on the periocular part. The visual saliency extraction is based on primary layers' activation by analyzing the feature-maps. We study how the visual attention-based features coupled to Deep Neural Networks can be used to discriminate between gender and race, hence extract a significant feature from periocular regions. Different pretrained architectures such as Alexnet and ResNet-50 were considered to extract visual saliency points or interest points. Several experiments were performed on periocular regions and a comparative study was conducted. The present results not only demonstrate the feasibility but also the robustness of the extracted interest points.
C1 [Khellat-Kihel, Souad] Univ Djillali Liabes Sidi Bel Abbes, Comp Sci Dept, EEDIS Lab, Sidi Bel Abbes, Algeria.
   [Tistarelli, Massimo] Univ Sassari, Comp Vis Lab, Viale Italia 39, I-07100 Sassari, Italy.
   [Muhammad, Jawad; Sun, Zhenan] Chinese Acad Sci, Inst Automat, N95 ZhongGuanCun East St, Beijing 100190, Peoples R China.
C3 University Djillali Liabes Sidi Bel Abbes; University of Sassari;
   Chinese Academy of Sciences; Institute of Automation, CAS
RP Khellat-Kihel, S (corresponding author), Univ Djillali Liabes Sidi Bel Abbes, Comp Sci Dept, EEDIS Lab, Sidi Bel Abbes, Algeria.
EM souad.khellat-kihel@univ-sba.dz
FU European Commission; Italian Ministry of Research [690907]
FX This research work has been partially supported by a grant from the
   European Commission (H2020 MSCA RISE 690907 IDENTITY) and by a grant of
   the Italian Ministry of Research (PRIN 2015) .
CR Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   [Anonymous], 2018, CS231n: Convolutional Neural Networks for Visual Recognition
   [Anonymous], 2001, WORKSH STAT COMP THE
   [Anonymous], 2003, P BRIT MACH VIS C
   Balci K, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047869
   Bobeldyk D., 2016, 2016 INT C BIOMETRIC, P1, DOI DOI 10.1109/BIOSIG.2016.7736928
   Cadoni M., 2020, APPIS 2020 3 INT C A, P7, DOI [10.1145/3378184.3378197, DOI 10.1145/3378184.3378197]
   Cantoni V, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P574, DOI 10.1109/SITIS.2014.40
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   ImageNet, ABOUT US
   Juefei-Xu F, 2016, IEEE COMPUT SOC CONF, P136, DOI 10.1109/CVPRW.2016.24
   Khellat-Kihel S., 2019, PROGR PATTERN RECOGN, V11896
   KhellatKihel S., 2018, P 6 INT WORKSH BIOM, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumari S, 2012, PROCEDIA ENGINEER, V38, P945, DOI 10.1016/j.proeng.2012.06.119
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Lyle J.R., 2010, IEEE 4 INT C BIOM TH
   Lyle JR, 2012, PATTERN RECOGN, V45, P3877, DOI 10.1016/j.patcog.2012.04.027
   Manyala A, 2019, PATTERN ANAL APPL, V22, P1493, DOI 10.1007/s10044-018-0722-3
   Merkow J., 2010, Proc. 4th IEEE Conf. on BTAS, P1, DOI DOI 10.1109/BTAS.2010.5634509
   O'Toole AJ, 2018, TRENDS COGN SCI, V22, P794, DOI 10.1016/j.tics.2018.06.006
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rodríguez P, 2017, PATTERN RECOGN, V72, P563, DOI 10.1016/j.patcog.2017.06.028
   Savchenko AV, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.197
   Savchenko Andrey V, 2021, arXiv
   Tapia J, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS), P529, DOI 10.1109/SITIS.2018.00086
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Viedma I, 2019, IET BIOMETRICS, V8, P340, DOI 10.1049/iet-bmt.2018.5233
   Wiskott L, 1999, INT SER COMPUTAT INT, P355
   Woodard D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P162, DOI DOI 10.1109/CVPRW.2010.5544621
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   US
NR 37
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103627
DI 10.1016/j.jvcir.2022.103627
EA SEP 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800008
DA 2024-07-18
ER

PT J
AU Zhang, SP
   Feng, SX
   Chen, JW
   Zhou, CJ
   Yang, FZ
AF Zhang, Saiping
   Feng, Shixuan
   Chen, Jingwu
   Zhou, Chunjie
   Yang, Fuzheng
TI A GCN-based fast CU partition method of intra-mode VVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile Video Coding; Intra partition mode prediction; Complexity
   reduction; Global convolutional network
AB In this paper, a global convolutional network (GCN)-based fast coding unit (CU) partition method of intra-mode VVC is proposed. By using the GCN module with large kernel size convolutions, the proposed method can capture global information in CUs, leading to an accurate partition mode prediction in the quad-tree plus multi-type tree (QTMT) structure. Ranked according to predicted probabilities, the partition modes with lower probabilities are discarded, which reduces the computational complexity of VVC. Additionally, tradeoffs between performance and complexity can be achieved with different strategies. Experimental results demonstrated that the proposed method can reduce encoding time by 51.06%similar to 61.15% while increasing Bjontegaard delta bit-rate (BD-BR) by 0.84%similar to 1.52% when implemented in VTM 10.0, outperforming the state-of-the-art methods, and that the proposed method can be used to accelerate VVenC 1.0 at the preset slower, achieving higher performance and lower complexity compared with the original VVenC 1.0 at the presets slow and medium.
C1 [Zhang, Saiping; Feng, Shixuan; Chen, Jingwu; Zhou, Chunjie; Yang, Fuzheng] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
C3 Xidian University
RP Zhang, SP (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
EM spzhang@stu.xidian.edu.cn
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Cheon M, 2018, IEEE T CIRC SYST VID, V28, P1467, DOI 10.1109/TCSVT.2017.2683504
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Fu PC, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458479
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu Z, 2019, IEEE DATA COMPR CONF, P593, DOI 10.1109/DCC.2019.00105
   Ng KT, 2005, IEEE T CIRC SYST VID, V15, P82, DOI 10.1109/TCSVT.2004.839989
   Park SH, 2021, IEEE T MULTIMEDIA, V23, P4388, DOI 10.1109/TMM.2020.3042062
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saldanha M, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103202
   Shuang Peng, 2019, 2019 IEEE International Conference on Real-time Computing and Robotics (RCAR). Proceedings, P65, DOI 10.1109/RCAR47638.2019.9044150
   Siqueira I, 2020, IEEE LAT AMER SYMP
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang G., 2019, P IEEE VIS COMM IM P, P1
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Tech G., 2021, APPL DIGITAL IMAGE P, V11842, P31
   Tech G., 2021, IEEE IMAGE PROC, P2109, DOI [10.1109/ICIP42928.2021.9506360, DOI 10.1109/ICIP42928.2021.9506360]
   Tech G, 2021, PICT COD SYMP, P31, DOI 10.1109/PCS50896.2021.9477452
   Tech G, 2021, IEEE DATA COMPR CONF, P3, DOI 10.1109/DCC50243.2021.00008
   Tissier A, 2020, IEEE IMAGE PROC, P3139, DOI [10.1109/ICIP40778.2020.9190797, 10.1109/icip40778.2020.9190797]
   Touvron H, 2021, Arxiv, DOI [arXiv:2105.03404, DOI 10.48550/ARXIV.2105.03404]
   Tsang SH, 2020, IEEE I C VI COM I PR, P177, DOI 10.1109/vcip49819.2020.9301885
   Wei Li, 2020, 2020 IEEE 5th International Conference on Signal and Image Processing (ICSIP), P108, DOI 10.1109/ICSIP49896.2020.9339262
   Wieckowski A, 2019, IEEE IMAGE PROC, P4130, DOI [10.1109/icip.2019.8803533, 10.1109/ICIP.2019.8803533]
   HoangVan X, 2021, PROC INT CONF ADV, P195, DOI 10.1109/ATC52653.2021.9598222
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Zhang HC, 2021, IEEE DATA COMPR CONF, P382, DOI 10.1109/DCC50243.2021.00060
   Zhang QW, 2021, IEEE ACCESS, V9, P119289, DOI 10.1109/ACCESS.2021.3108238
NR 36
TC 5
Z9 5
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103621
DI 10.1016/j.jvcir.2022.103621
EA AUG 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W2FV
UT WOS:000859982300005
DA 2024-07-18
ER

PT J
AU Inoue, K
   Cho, M
AF Inoue, Kotaro
   Cho, Myungjin
TI Amplitude based keyless optical encryption system using deep neural
   network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Optical encryption; Deep neural network; Amplitude-based double random
   phase; encryption
ID RANDOM-PHASE ENCRYPTION; IMAGE ENCRYPTION; PLAINTEXT ATTACK;
   AUTHENTICATION; VULNERABILITY; SPACE
AB Double random phase encryption (DRPE) system is a simple and powerful encoding technique that consists of only two lenses and two random phase masks. However, there are many issues for applying to actual security systems such as phase acquisition, vulnerability to phase retrieval techniques, and data throughput. Although various extensions of DRPE have addressed each issue, there is no comprehensive solution. To tackle all the issues of DRPE, we propose a new amplitude-based DRPE (ADRPE) system using deep learning. The encoding is the same as the current ADRPE system, and the decoding is achieved by an inverse ADRPE system using convolution neural networks. Our system can achieve a real-time end-to-end encryption system without any additional optical devices and exposure of the keys. To demonstrate our method, we applied it to simulations with various datasets such as passwords, Quick-Response (QR) codes, and fingerprints.
C1 [Inoue, Kotaro; Cho, Myungjin] Hankyong Natl Univ, Sch ICT Robot & Mech Engn, IITC, 327 Chungang Ro, Anseong 17579, Kyonggi Do, South Korea.
C3 Hankyong National University
RP Cho, M (corresponding author), Hankyong Natl Univ, Sch ICT Robot & Mech Engn, IITC, 327 Chungang Ro, Anseong 17579, Kyonggi Do, South Korea.
EM mjcho@hknu.ac.kr
OI Cho, Myungjin/0000-0003-2896-770X; Inoue, Kotaro/0000-0001-6313-3837
FU National Research Foundation of Korea (NRF) [2017K1A3A1A 19070753,
   NRF-2020R1F1A1068637]
FX National Research Foundation of Korea (NRF) (2017K1A3A1A 19070753,
   NRF-2020R1F1A1068637) .
CR Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Chen LF, 2020, OPT EXPRESS, V28, P28154, DOI 10.1364/OE.402958
   Chen W, 2010, OPT LETT, V35, P3817, DOI 10.1364/OL.35.003817
   Cho M, 2013, OPT LETT, V38, P3198, DOI 10.1364/OL.38.003198
   Gawande Ujwalla, 2014, International Conference on Computing and Communication Technologies (ICCCT). Proceedings, P1, DOI 10.1109/ICCCT2.2014.7066732
   Gawande U., 2013, Biometric Technology Today, P7, DOI DOI 10.1016/S0969-4765(13)70035-3
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hai H, 2019, OPT EXPRESS, V27, P21204, DOI 10.1364/OE.27.021204
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   I.O. for Standardization I.E. Commission, 2006, INFORM TECHNOLOGY AU
   Jang JY, 2016, J OPT SOC KOREA, V20, P228, DOI 10.3807/JOSK.2016.20.2.228
   JAVIDI B, 1989, APPL OPTICS, V28, P4518, DOI 10.1364/AO.28.004518
   Jiao SM, 2020, OPT EXPRESS, V28, P8085, DOI 10.1364/OE.387505
   Jiao SM, 2020, OPT EXPRESS, V28, P3717, DOI 10.1364/OE.382319
   Jung J, 2010, OPT LETT, V35, P1825, DOI 10.1364/OL.35.001825
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1990, NeurIPS, P396
   Li GW, 2017, OPT EXPRESS, V25, P8690, DOI 10.1364/OE.25.008690
   Maas A.L., 2013, P 30 INT C MACH LEAR, V30, P3
   Markman A, 2014, J OPT SOC AM A, V31, P394, DOI 10.1364/JOSAA.31.000394
   Monaghan DS, 2007, APPL OPTICS, V46, P6641, DOI 10.1364/AO.46.006641
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Qin Y, 2020, OPT LASER ENG, V127, DOI 10.1016/j.optlaseng.2019.105979
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shi YS, 2013, OPT LETT, V38, P1425, DOI 10.1364/OL.38.001425
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Test B.I, CASIA FINGERPRINT IM
   Unnikrishnan G, 2000, OPT ENG, V39, P2853, DOI 10.1117/1.1313498
   Wang Y, 2016, J OPT SOC AM A, V33, P2158, DOI 10.1364/JOSAA.33.002158
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZP, 2014, OPT COMMUN, V332, P36, DOI 10.1016/j.optcom.2014.06.070
   Yu F., P INT C LEARN REPR, P1
   Zhou LN, 2020, OPT LETT, V45, P5279, DOI 10.1364/OL.400174
   Zhou LN, 2020, OPT EXPRESS, V28, P2499, DOI 10.1364/OE.380004
NR 42
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103251
DI 10.1016/j.jvcir.2021.103251
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800007
DA 2024-07-18
ER

PT J
AU Lee, JY
   Park, SH
AF Lee, Jin Young
   Park, Sang-hyo
TI Adaptive fractional motion and disparity estimation skipping in MV-HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Encoding complexity; Disparity estimation (DE); Motion estimation (ME);
   Interview coding; MV-HEVC
ID VIDEO; EFFICIENCY; MULTIVIEW
AB MV-HEVC can efficiently compress multiview video data captured from different viewpoints. To achieve high coding efficiency, it consists of not only inter coding but also interview coding. The inter coding includes a motion estimation (ME) process that reduces temporal redundancies between consecutive frames, and the interview coding performs a disparity estimation (DE) that reduces interview redundancies between neighboring views. As a result, MV-HEVC needs high encoding complexity to perform both ME and DE. In order to reduce the complexity, this paper proposes an adaptive fractional ME and DE skipping method in a partitioned inter pre-diction unit (PU) mode, based on a result of a 2 N x 2 N inter PU coding. Experimental results show that the proposed method efficiently reduces the encoding complexity with negligible coding loss, compared to con-ventional methods.
C1 [Lee, Jin Young] Sejong Univ, Sch Intelligent Mechatron Engn, Seoul, South Korea.
   [Park, Sang-hyo] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
C3 Sejong University; Kyungpook National University
RP Park, SH (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu, South Korea.
EM jinyounglee@sejong.ac.kr; s.park@knu.ac.kr
OI Park, Sang-hyo/0000-0002-7282-7686
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [NRF-2018R1C1B5086072, NRF-2020M3F6A1109603, NRF-2021R1C1C 1006459];
   National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2020R1I1A3072227]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (NRF-2018R1C1B5086072,
   NRF-2020M3F6A1109603, NRF-2021R1C1C 1006459) and by Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Educa-tion (NRF-2020R1I1A3072227) .
CR [Anonymous], 2013, H265 ITUT
   [Anonymous], 2003, H264 ITUT
   [Anonymous], 2014, Doc. JCT3V-G1100
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Dai W., 2013, IEEE INT C IM PROC S
   Fan R, 2017, SIGNAL PROCESS-IMAGE, V53, P123, DOI 10.1016/j.image.2017.02.005
   Jung J., 2021, 1SC29WG04 ISOIECJTC
   Li Yuanyuan, 2016, VISUAL COMMUN-US, P1
   Lv H, 2012, 2012 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Merkle P, 2013, IEEE INT CON MULTI, P1
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Pan ZQ, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159170
   Park SH, 2019, ICT EXPRESS, V5, P136, DOI 10.1016/j.icte.2018.08.003
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Ugur K., 2013, IEEE INT C AC SPEECH
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 19
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103223
DI 10.1016/j.jvcir.2021.103223
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900012
DA 2024-07-18
ER

PT J
AU Tang, ZJ
   Zhang, SP
   Zhang, XQ
   Li, ZX
   Chen, ZH
   Yu, CQ
AF Tang, Zhenjun
   Zhang, Shaopeng
   Zhang, Xianquan
   Li, Zhixin
   Chen, Zhenhai
   Yu, Chunqiang
TI Video hashing with secondary frames and invariant moments*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video hashing; Hash function; Secondary frame; Discrete wavelet
   transform (DWT); Invariant moments
ID RING PARTITION; ROBUST; IMAGE; RETRIEVAL; QUANTIZATION; RECOGNITION;
   PROJECTIONS; TRANSFORM; AUDIO
AB Video hashing is a useful technique of many multimedia systems, such as video copy detection, video authentication, tampering localization, video retrieval, and anti-privacy search. In this paper, we propose a novel video hashing with secondary frames and invariant moments. An important contribution is the secondary frame construction with 3D discrete wavelet transform, which can reach initial data compression and robustness against noise and compression. In addition, since invariant moments are robust and discriminative features, hash generation based on invariant moments extracted from secondary frames can ensure good classification of the proposed video hashing. Extensive experiments on 8300 videos are conducted to validate efficiency of the proposed video hashing. The results show that the proposed video hashing can resist many digital operations and has good discrimination. Performance comparisons with some state-of-the-art algorithms illustrate that the proposed video hashing outperforms the compared algorithms in classification in terms of receiver operating characteristic results.
C1 Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min Secur, Guilin 541004, Peoples R China.
   [Tang, Zhenjun] Guangxi Normal Univ, Dept Comp Sci, 15 YuCai Rd, Guilin 541004, Peoples R China.
C3 Guangxi Normal University; Guangxi Normal University
RP Tang, ZJ (corresponding author), Guangxi Normal Univ, Dept Comp Sci, 15 YuCai Rd, Guilin 541004, Peoples R China.
EM tangzj230@163.com
RI Li, Zhixin/ABI-9264-2022
OI Li, Zhixin/0000-0002-5313-6134; Chen, Zhenhai/0000-0001-9414-6278
FU National Natural Science Foundation of China [61962008, 62062013,
   61762017, 61966004]; Guangxi "Bagui Scholar" Team for Innovation and
   Research; Guangxi Talent Highland Project of Big Data Intelligence and
   Application; Guangxi Collaborative Innovation Center of Multi-source
   Information Integration and Intelligent Processing; Natural Science
   Project of Guangxi Universities [2021KY0051]; Innovation Project of
   Guangxi Graduate Education [XYCSZ2021009]
FX This work is partially supported by the National Natural Science
   Foundation of China [Grant numbers 61962008, 62062013, 61762017,
   61966004] , Guangxi "Bagui Scholar" Team for Innovation and Research,
   the Guangxi Talent Highland Project of Big Data Intelligence and
   Application, Guangxi Collaborative Innovation Center of Multi-source
   Information Integration and Intelligent Processing, Natural Sci-ence
   Project of Guangxi Universities [Grant number 2021KY0051] , and the
   Innovation Project of Guangxi Graduate Education [Grant number
   XYCSZ2021009] . The authors would like to thank the anonymous re-viewers
   for their valuable comments and suggestions.
CR [Anonymous], REEFVID FREE REEF VI
   Balado F, 2007, IEEE T INF FOREN SEC, V2, P254, DOI 10.1109/TIFS.2007.897258
   Campisi P, 2005, IEEE IMAGE PROC, P941
   Chen HC, 2018, MULTIMED TOOLS APPL, V77, P5303, DOI 10.1007/s11042-017-4434-2
   Chen L, 2020, LECT NOTES COMPUT SC, V11961, P802, DOI 10.1007/978-3-030-37731-1_65
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   De Roover C, 2005, IEEE T SIGNAL PROCES, V53, P4020, DOI 10.1109/TSP.2005.855414
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Guo YC, 2018, IEEE T IMAGE PROCESS, V27, P949, DOI 10.1109/TIP.2017.2766445
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Hao YB, 2017, IEEE T IMAGE PROCESS, V26, P5531, DOI 10.1109/TIP.2017.2737329
   HSIA TC, 1981, IEEE T SYST MAN CYB, V11, P831
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu YC, 2018, J VIS COMMUN IMAGE R, V55, P21, DOI 10.1016/j.jvcir.2018.05.013
   Khelifi F, 2019, IEEE T CIRC SYST VID, V29, P50, DOI 10.1109/TCSVT.2017.2776159
   Kim HG, 2016, CLUSTER COMPUT, V19, P315, DOI 10.1007/s10586-015-0523-z
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P4397, DOI 10.1109/TIP.2012.2206036
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu QL, 2019, J VIS COMMUN IMAGE R, V59, P150, DOI 10.1016/j.jvcir.2018.11.011
   Liu W, 2020, MULTIMED TOOLS APPL, V79, P6709, DOI 10.1007/s11042-019-08147-2
   Liu XC, 2013, IEEE SIGNAL PROC LET, V20, P1253, DOI 10.1109/LSP.2013.2287006
   López O, 2010, IEEE INT CON MULTI, P1337, DOI 10.1109/ICME.2010.5583570
   Nie XS, 2016, SCI CHINA INFORM SCI, V59, DOI 10.1007/s11432-016-5528-6
   Nie XS, 2010, INT CONF SIGN PROCES, P1837, DOI 10.1109/ICOSP.2010.5656914
   Oostveen J, 2001, PROC SPIE, V4472, P121, DOI 10.1117/12.449746
   Rameshnath S, 2019, MULTIMED TOOLS APPL, V78, P18055, DOI 10.1007/s11042-019-7189-0
   Saikia N, 2015, 2015 INTERNATIONAL CONFERENCE ON GREEN COMPUTING AND INTERNET OF THINGS (ICGCIOT), P694, DOI 10.1109/ICGCIoT.2015.7380552
   Sandeep R, 2016, MULTIMED TOOLS APPL, V75, P7779, DOI 10.1007/s11042-015-2695-1
   Sandoval-Soto R., 2017, P INT C SIGNAL PROCE, P1, DOI 10.1109/SCCC.2017.8405140
   Setyawan I, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY SYSTEMS AND INNOVATION (ICITSI), P111, DOI 10.1109/ICITSI.2014.7048247
   Singh P, ROBUST HOMOMORPHIC V, P2021
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Tang Z., SECURITY COMMUNICATI, P2021
   Tang ZJ, 2020, COMPUT J, V63, P1017, DOI 10.1093/comjnl/bxz060
   Tang ZJ, 2020, IET IMAGE PROCESS, V14, P901, DOI 10.1049/iet-ipr.2019.1157
   Tang ZJ, 2019, IEEE T KNOWL DATA EN, V31, P549, DOI 10.1109/TKDE.2018.2837745
   Tang ZJ, 2016, IEEE T INF FOREN SEC, V11, P200, DOI 10.1109/TIFS.2015.2485163
   Tang ZJ, 2014, IET IMAGE PROCESS, V8, P142, DOI 10.1049/iet-ipr.2013.0332
   Tang ZJ, 2014, IEEE T KNOWL DATA EN, V26, P711, DOI 10.1109/TKDE.2013.45
   Wang J, 2012, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2012.6466942
   Weng L, 2010, LECT NOTES COMPUT SC, V5916, P662, DOI 10.1007/978-3-642-11301-7_66
   Wu GS, 2019, IEEE T IND ELECTRON, V66, P9868, DOI 10.1109/TIE.2018.2873547
   Wu GS, 2019, IEEE T IMAGE PROCESS, V28, P1993, DOI 10.1109/TIP.2018.2882155
   Xiang SJ, 2012, SCI CHINA INFORM SCI, V55, P1520, DOI 10.1007/s11432-011-4450-1
   Yang GB, 2012, COMPUT SECUR, V31, P33, DOI 10.1016/j.cose.2011.11.004
   Yuenan Li, 2010, Proceedings 2010 International Conference on Computational Intelligence and Security (CIS 2010), P433, DOI 10.1109/CIS.2010.100
   Zhan HN, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P146, DOI 10.1109/CompComm.2015.7387557
   Zhao JD, 2019, MULTIMED TOOLS APPL, V78, P75, DOI 10.1007/s11042-017-5254-0
NR 50
TC 8
Z9 8
U1 6
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103209
DI 10.1016/j.jvcir.2021.103209
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900010
DA 2024-07-18
ER

PT J
AU Liang, CH
   Su, HT
   Hsu, WH
AF Liang, Chih-Hung
   Su, Hung-Ting
   Hsu, Winston H.
TI Learn from the past - sequentially one-to-one video deblurring network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video deblurring; Deblurring; Image quality enhancement
AB With the growing availability of hand-held cameras in recent years, more and more images and videos are taken at any time and any place. However, they usually suffer from undesirable blur due to camera shake or object motion in the scene. In recent years, a few modern video deblurring methods are proposed and achieve impressive performance. However, they are still not suitable for practical applications as high computational cost or using future information as input. To address the issues, we propose a sequentially one-to-one video deblurring network (SOON) which can deblur effectively without any future information. It transfers both spatial and temporal information to the next frame by utilizing the recurrent architecture. In addition, we design a novel Spatio-Temporal Attention module to nudge the network to focus on the meaningful and essential features in the past. Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art deblurring methods, both quantitatively and qualitatively, on various challenging real-world deblurring datasets. Moreover, as our method deblurs in an online manner and is potentially real-time, it is more suitable for practical applications.
C1 [Liang, Chih-Hung; Su, Hung-Ting; Hsu, Winston H.] Natl Taiwan Univ, Taipei, Taiwan.
C3 National Taiwan University
RP Hsu, WH (corresponding author), Natl Taiwan Univ, Taipei, Taiwan.
EM r06922057@cmlab.csie.ntu.edu.tw; htsu@cmlab.csie.ntu.edu.tw;
   whsu@ntu.edu.tw
RI Su, Hung-Ting/HNC-5008-2023
FU Ministry of Science and Technology, Taiwan [MOST 1102634F002026]
FX This work was supported in part by the Ministry of Science and
   Technology, Taiwan, under Grant MOST 1102634F002026. We benefit from
   NVIDIA DGX-1 AI Supercomputer and are grateful to the National Center
   for Highperformance Computing.
CR [Anonymous], 2017, CVPR
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Cai X., 2018, MULTIMEDIA SYST, P1
   Delbracio M, 2015, IEEE T COMPUT IMAG, V1, P270, DOI 10.1109/TCI.2015.2501245
   Gong D, 2017, PROC CVPR IEEE, P3806, DOI 10.1109/CVPR.2017.405
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P., 2017, P IEEE C COMP VIS PA, P1125
   Kim TH, 2017, IEEE I CONF COMP VIS, P4058, DOI 10.1109/ICCV.2017.435
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kim TH, 2014, PROC CVPR IEEE, P2766, DOI 10.1109/CVPR.2014.348
   Kim Y, 2020, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR42600.2020.00354
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li W, 2013, J VIS COMMUN IMAGE R, V24, P1394, DOI 10.1016/j.jvcir.2013.09.008
   Li Z., 2017, Toward a Practical Perceptual Video Quality Metric
   Liao X, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Michaeli T, 2014, LECT NOTES COMPUT SC, V8691, P783, DOI 10.1007/978-3-319-10578-9_51
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Quan Y., 2020, P IEEE CVF C COMP VI P IEEECVF C COMPUTER, P1890
   Shi XJ, 2015, ADV NEUR IN, V28
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Sun LH, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P1
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Veerabadran V., 2020, P IEEE CVF C COMP VI P IEEE CVF C COMP VI, P168
   Wang M, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102648
   Wieschollek P, 2017, IEEE I CONF COMP VIS, P231, DOI 10.1109/ICCV.2017.34
   Xiao Cao, 2018, ARXIV PREPRINT ARXIV
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yang R, 2020, PROC CVPR IEEE, P6627, DOI 10.1109/CVPR42600.2020.00666
   Yue H., 2020, C COMP VIS PATT REC, P2301
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, DOI [10.1109/ICCV.2017.244, DOI 10.1109/ICCV.2017.244]
NR 39
TC 0
Z9 0
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103159
DI 10.1016/j.jvcir.2021.103159
EA JUN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LW
UT WOS:000674617500001
DA 2024-07-18
ER

PT J
AU Peixoto, BM
   Lavi, B
   Dias, Z
   Rocha, A
AF Peixoto, Bruno M.
   Lavi, Bahram
   Dias, Zanoni
   Rocha, Anderson
TI Harnessing high-level concepts, visual, and auditory features for
   violence detection in videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID NETWORKS
AB In detecting sensitive media, violence is one of the hardest to define objectively, and thus, a significant challenge to detect automatically. While many studies were conducted in detecting aspects of violence, very few try to approach the general concept. We propose a method that aims to enable machines to understand a high-level concept of violence by first breaking it down into smaller, more objective ones, such as fights, explosions, blood, and gunshots, to combine them later, leading to a better understanding of the scene. For this, we leverage characteristics of each individual sub-concept of violence (relying upon custom-tailored convolutional neural networks) to guide how they should be described. A fight scene should incorporate temporal features that a scene with blood does not need to describe. A scene with explosions or gunshots should weigh more on its audio features. With this multimodal approach, we trained visual and auditory feature detectors and later combined them into a decision neural network to give us a violence detector that considers several different aspects of the problem. This robust and modular approach allows different cultures and users to adapt the detector to their specific needs.
C1 [Peixoto, Bruno M.; Lavi, Bahram; Dias, Zanoni; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Lavi, B (corresponding author), Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
EM bruno.peixoto@ic.unicamp.br; bahram.lavi@ic.unicamp.br;
   zanoni@ic.unicamp.br; anderson.rocha@ic.unicamp.br
RI Lavi, Bahram/AAR-7746-2020; Rocha, Anderson/KHU-9621-2024
OI Lavi, Bahram/0000-0002-9226-9116; Dias, Zanoni/0000-0003-3333-6822;
   Peixoto, Bruno Malveira/0000-0002-4994-8973
FU Sao Paulo Research Foundation (FAPESP), Brazil [DejaVu 2017/12646-3,
   2018/05668-3]; National Counsel of Technological and Scientific
   Development (CNPq), Brazil [400487/2016-0, 425340/2016-3]
FX This work was funded by the Sao Paulo Research Foundation (FAPESP),
   Brazil under the thematic project DejaVu 2017/12646-3 and grant number
   2018/05668-3. Additional funding was awarded by the National Counsel of
   Technological and Scientific Development (CNPq), Brazil under grants
   400487/2016-0 and 425340/2016-3.
CR [Anonymous], 2013, MEDIAEVAL
   [Anonymous], 1996, WHO GLOBAL CONSULTAT
   [Anonymous], 2005, DOVE DETECTION MOVIE
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bilinski P, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P30, DOI 10.1109/AVSS.2016.7738019
   Blunsden S, 2009, ANN BMVA, V4
   Bogdanov D., 2013, P 21 ACM INT C MULT, P855, DOI [10.1145/2502081.2502229, DOI 10.1145/2502081]
   Borrelli C, 2019, IEEE INT WORKS INFOR, DOI 10.1109/wifs47025.2019.9034986
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Cheng W.-H., 2003, P 5 ACM SIGMM INT WO, P109, DOI DOI 10.1145/973264.973282
   Constantin Mihai Gabriel, 2020, IEEE T AFFECT COMPUT
   Dai Q., 2013, MediaEval
   Dai Qi, 2015, CEUR WORKSHOP PROC, V1436
   Datta A, 2002, INT C PATT RECOG, P433, DOI 10.1109/ICPR.2002.1044748
   Demarty CH, 2015, MULTIMED TOOLS APPL, V74, P7379, DOI 10.1007/s11042-014-1984-4
   Demarty Claire-Helene, 2014 12 INT WORKSH C
   Ding CH, 2014, LECT NOTES COMPUT SC, V8888, P551, DOI 10.1007/978-3-319-14364-4_53
   Dong ZH, 2016, COMM COM INF SC, V662, P517, DOI 10.1007/978-981-10-3002-4_43
   Edison A, 2017, IEEE COMPUT SOC CONF, P1642, DOI 10.1109/CVPRW.2017.209
   Ellis Daniel., 2007, Resources of Laboratory for the Recognition and Organization of Speech and Audio-LabROSA
   Fu EY, 2017, INT J PERVASIVE COMP, V13, P130, DOI 10.1108/IJPCC-02-2017-0018
   Hanson A., 2018, P EUROPEAN C COMPUTE, P0
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Jiang DN, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P113, DOI 10.1109/ICME.2002.1035731
   Jin Qin, 2015, CEUR WORKSHOP PROC, V1436
   Lam Vu, 2015, CEUR WORKSHOP PROC, V1436
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Larson Martha A., 2015, CEUR WORKSHOP PROC, V1436
   Li Xirong, 2016, ABS160408088 CORR
   Meng ZH, 2017, LECT NOTES COMPUT SC, V10528, P437, DOI 10.1007/978-3-319-68345-4_39
   Mironica Ionut, 2015, CEUR WORKSHOP PROC, V1436
   Moreira D, 2016, FORENSIC SCI INT, V268, P46, DOI 10.1016/j.forsciint.2016.09.010
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Peixoto B, 2019, INT CONF ACOUST SPEE, P8276, DOI 10.1109/ICASSP.2019.8682833
   Peixoto BM, 2019, 13TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY (ARES 2018), DOI 10.1145/3230833.3232809
   Perez M, 2019, INT CONF ACOUST SPEE, P2662, DOI [10.1109/icassp.2019.8683676, 10.1109/ICASSP.2019.8683676]
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Senst T, 2017, IEEE T INF FOREN SEC, V12, P2945, DOI 10.1109/TIFS.2017.2725820
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Souza F, 2011, LECT NOTES COMPUT SC, V7042, P248, DOI 10.1007/978-3-642-25085-9_29
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tsironi E, 2017, NEUROCOMPUTING, V268, P76, DOI 10.1016/j.neucom.2016.12.088
   Vlastelica P. Marin, 2015, CEUR WORKSHOP PROC, V1436
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wu P., 2020, COMPUTER VISION ECCV, P322
   Xia Q, 2018, LECT NOTES COMPUT SC, V10996, P157, DOI 10.1007/978-3-319-97909-0_17
   Yi Y., 2015, MEDIAEVAL, V1436
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhai XH, 2019, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2019.00156
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
NR 51
TC 9
Z9 10
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103174
DI 10.1016/j.jvcir.2021.103174
EA JUN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200008
DA 2024-07-18
ER

PT J
AU Li, ZY
   Hu, CM
   Nai, K
   Yuan, J
AF Li, Zhiyong
   Hu, Chenming
   Nai, Ke
   Yuan, Jin
TI Siamese target estimation network with AIoU loss for real-time visual
   tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Siamese network; Target estimation network;
   Intersection over union (IoU) loss
AB The fully convolutional siamese network based trackers achieve great progress recently. Most of these methods focus on improving the capability of siamese network to represent the target. In this paper, we propose our model which focuses on estimating the state of the target with our proposed novel IoU (intersection over union) loss function which is named AIoU. Our model consists of a siamese subnetwork for feature extraction and a target estimation subnetwork for state representation. The target estimation subnetwork contains a classification head for classifying background and foreground and a regression head for estimating target. In order to regress better bounding boxes, we further study the loss function utilized in the regression head and propose a powerful IoU loss function. Our tracker achieves competitive performance on OTB2015, VOT2018, and VOT2019 benchmarks with a speed of 180 FPS, which proves the effectiveness of our method.
C1 [Li, Zhiyong; Hu, Chenming; Nai, Ke; Yuan, Jin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Li, Zhiyong; Hu, Chenming; Nai, Ke; Yuan, Jin] Key Lab Embedded & Network Comp Hunan Prov, Changsha 410082, Peoples R China.
C3 Hunan University
RP Li, ZY; Hu, CM; Nai, K (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM zhiyong.li@hnu.edu.cn; triumphin@hnu.edu.cn; naike_hnu@hnu.edu.cn;
   yuanjin@hnu.edu.cn
RI Wang, Zejun/KBB-8454-2024; li, zy/HZM-1892-2023
OI , Chenming/0000-0002-4751-2789
FU National Key Research and Development Program of China [2018YFB1308604];
   National Natural Science Foundation of China [61672215, 61976086]; Hunan
   Science and Technology Innovation Project, China [2017XK2102]; Hunan
   Innovation Technology Investment Project, China [2019GK5061]
FX This work was partially supported by National Key Research and
   Development Program of China (No. 2018YFB1308604) , National Natural
   Science Foundation of China (No. 61672215, No. 61976086) , Hunan Science
   and Technology Innovation Project, China (No. 2017XK2102) , Hunan
   Innovation Technology Investment Project, China (No. 2019GK5061) .
CR [Anonymous], 2019, PROC INT C LEARN REP
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Cao Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102635
   Chen BY, 2018, LECT NOTES COMPUT SC, V11211, P328, DOI 10.1007/978-3-030-01234-2_20
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Everson, 2018, ABS180508511 CORR
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Fleuret, 2016, ARXIV161200604
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan LH, 2020, INT J NEUROSCI, V130, P857, DOI 10.1080/00207454.2019.1707822
   Lan L, 2018, IEEE T IMAGE PROCESS, V27, P4585, DOI 10.1109/TIP.2018.2843129
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu X, 2014, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2014.15
   Lukezic A, 2018, IEEE T CYBERNETICS, V48, P1849, DOI 10.1109/TCYB.2017.2716101
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2013, P ADV NEURAL INFORM
   Wang Q., 2017, ARXIV170404057
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou X., 2019, ABS190407850 ARXIV
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 64
TC 7
Z9 7
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103107
DI 10.1016/j.jvcir.2021.103107
EA APR 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700008
DA 2024-07-18
ER

PT J
AU Sahu, G
   Seal, A
   Krejcar, O
   Yazidi, A
AF Sahu, Geet
   Seal, Ayan
   Krejcar, Ondrej
   Yazidi, Anis
TI Single image dehazing using a new color channel
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Atmospheric light; Radiance; Illuminance scaling factor
ID VISIBILITY
AB Images with hazy scene suffer from low-contrast, which reduces the visible quality of the scene, thus making object detection a more challenging task. Low-contrast can result from foggy weather conditions during image acquisition. Dehazing is a process of removal of haze from the photography of a hazy scene. Single-image dehazing based on dark channel priors are well-known techniques in this field. However, the performance of such techniques is limited to priors or constraints. Moreover, this type of method fails when images have sky-region. So, a method is proposed, which can restore the visibility of hazy images. First, a hazy image is divided into blocks of size 32 x 32, then the score of each block is calculated to select a block having the highest score. Atmospheric light is calculated from the selected block. A new color channel is considered to remove atmospheric scattering, obtained channel value and atmospheric light are then used to calculate the transmission map in the second step. Third, radiance is computed using a transmission map and atmospheric light. The illumination scaling factor is adopted to enhance the quality of a dehazed image in the final step. Experiments are performed on six datasets namely, I-HAZE, O-HAZE, BSDS500, FRIDA, RESIDE dataset and natural images from Google. The proposed method is compared against 11 state-of-the-art methods. The performance is analyzed using fourteen quantitative evaluation metrics. All the results demonstrate that the proposed method outperforms 11 state-of-the-art methods in most of the cases.
C1 [Sahu, Geet; Seal, Ayan] PDPM Indian Inst Informat Technol, Design & Mfg, Jabalpur 482005, India.
   [Seal, Ayan; Krejcar, Ondrej] Univ Hradec Kralove, Ctr Basic & Appl Sci, Fac Informat & Management, Rokitanskeho 62, Hradec Kralove 50003, Czech Republic.
   [Krejcar, Ondrej] Univ Teknol Malaysia, Malaysia Japan Int Inst Technol MJIIT, Jalan Sultan Yahya Petra, Kuala Lumpur 54100, Malaysia.
   [Yazidi, Anis] Oslo Metropolitan Univ, Res Grp Appl Artificial Intelligence, N-460167 Oslo, Norway.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; University of Hradec Kralove; Universiti Teknologi Malaysia;
   Oslo Metropolitan University (OsloMet)
RP Seal, A (corresponding author), PDPM Indian Inst Informat Technol, Design & Mfg, Jabalpur 482005, India.
EM ayan@iiitdmj.ac.in
RI Krejcar, Ondrej/A-8639-2008; Seal, Ayan/AAI-1929-2020; Sahu,
   Geet/HHY-9855-2022
OI Krejcar, Ondrej/0000-0002-5992-2574; Seal, Ayan/0000-0002-9939-2926;
   SAHU, GEET/0000-0003-3772-307X
FU Computer Science and Engineering, PDPM Indian Institute of Information
   Technology, Design and Manufacturing, Jabalpur India [SPARC-MHRD-231];
   Grant Agency of Excellence, University of Hradec Kralove, Faculty of
   Informatics and Management, Czech Republic [2020/2204]; Universiti
   Teknologi Malaysia (UTM) under Research University Grant [Vot-20H04];
   Malaysia Research University Network (MRUN) [Vot 4L876]; Fundamental
   Research Grant Scheme (FRGS) under Ministry of Education Malaysia
   [Vot5F073]
FX This work is partially supported by the project "Prediction of diseases
   through computer assisted diagnosis system using images captured by
   minimally-invasive and non-invasive modalities'', Computer Science and
   Engineering, PDPM Indian Institute of Information Technology, Design and
   Manufacturing, Jabalpur India (under ID: SPARC-MHRD-231). This work is
   also partially supported by the project at (2020/2204), Grant Agency of
   Excellence, University of Hradec Kralove, Faculty of Informatics and
   Management, Czech Republic and by the project at Universiti Teknologi
   Malaysia (UTM) under Research University Grant Vot-20H04, Malaysia
   Research University Network (MRUN) Vot 4L876 and the Fundamental
   Research Grant Scheme (FRGS) Vot5F073 supported under Ministry of
   Education Malaysia for the completion of the research.
CR Al-Sammaraie MF, 2015, INT CONF COMP SCI ED, P95, DOI 10.1109/ICCSE.2015.7250224
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   [Anonymous], 2011, BERKELEY SEGMENTATIO
   [Anonymous], 2012, OPEN J APPL SCI
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen G, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 2, PROCEEDINGS, P53, DOI 10.1109/SNPD.2007.350
   Cheng YJ, 2013, IEEE SYS MAN CYBERN, P3627, DOI 10.1109/SMC.2013.618
   Ciaburro G., 2017, Neural Networks With R: Smart Models Using CNN, RNN, Deep Learning, and Artificial Intelligence Principles
   Du Q, 2007, IEEE GEOSCI REMOTE S, V4, P518, DOI 10.1109/LGRS.2007.896328
   Fang FM, 2014, SIAM J IMAGING SCI, V7, P969, DOI 10.1137/130919696
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Ge GY, 2015, OPTIK, V126, P3245, DOI 10.1016/j.ijleo.2015.07.138
   Gibson KB, 2012, IEEE T IMAGE PROCESS, V21, P662, DOI 10.1109/TIP.2011.2166968
   Gui B, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102792
   Guo F, 2020, NEUROCOMPUTING, V378, P9, DOI 10.1016/j.neucom.2019.09.094
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Hou Guojia, MULTIMEDIA TOOLS APP, P1
   [胡韦伟 Hu Weiwei], 2010, [工程图学学报, Journal of Engineering Graphics], V31, P104
   Huang SC, 2014, IEEE T CIRC SYST VID, V24, P1814, DOI 10.1109/TCSVT.2014.2317854
   Khmag A, 2018, VISUAL COMPUT, V34, P675, DOI 10.1007/s00371-017-1406-5
   Koschmieder H., 1924, Beitraege Phys. Atmosp., P33
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Li BY, 2018, AAAI CONF ARTIF INTE, P7016
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li YA, 2016, NEUROCOMPUTING, V182, P221, DOI 10.1016/j.neucom.2015.12.032
   Liu Q, 2017, SIGNAL PROCESS, V137, P33, DOI 10.1016/j.sigpro.2017.01.036
   Long J, 2012, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON COMPUTER VISION IN REMOTE SENSING, P132
   Luyan Tong, 2020, Artificial Intelligence and Security. 6th International Conference (ICAIS 2020). Proceedings. Lecture Notes in Computer Science (LNCS 12239), P339, DOI 10.1007/978-3-030-57884-8_30
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pang J., 2011, P APSIPA ASC, P1
   Panigrahy C, 2020, APPL OPTICS, V59, P5642, DOI 10.1364/AO.391234
   Panigrahy C, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106141
   Panigrahy C, 2020, IEEE SIGNAL PROC LET, V27, P690, DOI 10.1109/LSP.2020.2989054
   Pei YT, 2018, LECT NOTES COMPUT SC, V11214, P697, DOI 10.1007/978-3-030-01249-6_42
   Qi M, 2015, OPTIK, V126, P3400, DOI 10.1016/j.ijleo.2015.07.114
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   Sahu Geet, 2019, 2019 International Conference on Information Technology (ICIT), P388, DOI 10.1109/ICIT48102.2019.00075
   Salazar-Colores S, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0447-2
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Seal A, 2018, INT J NUMER METH BIO, V34, DOI 10.1002/cnm.2933
   Seal A, 2016, AEU-INT J ELECTRON C, V70, P1041, DOI 10.1016/j.aeue.2016.04.016
   Sengupta A, 2020, IEEE ACCESS, V8, P88385, DOI 10.1109/ACCESS.2020.2993607
   Shabna D., 2016, INT J INNOV RES SCI, V5
   Shu Ting, 2015, Jishou Daxue Xuebao (Ziran Kexue Ban), V36, P40, DOI 10.3969/j.issn.1007-2985.2015.01.010
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Sudhakar M., 2019, WIREL NETW, P1
   Tan ZM, 2014, FUJITSU SCI TECH J, V50, P60
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2010, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2010.5548128
   Wang Z, 2018, IET COMPUT VIS, V12, P393, DOI 10.1049/iet-cvi.2017.0318
   Xia P, 2016, OPTIK, V127, P7350, DOI 10.1016/j.ijleo.2016.05.071
   Xiao CX, 2012, VISUAL COMPUT, V28, P713, DOI 10.1007/s00371-012-0679-y
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2225, DOI 10.1109/ICACCI.2014.6968569
   Yan J., 2019, ARXIV PREPRINT ARXIV
   Yang J, 2017, ATMOS MEAS TECH, V10, P1191, DOI 10.5194/amt-10-1191-2017
   Yang Wanting, 2010, J COMPUT AIDED DES C, V6
   Yeh CH, 2013, OPT EXPRESS, V21, P27127, DOI 10.1364/OE.21.027127
   Zarges C., 2019, ARXIV PREPRINT ARXIV
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
   Zhao D, 2019, SIGNAL PROCESS-IMAGE, V74, P253, DOI 10.1016/j.image.2019.02.004
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu YY, 2018, NEUROCOMPUTING, V275, P499, DOI 10.1016/j.neucom.2017.08.055
   Zoran LF, 2009, UNIV POLIT BUCHAR S, V71, P37
NR 71
TC 32
Z9 33
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103008
DI 10.1016/j.jvcir.2020.103008
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500004
DA 2024-07-18
ER

PT J
AU Huang, JC
   Huang, HC
   Liu, HH
AF Huang, Jui-Chan
   Huang, Hao-Chen
   Liu, Hsin-Hung
TI Research on the parallelization of image quality analysis algorithm
   based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Image distortion; Image quality analysis; Parallelization
AB Image quality assessment is an indispensable in computer vision applications, such as image classification, image parsing. With the development of Internet, image data acquisition becomes more conveniently. However, image distortion is inevitable due to imperfect image acquisition system, image transmission medium and image recording equipment. Traditional image quality assessment algorithms only focus on low-level visual features such as color or texture, which could not encode high-level features effectively. CNN-based methods have shown satisfactory results in image quality assessment. However, existing methods have problems such as incomplete feature extraction, partial image block distortion, and inability to determine scores. So in this paper, we propose a novel framework for image quality assessment based on deep learning. We incorporate both low-level visual features and high-level semantic features to better describe images. And image quality is analyzed in a parallel processing mode. Experiments are conducted on LIVE and TID2008 datasets demonstrate the proposed model can predict the quality of the distorted image well, and both SROCC and PLCC can reach 0.92 or higher. (c) 2019 Elsevier Inc. All rights reserved.
C1 [Huang, Jui-Chan] Yango Univ, Fuzhou 350015, Peoples R China.
   [Huang, Hao-Chen] Natl Kaohsiung Univ Sci & Technol, Dept Publ Finance & Taxat, Kaohsiung 80778, Taiwan.
   [Liu, Hsin-Hung] Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 80778, Taiwan.
C3 National Kaohsiung University of Science & Technology; National
   Kaohsiung University of Science & Technology
RP Liu, HH (corresponding author), Natl Kaohsiung Univ Sci & Technol, Dept Int Business, Kaohsiung 80778, Taiwan.
EM haochen@nkust.edu.tw; kevinnana@yahoo.com
CR Alaql O, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P653, DOI [10.1109/CSCI.2016.128, 10.1109/CSCI.2016.0129]
   [Anonymous], 2016, ACTA MATH SIN ENGLIS, V32, P507, DOI [10.1007/s10114-016-5200-5, DOI 10.1007/S10114-016-5200-5]
   Bao JB, 2014, INTERNATIONAL CONFERENCE ON E-COMMERCE AND CONTEMPORARY ECONOMIC DEVELOPMENT (ECED 2014), P149
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Bianco S., 2017, Signal, Image and Video Processing, P1
   Chen Hui, 2018, J FRONTIERS COMPUT S, V12, P129
   [陈勇 Chen Yong], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P1645
   Cheng FC, 2018, WIRELESS PERS COMMUN, V102, P1917, DOI 10.1007/s11277-018-5246-z
   Corriveau P, 2000, P SOC PHOTO-OPT INS, V3959, P129, DOI 10.1117/12.387149
   Gao L, 2017, HUM EXP TOXICOL, V36, P395, DOI 10.1177/0960327116651121
   Gao M, 2015, APPL MATH COMPUT, V266, P429, DOI 10.1016/j.amc.2015.05.090
   Garmsiri N, 2017, CONTROL INTELL SYST, V45, P19, DOI 10.2316/Journal.201.2017.1.201-2766
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Kang Le, 2014, 2014 IEEE C COMP VIS, P1733
   Li Lin, 2016, J HUAZHONG U SCI TEC, V12, P75
   Li XL, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0358-7
   Liu F, 2016, B AUST MATH SOC, V94, P121, DOI 10.1017/S0004972715001392
   Liu Jian-lei, 2016, Optics and Precision Engineering, V24, P1176, DOI 10.3788/OPE.20162405.1176
   Lu Peng, 2018, APPL RES COMPUT, V35, P314
   Lv Y, 2015, 2015 IEEE INTERNATIONAL WIRELESS SYMPOSIUM (IWS 2015)
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pan C, 2017, IEEE INT CONF EMBED
   Paolini R, 2014, INT J ROBOT RES, V33, P600, DOI 10.1177/0278364913507756
   Ramos S, 2017, 2017 IEEE INT VEH S
   Ruderman D.L., 2010, NETWORK-COMP NEURAL, V5, P517
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tian Jinsha, 2016, Journal of Computer Applications, V36, P789, DOI 10.11772/j.issn.1001-9081.2016.03.789
   [王春峰 Wang Chunfeng], 2018, [中国科学院大学学报, Journal of University of Chinese Academy of Sciences], V35, P544
   Xiaobin Zhang, 2018, Procedia Computer Science, V131, P911, DOI 10.1016/j.procs.2018.04.221
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2010, IEEE T COMP INTEL AI, V2, P27, DOI 10.1109/TCIAIG.2010.2042449
   Yin Bao-cai, 2015, Journal of Beijing University of Technology, V41, P48, DOI 10.11936/bjutxb2014100026
   Zhang Junyang, 2018, APPL RES COMPUTERS, V35, P7
   Zhu PP, 2017, IEEE DECIS CONTR P
   Zhu Rui, 2017, COMPUT APPL SOFTWARE, V34, P175
NR 40
TC 2
Z9 2
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102709
DI 10.1016/j.jvcir.2019.102709
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900023
DA 2024-07-18
ER

PT J
AU Tang, W
   Wang, ZJ
   Zhai, JY
   Yang, ZJ
AF Tang, Wei
   Wang, Zhijian
   Zhai, Jiyou
   Yang, Zhangjing
TI Salient object detection via two-stage absorbing Markov chain based on
   background and foreground
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency object detection; Markov chain; Background absorbing;
   Foreground absorbing
ID RANDOM-WALKS; INTEGRATION; MODEL
AB This paper proposes a saliency detection method via two-stage absorbing Markov chain based on background and foreground for detecting salient objects in images. Firstly, image preprocessing is performed, followed by convex hull construction and superpixel segmentation, to prepare for subsequent processing. Secondly, according to the boundary connectivity, the superpixels with lower background probability value in the candidate boundary background set B-0 are deleted, and the boundary background set B-1 is obtained. With the saliency values of the nodes in the boundary-prior saliency map S-bg1, the background seeds are added appropriately in the region outside the candidate boundary background set B-0 and the convex hull H, and the background seed set B is obtained after update. Then, the background-absorbing Markov chain is constructed to generate background-absorbing saliency map S-bg2. By fusing the saliency maps S-bg1 and S-bg2, the first-stage background-based saliency map S-bg is obtained. Thirdly, in the range of the convex hull H, the foreground seed set F is determined according to the saliency map S-bg. Then, the foreground-absorbing Markov chain is constructed, to obtain the second-stage foreground-absorbing saliency map S-fg. Finally, the saliency maps S-bg and S-fg of the two stages are combined to obtain a fused saliency map S, and the final saliency map S* is obtained after optimization through smoothing mechanism. Compared with the traditional methods, the performance of the proposed method is significantly improved. The proposed method is tested on three public image datasets, and it shows great accuracy in detecting salient objects. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Tang, Wei; Wang, Zhijian] Hohai Univ, Coll Comp & Informat, Nanjing 211100, Peoples R China.
   [Tang, Wei; Yang, Zhangjing] Nanjing Audit Univ, Sch Informat Engn, Nanjing 211815, Peoples R China.
   [Zhai, Jiyou] Nanjing Inst Technol, Sch Comp Engn, Nanjing 211167, Peoples R China.
C3 Hohai University; Nanjing Audit University; Nanjing Institute of
   Technology
RP Tang, W (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing 211100, Peoples R China.
EM tangwei@nau.edu.cn
RI Wang, Ying/HJI-2509-2023; Liu, DY/JPL-4171-2023; wang,
   jian/HRB-9588-2023; Tang, Wei/IZQ-1283-2023; wang, tong/HTR-5412-2023;
   wang, jie/GRS-0942-2022; WANG, JINGYI/GSJ-1241-2022; wang,
   jie/HTQ-4920-2023
FU National Natural Science Foundation of China [U1831127]; Natural Science
   Foundation of Jiangsu Higher Education Institutions of China
   [16KJB520020]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. U1831127), the Natural Science Foundation of Jiangsu
   Higher Education Institutions of China (Grant No. 16KJB520020).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Gao V.M. D., 2007, NIPS, P497
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2009, PROC CVPR IEEE, P1698, DOI 10.1109/CVPRW.2009.5206767
   Han S, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P132, DOI 10.1109/DCC.2008.94
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin CC, 2014, NEUROCOMPUTING, V129, P378, DOI 10.1016/j.neucom.2013.09.021
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shehnaz M., 2015, P PICC, P1
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wang JW, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2522380
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 52
TC 3
Z9 3
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102727
DI 10.1016/j.jvcir.2019.102727
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900026
DA 2024-07-18
ER

PT J
AU Yang, JX
   Liao, X
AF Yang, Junxue
   Liao, Xin
TI An embedding strategy on fusing multiple image features for data hiding
   in multiple images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple images steganography; Embedding strategy; Multiple image
   features; Image complexity; Steganographic capacity
ID STEGANOGRAPHY; STEGANALYSIS
AB Data hiding in multiple images has been a significant research direction in information security. How to reasonably design the embedding strategy to spread the payload among multiple images is still an open issue. In this paper, we propose an embedding strategy on fusing multiple features. We utilize the typical characteristic parameters of gray level co-occurrence matrix, the image entropy and the shape parameter to describe image complexity. Furthermore, we combine with the number of cover images, the number of cover images assigned to steganographer and the size of cover image to estimate the steganographic capacity of each image. The strategy is implemented together with some state-of-the-art single image steganographic algorithms. Experimental results demonstrate that the security performance of the proposed strategy is higher than that of the state-of-the-art embedding strategy against the blind universal pooled steganalysis. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Yang, Junxue; Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Liao, Xin] Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
C3 Hunan University; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Liao, X (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.; Liao, X (corresponding author), Chinese Acad Sci, State Key Lab Informat Secur, Inst Informat Engn, Beijing 100093, Peoples R China.
EM xinliao@hnu.edu.cn
RI Liao, Xin/ITT-1021-2023; Liao, Xin/X-2736-2018
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578
FU National Natural Science Foundation of China [61972142, 61772191];
   National Hunan Provincial Natural Science Foundation of China
   [2020JJ4212]; CERNET Innovation Project [NGII20180412]; Open Project
   Program of National Laboratory of Pattern Recognition [201900017]
FX This work is supported by National Natural Science Foundation of China
   (Nos. 61972142, 61772191), National Hunan Provincial Natural Science
   Foundation of China (No. 2020JJ4212), CERNET Innovation Project (No.
   NGII20180412), Open Project Program of National Laboratory of Pattern
   Recognition (No. 201900017).
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2011, P 13 INF HID C PRAG
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Cogranne R, 2017, INT CONF ACOUST SPEE, P2122, DOI 10.1109/ICASSP.2017.7952531
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gretton A, 2006, Adv Neural Inf Process Syst, V19
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Ker A., 2008, P INT C SEC FOR STEG, P401
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker A.D., 2012, P INT C MED WAT SEC, P1
   Ker AD, 2012, P MULT SEC, P1
   Ker AD, 2007, LECT NOTES COMPUT SC, V4437, P265
   Ker AD, 2007, IEEE SIGNAL PROC LET, V14, P525, DOI 10.1109/LSP.2006.891319
   Ker AD, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P107, DOI 10.1145/1411328.1411349
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu QZ, 2008, INFORM SCIENCES, V178, P21, DOI 10.1016/j.ins.2007.08.007
   McCormick N, 2010, MATER TODAY, V13, P52, DOI 10.1016/S1369-7021(10)70235-2
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Wang Taiyue, 2006, CHINESE J ENG GEOPHY, V3, P172
   Wang Wei, 2015, Journal of Detection & Control, V37, P5
   Yang M, 2015, IEEE IMAGE PROC, P402, DOI 10.1109/ICIP.2015.7350829
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhao ZZ, 2017, LECT NOTES COMPUT SC, V10082, P494, DOI 10.1007/978-3-319-53465-7_37
NR 29
TC 10
Z9 10
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102822
DI 10.1016/j.jvcir.2020.102822
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400013
DA 2024-07-18
ER

PT J
AU Liu, X
   Li, YS
   Guo, TY
   Xia, RJ
AF Liu, Xing
   Li, Yanshan
   Guo, Tianyu
   Xia, Rongjie
TI Relative view based holistic-separate representations for two-person
   interaction recognition using multiple graph convolutional networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Activity analysis; Human interaction recognition; Skeleton data; Graph
   Convolution; Relative view
ID RETRIEVAL
AB In this paper, we focus on recognizing person-person interactions using skeletal data captured from depth sensors. First, we propose a novel and efficient view transformation scheme. The skeletal interaction sequence is re-observed under a new coordinate system, which is invariant to various setups and capturing views of depth cameras as well as the position or facing orientation exchange between two persons. Second, we propose concise and discriminative interaction representations simply composed of the joint locations from two persons. Proposed representations are efficient to describe both the holistic interactive scene and individual poses performed by each subject separately. Third, we introduce the graph convolutional networks(GCN) to directly learn proposed skeletal interaction representations. Moreover, we design a multiple GCN-based model to provide the final class score. Extensive experimental results on three skeletal action datasets NTU RGB+D 60, NTU RGB+D 120 and SBU consistently demonstrate the superiority of our interaction recognition method. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Liu, Xing; Li, Yanshan; Guo, Tianyu; Xia, Rongjie] Shenzhen Univ, ATR Natl Key Lab Def Technol, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Li, YS (corresponding author), Shenzhen Univ, ATR Natl Key Lab Def Technol, Shenzhen, Peoples R China.
EM lys@szu.edu.cn
OI Guo, Tianyu/0000-0001-5703-7064
FU National Natural Science Foundation of China [61771319, 61871154];
   Natural Science Foundation of Guangdong Province [2017A030313343,
   2019A1515011307]; Shenzhen Science and Technology Project
   [JCYJ20180507182259896]
FX This work was partially supported by National Natural Science Foundation
   of China (No. 61771319 and No. 61871154), Natural Science Foundation of
   Guangdong Province (No. 2017A030313343 and No. 2019A1515011307),
   Shenzhen Science and Technology Project (No. JCYJ20180507182259896).
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T CIRCUITS SYST
   Bibi S, 2018, COMPUT IND, V99, P282, DOI 10.1016/j.compind.2018.03.015
   Cho NG, 2017, NEUROCOMPUTING, V267, P169, DOI 10.1016/j.neucom.2017.06.009
   Hayes GR, 2011, ACM T COMPUT-HUM INT, V18, DOI 10.1145/1993060.1993065
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu T, 2019, MULTIMED TOOLS APPL, V78, P28715, DOI 10.1007/s11042-018-6074-6
   Ji YL, 2015, J VIS COMMUN IMAGE R, V33, P340, DOI 10.1016/j.jvcir.2015.10.001
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Li CL, 2018, AAAI CONF ARTIF INTE, P3482
   Li JJ, 2017, IET COMPUT VIS, V11, P560, DOI 10.1049/iet-cvi.2017.0025
   Li M, 2019, MULTIMED TOOLS APPL, V78, P5731, DOI 10.1007/s11042-018-5738-6
   Li M, 2016, IEEE T MULTIMEDIA, V18, P2293, DOI 10.1109/TMM.2016.2614228
   Li YS, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107293
   Liu BL, 2018, NEUROCOMPUTING, V318, P287, DOI 10.1016/j.neucom.2018.08.066
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2018, IEEE T PATTERN ANAL, V40, P3007, DOI 10.1109/TPAMI.2017.2771306
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Manzi A, 2018, IET COMPUT VIS, V12, P27, DOI 10.1049/iet-cvi.2017.0118
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Niepert M, 2016, PR MACH LEARN RES, V48
   Ramezani M, 2016, ARTIF INTELL REV, V46, P485, DOI 10.1007/s10462-016-9473-y
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Shu XB, 2021, IEEE T PATTERN ANAL, V43, P1110, DOI 10.1109/TPAMI.2019.2942030
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song Y., 2019, ARXIV 1905 06774
   Stergiou A., 2018, ARXIV 1808 00022
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Trabelsi R., ACM TRANS MULTIMEDIA, V1s
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wu HM, 2018, IEEE T HUM-MACH SYST, V48, P304, DOI 10.1109/THMS.2017.2776211
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yun K., 2012, 2012 IEEE COMP SOC C, P28, DOI DOI 10.1109/CVPRW.2012.6239234
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
NR 40
TC 5
Z9 5
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102833
DI 10.1016/j.jvcir.2020.102833
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900025
DA 2024-07-18
ER

PT J
AU Wu, YZ
   Xu, ZY
AF Wu, Yuzhe
   Xu, Zhiyi
TI Massive-scale visual information retrieval towards city residential
   environment surveillance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Satellite image; Land policy; Rough set; Fuzzy C-means clustering;
   Quantum ant colony algorithm
ID ANT COLONY OPTIMIZATION; CLUSTERING-ALGORITHM; CLASSIFICATION; NETWORK;
   IMAGERY
AB Urban residential environment surveillance plays an important role in modern intelligent city. Satellite images have been applied in various fields, and the analysis and processing of satellite images has become an important means to obtain the information perceived by satellites. This paper focuses on city residential environment surveillance based on massive-scale visual information retrieval. Since the shortcomings of low contrast, blurred boundary, large amount of information and susceptibility to noise, the performance of satellite image segmentation is not satisfactory, which will affect residential environment surveillance. We design an improved rough set fuzzy C-means clustering algorithm combined with ant colony algorithm. More specifically, satellite images are classified based on the gradient of pixels according to the indistinguishable relation of the image combined with rough set theory. Then, the traditional fuzzy set-based fuzzy C-means clustering algorithm is applied to the satellite image segmentation technology. Subsequently, the improved algorithm-quantum ant colony algorithm and rough set fuzzy clustering C-means algorithm are combined to achieve accurate segmentation of satellite images. Afterwards, we propose a satellite image retrieval algorithm, which can assist city residential environment surveillance. Comprehensive experiment show that our proposed method is effective and robust in residential environment surveillance. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wu, Yuzhe; Xu, Zhiyi] Zhejiang Univ, Sch Publ Affairs, Dept Land Management, Hangzhou 310058, Peoples R China.
C3 Zhejiang University
RP Xu, ZY (corresponding author), Zhejiang Univ, Sch Publ Affairs, Dept Land Management, Hangzhou 310058, Peoples R China.
EM xuzhiyi@zju.edu.cn
RI XU, Zee Z. Y./HSG-4674-2023
FU National Natural Science Foundation of China Urban Growth Boundary
   Management Strategy Guided by Agglomeration Development [71874155]
FX This study was funded by the National Natural Science Foundation of
   China Urban Growth Boundary Management Strategy Guided by Agglomeration
   Development: From the Perspective of Coupling of Intensiveness and
   Efficiency (No. 71874155).
CR Albanesi G., 2018, INT UROGYNECOL J, P1
   [Anonymous], 2018, IEEE T FUZZY SYST
   [Anonymous], 2018, IEEE T CYBERNETICS
   Cecilia JM, 2018, J PARALLEL DISTR COM, V113, P261, DOI 10.1016/j.jpdc.2017.12.002
   Chen CH, 2019, IEICE T INF SYST, VE102D, P1374, DOI 10.1587/transinf.2018EDP7299
   Chen CH, 2018, IEEE INTERNET THINGS, V5, P4231, DOI 10.1109/JIOT.2018.2863555
   Chen HX, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420580124
   Chen L, 2018, J APPL GEOPHYS, V152, P1, DOI 10.1016/j.jappgeo.2018.02.009
   Cheng D., 2018, SIGNAL IMAGE VIDEO P, V12, P1
   Chetih N, 2018, IET IMAGE PROCESS, V12, P652, DOI 10.1049/iet-ipr.2017.0399
   Das P, 2018, J MECH CONTIN MATH S, V13, P1, DOI 10.26782/jmcms.2018.12.00001
   Dong Z, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/6123874
   Fan JC, 2018, IEEE T FUZZY SYST, V26, P72, DOI 10.1109/TFUZZ.2016.2637373
   Feizollah A, 2018, ADV SCI LETT, V24, P929, DOI 10.1166/asl.2018.10660
   Goudarzi F, 2019, IEEE SYST J, V13, P571, DOI 10.1109/JSYST.2018.2806996
   Guo YH, 2018, MEASUREMENT, V119, P28, DOI 10.1016/j.measurement.2018.01.025
   Kukunda CB, 2018, INT J APPL EARTH OBS, V65, P12, DOI 10.1016/j.jag.2017.09.016
   Li CC, 2022, IEEE T AFFECT COMPUT, V13, P729, DOI 10.1109/TAFFC.2019.2954394
   Li CG, 2016, IEEE T VEH TECHNOL, V65, P6765, DOI 10.1109/TVT.2015.2472456
   Li ZN, 2018, ANAL METHODS ACCID R, V20, P1, DOI 10.1016/j.amar.2018.08.001
   Long QX, 2020, NAT MED, V26, P845, DOI 10.1038/s41591-020-0897-1
   Memon KH, 2017, IET IMAGE PROCESS, V11, P1, DOI 10.1049/iet-ipr.2016.0282
   Shamsudin H, 2018, ADV SCI LETT, V24, P1312, DOI 10.1166/asl.2018.10739
   Sharma S, 2018, INT J REMOTE SENS, V39, P2702, DOI 10.1080/01431161.2018.1430403
   Song YT, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719841295
   Subudhi S., 2018, VIETNAM J COMPUT SCI, P1
   Sumit SH, 2019, SOFT COMPUT, V23, P4329, DOI 10.1007/s00500-018-3086-0
   Wang D, 2019, J BIOPHARM STAT, V29, P98, DOI 10.1080/10543406.2018.1489410
   Wang JJ, 2020, APPL COMPUT HARMON A, V49, P831, DOI 10.1016/j.acha.2019.04.002
   Wisaeng K, 2018, SOFT COMPUT, V22, P2753, DOI 10.1007/s00500-017-2532-8
   Xu ML, 2021, IEEE T SYST MAN CY-S, V51, P1567, DOI 10.1109/TSMC.2019.2899047
   Xu ML, 2019, IEEE T MULTIMEDIA, V21, P1960, DOI 10.1109/TMM.2019.2891420
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2016, NEUROCOMPUTING, V195, P117, DOI 10.1016/j.neucom.2015.08.117
   Xue JX, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9654-6
   Zhang H, 2018, INT J REMOTE SENS, V39, P2207, DOI 10.1080/01431161.2017.1420934
   Zhu LJ, 2018, NEUROCOMPUTING, V315, P89, DOI 10.1016/j.neucom.2018.06.050
NR 38
TC 2
Z9 2
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102739
DI 10.1016/j.jvcir.2019.102739
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900003
DA 2024-07-18
ER

PT J
AU Jiang, M
   Li, C
   Kong, J
   Teng, ZD
   Zhuang, DF
AF Jiang, Min
   Li, Cong
   Kong, Jun
   Teng, Zhende
   Zhuang, Danfeng
TI Cross-level reinforced attention network for person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Features of different levels; Soft attention;
   Hard attention; Reinforced attention
AB Attention mechanism is a simple and effective method to enhance discriminative performance of person re-identification (Re-ID). Most of previous attention-based works have difficulty in eliminating the negative effects of meaningless information. In this paper, a universal module, named Cross-level Reinforced Attention (CLRA), is proposed to alleviate this issue. Firstly, we fuse features of different semantic levels using adaptive weights. The fused features, containing richer spatial and semantic information, can better guide the generation of subsequent attention module. Then, we combine hard and soft attention to improve the ability to extract important information in spatial and channel domains. Through the CLRA, the network can aggregate and propagate more discriminative semantic information. Finally, we integrate the CLRA with Harmonious Attention CNN (HA-CNN) and form a novel Cross-level Reinforced Attention CNN (CLRA-CNN) to optimize person Re-ID. Experiment results on several public benchmarks show that the proposed method achieves state-of-the-art performance. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Jiang, Min; Li, Cong; Kong, Jun; Teng, Zhende; Zhuang, Danfeng] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Jiang, M (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
EM minjiang@jiangnan.edu.cn
RI Zhuang, Danfeng/IST-2057-2023
OI Kong, Jun/0000-0003-2551-4748; Teng, Zhende/0000-0001-6020-2788
FU National Natural Science Foundation of China [61362030, 61201429,
   61876072]; China Postdoctoral Science Foundation [2015M581720,
   2016M600360]; Jiangsu Postdoctoral Science Foundation [1601216C];
   Scientific and Technological Aid Program of Xinjiang [2017E0279]
FX This work was partially supported by the National Natural Science
   Foundation of China (61362030, 61201429, 61876072), China Postdoctoral
   Science Foundation (2015M581720, 2016M600360), Jiangsu Postdoctoral
   Science Foundation (1601216C), Scientific and Technological Aid Program
   of Xinjiang (2017E0279).
CR [Anonymous], 2017, P BRIT MACH VIS C
   [Anonymous], 2017, ARXIV
   [Anonymous], 2016, ARXIV
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Chen YP, 2018, ADV NEUR IN, V31
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Jozefowicz Rafal, 2016, arXiv preprint arXiv:1602.02410
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Lo LJ, 2009, KIDNEY INT, V76, P893, DOI 10.1038/ki.2009.289
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4345
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu R., 2017, DIVIDE FUSE RERANKIN
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong WL, 2019, J VIS COMMUN IMAGE R, V62, P267, DOI 10.1016/j.jvcir.2019.06.001
NR 47
TC 6
Z9 6
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2020
VL 69
AR 102775
DI 10.1016/j.jvcir.2020.102775
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA LZ3UM
UT WOS:000541153600002
DA 2024-07-18
ER

EF