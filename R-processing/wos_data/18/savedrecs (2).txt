FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Wang, YH
   Peng, YL
   Liu, SG
   Li, J
   Wang, XL
AF Wang, Yuhong
   Peng, Yali
   Liu, Shigang
   Li, Jun
   Wang, Xili
TI Sparsity adaptive matching pursuit for face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Sparse representation; Matching pursuit
ID PRINCIPAL COMPONENT ANALYSIS; SIGNAL RECONSTRUCTION; REPRESENTATION
   METHOD; DICTIONARY; REGRESSION; ALGORITHM; MODEL; PCA
AB Sparse representation methods have exhibited promising performance for pattern recognition. However, these methods largely rely on the data sparsity available in advance and are usually sensitive to noise in the training samples. To solve these problems, this paper presents sparsity adaptive matching pursuit based sparse representation for face recognition (SAMPSR). This method adaptively explores the valid training samples that exactly represent the test via iterative updating. Next, the test samples are reconstructed via the valid training samples, and classification is performed subsequently. The two-phase strategy helps to improve the discriminating power of class probability distribution, and thus alleviates effect of the noise from the training samples to some extent and correctly performs classification. In addition, the method solves the sparse coefficient by comparing the residual between the test sample and the reconstructed sample instead of using the sparsity. A large number of experiments show that our method achieves promising performance. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wang, Yuhong; Peng, Yali; Liu, Shigang; Wang, Xili] Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.
   [Wang, Yuhong; Peng, Yali; Liu, Shigang; Wang, Xili] Engn Lab Teaching Informat Technol Shaanxi Prov, Xian 710119, Peoples R China.
   [Wang, Yuhong; Liu, Shigang; Wang, Xili] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
   [Li, Jun] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Peoples R China.
C3 Shaanxi Normal University; Nanjing Normal University
RP Peng, YL (corresponding author), Minist Educ, Key Lab Modern Teaching Technol, Xian 710062, Peoples R China.; Peng, YL (corresponding author), Engn Lab Teaching Informat Technol Shaanxi Prov, Xian 710119, Peoples R China.
EM wangyuhong@snnu.edu.cn; pengyl@snnu.edu.cn; shgliu@snnu.edu.cn;
   lijuncst@njnu.edu.cn; wangxili@snnu.edu.cn
RI Wang, Yu/GZL-9655-2022
FU National Key R&D Program of China [2017YFB1402102]; National Natural
   Science Foundation of China [61873155, 61672333, 61703096, 11772178];
   National Natural Science Foundation of Shaanxi Province, China
   [2018JM6050]; Transfer and Promotion Plan of Scientific and
   Technological Achievements of Shaanxi Province, China [2019CGXNG-019];
   Innovation Chain of Key Industries of Shaanxi Province, China
   [2019ZDLSF07-01]
FX This work is supported by the National Key R&D Program of China (No.
   2017YFB1402102), the National Natural Science Foundation of China (No.
   61873155, 61672333, 61703096, 11772178), the National Natural Science
   Foundation of Shaanxi Province, China (No. 2018JM6050), Transfer and
   Promotion Plan of Scientific and Technological Achievements of Shaanxi
   Province, China (No. 2019CGXNG-019), Innovation Chain of Key Industries
   of Shaanxi Province, China (No. 2019ZDLSF07-01).
CR An L, 2016, INFORM SCIENCES, V355, P74, DOI 10.1016/j.ins.2016.02.055
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], P ICPR
   [Anonymous], SPARSITY ADAPTIVE MA
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P4380, DOI 10.1109/TIP.2013.2273665
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Candes Emmanuel, 2004, MATH0410542 ARXIV
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Cheng H, 2013, SIGNAL PROCESS, V93, P1408, DOI 10.1016/j.sigpro.2012.09.011
   Dai W., 2008, SUBSPACE PURSUIT COM
   Debruyne M, 2010, ADV DATA ANAL CLASSI, V4, P151, DOI 10.1007/s11634-010-0068-1
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Goyal P, 2018, PROCEDIA COMPUT SCI, V125, P228, DOI 10.1016/j.procs.2017.12.031
   Han JQ, 2015, PATTERN RECOGN, V48, P3927, DOI 10.1016/j.patcog.2015.06.003
   He R., 2012, IEEE T NEURAL NETWOR, V24, P35
   Huang SY, 2009, NEURAL COMPUT, V21, P3179, DOI 10.1162/neco.2009.02-08-706
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kwak N, 2008, IEEE T PATTERN ANAL, V30, P1672, DOI 10.1109/TPAMI.2008.114
   Liu J., 2017, ADV MATER SCI ENG, V4, P1
   Liu SG, 2016, SIGNAL PROCESS, V124, P141, DOI 10.1016/j.sigpro.2015.09.033
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu XP, 2016, PR INT ASIA CONF IND, P177, DOI 10.2991/978-94-6239-145-1_18
   losifidis A., 2015, IEEE INT C IM PROC I, P2449
   Park S. W., 2010, EURASIP J ADV SIG PR, V2010, P6
   Peng YL, 2019, J COMPUT SCI-NETH, V33, P11, DOI 10.1016/j.jocs.2019.03.003
   Peng YL, 2019, NEUROCOMPUTING, V345, P67, DOI 10.1016/j.neucom.2018.12.075
   Peng YL, 2018, PATTERN RECOGN LETT, V116, P170, DOI 10.1016/j.patrec.2018.10.016
   Peng YL, 2018, IEEE ACCESS, V6, P488, DOI 10.1109/ACCESS.2017.2767907
   Peters J, 2017, ADAPT COMPUT MACH LE
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   Rao S, 2008, 2008 2ND ANNUAL IEEE SYSTEMS CONFERENCE, P1
   Tao DC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1287, DOI 10.1109/ICME.2004.1394460
   Wang Y.X., 2016, J. Mach. Learn. Res, V17, P320
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wen Y, 2012, DIGIT SIGNAL PROCESS, V22, P140, DOI 10.1016/j.dsp.2011.08.004
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2008, NEUROCOMPUTING, V71, P1857, DOI 10.1016/j.neucom.2007.09.021
   Xu Y, 2017, INFORM SCIENCES, V375, P171, DOI 10.1016/j.ins.2016.09.059
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Xu Y, 2013, NEUROCOMPUTING, V103, P164, DOI 10.1016/j.neucom.2012.08.038
   Xu Y, 2012, NEUROCOMPUTING, V79, P125, DOI 10.1016/j.neucom.2011.10.013
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu Y, 2010, OPT ENG, V49, DOI 10.1117/1.3359514
   Yang H., 2012, APPL RES COMPUT, V12, P87
   Yang JQ, 2011, 2011 INTERNATIONAL CONFERENCE ON APPLIED SOCIAL SCIENCE (ICASS 2011), VOL II, P1
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhu Q, 2013, NEURAL COMPUT APPL, V23, P169, DOI 10.1007/s00521-012-0851-3
NR 52
TC 5
Z9 6
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102764
DI 10.1016/j.jvcir.2020.102764
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800002
DA 2024-07-18
ER

PT J
AU Sharma, S
   Ravi, H
   Subramanyam, AV
   Emmanuel, S
AF Sharma, Shishir
   Ravi, Hareesh
   Subramanyam, A., V
   Emmanuel, Sabu
TI Anti-forensics of median filtering and contrast enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anti-forensics; Median filtering; Contrast enhancement; Huber Markov
   random field
ID IMAGE; TRACES
AB Digital images can be convincingly edited using image editing tools. In order to identify such image processing operations, various forensic techniques have been proposed. In response, anti-forensic operations designed as counter-measures have been devised. In this paper, we propose an anti-forensic technique to counter spatial domain forensic detectors and demonstrate its accuracy on popular image manipulation operations such as median filtering and contrast enhancement. The integrated anti-forensic attack is formulated as an optimization problem. The proposed optimization modifies the image so as to incorporate the median filtering or contrast enhancement operation while ensuring that its spatial characteristics do not change significantly. Through a series of experiments, we prove that the proposed algorithm can severely degrade the performance of median filtering and contrast enhancement detectors. The proposed algorithm also outperforms popular anti-forensic algorithms. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Sharma, Shishir] McGill Univ, Sch Comp Sci, Montreal, PQ, Canada.
   [Ravi, Hareesh] Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ USA.
   [Subramanyam, A., V] Indraprastha Inst Informat Technol, New Delhi, India.
   [Emmanuel, Sabu] Indian Inst Technol, Palakkad, Kerala, India.
C3 McGill University; Rutgers University System; Rutgers University New
   Brunswick; Indraprastha Institute of Information Technology Delhi;
   Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Palakkad
RP Subramanyam, AV (corresponding author), Indraprastha Inst Informat Technol, New Delhi, India.
EM subramanyam@iiitd.ac.in
OI Ravi, Hareesh/0000-0002-3237-1899
CR [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 1995, Markov random field modeling in computer vision
   Bahrami Khosro, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2654, DOI 10.1109/ICASSP.2014.6854081
   Barni M, 2018, IEEE IMAGE PROC, P3803, DOI 10.1109/ICIP.2018.8451698
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Cao G, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-4928-0
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao G, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P25
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Comesaña-Alfaro P, 2013, INT CONF ACOUST SPEE, P3048, DOI 10.1109/ICASSP.2013.6638218
   Dang-Nguyen DT, 2013, IEEE INT WORKSH MULT, P260, DOI 10.1109/MMSP.2013.6659298
   De Rosa A, 2015, IEEE SIGNAL PROC LET, V22, P1132, DOI 10.1109/LSP.2015.2389241
   Ding F, 2018, J VIS COMMUN IMAGE R, V50, P93, DOI 10.1016/j.jvcir.2017.11.009
   Fan W, 2015, IEEE T INF FOREN SEC, V10, P1076, DOI 10.1109/TIFS.2015.2398362
   Ferreira A, 2016, INTELL DATA ANAL, V20, pS17, DOI 10.3233/IDA-160843
   Fontani M, 2012, EUR SIGNAL PR CONF, P1239
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Gallagher AC, 2008, PROC CVPR IEEE, P253
   He H, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P933
   Henderson D, 2003, INT SER OPER RES MAN, V57, P287, DOI 10.1007/0-306-48056-5_10
   Kang XG, 2015, 2015 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING, P483, DOI 10.1109/ChinaSIP.2015.7230449
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kao YT, 2012, IEEE T IMAGE PROCESS, V21, P3443, DOI 10.1109/TIP.2012.2191562
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P1471, DOI 10.1109/TIP.2015.2405477
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li S. Z., 2009, Markov random field modeling in image analysis
   Lin XF, 2013, IEEE IMAGE PROC, P4467, DOI 10.1109/ICIP.2013.6738920
   Milani S, 2012, INT CONF ACOUST SPEE, P2253, DOI 10.1109/ICASSP.2012.6288362
   Ravi H, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2857069
   Ravi H, 2016, IEEE SIGNAL PROC LET, V23, P212, DOI 10.1109/LSP.2015.2509477
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   Roth S, 2005, PROC CVPR IEEE, P860
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shan WY, 2019, SIGNAL PROCESS-IMAGE, V71, P138, DOI 10.1016/j.image.2018.11.011
   Snyder CL, 2014, POLYMER PRODUCTS AND CHEMICAL PROCESSES: TECHNIQUES, ANALYSIS, AND APPLICATIONS, P165
   Sun JY, 2018, SIGNAL PROCESS-IMAGE, V63, P149, DOI 10.1016/j.image.2018.02.001
   Tian-Tsong Ng, 2005, 13th Annual ACM International Conference on Multimedia, P239
   Wang P, 2018, J VIS COMMUN IMAGE R, V55, P80, DOI 10.1016/j.jvcir.2018.05.020
   Wilson EB, 1927, J AM STAT ASSOC, V22, P209, DOI 10.2307/2276774
   Wu ZH, 2013, INT CONF ACOUST SPEE, P3043, DOI 10.1109/ICASSP.2013.6638217
   Yang JQ, 2015, DIGIT SIGNAL PROCESS, V41, P90, DOI 10.1016/j.dsp.2015.03.014
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
NR 48
TC 5
Z9 5
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102682
DI 10.1016/j.jvcir.2019.102682
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200001
DA 2024-07-18
ER

PT J
AU Kim, W
AF Kim, Wonjun
TI Multiple object tracking in soccer videos using topographic surface
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple object tracking; Topographic surface; Color similarity; Spatial
   proximity
ID VISUAL TRACKING; PLAYERS; FILTER; MODEL
AB Multiple object tracking is still a challenging problem in computer vision even though there have been several attempts lately to resolve the tracking problem in the framework of deep neural networks. In this paper, a novel method for multiple object tracking in soccer videos, which often contain complicated interactions between players with severe occlusions, is introduced. To do this, we propose to interpret the extracted foreground regions in a given frame as the topographic surface. This gives a great help to reliably chase target players by accurately providing the boundary lines of each object even with occlusions. Color similarity and spatial proximity are subsequently employed to refine the estimated position of target players for continuous tracking over whole video sequences. Experimental results on various soccer videos, which are taken of the actual games with the wide-angle camera, demonstrate that the proposed method is effective for tracking multiple players in the dynamic scene of the soccer video. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Kim, Wonjun] Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University
RP Kim, W (corresponding author), Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
EM wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research & Development
   Program [R2016030044]
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2016 (R2016030044,
   Development of Context-Based Sport Video Analysis, Summarization, and
   Retrieval Technologies).
CR [Anonymous], 2016, CVPR
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Baysal S, 2016, IEEE T CIRC SYST VID, V26, P1350, DOI 10.1109/TCSVT.2015.2455713
   Ben Shitrit H, 2014, IEEE T PATTERN ANAL, V36, P1614, DOI 10.1109/TPAMI.2013.210
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen L, 2009, IEEE IMAGE PROC, P4033, DOI 10.1109/ICIP.2009.5413757
   Cheng JR, 2009, IEEE T BIO-MED ENG, V56, P741, DOI 10.1109/TBME.2008.2008635
   D'Orazio T, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P559, DOI 10.1109/AVSS.2009.69
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Feris RS, 2012, IEEE T MULTIMEDIA, V14, P28, DOI 10.1109/TMM.2011.2170666
   Gao XZ, 2009, IN C IND ENG ENG MAN, P2295, DOI 10.1109/IEEM.2009.5373040
   Gonzalex R.C., 2002, DIGIAL IMAGE PROCESS
   Grabner H., 2006, BMVC, P47
   Hartley R. I., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P471
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Kim W, 2017, IEEE ACCESS, V5, P27453, DOI 10.1109/ACCESS.2017.2775040
   Kimmel R, 1996, J MATH IMAGING VIS, V6, P223, DOI 10.1007/BF00119840
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Kwon J, 2017, ELECTRON LETT, V53, P1358, DOI 10.1049/el.2017.2129
   Lee SH, 2018, IEEE ACCESS, V6, P67316, DOI 10.1109/ACCESS.2018.2879535
   Li X, 2012, INT CONF CLOUD COMPU, P985, DOI 10.1109/CCIS.2012.6664324
   Liu J, 2009, PATTERN RECOGN LETT, V30, P103, DOI 10.1016/j.patrec.2008.02.011
   Liu JC, 2013, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2013.239
   Lu WL, 2013, IEEE T PATTERN ANAL, V35, P1704, DOI 10.1109/TPAMI.2012.242
   Moon S, 2018, INT CONF ADV COMMUN, P460, DOI 10.23919/ICACT.2018.8323794
   Seo JH, 2018, 2018 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P3
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   Yang XD, 2006, IEEE T CIRCUITS-I, V53, P2405, DOI 10.1109/TCSI.2006.884469
   Yu WS, 2014, IET COMPUT VIS, V8, P588, DOI 10.1049/iet-cvi.2013.0250
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 36
TC 9
Z9 10
U1 3
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102683
DI 10.1016/j.jvcir.2019.102683
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700026
DA 2024-07-18
ER

PT J
AU Helbert, D
   Malek, M
   Bourdon, P
   Carré, P
AF Helbert, David
   Malek, Mohamed
   Bourdon, Pascal
   Carre, Philippe
TI Patch graph-based wavelet inpainting for color images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Inpainting; Color image
ID REGULARIZATION
AB We propose a novel inpainting process for color images. Our algorithm is based on the graph-based wavelet regularization and the non-local mean approach. At each step damaged structures are estimated by computing a graph of patches and applying a regularization model using a wavelet transform on graphs. Our approach uses color information of the image to reconstruct missing data according to local geometry. We show that the graph can be used to model geometry information in the frame of inpainting and to merge candidate pixels from a graph-based wavelet regularization. We provide details on numerical approaches and the results highlight an improvement of the geometrical information reconstruction of color images. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Helbert, David; Bourdon, Pascal; Carre, Philippe] Univ Poitiers, XLIM, CNRS, UMR 7252, F-86000 Poitiers, France.
   [Malek, Mohamed] ENSTA Bretagne, IT Dept, 2 Rue Francois Verny, F-29806 Brest, France.
C3 Universite de Poitiers; Centre National de la Recherche Scientifique
   (CNRS); CNRS - Institute for Engineering & Systems Sciences (INSIS);
   ENSTA Bretagne
RP Helbert, D (corresponding author), Univ Poitiers, XLIM, CNRS, UMR 7252, F-86000 Poitiers, France.
EM david.helbert@xlim.fr
OI Helbert, David/0000-0001-6518-1509
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   Ballester C, 2007, IEEE T IMAGE PROCESS, V16, P2476, DOI 10.1109/TIP.2007.903844
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chen SH, 2015, IEEE T SIGNAL PROCES, V63, P4609, DOI 10.1109/TSP.2015.2441042
   Chung F. R. K., 1997, AM MATH SOC, V92, DOI DOI 10.1090/CBMS/092
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   d'Angelo E, 2010, IEEE IMAGE PROC, P417, DOI 10.1109/ICIP.2010.5653412
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Daubechies I, 2004, COMMUN PUR APPL MATH, V57, P1413, DOI 10.1002/cpa.20042
   Ding D, 2019, IEEE T IMAGE PROCESS, V28, P1705, DOI 10.1109/TIP.2018.2880681
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Gadde A, 2013, IEEE IMAGE PROC, P1222, DOI 10.1109/ICIP.2013.6738252
   Ghoniem M, 2010, SIGNAL PROCESS, V90, P2445, DOI 10.1016/j.sigpro.2009.09.004
   Grady L, 2008, LECT NOTES COMPUT SC, V5241, P153, DOI 10.1007/978-3-540-85988-8_19
   Guillemot C, 2014, IEEE SIGNAL PROC MAG, V31, P127, DOI 10.1109/MSP.2013.2273004
   Hammond D.K., 2012, IMAGE PROCESSING ANA
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Jost F., 2019, ARXIV190612263
   Lezoray O, 2007, COMPUT VIS IMAGE UND, V107, P38, DOI 10.1016/j.cviu.2006.11.015
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   Malek M, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.053004
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Qin C, 2019, IEEE T CIRC SYST VID, V29, P3341, DOI 10.1109/TCSVT.2018.2878026
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Spielman D, 2012, CH CRC COMP SCI SER, P495
   Ulyanov D, 2018, PROC CVPR IEEE, P9446, DOI 10.1109/CVPR.2018.00984
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang S, 2018, IEEE T INF FOREN SEC, V13, P637, DOI 10.1109/TIFS.2017.2763119
NR 33
TC 3
Z9 3
U1 2
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102614
DI 10.1016/j.jvcir.2019.102614
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600015
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, LM
   Zhang, RX
   Jeng, TS
   Zeng, ZY
AF Zhang, Le-Min
   Zhang, Ruo-Xi
   Jeng, Tay-Sheng
   Zeng, Zi-Yuan
TI Cityscape protection using VR and eye tracking technology
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Urban renewal; Three-dimensional eye tracking; Cityscape feature
   identification; Human-oriented; Smart city
AB The traditional method for reconstructing cityscape relies greatly on the subjective judgment of designers, which makes the cityscape simple and homogenized. This paper aims to propose a new integrated approach to protect and design cityscape based on virtual reality (VR) and eye tracking technology. Through the integration and quantification of the eye tracking data and the protocol analysis data in the VR environment, this research has revealed the mechanism of identifying the cityscape features, and discovered the differences in the perception of the cityscape features by different people, thus proposing the multi-cultural integrated strategy for protecting cityscape. This research is of great significance for building a human-oriented scientific planning and protection method and promoting the application of cutting-edge digital technology in the field of smart city governance. (C) 2019 Published by Elsevier Inc.
C1 [Zhang, Le-Min; Zhang, Ruo-Xi] Xiamen Univ, Sch Architecture & Civil Engn, Xiamen, Fujian, Peoples R China.
   [Zhang, Le-Min; Jeng, Tay-Sheng] Natl Cheng Kung Univ, Dept Architecture, Tainan, Taiwan.
   [Zeng, Zi-Yuan] Zhihuijia Tech Co Ltd, Xiamen, Fujian, Peoples R China.
C3 Xiamen University; National Cheng Kung University
RP Zhang, LM (corresponding author), Xiamen Univ, Sch Architecture & Civil Engn, Xiamen, Fujian, Peoples R China.
EM zlmzj@126.com; zhangruoxi@xmu.edu.cn; tsjeng@mail.ncku.edu.tw;
   zengziyuan@zhjvr.com
FU Young Scientists Fund of the National Natural Science Foundation of
   China [51808472]
FX This research is supported by the Young Scientists Fund of the National
   Natural Science Foundation of China (Grant No. 51808472). The authors
   would like to thank Prof. Sheng-Fen Chien in National Cheng Kung
   University for her assistance, suggestion, and discussions.
CR Besharse J., 2011, The retina and its disorders
   Dupont L, 2014, LANDSCAPE RES, V39, P417, DOI 10.1080/01426397.2013.773966
   Fukuda T, 2013, ECAADE 2013: COMPUTATION AND PERFORMANCE, VOL 1, P219
   [郭素玲 Guo Suling], 2017, [资源科学, Resources Science], V39, P1137
   Han D.-I.D., 2019, VIRTUAL AUGMENTED RE, P113
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Jie Zhang, 2003, URBAN PLAN, V27, P40
   Kiefer P, 2017, SPAT COGN COMPUT, V17, P1, DOI 10.1080/13875868.2016.1254634
   Kuo C., 2008, J ARCHITECTURE, P145
   Lefebvre H., 1991, PRODUCTION SPACE
   Lynch K., 1960, IMAGE CITY
   Mantuano A, 2017, CASE STUD TRANSP POL, V5, P408, DOI 10.1016/j.cstp.2016.06.001
   Mokas I., 2019, VALUATION URBAN GREE
   Motamedi A, 2017, ADV ENG INFORM, V32, P248, DOI 10.1016/j.aei.2017.03.005
   Pfeiffer J., 2017, J BUSINESS RES
   Qing Chang, 2000, TIME ARCHITECTURE, V03, P25
   Schrom-Feiertag H, 2017, SPAT COGN COMPUT, V17, P163, DOI 10.1080/13875868.2016.1228654
   Schwarzkopf S., 2013, EY TRACK SPAT RES P
   Wang Shao-Sen, 2016, SO ARCHITECTURE, V176, P75
   Zhang L, 2018, CAADRIA 2018 23 INT
   Zhang Le-Min, 2015, URBAN ARCHITECTURE, V20, P12
NR 21
TC 25
Z9 26
U1 9
U2 85
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102639
DI 10.1016/j.jvcir.2019.102639
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600032
DA 2024-07-18
ER

PT J
AU Xu, ML
   Zhai, YF
   Guo, YB
   Lv, P
   Li, YF
   Wang, M
   Zhou, B
AF Xu, Mingliang
   Zhai, Yafang
   Guo, Yibo
   Lv, Pei
   Li, Yafei
   Wang, Meng
   Zhou, Bing
TI Personalized training through Kinect-based games for physical education
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kinect; Educational games
ID SIMULATION; MODEL
AB In recent years, the Kinect-based systems that enable users to be trained without the participation of teachers have been widely used in the field of physical education. In this paper, we propose a novel technique that helps the Kinect-based training system to select the subsequential training material for the users according to their realtime performance. An algorithm based on the Hidden Markov Model is demonstrated to generate the customized training pathes(training curriculums) for each individual. We present an edutainment gaming system for children in order to illustrate the feasibility of the training method. A user study of 10 children participants is conducted and the results show that the proposed technique enhances the effect of physical training significantly. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Xu, Mingliang; Zhai, Yafang; Guo, Yibo; Lv, Pei; Li, Yafei; Zhou, Bing] Zhengzhou Univ, Ctr Interdisciplinary Infromat Sci, Zhengzhou, Henan, Peoples R China.
   [Wang, Meng] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Zhengzhou University; Hefei University of Technology
RP Guo, YB (corresponding author), Zhengzhou Univ, Ctr Interdisciplinary Infromat Sci, Zhengzhou, Henan, Peoples R China.
EM ieybguo@zzu.edu.cn
RI Pan, Yue/KFS-4602-2024
FU National Natural Science Foundation of China [61602421]; China
   Postdoctoral Science Foundation [2016M600584]
FX This work was supported by the National Natural Science Foundation of
   China [Grant No. 61602421] and the China Postdoctoral Science Foundation
   [Grant No. 2016M600584].
CR Aditya K., 2018, 2018 IEEE International Conference on System, Computation, Automation and Networking, ICSCA 2018, P1, DOI [10.1109/ICSCAN.2018.8541163, DOI 10.1109/ICSCAN.2018.8541163]
   Anderson F., 2013, P 26 ANN ACM S US IN, P311, DOI [DOI 10.1145/2501988.2502045, 10.1145/2501988.2502045]
   [Anonymous], 2012, Tech. Rep. MSR-TR-2012-68
   [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], 2011, COMPUTER ANIMATION A
   Berg Tamara, 2012, P C SOC EL MUS US
   Bingbing Ni, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1147, DOI 10.1109/ICCVW.2011.6130379
   Burnik U, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P1229, DOI 10.1109/UKRCON.2017.8100449
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Charsky D, 2010, GAMES CULT, V5, P177, DOI 10.1177/1555412009354727
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   de Greef K., 2013, Games for Health, P197, DOI [10.1007/978-3-658-02897-8_15, DOI 10.1007/978-3-658-02897-8_15]
   Dehkordi Sara Reisi, 2018, INT J ENG TECHNOL UA, V7, P19, DOI DOI 10.14419/IJET.V7I3.15.17399
   Dias JR, 2019, INT J TECHNOL HUM IN, V15, P11, DOI 10.4018/IJTHI.2019040102
   DiGiovanna Emily, 2017, CANC THERAPY ONCOL I, V8
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Gallo L, 2011, COMP MED SY, DOI 10.1109/CBMS.2011.5999138
   Ge ZG, 2017, GAMING MEDIA SOC EFF, P113, DOI 10.1007/978-981-10-0861-0_8
   Han Jiawei, 2015, IEEE INT C SOFTW ENG
   Hollan J., 2000, ACM Transactions on Computer-Human Interaction, V7, P174, DOI 10.1145/353485.353487
   Huang JD, 2011, ASSETS 11: PROCEEDINGS OF THE 13TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P319
   HUTCHINS E, 1995, COGNITIVE SCI, V19, P265, DOI 10.1016/0364-0213(95)90020-9
   Ikram Aamrah, 2018, CHIN C IM GRAPH TECH, P635
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Koehn S, 2013, EUR J SPORT SCI, V13, P543, DOI 10.1080/17461391.2012.746731
   Lange B, 2011, IEEE ENG MED BIO, P1831, DOI 10.1109/IEMBS.2011.6090521
   Lee GC, 2016, MULTIMED TOOLS APPL, V75, P261, DOI 10.1007/s11042-014-2290-x
   Li BYL, 2016, NEUROCOMPUTING, V214, P93, DOI 10.1016/j.neucom.2016.06.012
   Lu X, 2013, INT J COMPUTER GAMES, V2013, P1
   Lun Roanna, 2019, Consumer-Driven Technologies in Healthcare IGI Global, P445
   Mao TL, 2015, COMPUT ANIMAT VIRT W, V26, P397, DOI 10.1002/cav.1642
   Mayer RE, 2002, EDUC PSYCHOL REV, V14, P87, DOI 10.1023/A:1013184611077
   Mingliang Xu., 2019, TIST, V10, P1
   Mun Ho Jeong, 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P132
   Shotton Jamie., 2011, Computer Vision and Pattern Recognition (CVPR)
   Smisek J., 2013, 3D with Kinect Consumer Depth Cameras for Computer Vision, P3, DOI [DOI 10.1007/978-1-4471-4640-7_1, 10.1007/978-1-4471-4640-7-1, DOI 10.1007/978-1-4471-4640-7-1]
   Trajkova Milka, 2015, USABILITY EVALUATION
   Vasiliou C, 2014, COMPUT HUM BEHAV, V41, P544, DOI 10.1016/j.chb.2014.09.057
   Villacis Cesar, 2014, 2014 IEEE/ACM 18th International Symposium on Distributed Simulation and Real Time Applications (DS-RT). Proceedings, P129, DOI 10.1109/DS-RT.2014.24
   Wang Hu.a., 2017, COMPUT GRAPH, V70
   Wang Hua, 2017, Journal of Computer Aided Design & Computer Graphics, V29, P211
   Wang Hua, 2014, Journal of Computer Aided Design & Computer Graphics, V26, P1818
   Wang H, 2014, COMPUT ANIMAT VIRT W, V25, P385, DOI 10.1002/cav.1576
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Xu ML, 2013, IEEE MULTIMEDIA, V20, P49, DOI 10.1109/MMUL.2012.54
   Yükseltürk E, 2018, EDUC TECHNOL SOC, V21, P159
NR 47
TC 12
Z9 12
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 394
EP 401
DI 10.1016/j.jvcir.2019.05.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA IL0CB
UT WOS:000476962600036
DA 2024-07-18
ER

PT J
AU Cai, H
   Li, LD
   Yi, ZL
   Gong, ML
AF Cai, Hao
   Li, Leida
   Yi, Zili
   Gong, Minglun
TI Blind quality assessment of gamut-mapped images via local and global
   statistical analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Gamut mapping; Natural scene statistics
AB Gamut mapping is a key technology to achieve high-quality cross-media color reproduction. To optimize a gamut mapping algorithm, an important step is to conduct an accurate evaluation of its psycho-visual performance. This paper presents an objective blind image quality assessment (BIQA) metric for gamut mapped images based on natural scene statistics. Considering both the local and global aspects of distortions in gamut-mapped images, two categories of statistics are analyzed. Specifically, the local statistical features are used to portray structural and color distortions and features extracted from global statistics are utilized to characterize the naturalness of image. The proposed metric does not need ground truth quality scores for training, thus it is "completely" blind. Experimental results on three gamut mapping databases demonstrate that our method outperforms the state-of-the-art general-purpose BIQA models. To further validate its effectiveness, the proposed metric is applied for benchmarking GMAs as an application and achieves encouraging performance. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Cai, Hao; Yi, Zili; Gong, Minglun] Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
   [Li, Leida] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
C3 Memorial University Newfoundland; Xidian University
RP Cai, H (corresponding author), Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1B 3X5, Canada.
EM hc1864@mun.ca
RI Cai, Hao/HPH-5544-2023; Li, Li/AEM-3636-2022; Zili, Yi/AAS-7855-2020;
   Gong, Minglun/AAU-3103-2020; li, li/HII-4157-2022
OI Zili, Yi/0000-0003-4854-2725; Gong, Minglun/0000-0001-5820-5381; 
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   National Natural Science Foundation of China [61771473, 61379143]
FX The authors would like to thank Dr. Joachim Giesen from
   Friedrich-Schiller-Universitat Jena and Dr. Peter Zolliker from EMPA for
   clarifying on the gamut mapping databases. This work was supported in
   part by the Natural Sciences and Engineering Research Council of Canada
   (NSERC), in part by the National Natural Science Foundation of China
   (Grant Nos. 61771473, 61379143).
CR [Anonymous], 2015, J INF HIDING MULTIME
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], 2008, Color Gamut Mapping
   [Anonymous], 2014, ICLR
   Bando E, 2005, PROC SPIE, V5666, P180, DOI 10.1117/12.587641
   Baranczuk Z, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.3.030201
   Braun GJ, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P167
   Cadík M, 2005, NINTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P920, DOI 10.1109/IV.2005.126
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dijk J., 2004, THESIS
   Fairchild MD, 2004, J ELECTRON IMAGING, V13, P126, DOI 10.1117/1.1635368
   Gabarda S, 2018, J VIS COMMUN IMAGE R, V52, P101, DOI 10.1016/j.jvcir.2018.02.008
   Giesen J, 2007, IEEE T IMAGE PROCESS, V16, P2401, DOI 10.1109/TIP.2007.904455
   Gong YH, 2015, LECT NOTES COMPUT SC, V9009, P47, DOI 10.1007/978-3-319-16631-5_4
   Gong YH, 2013, IEEE IMAGE PROC, P534, DOI 10.1109/ICIP.2013.6738110
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Hardeberg JY, 2008, COLOR TECHNOL, V124, P243, DOI 10.1111/j.1478-4408.2008.00148.x
   Kuo W. G., 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P261, DOI 10.1109/CSSE.2008.1320
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Li LD, 2017, IEEE ACCESS, V5, P2163, DOI 10.1109/ACCESS.2017.2661858
   Li LD, 2016, IEEE T IMAGE PROCESS, V25, P3775, DOI 10.1109/TIP.2016.2577891
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Lissner I, 2013, IEEE T IMAGE PROCESS, V22, P435, DOI 10.1109/TIP.2012.2216279
   Lissner I, 2012, IEEE T IMAGE PROCESS, V21, P1153, DOI 10.1109/TIP.2011.2163522
   Liu YX, 2014, J VIS COMMUN IMAGE R, V25, P1006, DOI 10.1016/j.jvcir.2014.02.018
   Liu Z, 2018, J VIS COMMUN IMAGE R, V52, P159, DOI 10.1016/j.jvcir.2018.02.011
   Millen BA, 2001, J ELECTRON IMAGING, V10, P399, DOI 10.1117/1.1350560
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Montag ED, 1997, IEEE T IMAGE PROCESS, V6, P977, DOI 10.1109/83.597273
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Morovic J., 2003, 153 CIE, V153
   Preiss Jens, 2015, THESIS
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Tang LJ, 2017, J VIS COMMUN IMAGE R, V49, P204, DOI 10.1016/j.jvcir.2017.09.010
   Taplin LA, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P348
   Thurstone LL, 1927, PSYCHOL REV, V34, P273, DOI 10.1037/h0070288
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang X., 1997, Journal of the Society for Information Display, V5, P61, DOI 10.1889/1.1985127
   Zhang Y, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043025
   Zhou Y, 2018, J VIS COMMUN IMAGE R, V55, P30, DOI 10.1016/j.jvcir.2018.05.023
   Zolliker P, 2007, IEEE T IMAGE PROCESS, V16, P664, DOI 10.1109/TIP.2006.891346
   Zolliker P, 2010, IEEE T IMAGE PROCESS, V19, P758, DOI 10.1109/TIP.2009.2038833
   2009, 17 COL IM C COL SCI, P21
   2015, IEICE T INF SYST, V98, P1613, DOI DOI 10.1587/TRANSINF.2015EDL8041
NR 56
TC 4
Z9 5
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 250
EP 259
DI 10.1016/j.jvcir.2019.04.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100026
DA 2024-07-18
ER

PT J
AU Chen, LQ
   Wang, P
   Dong, H
   Shi, F
   Han, J
   Guo, YK
   Childs, PRN
   Xiao, J
   Wu, C
AF Chen, Liuqing
   Wang, Pan
   Dong, Hao
   Shi, Feng
   Han, Ji
   Guo, Yike
   Childs, Peter R. N.
   Xiao, Jun
   Wu, Chao
TI An artificial intelligence based data-driven approach for design
   ideation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Idea generation; Artificial intelligence in design; Data-driven design;
   Generative adversarial networks; Semantic network analysis; Network
   visualisation; Computational creativity
ID LOW-RANK; CREATIVITY; FRAMEWORK
AB Ideation is a source of innovation and creativity, and is commonly used in early stages of engineering design processes. This paper proposes an integrated approach for enhancing design ideation by applying artificial intelligence and data mining techniques. This approach consists of two models, a semantic ideation network and a visual concepts combination model, which provide inspiration semantically and visually based on computational creativity theory. The semantic ideation network aims to provoke new ideas by mining potential knowledge connections across multiple knowledge domains, and this was achieved by applying "step-forward" and "path-track" algorithms which assist in exploring forward given a concept and in tracking back the paths going from a departure concept through a destination concept. In the visual concepts combination model, a generative adversarial networks model is proposed for generating images which synthesize two distinct concepts. An implementation of these two models was developed and tested in a design case study, which indicated that the proposed approach is able to not only generate a variety of cross-domain concept associations but also advance the ideation process quickly and easily in terms of quantity and novelty. (C) 2019 Published by Elsevier Inc.
C1 [Chen, Liuqing; Shi, Feng; Childs, Peter R. N.] Imperial Coll London, Dyson Sch Design Engn, London SW7 2AZ, England.
   [Wang, Pan; Dong, Hao; Guo, Yike] Imperial Coll London, Data Sci Inst, London SW7 2AZ, England.
   [Xiao, Jun; Wu, Chao] Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China.
   [Han, Ji] Univ Liverpool, Sch Engn, Liverpool L69 3BX, Merseyside, England.
C3 Imperial College London; Imperial College London; Zhejiang University;
   University of Liverpool
RP Chen, LQ (corresponding author), Imperial Coll London, Dyson Sch Design Engn, London SW7 2AZ, England.; Wu, C (corresponding author), Zhejiang Univ, Hangzhou 310027, Zhejiang, Peoples R China.
EM l.chen15@imperial.ac.uk; chao.wu@zju.edu.cn
RI Shi, Feng/G-3247-2012; Chen, Liuqing/HPE-0376-2023; 郭, 伊可/GYD-3212-2022
OI Chen, Liuqing/0000-0002-9049-0394; Childs, Peter/0000-0002-2465-8822;
   Han, Ji/0000-0003-3240-4942
FU Fundamental Research Funds for the Central Universities; Artificial
   Intelligence Research Foundation of Baidu Inc.; Zhejiang Natural Science
   Foundation [R19F020009, 1217F020001]; National Natural Science
   Foundation of China [61572431]; Key R&D Program of Zhejiang Province
   [2018C01006]; Program of China Knowledge Center for Engineering Sciences
   and Technology, Program of ZJU; Joint Research Program of ZJU; Major
   Scientifc Research Project of Zhejiang Lab [2018EC0ZX01-1]; Hikvision
   Research Institute; China Scholarship Council (CSC); Jaywing plc.;
   Zhejiang University
FX This work is supported by Fundamental Research Funds for the Central
   Universities, Artificial Intelligence Research Foundation of Baidu Inc.,
   Zhejiang University and Cybervein Joint Research Lab, Zhejiang Natural
   Science Foundation (R19F020009, 1217F020001), National Natural Science
   Foundation of China (61572431), Key R&D Program of Zhejiang Province
   (2018C01006), Program of China Knowledge Center for Engineering Sciences
   and Technology, Program of ZJU and Tongdun Joint Research Lab, Joint
   Research Program of ZJU and Hikvision Research Institute, and Major
   Scientifc Research Project of Zhejiang Lab (No. 2018EC0ZX01-1). The
   authors would also like to acknowledge China Scholarship Council (CSC)
   and Jaywing plc. for their support in doctorial funding, and Nvidia for
   donating a Titan-Xp GPU used in this work.
CR Agirre E., 2009, P HUMAN LANGUAGE TEC, P19, DOI 10.3115/1620754.1620758
   AMABILE TM, 1983, J PERS SOC PSYCHOL, V45, P357, DOI 10.1037/0022-3514.45.2.357
   [Anonymous], P TANG EMB INT
   [Anonymous], 2014, DESIGN COMPUTING COG
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], 2015, 3 INT C HUM AG INT P
   [Anonymous], P ICED 05 15 INT C E
   [Anonymous], 2012, BISOCIATIVE KNOWLEDG
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], ADV ENG INF
   [Anonymous], NEURAL ARCHITECTURES
   [Anonymous], P INT DES ENG TECHN
   [Anonymous], P AAAI
   [Anonymous], 2015, The Stanford CoreNLP Natural Language Processing Toolkit, DOI [10.3115/v1/p14-5010, DOI 10.3115/V1/P14-5010]
   [Anonymous], P ASME 2017 INT DES
   [Anonymous], 2017, INT DES ENG TECHN C
   [Anonymous], P IR C ART INT COGN
   [Anonymous], P DS 84 P DESIGN 201
   [Anonymous], 2012, P 3 INT C COMP CREAT
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2016, ARXIV161203242
   [Anonymous], 2008, P 7 PYTHON SCI C
   [Anonymous], ARXIV13111213
   Beliga Slobodan., 2014, KEYWORD EXTRACTION R
   Boden M.A., 2004, CREATIVE MIND MYTHS
   Bostock M, 2011, IEEE T VIS COMPUT GR, V17, P2301, DOI 10.1109/TVCG.2011.185
   Braha D., 2013, DATA MINING DESIGN M
   Chakrabarti A, 2005, AI EDAM, V19, P113, DOI 10.1017/S0890060405050109
   Chan J, 2011, J MECH DESIGN, V133, DOI 10.1115/1.4004396
   Chen W, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037306
   Christensen BT, 2007, MEM COGNITION, V35, P29, DOI 10.3758/BF03195939
   Daly SR, 2016, J MECH DESIGN, V138, DOI 10.1115/1.4034087
   Daly SR, 2012, J ENG EDUC, V101, P601, DOI 10.1002/j.2168-9830.2012.tb01121.x
   Dubitzky Werner, 2012, Bisociative Knowledge Discovery. An Introduction to Concept, Algorithms, Tools and Applications: LNCS 7250, P11, DOI 10.1007/978-3-642-31830-6_2
   English K, 2010, J COMPUT INF SCI ENG, V10, DOI 10.1115/1.3484089
   Fu K, 2014, J MECH DESIGN, V136, DOI 10.1115/1.4028289
   Gero JS, 2004, DESIGN STUD, V25, P373, DOI 10.1016/j.destud.2003.10.010
   Goel AK, 2004, ADV ENG INFORM, V18, P85, DOI 10.1016/j.aei.2004.09.003
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Green AE, 2012, J EXP PSYCHOL LEARN, V38, P264, DOI 10.1037/a0025764
   Han J, 2016, PROC INT DESIGN CONF, P639
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kairam S, 2015, COMPUT GRAPH FORUM, V34, P301, DOI 10.1111/cgf.12642
   Kelly N, 2015, KNOWL-BASED SYST, V80, P48, DOI 10.1016/j.knosys.2014.12.005
   Koestler Arthur, 1964, The Act of Creation
   Li JJ, 2019, IEEE T CYBERNETICS, V49, P2144, DOI 10.1109/TCYB.2018.2820174
   Li ZJ, 2007, AI EDAM, V21, P137, DOI 10.1017/S0890060407070199
   Lin CF, 2013, COMPUT EDUC, V68, P199, DOI 10.1016/j.compedu.2013.05.009
   Linsey J.S., 2008, ASME 2008 INT DESIGN, P21, DOI DOI 10.1115/DETC2008-49317
   Pinel F., 2015, Computational creativity research: Towards creative machines, P327, DOI [10.2991/978-94-6239-085-016, DOI 10.2991/978-94-6239-085-016, DOI 10.2991/978-94-6239-085-0_16]
   Radford A., 2015, ARXIV
   Scott John, 2012, Social network analysis
   Self James, 2016, Journal of Design Research, V14, P171
   Shah J. J., 2003, Design Studies, V24, P111, DOI 10.1016/S0142-694X(02)00034-0
   Shi F, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037649
   Smith G, 2012, J MECH DESIGN, V134, DOI 10.1115/1.4006261
   Stemler S. E., 2004, Practical Assessment, Research, and Evaluation, V9, DOI DOI 10.7275/96JP-XZ07
   Toivonen H, 2015, WIRES DATA MIN KNOWL, V5, P265, DOI 10.1002/widm.1170
   Vattam S, 2011, DESIGN CREATIVITY 2010, P115, DOI 10.1007/978-0-85729-224-7_16
   Wang H, 2015, STUD COMPUT INTELL, V564, P99, DOI 10.1007/978-4-431-55209-3_7
   Wang MM, 2015, J MECH DESIGN, V137, DOI 10.1115/1.4029373
   Wiggins GA, 2006, KNOWL-BASED SYST, V19, P449, DOI 10.1016/j.knosys.2006.04.009
   Wu JJ, 2016, ADV NEUR IN, V29
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Zheng SC, 2016, KNOWL-BASED SYST, V114, P12, DOI 10.1016/j.knosys.2016.09.019
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
NR 68
TC 56
Z9 58
U1 13
U2 104
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 10
EP 22
DI 10.1016/j.jvcir.2019.02.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA HY3GK
UT WOS:000468011100002
DA 2024-07-18
ER

PT J
AU Huang, Y
   Zhang, QP
AF Huang, Ying
   Zhang, Qingping
TI Research on image screening model of ancient villages
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Ancient villages; Image screening; SIFT; Convolutional neural network
ID OBJECTS; SYSTEM; DEEP
AB Ancient villages are the carrier of a nation's profound history and culture. They are the integration of history, culture, architecture and sculpture, and have many value attributes. With the development of society, the protection of ancient villages is very important. The establishment of digital archives is an important means to protect ancient villages. Because of the large number and wide distribution of ancient villages, crowd sourcing can quickly and widely access the digital resources of ancient villages. Because of the uneven quality and repetition of the images collected from ancient villages, it is necessary to screen the images of ancient villages. Therefore, this paper proposes a screening model of ancient villages based on SIFT and convolution neural network. Firstly, this paper chooses edge gray change rate and NIQE quality score to evaluate the quality of ancient village image; secondly, extracts SIFT features of image for matching, calculates matching similarity to determine whether the matched image is myopic repetition. Finally, the image is filtered or preserved by using convolution neural network with the edge gray change rate, NIQE quality score and some image attributes as features. Experiments show that the ancient village image screening model designed in this paper has higher accuracy and recall rate than other methods, and has better screening effect. (C) 2019 Published by Elsevier Inc.
C1 [Huang, Ying] Nanjing Forestry Univ, Coll Art & Design, Nanjing, Jiangsu, Peoples R China.
   [Zhang, Qingping] Nanjing Forestry Univ, Coll Landscape Architecture, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing Forestry University; Nanjing Forestry University
RP Zhang, QP (corresponding author), Nanjing Forestry Univ, Coll Landscape Architecture, Nanjing, Jiangsu, Peoples R China.
EM Zhangqingping2015@163.com
OI Zhang, Qingping/0000-0001-7969-5797
FU National Natural Science Foundation of China [51408310]
FX This work was supported by the National Natural Science Foundation of
   China (No.51408310).
CR Albayrak  A., 2017, SIGN PROC COMM APPL
   [Anonymous], 2017, IEEE T POWER SYST
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Ghosh T, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2017.2756034
   Gong  C., 2017, MOD PHYS LETT B, V31
   Guo T, 2018, SMART MATER STRUCT, V27, DOI 10.1088/1361-665X/aaa7ff
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Litman L, 2017, BEHAV RES METHODS, V49, P433, DOI 10.3758/s13428-016-0727-z
   Lu  Z., 2018, IEEE SIGNAL PROCESS, V25
   Miaomiao  L.I., 2017, OPT TECHNIQUE, V43, P25
   Monje M, 2018, ANNU REV NEUROSCI, V41, P61, DOI 10.1146/annurev-neuro-080317-061853
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Radenovic Filip, 2017, FINE TUNING CNN IMAG
   [贾银江 Jia Yinjiang], 2017, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V33, P123
   Song J, 2017, IEEE ENG MED BIO, P681, DOI 10.1109/EMBC.2017.8036916
   Wen L, 2018, IEEE T IND ELECTRON, V65, P5990, DOI 10.1109/TIE.2017.2774777
   Wu JX, 2015, IEEE T NEUR NET LEAR, V26, P2357, DOI 10.1109/TNNLS.2014.2382123
   Xie SP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25153-w
   Yang G, 2017, IEEE INTERNET THINGS, V4, P330, DOI 10.1109/JIOT.2016.2560518
   Yin YJ, 2015, IEEE T CYBERNETICS, V45, P1988, DOI 10.1109/TCYB.2014.2363078
   Yu SD, 2018, BMC MED IMAGING, V18, DOI 10.1186/s12880-018-0256-6
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhao  G., 2018, ASIA PACIFIC J TOUR, V23, P1
   Zhao Y., 2018, Advances in Materials Science and Engineering, V2018, P1
   Zheng YD, 2017, PROC VLDB ENDOW, V10, P541, DOI 10.14778/3055540.3055547
   2017, APPL SPAT ANAL POLIC, V10, P3, DOI DOI 10.1007/S12061-015-9168-9
   2013, P IEEE C COMP VIS PA, P1908, DOI DOI 10.1109/CVPR.2013.249
NR 36
TC 0
Z9 0
U1 4
U2 61
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 33
EP 41
DI 10.1016/j.jvcir.2019.02.029
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100004
DA 2024-07-18
ER

PT J
AU Wu, SF
   Wang, DH
AF Wu, Shifeng
   Wang, Dahu
TI Effect of subject's age and gender on face recognition results
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Deep learning; Gender; Age
ID OBJECT DETECTION; DEEP; FEATURES
AB Nowadays, more and more places need authentication. Face recognition is a mature technology for identity verification research. Recognition accuracy is an important indicator for evaluating authentication algorithms. In order to improve the accuracy of identity verification, advanced face is used. Feature recognition algorithm is an effective way, but it is also an effective algorithm to study the factors affecting facial features. Therefore, many researchers study the recognition results based on the poses of the face, light and other factors. This paper is also a study on the factors affecting face recognition, mainly by studying the influence of the age and gender factors on the identity verification results, and using the deep learning method to classify facial features. The simulation results show that the average recognition rate reaches 83.73%. At the same time, this paper analyzes the effect of age and gender on the classification results. The results show that the recognition effect of middle-aged men in male subjects is lower than that of youth and the elderly. Women have little difference in recognition effect with age. Males have higher recognition rates than women. (C) 2019 Published by Elsevier Inc.
C1 [Wu, Shifeng] Guangdong Polytech Normal Univ, Coll Math & Syst Sci, Guangzhou, Guangdong, Peoples R China.
   [Wang, Dahu] Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo, Henan, Peoples R China.
C3 Guangdong Polytechnic Normal University; Henan Polytechnic University
RP Wang, DH (corresponding author), Henan Polytech Univ, Sch Elect Engn & Automat, Jiaozuo, Henan, Peoples R China.
EM dahuwang2008@126.com
RI Wang, Dahu/W-7194-2018
FU Department of Education of Guangdong Province [2017KQNCX122]; second
   batch of production and education cooperative education projects of the
   Ministry of education [201702071143, 201702172009]; National Natural
   Science Foundation of China Youth Science Foundation [61601172]
FX This work was supported by Department of Education of Guangdong
   Province; (No. 2017KQNCX122).; This work was supported by the second
   batch of production and education cooperative education projects of the
   Ministry of education in 2017; (No. 201702071143, 201702172009).; This
   work was supported by National Natural Science Foundation of China Youth
   Science Foundation (No. 61601172).
CR An X., 2014, A Deep Learning Method for Classification of EEG Data Based on Motor Imagery, P203
   An X, 2014, LECT N BIOINFORMAT, V8590, P203, DOI 10.1007/978-3-319-09330-7_25
   [Anonymous], 1994, VIEW BASED MODULAR E
   [Anonymous], IEEE T CIRC SYST VID
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Gumus E, 2010, EXPERT SYST APPL, V37, P6404, DOI 10.1016/j.eswa.2010.02.079
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Jin H, 2017, COMPUT AIDED GEOM D, V50, P1, DOI 10.1016/j.cagd.2016.11.001
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Juneja K, 2017, COMM COM INF SC, V750, P216, DOI 10.1007/978-981-10-6544-6_21
   Kisku DR, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P63, DOI 10.1109/AUTOID.2007.380594
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu ZG, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P501, DOI 10.1145/3123266.3123377
   MacFarlane GR, 2006, J BIOL EDUC, V41, P13, DOI 10.1080/00219266.2006.9656051
   Schirrmeister RT, 2017, HUM BRAIN MAPP, V38, P5391, DOI 10.1002/hbm.23730
   [孙亚 SUN Ya], 2008, [计算机仿真, Computer Simulation], V25, P201
   Surabhi A., 2012, 2012 International Conference on Communication, Information Computing Technology (ICCICT), P1
   Tabar YR, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2560/14/1/016003
   Tan HL, 2014, IET COMPUT VIS, V8, P224, DOI 10.1049/iet-cvi.2012.0302
   TURK MA, 1991, P CVPR 91 IEEE COMP
   White  M., 2016, SIAM J SCI COMPUT, V32, P271
   Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244
   Yao M, 2017, IEEE INT C CONS EL C, P1
   YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   ZHANG Z, 1998, P 3 IEEE INT C AUT F
NR 38
TC 12
Z9 12
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 116
EP 122
DI 10.1016/j.jvcir.2019.01.013
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000014
DA 2024-07-18
ER

PT J
AU Li, D
   Wu, ZJ
   Wang, Q
AF Li, Dan
   Wu, Zhaojun
   Wang, Qiang
TI Edge guided compressive sensing for image reconstruction based on
   two-stage <i>l</i><sub>0</sub> minimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Image reconstruction; l(0) minimization; Edge
   prior; Multiple sampling scheme
ID SIGNAL RECOVERY; PURSUIT; ALGORITHM; OPTIMIZATION
AB In compressive sensing framework, the results of image reconstruction are sometimes not accurate enough due to the downsampled measurements, especially when the sampling rate is relatively small. This paper proposes a novel edge guided compressive sensing (EGCS) algorithm for natural image reconstruction based on two-stage l(0) minimization, aiming to improve the reconstruction performance. Firstly, wavelet transform is utilized to provide sparsity and multiple sampling scheme is employed to acquire the down-sampled measurements. Then, in the first stage, we design an edge-preserving smoothing method by l(0) gradient minimization to extract the important edge prior accurately, which can not only contribute a lot to improve the reconstruction accuracy of image structures but also reduce the computational complexity remarkably. Also, the use of multiple sampling scheme is beneficial to enhancing the guidance accuracy of multiple edge prior. In the second stage, under the guidance of multiple edge prior, the intelligent searching strategies are designed by taking advantages of intelligent optimization algorithms in solving combinatorial optimization problems and utilizing the superior performance of greedy algorithm on reconstruction speed, which is conductive to solve the joint sparse reconstruction based on l(0) minimization essentially. The better reconstruction performance can be achieved based on the fact that it is more likely to find the global optimal solution accurately by the designed intelligent searching strategies, especially when the sampling rate is relatively small. Experimental results on natural image reconstruction demonstrate that our proposed method EGCS is superior to the state-of-the-art reconstruction algorithms, and can well preserve the important image structures at the same time. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Dan] Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
   [Wu, Zhaojun; Wang, Qiang] Harbin Inst Technol, Control Sci & Engn, Harbin 150001, Heilongjiang, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Harbin Institute of
   Technology
RP Li, D (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
EM lidanhit@163.com; wangqiang@hit.edu.cn
RI Wang, Qiang/B-1053-2012
OI Wang, Qiang/0000-0002-9654-0268
FU National Science Foundations of China [61801214]
FX This work is financially supported by National Science Foundations of
   China (No. 61801214).
CR Bai Qinghai, 2010, COMPUTER INFORM SCI, V3, P180, DOI DOI 10.5539/CIS.V3N1P180
   Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Byeungwoo J., 2014, IEEE INT C MULT EXP
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Du XP, 2014, NEUROCOMPUTING, V131, P98, DOI 10.1016/j.neucom.2013.10.036
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Guo W., 2010, P SPIE VISUAL COMMUN, V7744
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Huang HL, 2011, IEEE SIGNAL PROC LET, V18, P391, DOI 10.1109/LSP.2011.2147313
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   La C, 2006, IEEE IMAGE PROC, P1277, DOI 10.1109/ICIP.2006.312578
   Li D, 2016, NEUROCOMPUTING, V207, P548, DOI 10.1016/j.neucom.2016.05.031
   Li D, 2016, SIGNAL PROCESS, V122, P138, DOI 10.1016/j.sigpro.2015.11.019
   Li D, 2014, IEEE IMTC P, P76, DOI 10.1109/I2MTC.2014.6860526
   Li D, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P1023, DOI 10.1109/ICInfA.2013.6720445
   Lin CH, 2013, INFORM SCIENCES, V241, P119, DOI 10.1016/j.ins.2013.04.001
   Lu W, 2010, INT CONF ACOUST SPEE, P3926, DOI 10.1109/ICASSP.2010.5495799
   Needell D, 2009, APPL COMPUT HARMON A, V26, P301, DOI 10.1016/j.acha.2008.07.002
   Needell D., ARXIV09054482
   Plumbley MD, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P14
   Rao N. S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1917, DOI 10.1109/ICIP.2011.6115845
   Canh TN, 2015, IEEE IMAGE PROC, P2700, DOI 10.1109/ICIP.2015.7351293
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P549, DOI [10.1016/j.sigpro.2005.05.029, 10.1016/j.sigpro.2005.05.028]
   Tuba M, 2014, NEUROCOMPUTING, V143, P197, DOI 10.1016/j.neucom.2014.06.006
   Vera E, 2009, 2009 IEEE/SP 15TH WORKSHOP ON STATISTICAL SIGNAL PROCESSING, VOLS 1 AND 2, P229, DOI 10.1109/SSP.2009.5278598
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu J, 2013, SIGNAL PROCESS, V93, P1662, DOI 10.1016/j.sigpro.2012.09.010
   Wu J, 2011, IEEE T IMAGE PROCESS, V20, P3483, DOI 10.1109/TIP.2011.2150231
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Zheng Hai-bo, 2013, Journal of China Universities of Posts and Telecommunications, V20, P97, DOI 10.1016/S1005-8885(13)60056-4
NR 35
TC 2
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 461
EP 474
DI 10.1016/j.jvcir.2019.01.025
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600050
DA 2024-07-18
ER

PT J
AU Wali, S
   Zhang, HY
   Chang, HB
   Wu, CL
AF Wali, Samad
   Zhang, Huayan
   Chang, Huibin
   Wu, Chunlin
TI A new adaptive boosting total generalized variation (TGV) technique for
   image denoising and inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total generalized variation; Boosting technique; Image denoising; Image
   inpainting; Primal-dual method
ID ITERATIVE REGULARIZATION; FUNCTIONALS; ALGORITHM; SPARSE; BV
AB In this paper we present a new adaptive boosting technique for total generalized variation (TGV) based image denoising and inpainting. Instead of the strengthening and substracting steps in existing boosting techniques, the proposed technique is iteratively operated by two steps: the first step is to take average of restored image with observed image, and updated parameter; the second step is to operate the TGV restoration algorithm with the average and dynamic parameter. For each iteration, as the input contains more correct information, the restoration algorithm can produce signals with more details. We have solved our boosting TGV model by primal-dual method, and applied the boosting TGV technique for gray/color image denoising and inpainting. Our algorithms have been discussed about influence of parameters, computational cost and compared with several typical existing methods. Plenty of experimental results show that our method can produce images with more structures and prevent staircase artifacts effectively. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wali, Samad; Wu, Chunlin] Nankai Univ, Sch Math Sci, Tianjin, Peoples R China.
   [Zhang, Huayan] Tianjin Polytech Univ, Sch Comp Sci & Software Engn, Tianjin, Peoples R China.
   [Chang, Huibin] Tianjin Normal Univ, Sch Math Sci, Tianjin, Peoples R China.
   [Wali, Samad] Univ Elect Sci & Technol China, Sch Informat & Commun Engn, Chengdu, Sichuan, Peoples R China.
C3 Nankai University; Tiangong University; Tianjin Normal University;
   University of Electronic Science & Technology of China
RP Zhang, HY (corresponding author), Tianjin Polytech Univ, Sch Comp Sci & Software Engn, Tianjin, Peoples R China.
EM zhanghuayan@tjpu.edu.cn
RI Chang, Huibin/I-4678-2015; li, fangyu/KCY-0521-2024; Wu,
   Chunlin/H-1171-2017; chen, minghui/KFR-8832-2024
OI li, fangyu/0009-0009-8303-9157; Wali, Samad/0000-0002-8633-4209
FU National Natural Science Foundation of China [61802279, G0561671135,
   61602341, 11871035, 11871372, 11531013]; Natural Science Foundation of
   Tianjin [18JCQNJC00100, 17JCQNJC00600, 18JCYBJC16600]; Fundamental
   Research Funds for the Central Universities; State Key Laboratory of
   Virtual Reality Technology and Systems, Beihang University
   [BUAA-VR-17KF-04]
FX This work was partially supported by National Natural Science Foundation
   of China (Nos. 61802279, G0561671135, 61602341, 11871035, 11871372 and
   11531013), Natural Science Foundation of Tianjin (Nos. 18JCQNJC00100,
   17JCQNJC00600 and 18JCYBJC16600), the Fundamental Research Funds for the
   Central Universities and the open funding project of State Key
   Laboratory of Virtual Reality Technology and Systems, Beihang University
   (Grant No. BUAA-VR-17KF-04). We also thank the authors of [33] for
   providing their denoising results and the authors of [29] for providing
   their code.
CR Blomgren P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P384, DOI 10.1109/ICIP.1997.632128
   Bredies K, 2015, J MATH IMAGING VIS, V52, P317, DOI 10.1007/s10851-015-0564-1
   Bredies K, 2014, LECT NOTES COMPUT SC, V8293, P44, DOI 10.1007/978-3-642-54774-4_3
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Burger M, 2016, J MATH IMAGING VIS, V55, P343, DOI 10.1007/s10851-015-0624-6
   Cao V. C., 2016, ARXIV E PRINTS
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Charest MR, 2008, IEEE T CIRC SYST VID, V18, P406, DOI 10.1109/TCSVT.2008.918444
   Chen YM, 2006, SIAM J APPL MATH, V66, P1383, DOI 10.1137/050624522
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   De los Reyes JC, 2017, J MATH IMAGING VIS, V57, P1, DOI 10.1007/s10851-016-0662-8
   Dong FF, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P1283, DOI 10.1109/ICNC.2013.6818176
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P74, DOI 10.5201/ipol.2012.g-tvd
   KAISER JF, 1977, IEEE T ACOUST SPEECH, V25, P415, DOI 10.1109/TASSP.1977.1162980
   Knoll F, 2011, MAGN RESON MED, V65, P480, DOI 10.1002/mrm.22595
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Meyer Yves., 2001, Lewis memorial lectures, V22
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Papafitsoros K, 2014, J MATH IMAGING VIS, V48, P308, DOI 10.1007/s10851-013-0445-4
   Romano Y, 2015, SIAM J IMAGING SCI, V8, P1187, DOI 10.1137/140990978
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Scherzer O., 2009, Variational methods in imaging, V320
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Sun L, 2014, BIT, V54, P523, DOI 10.1007/s10543-013-0448-y
   Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448
   Tai XC, 2011, SIAM J IMAGING SCI, V4, P313, DOI 10.1137/100803730
   Talebi H, 2013, IEEE T IMAGE PROCESS, V22, P1468, DOI 10.1109/TIP.2012.2231691
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   Wali S, 2018, NUMER MATH-THEORY ME, V11, P49, DOI 10.4208/nmtma.OA-2017-0046
   Wang WN, 2019, NUMER MATH-THEORY ME, V12, P467, DOI 10.4208/nmtma.OA-2017-0130
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie J., 2012, ADV NEURAL INFORM PR, P341
   Zhang JP, 2015, SIAM J IMAGING SCI, V8, P2487, DOI 10.1137/14097121X
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 37
TC 27
Z9 28
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 39
EP 51
DI 10.1016/j.jvcir.2018.12.047
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600005
DA 2024-07-18
ER

PT J
AU Tian, F
   Wang, QG
   Li, X
   Sun, N
AF Tian, Feng
   Wang, Quge
   Li, Xin
   Sun, Ning
TI Heterogeneous multimedia cooperative annotation based on multimodal
   correlation learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia annotation; Cooperative annotation; Multimodal correlation
   learning
ID LOW-RANK; IMAGE; RETRIEVAL; RELEVANCE
AB Rich multimedia contents are dominating the current Web. In popular social media platforms such as FaceBook, Twitter, and Instagram, there are over millions of multimedia contents being created by users. In the meantime, multimedia data consists of data in multiple modalities, such as text, images, videos, audio, time series sequences, and so on. Many research efforts have been devoted to multimedia annotation to further improve the performance. However, the prevailing methods are designed for single-media annotation task. In fact, heterogeneous media content describes given labels from respective modality and is complementary to each other, and it becomes critical to explore advanced techniques for heterogeneous data analysis and multimedia annotation. Inspired by this idea, this paper presents a new multimodal correlation learning method for heterogeneous multimedia cooperative annotation, named unified space learning, which projects heterogeneous media data into one unified space. We formulate the multimedia annotation task into a semi-supervised learning framework, in which we learn different projection matrices for different media type. By doing so, different media content is aligned cooperatively, and jointly provides a more complementary profile of given semantic labels. Experimental results on data set with images, audio clips, videos and 3D models show that the proposed approach is more effective. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Tian, Feng; Wang, Quge; Li, Xin; Sun, Ning] Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 153318, Peoples R China.
C3 Northeast Petroleum University
RP Tian, F (corresponding author), Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 153318, Peoples R China.
EM tianfeng@nepu.edu.cn
RI Sun, Ning/HLX-6289-2023; ARSLAN, Okan/AAA-3232-2020
FU Natural Science Foundation of China [61502094, 61402099]; Natural
   Science Foundation of Heilongjiang Province of China [F2016002,
   F2015020]
FX This work is partially supported by the Natural Science Foundation of
   China (Nos. 61502094, 61402099), Natural Science Foundation of
   Heilongjiang Province of China (Nos. F2016002, F2015020). Special thanks
   to the collaborators in Nus-Tsinghua Centre for Extreme Search, and the
   valuable suggestions from anonymous reviewers and the editors.
CR [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], ARXIV160705695
   [Anonymous], 2011, P ICML
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMEDIA SYST
   [Anonymous], ARXIV161001206
   [Anonymous], P 2 ACM WORKSH MULT
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], ARXIV13013781
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Arora R, 2013, INT CONF ACOUST SPEE, P7135, DOI 10.1109/ICASSP.2013.6639047
   Blaschko MB, 2011, PATTERN RECOGN LETT, V32, P1572, DOI 10.1016/j.patrec.2011.02.011
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hwang SJ, 2012, INT J COMPUT VISION, V100, P134, DOI 10.1007/s11263-011-0494-3
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112
   Srivastava Neelam., 2012, The Postcolonial Gramsci, P1
   Tian F, 2018, MULTIMED TOOLS APPL, V77, P3473, DOI 10.1007/s11042-017-5170-3
   Tian F, 2015, CHINESE J ELECTRON, V24, P790, DOI 10.1049/cje.2015.10.021
   Wang JD, 2014, COMPUT VIS IMAGE UND, V124, P61, DOI 10.1016/j.cviu.2014.02.011
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Xiaofeng Zhu, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference, PAKDD 2013. Proceedings, P520, DOI 10.1007/978-3-642-37453-1_43
   Zhang HW, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1079, DOI 10.1145/2733373.2806286
   Zhang SC, 2016, NEUROCOMPUTING, V195, P137, DOI 10.1016/j.neucom.2015.08.115
   Zhu XF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P223, DOI 10.1145/2600428.2609556
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Znaidia A, 2012, INT C PATT RECOG, P1509
NR 41
TC 5
Z9 6
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 544
EP 553
DI 10.1016/j.jvcir.2018.12.028
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100053
DA 2024-07-18
ER

PT J
AU Xu, N
   Liu, AA
   Liu, J
   Nie, WZ
   Su, YT
AF Xu, Ning
   Liu, An-An
   Liu, Jing
   Nie, Weizhi
   Su, Yuting
TI Scene graph captioner: Image captioning based on structural visual
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image captioning; Scene graph; Structural representation; Attention
ID VISION; MOTIFS
AB While deep neural networks have recently achieved promising results on the image captioning task, they do not explicitly use the structural visual and textual knowledge within an image. In this work, we propose the Scene Graph Captioner (SGC) framework for the image captioning task, which captures the comprehensive structural semantic of visual scene by explicitly modeling objects, attributes of objects, and relationships between objects. Firstly, we develop an approach to generate the scene graph by learning individual modules on the large object, attribute and relationship datasets. Then, SGC incorporates high-level graph information and visual attention information into a deep captioning framework. Specifically, we propose a novel framework to embed a scene graph into the structural representation, which captures the semantic concepts and the graph topology. Further, we develop the scene-graph-driven method to generate the attention graph by exploiting high internal homogeneity and external inhomogeneity among the nodes in the scene graph. Finally, a LSTM-based framework translates these information into text. We evaluate the proposed framework on a held-out MSCOCO dataset. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Xu, Ning; Liu, An-An; Liu, Jing; Nie, Weizhi; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Liu, AA; Liu, J (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM anan0422@gmail.com; jliu_tju@tju.edu.cn
RI Liu, Anan/AAB-8047-2020; Nie, Weizhi/ABF-5316-2021; Liu-Zeng,
   Jing/F-8582-2011
OI Liu, Anan/0000-0001-5755-9145; nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61772359, 61472275,
   61502337, 61701341]
FX This work was supported in part by the National Natural Science
   Foundation of China (61772359, 61472275, 61502337, 61701341).
CR [Anonymous], PHILOS T ROY SOC L B
   [Anonymous], CVPR
   [Anonymous], CoRR
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], CVPR, DOI DOI 10.1109/CVPR.2016.13
   [Anonymous], 2015, ICLR 2015
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], CORR
   [Anonymous], 2014, BMVC
   [Anonymous], 2014, P 2014 C EMPIRICAL M
   Bean BP, 2007, NAT REV NEUROSCI, V8, P451, DOI 10.1038/nrn2148
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Choi MJ, 2010, PROC CVPR IEEE, P129, DOI 10.1109/CVPR.2010.5540221
   Choi WG, 2013, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2013.12
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Desai C, 2011, INT J COMPUT VISION, V95, P1, DOI 10.1007/s11263-011-0439-x
   Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Elliott D, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P452
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Ferrari V., 2007, P 20 INT C NEUR INF, P433
   Fisher M, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964929
   Fouhey DF, 2014, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2014.260
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Huang Z., 2018, IEEE T NEURAL NETWOR, P1
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li J., 2018, IEEE T CYBERNET, P1
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin DH, 2014, PROC CVPR IEEE, P2657, DOI 10.1109/CVPR.2014.340
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu A, 2018, P 27 INT JOINT C ART, P821, DOI DOI 10.24963/IJCAI.2018/114
   Liu AA, 2017, COMPUT VIS IMAGE UND, V163, P113, DOI 10.1016/j.cviu.2017.04.013
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Mao JH, 2015, IEEE I CONF COMP VIS, P2533, DOI 10.1109/ICCV.2015.291
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Milo R, 2002, SCIENCE, V298, P824, DOI 10.1126/science.298.5594.824
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh D, 2011, IEEE I CONF COMP VIS, P503, DOI 10.1109/ICCV.2011.6126281
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Sporns O, 2004, PLOS BIOL, V2, P1910, DOI 10.1371/journal.pbio.0020369
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xu K., 2015, COMPUTER SCI, P2048
   Xu N, 2018, IEEE INTERNET THINGS, V5, P3419, DOI 10.1109/JIOT.2017.2779865
   Yang JM, 2014, PROC CVPR IEEE, P3294, DOI 10.1109/CVPR.2014.415
   Yang Y., 2011, P C EMP METH NAT LAN, P444
   Zhao YB, 2013, PROC CVPR IEEE, P3119, DOI 10.1109/CVPR.2013.401
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zitnick CL, 2013, IEEE I CONF COMP VIS, P1681, DOI 10.1109/ICCV.2013.211
   Zitnick CL, 2013, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR.2013.387
NR 67
TC 46
Z9 48
U1 3
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 477
EP 485
DI 10.1016/j.jvcir.2018.12.027
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100046
DA 2024-07-18
ER

PT J
AU Jian, MW
   Zhang, WY
   Yu, H
   Cui, CR
   Nie, XS
   Zhang, HX
   Yin, YL
AF Jian, Muwei
   Zhang, Wenyin
   Yu, Hui
   Cui, Chaoran
   Nie, Xiushan
   Zhang, Huaxiang
   Yin, Yilong
TI Saliency detection based on directional patches extraction and principal
   local color contrast
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Wavelet frame transform; Principal local color
   contrast; Directional patches
ID VISUAL-ATTENTION; IMAGE RETRIEVAL; OBJECT DETECTION; MODEL;
   DECOMPOSITION
AB Saliency detection has become an active topic in both computer vision and multimedia fields. In this paper, we propose a novel computational model for saliency detection by integrating the holistic center-directional map with the principal local color contrast (PLCC) map. In the proposed framework, perceptual directional patches are firstly detected based on discrete wavelet frame transform (DWFT) and sparsity criterion, then the center of the spatial distribution of the extracted directional patches are utilized to locate the salient object in an image. Meanwhile, we proposed an efficient local color contrast method, called principal local color contrast (PLCC), to compute the color contrast between the salient object and the image background, which is sufficient to highlight and separate salient objects from complex background while dramatically reduce the computational cost. Finally, by incorporating the complementary visual cues of the global center-directional map with the PLCC map, a final compounded saliency map can be generated. Extensive experiments performed on three publicly available image data-bases, verify that the proposed scheme is able to achieve satisfactory results compared to other state-of-the-art saliency-detection algorithms. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Jian, Muwei; Cui, Chaoran; Nie, Xiushan; Yin, Yilong] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
   [Jian, Muwei; Zhang, Wenyin] Linyi Univ, Sch Informat Sci & Engn, Linyi, Peoples R China.
   [Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
   [Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Yin, Yilong] Shandong Univ, Sch Software Engn, Jinan 250101, Shandong, Peoples R China.
C3 Shandong University of Finance & Economics; Linyi University; University
   of Portsmouth; Shandong Normal University; Shandong University
RP Jian, MW; Yin, YL (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Shandong, Peoples R China.
EM 20173016@sdufe.edu.cn
RI Nie, Xiushan/AAZ-6410-2020; Yu, Hui/G-1115-2018; Jian, Muwei/Q-8319-2018
OI Yu, Hui/0000-0002-7655-9228; Jian, Muwei/0000-0002-4249-2264
FU National Natural Science Foundation of China (NSFC) [61601427, 61602229,
   61771230, 61573219]; Natural Science Foundation of Shandong Province
   [ZR2016FM40]; Shandong Provincial Key Research and Development Program
   of China [2017CXGC0701, 2017CXGC1504]; Fostering Project of Dominant
   Discipline and Talent Team of Shandong Province Higher Education
   Institutions
FX This work was supported by National Natural Science Foundation of China
   (NSFC) (61601427, 61602229, 61771230, 61573219); Natural Science
   Foundation of Shandong Province (ZR2016FM40); Shandong Provincial Key
   Research and Development Program of China (2017CXGC0701, 2017CXGC1504);
   Fostering Project of Dominant Discipline and Talent Team of Shandong
   Province Higher Education Institutions.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2018, IEEE Transactions on Cybernetics
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cholakkal H., 2015, BMVC
   Daneshvarfard F, 2018, BRAIN DEV-JPN, V40, P2, DOI 10.1016/j.braindev.2017.07.010
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Gao V.M. D., 2007, NIPS, P497
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hati A, 2017, J VIS COMMUN IMAGE R, V43, P212, DOI 10.1016/j.jvcir.2017.01.007
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian M, 2017, MULTIMED TOOLS APPL, P1
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2017, IEEE INT CON MULTI, P1297, DOI 10.1109/ICME.2017.8019324
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Jing PG, 2017, IEEE T MULTIMEDIA, V19, P1050, DOI 10.1109/TMM.2016.2644866
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kong YQ, 2016, LECT NOTES COMPUT SC, V9910, P583, DOI 10.1007/978-3-319-46466-4_35
   Li Z, 2018, J VIS COMMUN IMAGE R, V50, P16, DOI 10.1016/j.jvcir.2017.11.004
   Liu AN, 2018, SIGNAL PROCESS, V152, P206, DOI 10.1016/j.sigpro.2018.06.001
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Oliva A., 2003, IEEE ICIP, V1
   OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Shutao Li, 2002, Information Fusion, V3, P17, DOI 10.1016/S1566-2535(01)00037-9
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Villena-González M, 2016, NEUROIMAGE, V132, P71, DOI 10.1016/j.neuroimage.2016.02.013
   Wang Q, 2018, PATTERN RECOGN, V75, P272, DOI 10.1016/j.patcog.2017.03.030
   Wang Q, 2018, IEEE T CIRC SYST VID, V28, P2633, DOI 10.1109/TCSVT.2017.2703920
   Wang Q, 2013, IEEE T CIRC SYST VID, V23, P1150, DOI 10.1109/TCSVT.2012.2226528
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wu YT, 2008, PATTERN RECOGN, V41, P1948, DOI 10.1016/j.patcog.2007.11.020
   Xi T, 2017, IEEE T IMAGE PROCESS, V26, P3425, DOI 10.1109/TIP.2016.2631900
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Yan XY, 2017, J VIS COMMUN IMAGE R, V48, P224, DOI 10.1016/j.jvcir.2017.06.013
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang JM, 2017, IEEE T PATTERN ANAL, V39, P576, DOI 10.1109/TPAMI.2016.2547384
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang JH, 2018, J VIS COMMUN IMAGE R, V53, P102, DOI 10.1016/j.jvcir.2018.03.002
   Zhang J, 2018, IEEE SIGNAL PROC LET, V25, P333, DOI 10.1109/LSP.2017.2748604
   Zhu L, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P726, DOI 10.1145/3123266.3123301
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 68
TC 58
Z9 64
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 1
EP 11
DI 10.1016/j.jvcir.2018.10.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hung, KW
   Wang, K
   Jiang, JM
AF Hung, Kwok-Wai
   Wang, Kun
   Jiang, Jianmin
TI Image up-sampling using deep cascaded neural networks in dual domains
   for images down-sampled in DCT domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE DCT up-sampling; Interpolation; Super-resolution; Deep neural networks
ID SCHEME; INTERPOLATION
AB Recent researches show that the high-frequency discrete cosine transform (DCT) coefficients can be estimated from low-frequency DCT coefficients by exploiting the spatial correlations. Hence, images coded by DCT such as JPEG/MJPEG/H.264, etc., can be down-sampled in DCT domain, where the high frequency information can be accurately restored through image up-sampling. In this letter, we propose a novel deep neural network using the cascaded fully connected layers and convolution layers in dual domains (DCT) and spatial domains), in order to restore high-frequency DCT coefficients from observed low-frequency DCT coefficients by exploiting the DCT inter-block and spatial correlations. In the proposed network, many recent techniques are adopted, including residual network in dual domains, batch normalization, denseNet, etc. Experimental results show that the proposed cascaded networks in dual domains significantly outperforms the state-of-the-art DCT up-sampling methods in terms of PSNR (0.63-2.57 dB gain), SSIM values, and subjective evaluations on standard image datasets Set5 and Set14. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Hung, Kwok-Wai; Wang, Kun; Jiang, Jianmin] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Shenzhen University
RP Hung, KW (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM kwhung@szu.edu.cn
OI Hung, Kwok Wai/0000-0002-1665-3669
FU National Natural Science Foundation of China [61602312, 61620106008,
   61602313]; Shenzhen Emerging Industries of the Strategic Basic Research
   Project [JCYJ20160226191842793]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 61602312, 61620106008, 61602313) and Shenzhen
   Emerging Industries of the Strategic Basic Research Project (No.
   JCYJ20160226191842793).
CR Alkachouh Z, 2000, IEEE T IMAGE PROCESS, V9, P729, DOI 10.1109/83.841948
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   Cho MK, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2234736
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X., 2018, IEEE INT C IMAGE PRO
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hung KW, 2014, IEEE T CIRC SYST VID, V24, P2018, DOI 10.1109/TCSVT.2014.2329352
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Jiang F, 2018, IEEE T CIRC SYST VID, V28, P3007, DOI 10.1109/TCSVT.2017.2734838
   Jiang Jianmin, 2017, IEEE INT C IM PROC I
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Li Y, 2018, IEEE T CIRC SYST VID, V28, P2316, DOI 10.1109/TCSVT.2017.2727682
   Lim H, 2011, IEEE T CIRC SYST VID, V21, P879, DOI 10.1109/TCSVT.2011.2133250
   loffe S., 32 INT C MACH LEARN, V37, P448
   Mukherjee J, 2002, IEEE T CIRC SYST VID, V12, P620, DOI 10.1109/TCSVT.2002.800509
   NGAN KN, 1986, SIGNAL PROCESS, V11, P249, DOI 10.1016/0165-1684(86)90004-6
   Park Y, 2004, IEEE T CIRC SYST VID, V14, P274, DOI 10.1109/TCSVT.2003.819183
   Shen MM, 2011, IEEE T CIRC SYST VID, V21, P755, DOI 10.1109/TCSVT.2011.2130390
   Shi ZB, 2012, IEEE T CIRC SYST VID, V22, P1813, DOI 10.1109/TCSVT.2012.2223031
   Shin I, 2009, IEEE T CIRC SYST VID, V19, P206, DOI 10.1109/TCSVT.2008.2009256
   Shu HY, 2007, IEEE T CIRC SYST VID, V17, P248, DOI 10.1109/TCSVT.2006.887075
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Wu XL, 2009, IEEE T IMAGE PROCESS, V18, P552, DOI 10.1109/TIP.2008.2010638
   Wu ZY, 2016, IEEE IMAGE PROC, P1160, DOI 10.1109/ICIP.2016.7532540
   Wu ZY, 2010, IEEE SIGNAL PROC LET, V17, P827, DOI 10.1109/LSP.2010.2059700
   Zhang M, 2016, IEICE T INF SYST, VE99D, P475, DOI 10.1587/transinf.2015EDP7141
   Zhu S., 2016, 2016 Eleventh International Conference on Ecological Vehicles and Renewable Energies (EVER), P1
NR 29
TC 3
Z9 5
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 144
EP 149
DI 10.1016/j.jvcir.2018.09.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500013
DA 2024-07-18
ER

PT J
AU Liu, B
   Zhang, XH
   Wang, MZ
   Li, FQ
AF Liu, Bin
   Zhang, Xiaohui
   Wang, Mingzhe
   Li, Fengqi
TI An automatic and serialized ROI extraction framework for the slow-motion
   video frames
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Slow-motion video; Serialized extraction; Color frame image; Automatic
   seed point generation
ID IMAGE SEGMENTATION; FUZZY CONNECTEDNESS; ALGORITHMS; SNAKES; ROAD; USER
AB Currently, high-speed cameras has been a very common equipment in many important application fields. How to effectively and automatically extract the ROI (region of interest) for the slow-motion video has been a novel interesting challenge. In recent research work, we designed a ROI extraction framework for the video frames produced by high-speed cameras. The entire framework includes two parts: a novel but simple color similarity measure model is improved to distinguish different pixels; a skeleton feature points based serialized segmentation tactics is proposed to generate seed points. By using the multithreading patterns of parallelizing computations in the extraction process, the ROI in the serialized color slow-motion video frames can be marked automatically and accurately. Comparing with the common methods, this method has advantage in segmentation effect and computational efficiency. It can establish the technical basis for the pertinent subsequent studies.
C1 [Liu, Bin; Zhang, Xiaohui; Wang, Mingzhe] Dalian Univ Technol, DUT RU Inter Sch Informat Sci & Engn, Dalian 116620, Peoples R China.
   [Liu, Bin] Key Lab Ubiquitous Network & Serv Software Liaoni, Dalian 116620, Peoples R China.
   [Li, Fengqi] Dalian Univ Technol, Natl Demonstrat Sch Software, Dalian 116620, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology
RP Li, FQ (corresponding author), Dalian Univ Technol, Natl Demonstrat Sch Software, Dalian 116620, Peoples R China.
EM fengqili_dut@sina.com
RI Li, FengQi/HLQ-1543-2023
OI Li, FengQi/0000-0003-4056-548X
FU National Natural Science Foundation of China [61572101, 61300085];
   National Key Research and Development Program of China [2016YFB1101100];
   Scientific Research Fund of Liaoning Provincial Education Department of
   China [L2013012]
FX Many thanks to 'The Slow Mo Guys' and Youku for providing experimental
   slow-motion videos. This research is supported by the National Natural
   Science Foundation of China (Nos. 61572101, 61300085), the National Key
   Research and Development Program of China (No. 2016YFB1101100), the
   Scientific Research Fund of Liaoning Provincial Education Department of
   China (No. L2013012).
CR [Anonymous], ACOUST SPEECH SIG PR
   Babaguchi Noboru, 2000, ACM WORKSHOPS MULTIM, P205
   Bai Xue, 2009, ACM T GRAPH SIGGRAPH, V28
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cristani M, 2013, NEUROCOMPUTING, V100, P86, DOI 10.1016/j.neucom.2011.12.038
   Cyganek B, 2008, INT J NEURAL SYST, V18, P339, DOI 10.1142/S0129065708001646
   Dong Y, 2012, INFORM SYST FRONT, V14, P517, DOI 10.1007/s10796-010-9256-y
   Sánchez JLG, 2012, BEHAV INFORM TECHNOL, V31, P1033, DOI 10.1080/0144929X.2012.710648
   Gowsikhaa D, 2014, ARTIF INTELL REV, V42, P747, DOI 10.1007/s10462-012-9341-3
   Ikonomakis N, 2000, J INTELL ROBOT SYST, V28, P5, DOI 10.1023/A:1008163913937
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li HT, 2010, INT J REMOTE SENS, V31, P1453, DOI 10.1080/01431160903475266
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Minetto R, 2012, COMPUT VIS IMAGE UND, V116, P274, DOI 10.1016/j.cviu.2011.10.003
   Muller-Lietzkow J., 2012, International Journal of, V11, P42
   Nagano K., 2013, P ACM SIGGRAPH EMERG, V3
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Priese L., 2003, Introduction to the color structure code and its implementation
   Priese L., 1993, P IEEE INT VEH S 93, P95
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saha PK, 2000, COMPUT VIS IMAGE UND, V77, P145, DOI 10.1006/cviu.1999.0813
   Santos BS, 2011, IEEE COMPUT GRAPH, V31, P14, DOI 10.1109/MCG.2011.78
   Shapiro L. G., 2001, COMPUTER VISION
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Turk M, 2014, PATTERN RECOGN LETT, V36, P189, DOI 10.1016/j.patrec.2013.07.003
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   Udupa JK, 2003, P IEEE, V91, P1649, DOI 10.1109/JPROC.2003.817883
   VONWANGENHEIM A, 2008, J BRAZ COMPUT SOC, V14, P29
   Wang SQ, 2009, PROCEEDINGS OF THE 2009 CHINESE CONFERENCE ON PATTERN RECOGNITION AND THE FIRST CJK JOINT WORKSHOP ON PATTERN RECOGNITION, VOLS 1 AND 2, P1, DOI 10.1109/PLASMA.2009.5227540
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yu ZY, 2002, LECT NOTES COMPUT SC, V2352, P517
   Zhong Fan, 2012, ACM T GRAPH SIGGRAPH, V31
NR 36
TC 0
Z9 0
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 270
EP 318
DI 10.1016/j.jvcir.2018.06.013
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100024
DA 2024-07-18
ER

PT J
AU Morillas, S
   Fairchild, MD
AF Morillas, Samuel
   Fairchild, Mark D.
TI Using suprathreshold color-difference ellipsoids to estimate any
   perceptual color-difference
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color-difference formulas; Fuzzy logic; Fuzzy Metrics; STRESS
ID EXPERIMENTAL DATASETS; SURFACE COLORS; METRIC-SPACES; PERFORMANCE;
   APPEARANCE; CIEDE2000; FORMULA
AB Relating instrumentally measured to visually perceived colour-differences is one of the challenges of advanced colorimetry. Lately, the use of color difference formulas is becoming more important in the computer vision field as it is a key tool in advancing towards perceptual image processing and understanding. In the last decades, the study of contours of equal color-differences around certain color centers has been of special interest. In particular, the contour of threshold level difference that determines the just noticeable differences (JND) has been deeply studied and, as a result, a set of 19 different ellipsoids of suprathreshold color-difference is available in the literature. In this paper we study whether this set of ellipsoids could be used to compute any color difference in any region of the color space. To do so, we develop a fuzzy multi-ellipsoid model using the ellipsoids information along with two different metrics. We see that the performance of the two metrics vary significantly for very small, small, medium and large color differences. Therefore, we also study how to adapt two metric parameters to optimize performance. The obtained results outperform the currently CIE-recommended colordifference formula CIEDE2000.
C1 [Morillas, Samuel] Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Camino Vera S-N, E-46022 Valencia, Spain.
   [Fairchild, Mark D.] Rochester Inst Technol, Munsell Color Sci Lab, 1 Lomb Mem Dr, Rochester, NY 14623 USA.
C3 Universitat Politecnica de Valencia; Rochester Institute of Technology
RP Morillas, S (corresponding author), Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Camino Vera S-N, E-46022 Valencia, Spain.
EM smorillas@mat.upv.es
RI Morillas, Samuel/H-2610-2015
OI Morillas, Samuel/0000-0001-9262-6139
FU Ministerio de Educacion, Cultura y Deporte [PRX16/00050, PRX17/00384];
   MINECO/FEDER, UE [MTM2015-64373-13]
FX S. Morillas acknowledges the support of grants PRX16/00050 and
   PRX17/00384 (Ministerio de Educacion, Cultura y Deporte) and
   MTM2015-64373-13 (MINECO/FEDER, UE). The authors thank Dr. Manuel
   Melgosa, Dr. Luis Gomez-Robledo, Dr. Esther Sanabria-Codesal, Dr.
   Francisco Montserrat and Mr. Fu Jiang for providing useful materials,
   information and suggestions.
CR [Anonymous], 1998, FUZZY SETS APPROXIMA
   [Anonymous], 2001, CIE PUBLICATION
   [Anonymous], 2004, CIE PUBLICATION, V15
   Benavente R, 2008, J OPT SOC AM A, V25, P2582, DOI 10.1364/JOSAA.25.002582
   BERNS RS, 1991, COLOR RES APPL, V16, P297, DOI 10.1002/col.5080160505
   CHEUNG M, 1986, COLOR RES APPL, V11, P185, DOI 10.1002/col.5080110305
   Fairchild MD, 2004, J ELECTRON IMAGING, V13, P126, DOI 10.1117/1.1635368
   García PA, 2007, J OPT SOC AM A, V24, P1823, DOI 10.1364/JOSAA.24.001823
   GEORGE A, 1994, FUZZY SET SYST, V64, P395, DOI 10.1016/0165-0114(94)90162-7
   Grecova S, 2016, J VIS COMMUN IMAGE R, V34, P230, DOI 10.1016/j.jvcir.2015.04.003
   Gregori V, 2000, FUZZY SET SYST, V115, P477, DOI 10.1016/S0165-0114(98)00368-6
   Johnson GM, 2003, COLOR RES APPL, V28, P425, DOI 10.1002/col.10195
   Luo MR, 2006, COLOR RES APPL, V31, P320, DOI 10.1002/col.20227
   LUO MR, 1986, COLOR RES APPL, V11, P25, DOI 10.1002/col.5080110107
   MacAdam DL, 1942, J OPT SOC AM, V32, P247, DOI 10.1364/JOSA.32.000247
   Melgosa M, 1997, COLOR RES APPL, V22, P148, DOI 10.1002/(SICI)1520-6378(199706)22:3<148::AID-COL3>3.0.CO;2-R
   MELGOSA M, 1994, APPL OPTICS, V33, P8069, DOI 10.1364/AO.33.008069
   MELGOSA M, 1992, J OPT SOC AM A, V9, P1247, DOI 10.1364/JOSAA.9.001247
   Melgosa M, 2008, J OPT SOC AM A, V25, P1828, DOI 10.1364/JOSAA.25.001828
   Morillas S., 2007, THESIS
   Morillas S, 2016, J OPT SOC AM A, V33, P2289, DOI 10.1364/JOSAA.33.002289
   Morillas S, 2009, J MOD OPTIC, V56, P1447, DOI 10.1080/09500340902944038
   Oleari C, 2009, J OPT SOC AM A, V26, P121, DOI 10.1364/JOSAA.26.000121
   Shen SZ, 2009, COLOR RES APPL, V34, P375, DOI 10.1002/col.20521
NR 24
TC 3
Z9 3
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 142
EP 148
DI 10.1016/j.jvcir.2018.05.022
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100013
OA Green Published
DA 2024-07-18
ER

PT J
AU Tang, YZ
   Gao, Z
   Lin, F
   Li, YF
   Wen, F
AF Tang, Yazhe
   Gao, Zhi
   Lin, Feng
   Li, Y. F.
   Wen, Fei
TI Visual adaptive tracking for monocular omnidirectional camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Omnidirectional camera; Multi-feature integration
AB This paper presents a sophisticated patch-based visual tracking algorithm using an omnidirectional camera with distortion adaptation. The omnidirectional camera is modeled using the equivalent projection theory, so that a nonlinear deformed neighbourhood can be accurately estimated in the image plane, which significantly facilitates feature coding. In order to improve the omnidirectional tracking performance, a patch-based multi-feature matching method is proposed under a probability framework. In particular, the distributions of patches covering key parts of the target are weighted adaptively according to their joint-feature response, which is able to track target robustly and filter out the outliers effectively. Extensive experiments have been conducted to verify the performance of the proposed omnidirectional tracking algorithm, which obtains promising results on challenging datasets and outperforms many state-of-the-art methods.
C1 [Tang, Yazhe; Gao, Zhi; Lin, Feng] Natl Univ Singapore, Temasek Labs, Singapore 117411, Singapore.
   [Li, Y. F.] City Univ Hong Kong, Dept Mech & Biomet Enggn, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
   [Wen, Fei] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Hubei, Peoples R China.
C3 National University of Singapore; City University of Hong Kong; Wuhan
   University
RP Tang, YZ; Gao, Z (corresponding author), Natl Univ Singapore, Temasek Labs, Singapore 117411, Singapore.
EM yztang2008@yahoo.com; gaozhinus@gmail.com; linfeng@nus.edu.sg;
   meyfli@cityu.edu.hk; wenfei@whu.edu.cn
OI LI, You Fu/0000-0002-5227-1326
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2003 CVPRW 03 C COMP
   [Anonymous], COMPUT VISION IMAGE
   [Anonymous], BRIT MACH VIS C 2009
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Bazin JC, 2012, INT J ROBOT RES, V31, P63, DOI 10.1177/0278364911421954
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Boult TE, 2004, IMAGE VISION COMPUT, V22, P515, DOI 10.1016/j.imavis.2003.09.005
   Daniilidis K, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P3, DOI 10.1109/OMNVIS.2002.1044483
   Demonceaux C, 2006, PATTERN RECOGN LETT, V27, P1957, DOI 10.1016/j.patrec.2006.05.007
   Dou JF, 2014, NEUROCOMPUTING, V135, P118, DOI 10.1016/j.neucom.2013.12.049
   Erdem E, 2012, COMPUT VIS IMAGE UND, V116, P827, DOI 10.1016/j.cviu.2012.03.005
   Fang JW, 2014, IEEE T CIRC SYST VID, V24, P854, DOI 10.1109/TCSVT.2013.2283646
   Gandhi T, 2006, IEEE T INTELL TRANSP, V7, P293, DOI 10.1109/TITS.2006.880635
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hoy M., 2016, I C CONT AUTOMAT ROB, P1
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma L, 2015, IEEE I CONF COMP VIS, P3128, DOI 10.1109/ICCV.2015.358
   Makris A, 2013, IEEE T INTELL TRANSP, V14, P1896, DOI 10.1109/TITS.2013.2271113
   Maksai A, 2017, IEEE I CONF COMP VIS, P2563, DOI 10.1109/ICCV.2017.278
   Oron S, 2015, INT J COMPUT VISION, V111, P213, DOI 10.1007/s11263-014-0740-6
   Rameau F, 2011, ELECTRON LETT, V47, P1183, DOI 10.1049/el.2011.2838
   Spruyt V, 2010, IEEE IMAGE PROC, P3117, DOI 10.1109/ICIP.2010.5653220
   Svoboda T., 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P733
   Tang YZ, 2016, IEEE T AUTOM SCI ENG, V13, P743, DOI 10.1109/TASE.2015.2392160
   Tang YZ, 2015, APPL OPTICS, V54, P6969, DOI 10.1364/AO.54.006969
   Tarhan M, 2011, J INTELL ROBOT SYST, V61, P119, DOI 10.1007/s10846-010-9504-x
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhao L, 2015, IEEE T IMAGE PROCESS, V24, P5274, DOI 10.1109/TIP.2015.2473662
   Zhou XL, 2014, IEEE T IND INFORM, V10, P1064, DOI 10.1109/TII.2013.2294156
NR 35
TC 3
Z9 3
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 253
EP 262
DI 10.1016/j.jvcir.2018.06.015
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100022
DA 2024-07-18
ER

PT J
AU Yang, CN
   Wu, FH
   Peng, SL
AF Yang, Ching-Nung
   Wu, Fu-Heng
   Peng, Sheng-Lung
TI Enhancing multi-factor cheating prevention in visual cryptography based
   minimum (<i>k</i>, <i>n</i>)-connected graph
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Cheating attack; Cheating prevention; Verification
   image; Shadow image
ID SCHEMES; CONSTRUCTIONS
AB Recently, Lin et al. [29] introduced a (k, n) multi-factor cheating prevention visual cryptographic scheme (MCPVCS) by hiding verification images into shadow images. Through authenticating the verification image and the reconstructed image simultaneously, Lin et al.'s MCPVCS can prevent cheating attack that dishonest participants may collude and cheat the honest one to get a wrong secret image. However, the large n reduces the size of verification image and makes the verification difficult. In this paper, a (k, n)-MCPVCS with the large size of verification image is proposed. There are three main contributions for the proposed (k, n)-MCPVCS: (i) the verification condition in (k, n)-MCPVCS is redefined, (ii) a new minimum (k, n)-connected graph problem is introduced, on which the minimum number of verification images is determined, and (iii) the proposed (k, n).MCPVCS with the large size of verification image can more easily authenticate the unambiguity of verification image.
C1 [Yang, Ching-Nung; Wu, Fu-Heng; Peng, Sheng-Lung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, 1,Sec 2,Hsueh Rd, Hualien, Taiwan.
C3 National Dong Hwa University
RP Yang, CN (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, 1,Sec 2,Hsueh Rd, Hualien, Taiwan.
EM cnyang@gms.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
FU Ministry of Science and Technology [105-2221-E-259-015-MY2]
FX This research was supported in part by Ministry of Science and
   Technology, under Grant 105-2221-E-259-015-MY2.
CR Chen YC, 2017, IEEE T INF FOREN SEC, V12, P1082, DOI 10.1109/TIFS.2016.2641378
   Ching-Nung Yang, 2016, ICISSP 2016. 2nd International Conference on Information Systems Security and Privacy. Proceedings, P400
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   De Prisco R, 2010, COMPUT J, V53, P1485, DOI 10.1093/comjnl/bxp068
   Diestel R, 2010, GRADUATE TEXTS MATH, P22
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Kuwakado H, 2004, IEICE T FUND ELECTR, VE87A, P1193
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin CH, 2014, J VIS COMMUN IMAGE R, V25, P1543, DOI 10.1016/j.jvcir.2014.06.011
   Lin PY, 2015, INFORM SCIENCES, V301, P61, DOI 10.1016/j.ins.2014.12.046
   Liu F, 2011, IET INFORM SECUR, V5, P51, DOI 10.1049/iet-ifs.2008.0064
   Monoth T, 2010, PROCEDIA COMPUT SCI, V2, P143, DOI 10.1016/j.procs.2010.11.018
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shyu SJ, 2018, IEEE T CIRC SYST VID, V28, P2397, DOI 10.1109/TCSVT.2017.2707923
   Shyu SJ, 2013, IEEE T INF FOREN SEC, V8, P733, DOI 10.1109/TIFS.2013.2250432
   Surekha B., 2010, COMPUT APPL, V1, P77
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Wan S, 2018, J REAL-TIME IMAGE PR, V14, P25, DOI 10.1007/s11554-017-0678-3
   Wang DS, 2011, INFORM SCIENCES, V181, P2189, DOI 10.1016/j.ins.2011.01.019
   Weir J, 2010, IEEE INT SYMP CIRC S, P1695, DOI 10.1109/ISCAS.2010.5537511
   Yang C.-N., 1999, NATL COMPUTER S, V3, P260
   Yang CN, 2019, IEEE T CIRC SYST VID, V29, P252, DOI 10.1109/TCSVT.2017.2771255
   Yang CN, 2017, J VIS COMMUN IMAGE R, V48, P182, DOI 10.1016/j.jvcir.2017.06.012
   Yang CN, 2015, INFORM SCIENCES, V312, P131, DOI 10.1016/j.ins.2015.03.024
   Yang CN, 2014, INFORM SCIENCES, V271, P246, DOI 10.1016/j.ins.2014.02.099
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 31
TC 9
Z9 9
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 660
EP 676
DI 10.1016/j.jvcir.2018.07.012
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100057
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Tseng, WY
   Kang, LW
   Lee, CW
   Muchtar, K
   Chen, MJ
AF Yeh, Chia-Hung
   Tseng, Wen-Yu
   Kang, Li-Wei
   Lee, Cheng-Wei
   Muchtar, Kahlil
   Chen, Mei-Juan
TI Coding unit complexity-based predictions of coding unit depth and
   prediction unit mode for efficient HEVC-to-SHVC transcoding with quality
   scalability
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HEVC (high efficiency video coding); SHVC (scalability extension of
   HEVC); Video transcoding; Scalable video coding; Early termination;
   Coding unit complexity
ID VIDEO COMPRESSION; SCALABLE HEVC; STANDARD; H.264/AVC; DECISION;
   EXTENSIONS; ENCODERS; SIZE
AB To support good video quality of experiences in heterogeneous environments, transcoding an existed HEVC (high efficiency video coding) video bitstream to a SHVC (scalability extension of HEVC) bitstream with quality scalability is highly required. A straightforward way is to first fully decode the input HEVC bitstream and then fully re-encode it with the SHVC encoder, which requires a tremendous computational complexity. To solve the problem, in this paper, a coding unit complexity (CUC)-based prediction method for predictions of CU (coding unit) depth and PU (prediction unit) mode for efficient HEVC-to-SHVC transcoding with quality scalability is proposed to significantly reduce the transcoding complexity. The proposed method contains two prediction techniques, including (i) early termination and (ii) adaptive confidence interval, and predicts the CU depth and PU mode relying on the decoded information from the input HEVC bitstream. Experimental results have shown that the proposed method significantly outperforms the traditional HEVC-to-SHVC method by 74.14% on average in reductions of encoding time for SHVC enhancement layer.
C1 [Yeh, Chia-Hung] Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.
   [Yeh, Chia-Hung; Tseng, Wen-Yu; Lee, Cheng-Wei] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
   [Kang, Li-Wei] Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol Doctoral Program, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.
   [Kang, Li-Wei] Natl Yunlin Univ Sci & Technol, Artificial Intelligence Recognit Ind Serv Res Ctr, Touliu, Yunlin, Taiwan.
   [Muchtar, Kahlil] Syiah Kuala Univ, Dept Elect & Comp Engn, Aceh, Indonesia.
   [Muchtar, Kahlil] Nodeflux Inc, Jakarta, Indonesia.
   [Chen, Mei-Juan] Natl Dong Hwa Univ, Dept Elect Engn, Hualien, Taiwan.
C3 National Taiwan Normal University; National Sun Yat Sen University;
   National Yunlin University Science & Technology; National Yunlin
   University Science & Technology; Universitas Syiah Kuala; National Dong
   Hwa University
RP Kang, LW (corresponding author), Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol Doctoral Program, Dept Comp Sci & Informat Engn, Touliu, Yunlin, Taiwan.; Kang, LW (corresponding author), Natl Yunlin Univ Sci & Technol, Artificial Intelligence Recognit Ind Serv Res Ctr, Touliu, Yunlin, Taiwan.
EM lwkang@yuntech.edu.tw
RI Muchtar, Kahlil/P-8532-2019
OI Muchtar, Kahlil/0000-0001-5740-1938; Chen, Mei-Juan/0000-0003-3382-8296
FU Ministry of Science and Technology, Taiwan [NSC 102-2221-E-110-032-MY3,
   MOST 103-2221-E-110-045-MY3, MOST 103-2221-E-003-034-MY3, MOST
   105-2221-E-003-030-MY3, MOST 105-2628-E-224-001-MY3]; "Artificial
   Intelligence Recognition Industry Service Research Center" from The
   Featured Areas Research Center Program by the Ministry of Education
   (MOE) in Taiwan [107-N04-2]
FX This work was supported in part by Ministry of Science and Technology,
   Taiwan, under the Grants NSC 102-2221-E-110-032-MY3, MOST
   103-2221-E-110-045-MY3, MOST 103-2221-E-003-034-MY3, MOST
   105-2221-E-003-030-MY3, and MOST 105-2628-E-224-001-MY3. This work was
   also financially supported by the "Artificial Intelligence Recognition
   Industry Service Research Center (Project No.107-N04-2)" from The
   Featured Areas Research Center Program within the framework of the
   Higher Education Sprout Project by the Ministry of Education (MOE) in
   Taiwan.
CR [Anonymous], 2017, 26948 3GPP TR
   [Anonymous], 2014, SHVC REFERENCE SOFTW
   [Anonymous], 2012, JCTVCH0022 AHG
   Bjontegaard G., 2001, Q6SG16 ITUT VCEG
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Choi K, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.3.030502
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Côté G, 1998, IEEE T CIRC SYST VID, V8, P849, DOI 10.1109/76.735381
   De Cock J, 2009, IEEE T MULTIMEDIA, V11, P1209, DOI 10.1109/TMM.2009.2030606
   Garrido-Cantos R, 2016, MULTIMED TOOLS APPL, V75, P497, DOI 10.1007/s11042-014-2302-x
   Gudumasu S, 2015, PROC SPIE, V9599, DOI 10.1117/12.2186866
   Gweon RH, 2012, IEICE T FUND ELECTR, VE95A, P1215, DOI 10.1587/transfun.E95.A.1215
   Hagg R., 2015, SCALABLE HIGH EFFICI
   Huang Y.-C., 2012, P IEEE INT C ITS TEL
   Kim HS, 2016, IEEE T CIRC SYST VID, V26, P130, DOI 10.1109/TCSVT.2015.2444672
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   LEGALL D, 1991, COMMUN ACM, V34, P46, DOI 10.1145/103085.103090
   Li XN, 2017, MULTIMED TOOLS APPL, V76, P8011, DOI 10.1007/s11042-016-3460-9
   Lin CW, 2013, IEEE J-STSP, V7, P1084, DOI 10.1109/JSTSP.2013.2273659
   Netravali A. N, 1996, Digital video: an introduction to MPEG-2
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Pourazad MT, 2012, IEEE CONSUM ELECTR M, V1, P36, DOI 10.1109/MCE.2012.2192754
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sharabayko MP, 2014, ENTROPY-SWITZ, V16, P6667, DOI 10.3390/e16126667
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sikora T, 1997, IEEE T CIRC SYST VID, V7, P19, DOI 10.1109/76.554415
   Sole J., 2012, IEEE T CIRCUITS SYST, V22, P1765
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tohidypour HR, 2017, IEEE T CIRC SYST VID, V27, P2204, DOI 10.1109/TCSVT.2016.2576738
   Tohidypour HR, 2016, IEEE T BROADCAST, V62, P664, DOI 10.1109/TBC.2016.2576600
   Tohidypour HR, 2016, IEEE T MULTIMEDIA, V18, P182, DOI 10.1109/TMM.2015.2510332
   Turletti T., 1993, RR1834 INRIA
   Van Leuven S, 2013, IEEE T CONSUM ELECTR, V59, P672, DOI 10.1109/TCE.2013.6626255
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Yeh CH, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-204
   Zhang XG, 2013, IEEE T MULTIMEDIA, V15, P1769, DOI 10.1109/TMM.2013.2280117
NR 41
TC 3
Z9 3
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 342
EP 351
DI 10.1016/j.jvcir.2018.06.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100027
DA 2024-07-18
ER

PT J
AU Zhang, JJ
   Shao, K
   Luo, X
AF Zhang, Jiajia
   Shao, Kun
   Luo, Xing
TI Small sample image recognition using improved Convolutional Neural
   Network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image recognition; Convolutional Neural Network (CNN); General
   Regression Neural Network (GRNN); Small sample; Real-time
ID MODEL
AB In recent years, with the raise of the neural network and deep learning, significant progress has been achieved in the field of image recognition. Convolutional Neural Network (CNN) has been widely used in multiple image recognition tasks, but the recognition accuracy still has a lot of room for improvement. In this paper, we proposed a hybrid model CNN-GRNN to improve recognition accuracy. The model uses CNN to extract multilayer image representation and it uses General Regression Neural Network (GRNN) to classify image using the extracted feature. The CNN-GRNN model replace Back propagation (BP) neural network inside CNN with GRNN to improve generalization and robustness of CNN. Furthermore, we validate our model on the Oxford-IIIT Pet Dataset database and the Keck Gesture Dataset, the experiment result indicate that our model is superior to Gray Level Co-occurrency (GLCM),HU invariant moments, CNN and CNN_SVM on small sample dataset. Our model has favorable real-time characteristic at the same time.
C1 [Zhang, Jiajia; Shao, Kun; Luo, Xing] Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Zhang, JJ (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei, Anhui, Peoples R China.
EM 1293742589@qq.com
FU National Natural Science Foundation of China [61672201]
FX This work is partially supported by National Natural Science Foundation
   of China (61672201).
CR Chen YX, 2016, INFORM SCIENCES, V372, P148, DOI 10.1016/j.ins.2016.08.050
   Chen YX, 2015, INFORM SCIENCES, V320, P361, DOI 10.1016/j.ins.2015.03.023
   Chen YX, 2014, IEEE T CIRC SYST VID, V24, P1992, DOI 10.1109/TCSVT.2014.2329380
   Fu MY, 2014, CHIN CONTR CONF, P670, DOI 10.1109/ChiCC.2014.6896705
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Hong Richang, 2015, IEEE T BIG DATA, V1
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Niu XX, 2012, PATTERN RECOGN, V45, P1318, DOI 10.1016/j.patcog.2011.09.021
   Shen XJ, 2017, IET IMAGE PROCESS, V11, P44, DOI 10.1049/iet-ipr.2016.0238
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Tivive F.H.C., 2006, 8 INT S SIGN PROC IT, P90
   Tivive FHC, 2003, IEEE IJCNN, P2157
   Yu SD, 2017, LECT NOTES COMPUT SC, V10116, P50, DOI 10.1007/978-3-319-54407-6_4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zheng H., 2017, INT C GEOSP KNOWL IN, P2
NR 29
TC 39
Z9 41
U1 7
U2 95
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 640
EP 647
DI 10.1016/j.jvcir.2018.07.011
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100054
DA 2024-07-18
ER

PT J
AU Zheng, WW
   Yu, HM
   Huang, W
AF Zheng, Weiwei
   Yu, Huimin
   Huang, Wei
TI Visual tracking via Graph Regularized Kernel Correlation Filer and
   Multi-Memory Voting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual object tracking; Graph Regularized Kernel Correlation Filer;
   Multi-Memory Voting; Drift handling
ID OBJECT TRACKING; SYSTEM
AB Correlation filter based tracking approach has been an important branch of visual tracking. However, most correlation filter based trackers fail to work under occlusion due to their frame-by-frame model update strategy, and the tracking performance can be further enhanced by optimizing the energy equation. The target appearance during tracking is nearly moving on a manifold. So, the classification scores should be similar on the target manifold. K Nearest Neighbor graphs are constructed and the classification scores on the neighborhood are regularized to have similar values. Through the local score propagation on the graph, the learned Graph Regularized Kernel Correlation Filer can represent different appearances of the object. Furthermore, in the proposed Multi-Memory Voting scheme, occlusion problem is addressed by voting from multiple target snapshots in the memory pool. An extensive evaluation on two recent benchmarks shows that the proposed tracker achieves competitive performance compared to nine other state-of-the-art trackers. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zheng, Weiwei; Yu, Huimin; Huang, Wei] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Yu, HM (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Zhejiang, Peoples R China.
EM yhm2005@zju.edu.cn
FU National Natural Science Foundation of China [61471321]; Zhejiang
   Science and Technology Plan [2017C31023]; Ministry of Education-China
   Mobile Research Fund [MCM20150 503]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61471321, the Zhejiang Science and Technology Plan
   under Grant 2017C31023, and the Ministry of Education-China Mobile
   Research Fund under Grant MCM20150 503.
CR Alfalou A, 2015, PROG OPTICS, V60, P119, DOI 10.1016/bs.po.2015.02.002
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2014, P BMVC
   [Anonymous], 2016, CVPR
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bai QX, 2013, IEEE I CONF COMP VIS, P2040, DOI 10.1109/ICCV.2013.255
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Benarab D, 2017, OPT LASER ENG, V89, P195, DOI 10.1016/j.optlaseng.2016.05.013
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bouzidi F, 2016, OPT COMMUN, V358, P132, DOI 10.1016/j.optcom.2015.09.022
   Chawla S, 2018, P 18 INT C MACH LEAR, P2143
   Danelljan M., 2017, CVPR, P21
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Li CG, 2015, PROC CVPR IEEE, P277, DOI 10.1109/CVPR.2015.7298624
   Li X, 2013, PROC CVPR IEEE, P2419, DOI 10.1109/CVPR.2013.313
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Ma L, 2015, IEEE I CONF COMP VIS, P4301, DOI 10.1109/ICCV.2015.489
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Napoléon T, 2017, OPT LASER ENG, V89, P150, DOI 10.1016/j.optlaseng.2016.06.019
   Ning J., 2016, 2016 IEEE C COMP VIS
   Ouerhani Y, 2017, OPT LASER ENG, V89, P184, DOI 10.1016/j.optlaseng.2016.05.020
   Sindhwani V., 2005, ICML, V2005, P74
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wang Q, 2017, ADV OPT PHOTONICS, V9, P1, DOI 10.1364/AOP.9.000001
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhang TZ, 2014, PROC CVPR IEEE, P1258, DOI 10.1109/CVPR.2014.164
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
NR 40
TC 2
Z9 2
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 688
EP 697
DI 10.1016/j.jvcir.2018.08.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100059
DA 2024-07-18
ER

PT J
AU Zhou, XF
   Liu, Z
   Li, K
   Sun, GL
AF Zhou, Xiaofei
   Liu, Zhi
   Li, Kai
   Sun, Guangling
TI Video saliency detection via bagging-based prediction and spatiotemporal
   propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatiotemporal saliency; Unconstrained video; Bagging; Prediction;
   Propagation
ID VISUAL-ATTENTION; LOW-RANK; OBJECT DETECTION; DETECTION MODEL;
   LOW-LEVEL; IMAGE; CONTRAST; TRACKING
AB The task of spatiotemporal saliency detection is to distinguish the salient objects from background across all the frames in the video. Although many spatiotemporal models have been designed from various aspects, it is still a very challenging task for handing the unconstrained videos with complicated motions and complex scenes. Therefore, in this paper we propose a novel spatiotemporal saliency model to estimate salient objects in unconstrained videos. Specifically, a bagging-based saliency prediction model, i.e. an ensembling regressor, which is the combination of random forest regressors learned from undersampled training sets, is first used to perform saliency prediction for each current frame. Then, both forward and backward propagation within a local temporal window are deployed on each current frame to make a complement to the predicted saliency map and yield the temporal saliency map, in which the backward propagation is constructed based on the temporary saliency estimation of the following frames. Finally, by building the appearance and motion based graphs in a parallel way, spatial propagation is employed over the temporal saliency map to generate the final spatiotemporal saliency map. Through experiments on two challenging datasets, the proposed model consistently outperforms the state-of-the-art models for popping out salient objects in unconstrained videos.
C1 [Zhou, Xiaofei; Liu, Zhi; Li, Kai] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Zhou, Xiaofei; Liu, Zhi; Li, Kai; Sun, Guangling] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI LIU, Zhi/D-4518-2012; Xiaofei, Zhou/AAE-8347-2020
OI LIU, Zhi/0000-0002-8428-1131; 
FU National Natural Science Foundation of China [61471230, 61601278];
   Shanghai Municipal Natural Science Foundation [16ZR1411100]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61471230 and No. 61601278, and by Shanghai
   Municipal Natural Science Foundation under Grant No. 16ZR1411100.
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], P ACM ICMR
   [Anonymous], 2017, INT C HUM COMP INT
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE T PATTERN ANAL, DOI DOI 10.1007/978-3-642-14267-3_2
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2008, NIPS
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Cao P., 2013, PROC IEEE IJCNN, P1
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cui Xinyi, 2009, P 17 ACM INT C MULT, P617, DOI DOI 10.1145/1631272.1631370
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Gao D., 2008, Advances in Neural Information Processing Systems 20, P497
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Gopalakrishnan V, 2012, IEEE T CIRC SYST VID, V22, P683, DOI 10.1109/TCSVT.2011.2177177
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang CR, 2014, IEEE T CIRC SYST VID, V24, P1336, DOI 10.1109/TCSVT.2014.2308652
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim H, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2425544
   Kim W, 2014, IEEE T CIRC SYST VID, V24, P646, DOI 10.1109/TCSVT.2013.2290579
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Le Meur O, 2016, VISION RES, V121, P72, DOI 10.1016/j.visres.2016.01.005
   Le Meur O, 2015, VISION RES, V116, P152, DOI 10.1016/j.visres.2014.12.026
   Lee WF, 2011, IEEE T IMAGE PROCESS, V20, P3028, DOI 10.1109/TIP.2011.2144610
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Li JH, 2015, SIGNAL PROCESS-IMAGE, V38, P100, DOI 10.1016/j.image.2015.04.014
   Li Q, 2012, COMM COM INF SC, V321, P178
   Li WT, 2013, IEEE T IMAGE PROCESS, V22, P2600, DOI 10.1109/TIP.2013.2253483
   Li YB, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION IN COMMUNICATION, P246, DOI 10.1109/ICASID.2009.5276913
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Lin YW, 2013, IEEE T PATTERN ANAL, V35, P314, DOI 10.1109/TPAMI.2012.119
   Liu C, 2009, PATTERN RECOGN, V42, P2897, DOI 10.1016/j.patcog.2009.02.002
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Lu HC, 2017, IEEE T IMAGE PROCESS, V26, P414, DOI 10.1109/TIP.2016.2627804
   Luo Y., 2012, P IEEE COMP SOC C CO, P33
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mahapatra D, 2014, IEEE J-STSP, V8, P454, DOI 10.1109/JSTSP.2014.2315874
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Muthuswamy K, 2013, IEEE SIGNAL PROC LET, V20, P996, DOI 10.1109/LSP.2013.2277884
   Muthuswamy K, 2012, INT CONF ACOUST SPEE, P1465, DOI 10.1109/ICASSP.2012.6288167
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Ren JR, 2018, J VIS COMMUN IMAGE R, V50, P227, DOI 10.1016/j.jvcir.2017.12.002
   Ren ZX, 2013, IEEE T IMAGE PROCESS, V22, P3120, DOI 10.1109/TIP.2013.2259837
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi R, 2012, IEEE SIGNAL PROC LET, V19, P215, DOI 10.1109/LSP.2012.2188388
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2012, IEEE T PATTERN ANAL, V34, P1080, DOI 10.1109/TPAMI.2011.198
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yuan Z, 2012, IEEE T CIRC SYST VID, V22, P890, DOI 10.1109/TCSVT.2011.2181230
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
NR 82
TC 16
Z9 16
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 131
EP 143
DI 10.1016/j.jvcir.2018.01.014
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500013
DA 2024-07-18
ER

PT J
AU Kuo, CCJ
   Chen, YR
AF Kuo, C. -C. Jay
   Chen, Yueru
TI On data-driven Saak transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data-driven transform; RECOS transform; Saak transform; The
   Karhunen-Loeve transform (KLT); Linear subspace approximation; Principal
   component analysis
ID NEURAL-NETWORKS
AB Being motivated by the multilayer RECOS (REctified-COrrelations on a Sphere) transform, we develop a data driven Saak (Subspace approximation with augmented kernels) transform in this work. The Saak transform consists of three steps: (1) building the optimal linear subspace approximation with orthonormal bases using the second-order statistics of input vectors, (2) augmenting each transform kernel with its negative, (3) applying the rectified linear unit (ReLU) to the transform output. The Karhunen-Loeve transform (KLT) is used in the first step. The integration of Steps 2 and 3 is powerful since they resolve the sign confusion problem, remove the rectification loss and allow a straightforward implementation of the inverse Saak transform at the same time. Multiple Saak transforms are cascaded to transform images of a larger size. All Saak transform kernels are derived from the second-order statistics of input random vectors in a one-pass feedforward manner. Neither data labels nor backpropagation is used in kernel determination. Multi-stage Saak transforms offer a family of joint spatial-spectral representations between two extremes; namely, the full spatial-domain representation and the full spectral-domain representation. We select Saak coefficients of higher discriminant power to form a feature vector for pattern recognition, and use the MNIST dataset classification problem as an illustrative example.
C1 [Kuo, C. -C. Jay; Chen, Yueru] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Kuo, CCJ (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM cckuo@sipi.usc.edu
RI Chen, Yueru/GWC-9924-2022; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU DARPA; Air Force Research Laboratory (AFRL) [FA8750-16-2-0173]; National
   Heart Lung Institute [R01HL129727]
FX This material is partially based on research sponsored by DARPA and Air
   Force Research Laboratory (AFRL) under agreement number
   FA8750-16-2-0173. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purposes notwithstanding any
   copyright notation thereon. The views and conclusions contained herein
   are those of the authors and should not be interpreted as necessarily
   representing the official policies or endorsements, either expressed or
   implied, of DARPA and Air Force Research Laboratory (AFRL) or the U.S.
   Government. This project was also partially supported by the National
   Heart Lung Institute (R01HL129727) (T.K.H.).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], GENERATIVE MODELING
   [Anonymous], TECH REP
   [Anonymous], 1986, Probability, random processes, and estimation theory for engineers
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Cohen Nadav., On the Expressive Power of Deep Learning: A Tensor Analysis
   Cybenko G., 1989, Mathematics of Control, Signals, and Systems, V2, P303, DOI 10.1007/BF02551274
   Donahue J, 2014, PR MACH LEARN RES, V32
   Ganin Y., 2015, ICML
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   GRUBBS FE, 1950, ANN MATH STAT, V21, P27, DOI 10.1214/aoms/1177729885
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   JARQUE CM, 1987, INT STAT REV, V55, P163, DOI 10.2307/1403192
   Juang BH, 2016, APSIPA TRANS SIGNAL, V5, DOI 10.1017/ATSIP.2016.9
   Kingma DP, 2013, ARXIV
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Montavon G., Explaining NonLinear Classification Decisions with Deep Taylor Decomposition
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Soltanolkotabi M., THEORETICAL INSIGHTS
   Sulam J., MULTILAYER CONVOLUTI
   Wiatowski T., MATH THEORY DEEP CON
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou Bolei., 2014, Object detectors emerge in deep scene cnns
NR 29
TC 56
Z9 57
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 237
EP 246
DI 10.1016/j.jvcir.2017.11.023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700024
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Wang, LF
AF Pan, Zhibin
   Wang, Lingfei
TI Novel reversible data hiding scheme for Two-stage VQ compressed images
   based on search-order coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding (RDH); Vector quantization (VQ); Side-match
   vector quantization (SMVQ); SOC (Search-order coding); Two-stage VQ;
   Difference image
ID VECTOR QUANTIZATION; WATERMARKING ALGORITHM; STEGANOGRAPHIC SCHEME;
   MULTI-WATERMARKING; SMVQ INDEXES; SIDE-MATCH; EFFICIENT; MECHANISM
AB In this paper, a novel reversible data hiding scheme for Two-stage VQ (Vector quantization) compressed images based on SOC (Search-order coding) scheme is proposed. Two-stage VQ improves VQ by obtaining better reconstructed image and generating indices with higher correlation. The difference image, as the input of Two stage VQ, is produced by employing the first codeword in state codebook and the current image block. The main idea of SOC method is exploiting the correlation of indices to derive better compression performance. The combination of SOC and data hiding can achieve both high compression rate and high embedding capacity. Since Two-stage VQ can achieve indices with higher correlation, this advantage is applied to enhance the data hiding performance. Moreover, the cover image can be reconstructed by the receiver without using any side information. To show the superiority of our proposed scheme, several state-of-the-art schemes designed for compression domain are cited for comparison.
C1 [Pan, Zhibin; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Pan, Zhibin] Inst Zhejiang Prov, Xian, Shaanxi, Peoples R China.
   [Pan, Zhibin] Xi An Jiao Tong Univ, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Priority Academic Program Development of Jiangsu Higher Education
   Institutions (PAPD); Industrial Program of Zhejiang Province
   [2016C31G4180003]; Open Research Fund of Key Laboratory of Spectral
   Imaging Technology, Chinese Academy of Sciences [LSIT201606D]; Key
   Science and Technology Program of Shaanxi Province [2016GY-097]
FX This work is supported in part by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions (PAPD), the
   Industrial Program of Zhejiang Province (Grant No. 2016C31G4180003), the
   Open Research Fund of Key Laboratory of Spectral Imaging Technology,
   Chinese Academy of Sciences (Grant No. LSIT201606D) and the Key Science
   and Technology Program of Shaanxi Province (Grant No. 2016GY-097).
CR Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chang CC, 2012, INFORM SCIENCES, V201, P70, DOI 10.1016/j.ins.2011.12.025
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Huang HC, 2002, IEICE T FUND ELECTR, VE85A, P1719
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Kieu TD, 2015, EXPERT SYST APPL, V42, P713, DOI 10.1016/j.eswa.2014.09.001
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee CF, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1293, DOI 10.1109/IIH-MSP.2008.200
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Ma XX, 2015, J VIS COMMUN IMAGE R, V30, P191, DOI 10.1016/j.jvcir.2015.04.009
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ou B, 2015, SIGNAL PROCESS, V108, P642, DOI 10.1016/j.sigpro.2014.10.012
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Shie SC, 2012, SIGNAL PROCESS, V92, P2332, DOI 10.1016/j.sigpro.2012.02.023
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang LF, 2014, J VIS COMMUN IMAGE R, V25, P454, DOI 10.1016/j.jvcir.2013.12.004
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Xin Z, 2007, OPT LASER TECHNOL, V39, P1360, DOI 10.1016/j.optlastec.2006.11.002
   Xiong L, 2017, MULTIDIMENSION SYST
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 37
TC 10
Z9 11
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 186
EP 198
DI 10.1016/j.jvcir.2017.11.020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700019
DA 2024-07-18
ER

PT J
AU Dubey, SR
   Singh, SK
   Singh, RK
AF Dubey, Shiv Ram
   Singh, Satish Kumar
   Singh, Rajat Kumar
TI Local SVD based NIR face retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local features; Near-infrared face image; Face retrieval; Singular value
   decomposition; Local binary pattern
ID SINGULAR-VALUE DECOMPOSITION; CT IMAGE RETRIEVAL; FEATURE DESCRIPTOR;
   BINARY PATTERNS; RECOGNITION; ROTATION; SCALE
AB From last decade, local descriptor such as Local Binary Pattern (LBP) is accepted as a very prominent feature descriptor for characterizing the images such as faces. The performance of such descriptors depends upon the local relationship of the image. The local relationship of the image can be utilized in more discriminative and robust way after some preprocessing as compared to the original image. The preprocessed images in the form of 4 sub-bands (i.e. S, U, V, and D sub-bands) are obtained by applying the Singular Value Decomposition (SVD) over the original image. The local descriptors are computed over these sub-bands (mainly S sub-band) and termed as the SVD based local descriptors. The performance of four local descriptors over SVD sub-bands are tested for near-infrared face retrieval using PolyU-NIR and CASIA-NIR face databases, and compared with the results obtained using descriptors without SVD sub-band. The experimental results confirm the superiority of using S sub-band of SVD in terms of performance of the local descriptors over NIR face databases. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Dubey, Shiv Ram] Indian Inst Informat Technol Chittoor, Sri City, India.
   [Singh, Satish Kumar; Singh, Rajat Kumar] Indian Inst Informat Technol Allahabad, Allahabad, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Allahabad
RP Dubey, SR (corresponding author), Indian Inst Informat Technol Chittoor, Sri City, India.
EM shivram1987@gmail.com
RI Singh, Dr Satish Kumar/JMP-6186-2023; singh, satish/U-7158-2018; Dubey,
   Shiv Ram/T-7541-2019
OI Singh, Dr Satish Kumar/0000-0003-1991-7727; singh,
   satish/0000-0002-8536-4991; Dubey, Shiv Ram/0000-0002-4532-8996
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   Bhatnagar G, 2014, INFORM SCIENCES, V277, P247, DOI 10.1016/j.ins.2014.02.018
   Chai ZH, 2014, IEEE T INF FOREN SEC, V9, P14, DOI 10.1109/TIFS.2013.2290064
   Chandar K. P., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P051, DOI 10.1109/RAICS.2011.6069271
   Dubey SR, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2577887
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Dubey SR, 2015, COMPUT ELECTR ENG, V46, P288, DOI 10.1016/j.compeleceng.2015.04.011
   Dubey SR, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493446
   Dubey SR, 2015, IET IMAGE PROCESS, V9, P578, DOI 10.1049/iet-ipr.2014.0769
   Dubey SR, 2015, MULTIMED TOOLS APPL, V74, P11223, DOI 10.1007/s11042-014-2226-5
   Dubey SR, 2015, IEEE SIGNAL PROC LET, V22, P1215, DOI 10.1109/LSP.2015.2392623
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Gao J., 2012, WSEAS T MATH, V11, P728
   Gao JQ, 2013, INT J AP MAT COM-POL, V23, P887, DOI 10.2478/amcs-2013-0066
   Gao JQ, 2013, APPL MATH COMPUT, V219, P6410, DOI 10.1016/j.amc.2013.01.005
   Gul G, 2010, IEEE T INF FOREN SEC, V5, P349, DOI 10.1109/TIFS.2010.2041826
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hollingsworth KP, 2012, IEEE T INF FOREN SEC, V7, P588, DOI 10.1109/TIFS.2011.2173932
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Nguyen TT, 2015, IEEE T INF FOREN SEC, V10, P1739, DOI 10.1109/TIFS.2015.2426144
   Jeong K, 2015, IEEE SIGNAL PROC LET, V22, P1400, DOI 10.1109/LSP.2014.2372762
   Jianqiang Gao, 2011, WSEAS Transactions on Mathematics, V10, P358
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Kim W, 2014, IEEE SIGNAL PROC LET, V21, P1336, DOI 10.1109/LSP.2014.2334656
   Konda T, 2009, PARALLEL COMPUT, V35, P331, DOI 10.1016/j.parco.2009.02.001
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   Li L, 2016, OPTIK, V127, P7408, DOI 10.1016/j.ijleo.2016.05.105
   Li L, 2016, AEU-INT J ELECTRON C, V70, P920, DOI 10.1016/j.aeue.2016.04.007
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu K, 2015, IEEE T IMAGE PROCESS, V24, P1449, DOI 10.1109/TIP.2015.2395961
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pang YW, 2009, IEEE T INF FOREN SEC, V4, P441, DOI 10.1109/TIFS.2009.2026455
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Ren JF, 2014, IEEE SIGNAL PROC LET, V21, P1346, DOI 10.1109/LSP.2014.2336252
   Sao AK, 2007, IEEE T INF FOREN SEC, V2, P636, DOI 10.1109/TIFS.2007.902920
   Singh SK, 2011, PERTANIKA J SCI TECH, V19, P229
   Singh SK, 2009, UKSIM EURO SYMP COMP, P235, DOI 10.1109/EMS.2009.100
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866
   Wei S, 2012, IEEE T INF FOREN SEC, V7, P765, DOI 10.1109/TIFS.2011.2181500
   YANG JF, 1995, IEEE T IMAGE PROCESS, V4, P1141, DOI 10.1109/83.403419
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Zhang BC, 2010, PATTERN RECOGN LETT, V31, P2337, DOI 10.1016/j.patrec.2010.07.006
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
NR 53
TC 12
Z9 15
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 141
EP 152
DI 10.1016/j.jvcir.2017.09.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800012
DA 2024-07-18
ER

PT J
AU Jing, M
   Scotney, B
   Coleman, S
   McGinnity, TM
AF Jing, Min
   Scotney, Bryan
   Coleman, Sonya
   McGinnity, T. Martin
TI Novel "Squiral" (square spiral) architecture for fast image processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Square spiral ("squiral") image processing (SIP); Spiral addressing
   scheme; Eye tremor; Non-overlapping convolution; Fast image processing
ID MULTISCALE DIFFERENTIAL-OPERATORS; TRANSFORMATIONS
AB Fast image processing is a key element in achieving real-time image and video analysis. We propose a novel framework based on a square spiral (denoted as "squiral") architecture to facilitate fast image processing. Unlike conventional image pixel addressing schemes, where the pixel indices are based on two-dimensional Cartesian coordinates, the spiral addressing scheme enables the image pixel indices to be stored in a one dimensional vector, thereby accelerating the subsequent processing. We refer to the new framework as "Squiral" Image Processing (SIP). Firstly we introduce the approach for SIP conversion that transforms a standard 2D image to a 1D vector according to the proposed "squiral" architecture. Secondly we propose a non-overlapping convolution technique for SIP-based convolution, in which the SIP addressing scheme is incorporated by simulating the phenomenon of eye tremor in the human visual system. Furthermore, we develop a strategy to extend the SIP framework to be multiscale. The performance of the proposed framework is evaluated by the application of SIP-based approaches to edge and corner detection. The results demonstrate the efficiency of the proposed SIP framework compared with standard 2D convolution.
C1 [Jing, Min; Scotney, Bryan; Coleman, Sonya; McGinnity, T. Martin] Ulster Univ, Coleraine, Londonderry, North Ireland.
   [McGinnity, T. Martin] Nottingham Trent Univ, Nottingham, England.
C3 Ulster University; Nottingham Trent University
RP Jing, M (corresponding author), Ulster Univ, Coleraine, Londonderry, North Ireland.
EM m.jing@ulster.ac.uk
OI Jing, Min/0000-0001-8547-7024; Coleman, Sonya/0000-0002-4676-7640
FU European Community's Seventh Framework Programme [607691]
FX The research leading to these results has received funding from the
   European Community's Seventh Framework Programme under grant agreement
   No. 607691, SLANDAIL (Security System for Language and Image Analysis).
   The materials presented and views expressed here are the responsibility
   of the author(s) only. The EU Commission takes no responsibility for any
   use made of the information set out.
CR Asharindavida F., 2012, INT P COMPUT SCI INF, P7
   Coleman SA., 2013, IAPR P MACH VIS APPL, P129
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   He X., 2007, PROC CVPR IEEE, P340
   HER I, 1995, IEEE T IMAGE PROCESS, V4, P1213, DOI 10.1109/83.413166
   Kerr D., 2010, P INT MACH VIS IM PR
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu SJ, 2011, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2011.6115598
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Martinez-Conde S, 2004, NAT REV NEUROSCI, V5, P229, DOI 10.1038/nrn1348
   Middleton L., 2006, Hexagonal Image Processing: A Practical Approach
   Packer OS, 2002, J VISION, V2, DOI 10.1167/2.4.1
   Roka Andras., 2007, Sciences-New York, V4, P31
   Scotney B, 2011, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2011.6116077
   Sheridan P, 2000, IMAGE VISION COMPUT, V18, P907, DOI 10.1016/S0262-8856(00)00036-6
   Sheridan P., 1996, THESIS
   Sheridan P, 2007, IEEE T IMAGE PROCESS, V16, P1355, DOI 10.1109/TIP.2007.891790
   von Helmholtz H., 2005, TREATISE PHYSL OPTIC, V3
   Wang YP, 2003, IEEE T MED IMAGING, V22, P685, DOI 10.1109/TMI.2003.812255
   Wang YP, 1999, IEEE T IMAGE PROCESS, V8, P1757, DOI 10.1109/83.806621
NR 20
TC 0
Z9 0
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 371
EP 381
DI 10.1016/j.jvcir.2017.09.014
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800031
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, MJ
   Wang, Y
   Li, T
   Lv, J
   Wu, J
AF Sun, Maojin
   Wang, Yan
   Li, Teng
   Lv, Jing
   Wu, Jun
TI Vehicle counting in crowded scenes with multi-channel and multi-task
   convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vehicle counting; Urban setting; Semantic feature; Regression;
   Classification
AB Vehicle counting in crowded urban setting plays a significant role in public security area. Most existing works on vehicle counting focused on video sequence. Though these techniques has achieved significant progress, it has a significant disadvantage: only moving vehicle could be counted. It is not realistic that vehicles are often stopped in most crowded cases, e.g. carpark and traffic-light intersections. To deal with this issue, in this paper, we propose a novel multi-channel and multi-task convolutional neural networks (CNN) to count vehicles from still images. More specially, we present a novel algorithm to produce illumination invariance image and combine it with original gray image as input channels, which could handle more details. And we deem vehicle counting as a local consistency deep regression problem, using a local label supervised deep CNN model to fit it. Moreover, we utilize surveillance camera view classification as a related task to improve the performance of vehicle counting task and the two tasks are trained end-to-end jointly. To evaluate the proposed model, we collect a real-work dataset for research and extensive experimental results show that the proposed method performs better than existing state-of-the-art methods.
C1 [Sun, Maojin; Lv, Jing] Dalian Maritime Univ, Transportat Management Coll, Dalian, Peoples R China.
   [Wang, Yan; Li, Teng] Anhui Univ, Hefei 230601, Anhui, Peoples R China.
   [Wu, Jun] Chongqing KaizeTechnol Co Ltd, Chongqing, Peoples R China.
C3 Dalian Maritime University; Anhui University
RP Li, T (corresponding author), Anhui Univ, Hefei 230601, Anhui, Peoples R China.
EM liteng@ahu.edu.cn
FU National Natural Science Foundation (NSF) of China [61572029]; Special
   Financial Grant from China Postdoctoral Science Foundation [2016T90148]
FX This work is supported by the National Natural Science Foundation (NSF)
   of China (No. 61572029), and partially supported by a Special Financial
   Grant from the China Postdoctoral Science Foundation (No. 2016T90148).
CR [Anonymous], 2016, YOL09000 BETTER FAST
   [Anonymous], 2013, 9 WORKSH VIS COMP WV, DOI DOI 10.13140/2.1.1740.7044
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guo X., 2016, P 24 ACM INT C MULT, P87
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kamkar S, 2016, IET INTELL TRANSP SY, V10, P406, DOI 10.1049/iet-its.2015.0157
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Lin M., 2013, ADV NEURAL INFORM PR
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X, 2016, PROC CVPR IEEE, P3016, DOI 10.1109/CVPR.2016.329
   Loy CC, 2013, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2013.270
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Quesada J, 2016, IEEE IMAGE PROC, P3822, DOI 10.1109/ICIP.2016.7533075
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sobral A., 2014, VEHICLE DETECTION TR
   Uddin M, 2017, I C NETWORK PROTOCOL, DOI 10.1109/TPAMI.2017.2656884
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Xia YJ, 2016, SIGNAL PROCESS, V120, P672, DOI 10.1016/j.sigpro.2014.10.035
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
NR 35
TC 17
Z9 18
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 412
EP 419
DI 10.1016/j.jvcir.2017.10.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800035
DA 2024-07-18
ER

PT J
AU Yan, XY
   Wang, YH
   Song, Q
   Dai, KH
AF Yan, Xiaoyun
   Wang, Yuehuan
   Song, Qiong
   Dai, Kaiheng
TI Salient object detection via boosting object-level distinctiveness and
   saliency refinement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency; Salient object detection; Object-level distinctiveness;
   Boosting algorithm; Saliency refinement
ID REGION DETECTION; IMAGE; MODEL
AB Many salient object detection approaches share the common drawback that they cannot uniformly highlight heterogeneous regions of salient objects, and thus, parts of the salient objects are not discriminated from background regions in a saliency map. In this paper, we focus on this drawback and accordingly propose a novel algorithm that more uniformly highlights the entire salient object as compared to many approaches. Our method consists of two stages: boosting the object-level distinctiveness and saliency refinement. In the first stage, a coarse object-level saliency map is generated based on boosting the distinctiveness of the object proposals in the test images, using a set of object-level features and the Modest AdaBoost algorithm. In the second stage, several saliency refinement steps are executed to obtain a final saliency map in which the boundaries of salient objects are preserved. Quantitative and qualitative comparisons with state-of-the-art approaches demonstrate the superior performance of our approach. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yan, Xiaoyun; Wang, Yuehuan; Song, Qiong; Dai, Kaiheng] Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Hubei, Peoples R China.
   [Wang, Yuehuan] Natl Key Lab Sci & Technol Multi Spectral Informa, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Wang, YH (corresponding author), Huazhong Univ Sci & Technol, Sch Automat, Wuhan 430074, Hubei, Peoples R China.
EM yuehwang@hust.edu.cn
FU Natural Science Foundation of China [61227007]; National Defense
   Research Foundation of China [9140A01060113JW05016]; National Defense
   Research Project of China [41415020402]
FX This work was funded by the Natural Science Foundation of China (No.
   61227007), National Defense Research Foundation of China (No.
   9140A01060113JW05016), and National Defense Research Project of China
   (No. 41415020402).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Borji A., SALIENT OBJECT DETEC
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Donoser M, 2014, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2014.404
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hosang J, 2016, IEEE T PATTERN ANAL, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   JOHNSON DB, 1977, J ACM, V24, P1, DOI 10.1145/321992.321993
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P33, DOI 10.1007/978-3-642-14267-3_2
   Ma XL, 2015, J VIS COMMUN IMAGE R, V32, P95, DOI 10.1016/j.jvcir.2015.08.003
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Vezhnevets A., 2005, P INT C COMP GRAPH V
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Yan CC, 2014, J VIS COMMUN IMAGE R, V25, P1130, DOI 10.1016/j.jvcir.2014.03.005
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang LB, 2015, J VIS COMMUN IMAGE R, V33, P273, DOI 10.1016/j.jvcir.2015.09.019
   Zhao HD, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2219
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou BJ, 2015, J VIS COMMUN IMAGE R, V33, P378, DOI 10.1016/j.jvcir.2015.09.017
NR 48
TC 7
Z9 8
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 224
EP 237
DI 10.1016/j.jvcir.2017.06.013
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700018
DA 2024-07-18
ER

PT J
AU Mittal, A
   Roy, PP
   Singh, P
   Raman, B
AF Mittal, Anshul
   Roy, Partha Pratim
   Singh, Priyanka
   Raman, Balasubramanian
TI Rotation and script independent text detection from video frames using
   sub pixel mapping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-oriented text detection; Low resolution videos; Sub pixel mapping;
   Script independent text segmentation
ID PARALLEL FRAMEWORK; SUPERRESOLUTION; ENHANCEMENT; SEGMENTATION;
   RECOGNITION; IMAGES
AB Text detection and recognition in video frames is a challenging task due to low contrast and noise from background that hinder the processing. In this paper we have proposed a robust multi-oriented text detection approach in video frames. Proposed method uses sub pixel mapping based super resolution approach to enhance the image. Next, in this enhanced image, Histogram of Oriented Moment feature is extracted from connected components and Support Vector Machine (SVM) classifier is used for multi-oriented text/non-text identification. Finally, Recurrent Neural Network (RNN) based classifier is used for recognition of text characters. We have performed our experiment in 1CDAR2013 Robust Reading Competition Karatzas et al. (2013). To evaluate the script independent text extraction performance, we tested our framework in IITR dataset Verma et al. (2016) that contains text of multiple scripts in scene images. We have obtained F-measure of 0.82 which surpasses the current state of art techniques in ICDAR2013 Karatzas et al. (2013) and 0.8 in IITR Dataset Verma et al. (2016) for text detection. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Mittal, Anshul] Indian Inst Technol Roorkee, Dept Civil Engn, Roorkee, Uttar Pradesh, India.
   [Roy, Partha Pratim; Singh, Priyanka; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Roy, PP (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM 2partharoy@gmail.com
RI Singh, Priyanka/GRF-6098-2022; singh, priyanka/JWP-2636-2024; Singh,
   Priyanka/N-1372-2018; Roy, Partha Pratim/AAV-9061-2020; Roy, Partha
   Pratim/AAW-2994-2020; Roy, Partha Pratim/GPF-4253-2022
OI Singh, Priyanka/0000-0001-7874-7778; Singh,
   Priyanka/0000-0003-0841-1544; Roy, Partha Pratim/0000-0002-5735-5254;
   SINGH, PRIYANKA/0000-0001-5002-8800
CR [Anonymous], P COMP VIS PATT REC
   [Anonymous], 1995, CMUCS95186
   [Anonymous], 2009, INT C COMP VIS
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], J MACH LEARN RES
   [Anonymous], P 1 INT WORKSH CAM B
   [Anonymous], APPL MECH MAT
   [Anonymous], P INT J DOCUMENT ANA
   [Anonymous], INT C DOC AN REC
   [Anonymous], P 1 INT WORKSH CAM B
   [Anonymous], INT C COMP VIS IM PR
   [Anonymous], P ACM INT C DIG LIB
   [Anonymous], P INT C DOC AN REC
   Atkinson P.M., 1997, INNOVATIONS GIS 4, P166, DOI 10.1201/9781482272956-25/mapping-sub-pixelboundaries-remotely-sensed-images-peter-atkinson
   Bosamiya H, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P151, DOI 10.1109/ACPR.2015.7486484
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Capel D, 2000, INT C PATT RECOG, P600, DOI 10.1109/ICPR.2000.905409
   Chen DT, 2005, PATTERN RECOGN LETT, V26, P1386, DOI 10.1016/j.patrec.2004.11.019
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   Dalley G, 2004, IEEE IMAGE PROC, P3295
   Donaldson K., 2005, International Journal on Document Analysis and Recognition, V7, P159, DOI 10.1007/s10032-004-0139-y
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Garcia C, 2000, INT CONF ACOUST SPEE, P2326, DOI 10.1109/ICASSP.2000.859306
   He ZW, 2005, IEEE T INTELL TRANSP, V6, P72, DOI 10.1109/TITS.2004.838509
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Khare V, 2015, EXPERT SYST APPL, V42, P7627, DOI 10.1016/j.eswa.2015.06.002
   Li HP, 2000, INT C PATT RECOG, P847, DOI 10.1109/ICPR.2000.905546
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Ma TH, 2014, PHYSICA A, V416, P400, DOI 10.1016/j.physa.2014.09.026
   Park J, 2005, PROC INT CONF DOC, P374
   Roy PP, 2012, PATTERN RECOGN, V45, P1972, DOI 10.1016/j.patcog.2011.09.026
   Roy S., 2013, NATL C COMPUTER VISI, P1
   Roy S, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P288, DOI 10.1109/ACPR.2013.60
   Saidane Z, 2007, PROC INT CONF DOC, P874
   Sattar F, 1999, IEEE SIGNAL PROC LET, V6, P249, DOI 10.1109/97.789601
   Sharma N, 2015, PROC INT CONF DOC, P951, DOI 10.1109/ICDAR.2015.7333902
   Shivakumara P, 2013, IEEE T CIRC SYST VID, V23, P1729, DOI 10.1109/TCSVT.2013.2255396
   Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Tatem AJ, 2002, REMOTE SENS ENVIRON, V79, P1, DOI 10.1016/S0034-4257(01)00229-2
   Wyman C., 2013, J. Comput. Graph. Tech, V2, P1
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang J, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P5, DOI 10.1109/DAS.2008.49
   Zhiwei Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P133, DOI 10.1109/ICPR.2010.41
NR 46
TC 16
Z9 17
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 187
EP 198
DI 10.1016/j.jvcir.2017.03.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500017
DA 2024-07-18
ER

PT J
AU Wang, HQ
   Katsavounidis, I
   Zhou, JT
   Park, J
   Lei, SM
   Zhou, X
   Pun, MO
   Jin, X
   Wang, RG
   Wang, X
   Zhang, Y
   Huang, JW
   Kwong, S
   Kuo, CCJ
AF Wang, Haiqiang
   Katsavounidis, Ioannis
   Zhou, Jiantong
   Park, Jeonghoon
   Lei, Shawinin
   Zhou, Xin
   Pun, Man-On
   Jin, Xin
   Wang, Ronggang
   Wang, Xu
   Zhang, Yun
   Huang, Jiwu
   Kwong, Sam
   Kuo, C. -C. Jay
TI VideoSet: A large-scale compressed video quality dataset based on JND
   measurement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human visual system (HVS); Just noticeable difference (JND); Video
   quality; Video coding
ID JUST-NOTICEABLE-DISTORTION
AB A new methodology to measure coded image/video quality using the just-noticeable-difference (JND) idea was proposed in Lin et al. (2015). Several small JND-based image/video quality datasets were released by the Media Communications Lab at the University of Southern California in Jin et al. (2016) and Wang et al. (2016) [3]. In this work, we present an effort to build a large-scale JND-based coded video quality dataset. The dataset consists of 220 5-s sequences in four resolutions (i.e., 1920 x 1080,1280 x 720, 960 x 540 and 640 x 360). For each of the 880 video clips, we encode it using the H.264/AVC codec with QP = 1,...,51 and measure the first three JND points with 30 + subjects. The dataset is called the "VideoSet", which is an acronym for "Video Subject Evaluation Test (SET)". This work describes the subjective test procedure, detection and removal of outlying measured data, and the properties of collected JND data. Finally, the significance and implications of the VideoSet to future video coding research and standardization efforts are pointed out. All source/coded video clips as well as measured JND data included in the VideoSet are available to the public in the IEEE DataPort. (C) 2017 The Authors. Published by Elsevier Inc.
C1 [Wang, Haiqiang; Kuo, C. -C. Jay] Univ Southern Calif, Los Angeles, CA USA.
   [Katsavounidis, Ioannis] Netflix, Los Gatos, CA USA.
   [Zhou, Jiantong] Huawei Technol, Shenzhen, Peoples R China.
   [Park, Jeonghoon] Samsung, DMC R&D, Seoul, South Korea.
   [Lei, Shawinin] Mediatek, Hsinchu, Taiwan.
   [Zhou, Xin] Northwestern Polytech Univ, Xian, Peoples R China.
   [Pun, Man-On] Chinese Univ Hong Kong SZ, Shenzhen, Peoples R China.
   [Jin, Xin] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen, Guangdong, Peoples R China.
   [Wang, Ronggang] Peking Univ, Shenzhen Grad Sch, Shenzhen, Peoples R China.
   [Wang, Xu; Huang, Jiwu] Shenzhen Univ, Shenzhen, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen, Peoples R China.
   [Kwong, Sam] City Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
C3 University of Southern California; Netflix, Inc.; Huawei Technologies;
   Samsung; Mediatek Incorporated; Northwestern Polytechnical University;
   The Chinese University of Hong Kong, Shenzhen; Tsinghua Shenzhen
   International Graduate School; Tsinghua University; Peking University;
   Shenzhen University; Chinese Academy of Sciences; City University of
   Hong Kong
RP Zhou, X (corresponding author), Northwestern Polytech Univ, Xian, Peoples R China.
EM xinzhou@nwpu.edu.cn
RI Kwong, Sam/C-9319-2012; jin, xin/GQZ-5811-2022; huang, jw/KVY-9917-2024;
   Zhang, Yun/V-7261-2019; Kuo, C.-C. Jay/A-7110-2011
OI Kwong, Sam/0000-0001-7484-7261; Zhang, Yun/0000-0001-9457-7801; Kuo,
   C.-C. Jay/0000-0001-9474-5035
FU Netflix; Huawei; Samsung; MediaTek
FX This research was funded by Netflix, Huawei, Samsung and MediaTek. The
   subjective tests were conducted in the City University of Hong Kong and
   five universities in the Shenzhen City of China. They were Shenzhen
   University, Chinese University of Hong Kong (SZ), Tsinghua University,
   Peking University and Chinese Academy of Sciences. Computation for the
   work was supported in part by the University of Southern California's
   Center for High Performance Computing (hpc.usc.edu). The authors would
   like to give thanks to these companies and universities for their strong
   support.
CR [Anonymous], X264 A FREE H264 AVC
   [Anonymous], SPIE OPTICAL ENG APP
   [Anonymous], CONSUMER DIGITAL VID
   [Anonymous], VIDEOSET LARGE SCALE
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], REP VAL VID QUAL MOD
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   GRUBBS FE, 1950, ANN MATH STAT, V21, P27, DOI 10.1214/aoms/1177729885
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hu S., 2016, IEEE T CIRC SYST VID, VPP, P1
   JARQUE CM, 1987, INT STAT REV, V55, P163, DOI 10.2307/1403192
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Kim J, 2015, IEEE T CIRC SYST VID, V25, P1786, DOI 10.1109/TCSVT.2015.2389491
   Lin JY, 2015, J VIS COMMUN IMAGE R, V30, P1, DOI 10.1016/j.jvcir.2015.02.012
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Luo ZY, 2013, IEEE T CIRC SYST VID, V23, P935, DOI 10.1109/TCSVT.2013.2240919
   Ma L, 2011, SIGNAL PROCESS-IMAGE, V26, P162, DOI 10.1016/j.image.2011.02.002
   Ou TS, 2011, IEEE T CIRC SYST VID, V21, P682, DOI 10.1109/TCSVT.2011.2129890
   Ou YF, 2014, IEEE T IMAGE PROCESS, V23, P2473, DOI 10.1109/TIP.2014.2303636
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sharma G., 2002, DIGITAL COLOR IMAGIN
   Turkowski K, 1990, GRAPHICS GEMS, P147, DOI DOI 10.1016/B978-0-08-050753-8.50042-5
   Wang HG, 2016, IEEE IMAGE PROC, P1509, DOI 10.1109/ICIP.2016.7532610
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu GL, 2013, IEEE T IMAGE PROCESS, V22, P2247, DOI 10.1109/TIP.2013.2247409
   You JY, 2014, IEEE T IMAGE PROCESS, V23, P200, DOI 10.1109/TIP.2013.2287611
   Zhang W, 2016, IEEE T NEUR NET LEAR, V27, P1266, DOI 10.1109/TNNLS.2015.2461603
   Zhang XF, 2017, IEEE SIGNAL PROC LET, V24, P96, DOI 10.1109/LSP.2016.2641456
NR 31
TC 92
Z9 106
U1 2
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 292
EP 302
DI 10.1016/j.jvcir.2017.04.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500026
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Adeyemi-Ejeye, AO
   Alreshoodi, M
   Al-Jobouri, L
   Fleury, M
   Woods, J
AF Adeyemi-Ejeye, A. O.
   Alreshoodi, M.
   Al-Jobouri, L.
   Fleury, M.
   Woods, J.
TI Packet loss visibility across SD, HD, 3D, and UHD video streams
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video streaming; Packet loss visibility; Objective MOS; Beyond HD
ID QUALITY ASSESSMENT; EFFICIENCY
AB The trend towards video streaming with increased spatial resolutions and dimensions, SD, HD, 3D, and 4kUHD, even for portable devices has important implications for displayed video quality. There is an interplay between packetization, packet loss visibility, choice of codec, and viewing conditions, which implies that prior studies at lower resolutions may not be as relevant. This paper presents two sets of experiments, the one at a Variable BitRate (VBR) and the other at a Constant BitRate (CBR), which highlight different aspects of the interpretation. The latter experiments also compare and contrast encoding with either an H.264 or an High Efficiency Video Coding (HEVC) codec, with all results recorded as objective Mean Opinion Score (MOS). The video quality assessments will be of interest to those considering: the bitrates and expected quality in error-prone environments; or, in fact, whether to use a reliable transport protocol to prevent all errors, at a cost in jitter and latency, rather than tolerate low levels of packet errors. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Adeyemi-Ejeye, A. O.] Univ Kingston, Fac Sci Engn & Comp, London, England.
   [Alreshoodi, M.] Qassim Univ, Community Coll, Buraydah, Saudi Arabia.
   [Al-Jobouri, L.; Fleury, M.; Woods, J.] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 Kingston University; Qassim University; University of Essex
RP Fleury, M (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
EM fleum@essex.ac.uk
RI Alreshoodi, Mohammed/AAK-4165-2020; Adeyemi-Ejeye, Anthony/AAO-8477-2020
OI Adeyemi-Ejeye, Anthony/0000-0002-8371-7829; Alreshoodi,
   Mohammed/0000-0002-3066-6909; Al-Jobouri, Laith/0000-0003-4600-9513
CR Adeyemi-Ejeye A., 2014, HEVC MPEG TS DEFINIT
   Adeyemi-Ejeye AO, 2013, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (CONTEL 2013), P109
   [Anonymous], 2004, FINAL REPORT VIDEO Q
   [Anonymous], 2014, BT2020 ITUT
   [Anonymous], 2010, P910 ITUT
   [Anonymous], 2007, PACKET VIDEO 2007
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   [Anonymous], 2008, SUBJECTIVE VIDEO QUA
   [Anonymous], P INT C DSP JUL
   Argyropoulos S, 2011, INT CONF ACOUST SPEE, P1169
   Bae SH, 2013, IEEE T BROADCAST, V59, P209, DOI 10.1109/TBC.2013.2247171
   Battisti F., 2014, Euro Med Telco Conference (EMTC), 2014, P1
   Bing B, 2010, ARTECH HSE TELECOM S, P1
   Blender-Foundation, 2011, SINT 4K
   Boulos F., 2009, P 4 INT WORKSH VID P, P1
   Cermak GW, 2009, INT WORK QUAL MULTIM, P41, DOI 10.1109/QOMEX.2009.5246980
   Chan A., 2010, 2010 Proceedings IEEE INFOCOM, P1, DOI DOI 10.1109/INFCOM.2010.5461979
   De Simone F, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/190431
   Gharai L, 2004, IEEE IC COMP COM NET, P73, DOI 10.1109/ICCCN.2004.1401591
   Girod B, 2002, IEEE IMAGE PROC, P9
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Jaiswal S, 2007, IEEE ACM T NETWORK, V15, P54, DOI 10.1109/TNET.2006.890117
   Joskowicz J, 2013, IEEE T BROADCAST, V59, P569, DOI 10.1109/TBC.2013.2277951
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kanumuri S, 2006, IEEE IMAGE PROC, P2245, DOI 10.1109/ICIP.2006.312809
   Khan A, 2012, IEEE T MULTIMEDIA, V14, P431, DOI 10.1109/TMM.2011.2176324
   Krzanowski W., 2000, PRINCIPLES MULTIVARI, V23
   Li SN, 2012, IEEE T CIRC SYST VID, V22, P1100, DOI 10.1109/TCSVT.2012.2190473
   Li Zhang, 2012, Intelligent Tutoring Systems. Proceedings 11th International Conference (ITS 2012), P33, DOI 10.1007/978-3-642-30950-2_4
   LIANG YJ, 2003, IEEE INT C AC SPEECH
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Mehendale M., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P226, DOI 10.1109/ISSCC.2012.6176986
   Merkle P, 2009, IEEE 3DTV C, P1
   Merritt L., 2007, IEEE, 1-4244-1437-7/07, P309
   Mohamed S, 2002, IEEE T CIRC SYST VID, V12, P1071, DOI 10.1109/TCSVT.2002.806808
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Nightingale J, 2014, IEEE T CONSUM ELECTR, V60, P242, DOI 10.1109/TCE.2014.6852000
   Nightingale J, 2012, IEEE T CONSUM ELECTR, V58, P404, DOI 10.1109/TCE.2012.6227440
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Perahia E., 2013, Next Generation Wireless LANs: 802.11n and 802.11ac
   Perkins C., 2003, RTP : Audio and Video for the Internet
   Pinson MH, 2010, IEEE T BROADCAST, V56, P86, DOI 10.1109/TBC.2009.2034511
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Sarwar G, 2011, IEEE ICC
   Scholler S, 2012, IEEE T IMAGE PROCESS, V21, P2619, DOI 10.1109/TIP.2012.2187672
   Shin J, 2010, INT CONF ACOUST SPEE, P910, DOI 10.1109/ICASSP.2010.5495279
   Snecdecor G.W., 1991, STAT METHODS, V8th
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Ventakaraman M., 2010, P IEEE GLOBECOM MIAM, P1
   Vetro A, 2011, IEEE T BROADCAST, V57, P384, DOI 10.1109/TBC.2010.2102950
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yasakethu SLP, 2010, ELECTRON LETT, V46, P837, DOI 10.1049/el.2010.3540
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Zorzi M, 1996, PIMRC'96 - THE SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, PROCEEDINGS, VOLS 1-3, P1074, DOI 10.1109/PIMRC.1996.568447
NR 55
TC 10
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 95
EP 106
DI 10.1016/j.jvcir.2017.02.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Xiao, D
   Xiang, YP
   Zheng, HY
   Wang, Y
AF Xiao, Di
   Xiang, Yanping
   Zheng, Hongying
   Wang, Yong
TI Separable reversible data hiding in encrypted image based on pixel value
   ordering and additive homomorphism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Encrypted image; Pixel value ordering; Additive
   homomorphism; Separable
ID SCHEME; WATERMARKING; DIFFERENCE; EXPANSION; RC4
AB This work proposes a separable reversible data hiding scheme in encrypted images based on pixel value ordering (PVO). After the original image is encrypted using homomorphism encryption by the content owner, the data hider embeds the secret data in encrypted domain. The PVO strategy realizes hiding data in each block. Additive homomorphism guarantees the performance of PVO in encrypted domain is close to that in plain domain. Besides, the homomorphism encryption does not cause data expansion, and the payload can be further improved. With the watermarked encrypted image, if the receiver has only the data hiding key, he can extract the additional data. If the receiver has only the encryption key, he can obtain a decrypted image similar to the original one. If the receiver has both the data hiding key and the encryption key, he can extract the additional data without any error and recover the original image losslessly. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Xiao, Di; Xiang, Yanping; Zheng, Hongying] Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Wang, Yong] Chongqing Univ Posts & Telecommun, Key Lab Elect Commerce & Logist Chongqing, Chongqing 400065, Peoples R China.
C3 Chongqing University; Chongqing University of Posts & Telecommunications
RP Xiao, D (corresponding author), Chongqing Univ, Coll Comp Sci, Minist Educ, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
RI zhang, jt/JVE-1333-2024
OI Wang, Yong/0000-0002-5247-043X
FU National Natural Science Foundation of China [61472464, 61502399,
   61572089, 61633005, 61602158]; atural Science Foundation of Chongqing
   Science and Technology Commission [cstc2012jjA40017, cstc2013jcyjA40017,
   cstc2015jcyjA40039]; Fundamental Research Funds for the Central
   Universities [106112014MIZR185501]
FX The work described in this paper was funded by the National Natural
   Science Foundation of China (Grant Nos. 61472464, 61502399, 61572089,
   61633005, 61602158), the Natural Science Foundation of Chongqing Science
   and Technology Commission (Grant Nos. cstc2012jjA40017,
   cstc2013jcyjA40017, cstc2015jcyjA40039) and the Fundamental Research
   Funds for the Central Universities (Grant No. 106112014MIZR185501).
CR [Anonymous], 1978, FDN SEC COMPUT
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Damgard I., 1992, LECT NOTES COMPUT SC, V2001, P119
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hwang K, 2010, IEEE INTERNET COMPUT, V14, P14, DOI 10.1109/MIC.2010.86
   Klein A, 2008, DESIGN CODE CRYPTOGR, V48, P269, DOI 10.1007/s10623-008-9206-6
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni Z., 2004, IEEE T CIRCUITS SYST, V2, P157
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Paul G, 2008, DESIGN CODE CRYPTOGR, V49, P123, DOI 10.1007/s10623-008-9177-7
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang X., 2015, IEEE T CIRCUITS SYST, VPP, P1, DOI DOI 10.1177/0954409715613538
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 33
TC 63
Z9 66
U1 1
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 1
EP 10
DI 10.1016/j.jvcir.2017.02.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100001
DA 2024-07-18
ER

PT J
AU Zhang, SZ
   Yang, D
   Huang, S
   Zhang, XH
   Tu, LY
   Ren, ZM
AF Zhang, Shizheng
   Yang, Dan
   Huang, Sheng
   Zhang, Xiaohong
   Tu, Liyun
   Ren, Zemin
TI Robust corner detection using the eigenvector-based angle estimator
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eigenvector; Angle estimation; Curvature; Corner detection;
   Repeatability; Localization error
ID CURVATURE SCALE-SPACE; CLASSIFICATION; DIFFERENCE; MODEL; SHAPE
AB Angle is an intuitive and important property for representing corners. This fact motivates us to present a novel angle-based corner detector, named Eigenvector-based Angle Estimator (EAE). EAE estimates the angle of each point in a contour via computing the eigenvectors of the covariance matrix of boundary points over a small Region of Support (RoS). Since EAE is sensitive to uniform scaling due to the fixed RoS, an enhanced version of EAE named Weighted EAE (WEAE) is proposed. WEAE achieves robustness to uniform scaling by weighting the boundary points using their distances from the target point. Experimental results demonstrate that EAE and WEAE can efficiently achieve promising performance in comparisons with several recent state-of-the-art approaches under two commonly used evaluation metrics, namely, Average Repeatability (AR) and Localization Error (LE). (C) 2017 Elsevier Inc. All rights reserved.
C1 [Zhang, Shizheng; Yang, Dan; Tu, Liyun] Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450000, Peoples R China.
   [Yang, Dan; Huang, Sheng; Zhang, Xiaohong] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
   [Ren, Zemin] Chongqing Univ Sci & Technol, Coll Math & Phys, Chongqing 401331, Peoples R China.
C3 Zhengzhou University of Light Industry; Chongqing University; Chongqing
   University of Science & Technology
RP Zhang, SZ (corresponding author), Zhengzhou Univ Light Ind, Software Engn Coll, Zhengzhou 450000, Peoples R China.
EM zshizheng@sina.cn
RI YANG, Dan/HHD-2733-2022; Zhang, Xiaohong/A-3060-2015
OI Tu, Liyun/0000-0002-3389-400X; Huang, Sheng/0000-0001-5610-0826
FU National Natural Science Foundation of China [61602068, 61601068];
   Natural Science Foundation of Chongqing [cstc2016jcyjA0458]; Fundamental
   Research Funds for the Central Universities [CDJZR12098801,
   CDJZR11095501]; Foundation of Chongqing University of Science and
   Technology [CK2015B18]; Scientific and Technological Research Program of
   Chongqing Municipal Education Commission [KJ1601317]
FX The work in this paper was partially supported by the National Natural
   Science Foundation of China (Grant no. 61602068), the Natural Science
   Foundation of Chongqing (Grant no. cstc2016jcyjA0458), the Fundamental
   Research Funds for the Central Universities (Grant Nos. CDJZR12098801
   and CDJZR11095501), the Foundation of Chongqing University of Science
   and Technology (CK2015B18), the Scientific and Technological Research
   Program of Chongqing Municipal Education Commission (Grant No.
   KJ1601317), and the National Natural Science Foundation of China
   (61601068). The authors would like to thank the reviewers for their
   helpful suggestions and Dr. M. Awrangjeb for sharing his source code and
   Dataset 2.
CR Alvarez L, 1997, INT J COMPUT VISION, V25, P95, DOI 10.1023/A:1007959616598
   ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472
   Awrangjeb M., 2015, DATA SET
   Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   Awrangjeb M, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P519, DOI 10.1109/DICTA.2009.91
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Clady X, 2015, NEURAL NETWORKS, V66, P91, DOI 10.1016/j.neunet.2015.02.013
   DAVIS LS, 1977, IEEE T COMPUT, V26, P236, DOI 10.1109/TC.1977.1674812
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   FAIRNEY DP, 1994, IMAGE VISION COMPUT, V12, P259, DOI 10.1016/0262-8856(94)90031-0
   Gao XT, 2007, IEEE T CIRC SYST VID, V17, P868, DOI 10.1109/TCSVT.2007.897473
   Han JH, 2001, PATTERN RECOGN LETT, V22, P1133, DOI 10.1016/S0167-8655(01)00063-0
   Harris C., 1988, ALVEY VISION C, P147151
   He XC, 2008, OPT ENG, V47, DOI 10.1117/1.2931681
   Kahaki SMM, 2014, SENSORS-BASEL, V14, P4126, DOI 10.3390/s140304126
   Laganière R, 2002, INT C PATT RECOG, P672
   LEE JS, 1995, IEEE T IMAGE PROCESS, V4, P100, DOI 10.1109/83.350810
   Lewiner T, 2005, COMPUT GRAPH-UK, V29, P641, DOI 10.1016/j.cag.2005.08.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mokhtarian F., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P145
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8
   Qin X. B., 2012, J SIG PROCESS, V16, P593
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Shui PL, 2013, IEEE T IMAGE PROCESS, V22, P3204, DOI 10.1109/TIP.2013.2259834
   SINGH A, 1990, COMPUT VISION GRAPH, V51, P54, DOI 10.1016/S0734-189X(05)80062-3
   Sinzinger ED, 2008, PATTERN RECOGN, V41, P494, DOI 10.1016/j.patcog.2007.06.032
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Teng SW, 2015, PATTERN RECOGN, V48, P2185, DOI 10.1016/j.patcog.2015.01.016
   TSAI DM, 1994, PATTERN RECOGN, V27, P699, DOI 10.1016/0031-3203(94)90048-5
   Tsai DM, 1999, PATTERN RECOGN LETT, V20, P31, DOI 10.1016/S0167-8655(98)00130-5
   Vincent E, 2005, J VIS COMMUN IMAGE R, V16, P38, DOI 10.1016/j.jvcir.2004.05.001
   WORRING M, 1993, CVGIP-IMAG UNDERSTAN, V58, P366, DOI 10.1006/ciun.1993.1048
   Yeh CH, 2003, PATTERN RECOGN LETT, V24, P2797, DOI 10.1016/S0167-8655(03)00124-7
   Zhang SZ, 2015, ELECTRON LETT, V51, P1988, DOI 10.1049/el.2015.2491
   Zhang WC, 2015, PATTERN RECOGN, V48, P2785, DOI 10.1016/j.patcog.2015.03.021
   Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006
   Zhang XH, 2015, IEEE T PATTERN ANAL, V37, P2207, DOI 10.1109/TPAMI.2015.2396074
   Zhang XH, 2010, PATTERN RECOGN, V43, P1207, DOI 10.1016/j.patcog.2009.10.017
   Zhang XH, 2009, PATTERN RECOGN LETT, V30, P449, DOI 10.1016/j.patrec.2008.11.002
   Zhong BJ, 2007, IEEE T PATTERN ANAL, V29, P508, DOI 10.1109/TPAMI.2007.50
NR 48
TC 14
Z9 14
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 181
EP 193
DI 10.1016/j.jvcir.2017.01.020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100016
DA 2024-07-18
ER

PT J
AU Hu, GQ
   Xiao, D
   Wang, Y
   Xiang, T
AF Hu, Guiqiang
   Xiao, Di
   Wang, Yong
   Xiang, Tao
TI An image coding scheme using parallel compressive sensing for
   simultaneous compression-encryption applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Cryptography; Image compression; Image encryption;
   Parallel processing
ID SECRECY
AB Recently, using compressive sensing (CS) as a cryptosystem has drawn attention due to its compressibility and low-complexity during the sampling process. However, when applying such cryptosystem to images, how to protect the privacy of the image while keeping efficiency becomes a challenge. In this paper, we propose a novel image coding scheme that achieves combined compression and encryption under a parallel compressive sensing framework, where both the CS sampling and the CS reconstruction are performed in parallel. In this way, the efficiency can be guaranteed. On the other hand, for security, the resistance to chosen plaintext attack (CPA) is realized with the help of the cooperation between a nonlinear chaotic sensing matrix construction process and a counter mode operation. Furthermore, the defect of energy information leakage in CS-based cryptosystem is also overcome by a diffusion procedure. Experimental and analysis results show the scheme achieves effectiveness, efficiency and high security simultaneously. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Hu, Guiqiang; Xiao, Di; Xiang, Tao] Chongqing Univ, Minist Educat, Coll Comp Sci, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
   [Wang, Yong] Chongqing Univ, Posts & Telecommun, Key Lab Elect Commerce & Logist Chongqing, Chongqing 400065, Peoples R China.
C3 Chongqing University; Chongqing University
RP Xiao, D (corresponding author), Chongqing Univ, Minist Educat, Coll Comp Sci, Key Lab Dependable Serv Comp Cyber Phys Soc, Chongqing 400044, Peoples R China.
EM xiaodi_cqu@hotmail.com
RI Xiang, Tao/N-3706-2016; Hu, Guiqiang/GPC-5126-2022
OI Xiang, Tao/0000-0002-9439-4623; Hu, Guiqiang/0000-0002-1184-794X; Wang,
   Yong/0000-0002-5247-043X
FU National Natural Science Foundation of China [61472464, 61502399,
   61572089, 61633005, 61672118]; Natural Science Foundation of Chongqing
   Science and Technology Commission of China [cstc2013jcyjA40017,
   cstc2015jcyjA40039]; Chongqing Graduate Student Research Innovation
   Projects of China [CYB14002]; Fundamental Research Funds for the Central
   Universities of China [106112014CDJZR185501]
FX The work was funded by the National Natural Science Foundation of China
   (Grant Nos. 61472464, 61502399, 61572089, 61633005, 61672118), the
   Natural Science Foundation of Chongqing Science and Technology
   Commission of China (Grant Nos. cstc2013jcyjA40017 and
   cstc2015jcyjA40039) and the Chongqing Graduate Student Research
   Innovation Projects of China (Grant No. CYB14002) and the Fundamental
   Research Funds for the Central Universities of China (Grant No.
   106112014CDJZR185501).
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 1987, SIGPLAN Notices, V22, P9, DOI 10.1145/24686.24687
   [Anonymous], 2011, SIGNAL PROCESSING AL
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Cambareri V, 2015, IEEE T SIGNAL PROCES, V63, P2183, DOI 10.1109/TSP.2015.2407315
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Deepan B, 2014, APPL OPTICS, V53, P4539, DOI 10.1364/AO.53.004539
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fang H, 2014, IEEE T SIGNAL PROCES, V62, P196, DOI 10.1109/TSP.2013.2284762
   Fang H, 2012, CONF REC ASILOMAR C, P1925, DOI 10.1109/ACSSC.2012.6489374
   Fay R, 2016, INFORM PROCESS LETT, V116, P279, DOI 10.1016/j.ipl.2015.11.010
   Gao ZR, 2013, J VIS COMMUN IMAGE R, V24, P885, DOI 10.1016/j.jvcir.2013.06.006
   Han B, 2010, J VIS COMMUN IMAGE R, V21, P325, DOI 10.1016/j.jvcir.2010.02.007
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang XL, 2015, SECUR COMMUN NETW, V8, P3659, DOI 10.1002/sec.1289
   Katz J., 2014, INTRO MODERN CRYPTOG
   Lei Yu, 2010, 2010 7th International Symposium on Communication Systems, Networks & Digital Signal Processing (CSNDSP 2010), P229
   Liu XM, 2016, IEEE T IMAGE PROCESS, V25, P2844, DOI 10.1109/TIP.2016.2554320
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Lui OY, 2012, APPL SOFT COMPUT, V12, P125, DOI 10.1016/j.asoc.2011.09.003
   Orsdemir A., 2008, MILITARY COMMUNICATI, P1
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Stankovic V, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P7, DOI 10.1109/CISP.2008.476
   Stinson D. R., 2005, CRYPTOGRAPHY THEORY
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Zhang LY, 2016, IEEE T MULTIMEDIA, V18, P1720, DOI 10.1109/TMM.2016.2581593
   Zhang YS, 2016, IEEE ACCESS, V4, P2507, DOI 10.1109/ACCESS.2016.2569421
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 32
TC 92
Z9 93
U1 3
U2 60
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 116
EP 127
DI 10.1016/j.jvcir.2017.01.022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600011
DA 2024-07-18
ER

PT J
AU Chaurasia, V
   Chaurasia, V
AF Chaurasia, Vijayshri
   Chaurasia, Vaishali
TI Statistical feature extraction based technique for fast fractal image
   compression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Affine transform; Domain image; Fractal; Image compression; Range image;
   Suitable domain search; Speedup
ID SPATIAL CORRELATION; PARALLEL FRAMEWORK; GENETIC ALGORITHM; HEVC;
   CLASSIFICATION; SCHEME
AB Fractal image compression is an innovative way of image representation by using relationships among the sub-section of image itself. It utilizes the existence of self-symmetry and uses affine contractive transforms. This technique has manifold advantages like, very high compression ratio, high decompression speed, high bit-rate and resolution independence, but high computation time expenses of suitable domain search in coding phase is the major bottleneck of the technique. This paper presents a fast fractal compression scheme based on feature extraction and innovative way of image comparison. In proposed development the complexity of suitable domain search is reduced by transforming the problem from image domain to vector domain. Simulation results confirms that suggested variant leads to a faster system as compared to existing state-of art Fractal Image Compression techniques. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Chaurasia, Vijayshri] Maulana Azad Natl Inst Technol, Bhopal, MP, India.
   [Chaurasia, Vaishali] Junction Software Pvt Ltd, Bhopal, MP, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Chaurasia, V (corresponding author), Maulana Azad Natl Inst Technol, Bhopal, MP, India.
EM vijayshree21@gmail.com; techvaishali@gmail.com
RI Chaurasia, Vijayshri/A-5554-2016
OI Chaurasia, Vijayshri/0000-0002-3347-5630
CR BARNSLEY MF, 1985, P ROY SOC LOND A MAT, V399, P243, DOI 10.1098/rspa.1985.0057
   Barnsley MF., 1993, Fractals Everywhere
   BRONSON R., 1989, Schaum's Outline of Theory and Problems of Matrix Operations
   CHAURASIA V, 2010, INT J ENG SCI TECHNO, V2, P104
   Chaurasia V, 2009, ICDIP 2009: INTERNATIONAL CONFERENCE ON DIGITAL IMAGE PROCESSING, PROCEEDINGS, P319, DOI 10.1109/ICDIP.2009.66
   Dattorro J., 2005, Convex Optimization & Euclidean Distance Geometry
   Du SL, 2015, IEEE SIGNAL PROC LET, V22, P499, DOI 10.1109/LSP.2014.2363689
   Duh DJ, 2008, IMAGING SCI J, V56, P79, DOI 10.1179/174313107X214259
   Duh DJ, 2005, IMAGE VISION COMPUT, V23, P1115, DOI 10.1016/j.imavis.2005.05.013
   Fisher Y., 1994, Fractal Image Compression
   FISHER Y, 1992, SIGGRAPH 92 COURSE N
   Grover LK, 1998, PHYS REV LETT, V80, P4329, DOI 10.1103/PhysRevLett.80.4329
   HUTCHINSON JE, 1981, INDIANA U MATH J, V30, P713, DOI 10.1512/iumj.1981.30.30055
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jaferzadeh K, 2012, IET IMAGE PROCESS, V6, P1024, DOI 10.1049/iet-ipr.2011.0181
   Joanes DN, 1998, J ROY STAT SOC D-STA, V47, P183
   Lin YL, 2011, COMPUT MATH APPL, V62, P310, DOI 10.1016/j.camwa.2011.05.011
   Mandelbrot B. B., 1982, FRACTAL GEOMETRY NAT
   Manolopoulos Y., 2005, S COMP SCI
   Mitra SK, 1998, IEEE T IMAGE PROCESS, V7, P586, DOI 10.1109/83.663505
   Nixon M.S., 2002, FEATURE EXTRACTION I
   Truong TK, 2004, CHAOS SOLITON FRACT, V22, P1071, DOI 10.1016/j.chaos.2004.03.015
   Tseng CC, 2008, IMAGE VISION COMPUT, V26, P1154, DOI 10.1016/j.imavis.2008.01.003
   Vences L., 1997, P COMPUTACION VISUAL, P35
   Wang JJ, 2013, IEEE T IMAGE PROCESS, V22, P3690, DOI 10.1109/TIP.2013.2268977
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wang XY, 2015, IET IMAGE PROCESS, V9, P153, DOI 10.1049/iet-ipr.2014.0001
   Wang XY, 2010, IMAGE VISION COMPUT, V28, P1303, DOI 10.1016/j.imavis.2010.01.008
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang XY, 2009, FRACTALS, V17, P451, DOI 10.1142/S0218348X09004545
   WEISTEAD S, 2005, FRACTAL WAVELET IMAG
   Wohlberg B, 1999, IEEE T IMAGE PROCESS, V8, P1716, DOI 10.1109/83.806618
   Wu MS, 2007, ENG APPL ARTIF INTEL, V20, P531, DOI 10.1016/j.engappai.2006.08.005
   Wu MS, 2010, DIGIT SIGNAL PROCESS, V20, P1150, DOI 10.1016/j.dsp.2009.12.009
   Wu MS, 2006, CHAOS SOLITON FRACT, V28, P497, DOI 10.1016/j.chaos.2005.07.004
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zalka C, 1999, PHYS REV A, V60, P2746, DOI 10.1103/PhysRevA.60.2746
NR 39
TC 23
Z9 23
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 87
EP 95
DI 10.1016/j.jvcir.2016.09.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000009
DA 2024-07-18
ER

PT J
AU Wu, XT
   Chen, B
   Weng, J
AF Wu, Xiaotian
   Chen, Bing
   Weng, Jian
TI Reversible data hiding for encrypted signals by homomorphic encryption
   and signal energy transfer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Homomorphic encryption; Signal energy transfer;
   Encrypted signals; Visual quality; Perfect reconstruction; Embedding
   rate; Encoded multimedia
ID IMAGES
AB Reversible data hiding for encrypted signals with prefect reconstruction of directly decrypted signals is introduced in this paper. Each unit in the original image is separated into three components by energy transfer equation, and each component is encrypted by Paillier homomorphic encryption. Additional bits are concealed into the encrypted image by manipulating the encrypted signals. Finally, the original image can be perfectly recovered when direct decryption is applied. The embedded bits are lossless extracted as well. Optimal visual quality and improved embedding rate are obtained by the proposed approach, since the value of the directly decrypted unit is the same as the original one. Experimental results and comparisons are demonstrated to illustrate the effectiveness and advantages of the proposed method. Moreover, the proposed method can be extended to deal with encoded multimedia, which further enriches the application scenarios. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wu, Xiaotian; Weng, Jian] Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Wu, Xiaotian] Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Chen, Bing] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Weng, Jian] Shenzhen Univ, Guangdong Prov Big Data Collaborat Innovat Ctr, Shenzhen, Peoples R China.
C3 Jinan University; Nanjing University of Information Science &
   Technology; Sun Yat Sen University; Shenzhen University
RP Weng, J (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM wxt.sysu@gmail.com; cryptjweng@gmail.com
OI Weng, Jian/0000-0003-4067-8230; Wu, Xiaotian/0000-0002-1484-2247
FU National Natural Science Foundation of China [61602211, 61272413,
   61133014, 61272415, 61472165]; Research Fund for the Doctoral Program of
   Higher Education of China [20134401110011]; special fund for Applied
   Science & Technology Development and Transformation of Major Scientific
   and Technological Achievements; fund for Zhuhai City Predominant
   Disciplines; Open Project Program of the Guangdong Provincial Big Data
   Collaborative Innovation Center; Priority Academic Program Development
   of Jiangsu Higer Education Institutions (PAPD); Jiangsu Collaborative
   Innovation Center on Atmospheric Environment and Equipment Technology
   (CICAEET)
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos. 61602211, 61272413, 61133014, 61272415 and
   61472165), Research Fund for the Doctoral Program of Higher Education of
   China (Grant No. 20134401110011), the 2016 special fund for Applied
   Science & Technology Development and Transformation of Major Scientific
   and Technological Achievements, the fund for Zhuhai City Predominant
   Disciplines, the Open Project Program of the Guangdong Provincial Big
   Data Collaborative Innovation Center, Priority Academic Program
   Development of Jiangsu Higer Education Institutions (PAPD) and Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Fu Z., IEEE T PARALL DISTRI
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ma TH, 2015, IEICE T INF SYST, VE98D, P902, DOI 10.1587/transinf.2014EDP7283
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Puech W., 2008, INT SOC OPTICS PHOTO
   Qian ZX, 2013, ADV INTEL SYS RES, V84, P869
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang X., IEEE T CIRC SYST VID
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 26
TC 35
Z9 39
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 58
EP 64
DI 10.1016/j.jvcir.2016.09.005
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000006
DA 2024-07-18
ER

PT J
AU Yuan, MD
   Feng, DZ
   Liu, WJ
   Xiao, CB
AF Yuan, Ming-Dong
   Feng, Da-Zheng
   Liu, Wen-Juan
   Xiao, Chun-Bao
TI Collaborative representation discriminant embedding for image
   classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Subspace learning; Collaborative representation; Graph embedding;
   Maximum margin criterion; Regularized least squares; Image
   classification
ID CANONICAL CORRELATION-ANALYSIS; ROBUST FEATURE-EXTRACTION; SAMPLE-SIZE
   PROBLEM; FACE-RECOGNITION; DIMENSIONALITY REDUCTION; PROJECTIONS;
   EFFICIENT; LDA; EIGENFACES
AB In this paper, an effective subspace learning approach, coined collaborative representation discriminant embedding (CRDE), is proposed for image classification. In CRDE, a 2 norm regularized least squares with closed form solution is first applied to pursue the collaborative reconstruction coefficients, which is datum adaptive and computationally more efficient than sparse representation based approaches. Then, the resulted graph is integrated with the modified maximum margin criterion (MMC) to seek the optimal discriminant directions. As a result, the local properties originated in the procedure of collaborative representation and the global discriminative information induced from the modified MMC can be sufficiently exploited. We also show that many popular approaches, such as locality preserving discriminant projections (LPDP), locally linear discriminant embedding (LLDE) and discriminant sparse neighborhood preserving embedding (DSNPE), can be incorporated into our CRDE framework. Experiment results on six databases validate the effectiveness of CRDE compared with nine approaches. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yuan, Ming-Dong; Feng, Da-Zheng; Liu, Wen-Juan] Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Peoples R China.
   [Xiao, Chun-Bao] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Yuan, MD (corresponding author), Xidian Univ, Natl Lab Radar Signal Proc, Xian 710071, Peoples R China.
EM mdyuan926@163.com
RI liu, wen/HGE-3071-2022; Yuan, Ming-Dong/T-1183-2019
OI Yuan, Ming-Dong/0000-0002-5820-8491
FU National Natural Science Foundation of China [61271293]
FX The authors would like to thank the editor and three anonymous reviewers
   for their valuable suggestions. This work was supported by the National
   Natural Science Foundation of China under grant 61271293.
CR [Anonymous], 2012, ARXIV12042358
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bian W, 2011, IEEE T PATTERN ANAL, V33, P1037, DOI 10.1109/TPAMI.2010.189
   Cai D, 2007, IEEE DATA MINING, P73, DOI 10.1109/ICDM.2007.89
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Clemmensen L, 2011, TECHNOMETRICS, V53, P406, DOI 10.1198/TECH.2011.08118
   Golub G.H., 1996, MATRIX COMPUTATIONS, P374
   Gong C, 2014, AAAI CONF ARTIF INTE, P1847
   Guan N., 2012, ARXIV12073438
   Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017
   Han PY, 2009, J VIS COMMUN IMAGE R, V20, P532, DOI 10.1016/j.jvcir.2009.08.003
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Howland P, 2006, PATTERN RECOGN, V39, P277, DOI 10.1016/j.patcog.2005.06.013
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jiang XD, 2011, IEEE SIGNAL PROC MAG, V28, P16, DOI 10.1109/MSP.2010.939041
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Kyperountas M, 2007, IEEE T NEURAL NETWOR, V18, P506, DOI 10.1109/TNN.2006.885038
   Lawrence N., 2001, P 18 INT C MACH LEAR
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li B, 2008, PATTERN RECOGN, V41, P3813, DOI 10.1016/j.patcog.2008.05.027
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Liu J, 2007, IEEE T NEURAL NETWOR, V18, P1862, DOI 10.1109/TNN.2007.900813
   Liu QS, 2006, IEEE T NEURAL NETWOR, V17, P1081, DOI 10.1109/TNN.2006.875970
   Liu TL, 2016, IEEE T NEUR NET LEAR, V27, P1851, DOI 10.1109/TNNLS.2015.2458986
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Lou SJ, 2016, NEUROCOMPUTING, V173, P290, DOI 10.1016/j.neucom.2015.04.116
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Nene S. A., 1996, COLUMBIA OBJECT IMAG
   Nie FP, 2012, PATTERN RECOGN LETT, V33, P485, DOI 10.1016/j.patrec.2011.11.028
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Raducanu B, 2014, PATTERN RECOGN, V47, P480, DOI 10.1016/j.patcog.2013.06.021
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shi QF, 2011, PROC CVPR IEEE, P553, DOI 10.1109/CVPR.2011.5995556
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang HX, 2008, IEEE T NEURAL NETWOR, V19, P571, DOI 10.1109/TNN.2007.910733
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu C., 2014, P INT C MACH LEARN, p865~873
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yan Shuicheng., 2009, SOC IND APPL MATH P, P792, DOI [10.1137/1.9781611972795.68, DOI 10.1137/1.9781611972795.68]
   Yang WK, 2016, NEUROCOMPUTING, V175, P198, DOI 10.1016/j.neucom.2015.10.049
   Yang WK, 2015, PATTERN RECOGN, V48, P20, DOI 10.1016/j.patcog.2014.07.009
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhou TY, 2013, IEEE T IMAGE PROCESS, V22, P244, DOI 10.1109/TIP.2012.2202678
   Zhou TY, 2011, DATA MIN KNOWL DISC, V22, P340, DOI 10.1007/s10618-010-0182-x
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 60
TC 8
Z9 10
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 212
EP 224
DI 10.1016/j.jvcir.2016.10.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000019
DA 2024-07-18
ER

PT J
AU Zhang, JG
   Jiang, JM
AF Zhang, Jianguang
   Jiang, Jianmin
TI Decomposition-based tensor learning regression for improved
   classification of multimedia
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tensor; Logistic regression; Tucker decomposition; l(F)-norm; Multimedia
   classification
ID LINEAR DISCRIMINANT-ANALYSIS; SELECTION
AB Existing vector-based multimedia classification often incurs loss of space-time information and requires generation of high-dimensional vectors. To explore a possible new solution for the problem, we propose a novel tensor-based logistic regression algorithm via Tucker decomposition to complete multimedia classification. In order to strengthen the classification process, l(F)-norm is used for regularization term. A logistic Tucker regression model is established to achieve effective extraction of principal components out of the tensors, and hence reduce the dimension of inputs to improve the efficiency of multimedia classification. To evaluate the proposed algorithm, we carried out extensive experiments on a number of data sets, including two second-order grayscale image datasets and one third-order video sequence dataset. All the results indicate that our proposed algorithm outperforms the existing state-of-the-arts in relevant areas. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Jianguang] Hengshui Univ, Dept Math & Comp Sci, Hengshui, Peoples R China.
   [Zhang, Jianguang; Jiang, Jianmin] Shenzhen Univ, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
C3 Hengshui University; Shenzhen University
RP Jiang, JM (corresponding author), Shenzhen Univ, Sch Comp Sci & Software Engn, Shenzhen, Peoples R China.
EM lynxzjg@tju.edu.cn; jianmin.jiang@szu.edu.cn
FU Hebei Provincial Natural Science Foundation, China [F2016111005];
   Chinese Natural Science Foundation (CNSF) [61620106008, 61373103]
FX This work was supported by the Hebei Provincial Natural Science
   Foundation, China (under Grant F2016111005). This work also was
   supported by the Chinese Natural Science Foundation (CNSF) (under Grant
   61620106008, Grant 61373103).
CR [Anonymous], P ACM MULT C MM 12 N
   [Anonymous], 2003, PROC CVPR IEEE
   [Anonymous], 2005, 5 IEEE INT C DAT MIN
   [Anonymous], 2013, INT JOINT C ART INT
   Gao QX, 2015, IEEE T IMAGE PROCESS, V24, P5684, DOI 10.1109/TIP.2015.2479559
   Gao XB, 2009, PATTERN RECOGN LETT, V30, P140, DOI 10.1016/j.patrec.2008.02.009
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Gourier N., 2004, FG NET WORKSHOP VISU, P1
   Guo WW, 2012, IEEE T IMAGE PROCESS, V21, P816, DOI 10.1109/TIP.2011.2165291
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kotsia I, 2011, PROC CVPR IEEE, P633, DOI 10.1109/CVPR.2011.5995663
   Li K, 2015, IEEE T CYBERNETICS, V45, P1401, DOI 10.1109/TCYB.2014.2351831
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Li YM, 2016, IEEE T CIRC SYST VID, V26, P1044, DOI 10.1109/TCSVT.2015.2430711
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Ma ZG, 2014, INT J COMPUT VISION, V109, P60, DOI 10.1007/s11263-014-0717-5
   Maalouf Maher, 2011, International Journal of Data Analysis Techniques and Strategies, V3, P281, DOI 10.1504/IJDATS.2011.041335
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Raghavendra R, 2014, PATTERN RECOGN, V47, P2205, DOI 10.1016/j.patcog.2013.12.011
   Ren JC, 2014, J VIS COMMUN IMAGE R, V25, P1558, DOI 10.1016/j.jvcir.2014.07.001
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shakhnarovich G., 2006, NEAREST NEIGHBOR MET
   Velasco-Forero S, 2013, PATTERN RECOGN, V46, P566, DOI 10.1016/j.patcog.2012.08.011
   Xiao ZJ, 2015, J SYST SOFTWARE, V101, P260, DOI 10.1016/j.jss.2014.12.030
   Xu D, 2008, IEEE T CIRC SYST VID, V18, P36, DOI 10.1109/TCSVT.2007.903317
   Xu Tan, 2013, Intelligent Science and Intelligent Data Engineering. Third Sino-foreign-interchange Workshop, IScIDE 2012. Revised Selected Papers, P573, DOI 10.1007/978-3-642-36669-7_70
   Yan SC, 2007, IEEE T IMAGE PROCESS, V16, P212, DOI 10.1109/TIP.2006.884929
   Yan Y., IEEE T PATT ANAL MAC
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yang Y, 2016, IEEE T NEUR NET LEAR, V27, P952, DOI 10.1109/TNNLS.2015.2430821
   Yao BP, 2010, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2010.5540234
   Zhang J., 2015, ADV MAT SCI ENG, V1, P1
   Zhang JG, 2015, J VIS COMMUN IMAGE R, V30, P376, DOI 10.1016/j.jvcir.2015.05.004
   Zhang Y., 2015, COMPUT INTEL NEUROSC, V2015, P44
   Zhong FJ, 2014, IEEE T NEUR NET LEAR, V25, P2065, DOI 10.1109/TNNLS.2014.2303798
   Zhu YM, 2014, SIGNAL PROCESS-IMAGE, V29, P875, DOI 10.1016/j.image.2014.06.005
NR 41
TC 8
Z9 8
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 260
EP 271
DI 10.1016/j.jvcir.2016.10.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000023
DA 2024-07-18
ER

PT J
AU Xu, XC
   Ma, J
   Nie, LQ
AF Xu, Xiaocheng
   Ma, Jun
   Nie, Liqiang
TI Weakly supervised image parsing via label propagation over
   discriminatively semantic graph
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised image parsing; Discriminative semantics
ID SEGMENTATION; RECOGNITION
AB In this paper, we concentrate on a challenging problem, i.e., weakly supervised image parsing, whereby only weak image-level labels are available in the dataset. In tradition, an affinity graph of superpixels is constructed to strengthen weak information by leveraging the neighbors from the perspective of image level labels. Existing work constructs the affinity graph by purely utilizing the visual relevance, where the context homogenization is a common phenomenon and hinders the performance of label prediction. To overcome the context homogenization problem, we not only consider the visual and semantic relevance but also the semantic distinction between every target superpixel and its neighbor superpixels in the affinity graph construction. We propose a novel way in constructing the inter-image contextual graph, and design a label propagation framework jointly combining visual relevance, semantic relevance and discriminative ability. Extensive experiments on real-world datasets demonstrate that our approach obtains significant gains. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xu, Xiaocheng; Ma, Jun; Nie, Liqiang] Shandong Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
C3 Shandong University
RP Ma, J (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM sduxxc@163.com; majun@sdu.edu.cn; nieliqiang@gmail.com
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], ARXIV150202734
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 2014 IEEE C COMP VIS
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cheng MM, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2682628
   Cui CR, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P895, DOI 10.1145/2733373.2806358
   [崔超然 Cui Chaoran], 2013, [计算机学报, Chinese Journal of Computers], V36, P654
   Ladicky L, 2013, INT J COMPUT VISION, V103, P213, DOI 10.1007/s11263-012-0583-y
   Ladicky L, 2009, IEEE I CONF COMP VIS, P739, DOI 10.1109/ICCV.2009.5459248
   Liu S, 2012, IEEE T MULTIMEDIA, V14, P361, DOI 10.1109/TMM.2011.2174780
   Liu XB, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2379790.2379792
   Liu XH, 2009, MPI STUD INTELL PROP, V6, P115, DOI 10.1145/1631272.1631291
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Sawant N, 2011, MULTIMED TOOLS APPL, V51, P213, DOI 10.1007/s11042-010-0650-8
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tighe J, 2010, LECT NOTES COMPUT SC, V6315, P352, DOI 10.1007/978-3-642-15555-0_26
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   Vezhnevets A, 2011, IEEE I CONF COMP VIS, P643, DOI 10.1109/ICCV.2011.6126299
   Xie WX, 2014, AAAI CONF ARTIF INTE, P2853
   Xie WX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P277, DOI 10.1145/2647868.2654910
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
NR 27
TC 0
Z9 0
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 808
EP 815
DI 10.1016/j.jvcir.2016.08.005
PN B
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600034
DA 2024-07-18
ER

PT J
AU Al-Zaydi, ZQH
   Ndzi, DL
   Yang, YY
   Kamarudin, ML
AF Al-Zaydi, Zeyad Q. H.
   Ndzi, David L.
   Yang, Yanyan
   Kamarudin, Munirah L.
TI An adaptive people counting system with dynamic features selection and
   occlusion handling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Surveillance systems; Image processing; Computer vision
ID CROWD ESTIMATION; DENSITY
AB This paper presents an adaptive crowd counting system for video surveillance applications. The proposed method is composed of a pair of collaborative Gaussian process models (GP) with different kernels, which are designed to count people by taking the level of occlusion into account. The level of occlusion is measured and compared with a predefined threshold for regression model selection for each frame. In addition, the proposed method dynamically identifies the best combination of features for people counting. The Mall and UCSD datasets are used to evaluate the proposed method. The results show that the proposed method offers a higher accuracy when compared against state of the art methods reported in open literature. The mean absolute error (MAE), mean squared error (MSE) and the mean deviation error (MDE) for the proposed algorithm are 2.90, 13.70 and 0.095, respectively, for the Mall dataset and 1.63, 4.32 and 0.066, respectively, for UCSD dataset. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Al-Zaydi, Zeyad Q. H.; Ndzi, David L.; Yang, Yanyan] Univ Portsmouth, Sch Engn, Portsmouth PO1 3DJ, Hants, England.
   [Kamarudin, Munirah L.] Univ Malaysia Perlis, Sch Comp & Commun Engn, Perlis, Malaysia.
C3 University of Portsmouth; Universiti Malaysia Perlis
RP Al-Zaydi, ZQH (corresponding author), Univ Portsmouth, Sch Engn, Portsmouth PO1 3DJ, Hants, England.
EM zeyad.al-zaydi@port.ac.uk; david.ndzi@port.ac.uk; linda.yang@port.ac.uk;
   latifahmunirah@unimap.edu.my
RI Kamarudin, Latifah Munirah/AAF-9445-2020; Yang, Linda/KEJ-3896-2024;
   Habeeb, Zeyad Qasim/D-4470-2019; Kamarudin, Latifah Munirah/G-8267-2016
OI Habeeb, Zeyad Qasim/0000-0001-6188-9956; Ndzi,
   David/0000-0002-1125-1978; Kamarudin, Latifah
   Munirah/0000-0002-2547-3934; Yang, Yanyan/0000-0003-1047-2274
CR Albiol A., 2009, 3International_Workshop_on Performance_Evaluation_of_Tracking_and_Surveillance, P31
   Albiol A, 2009, IEEE IMAGE PROC, P2569, DOI 10.1109/ICIP.2009.5414002
   [Anonymous], P IEEE INT C VID SIG
   [Anonymous], 2014, PEOPLE DETECTION TRA
   [Anonymous], GAUSSIAN PROCESSES R
   [Anonymous], 2004, Surveillance & Society, DOI 10.24908/ss.v2i2/3.3369
   [Anonymous], SINGLE PIXEL APPROAC
   [Anonymous], 12034855 ARXIV
   [Anonymous], 2011 IEEE INT WORK I
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 9 INT S PETS NO PETS
   [Anonymous], CROWD MONITORING USI
   [Anonymous], 2013, CROWD MONITORING USI
   [Anonymous], P BR MACH VIS C 2012
   [Anonymous], DATA ASSIMILATION AG
   [Anonymous], 2008 IEEE COMP SOC C
   [Anonymous], IMPROVED METHOD CROW
   [Anonymous], 4 INT C FUZZ SYST KN
   [Anonymous], AM J SOCIAL ISSUES H
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   [Anonymous], 26 IEEE C COMP VIS P
   Bobo Wang, 2013, Journal of Multimedia, V8, P331, DOI 10.4304/jmm.8.4.331-337
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen K, 2014, INT C PATT RECOG, P4672, DOI 10.1109/ICPR.2014.799
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Cho SY, 1999, NEURAL PROCESS LETT, V10, P111, DOI 10.1023/A:1018781301409
   Cho SY, 1999, IEEE T SYST MAN CY B, V29, P535, DOI 10.1109/3477.775269
   Chow TWS, 1999, ARTIF INTELL ENG, V13, P301, DOI 10.1016/S0954-1810(99)00016-3
   Conte D., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1743, DOI 10.1109/ICPR.2010.431
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Foroughi Homa, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4354, DOI 10.1109/ICASSP.2014.6854424
   Fradi H, 2012, EUR SIGNAL PR CONF, P136
   Gandhi V, 2012, IEEE INT CONF ROBOT, P4742, DOI 10.1109/ICRA.2012.6224771
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Hou YL, 2011, IEEE T SYST MAN CY A, V41, P24, DOI 10.1109/TSMCA.2010.2064299
   Jeong CY, 2013, IEEE IMAGE PROC, P4545, DOI 10.1109/ICIP.2013.6738936
   Jin R, 2004, LECT NOTES COMPUT SC, V3201, P560
   Jin R, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P746
   Jingwen Li, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P54, DOI 10.1109/AVSS.2011.6027294
   Lin WC, 2011, 2011 IEEE 22ND INTERNATIONAL SYMPOSIUM ON PERSONAL INDOOR AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1015, DOI 10.1109/PIMRC.2011.6139649
   Loy C.C., 2013, Crowd counting and profiling: Methodology and evaluation
   Ma HD, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2089094.2089107
   Ma RH, 2004, 2004 IEEE CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS, VOLS 1 AND 2, P170
   Ma Z, 2013, PROC CVPR IEEE, P2539, DOI 10.1109/CVPR.2013.328
   Marana AN, 1999, INT CONF ACOUST SPEE, P3521, DOI 10.1109/ICASSP.1999.757602
   Merad Djamel, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P233, DOI 10.1109/AVSS.2010.77
   Nakatsuka M., 2008, 4 INT C MOB COMPUT U, P1
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Ryan D, 2014, PATTERN RECOGN LETT, V44, P98, DOI 10.1016/j.patrec.2013.10.002
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Saleh SAM, 2015, ENG APPL ARTIF INTEL, V41, P103, DOI 10.1016/j.engappai.2015.01.007
   Topkaya IS, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P313, DOI 10.1109/AVSS.2014.6918687
   Tu JH, 2013, IEEE IMAGE PROC, P3340, DOI 10.1109/ICIP.2013.6738688
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xi W, 2014, IEEE INFOCOM SER, P361, DOI 10.1109/INFOCOM.2014.6847958
   Yaoxuan Yuan, 2011, Proceedings of the 2011 Seventh International Conference on Mobile Ad-hoc and Sensor Networks (MSN 2011), P138, DOI 10.1109/MSN.2011.31
   Zhang JP, 2011, IEEE T INTELL TRANSP, V12, P1037, DOI 10.1109/TITS.2011.2132759
   Zhang ZX, 2015, NEUROCOMPUTING, V166, P151, DOI 10.1016/j.neucom.2015.03.083
   Zhu F.Z.F., 2009, 2009 2 INT C INT NET, V1, P5
NR 61
TC 15
Z9 16
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 218
EP 225
DI 10.1016/j.jvcir.2016.05.018
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900021
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Muddala, SM
   Sjöström, M
   Olsson, R
AF Muddala, Suryanarayana M.
   Sjostrom, Marten
   Olsson, Roger
TI Virtual view synthesis using layered depth image generation and
   depth-based inpainting for filling disocclusions and translucent
   disocclusions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE View synthesis; Depth-image based rendering; Image inpainting; Texture
   synthesis; Hole filling; Disocclusions; Translucent disocclusions;
   Layered depth image
ID VIDEO
AB View synthesis is an efficient solution to produce content for 3DTV and FTV. However, proper handling of the disocclusions is a major challenge in the view synthesis. Inpainting methods offer solutions for handling disocclusions, though limitations in foreground-background classification causes the holes to be filled with inconsistent textures. Moreover, the state-of-the art methods fail to identify and fill disocclusions in intermediate distances between foreground and background through which background may be visible in the virtual view (translucent disocclusions). Aiming at improved rendering quality, we introduce a layered depth image (LDI) in the original camera view, in which we identify and fill occluded background so that when the LDI data is rendered to a virtual view, no disocclusions appear but views with consistent data are produced also handling translucent disocclusions. Moreover, the proposed foreground-background classification and inpainting fills the disocclusions with neighboring background texture consistently. Based on the objective and subjective evaluations, the proposed method outperforms the state-of-the art methods at the disocclusions. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Muddala, Suryanarayana M.; Sjostrom, Marten; Olsson, Roger] Mid Sweden Univ, Dept Informat & Commun Syst, S-85170 Sundsvall, Sweden.
C3 Mid-Sweden University
RP Sjöström, M (corresponding author), Mid Sweden Univ, Dept Informat & Commun Syst, S-85170 Sundsvall, Sweden.
EM marten.sjostrom@miun.se
RI Sjöström, Mårten/AAE-8617-2022
OI Sjöström, Mårten/0000-0003-3751-6089
FU KK Foundation, Sweden [20120328, 20140200]
FX The authors would like to thank the reviewers for their comments and
   suggestions, which has enabled us to improve the presentation of this
   research. This work has in part been supported by grants 20120328 and
   20140200 of the KK Foundation, Sweden.
CR Ahn I, 2013, IEEE T BROADCAST, V59, P614, DOI 10.1109/TBC.2013.2281658
   [Anonymous], P SPIE
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2011, 3DTV C TRUE VIS CAPT
   [Anonymous], 2010, JTC1SC29WG11 ISOIEC
   Bartczak B, 2011, IEEE T BROADCAST, V57, P477, DOI 10.1109/TBC.2011.2120790
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Choi S, 2013, IEEE T IMAGE PROCESS, V22, P2429, DOI 10.1109/TIP.2013.2251646
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo I, 2011, IEEE T BROADCAST, V57, P533, DOI 10.1109/TBC.2011.2125110
   Domanski M, 2009, ISO/IEC JTC1/SC29/WG11 MPEG/M17050
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Habigt J, 2013, IEEE IMAGE PROC, P2131, DOI 10.1109/ICIP.2013.6738439
   Jantet V, 2011, 3D RES, V2, DOI 10.1007/3DRes.04(2011)4
   Lim H, 2011, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP.2011.6115615
   Ma LN, 2012, IEEE IMAGE PROC, P1721, DOI 10.1109/ICIP.2012.6467211
   Muddala S. M., 2014, 3DTV C TRUE VIS CAPT, P1
   Muddala S.M., 2013, 5 INT C ADV MULT MME
   Muddala S. M., 2013, INT J ADV TEL COM, V6, P132
   Muddala SM, 2012, INT CONF 3D IMAG
   Muller K., 2009, EURASIP Journal on Image and Video Processing, P1
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Schreer O, 2005, 3D VIDEOCOMMUNICATION: ALGORITHMS, CONCEPTS AND REAL-TIME SYSTEMS IN HUMAN CENTRED COMMUNICATION, P1, DOI 10.1002/0470022736
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Sjostrom M., 2011, 2011 3DTV C TRUE VIS, P1
   Smolic A, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P389
   Tanimoto M., 2006, P IEEE COMP VIS PATT, P172
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tian D, 2009, PROC SPIE, V7443, DOI 10.1117/12.829372
   Um GM, 2008, JTC1SC29WG11M15371 I
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolinski D., 2013, ACM MULTIMEDIA
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zilly F, 2014, J VIS COMMUN IMAGE R, V25, P632, DOI 10.1016/j.jvcir.2013.07.002
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 37
TC 23
Z9 25
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 351
EP 366
DI 10.1016/j.jvcir.2016.02.017
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100030
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Wei, L
   Wang, XF
   Yin, J
   Wu, AH
AF Wei, Lai
   Wang, Xiaofeng
   Yin, Jun
   Wu, Aihua
TI Spectral clustering steered low-rank representation for subspace
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Subspace segmentation; Sparse representation; low-rank representation;
   Normalize cut
ID PARALLEL FRAMEWORK; FACE RECOGNITION; SPARSE GRAPH; ALGORITHM; HEVC
AB Low-rank representation (LRR) and its variations have achieved great successes in subspace segmentation tasks. However, the segmentation processes of the existing LRR-related methods are all divided into two separated steps: affinity graphs construction and segmentation results obtainment. In the second step, normalize cut (Ncut) algorithm is used to get the final results based on the constructed graphs. This implies that the affinity graphs obtained by LRR-related algorithms may not be most suitable for Ncut, and the best results are not guaranteed to be achieved. In this paper, we propose a spectral clustering steered LRR representation algorithm (SCSLRR) which combines the objection functions of Ncut, K-means and LRR together. By solving a joint optimization problem, SCSLRR is able to find low-rank affinity matrices which are most beneficial for Ncut to get best segmentation results. The extensive experiments of subspace segmentation on several benchmark datasets show that SCSLRR dominates the related methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wei, Lai; Wang, Xiaofeng; Yin, Jun; Wu, Aihua] Shanghai Maritime Univ, Dept Comp Sci, Haigang Ave 1550, Shanghai, Peoples R China.
C3 Shanghai Maritime University
RP Wei, L (corresponding author), Shanghai Maritime Univ, Dept Comp Sci, Haigang Ave 1550, Shanghai, Peoples R China.
EM weilai@shmtu.edu.cn; xfwang@shmtu.edu.cn; junyin@shmtu.edu.cn;
   ahwu@shmtu.edu.cn
RI li, ye/GWN-2672-2022; Yin, Jun/P-6858-2014; Hu, Shaolin/N-1791-2018; Li,
   Ye/JBS-2949-2023
FU National Science Foundation of China [61203240, 61202022]; National
   Science Foundation of Shanghai [13ZR1455600]; Innovation Program of
   Shanghai Municipal Education Commission [14YZ102]
FX The authors thank anonymous reviewers for their constructive comments on
   this paper. This work is supported by the National Science Foundation of
   China (Nos. 61203240, 61202022), the National Science Foundation of
   Shanghai (No. 13ZR1455600) and the Innovation Program of Shanghai
   Municipal Education Commission (14YZ102).
CR [Anonymous], CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], 2015, CVPR
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bradley PS, 2000, J GLOBAL OPTIM, V16, P23, DOI 10.1023/A:1008324625522
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chen JH, 2014, IEEE T CYBERNETICS, V44, P1432, DOI 10.1109/TCYB.2013.2286106
   Ding C., 2004, ICML
   Duchi J., 2009, P 26 ANN INT C MACHI, P297
   Duda R., 1973, Pattern Classification and Scene Analysis
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Huang K, 2004, PROC CVPR IEEE, P631
   Jiang JL, 2015, NEUROCOMPUTING, V151, P817, DOI 10.1016/j.neucom.2014.10.017
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leonardis A, 2002, PATTERN RECOGN, V35, P2613, DOI 10.1016/S0031-3203(01)00198-4
   Li L, 2012, IEEE T MULTIMEDIA, V14, P1401, DOI 10.1109/TMM.2012.2194993
   Li S., 2013, IJCAI
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lu CY, 2013, IEEE I CONF COMP VIS, P1801, DOI 10.1109/ICCV.2013.226
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Ma Y, 2008, SIAM REV, V50, P413, DOI 10.1137/060655523
   Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Patel VM, 2013, IEEE I CONF COMP VIS, P225, DOI 10.1109/ICCV.2013.35
   Qiao LS, 2010, PATTERN RECOGN LETT, V31, P422, DOI 10.1016/j.patrec.2009.11.005
   Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang KW, 2014, IEEE T NEUR NET LEAR, V25, P2167, DOI 10.1109/TNNLS.2014.2306063
   Tron R., 2007, P 2007 CVPR 07 IEEE, V1, P8
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   Wei L, 2015, EXPERT SYST APPL, V42, P6598, DOI 10.1016/j.eswa.2015.04.041
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang M., 2011, CVPR
   Yin M., 2015, IEEE T PATTERN ANAL, P1
   Yin M, 2015, IEEE T IMAGE PROCESS, V24, P4918, DOI 10.1109/TIP.2015.2472277
   Zhang T, 2012, INT J COMPUT VISION, V100, P217, DOI 10.1007/s11263-012-0535-6
   Zhao MY, 2014, NEUROCOMPUTING, V140, P84, DOI 10.1016/j.neucom.2014.03.033
   Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944
NR 48
TC 11
Z9 11
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 386
EP 395
DI 10.1016/j.jvcir.2016.03.017
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100033
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhang, BX
   Zhu, ZB
   Wang, S
AF Zhang, Benxin
   Zhu, Zhibin
   Wang, Shuo
TI A simple primal-dual method for total variation image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Primal-dual method; Saddle-point problem; Total variation; Image
   reconstruction
ID MANY-CORE PROCESSORS; CONVERGENCE ANALYSIS; CONVEX MINIMIZATION;
   PARALLEL FRAMEWORK; SPLITTING METHOD; ALGORITHM; HEVC; OPTIMIZATION;
   MULTIPLIERS
AB In this study we propose a simple primal-dual method for total variation minimization problems. A predictor-corrector scheme to the dual variable is used in our algorithms and convergence of the method is proved. We also show that the iterative scheme has O(1/N) convergence rate in the ergodic sense, where N denotes the iteration number. Numerical results including image deblurring and computerized tomography reconstruction demonstrate the efficient of the new algorithms. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Benxin] Guilin Univ Elect Technol, Key Lab Automat Detecting Technol & Instruments, Sch Elect Engn & Automat, Guilin 541004, Peoples R China.
   [Zhu, Zhibin; Wang, Shuo] Guilin Univ Elect Technol, Sch Math & Comp Sci, Guangxi Coll & Univ, Key Lab Data Anal & Computat, Guilin 541004, Peoples R China.
C3 Guilin University of Electronic Technology; Guilin University of
   Electronic Technology
RP Zhu, ZB (corresponding author), Guilin Univ Elect Technol, Sch Math & Comp Sci, Guangxi Coll & Univ, Key Lab Data Anal & Computat, Guilin 541004, Peoples R China.
EM optimization_zhu@163.com
RI Zhu, Zhi-Bin/H-6871-2012
FU NNSF of China [11361018, 11461015]; Guangxi Natural Science Foundation
   [2014GXNSFFA118001]; Guangxi Key Laboratory of Automatic Detecting
   Technology and Instruments [YQ15112, YQ16112]; Guilin Science and
   Technology Project [20140127-2]; Innovation Project of Guangxi Graduate
   Education and Innovation Project of GUET Graduate Education
   [YJCXB201502]
FX We thank the editor and the anonymous reviewers for their valuable
   comments which help to improve this paper. This work is supported in
   part by NNSF (Nos. 11361018 and 11461015) of China, Guangxi Natural
   Science Foundation (No. 2014GXNSFFA118001), Guangxi Key Laboratory of
   Automatic Detecting Technology and Instruments (Nos. YQ15112 and
   YQ16112), Guilin Science and Technology Project (No. 20140127-2),
   Innovation Project of Guangxi Graduate Education and Innovation Project
   of GUET Graduate Education(No. YJCXB201502).
CR [Anonymous], 2008, SIAM J OPTIMIZ
   [Anonymous], 2008, 0834 CAM UCLA
   Avinash C. K., 2001, PRINCIPLES COMPUTERI
   Bauschke H., 2011, AMS BOOKS MATH
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bertsekas D. P., 1982, REINFORCEMENT LEARNI
   Bonettini S, 2012, J MATH IMAGING VIS, V44, P236, DOI 10.1007/s10851-011-0324-9
   Bot RI, 2013, SIAM J OPTIMIZ, V23, P2011, DOI 10.1137/12088255X
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Chen CH, 2016, MATH PROGRAM, V155, P57, DOI 10.1007/s10107-014-0826-5
   Chen PJ, 2013, INVERSE PROBL, V29, DOI 10.1088/0266-5611/29/2/025011
   Chen YM, 2013, COMPUT OPTIM APPL, V54, P317, DOI 10.1007/s10589-012-9519-2
   Combettes P, 2012, SET-VALUED VAR ANAL, V20, P307, DOI 10.1007/s11228-011-0191-y
   Dai YH, 2005, NUMER MATH, V100, P21, DOI 10.1007/s00211-004-0569-y
   Davis D., 2015, 1513 UCLA CAM
   Davis D, 2015, SIAM J OPTIMIZ, V25, P1912, DOI 10.1137/151003076
   Drori Y, 2015, OPER RES LETT, V43, P209, DOI 10.1016/j.orl.2015.02.001
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Fang EX, 2015, MATH PROGRAM COMPUT, V7, P149, DOI 10.1007/s12532-015-0078-2
   Gabay D., 1976, COMPUT MATH APPL, V2, P16, DOI DOI 10.1016/0898-1221(76)90003-1
   GLOWINSKI R, 1975, REV FR AUTOMAT INFOR, V9, P41
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   He BS, 2015, MATH PROGRAM, V153, P715, DOI 10.1007/s10107-014-0805-x
   He BS, 2015, NUMER MATH, V130, P567, DOI 10.1007/s00211-014-0673-6
   He BS, 2014, SIAM J IMAGING SCI, V7, P2526, DOI 10.1137/140963467
   He BS, 2012, SIAM J IMAGING SCI, V5, P119, DOI 10.1137/100814494
   Hestenes M. R., 1969, Journal of Optimization Theory and Applications, V4, P303, DOI 10.1007/BF00927673
   Nemirovski A, 2004, SIAM J OPTIMIZ, V15, P229, DOI 10.1137/S1052623403425629
   NESTEROV IE, 1983, DOKL AKAD NAUK SSSR+, V269, P543
   Nesterov Y, 2005, SIAM J OPTIMIZ, V16, P235, DOI 10.1137/S1052623403422285
   Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5
   Powell M.J.D., 1969, Optimization, P283
   ROCKAFELLAR RT, 1976, SIAM J CONTROL, V14, P877, DOI 10.1137/0314056
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shefi R, 2014, SIAM J OPTIMIZ, V24, P269, DOI 10.1137/130910774
   Tseng P, 2000, SIAM J CONTROL OPTIM, V38, P431, DOI 10.1137/S0363012998338806
   Tseng P, 1997, SIAM J OPTIMIZ, V7, P951, DOI 10.1137/S1052623495279797
   Wen YW, 2012, IEEE T IMAGE PROCESS, V21, P106, DOI 10.1109/TIP.2011.2159983
   Xiao Y., 2015, ARXIV150705691V1
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang TB, 2015, MACH LEARN, V98, P369, DOI 10.1007/s10994-014-5436-1
   Yu GH, 2009, J MATH IMAGING VIS, V35, P143, DOI 10.1007/s10851-009-0160-3
   Zhang XQ, 2011, J SCI COMPUT, V46, P20, DOI 10.1007/s10915-010-9408-8
NR 48
TC 12
Z9 14
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 814
EP 823
DI 10.1016/j.jvcir.2016.04.025
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100068
DA 2024-07-18
ER

PT J
AU Zhao, M
   Zhang, HX
   Sun, JD
AF Zhao, Meng
   Zhang, Huaxiang
   Sun, Jiande
TI A novel image retrieval method based on multi-trend structure descriptor
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-trend structure descriptor; Image retrieval; Visual perception
   mechanism; Local descriptor
ID TEXTURE CLASSIFICATION; COLOR; SCALE; FEATURES
AB This paper proposes an image feature representation method, namely Multi-Trend Structure Descriptor (MTSD), which is built based on the local and multi-trend structures. The local structures can be regarded as the basic units for image analysis, and the multi-trend structures are introduced to explore the correlation among pixels in local structures according to the information change of pixels. The visual information such as color, edge orientation and intensity map are considered and quantized, and with the local structure as a bridge, we use multi-trend to detect color, edge orientation and intensity map respectively for feature extraction. MTSD can characterize not only the low-level features, such as color, shape and texture, but also the local spatial structure information. We evaluate the performance of the proposed algorithm on Corel and Caltech datasets, and experimental results demonstrate that, MTSD significantly outperforms texton co-occurrence matrix, multi-texton histogram, micro-structure descriptor and saliency structure histogram. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhao, Meng; Zhang, Huaxiang; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@hotmail.com
RI Sun, Jiande/B-4681-2018
FU National Natural Science Foundation of China [61170145, 61373081,
   61402268, 61401260, 61572298]; Technology and Development Project of
   Shandong [2013GGX10125]; Natural Science Foundation of Shandong China
   [BS2014DX006, ZR2014FM012]; Taishan Scholar Project of Shandong, China
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61170145, 61373081, 61402268, 61401260,
   61572298), the Technology and Development Project of Shandong (No.
   2013GGX10125) the Natural Science Foundation of Shandong China (Nos.
   BS2014DX006, ZR2014FM012) and the Taishan Scholar Project of Shandong,
   China.
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 2002, P 5 NORD SIGN PROC S
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Celik T, 2011, PATTERN RECOGN LETT, V32, P159, DOI 10.1016/j.patrec.2010.10.003
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Ke Y., 2004, P 2004 IEEE COMP SOC, V2, pII
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Junling, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P921
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath B.S., 2002, Introduction to MPEG-7: multimedia content description interface, V1
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qiu GP, 2007, PATTERN RECOGN, V40, P1711, DOI 10.1016/j.patcog.2006.09.020
   Rallabandi VPS, 2008, KNOWL-BASED SYST, V21, P89, DOI 10.1016/j.knosys.2007.02.002
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   THEEUWES J, 1993, ACTA PSYCHOL, V83, P93, DOI 10.1016/0001-6918(93)90042-P
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [DOI 10.1145/2072298.2072034, 10.1145/2072298.2072034]
   Yao CH, 2003, PATTERN RECOGN, V36, P913, DOI 10.1016/S0031-3203(02)00124-3
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zheng L, 2015, IEEE T MULTIMEDIA, V17, P648, DOI 10.1109/TMM.2015.2408563
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
NR 38
TC 39
Z9 39
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 73
EP 81
DI 10.1016/j.jvcir.2016.02.016
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100008
DA 2024-07-18
ER

PT J
AU Shaila, SG
   Vadivel, A
AF Shaila, S. G.
   Vadivel, A.
TI Indexing and encoding based image feature representation with bin
   overlapped similarity measure for CBIR applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Indexing; Encoding; Distance measure; Image retrieval; Color features;
   GR Coding; BOSM; Histogram dimension
ID APPROXIMATE NEAREST-NEIGHBOR; RETRIEVAL; COLOR; SEARCH; TREES
AB In Content Based Image Retrieval (CBIR) system, the exhaustive search for a given query image to find the relevant images in the database are non-scalable. In this paper, we propose indexing, coding technique and similarity measure to address the above mentioned problem. We consider the color histogram of the image and its bin values are analyzed to understand the color information in the image. The histogram dimension is reduced by removing trivial bins and only those bins that represent color information significantly are considered. Based on the dimensions of the histogram, it is clustered and indexed. The Golomb-Rice (GR) coding is used to encode the indexed histograms. The Bin Overlapped Similarity Measure (BOSM) is proposed to compute the distance values between query and database image histograms. The performance of proposed approach is evaluated on benchmark datasets and found that the performance of the proposed approach is encouraging. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Shaila, S. G.; Vadivel, A.] Natl Inst Technol, Dept Comp Applicat, Informat Retrieval Grp, Tiruchirappalli 620015, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli
RP Vadivel, A (corresponding author), Natl Inst Technol, Dept Comp Applicat, Informat Retrieval Grp, Tiruchirappalli 620015, Tamil Nadu, India.
EM vadi@nitt.edu
RI A, Vadivel/AAX-2522-2020
OI A, Vadivel/0000-0002-0884-4676
FU Indo-US 21st Century Knowledge Initiative programme through University
   Grants Commission, India [F. No/94-5/2013(IC)]
FX The work done is supported by research grant from the Indo-US 21st
   Century Knowledge Initiative programme through University Grants
   Commission, India under Grant F. No/94-5/2013(IC) dated 19-08-2013.
CR Agrawal R., 1998, SIGMOD Record, V27, P94, DOI 10.1145/276305.276314
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], 10 INT C COMP INT SO
   [Anonymous], 1997, ART COMPUTER PROGRAM
   [Anonymous], 14 GI FACHT DAT BUS
   [Anonymous], MACHINE LEARNING DAT
   [Anonymous], INT J MULTIMEDIA APP
   [Anonymous], ACM COMPUT SURV CSUR
   [Anonymous], IEEE 2 INT C CYB CYB
   [Anonymous], INT C EL IM SPIE HUM
   [Anonymous], ICDE
   [Anonymous], 2010, CVPR
   [Anonymous], 2009, NIPS
   [Anonymous], INT C HUM VIS EL IM
   [Anonymous], 2010, ECCV
   [Anonymous], INT C EL IM SPIE HUM
   [Anonymous], 1992, Chaos and fractals: new frontiers of science
   [Anonymous], 2007, CVPR
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2009, NEURIPS
   [Anonymous], SELF ORGANIZING MAPS
   [Anonymous], 2008, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2008.4587841
   [Anonymous], 2010, CVPR
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   BARNSLEY MF, 1988, BYTE, V13, P215
   Barranco CD, 2008, FUZZY SET SYST, V159, P1431, DOI 10.1016/j.fss.2008.01.006
   Bawa M, 2005, Proceedings of the 14th International Conference on World Wide Web-WWW'05, P651, DOI [DOI 10.1145/1060745.1060840, 10.1145/1060745.1060840]
   Bayer R., 1972, Acta Informatica, V1, P173, DOI 10.1007/BF00288683
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bezdek JC, 2001, INT J INTELL SYST, V16, P1445, DOI 10.1002/int.1068
   Bhatia S. K., 2005, 2005 IEEE International Conference on Electro Information Technology (IEEE Cat. No. 05EX1098C)
   Bronstein AM, 2006, P NATL ACAD SCI USA, V103, P1168, DOI 10.1073/pnas.0508601103
   Cayton L, 2012, INT PARALL DISTRIB P, P402, DOI 10.1109/IPDPS.2012.45
   Chen LJ, 2011, IEEE T KNOWL DATA EN, V23, P204, DOI 10.1109/TKDE.2010.103
   Chen S., 2002, Proceedings of the 2002 ACM SIGMOD international conference on Management of data, P157
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   Cho SY, 2003, IEEE T NEURAL NETWOR, V14, P781, DOI 10.1109/TNN.2003.813831
   Chuang CH, 2014, J VIS COMMUN IMAGE R, V25, P1018, DOI 10.1016/j.jvcir.2014.02.014
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   Daoudi I, 2015, MULTIMED TOOLS APPL, V74, P4507, DOI 10.1007/s11042-013-1820-2
   Dasgupta S, 2008, ACM S THEORY COMPUT, P537
   Delhumeau J, 2013, REVISITING VLAD IMAG
   Fagin R., 1979, ACM Transactions on Database Systems, V4, P315, DOI 10.1145/320083.320092
   Garcia V, 2010, IEEE IMAGE PROC, P3757, DOI 10.1109/ICIP.2010.5654017
   Gouiffès M, 2013, J VIS COMMUN IMAGE R, V24, P361, DOI 10.1016/j.jvcir.2013.01.009
   Guibas Leo J., 1978, P 19 ANN S FDN COMP, P8, DOI DOI 10.1109/SFCS.1978.3
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   Guo JM, 2010, DIGIT SIGNAL PROCESS, V20, P97, DOI 10.1016/j.dsp.2009.04.007
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Hajebi Kiana, 2011, P 22 INT JOINT C ART, P1312
   He J., 2010, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P1129
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   JACQUIN AE, 1993, P IEEE, V81, P1451, DOI 10.1109/5.241507
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jannink J., 1995, SIGMOD Record, V24, P33, DOI 10.1145/202660.202666
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jia Y, 2010, PROC CVPR IEEE, P3392, DOI 10.1109/CVPR.2010.5540006
   Jouili S, 2012, PATTERN RECOGN, V45, P4054, DOI 10.1016/j.patcog.2012.04.016
   Kailing K, 2004, SIAM PROC S, P246
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kim Changkyu, 2010, P 2010 ACM SIGMOD IN, P339
   Kramm Matthias, 2007, 2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System (SITIS), P989, DOI 10.1109/SITIS.2007.144
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Laaksonen J, 2002, IEEE T NEURAL NETWOR, V13, P841, DOI 10.1109/TNN.2002.1021885
   Le SQ, 2005, PATTERN RECOGN LETT, V26, P2549, DOI 10.1016/j.patrec.2005.06.002
   Lechman T. J., 1986, Proceedings of Very Large Data Bases. Twelfth International Conference on Very Large Data Bases, P294
   Lee IH, 2007, LECT NOTES COMPUT SC, V4443, P398
   Litwin Witold., 1980, VLDB
   Liu Y, 2008, PATTERN RECOGN, V41, P2554, DOI 10.1016/j.patcog.2007.12.003
   Lord PW, 2003, BIOINFORMATICS, V19, P1275, DOI 10.1093/bioinformatics/btg153
   Lu Haiping., 2008, P 25 INT C MACHINE L, P616
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Poursistani P, 2013, MATH COMPUT MODEL, V57, P1005, DOI 10.1016/j.mcm.2011.11.064
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Rahman SA, 2013, J VIS COMMUN IMAGE R, V24, P217, DOI 10.1016/j.jvcir.2012.12.001
   Recupero DR, 2007, INFORM RETRIEVAL, V10, P563, DOI 10.1007/s10791-007-9035-7
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rubner L. J., 1997, P ARPA IM UND WORKSH, P661
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Sebastian TB, 2002, INT C PATT RECOG, P291, DOI 10.1109/ICPR.2002.1047852
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   SPROULL RF, 1991, ALGORITHMICA, V6, P579, DOI 10.1007/BF01759061
   Stehling RO, 2001, 2001 INTERNATIONAL DATABASE ENGINEERING & APPLICATIONS SYMPOSIUM, PROCEEDINGS, P356, DOI 10.1109/IDEAS.2001.938104
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao Yang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P459, DOI 10.1109/IIH-MSP.2009.191
   Torres L., 1996, VIDEO CODING 2 GENER
   Vadivel A, 2008, INT J SIGNAL IMAGING, V1, P245, DOI 10.1504/IJSISE.2008.026796
   Vadivel A., 2003, P INT C INF TECHN CI, P159
   Wang H., 2013, INT C MACHINE LEARNI, P352
   Wang H, 2013, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2013.398
   Wang J, 2012, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2012.6247790
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2010, IMAGE VISION COMPUT, V28, P1303, DOI 10.1016/j.imavis.2010.01.008
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Weiss Y., 2008, NIPS, V9, P6
   Weiss Y, 2012, LECT NOTES COMPUT SC, V7576, P340, DOI 10.1007/978-3-642-33715-4_25
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xu H, 2011, IEEE I CONF COMP VIS, P1631, DOI 10.1109/ICCV.2011.6126424
   Xu HL, 2007, LECT NOTES COMPUT SC, V4418, P82
   Yazici A, 2008, IEEE T FUZZY SYST, V16, P942, DOI 10.1109/TFUZZ.2008.917304
   Yu DT, 2003, IEEE T KNOWL DATA EN, V15, P1316, DOI 10.1109/TKDE.2003.1232281
   Yu Guangchuang, 2011, J Clin Bioinforma, V1, P15, DOI 10.1186/2043-9113-1-15
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou Jingren, 2002, P 2002 ACM SIGMOD IN, P145, DOI DOI 10.1145/564691.564709
NR 119
TC 7
Z9 7
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 40
EP 55
DI 10.1016/j.jvcir.2016.01.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200004
DA 2024-07-18
ER

PT J
AU Xu, DW
   Wang, RD
   Shi, YQ
AF Xu, Dawen
   Wang, Rangding
   Shi, Yun Q.
TI An improved scheme for data hiding in encrypted H.264/AVC videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Encrypted domain; H.264/AVC; Context-adaptive variable
   length coding (CAVLC); Code-word substitution; Data extraction;
   Code-word pair; Data embedding capacity
ID WATERMARKING
AB Recently, a novel scheme to hide data into encrypted H.264/AVC videos using code-word substitution has been proposed by Xu et al. However, the statistical analysis of CAVLC code-words demonstrate that Xu et al.'s work does not fully exploit redundancy existing in CAVLC code-word for data embedding. In this paper, an improved version of Xu et al.'s data hiding method in encrypted H.264/AVC videos is proposed. Specifically, when suffixLength is equal to 1, data embedding is performed by paired code-word substitution. When suffixLength is greater than 2, not the single code-word substitution but the multiple-based notational system is adopted for data embedding. Experimental results have demonstrated that the improved method is indeed capable of providing a larger embedding capacity in comparison with Xu et al.'s method. Moreover, both encryption and data embedding can be accomplished without affecting the coding efficiency of H.264/AVC by keeping exactly the same bitrate. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xu, Dawen] Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Zhejiang, Peoples R China.
   [Wang, Rangding] Ningbo Univ, CKC Software Lab, Ningbo 315211, Zhejiang, Peoples R China.
   [Shi, Yun Q.] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
C3 Ningbo University of Technology; Ningbo University; New Jersey Institute
   of Technology
RP Xu, DW (corresponding author), Ningbo Univ Technol, Sch Elect & Informat Engn, Ningbo 315016, Zhejiang, Peoples R China.
EM dawenxu@126.com
RI Shi, Yun/JWP-3360-2024; xu, dawen/ABF-5343-2021
OI xu, dawen/0000-0002-9619-8407
FU National Natural Science Foundation of China [61301247, 61170137,
   61300055]; Zhejiang Provincial Natural Science Foundation of China
   [LY13F020013, LZ15F020002]; Public Welfare Technology Application
   Research Project of Zhejiang Province [2015C33237]; Open Fund of
   Zhejiang Provincial Top Key Discipline [xkx11405]
FX This work is supported by the National Natural Science Foundation of
   China (61301247, 61170137 and 61300055), Zhejiang Provincial Natural
   Science Foundation of China (LY13F020013 and LZ15F020002), Public
   Welfare Technology Application Research Project of Zhejiang Province
   (2015C33237), Open Fund of Zhejiang Provincial Top Key Discipline
   (xkx11405).
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Li J, 2012, TRANSPORTMETRICA, V8, P387, DOI 10.1080/18128602.2010.521532
   Lian SG, 2006, IEEE T CONSUM ELECTR, V52, P621, DOI 10.1109/TCE.2006.1649688
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Stütz T, 2014, IEEE T MULTIMEDIA, V16, P1337, DOI 10.1109/TMM.2014.2310595
   Stütz T, 2012, IEEE T CIRC SYST VID, V22, P325, DOI 10.1109/TCSVT.2011.2162290
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tew Y, 2014, IEEE T CIRC SYST VID, V24, P305, DOI 10.1109/TCSVT.2013.2276710
   Xu DW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033028
   Xu DW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053022
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Xu DW, 2012, J REAL-TIME IMAGE PR, V7, P205, DOI 10.1007/s11554-010-0175-4
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
   Zhao B, 2010, INFORM SCIENCES, V180, P4672, DOI 10.1016/j.ins.2010.08.003
   Zheng P. J., 2012, 14 INF HID C BERK CA, P1
   Zhou L, 2013, IEEE T INF FOREN SEC, V8, P1947, DOI 10.1109/TIFS.2013.2286456
NR 21
TC 34
Z9 34
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 229
EP 242
DI 10.1016/j.jvcir.2016.02.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200019
DA 2024-07-18
ER

PT J
AU Zheng, YP
   Sarem, M
AF Zheng, Yunping
   Sarem, Mudar
TI A fast region segmentation algorithm on compressed gray images using
   Non-symmetry and Anti-packing Model and Extended Shading representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; Image segmentation; Quadtree Shading (QS);
   Hierarchical representation model; Non-symmetry and Anti-packing Model
   and Extended Shading (NAMES); Binary Partition Tree (BPT); Homogeneous
   block; Region segmentation; Compressed gray images
ID BINARY-TREE; MEAN-SHIFT; QUADTREE; RECOGNITION; STRATEGIES; STANDARD;
   LEVEL
AB Image segmentation is one of the fundamental steps in image analysis for object identification. The main goal of image segmentation is to recognize homogeneous regions within an image as distinct and belonging to different objects. Inspired by the idea of the packing problem, in this paper, we propose a fast O(N alpha(N))-time algorithm for image segmentation by using Non-symmetry and Anti-packing Model and Extended Shading representation, which was called the NAMES-based algorithm, where N is the number of homogenous blocks and alpha(N) is the inverse of the Ackerman's function and it is a very slowly growing function. We first put forward four extended Lemmas and two extended Theorems. Then, we present a new scanning method used to process each NAMES block. Finally, we propose a novel NAMES-based data structure used to merge two regions. With the same experimental conditions and the same time complexity, our proposed NAMES-based algorithm, which extends the popular hierarchical representation model to a new non-hierarchical representation model, has about 86.75% and 89.47% average execution time improvement ratio when compared to the Binary Partition Tree (BPT)-based algorithm and the Quadtree Shading (QS)-based algorithm which has about 55.4% execution time improvement ratio when the QS -based algorithm itself is compared to the previous fastest region segmentation algorithm by Fiorio and Gustedt whose O(N-2) -time algorithm is run on the original N x N gray image. Further, the NAMES can improve the memory-saving by 28.85% (5.04%) and simultaneously reduce the number of the homogeneous blocks by 49.05% (36.04%) more than the QS (the BPT) whereas maintaining the satisfactory image quality. Therefore, by comparing our NAMES-based algorithm with the QS-based algorithm and the BPT-based algorithm, the experimental results presented in this paper show that the former has not only higher compression ratio and less number of homogenous blocks than the latter whereas maintaining the satisfactory image quality, but also can significantly improve the execution speed for image segmentation, and therefore it is a much more effective algorithm for image segmentation. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Zheng, Yunping] S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Zheng, Yunping] Univ Penn, Dept Radiol, Med Image Proc Grp, Philadelphia, PA 19104 USA.
   [Sarem, Mudar] Huazhong Univ Sci & Technol, Sch Software Engn, Wuhan 430074, Hubei, Peoples R China.
C3 South China University of Technology; University of Pennsylvania;
   Huazhong University of Science & Technology
RP Zheng, YP (corresponding author), S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM zhengyp@scut.edu.cn; mudar@hust.edu.cn
FU National Natural Science Foundation of China [61300134]; Research Fund
   for the Doctoral Program of Higher Education of China [20120172120036];
   Natural Science Foundation of Guangdong Province of China
   [S2011040005815, S2013010012515, 2015A030313206]; Fundamental Research
   Funds for the Central Universities of China [2015ZM133]; Chinese
   National Scholarship Fund [201406155015]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61300134, the Research Fund for the Doctoral
   Program of Higher Education of China under Grant No. 20120172120036, the
   Natural Science Foundation of Guangdong Province of China under Grant
   Nos. S2011040005815, S2013010012515, and 2015A030313206, the Fundamental
   Research Funds for the Central Universities of China under Grant No.
   2015ZM133, and Chinese National Scholarship Fund under Grant No.
   201406155015.
CR Banerjee B, 2014, IEEE J-STARS, V7, P888, DOI 10.1109/JSTARS.2013.2266572
   Bauer C, 2014, IEEE T BIO-MED ENG, V61, P119, DOI 10.1109/TBME.2013.2277936
   Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792
   Chen C., 1988, 9 INT C PATT REC, V1, P576
   Chen CB, 2011, COMPUT ELECTR ENG, V37, P669, DOI 10.1016/j.compeleceng.2011.07.006
   Chen SK, 2006, IEEE T KNOWL DATA EN, V18, P784, DOI 10.1109/TKDE.2006.86
   Chen TW, 2012, IEEE T VLSI SYST, V20, P2329, DOI 10.1109/TVLSI.2011.2170203
   Cho H, 2014, IEEE T CONSUM ELECTR, V60, P719, DOI 10.1109/TCE.2014.7027348
   Chung KL, 2000, IEEE T COMMUN, V48, P748, DOI 10.1109/26.843184
   Chung KL, 2004, PATTERN RECOGN, V37, P1591, DOI 10.1016/j.patcog.2004.02.009
   David T, 2011, MATH COMPUT SIMULAT, V81, P1464, DOI 10.1016/j.matcom.2010.04.020
   Dillencourt MB, 1996, ALGORITHMICA, V15, P82, DOI 10.1007/BF01942608
   Distasi R, 1997, IEEE T COMMUN, V45, P1095, DOI 10.1109/26.623074
   Fiorio C, 1996, THEOR COMPUT SCI, V154, P165, DOI 10.1016/0304-3975(94)00262-2
   Gao H, 2001, IEEE T CIRC SYST VID, V11, P1273, DOI 10.1109/76.974681
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Gong ML, 2004, PATTERN RECOGN, V37, P1723, DOI 10.1016/j.patcog.2004.02.004
   Gonzalez A. A., 2012, IEEE T GEOSCI REMOTE, V50, P593, DOI [10.1109/TGRS.2011.2160647, DOI 10.1109/TGRS.2011.2160647]
   Hariharan B, 2005, PARALLEL COMPUT, V31, P311, DOI 10.1016/j.parco.2004.12.007
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Huang KK, 2012, IEEE T GEOSCI REMOTE, V50, P3737, DOI 10.1109/TGRS.2012.2187340
   Katouzian A, 2012, IEEE T INF TECHNOL B, V16, P823, DOI 10.1109/TITB.2012.2189408
   Klinger A., 1973, P 1 INT JOINT C PATT, P497
   Chung KL, 2006, J VIS COMMUN IMAGE R, V17, P1209, DOI 10.1016/j.jvcir.2006.01.002
   Laferté JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777
   Liu Z, 2011, SIGNAL PROCESS, V91, P290, DOI 10.1016/j.sigpro.2010.07.006
   Nguyen TM, 2010, IEEE T NEURAL NETWOR, V21, P1326, DOI 10.1109/TNN.2010.2054109
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   PANDA DP, 1978, IEEE T COMPUT, V27, P875, DOI 10.1109/TC.1978.1675208
   Perret B, 2012, IEEE T IMAGE PROCESS, V21, P14, DOI 10.1109/TIP.2011.2161322
   SAMET H, 1984, ACM COMPUT SURV, V16, P187, DOI DOI 10.1145/356924.356930
   Shridhar M., 1986, Canadian Electrical Engineering Journal, V11, P172
   Sidiropoulos P, 2011, PATTERN RECOGN, V44, P739, DOI 10.1016/j.patcog.2010.09.014
   SKLANSKY J, 1978, IEEE T SYST MAN CYB, V8, P237, DOI 10.1109/TSMC.1978.4309944
   Udupa JK, 2014, MED IMAGE ANAL, V18, P752, DOI 10.1016/j.media.2014.04.003
   Veganzones MA, 2014, IEEE T IMAGE PROCESS, V23, P3574, DOI 10.1109/TIP.2014.2329767
   Wang JD, 2014, IEEE T IMAGE PROCESS, V23, P1909, DOI 10.1109/TIP.2014.2307479
   Wang XF, 2015, IEEE T IMAGE PROCESS, V24, P1399, DOI 10.1109/TIP.2015.2397313
   Werghi N, 2007, IEEE T SYST MAN CY C, V37, P1122, DOI 10.1109/TSMCC.2007.905808
   Wong WCK, 2005, IEEE T IMAGE PROCESS, V14, P1512, DOI 10.1109/TIP.2005.852199
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Zheng YP, 2014, FRONT COMPUT SCI-CHI, V8, P763, DOI 10.1007/s11704-014-3103-0
   Zheng YP, 2012, J VIS COMMUN IMAGE R, V23, P972, DOI 10.1016/j.jvcir.2012.06.007
   Zheng YP, 2011, FRONT COMPUT SCI CHI, V5, P57, DOI 10.1007/s11704-010-0337-3
NR 45
TC 10
Z9 11
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2016
VL 34
BP 153
EP 166
DI 10.1016/j.jvcir.2015.11.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DC1HM
UT WOS:000368967400014
DA 2024-07-18
ER

PT J
AU Tao, JW
   Wen, ST
   Hu, WJ
AF Tao, JianWen
   Wen, Shiting
   Hu, Wenjun
TI Robust domain adaptation image classification via sparse and low rank
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Robust domain adaptation learning; Low rank representation; Maximum mean
   discrepancy; Sparse representation; Transfer learning; Semi-supervised
   learning; Image classification; Robustness
ID LABEL PROPAGATION; REGULARIZATION
AB Domain adaptation image classification addresses the problem of adapting the image distribution of the source domain to the target domain for an effective learning task, where the classification objective is intended but the data distributions are different. However, corrupted data (e.g. noise and outliers, which exist universally in real-world domains) can cause significant deterioration of the practical performance of existing methods in cross-domain image classification. This motivates us to propose a robust domain adaptation image classification method with sparse and low rank representation. Specifically, we first obtain an optimal Domain Adaptation Sparse and Low Rank Representation (DASLRR) for all the data from both domains by incorporating a distribution adaptation regularization term, which is expected to minimize the distribution discrepancy between the source and target domain, into the existing low rank and sparse representation objective function. Formulating an optimization problem that combines the objective function of the sparse and low rank representation, constrained by distribution adaptation and local consistency, we propose an algorithm that alternates between obtaining an effective dictionary, while preserving the DASLRR to make the new representations robust to the distribution difference. Based on the obtained DASLRR, we then provide a flexible semi-supervised learning framework, which can propagate the labels of labeled data from both domains to unlabeled data from In-Sample as well as Out-of-Sample datasets by simultaneously learning a prediction label matrix and a classifier model. The proposed method can capture the global mixture of the clustering structure (by the sparseness and low rankness) and the locally consistent structure (by the local graph regularization) as well as the distribution difference (by the distribution adaptation) of the domains data. Hence, the proposed method is robust for accurately classifying cross-domain images that may be corrupted by noise or outliers. Extensive experiments demonstrate the effectiveness of our method on several types of images and video datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Tao, JianWen; Wen, Shiting] Zhejiang Univ, Ningbo Inst Technol, Sch Informat Sci & Engn, Ningbo 315100, Zhejiang, Peoples R China.
   [Hu, Wenjun] Huzhou Teachers Coll, Sch Informat & Engn, Huzhou 313000, Peoples R China.
C3 Zhejiang University; Huzhou University
RP Wen, ST (corresponding author), Zhejiang Univ, Ningbo Inst Technol, Sch Informat Sci & Engn, Ningbo 315100, Zhejiang, Peoples R China.
EM jianwen_tao@aliyun.com; wensht@nit.net.cn
RI Hu, Wenjun/I-9392-2018
FU Humanities and Social Science Foundation of Ministry of Education of
   China [13YJAZH084]; Natural Science Foundation of Zhejiang Province
   [LY14F020009, LY16F030012, LY13F020011]; Natural Science Foundation of
   Ningbo City [2014A610024, 2014A610066]
FX This work was supported in part by the Humanities and Social Science
   Foundation of Ministry of Education of China under Grant 13YJAZH084, by
   the Natural Science Foundation of Zhejiang Province under Grants
   LY14F020009, LY16F030012 and LY13F020011, and by the Natural Science
   Foundation of Ningbo City under Grants 2014A610024 and 2014A610066.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], COMPUTER VISION ICCV
   [Anonymous], ADV NEURAL INF PROCE
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bruzzone L, 2010, IEEE T PATTERN ANAL, V32, P770, DOI 10.1109/TPAMI.2009.57
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Geng B, 2011, IEEE T IMAGE PROCESS, V20, P2980, DOI 10.1109/TIP.2011.2134107
   Gonzalez-Abril L, 2008, IEEE T NEURAL NETWOR, V19, P723, DOI 10.1109/TNN.2007.914138
   Gretton A., 2010, Advances in Neural Information Processing Systems, V22, P673
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Lin Z., 2009, Technical Report (No. UILU-ENG-09-2215
   Lina J., 2014, 0320141 IVU AR STAT
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809
   Long MS, 2013, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2013.59
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Quanz B, 2011, PROC INT CONF DATA, P769, DOI 10.1109/ICDE.2011.5767917
   Scholkopf B., 2002, Learning with Kernels
   Shao Ming, 2012, P 2012 IEEE 12 INT C
   Tao JW, 2014, NEUROCOMPUTING, V139, P202, DOI 10.1016/j.neucom.2014.02.044
   Tao JW, 2012, SCI CHINA INFORM SCI, V55, P1983, DOI 10.1007/s11432-012-4611-x
   Tao JW, 2012, PATTERN RECOGN, V45, P3962, DOI 10.1016/j.patcog.2012.04.014
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang H., 2013, P 30 INT C MACH LEAR
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu YB, 2012, IEEE ICC
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Zhang C., 2011, IEEE C COMP VIS PATT
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zheng YG, 2013, NEUROCOMPUTING, V122, P398, DOI 10.1016/j.neucom.2013.06.013
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X.J., 2005, Semi-Supervised Learning Literature Survey
NR 48
TC 7
Z9 8
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 134
EP 148
DI 10.1016/j.jvcir.2015.09.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700014
DA 2024-07-18
ER

PT J
AU Bag, S
   Bhowmick, P
AF Bag, Soumen
   Bhowmick, Partha
TI Adaptive-interpolative binarization with stroke preservation for
   restoration of faint characters in degraded documents
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive thresholding; Degraded document image; Faint character;
   Grid-based approach; Multi-scale framework; Stroke preservation;
   Interpolation technique; Post-processing
ID THRESHOLDING TECHNIQUES; SELECTION
AB A novel technique for binarization with stroke preservation of faint characters in degraded documents is proposed. It works in a multi-scale framework with an adaptive-interpolative thresholding technique. Instead of computing a global threshold value, it computes the local threshold values for a small set of grid points by observing the intensity pattern of the pixels lying in the concerned grid cells. Estimated thresholds are used, in turn, to compute the threshold values of all the remaining pixels using a fast-yet-efficient interpolation procedure. To handle noises in degraded images, this grid-based adaptive thresholding is applied in successively reducing scales to obtain the near-optimal binarization as a set of connected components. After a post-processing meant for stroke preservation with these connected components, we get the final output. Exhaustive experimentation and comparison with other existing methods have been successfully carried out with benchmark datasets and also with our own datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Bag, Soumen] Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
   [Bhowmick, Partha] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad; Indian Institute of
   Technology System (IIT System); Indian Institute of Technology (IIT) -
   Kharagpur
RP Bag, S (corresponding author), Indian Sch Mines, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM bagsoumen@gmail.com; bhowmick@gmail.com
CR [Anonymous], 1982, Digital Picture Processing
   [Anonymous], INT C IM INF PROC
   Berkner K, 2001, APPL COMPUT HARMON A, V11, P2, DOI 10.1006/acha.2000.0339
   Bernsen J., 1986, In: Proceedings of the Eighth International Conference on Pattern Recognition, P1251
   Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   BRINK AD, 1992, PATTERN RECOGN, V25, P803, DOI 10.1016/0031-3203(92)90034-G
   Chanda B., 2011, Digital Image Processing Analysis, V2nd
   Cheriet M, 1999, INT J PATTERN RECOGN, V13, P665, DOI 10.1142/S0218001499000392
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gatos B, 2004, LECT NOTES COMPUT SC, V3163, P102
   Gatos B., 2009, International Conference on Document Analysis and Recognition, P1375, DOI 10.1109/icdar.2009.246
   He J, 2005, PROC INT CONF DOC, P538, DOI 10.1109/ICDAR.2005.3
   Huang QM, 2005, PATTERN RECOGN LETT, V26, P801, DOI 10.1016/j.patrec.2004.09.035
   Kavallieratou E, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P340, DOI 10.1109/DIAL.2006.23
   Leedham G, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P244, DOI 10.1109/IWFHR.2002.1030917
   Lu SJ, 2010, INT J DOC ANAL RECOG, V13, P303, DOI 10.1007/s10032-010-0130-8
   Moghaddam RF, 2010, PATTERN RECOGN, V43, P2186, DOI 10.1016/j.patcog.2009.12.024
   Moon-Soo Chang, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P636, DOI 10.1109/ICDAR.1995.601976
   Niblack W., 1986, An Introduction to Image Processing
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PARKER JR, 1991, IEEE T PATTERN ANAL, V13, P813, DOI 10.1109/34.85672
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Solihin Y, 1999, IEEE T PATTERN ANAL, V21, P761, DOI 10.1109/34.784289
   Stathis P, 2008, INT C PATT RECOG, P1953
   Tabatabaei SA, 2010, IEEE IMAGE PROC, P3573, DOI 10.1109/ICIP.2010.5650950
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   Valizadeh M, 2013, INT J DOC ANAL RECOG, V16, P165, DOI 10.1007/s10032-012-0182-z
   WHITE JM, 1983, IBM J RES DEV, V27, P400, DOI 10.1147/rd.274.0400
   YANG JD, 1994, PATTERN RECOGN LETT, V15, P141, DOI 10.1016/0167-8655(94)90043-4
   Yang YB, 2000, PATTERN RECOGN, V33, P787, DOI 10.1016/S0031-3203(99)00094-1
NR 33
TC 2
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 266
EP 281
DI 10.1016/j.jvcir.2015.07.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600024
DA 2024-07-18
ER

PT J
AU Jang, WS
   Ho, YS
AF Jang, Woo-Seok
   Ho, Yo-Sung
TI Discontinuity preserving disparity estimation with occlusion handling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distance transform; Occlusion handling; Stereo vision; Energy
   optimization; Depth image-based rendering; Depth discontinuity;
   Hierarchical structure; 3D content
ID STEREO; SEGMENTATION; GENERATION
AB In this paper, we propose a stereo matching algorithm based on distance transform to generate high-quality disparity maps with occlusion handling. In general, pixel intensities around object edges are smeared due to mixed values located between the object and its background. This leads to problems when identifying discontinuous disparities. In order to handle these problems, we present an edge control function according to distance transform values. Meanwhile, occluded regions occur, i.e., some portions are visible only in one image. An energy function is designed to detect such regions considering warping, cross check, and luminance difference constraints. Consequently, we replace the disparity in the occluded region with the one chosen from its neighboring disparities in the non-occluded region based on color and spatial correlations. In particular, the occlusion hole is filled according to region types. Experimental results show that the proposed method outperforms conventional stereo matching algorithms with occlusion handling. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Jang, Woo-Seok; Ho, Yo-Sung] Gwangju Inst Sci & Technol, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Jang, WS (corresponding author), Gwangju Inst Sci & Technol, 123 Cheomdan Gwagiro, Kwangju 500712, South Korea.
EM jws@gist.ac.kr; hoyo@gist.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2013-067321]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (No. 2013-067321).
CR Ben-Ari R, 2010, IEEE T PATTERN ANAL, V32, P2071, DOI 10.1109/TPAMI.2010.32
   Bleyer M, 2007, SIGNAL PROCESS-IMAGE, V22, P127, DOI 10.1016/j.image.2006.11.012
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Crabb Ryan, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563170
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Felzenszwalb P. F., 2004, IEEE COMP SOC C COMP, P1
   Gao ZW, 2010, IEEE T CONSUM ELECTR, V56, P324, DOI 10.1109/TCE.2010.5505935
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   Ho Y S, 2013, OCCLUSION DETECTION, P363
   Humenberger M., 2010, 2010 IEEE COMP SOC C, P77, DOI [10.1109/CVPRW.2010.5543769, DOI 10.1109/CVPRW.2010.5543769]
   Jang WS, 2012, IEEE INT SYMP CIRC S, P600, DOI 10.1109/ISCAS.2012.6272102
   Jang WS, 2011, IEEE T CONSUM ELECTR, V57, P1937, DOI 10.1109/TCE.2011.6131174
   Kim SY, 2013, IEEE T CONSUM ELECTR, V59, P681, DOI 10.1109/TCE.2013.6626256
   Kim SY, 2010, SIGNALS COMMUN TECHN, P349, DOI 10.1007/978-3-642-12802-8_15
   Kim SY, 2010, IEEE T CONSUM ELECTR, V56, P1730, DOI 10.1109/TCE.2010.5606319
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Liu TL, 2009, LECT NOTES COMPUT SC, V5414, P449
   Michael M, 2013, IEEE INT VEH SYM, P1197, DOI 10.1109/IVS.2013.6629629
   Rajesh R.J., 2012, ADV COMPUTING, P41
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Video and Requirement Group, 2011, JTC1SC29WG11 ISOIEC
   Yang Q., 2006, P 17 BRIT MACHINE VI, P989
   Yang QX, 2010, PROC CVPR IEEE, P1458, DOI 10.1109/CVPR.2010.5539797
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 29
TC 14
Z9 15
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1595
EP 1603
DI 10.1016/j.jvcir.2014.07.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100010
DA 2024-07-18
ER

PT J
AU Yin, J
   Yu, H
   Xu, WZ
   Wang, YX
   Tian, Z
   Zhang, YP
   Chen, BC
AF Yin, Jian
   Yu, Hui
   Xu, Weizhi
   Wang, Yuxuan
   Tian, Zhu
   Zhang, Yingping
   Chen, Bochuan
TI Highly parallel GEMV with register blocking method on GPU architecture
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE GEMV; Register blocking; Data reuse; Memory bandwidth; GPU; Many-core;
   Parallelization; CUDA
ID DEBLOCKING FILTER; HEVC; FRAMEWORK
AB GPUs can provide powerful computing ability especially for data parallel applications, such as video/image processing applications. However, the complexity of GPU system makes the optimization of even a simple algorithm difficult. Different optimization methods on a GPU often lead to different performances. The matrix-vector multiplication routine for general dense matrices (GEMV) is an important kernel in video/image processing applications. We find that the implementations of GEMV in CUBLAS or MAGMA are not efficient, especially for small or fat matrix. In this paper, we propose a novel register blocking method to optimize GEMV on GPU architecture. This new method has three advantages. First, instead of using only one thread, we use a warp to compute an element of vector y so that the method can exploit the highly parallel GPU architecture. Second, the register blocking method is used to reduce the requirement of off-chip memory bandwidth. At last, the memory access order is elaborately arranged for the threads in one warp so that coalesced memory access is ensured. The proposed optimization methods for GEMV are comprehensively evaluated on different matrix sizes. The performance of the register blocking method with different block sizes is also evaluated in the experiment. Experiment results show that the new method can achieve very high speedup for small square matrices and fat matrices compared to CUBLAS or MAGMA, and can also achieve higher performance for large square matrices. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yin, Jian; Wang, Yuxuan; Tian, Zhu] Shandong Univ, Dept Comp, Weihai, Peoples R China.
   [Yu, Hui] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Xu, Weizhi] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Xu, Weizhi] Tsinghua Univ, Inst Microelect, Beijing 100084, Peoples R China.
C3 Shandong University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Tsinghua University
RP Xu, WZ (corresponding author), Tsinghua Univ, Inst Microelect, Beijing 100084, Peoples R China.
EM weizhixu@gmail.com
RI liu, mengjie/KDN-1890-2024
FU China Major ST Project [2013ZX01033001-001-003]; International S & T
   Cooperation Project of China [2012DFA11170]; Tsinghua Indigenous
   Research Project [20111080997]; NNSF of China [61274131]; NVIDIA
   Corporation
FX This work is supported in part by the China Major S&T Project (No.
   2013ZX01033001-001-003), the International S & T Cooperation Project of
   China Grant (No. 2012DFA11170), the Tsinghua Indigenous Research Project
   (No. 20111080997) and the NNSF of China Grant (No. 61274131). We
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the GPU used for this research.
CR Anderson MJ, 2012, INT PARALL DISTRIB P, P2, DOI 10.1109/IPDPS.2012.11
   [Anonymous], NVIDIA CUDA COMPUTE
   Bauer M., 2011, HIGH PERFORMANCE COM, P1
   Choi JW, 2010, ACM SIGPLAN NOTICES, V45, P115, DOI 10.1145/1837853.1693471
   Dongarra J., 2011, P 2011 INT C HIGH PE, P1
   FUJIMOTO N., 2008, P WORKSHOP LARGE SCA, P1, DOI DOI 10.1109/IPDPS.2008.4536350
   Liu YX, 2009, INT PARALL DISTRIB P, P74
   Weizhi Xu, 2012, Proceedings of the 2012 13th ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel & Distributed Computing (SNPD 2012), P231, DOI 10.1109/SNPD.2012.20
   Xu Weizhi, 2012, 18 IEEE INT IN PRESS
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P530, DOI 10.1109/DCC.2013.109
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yan CG, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6011904
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
NR 16
TC 3
Z9 5
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1566
EP 1573
DI 10.1016/j.jvcir.2014.06.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100007
DA 2024-07-18
ER

PT J
AU Zhang, CJ
   Xiao, X
   Pang, JB
   Liang, C
   Zhang, YF
   Huang, QM
AF Zhang, Chunjie
   Xiao, Xian
   Pang, Junbiao
   Liang, Chao
   Zhang, Yifan
   Huang, Qingming
TI Beyond visual word ambiguity: Weighted local feature encoding with
   governing region
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual word ambiguity; Governing region; Weighted encoding; Image
   classification; Sparse; Bag-of-visual words; Object categorization;
   Locality constraint
ID FACE RECOGNITION; SPARSE; SCENE; MODEL
AB Typically, k-means clustering or sparse coding is used for codebook generation in the bag-of-visual words (BOW) model. Local features are then encoded by calculating their similarities with visual words. However, some useful information is lost during this process. To make use of this information, in this paper, we propose a novel image representation method by going one step beyond visual word ambiguity and consider the governing regions of visual words. For each visual application, the weights of local features are determined by the corresponding visual application classifiers. Each weighted local feature is then encoded not only by considering its similarities with visual words, but also by visual words' governing regions. Besides, locality constraint is also imposed for efficient encoding. A weighted feature sign search algorithm is proposed to solve the problem. We conduct image classification experiments on several public datasets to demonstrate the effectiveness of the proposed method. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Zhang, Chunjie; Huang, Qingming] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 100049, Peoples R China.
   [Xiao, Xian] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Pang, Junbiao] Beijing Univ Technol, Coll Comp Sci & Technol, Beijing 100124, Peoples R China.
   [Liang, Chao] Wuhan Univ, Sch Comp, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Zhang, Yifan] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing, Peoples R China.
   [Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Key Lab Intell Info Proc, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS; Beijing
   University of Technology; Wuhan University; Chinese Academy of Sciences;
   Institute of Automation, CAS; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS
RP Xiao, X (corresponding author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
EM cjzhang@jdl.ac.cn; xaioxain@gmail.com; junbiao_pang@bjut.edu.cn;
   cliang@whu.edu.cn; yfzhang@nlpr.ia.ac.cn; qmhuang@jdl.ac.cn
RI zhang, chunjie/Z-3035-2019; zhang, yifan/ABB-5853-2021
OI zhang, chunjie/0000-0002-1161-8995; 
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61303154, 61202234,
   61305018, 61303114, 61202325, 61332016]; Open Project Program of the
   National Laboratory of Pattern Recognition (NLPR); President Fund of
   University of Chinese Academy of Sciences (UCAS); Beijing Municipal
   Natural Science Foundation of China [4132010]; Specialized Research Fund
   for the Doctoral Program of Higher Education [20130141120024]
FX This work is supported by National Basic Research Program of China (973
   Program): 2012CB316400, National Natural Science Foundation of China:
   61303154, 61202234, 61305018, 61303114, 61202325 and 61332016, the Open
   Project Program of the National Laboratory of Pattern Recognition
   (NLPR), the President Fund of University of Chinese Academy of Sciences
   (UCAS). Beijing Municipal Natural Science Foundation of China No.
   4132010. Specialized Research Fund for the Doctoral Program of Higher
   Education (No. 20130141120024).
CR [Anonymous], 2006, P 20 ANN C NEUR INF
   [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], IEEE INT C ICCV
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], ECCV WORKSH REPR US
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], UCBCSD041366 CALT
   [Anonymous], 2010, ADV NEURAL PROCESSIN
   Boiman O., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587598
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen Q, 2012, PROC CVPR IEEE, P3426, DOI 10.1109/CVPR.2012.6248083
   Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fernando B, 2012, PROC CVPR IEEE, P3434, DOI 10.1109/CVPR.2012.6248084
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li L.J., 2007, PROC IEEE INT C COMP
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McCann S, 2012, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2012.6248111
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Perronnin F., 2007, PROC IEEE INT C COMP, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rasiwasia N., 2008, PROC IEEE INT C COMP, P1
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Su Y, 2012, INT J COMPUT VISION, V100, P59, DOI 10.1007/s11263-012-0529-4
   Timofte R, 2012, PROC CVPR IEEE, P2456, DOI 10.1109/CVPR.2012.6247960
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu JX, 2009, IEEE I CONF COMP VIS, P630, DOI 10.1109/ICCV.2009.5459178
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhang CJ, 2012, IEEE MULTIMEDIA, V19, P58, DOI 10.1109/MMUL.2011.20
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364
NR 43
TC 3
Z9 4
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1387
EP 1398
DI 10.1016/j.jvcir.2014.05.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100009
DA 2024-07-18
ER

PT J
AU Nan, XM
   He, YF
   Guan, L
AF Nan, Xiaoming
   He, Yifeng
   Guan, Ling
TI Queueing model based resource optimization for multimedia cloud
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia cloud; Resource optimization; Queueing model; Response time;
   Resource cost; Quality of service (QoS); Convex optimization; Priority
   service
ID ALLOCATION; SERVICE
AB Multimedia cloud is a specific cloud computing paradigm, focusing on how cloud can effectively support multimedia services. For multimedia service providers (MSP), there are two fundamental concerns: the quality of service (QoS) and the resource cost. In this paper, we investigate these two fundamental concerns with queueing theory and optimization methods. We introduce a queueing model to characterize the service process in multimedia cloud. Based on the proposed queueing model, we study resource allocation problems in three different scenarios: single-service scenario, multi-service scenario, and priority-service scenario. In each scenario, we formulate and solve the response time minimization problem and the resource cost minimization problem, respectively. We conduct extensive simulations with practical parameters of Windows Azure. Simulation results demonstrate that the proposed resource allocation schemes can optimally allocate cloud resources for each service to achieve the minimal response time under a certain budget or guarantee the QoS provisioning at the minimal resource cost. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Nan, Xiaoming; He, Yifeng; Guan, Ling] Ryerson Univ, Toronto, ON M5B 2K3, Canada.
C3 Toronto Metropolitan University
RP Nan, XM (corresponding author), Ryerson Univ, Toronto, ON M5B 2K3, Canada.
EM xnan@ee.ryerson.ca; yhe@ee.ryerson.ca; lguan@ee.ryerson.ca
FU Canada Research Chair Program; NSERC; NSFC [61210005]
FX This work was supported in part by the Canada Research Chair Program,
   NSERC Discovery Grant, and NSFC Grant 61210005.
CR [Anonymous], 2006, ACM SIGOPS OPER SYST
   Appleby K., 2001, 2001 IEEE/IFIP International Symposium on Integrated Network Management Proceedings. Integrated Network Management VII. Integrated Management Strategies for the New Millennium (Cat. No.01EX470), P855, DOI 10.1109/INM.2001.918085
   Ardagna D., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P163, DOI 10.1109/CLOUD.2011.32
   Arlitt MF, 1997, IEEE ACM T NETWORK, V5, P631, DOI 10.1109/90.649565
   Boyd S., 2004, CONVEX OPTIMIZATION
   Buyya R, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P5, DOI 10.1109/HPCC.2008.172
   Chaisiri B.-S., 2009, 2009 IEEE AS PAC SER, P103, DOI DOI 10.1109/APSCC.2009.5394134
   Cherkasova L, 2003, CCGRID 2003: 3RD IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, PROCEEDINGS, P52, DOI 10.1109/CCGRID.2003.1199352
   Gross D., 2009, Fundamentals of Queueing Theory, V4th
   Hui Wen, 2011, 2011 International Conference on Electronic & Mechanical Engineering and Information Technology (EMEIT 2011), P165, DOI 10.1109/EMEIT.2011.6022888
   Lin W.P., 2010, IPFA, P1, DOI [DOI 10.1109/ITAPP.2010.5566394, 10.1109/POWERCON.2010.5666123, DOI 10.1109/ICVES.2010.5550951]
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Miao Dan., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1237
   Mordecai Avriel, 2012, NONLINEAR PROGRAMMIN
   Murphy MA, 2009, CCGRID: 2009 9TH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P364, DOI 10.1109/CCGRID.2009.37
   Nan X., 2013, SPIE OPTICAL ENG APP
   Nan XM, 2013, IEEE INT SYMP CIRC S, P2872, DOI 10.1109/ISCAS.2013.6572478
   Nan XM, 2011, IEEE INT WORKSH MULT
   Nan XM, 2012, IEEE INT SYMP CIRC S, P1111
   Narendra Kumar J., 1968, PRIORITY QUEUES, V50
   Padala P., 2007, Operating Systems Review, V41, P289, DOI 10.1145/1272998.1273026
   Ross S. M., 1996, STOCHASTIC PROCESSES, V2
   SCHRAGE LE, 1966, OPER RES, V14, P670, DOI 10.1287/opre.14.4.670
   Shea R, 2013, IEEE NETWORK, V27, P16, DOI 10.1109/MNET.2013.6574660
   Shi WM, 2012, INT J COMPUT SCI ENG, V7, P319, DOI 10.1504/IJCSE.2012.049752
   Song Y, 2009, CCGRID: 2009 9TH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P148, DOI 10.1109/CCGRID.2009.11
   Verma A, 2008, LECT NOTES COMPUT SC, V5346, P243, DOI 10.1007/978-3-540-89856-6_13
   Wang F, 2012, IEEE INFOCOM SER, P199, DOI 10.1109/INFCOM.2012.6195578
   Wang SX, 2013, IEEE T MULTIMEDIA, V15, P870, DOI 10.1109/TMM.2013.2240674
   Wang S, 2007, PR IEEE COMP DESIGN, P25
   Wolke A, 2010, LECT NOTES COMPUT SC, V6481, P13, DOI 10.1007/978-3-642-17694-4_2
   Wu Y, 2013, IEEE T MULTIMEDIA, V15, P821, DOI 10.1109/TMM.2013.2240670
   Wu Y, 2011, INT CON DISTR COMP S, P268, DOI 10.1109/ICDCS.2011.50
   Xu J., 2007, 4 INT C AUTONOMIC CO, P25, DOI DOI 10.1109/ICAC.2007.28
   Yang B, 2009, LECT NOTES COMPUT SC, V5931, P571, DOI 10.1007/978-3-642-10665-1_54
   Zhang N, 2012, IEEE INT WORKSH MULT, P238, DOI 10.1109/MMSP.2012.6343447
   Zhang Q, 2010, J INTERNET SERV APPL, V1, P7, DOI 10.1007/s13174-010-0007-6
   Zheng J, 2005, LECT NOTES COMPUT SC, V3779, P285
   Zhou Minqi., 2010, Universal Communication Symposium (IUCS), 2010 4th International, P40
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 40
TC 30
Z9 32
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 928
EP 942
DI 10.1016/j.jvcir.2014.02.008
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200021
DA 2024-07-18
ER

PT J
AU Razzaghi, P
   Samavi, S
AF Razzaghi, Parvin
   Samavi, Shadrokh
TI Hierarchical Implicit Shape Modeling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object recognition; Statistical part-based object recognition; Implicit
   shape model; Hierarchical Implicit Shape Model; Hierarchical star graph;
   Discriminative parts; Parts filter; Histogram of gradients
ID OBJECT; RECOGNITION; FEATURES
AB In this paper, a new hierarchical approach for object detection is proposed. Object detection methods based on Implicit Shape Model (ISM) efficiently handle deformable objects, occlusions and clutters. The structure of each object in ISM is defined by a spring like graph. We introduce hierarchical ISM in which structure of each object is defined by a hierarchical star graph. Hierarchical ISM has two layers. In the first layer, a set of local ISMs are used to model object parts. In the second layer, structure of parts with respect to the object center is modeled by global ISM. In the proposed approach, the obtained parts for each object category have high discriminative ability. Therefore, our approach does not require a verification stage. We applied the proposed approach to some datasets and compared the performance of our algorithm to comparable methods. The results show that our method has a superior performance. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Razzaghi, Parvin; Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
C3 Isfahan University of Technology; McMaster University
RP Razzaghi, P (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
EM p.razzaghi@ec.iut.ac.ir
RI Razzaghi, Parvin/F-3913-2019; Razzaghi, Parvin/AAE-2348-2022
OI Razzaghi, Parvin/0000-0002-7031-4609
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Crandall D., 2005, COMPUTER VISION PATT
   Crandall D.J., 2008, THESIS CORNELL U
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2005, LECT NOTES COMPUT SC, V3663, P326
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fei-Fei Li., 2007, Recognizing and learning object categories
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fergus R, 2007, INT J COMPUT VISION, V71, P273, DOI 10.1007/s11263-006-8707-x
   Fergus R, 2003, PROC CVPR IEEE, P264
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Grant M.C., 2012, CVX USERS GUIDE
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211
   Leibe B., 2006, P BRIT MACH VIS C 20, DOI [10.5244/C.20.81, DOI 10.5244/C.20.81]
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk Krystian., 2006, IEEE C COMPUTER VISI, P26
   Mottaghi R., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P561, DOI 10.1109/ICCVW.2011.6130293
   Mottaghi R, 2012, PROC CVPR IEEE, P3116, DOI 10.1109/CVPR.2012.6248044
   Niu Z., 2011, COMPUTER VISION PATT
   Opelt A, 2008, INT J COMPUT VISION, V80, P16, DOI 10.1007/s11263-008-0139-3
   Shotton J., 2005, INT C COMP VIS
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Villamizar M, 2010, PROC CVPR IEEE, P1038, DOI 10.1109/CVPR.2010.5540104
   Williams C.K.I., PASCAL VISUAL OBJECT
   Yarlagadda P, 2010, LECT NOTES COMPUT SC, V6315, P197, DOI 10.1007/978-3-642-15555-0_15
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhu L, 2010, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2010.5540096
NR 30
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1251
EP 1261
DI 10.1016/j.jvcir.2013.12.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200049
DA 2024-07-18
ER

PT J
AU Martins, P
   Carvalho, P
   Gatta, C
AF Martins, P.
   Carvalho, P.
   Gatta, C.
TI Context-aware features and robust image representations
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local features; Keypoint extraction; Image content descriptors; Image
   representation; Visual saliency; Information theory; Kernel estimators;
   Complementarity
ID SCALE
AB Local image features are often used to efficiently represent image content. The limited number of types of features that a local feature extractor responds to might be insufficient to provide a robust image representation. To overcome this limitation, we propose a context-aware feature extraction formulated under an information theoretic framework. The algorithm does not respond to a specific type of features; the idea is to retrieve complementary features which are relevant within the image context. We empirically validate the method by investigating the repeatability, the completeness, and the complementarity of context-aware features on standard benchmarks. In a comparison with strictly local features, we show that our context-aware features produce more robust image representations. Furthermore, we study the complementarity between strictly local features and context-aware ones to produce an even more robust representation. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Martins, P.; Carvalho, P.] Univ Coimbra, Ctr Informat & Syst, Coimbra, Portugal.
   [Gatta, C.] Autonomous Univ Barcelona, Comp Vis Ctr, Barcelona, Spain.
C3 Universidade de Coimbra; Centre de Visio per Computador (CVC);
   Autonomous University of Barcelona
RP Martins, P (corresponding author), Univ Coimbra, Ctr Informat & Syst, Coimbra, Portugal.
EM pjmm@dei.uc.pt; carvalho@dei.uc.pt; cgatta@cvc.uab.es
RI Martins, Pedro/L-2642-2015
OI Martins, Pedro/0000-0002-3630-7034; de Carvalho,
   Paulo/0000-0002-9847-0590
CR Alcantarilla P.F., 2012, P 12 EUR C COMP VIS
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Deng H., 2007, IEEE C COMP VIS PATT
   Dickscheid T, 2011, INT J COMPUT VISION, V94, P154, DOI 10.1007/s11263-010-0340-z
   Donoser M., 2006, COMPUTER VISION PATT, V1, P553, DOI DOI 10.1109/CVPR.2006.107
   Donoser M, 2006, INT C PATT RECOG, P63
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Förstner W, 2009, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2009.5459458
   Forssen P.-E., 2007, P 2007 IEEE C COMP V, P1143
   Forssén PE, 2007, IEEE I CONF COMP VIS, P1530
   Forstner W., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P383, DOI 10.1007/BFb0028370
   Gilles S., 1998, PhD thesis
   Goferman S, 2012, IEEE T PATTERN ANAL
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kenney CS, 2003, IEEE T PATTERN ANAL, V25, P1437, DOI 10.1109/TPAMI.2003.1240118
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Koffman E. B., 2007, OBJECTS ABSTRACTION
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martins P., 2012, P 2012 BRIT MACH VIS
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Mikolajczyk K., 2006, IEEE COMP VIS PATT R
   Mirmehdi M., 2001, P BRIT MACH VIS C 20
   Murphy-Chutorian E., 2006, P BRIT MACH VIS C
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   Noble A, 1989, THESIS U OXFORD
   Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Rohr K, 1997, IMAGE VISION COMPUT, V15, P219, DOI 10.1016/S0262-8856(96)01127-4
   Schnitzspan P, 2010, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2010.5540220
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
NR 45
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 339
EP 348
DI 10.1016/j.jvcir.2013.10.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Camplani, M
   Salgado, L
AF Camplani, Massimo
   Salgado, Luis
TI Background foreground segmentation with RGB-D Kinect data: An efficient
   combination of classifiers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE RGB-D cameras; Microsoft Kinect; Background/foreground segmentation;
   Combination of classifiers; RGB-D dataset; Mixture of Gaussian; Color
   and depth data combination; Object detection
ID DENSITY-ESTIMATION; SUBTRACTION; DEPTH; SURVEILLANCE
AB Low cost RGB-D cameras such as the Microsoft's Kinect or the Asus's Xtion Pro are completely changing the computer vision world, as they are being successfully used in several applications and research areas. Depth data are particularly attractive and suitable for applications based on moving objects detection through foreground/background segmentation approaches; the RGB-D applications proposed in literature employ, in general, state of the art foreground/background segmentation techniques based on the depth information without taking into account the color information. The novel approach that we propose is based on a combination of classifiers that allows improving background subtraction accuracy with respect to state of the art algorithms by jointly considering color and depth data. In particular, the combination of classifiers is based on a weighted average that allows to adaptively modifying the support of each classifier in the ensemble by considering foreground detections in the previous frames and the depth and color edges. In this way, it is possible to reduce false detections due to critical issues that can not be tackled by the individual classifiers such as: shadows and illumination changes, color and depth camouflage, moved background objects and noisy depth measurements. Moreover, we propose, for the best of the author's knowledge, the first publicly available RGB-D benchmark dataset with hand-labeled ground truth of several challenging scenarios to test background/foreground segmentation algorithms. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Camplani, Massimo; Salgado, Luis] Univ Politecn Madrid, Grp Tratamiento Imagenes, ETSI Telecomunicac, E-28040 Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Camplani, M (corresponding author), Univ Politecn Madrid, Grp Tratamiento Imagenes, ETSI Telecomunicac, E-28040 Madrid, Spain.
EM mac@gti.ssr.upm.es
RI Camplani, Massimo/J-2549-2012; Salgado, Luis/AAA-9871-2019
OI Camplani, Massimo/0000-0002-6101-5324; Salgado, Luis/0000-0002-5364-9837
FU Ministerio de Economia y Competitividad of the Spanish Government
   [TEC2010-20412]; European Union; Universidad Politecnica de Madrid (UPM)
FX This work has been partially supported by the Ministerio de Economia y
   Competitividad of the Spanish Government under the project TEC2010-20412
   (Enhanced 3DTV). M. Camplani would like to acknowledge the European
   Union and the Universidad Politecnica de Madrid (UPM) for supporting his
   activities through the Marie Curie-Cofund research grant.
CR [Anonymous], 2009, 2009 3DTV C TRUE VIS
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans Thierry, 2011, Recent Patents on Computer Science, V4, P147, DOI 10.2174/1874479611104030147
   Bouwmans T., 2008, Recent Patents Comput. Sci., V1, P219
   Camplani M., 2012, 3 DIMENSIONAL IMAGE, V8290
   Camplani M, 2012, IEEE IMAGE PROC, P1741, DOI 10.1109/ICIP.2012.6467216
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   Di Stefano L, 2004, IMAGE VISION COMPUT, V22, P983, DOI 10.1016/j.imavis.2004.03.009
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Gordon G., 1999, C COMP VIS PATT REC, V2
   Goyette N., 2012, WORKSH CHANG DET CVP
   Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382
   Jodoin PM, 2007, IEEE T CIRC SYST VID, V17, P1758, DOI 10.1109/TCSVT.2007.906935
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Klare Brendan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P66, DOI 10.1109/CVPR.2009.5204078
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Landabaso J.-L., 2008, THESIS TU CATALUNYA
   Leens J, 2009, LECT NOTES COMPUT SC, V5815, P104, DOI 10.1007/978-3-642-04667-4_11
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   RICHARDS FJ, 1959, J EXP BOT, V10, P290, DOI 10.1093/jxb/10.2.290
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stone E, 2011, J AMB INTEL SMART EN, V3, P349, DOI 10.3233/AIS-2011-0124
   Stormer A., 2010, 2010 13th international conference on information fusion, P1
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 32
TC 53
Z9 73
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 122
EP 136
DI 10.1016/j.jvcir.2013.03.009
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Guo, JM
   Prasetyo, H
   Su, HS
AF Guo, Jing-Ming
   Prasetyo, Heri
   Su, Huai-Sheng
TI Image indexing using the color and bit pattern feature fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content-based image retrieval; Image indexing; Ordered Dither Block
   Truncation Coding; Particle Swarm Optimization (PSO)
ID PARTICLE SWARM; RETRIEVAL; WAVELET; BTC
AB This paper presents a new way to index a color image by exploiting the low complexity of the Ordered-Dither Block Truncation Coding (ODBTC) for generating the image features. Image content descriptor is directly constructed from two ODBTC quantizers and the corresponding bitmap image without performing the decoding process. The color co-occurrence feature (CCF) derived from the ODBTC quantizers captures the color distribution and image contrast in block based manner, while the Bit Pattern Feature (BPF) characterizes image edges and visual patterns. The similarity between two images can be easily determined based on their CCF and BPF under a specific distance metric measurement. A metaheuristic algorithm, namely Particle Swarm Optimization (PSO), is employed to find the optimum similarity constants and improve the retrieval accuracy. Experimental results demonstrate that the proposed indexing method is superior to the former Block Truncation Coding (BTC) image retrieval system and the other existing methods. The ODBTC method offers an effective way to index an image in a content-based image retrieval system, and simultaneously it is able to compress an image efficiently. Thus, this system can be a very competitive candidate in image retrieval applications. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Guo, Jing-Ming; Prasetyo, Heri; Su, Huai-Sheng] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jmguo@seed.net.tw; heri_inf_its_02@yahoo.co.id;
   D10207303@mail.ntust.edu.tw
RI Prasetyo, Heri/AAD-2388-2022
OI Prasetyo, Heri/0000-0002-1257-4832
CR [Anonymous], 2009, INT J COMPUTER SCI I
   [Anonymous], 2006, J INF TECHNOL APPL, DOI DOI 10.1109/TMM.20082001357
   [Anonymous], P IEEE INT C AC SPEE
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Brodatz P., 1996, TEXTURES PHOTOGRAPHI
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   Fränti P, 1999, SIGNAL PROCESS-IMAGE, V14, P677, DOI 10.1016/S0923-5965(98)00037-X
   Gahroudi M. R., 2007, INT S SIGN PROC ITS
   Guo JM, 2010, DIGIT SIGNAL PROCESS, V20, P97, DOI 10.1016/j.dsp.2009.04.007
   Guo JM, 2009, SIGNAL PROCESS, V89, P1864, DOI 10.1016/j.sigpro.2009.03.013
   Guo JM, 2009, IEEE T IMAGE PROCESS, V18, P211, DOI 10.1109/TIP.2008.2007385
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Huang CS, 1997, IEEE SIGNAL PROC LET, V4, P328, DOI 10.1109/97.650036
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Kennedy J., 1995, P IEEE INT C NEUR NE, VIV, P1941
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Krohling RA, 2006, IEEE T SYST MAN CY B, V36, P1407, DOI 10.1109/TSMCB.2006.873185
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Lu TC, 2007, INFORM PROCESS MANAG, V43, P461, DOI 10.1016/j.ipm.2006.07.014
   Lu ZM, 2005, ELECTRON LETT, V41, P956, DOI 10.1049/el:20052176
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Moghaddam HA, 2006, INT C PATT RECOG, P925
   Ning JF, 2009, INT J PATTERN RECOGN, V23, P1245, DOI 10.1142/S0218001409007624
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Poursistani P, 2013, MATH COMPUT MODEL, V57, P1005, DOI 10.1016/j.mcm.2011.11.064
   Qiu GP, 2003, IEEE T IMAGE PROCESS, V12, P93, DOI 10.1109/TIP.2002.807356
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Subrahmanyam M, 2012, SIGNAL PROCESS, V92, P1467, DOI 10.1016/j.sigpro.2011.12.005
   Subrahmanyam M, 2012, EXPERT SYST APPL, V39, P5104, DOI 10.1016/j.eswa.2011.11.029
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   UDPIKAR VR, 1987, IEEE T COMMUN, V35, P352, DOI 10.1109/TCOM.1987.1096773
   Wang XY, 2012, COMPUT STAND INTER, V34, P31, DOI 10.1016/j.csi.2011.05.001
   Wang XY, 2009, J VIS COMMUN IMAGE R, V20, P505, DOI 10.1016/j.jvcir.2009.07.002
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wu YG, 1998, IEEE T CONSUM ELECTR, V44, P317
   WU YY, 1991, IEEE T COMMUN, V39, P1283, DOI 10.1109/26.99132
   Yildizer E, 2012, EXPERT SYST APPL, V39, P2385, DOI 10.1016/j.eswa.2011.08.086
   Yu FX, 2011, ELECTRON LETT, V47, P100, DOI 10.1049/el.2010.3232
NR 49
TC 36
Z9 39
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1360
EP 1379
DI 10.1016/j.jvcir.2013.09.005
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700013
DA 2024-07-18
ER

PT J
AU Son, CH
   Choo, H
   Park, HM
AF Son, Chang-Hwan
   Choo, Hyunseung
   Park, Hyung-Min
TI Image-pair-based deblurring with spatially varying norms and noisy image
   updating
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image stabilization; Multi-exposure imaging; Spatially varying norm;
   Alternating minimization; Noise-level estimation; Point spread function;
   Image fusion; Maximum-a-posterior
ID NONLOCAL ALGORITHM; SPACE; SPARSE
AB This paper presents a deblurring method that effectively restores fine textures and details, such as a tree's leaves or regular patterns, and suppresses noises in flat regions using consecutively captured blurry and noisy images. To accomplish this, we used a method that combines noisy image updating with one iteration and fast deconvolution with spatially varying norms in a modified alternating minimization scheme. The captured noisy image is first denoised with a nonlocal means (NL-means) denoising method, and then fused with a deconvolved version of the captured blurred image on the frequency domain, to provide an initially restored image with less noise. Through a feedback loop, the captured noisy image is directly substituted with the initially restored image for one more NL-means denoising, which results in an upgraded noisy image with clearer outlines and less noise. Next, an alpha map that stores spatially varying norm values, which indicate local gradient priors in a maximum-a-posterior (MAP) estimation, is created based on texture likelihoods found by applying a texture detector to the initially restored image. The alpha map is used in a modified alternating minimization scheme with the pair of upgraded noisy images and a corresponding point spread function (PSF) to improve texture representation and suppress noises and ringing artifacts. Our results show that the proposed method effectively restores details and textures and alleviates noises in flat regions. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Son, Chang-Hwan; Choo, Hyunseung] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 440746, South Korea.
   [Park, Hyung-Min] Sogang Univ, Dept Elect Engn, Seoul 121742, South Korea.
C3 Sungkyunkwan University (SKKU); Sogang University
RP Son, CH (corresponding author), Sungkyunkwan Univ, Coll Informat & Commun Engn, 300 Chunchundong, Suwon 440746, South Korea.
EM jjdhompy@hotmail.com
OI Park, Hyung-Min/0000-0002-7105-5493
FU MSIP(NIPA,KEIT); MOE(NRF), Korean government under ITRC
   [NIPA-2013-(H0301-13-3001)]; MOE(NRF), Korean government under IT RD
   Program [10041244]; MOE(NRF), Korean government under PRCP
   [NRF-2010-0020210]; Samsung Electronics Co., Ltd.
FX This research was supported in part by MSIP(NIPA,KEIT) and MOE(NRF),
   Korean government, under ITRC (NIPA-2013-(H0301-13-3001)), IT R&D
   Program[10041244, SmartTV 2.0 Software Platform], and
   PRCP(NRF-2010-0020210), respectively. This work was supported in part by
   the Samsung Electronics Co., Ltd. I really appreciate the help of Prof.
   Rae-Hong Park, Sogang University, who provided the code of the
   conventional image fusion method.
CR [Anonymous], 2008, ACM T GRAPH
   [Anonymous], 2009, NIPS
   [Anonymous], J REAL TIME IMAGE PR
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bergman R., 2007, Detection of textured areas in images using a disorganization indicator based on component counts
   BIEMOND J, 1990, P IEEE, V78, P856, DOI 10.1109/5.53403
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chaux C, 2007, INVERSE PROBL, V23, P1495, DOI 10.1088/0266-5611/23/4/008
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Cho TS, 2010, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2010.5540214
   Choi BD, 2008, IEEE T CONSUM ELECTR, V54, P981, DOI 10.1109/TCE.2008.4637576
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   De Stefano A, 2004, EURASIP J APPL SIG P, V2004, P2400, DOI 10.1155/S1110865704401218
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Foi A, 2007, IEEE T IMAGE PROCESS, V16, P1395, DOI 10.1109/TIP.2007.891788
   Gonzales R.C., 2002, Digital image processing
   Katsaggelos A. K., 1990, Journal of Visual Communication and Image Representation, V1, P93, DOI 10.1016/1047-3203(90)90019-R
   Lee JH, 2011, J VIS COMMUN IMAGE R, V22, P653, DOI 10.1016/j.jvcir.2011.07.010
   Lim S.H., 2008, ESTIMATION REMOVAL M
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Raskar R, 2006, ACM T GRAPHIC, V25, P795, DOI 10.1145/1141911.1141957
   Rav-Acha A, 2005, PATTERN RECOGN LETT, V26, P311, DOI 10.1016/j.patrec.2004.10.017
   Son CH, 2011, IEEE T CONSUM ELECTR, V57, P1791, DOI 10.1109/TCE.2011.6131155
   Sorel M, 2008, IEEE T IMAGE PROCESS, V17, P105, DOI 10.1109/TIP.2007.912928
   Sorel M, 2009, NATO SCI PEACE SEC B, P259, DOI 10.1007/978-1-4020-9253-4_13
   Tico M, 2007, IEEE IMAGE PROC, P117
   Tico M, 2010, IEEE IMAGE PROC, P3321, DOI 10.1109/ICIP.2010.5651532
   Tico M, 2009, IEEE IMAGE PROC, P1521, DOI 10.1109/ICIP.2009.5413626
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Yuan L, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239452
   Zhuo SJ, 2010, PROC CVPR IEEE, P2440, DOI 10.1109/CVPR.2010.5539941
NR 35
TC 9
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1303
EP 1315
DI 10.1016/j.jvcir.2013.09.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700008
DA 2024-07-18
ER

PT J
AU Feng, SH
   Lang, CY
   Liu, HZ
   Huang, XK
AF Feng, Songhe
   Lang, Congyan
   Liu, Hongzhe
   Huang, Xiankai
TI Adaptive all-season image tag ranking by saliency-driven image
   pre-classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive tag ranking; Visual attention model; Sparse representation;
   Multi-instance learning; Tag saliency ranking; Tag relevance ranking;
   Image pre-classification; Gray histogram descriptor
AB Social image tag ranking has emerged as an important research topic due to its application on web image search. This paper presents an adaptive all-season tag ranking algorithm which can handle the images with and without distinct object(s) using different tag ranking strategies. Firstly, based on saliency map derived from the visual attention model, a linear SVM is trained to pre-classify an image as attentive or non-attentive category by using the gray histogram descriptor on the corresponding saliency map. Then, an image with distinct object is processed by the tag saliency ranking algorithm emphasizing distinct object, which combines image saliency map with sparse representation based multi-instance learning algorithm. On the other hand, an image without distinct object can be processed by the tag relevance ranking algorithm via the sparse representation based neighbor-voting strategy. Such adaptive all-season tag ranking strategy can be regarded as taking full advantage of existing tag ranking paradigms. Experiments conducted on well-known image data sets demonstrate the effectiveness of the proposed framework. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Feng, Songhe; Lang, Congyan] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Liu, Hongzhe] Beijing Union Univ, Beijing Key Lab Informat Serv Engn, Beijing, Peoples R China.
   [Huang, Xiankai] Beijing Union Univ, Tourism Inst, Beijing, Peoples R China.
   [Feng, Songhe] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Beijing Union University; Beijing Union
   University; Beijing Jiaotong University
RP Feng, SH (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM shfeng@bjtu.edu.cn; cylang@bjtu.edu.cn; liuhongzhe@buu.edu.cn;
   xkhuang@buu.edu.cn
OI Liu, Hongzhe/0000-0003-2314-5272
FU National Nature Science Foundation of China [61100142, 61272352,
   61271369]; Fundamental Research Funds for the Central Universities
   [2011JBM218, 2012JBM040]; Doctoral Fund of Ministry of Education of
   China [20110009120005]; Science Foundation of Beijing Jiaotong
   University [2012RC008]
FX This work is supported by National Nature Science Foundation of China
   (61100142, 61272352, 61271369), the Fundamental Research Funds for the
   Central Universities (2011JBM218, 2012JBM040), the Doctoral Fund of
   Ministry of Education of China (20110009120005) and the Science
   Foundation of Beijing Jiaotong University (2012RC008).
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   [Anonymous], 2009, ACM CIVR
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Feng S., 2012, ACM MULTIMEDIA, P917
   Feng S, 2010, P ACM INT C IM VID R, P288
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   Fu H., 2010, ACIVS
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Li X, 2009, IEEE T MULTIMEDIA, V20, P1254
   Liu D, 2011, MULTIMED TOOLS APPL, V51, P723, DOI 10.1007/s11042-010-0647-3
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu J., 2013, NEUROCOMPUTING, V25, P172
   Maron O., 1998, ICML, P570
   Tang J., 2009, INFERRING SEMANTIC C
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Wang Zheng., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '10, P42
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yuan XT, 2010, PROC CVPR IEEE, P3493, DOI 10.1109/CVPR.2010.5539967
   Zhang Q, 2002, ADV NEUR IN, V14, P1073
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhuang J., 2011, ACM WSDM
NR 25
TC 5
Z9 7
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1031
EP 1039
DI 10.1016/j.jvcir.2013.06.018
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700027
DA 2024-07-18
ER

PT J
AU Wang, C
   Song, XB
AF Wang, Chao
   Song, Xubo
TI Robust frontal view search using extended manifold learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Frontal view search; Manifold learning; Pairwise K-nearest neighbor
   protocol; Localized edge orientation histogram; Locally linear
   embedding; Laplacian eigenmaps; Pose estimation; Frontal face; Frontal
   view; Manifold learning
ID FACE RECOGNITION; DIMENSIONALITY REDUCTION; POSE ESTIMATION; HEAD POSE;
   2D
AB Many 2D face processing algorithms can perform better using frontal or near frontal faces. In this paper, we present a robust frontal view search method based on manifold learning, with the assumption that with the pose being the only variable, face images should lie in a smooth and low-dimensional manifold. In 2D embedding, we find that manifold geometry of face images with varying poses has the shape of a parabola with the frontal view in the vertex. However, background clutter and illumination variations make frontal view deviate from the vertex. To address this problem, we propose a pairwise K-nearest neighbor protocol to extend manifold learning. In addition, we present an illumination-robust localized edge orientation histogram to represent face image in the extended manifold learning. The experimental results show that the extended algorithms have higher search accuracy, even under varying illuminations. (C) 2013 Published by Elsevier Inc.
C1 [Wang, Chao; Song, Xubo] Oregon Hlth & Sci Univ, Dept Biomed Engn, Portland, OR 97201 USA.
C3 Oregon Health & Science University
RP Song, XB (corresponding author), Oregon Hlth & Sci Univ, Dept Biomed Engn, Portland, OR 97201 USA.
EM songx@ohsu.edu
FU National Science Foundation [NSF IIS-0905095]; Div Of Information &
   Intelligent Systems; Direct For Computer & Info Scie & Enginr [0905095]
   Funding Source: National Science Foundation
FX This paper is supported by a National Science Foundation Grant NSF
   IIS-0905095.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   [Anonymous], NEUROCOMPUTING
   [Anonymous], CMURITR0123
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE COMP VIS PATT R
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], CMURITR0738
   Balasubramanian V., 2007, IEEE C COMPUTER VISI, P1
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   BenAbdelkader C, 2010, LECT NOTES COMPUT SC, V6316, P518, DOI 10.1007/978-3-642-15567-3_38
   Blanz V, 2005, PROC CVPR IEEE, P454
   Caifeng Shan, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P116, DOI 10.1109/CVPR.2009.5204261
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cootes T. F., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P227, DOI 10.1109/AFGR.2000.840639
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gao YS, 2003, IEEE T SYST MAN CY A, V33, P407, DOI 10.1109/TSMCA.2003.817057
   Garcia-Mateos G, 2008, PROC CVPR IEEE, P757, DOI 10.1109/CVPRW.2008.4563050
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Heusch G, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P9
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang J, 2003, LECT NOTES COMPUT SC, V2688, P27
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lee HS, 2006, PATTERN RECOGN LETT, V27, P747, DOI 10.1016/j.patrec.2005.11.003
   Li SZ, 2005, IEEE T IMAGE PROCESS, V14, P705, DOI 10.1109/TIP.2005.847295
   Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005
   Lin C, 2000, INT C PATT RECOG, P941, DOI 10.1109/ICPR.2000.906229
   Little G, 2005, INT CONF ACOUST SPEE, P89
   Louis W, 2010, IEEE IMAGE PROC, P3809, DOI 10.1109/ICIP.2010.5653543
   McKenna SJ, 1998, REAL-TIME IMAGING, V4, P333, DOI 10.1016/S1077-2014(98)90003-1
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Raytchev B, 2004, INT C PATT RECOG, P462, DOI 10.1109/ICPR.2004.1333802
   Raytchev B, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P625
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sanderson C, 2007, LECT NOTES COMPUT SC, V4778, P276
   Shan T, 2006, INT C PATT RECOG, P515
   Teli KN., 2009, IEEE INT C BIOMETRIC, P1
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wen Yi Zhao, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P285, DOI 10.1109/AFGR.2000.840648
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Yang J, 2005, PATTERN RECOGN, V38, P1125, DOI 10.1016/j.patcog.2004.11.019
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yuan Q, 2002, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2002.1044580
   Zafeiriou S, 2007, PATTERN RECOGN, V40, P2798, DOI 10.1016/j.patcog.2007.01.026
NR 45
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1147
EP 1154
DI 10.1016/j.jvcir.2013.06.013
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700038
DA 2024-07-18
ER

PT J
AU Lang, CY
   Feng, SH
   Chen, B
   Yuan, XT
AF Lang, Congyan
   Feng, Songhe
   Chen, Bin
   Yuan, Xiaotong
TI Supervised sparse patch coding towards misalignment-robust face
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Spatial misalignment; Image occlusions; Sparse coding;
   Misalignment robust; Supervised sparse coding; Dual sparsity; Collective
   sparse reconstructions
AB We address the challenging problem of face recognition under the scenarios where both training and test data are possibly contaminated with spatial misalignments. A supervised sparse coding framework is developed in this paper towards a practical solution to misalignment-robust face recognition. Each gallery face image is represented as a set of patches, in both original and misaligned positions and scales, and each given probe face image is then uniformly divided into a set of local patches. We propose to sparsely reconstruct each probe image patch from the patches of all gallery images, and at the same time the reconstructions for all patches of the probe image are regularized by one term towards enforcing sparsity on the subjects of those selected patches. The derived reconstruction coefficients by l(1)-norm minimization are then utilized to fuse the subject information of the patches for identifying the probe face. Such a supervised sparse coding framework provides a unique solution to face recognition with all (Here, we emphasize "all" because some conventional algorithms for face recognition possess partial of these characteristics.) the following four characteristics: (1) the solution is model-free, without the model learning process, (2) the solution is robust to spatial misalignments, (3) the solution is robust to image occlusions, and (4) the solution is effective even when there exist spatial misalignments for gallery images. Extensive face recognition experiments on three benchmark face datasets demonstrate the advantages of the proposed framework over holistic sparse coding and conventional subspace learning based algorithms in terms of robustness to spatial misalignments and image occlusions. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Lang, Congyan; Feng, Songhe] Beijing Jiaotong Univ, Dept Comp Sci & Engn, Beijing, Peoples R China.
   [Chen, Bin; Yuan, Xiaotong] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117548, Singapore.
C3 Beijing Jiaotong University; National University of Singapore
RP Lang, CY (corresponding author), Beijing Jiaotong Univ, Dept Comp Sci & Engn, Beijing, Peoples R China.
EM cylang@bjtu.edu.cn; shfeng@bjtu.edu.cn; g0800415@nus.edu.sg;
   eleyuanx@nus.edu.sg
FU National Nature Science Foundation of China [61100142, 90820013];
   Beijing Jiaotong University Science Foundation [2011JBM219]
FX This work was partially supported by National Nature Science Foundation
   of China (61100142, 90820013), Beijing Jiaotong University Science
   Foundation (No. 2011JBM219).
CR [Anonymous], 2003, P ADV NEURAL INFORM
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI [10.1145/1899412.1899418, DOI 10.1145/1899412.1899418]
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Joliffe I.T., 1986, Principal Component Analysis
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li XL, 2008, IEEE T SYST MAN CY B, V38, P342, DOI 10.1109/TSMCB.2007.911536
   Pang YW, 2008, IEEE T SYST MAN CY B, V38, P1176, DOI 10.1109/TSMCB.2008.923151
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314
   Tang Jinhui., 2009, Proceedings of ACM international conference on Multimedia, P223, DOI DOI 10.1145/1631272.1631305
   Wang H., 2008, Proceedings of the 3rd International Conference on BioInspired Models of Network, Information and Computing Sytems, P22
   Wang P., 2005, 2005 IEEE COMP SOC C, P164
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu D, 2008, IEEE T IMAGE PROCESS, V17, P2256, DOI 10.1109/TIP.2008.2004430
   Yang JC, 2009, IEEE T IMAGE PROCESS, V18, P241, DOI 10.1109/TIP.2008.2009415
NR 17
TC 2
Z9 2
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2013
VL 24
IS 2
SI SI
BP 103
EP 110
DI 10.1016/j.jvcir.2012.06.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 088TC
UT WOS:000314859000003
DA 2024-07-18
ER

PT J
AU Oh, BT
   Kuo, CCJ
AF Oh, Byung Tae
   Kuo, C-C Jay
TI Super-resolution texture synthesis using stochastic PAR/NL model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Texture interpolation; Texture synthesis; Random
   texture; Stochastic texture; Non-local algorithm; Auto-regressive model;
   Self-similarity
ID IMAGE INTERPOLATION; EM ALGORITHM; RECONSTRUCTION
AB Super-resolution texture synthesis using a locally-adaptive stochastic signal model is investigated in this work. The 2D random texture is modeled by a piecewise auto-regressive (PAR) process whose parameters are determined by a non-local (NL) training procedure and, consequently, it is called the PAR/NL model. Unlike previous work that applies the NL scheme to image pixels directly, the proposed PAR/NL scheme applies the NL scheme to PAR model parameters by assuming that these parameters are self-similar. Furthermore, we describe a probabilistic method for PAR/NL model computation using the maximum a posteriori (MAP) and the expectation-maximization (EM) principles. Experimental results are given to demonstrate the synthesis performance of the proposed PAR/NL technique, which can boost texture detail and eliminate the blurring artifact perceptually. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Oh, Byung Tae] Samsung Adv Inst Technol, Multimedia Lab, Seoul, South Korea.
   [Kuo, C-C Jay] Univ So Calif, Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 Samsung; University of Southern California
RP Oh, BT (corresponding author), Samsung Adv Inst Technol, Multimedia Lab, Seoul, South Korea.
EM btoh77@gmail.com
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU Xerox
FX This research is supported in part by a gift grant from Xerox.
CR [Anonymous], 200715 MCMLA
   [Anonymous], STATE ART REPORTS
   [Anonymous], P SPIE ELECT IMAGING
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2010, IEEE T IMAGE PROCESS
   Brodatz P., 1966, Texture: A Photographic Album for Artists and Designers
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Carey WK, 1999, IEEE T IMAGE PROCESS, V8, P1293, DOI 10.1109/83.784441
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen C.H., 1998, Handbook of Pattern Recognition and Computer Vision, V2nd, P207
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fahmy G, 2006, IEEE T IMAGE PROCESS, V15, P1389, DOI 10.1109/TIP.2006.871160
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   FRANCOS JM, 1993, IEEE T SIGNAL PROCES, V41, P2665, DOI 10.1109/78.229897
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Han C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360650
   HEBERT T, 1989, IEEE T MED IMAGING, V8, P194, DOI 10.1109/42.24868
   Huang Y, 2004, IEEE T IMAGE PROCESS, V13, P1, DOI 10.1109/TIP.2003.819432
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jiji CV, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/73767
   Julesz B., 1962, IEEE T INFORM THEORY, V8, P84, DOI DOI 10.1109/TIT.1962.1057698
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Lee MS, 2007, IEEE COMMUN MAG, V45, P61, DOI 10.1109/MCOM.2007.284539
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li X, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/41516
   Li X, 2008, IEEE IMAGE PROC, P1748, DOI 10.1109/ICIP.2008.4712113
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Muresan DD, 2004, IEEE T IMAGE PROCESS, V13, P690, DOI 10.1109/TIP.2004.826097
   Nemirovsky S, 2009, SIGNAL PROCESS-IMAGE, V24, P139, DOI 10.1016/j.image.2008.11.001
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Peyre G, 2008, LECT NOTES COMPUT SC, V5304, P57, DOI 10.1007/978-3-540-88690-7_5
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Sun J, 2003, PROC CVPR IEEE, P729
   Takeda H, 2009, IEEE T IMAGE PROCESS, V18, P1958, DOI 10.1109/TIP.2009.2023703
   VILNROTTER FM, 1986, IEEE T PATTERN ANAL, V8, P76, DOI 10.1109/TPAMI.1986.4767754
   Wang LJ, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P75, DOI 10.1109/VISUAL.2004.35
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
NR 48
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 995
EP 1007
DI 10.1016/j.jvcir.2012.06.010
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900004
DA 2024-07-18
ER

PT J
AU Woodward, A
   Delmas, P
   Chan, YH
   Strozzi, AG
   Gimel'farb, G
   Flores, JM
AF Woodward, Alexander
   Delmas, Patrice
   Chan, Yuk Hin
   Strozzi, Alfonso Gastelum
   Gimel'farb, Georgy
   Marquez Flores, Jorge
TI An interactive 3D video system for human facial reconstruction and
   expression modeling
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Dynamic 3D face reconstruction; 3D video; Active
   illumination; Composite expression synthesis; Video-based texture
   generation; Motion capture; Low cost computer vision
ID CALIBRATION; CAPTURE
AB A 3D facial reconstruction and expression modeling system which creates 3D video sequences of test subjects and facilitates interactive generation of novel facial expressions is described. Dynamic 3D video sequences are generated using computational binocular stereo matching with active illumination and are used for interactive expression modeling. An individual's 3D video set is annotated with control points associated with face subregions. Dragging a control point updates texture and depth in only the associated subregion so that the user generates new composite expressions unseen in the original source video sequences. Such an interactive manipulation of dynamic 3D face reconstructions requires as little preparation on the test subject as possible. Dense depth data combined with video-based texture results in realistic and convincing facial animations, a feature lacking in conventional marker-based motion capture systems. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Woodward, Alexander] Univ Tokyo, Grad Sch Arts & Sci, Dept Gen Syst Sci, Tokyo 1138654, Japan.
   [Delmas, Patrice; Chan, Yuk Hin; Strozzi, Alfonso Gastelum; Gimel'farb, Georgy] Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand.
   [Marquez Flores, Jorge] UNAM Mexico City, CCADET, Mexico City, DF, Mexico.
C3 University of Tokyo; University of Auckland; Universidad Nacional
   Autonoma de Mexico
RP Woodward, A (corresponding author), Univ Tokyo, Grad Sch Arts & Sci, Dept Gen Syst Sci, Tokyo 1138654, Japan.
EM alex@sacral.c.u-tokyo.ac.jp
RI El-Baz, Ayman/AAC-6689-2019; Woodward, Alexander/AAG-1603-2019; Gastelum
   Strozzi, Alfonso/M-8874-2016; Woodward, Alexander/AAG-1626-2019
OI El-Baz, Ayman/0000-0001-7264-1323; Woodward,
   Alexander/0000-0003-3068-1401; Gastelum Strozzi,
   Alfonso/0000-0001-9668-5822; Gimel'farb, Georgy/0000-0003-2120-9391
CR Alyüz N, 2008, LECT NOTES COMPUT SC, V5372, P57, DOI 10.1007/978-3-540-89991-4_7
   Borshukov G., ACM SIGGRAPH 2003 SK, P1
   Borshukov G., ACM SIGGRAPH 2006 CO, P20
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Fidaleo D, 2004, COMPUT ANIMAT VIRT W, V15, P15, DOI 10.1002/cav.4
   Fusion Camera System from the CAMERON - PACE Group (CPG), 2011, FUS CAM SYST
   Ghosh A, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024163
   Gimel'farb G, 2002, PATTERN RECOGN LETT, V23, P431, DOI 10.1016/S0167-8655(01)00175-1
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Joshi P., ACM SIGGRAPH 2005 CO, P8
   Karpinsky N., 2010, J REAL-TIME IMAGE PR, P1
   Leclercq P, 2004, LECT NOTES COMPUT SC, V3322, P690
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lin J., 2006, P IM VIS COMP NZ C I, P13
   Liu KY, 2011, COMPUT ANIMAT VIRT W, V22, P159, DOI 10.1002/cav.404
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lucero JC, 2008, J ACOUST SOC AM, V124, P2283, DOI 10.1121/1.2973196
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Woodward A., 2010, P IM VIS COMP NZ C I, P1
   Woodward A, 2007, LECT NOTES COMPUT SC, V4872, P763
   Woodward A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2057, DOI 10.1109/ICME.2006.262619
   Woodward A, 2006, LECT NOTES COMPUT SC, V4109, P270
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhu J., 2003, 3DIM, P217
NR 28
TC 1
Z9 2
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1113
EP 1127
DI 10.1016/j.jvcir.2012.07.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900014
DA 2024-07-18
ER

PT J
AU Topal, C
   Akinlar, C
AF Topal, Cihan
   Akinlar, Cuneyt
TI Edge Drawing: A combined real-time edge and segment detector
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edge detection; Edge segment detection; Edge quality metrics; Real-time
   imaging
ID LINKING; PERFORMANCE
AB We present a novel edge segment detection algorithm that runs real-time and produces high quality edge segments, each of which is a linear pixel chain. Unlike traditional edge detectors, which work on the thresholded gradient magnitude cluster to determine edge elements, our method first spots sparse points along rows and columns called anchors, and then joins these anchors via a smart, heuristic edge tracing procedure, hence the name Edge Drawing (ED). ED produces edge maps that always consist of clean, perfectly contiguous, well-localized, one-pixel wide edges. Edge quality metrics are inherently satisfied without a further edge linking procedure. In addition, ED is also capable of outputting the result in vector form as an array of chain-wise edge segments. Experiments on a variety of images show that ED produces high quality edge maps and runs up to 10% faster than the fastest known implementation of the Canny edge detector (OpenCV's implementation). (c) 2012 Elsevier Inc. All rights reserved.
C1 [Topal, Cihan; Akinlar, Cuneyt] Anadolu Univ, Dept Comp Engn, TR-26470 Eskisehir, Turkey.
C3 Anadolu University
RP Topal, C (corresponding author), Anadolu Univ, Dept Comp Engn, TR-26470 Eskisehir, Turkey.
EM cihant@andolu.edu.tr; cakinlar@andolu.edu.tr
RI Akinlar, Cuneyt/AAH-7483-2019; TOPAL, CIHAN/ABC-9414-2021; Akinlar,
   Cuneyt/U-5132-2019
OI TOPAL, CIHAN/0000-0002-6329-5251; AKINLAR, CUNEYT/0000-0002-0961-7790
FU The Scientific and Technological Research Council of Turkey (TUBITAK)
   [111E053]
FX This work is partially supported by The Scientific and Technological
   Research Council of Turkey (TUBITAK) with Grant No. 111E053.
CR Akinlar C, 2012, INT CONF ACOUST SPEE, P1309, DOI 10.1109/ICASSP.2012.6288130
   Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   BASAK J, 1994, IEEE T SYST MAN CYB, V24, P413, DOI 10.1109/21.278991
   BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   Bryant D. J., 1979, Proceedings of the 1979 IEEE Computer Society Conference on Pattern Recognition and Image Processing, P138
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dai X., 1999, IEEE T GEOSCI REMOTE, V37
   Desolneux A., 2001, J MATH IMAGING VIS, V14
   ETEMADI A, 1992, IEE CONF PUBL, V354, P311
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   FRAM JR, 1975, IEEE T COMPUT, VC 24, P616, DOI 10.1109/T-C.1975.224274
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   GOKMEN M, 1993, IEEE T PATTERN ANAL, V15, P492, DOI 10.1109/34.211469
   GREGSON PH, 1993, IEEE T PATTERN ANAL, V15, P682, DOI 10.1109/34.221169
   GUPTA L, 1987, PATTERN RECOGN, V20, P267, DOI 10.1016/0031-3203(87)90001-X
   Hajjar A, 1999, IEEE T PATTERN ANAL, V21, P89, DOI 10.1109/34.745740
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   HIGGINS WE, 1994, PATTERN RECOGN, V27, P277, DOI 10.1016/0031-3203(94)90059-0
   Hough P., 1962, US Patent, Patent No. 306954
   Iivarinen J., 1997, P 8 BRIT MACH VIS C
   ILLINGWORTH J, 1988, COMPUT VISION GRAPH, V44, P87, DOI 10.1016/S0734-189X(88)80033-1
   IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562
   Jackson A.L., 2009, THESIS WASHINGTON LE
   Jevtic A., 2009, IEEE INT C IND EL
   [康文静 KANG Wenjing], 2007, [光电工程, Opto-Electronic Engineering], V34, P105
   KANUNGO T, 1995, IEEE T IMAGE PROCESS, V4, P1667, DOI 10.1109/83.475516
   Kiranyaz S, 2008, IEEE T IMAGE PROCESS, V17, P377, DOI 10.1109/TIP.2007.915562
   KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E
   Lin Q., 2010, INT C COMP RES DEV
   Luo Y., 2008, COMP VIS PATT REC WO
   MARSHALL S, 1989, IMAGE VISION COMPUT, V7, P281, DOI 10.1016/0262-8856(89)90032-2
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   MILLER FL, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1808, DOI 10.1109/IROS.1993.583881
   NVIDIA, 2007, CUDA PROGR GUID VERS
   Ogawa K., 2010, INT C NETW COMP ICNC
   Ozsen O., 2012, IEEE INT C EM SIGN P
   Prewitt J.M.S., 1970, OBJECT ENHANCEMENT E
   Rahebi J., 2010, IEEE INT C CYB INT S
   RAMESH V, 1992, P SOC PHOTO-OPT INS, V1708, P252, DOI 10.1117/12.58577
   RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490
   Rothwell C. A., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P395, DOI 10.1109/ISCV.1995.477034
   Scharr H., 2000, THESIS HEIDELBERG U
   Shih FY, 2004, INFORM SCIENCES, V167, P9, DOI 10.1016/j.ins.2003.07.020
   Shing-Min Liu, 1988, 9th International Conference on Pattern Recognition (IEEE Cat. No.88CH2614-6), P1120, DOI 10.1109/ICPR.1988.28458
   Sobel I., 1973, A 3x3 isotropic gradient operator for image processing, P271
   SRINIVASAN V, 1994, PATTERN RECOGN, V27, P1653, DOI 10.1016/0031-3203(94)90084-1
   Stahl JS, 2007, IEEE T IMAGE PROCESS, V16, P2590, DOI 10.1109/TIP.2007.904463
   STRICKLAND RN, 1993, OPT ENG, V32, P944, DOI 10.1117/12.130263
   TADROUS PJ, 1995, PATTERN RECOGN, V28, P1575, DOI 10.1016/0031-3203(95)00029-Y
   Topal Cihan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2424, DOI 10.1109/ICPR.2010.593
   Topal C, 2011, INT SYMP IMAGE SIG, P313
   VANDERHEIJDEN F, 1995, IEEE T PATTERN ANAL, V17, P16, DOI 10.1109/34.368155
   Wang ZJ, 2008, IEEE ASME INT C ADV, P151, DOI 10.1109/AIM.2008.4601650
   Wong Ya-Ping, 2008, INT C COMP GRAPH IM
   Xia MH, 2004, IEEE T IMAGE PROCESS, V13, P720, DOI 10.1109/TIP.2003.822611
   XIE M, 1992, PATTERN RECOGN LETT, V13, P647, DOI 10.1016/0167-8655(92)90121-F
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   ZIOU D, 1993, PATTERN RECOGN, V26, P1305, DOI 10.1016/0031-3203(93)90137-L
NR 61
TC 133
Z9 152
U1 2
U2 107
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 862
EP 872
DI 10.1016/j.jvcir.2012.05.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900004
DA 2024-07-18
ER

PT J
AU Tu, TH
   Hsueh, CW
   Wu, JL
AF Tu, Tang-Hsun
   Hsueh, Chih-Wen
   Wu, Ja-Ling
TI Batch-pipelining for multicore H.264 decoding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Parallelization; Pipelining; Batch; H.264; HEVC; Multicore;
   Synchronization; Optimization
AB Pipelining has been applied in many area to improve system performance by overlapping executions of hardware or software computing stages. However, direct pipelining for H.264 decoding is difficult because video bitstreams are encoded with lots of dependencies and little parallelism is left to be explored. Fortunately, pure software pipelining can still be applied to H.264 decoding at macroblock level with reasonable performance gain. However, the pipeline stages might need to synchronize with each other and incur lots of extra overhead. For optimized decoders, the overhead is relatively more significant and software pipelining might lead to negative performance gain. We first group multiple stages into larger batches and execute these batches concurrently, called batch-pipelining, to explore more parallelism on multicore systems. Experimental results show that it can speed the decoding up to 89% and achieve up to 259 and 69 frames per second for resolution 720P and 1080P, respectively, on a 4-core x86 machine over an optimized H.264 decoder. Because of its flexibility, batch-pipelining can be applied to not only H.264 but also many similar applications, such as the next-generation video coding: high efficiency video coding. Therefore, we believe the batch-pipelining mechanism creates a new effective direction for software codec development. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Tu, Tang-Hsun; Hsueh, Chih-Wen; Wu, Ja-Ling] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
C3 National Taiwan University
RP Hsueh, CW (corresponding author), Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10617, Taiwan.
EM d98944004@ntu.edu.tw; cwhsueh@csie.ntu.edu.tw; wjl@cmlab.csie.ntu.edu.tw
OI WU, JA-LING/0000-0002-3631-1551
FU ROC National Science Council [NSC-100-2628-E-002-017-, NSC
   101-2219-E-002-002-]
FX Supported in part by research grants from the ROC National Science
   Council, NSC-100-2628-E-002-017- and NSC 101-2219-E-002-002-.
CR Allan VH, 1995, ACM COMPUT SURV, V27, P367, DOI 10.1145/212094.212131
   Anderson T.E., 2002, IEEE T PARALL DISTR, V1, P6
   [Anonymous], 2009, 1449610 ISOIEC
   [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   [Anonymous], ASIA PACIFIC SIGNAL
   [Anonymous], 2009, FREE LIST
   [Anonymous], 2006, COMPILERS PRINCIPLES
   [Anonymous], 1967, AFIPS, DOI 10.1145/1465482.1465560
   Hyunki Baik, 2007, 2007 IEEE International Symposium on Signal Processing and Information Technology, P791
   Kahle J.A., 2005, INTRO CELL MULTIPROC
   Meenderinck C, 2009, J SIGNAL PROCESS SYS, V57, P173, DOI 10.1007/s11265-008-0256-9
   Park J, 2007, EMB SYST REAL TIME M, P27, DOI 10.1109/ESTMED.2007.4375797
   Paul M, 2005, IEEE T CIRC SYST VID, V15, P753, DOI 10.1109/TCSVT.2005.848312
   Paul M, 2010, IEEE T IMAGE PROCESS, V19, P691, DOI 10.1109/TIP.2009.2033406
   Roitzsch M., 2007, EMSOFT '07, P269
   Schöffmann K, 2007, LECT NOTES COMPUT SC, V4641, P782
   Seitner FH, 2008, PROC SPIE, V6821, DOI 10.1117/12.766423
   Tu T.-H., 2009, 15 INT C REAL TIM CO
   Tu TH, 2010, IEEE DATA COMPR CONF, P553, DOI 10.1109/DCC.2010.57
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   VANDERTOL E, 2003, P SPIE C IM VID COMM
   Wang S.-W., 2004, P SPIE, V5558
   Wang SW, 2009, J SIGNAL PROCESS SYS, V57, P195, DOI 10.1007/s11265-008-0321-4
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wong KW, 2001, IEEE T CIRC SYST VID, V11, P1128, DOI 10.1109/76.954499
   Yuan Y., 2007, P 15 INT C MULT, P459
   Zhou X., 2003, P SPIE C IM VID COMM, V5022
NR 27
TC 1
Z9 1
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 742
EP 752
DI 10.1016/j.jvcir.2012.03.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400006
DA 2024-07-18
ER

PT J
AU Roccetti, M
   Marfia, G
   Semeraro, A
AF Roccetti, Marco
   Marfia, Gustavo
   Semeraro, Angelo
TI Playing into the wild: A gesture-based interface for gaming in public
   spaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Computer games; Image processing; Immersive environments; Action
   recognition algorithms; Gesture following; Gaming in public spaces;
   Tortellini pasta; Shanghai 2010 World Expo
AB Gestural-based interfaces have become one of the fundamental technologies that can determine the success of new computer games. In fact, computer games today offer interaction paradigms that go well beyond the use of remote controls, letting players directly perform exchanges with the objects and characters that compose the virtual worlds that are displayed in front of them. To perform such exchanges, new algorithms and technologies have been devised which include advanced visual recognition schemes, new video cameras and accelerometer sensors. At the same time, other important trends are also quietly emerging in the same domain: game designers, in fact, are slowly shifting their attention out of the walls of gaming fanatics homes, broadening their interests to computer games that can be played in public spaces, as exhibitions and museums. However, to the best of our knowledge, only a very limited amount of research experiences have taken into account the problem of producing computer games, based on gesture-based interfaces that well suit such settings. Hence, in this paper we address the problem of differentiating the design of a gesture-based interface for a console from the problem of designing it for a public space setting. Moreover, we will show that within a public space, it is possible to narrow down the vision algorithms that can well support the recognition of complex actions, whereas solely relying on a simple webcam. In particular, we will describe the design and implementation of an interface that well suits public immersive scenarios, since it is based on a simple and efficient set of algorithms which, combined with the intelligence given by the knowledge of the context of where a game is played, leads to a fast and robust interpretation of hand gestures. To witness this last aspect, we will report on the results obtained from the deployment of a computer game we specifically developed for public spaces, termed Tortellino X-Perience, which has been enjoyed by hundreds of visitors at the 2010 Shanghai World Expo. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Roccetti, Marco; Marfia, Gustavo; Semeraro, Angelo] Univ Bologna, I-40127 Bologna, Italy.
C3 University of Bologna
RP Roccetti, M (corresponding author), Univ Bologna, Mura Anteo Zamboni 7, I-40127 Bologna, Italy.
EM roccetti@cs.unibo.it
RI Marfia, Gustavo/D-1347-2010
OI MARFIA, GUSTAVO/0000-0003-3058-8004; ROCCETTI, MARCO/0000-0003-1264-8595
FU International FIRB
FX The authors acknowledge the International FIRB Damasco Project for
   supporting this work.
CR [Anonymous], BOLOGNA SHANGHAI WOR
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bannach D, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND GAMES, P32, DOI 10.1109/CIG.2007.368076
   Campbell D., 2008, P 7 IEEE ACM INT S M
   El Rhalibi A, 2008, CONSUM COMM NETWORK, P1059, DOI 10.1109/ccnc08.2007.241
   Ferretti S., 2005, P 2005 ACM SIGCHI IN, P405
   Giles J., 2011, NEW SCI          JAN
   Harrison C, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P507
   Illingworth J., 1988, COMPUT VIS GRAPH IMA, V44, P7
   Lee JC, 2008, IEEE PERVAS COMPUT, V7, P39, DOI 10.1109/MPRV.2008.53
   Manresa C., 2005, ELECT LETT COMPUTER, V3, P96, DOI DOI 10.5565/REV/ELCVIA.109
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Mitzman D., BBC NEWS        0622
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Palazzi C. E., 2005, ACM J COMPUTERS ENTE, V3, P1
   Pasch M, 2009, ENTERTAIN COMPUT, V1, P49, DOI 10.1016/j.entcom.2009.09.004
   ROBERTSON Judy., Computers, creativity and learning
   Roccetti M., P 2001 ACM S APPL CO, P94
   Roccetti M., 2010, ACM COMPUT ENTERTAIN, V8
   Roccetti M, 2011, P 3 IEEE INT WORKSH
   Schlmer T., 2008, Second International Conference on Tangible and Embedded Interaction, P11, DOI [DOI 10.1145/1347390.1347395, 10.1145/1347390.1347395]
   Selker T, 2000, IBM SYST J, V39, P880, DOI 10.1147/sj.393.0880
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Wilson AD, 2007, SECOND ANNUAL IEEE INTERNATIONAL WORKSHOP ON HORIZONTAL INTERACTIVE HUMAN-COMPUTER SYSTEMS, PROCEEDINGS, P201, DOI 10.1109/TABLETOP.2007.35
NR 24
TC 51
Z9 55
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 426
EP 440
DI 10.1016/j.jvcir.2011.12.006
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800003
DA 2024-07-18
ER

PT J
AU Bhowmick, P
   Biswas, A
   Bhattacharya, BB
AF Bhowmick, Partha
   Biswas, Arindam
   Bhattacharya, Bhargab B.
TI On the representation of a digital contour with an unordered point set
   for visual perception
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Order-free point set; Shape visualization; Geometric graphs; Nearest
   neighbor; Delaunay triangulation; Digital geometry; Visual perception;
   Digital object
ID RELATIVE NEIGHBORHOOD GRAPH; POLYGONAL-APPROXIMATION; CURVE
   RECONSTRUCTION; SHAPE; BUILDINGS; SEGMENTATION; SKELETON; SHADOWS;
   SPHERE; CRUST
AB In this paper, we study the problem of representing the boundary of a digital object with an unordered set of points (pixels) chosen from its 1-pixel wide contour such that its shape is visually perceptible and uniquely reconstructible. Extraction of such a set is important from the viewpoint of shape description and may also offer potential solutions to various applications like object representation, recognition, and discrimination. We propose a novel technique of determining an irredundant point set from a digital contour using the classical concept of pointillism. Pointillism, a movement of painting with dots that would blend in the viewer's eye, was developed by certain Neo-Impressionists of France late in the 19th century. In order to extract the representative point set, we first consider the digitally straight pieces constituting the contour and then obtain a digital polygon P that approximates the bounding curve in a compact form. The polygon P, defined in terms of its ordered set of vertices, is replaced, in turn, with an irredundant set P' of pseudo-vertices lying on its digital edges, so that the union of P and P' produces an unordered point set that obviates the vertex ordering but captures the underlying geometric orderliness and the neighborhood relations defining the boundary of the original object. The pseudo-vertices may be chosen by controlling a parameter called pointillist factor that governs our visual perception with the nearest-neighbor correlation of a point set. The pointillist factor can be regulated to control the prominence of the underlying object with its unordered set of points - a strong outcome that establishes the technique about its ability to capture the shape information by an order-free point set of optimal or suboptimal size. We have also given a reconstruction procedure along with an error analysis related with the concerned descriptor. Experimental results on several databases demonstrate its elegance and effectiveness. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Bhowmick, Partha] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   [Biswas, Arindam] Bengal Engn & Sci Univ, Dept Informat Technol, Sibpur, Howrah, India.
   [Bhattacharya, Bhargab B.] Indian Stat Inst, Adv Comp & Microelect Unit, Kolkata, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Engineering Science
   Technology Shibpur (IIEST); Indian Statistical Institute; Indian
   Statistical Institute Kolkata
RP Bhowmick, P (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM pb@cse.iitkgp.ernet.in; abiswas@it.becs.ac.in; bhargab@isical.ac.in
RI Bhattacharya, Bhargab/AAE-6130-2020; Biswas, Arindam/X-9730-2019
OI Biswas, Arindam/0000-0002-2141-0215
CR Althaus E, 2001, SIAM J COMPUT, V31, P27, DOI 10.1137/S0097539700366115
   Althaus E, 2000, P 2 WORKSH ALG ENG E, P103
   Amenta N, 1998, GRAPH MODEL IM PROC, V60, P125, DOI 10.1006/gmip.1998.0465
   Angiulli F, 2007, IEEE T PATTERN ANAL, V29, P1746, DOI 10.1109/TPAMI.2007.1086
   [Anonymous], 1997, FLATLAND GEOMETRIC F, DOI DOI 10.1016/B978-044481538-5/50005-8
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   [Anonymous], 2003, Handbook of fingerprint recognition
   Attali D., 1997, Proceedings of the Thirteenth Annual Symposium on Computational Geometry, P248, DOI 10.1145/262839.262980
   AVIS D, 1985, ANN NY ACAD SCI, V440, P323, DOI 10.1111/j.1749-6632.1985.tb14563.x
   Bazen AM, 2003, PATTERN RECOGN, V36, P1859, DOI 10.1016/S0031-3203(03)00036-0
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bernardini F., 1997, PROC 9 CANADIAN C CO, P193
   Bhowmick P, 2005, INT J IMAGE GRAPH, V5, P537, DOI 10.1142/S0219467805001896
   Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082
   Bhowmick P, 2009, PATTERN RECOGN, V42, P465, DOI 10.1016/j.patcog.2008.03.009
   Ceguerra AV, 2002, INT C PATT RECOG, P347, DOI 10.1109/ICPR.2002.1047865
   Cormen T.H., 2000, INTRO ALGORITHMS
   De Winter J, 2008, PERCEPT PSYCHOPHYS, V70, P50, DOI 10.3758/PP.70.1.50
   DEFIGUEIREDO LH, 1994, VISUAL COMPUT, V11, P105, DOI 10.1007/BF01889981
   DEY T., 2007, CURVE SURFACE RECONS
   Dey T.K., 1999, P SODA BALT MD US 17, VVolume 99, P893
   Dey TK, 2000, COMP GEOM-THEOR APPL, V15, P229, DOI 10.1016/S0925-7721(99)00051-6
   Díaz-Báñez JM, 2001, EUR J OPER RES, V130, P214, DOI 10.1016/S0377-2217(00)00023-0
   DWYER RA, 1995, COMP GEOM-THEOR APPL, V5, P155, DOI 10.1016/0925-7721(94)00025-Q
   EDELSBRUNNER H, 1983, IEEE T INFORM THEORY, V29, P551, DOI 10.1109/TIT.1983.1056714
   Edelsbrunner H, 1998, LECT NOTES COMPUT SC, V1380, P119, DOI 10.1007/BFb0054315
   Feldman J, 2000, J EXP PSYCHOL HUMAN, V26, P152, DOI 10.1037/0096-1523.26.1.152
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Freeman H., 1961, PROC NATL ELECT C, V17, P421
   GAGE T, 1987, ART B, V69
   GERKEN P, 1994, IEEE T CIRC SYST VID, V4, P228, DOI 10.1109/76.305868
   Giesen J, 2000, DISCRETE COMPUT GEOM, V24, P577, DOI 10.1007/s004540010061
   Gold C, 2001, ALGORITHMICA, V30, P144, DOI 10.1007/s00453-001-0014-x
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   HELD A, 1994, IEEE T SYST MAN CYB, V24, P942, DOI 10.1109/21.293514
   Hotter M., 1990, Signal Processing: Image Communication, V2, P409, DOI 10.1016/0923-5965(90)90027-F
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   IRVIN RB, 1989, IEEE T SYST MAN CYB, V19, P1564, DOI [10.1109/21.44071, 10.1117/12.952691]
   Jain A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P282, DOI 10.1109/ICIP.2001.958106
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jaromczyk J. W., 1987, P 3 ANN S COMP GEOM, P233
   KARTIKEYAN B, 1989, IEEE T PATTERN ANAL, V11, P977, DOI 10.1109/34.35501
   Katsaggelos AK, 1998, P IEEE, V86, P1126, DOI 10.1109/5.687833
   Kirkpatrick D. G., 1985, Machine Intelligence and Pattern Recognition, V2, P217, DOI DOI 10.1016/B978-0-444-87806-9.50013-X
   KLETTE R, 2004, M KAUFMANN SERIES CO
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   LIOW YT, 1990, COMPUT VISION GRAPH, V49, P242, DOI 10.1016/0734-189X(90)90139-M
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mason K, 2005, LECT NOTES COMPUT SC, V3638, P103
   MATULA DW, 1980, GEOGR ANAL, V12, P205
   MUKHOPADHYAY A, 1998, P 10 CAN C COMP GEOM
   Noronha S, 2001, IEEE T PATTERN ANAL, V23, P501, DOI 10.1109/34.922708
   OROURKE J, 1982, PATTERN RECOGN, V15, P189, DOI 10.1016/0031-3203(82)90070-X
   RIEMENSCHNEIDER H, 2010, P ECCV, V10, P29
   ROSENFELD A, 2001, NOTES THEOR COMPUT S, V46
   ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Rosin PL, 1999, MACH VISION APPL, V11, P191, DOI 10.1007/s001380050101
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   Schwarzkopf O.., 2000, Computational Geometry: Algorithms and Applications, V2nd
   Seurat G.P., 1966, IMPRESSIONISM POSTIM, P113
   Sonka M., 1993, IMAGE PROCESSING ANA
   Sternberg R. J., 2003, Cognitive Psychology
   Toussaint G.T., 1988, COMPUTATIONAL MORPHO
   TOUSSAINT GT, 1980, PATTERN RECOGN, V12, P261, DOI 10.1016/0031-3203(80)90066-7
   Veltkamp R. C., 1992, Computational Geometry: Theory and Applications, V1, P227, DOI 10.1016/0925-7721(92)90003-B
   VELTKAMP RC, 1995, GRAPH MODEL IM PROC, V57, P441, DOI 10.1006/gmip.1995.1038
   VENTURA JA, 1992, PATTERN RECOGN, V25, P1129, DOI 10.1016/0031-3203(92)90016-C
   WANG B, 2010, P ECCV, V10, P15
   Willats J., 1997, Art and Representation: New Principles in the Analysis of Pictures
   WILSON M, 2006, CHI, P247
   Zunic J, 2003, IEEE T PATTERN ANAL, V25, P1193, DOI 10.1109/TPAMI.2003.1227997
   [No title captured]
   HANDWRITTEN BANGLA C
   2000, FVC 2000 FINGERPRINT
NR 76
TC 1
Z9 1
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 590
EP 605
DI 10.1016/j.jvcir.2011.07.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800002
DA 2024-07-18
ER

PT J
AU Hu, HM
   Lin, WY
   Li, B
   Sun, MT
AF Hu, Hai-Miao
   Lin, Weiyao
   Li, Bo
   Sun, Ming-Ting
TI A region-based rate-control scheme using inter-layer information for
   H.264/SVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/SVC; Region-based rate-control; Moving region (MR) detection;
   Non-MR sub-division; Bit-allocation; Inter-layer information; Low-bit
   rate applications; Motion information
ID VIDEO COMMUNICATION
AB This paper proposes a region-based rate-control scheme for H.264/SVC. The inter-layer information is utilized to improve both the coding efficiency and the subjective quality of the moving region (MR). Firstly, we propose an MR extraction method by combining the inter-layer and inter-frame information. The difference between the current frame and the previous frame is used as the inter-frame information to detect moving areas. The motion information of the reference layer is used as the inter-layer information to combine with the inter-frame information to achieve a suitable MR extraction. Secondly, according to the coding result of the reference layer, we propose to sub-divide the non-MR into complex regions and flat regions based on a MacroBlock (MB) complexity measure. Experimental results demonstrate that the proposed scheme can obtain better quality both subjectively and objectively by using different weighting factors for the three regions. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hu, Hai-Miao; Li, Bo] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
   [Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Sun, Ming-Ting] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
C3 Beihang University; Shanghai Jiao Tong University; Beihang University;
   University of Washington; University of Washington Seattle
RP Li, B (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM bhboli@vip.sina.com
RI lin, yuxi/HKF-6212-2023; Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888; Lin, Weiyao/0000-0001-8307-7107
FU 973 Program [2010CB327900]; National 863 Program [2009AA12Z112]
FX This work was partially supported by the 973 Program (Project No.
   2010CB327900), the National 863 Program (2009AA12Z112).
CR Chi MC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P93
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   LEE S, 2002, IEEE T MULTIMED, V4
   LI H, 2006, IEEE INT C SIGN PROC, V2, P16
   Li ZG, 2006, J VIS COMMUN IMAGE R, V17, P376, DOI 10.1016/j.jvcir.2005.04.004
   Li ZG, 2003, 7 JVT M PATT 2 JVT G
   Liu Y, 2006, IEEE IMAGE PROC, P3129, DOI 10.1109/ICIP.2006.312936
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P116, DOI 10.1109/TCSVT.2007.903325
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   REICHEL J, 2007, JVTW202
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Song HJ, 2004, IEEE T MULTIMEDIA, V6, P489, DOI 10.1109/TMM.2004.827488
   Sun Y, 2006, IEEE T MULTIMEDIA, V8, P1, DOI 10.1109/TMM.2005.861296
   Vieron J., 2008, JVTW203
   Xu L, 2005, PROC SPIE, V5960, P525, DOI 10.1117/12.631424
   Xu L, 2007, IEEE INT SYMP CIRC S, P49, DOI 10.1109/ISCAS.2007.378179
NR 18
TC 6
Z9 6
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2011
VL 22
IS 7
BP 615
EP 626
DI 10.1016/j.jvcir.2011.07.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 823TQ
UT WOS:000295149800004
DA 2024-07-18
ER

PT J
AU Lin, CH
   Syu, YJ
AF Lin, Chuen-Horng
   Syu, Yu-Jhuang
TI Fast segmentation of porcelain images based on texture features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital archiving; Porcelain; Texture feature; Coarseness; Contrast;
   Directionality; Gradient; Principal component analysis; Morphological
   processing; Segmentation
ID SELECTION; MODEL
AB This study aims to segment objects within images of porcelain artifacts to help users retrieve the images in an efficient and convenient manner. Through digital archiving, a tremendous number of porcelain images have been created. To avoid interference due to the image's background during the retrieval process, it is necessary to segment objects in advance to accommodate high-precision image retrieval. In the proposed segmentation process, four texture features, including coarseness, contrast, directionality, and gradient, are first obtained. The morphological processing, which involves PCA (principal component analysis), Otsu's method, and object filter for opening and closing operation, is applied. Finally, regarding the objects selected by object filter, boundary extraction and watershed segmentation are performed to segment the porcelain objects from the background. In our image segmentation experiment using images of Chinese porcelain from various dynasties, featuring various shapes and colors, complete and accurate segmentation results are produced. The results can be used as a reference for future identification of the era to which the artifacts belong, and also to lay a foundation for future development of porcelain image retrieval techniques as a benefit to academic research. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lin, Chuen-Horng; Syu, Yu-Jhuang] Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, Taichung, Taiwan.
RP Lin, CH (corresponding author), Natl Taichung Inst Technol, Grad Sch Comp Sci & Informat Technol, 129,Sec 3,Sanmin Rd, Taichung, Taiwan.
EM linch@ntit.edu.tw; s18953108@ntit.edu.tw
FU National Science Council, Taiwan [NSC 97-2221-E-025-011]
FX This work was supported in part by National Science Council, Taiwan,
   under Grant No. NSC 97-2221-E-025-011.
CR BESSER H, 1990, LIBR TRENDS, V38, P787
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   DAVATZIKOS CA, 1995, IEEE T MED IMAGING, V14, P65, DOI 10.1109/42.370403
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Ding JD, 2008, IEEE T IMAGE PROCESS, V17, P204, DOI 10.1109/TIP.2007.912918
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Dupuis A, 2006, IMAGE VISION COMPUT, V24, P1053, DOI 10.1016/j.imavis.2006.02.027
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hou Z, 2006, PATTERN RECOGN LETT, V27, P1732, DOI 10.1016/j.patrec.2006.04.012
   Huang PW, 2006, J VIS COMMUN IMAGE R, V17, P947, DOI 10.1016/j.jvcir.2005.08.005
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kato Z, 2006, IMAGE VISION COMPUT, V24, P1103, DOI 10.1016/j.imavis.2006.03.005
   MMFORD D, 1989, COMMUNICATIONS PURE, V42, P577
   *NAT DIG ARCH PROG, NAT DIG ARCH PROGR M
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pellegrino FA, 2004, IEEE T SYST MAN CY B, V34, P1500, DOI 10.1109/TSMCB.2004.824147
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shih FY, 2005, IMAGE VISION COMPUT, V23, P877, DOI 10.1016/j.imavis.2005.05.015
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   *UN CAT DIG ARCH, TAIW ART
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu N, 2007, COMPUT VIS IMAGE UND, V107, P210, DOI 10.1016/j.cviu.2006.11.004
   NATL PALACE MUSEUM A
   CHINESE PORCELAIN AR
NR 26
TC 12
Z9 12
U1 2
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 707
EP 721
DI 10.1016/j.jvcir.2010.05.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400010
DA 2024-07-18
ER

PT J
AU Liu, YW
   Huang, QM
   Ma, SW
   Zhao, DB
   Gao, W
AF Liu, Yanwei
   Huang, Qingming
   Ma, Siwei
   Zhao, Debin
   Gao, Wen
TI RD-optimized interactive streaming of multiview video with multiple
   encodings
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive streaming; Multiview video; Multiple encodings;
   Rate-distortion; H.264/MVC; RD-optimized scheduling; End-to-end
   distortion model; Error-resilience
AB This paper presents a rate-distortion (RD) optimized interactive streaming method for multiview video pre-compressed by H.264 Joint Multiview Video Model (JMVM). In the proposed method, multiple encodings are first used to facilitate the flexible server-client interaction. Second, a RD-optimized scheduling strategy is provided to guarantee the optimal view-dependent delivery of multiview video. In the RD-optimized scheduling strategy, a distortion model is proposed to estimate the expected end-to-end distortion by accounting for both coding and packet-loss-induced distortions, as well as rendering-induced distortion. With the end-to-end distortion model, the server can select the optimal encoding combination for transmission. Experimental results demonstrate that the proposed method can achieve a significant end-to-end RD performance improvement over the selective streaming methods with simulcast coding or scalable multiview coding. In addition, it has better error-resilience performance to combat with packet-losses over the Internet protocol (IP) networks. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Liu, Yanwei; Huang, Qingming] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Liu, Yanwei; Huang, Qingming] Chinese Acad Sci, Grad Sch, Beijing, Peoples R China.
   [Ma, Siwei; Gao, Wen] Peking Univ, Inst Digital Media, Beijing 100871, Peoples R China.
   [Zhao, Debin] Harbin Inst Technol, Dept Comp Sci, Harbin 150006, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Peking University; Harbin Institute of Technology
RP Liu, YW (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM ywliu@jdl.ac.cn
RI liu, yanwei/L-2453-2019; Huang, Qingming/GLR-3473-2022; Zhao,
   Debin/JEP-0204-2023
OI Huang, Qingming/0000-0002-3025-7099; 
CR [Anonymous], P PACK VID 2007
   Chakareski J, 2005, IEEE T CIRC SYST VID, V15, P1257, DOI 10.1109/TCSVT.2005.854227
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P511, DOI 10.1109/TCSVT.2002.800313
   ISHIKAWA A, MPEG2005 M12402 73 M
   *ISO IEC JTC1 SC29, 2007, JOINT MULT VID MOD J
   Kim JH, 2007, IEEE T CIRC SYST VID, V17, P1519, DOI 10.1109/TCSVT.2007.909976
   KIMATA H, 2006, IEICE JAPAN J, V89, P40
   KURUTEPE E, 2006, P INT WORKSH MULT CO, P586
   KURUTEPE E, 2006, J ZHEJIANG UNIV-SC A, V7, P830
   Kurutepe E, 2007, IEEE T CIRC SYST VID, V17, P1558, DOI 10.1109/TCSVT.2007.903664
   Li J, 2003, IEEE T MULTIMEDIA, V5, P581, DOI [10.1109/TMM.2003.813284, 10.1109/TTM.2003.813284]
   LIU Y, 2006, P 7 PAC RIM C MULT P, P564
   Liu YW, 2007, IEEE INT SYMP CIRC S, P997, DOI 10.1109/ISCAS.2007.378137
   Lou JG, 2007, ADV MULTIMED, V2007, DOI 10.1155/2007/97535
   Luo K, 2005, CHINESE J CHEM ENG, V13, P161
   LUTTRELL M, 1999, Q15I09 ITUT VCEG
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   RADULOVIC I, 2004, P IEEE ICME TAIP JUN
   Ramanathan P, 2007, IEEE T MULTIMEDIA, V9, P813, DOI 10.1109/TMM.2007.893350
   Rarnanathan P, 2006, SIGNAL PROCESS-IMAGE, V21, P462, DOI 10.1016/j.image.2006.03.002
   Smolic A, 2005, P IEEE, V93, P98, DOI 10.1109/JPROC.2004.839608
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Tekalp AM, 2007, IEEE SIGNAL PROC MAG, V24, P77, DOI 10.1109/MSP.2007.905878
   VETRO A, 2004, P PICT COD S PCS DEC
   Yang WX, 2006, IEEE T CIRC SYST VID, V16, P1385, DOI 10.1109/TCSVT.2006.884571
   Yoon SU, 2007, IEEE T CIRC SYST VID, V17, P1450, DOI 10.1109/TCSVT.2007.905363
   Zhang C, 2005, IEEE T MULTIMEDIA, V7, P1170, DOI 10.1109/TMM.2005.858406
   Zhang C, 2007, IEEE T MULTIMEDIA, V9, P520, DOI 10.1109/TMM.2006.888010
   ZHANG R, 2001, IEEE C 35 AS C SIGN
NR 29
TC 12
Z9 13
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 523
EP 532
DI 10.1016/j.jvcir.2010.02.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600014
DA 2024-07-18
ER

PT J
AU Sanchez-Cruz, H
AF Sanchez-Cruz, Hermilo
TI Proposing a new code by considering pieces of discrete straight lines in
   contour shapes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Entropy; Discrete straight lines; Freeman chain codes; Huffman
   algorithm; Shapes; Vertex chain codes; Three orthogonal directions;
   Rotation transformations
ID LOSSLESS COMPRESSION; BILEVEL IMAGES; CHAIN CODE
AB Pattern substrings analysis to find high redundancy in binary shapes is carried out to improve compression levels in binary objects. Modifications of a recent set of symbols to encode arbitrary contour shapes is proposed. The concept of Pieces of Discrete Straight Lines is introduced and the probability of appearance of symbols in contours is analyzed to propose a code of nine symbols, MDF9. Also, this code is compared with the six well-known contour codes for compression without loss of information: FCCE, FCCF, VCC, 30T, DFCCE and C_VCC. The proposed MDF9 code in this paper, gives better compression efficiency than existing codes. (C) 2010 Elsevier Inc. All rights reserved.
C1 Univ Autonoma Aguascalientes, Ctr Ciencias Basicas, Dept Ciencias Comptac, Aguascalientes 20131, Mexico.
C3 Universidad Autonoma de Aguascalientes
RP Sanchez-Cruz, H (corresponding author), Univ Autonoma Aguascalientes, Ctr Ciencias Basicas, Dept Ciencias Comptac, Av Univ 940, Aguascalientes 20131, Mexico.
EM hsanchez@correo.uaa.mx
RI Sánchez-Cruz, Hermilo/B-2235-2016
OI Sánchez-Cruz, Hermilo/0000-0001-9081-6449
CR Ageenko E, 2000, COMPUT GRAPH-UK, V24, P91, DOI 10.1016/S0097-8493(99)00140-5
   Aghito SM, 2007, IEEE T IMAGE PROCESS, V16, P2234, DOI 10.1109/TIP.2007.903902
   Aghito SM, 2006, IEEE T IMAGE PROCESS, V15, P2120, DOI 10.1109/TIP.2006.875168
   Akimov A, 2007, PATTERN RECOGN, V40, P944, DOI 10.1016/j.patcog.2006.08.005
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   Bribiesca E, 2008, J VIS COMMUN IMAGE R, V19, P184, DOI 10.1016/j.jvcir.2008.01.001
   Echavarri-Aguinaga L., 2007, OPTICAL ENG, V46
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   Hoque S, 2003, PROC INT CONF DOC, P834
   HUFFMAN M, 2003, LOSSLESS COMPRESSION
   IBANEZ L, 2001, IEEE T VISUALIZATION, V7
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Liu K, 1999, IEEE T PATTERN ANAL, V21, P1095, DOI 10.1109/34.799914
   Liu YK, 2005, PATTERN RECOGN, V38, P553, DOI 10.1016/j.patcog.2004.08.017
   Liu YK, 2007, PATTERN RECOGN, V40, P2908, DOI 10.1016/j.patcog.2007.03.001
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Martinez-Perez ME, 2002, IEEE T BIO-MED ENG, V49, P912, DOI 10.1109/TBME.2002.800789
   Pinho AJ, 2001, IEEE SIGNAL PROC LET, V8, P4, DOI 10.1109/97.889634
   Rosin PL, 2005, COMPUT VIS IMAGE UND, V99, P175, DOI 10.1016/j.cviu.2005.01.003
   Sánchez-Cruz H, 2005, OPT ENG, V44, DOI 10.1117/1.2052793
   Sanchez-Cruz Hermilo, 2008, Proceedings of the Tenth IASTED International Conference on Computer Graphics and Imaging, P6
   Sánchez-Cruz H, 2007, PATTERN RECOGN, V40, P1660, DOI 10.1016/j.patcog.2006.10.013
   Sánchez-Cruz H, 2006, LECT NOTES COMPUT SC, V4179, P161
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
NR 26
TC 16
Z9 20
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 311
EP 324
DI 10.1016/j.jvcir.2010.02.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800004
DA 2024-07-18
ER

PT J
AU Chu, WT
   Lin, CH
AF Chu, Wei-Ta
   Lin, Chia-Hung
TI Consumer photo management and browsing facilitated by near-duplicate
   detection with feature filtering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Near-duplicate detection; Representative selection; Region-of-interest;
   Feature filtering; Photo management and browsing; Image clustering;
   Photo summarization; Probabilistic latent semantic analysis
ID SEARCH
AB Near-duplicate detection techniques are exploited to facilitate representative photo selection and region-of-interest (ROI) determination, which are important functionalities for efficient photo management and browsing. To make near-duplicate detection module resist to noisy features, three filtering approaches, i.e., point-based, region-based, and probabilistic latent semantic (pLSA), are developed to categorize feature points. For the photos taken in travels, we construct a support vector machine classifier to model matching patterns between photos and determine whether photos are near-duplicate pairs. Relationships between photos are then described as a graph, and the most central photo that best represents a photo cluster is selected according to centrality values. Because matched feature points are often located in the interior or at the contour of important objects, the region that compactly covers the matched feature points is determined as the ROI. We compare the proposed approaches with conventional ones and demonstrate their effectiveness. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Chu, Wei-Ta; Lin, Chia-Hung] Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Chung Cheng University
RP Chu, WT (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM wtchu@cs.ccu.edu.tw
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239
FU National Science Council of ROC [NSC 96-2218-E-194-005, NSC
   97-2221-E-194-050]
FX This work was partially supported by the National Science Council of ROC
   under NSC 96-2218-E-194-005 and NSC 97-2221-E-194-050. The authors would
   like to thank anonymous reviewers for giving valuable comments.
CR [Anonymous], Probabilistic latent semantic analysis
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], P CVPR
   [Anonymous], P IEEE INT C COMP VI
   CHANG CC, 2001, L1BSVM LIB SUPPORT V
   Chu W.T., 2009, Proceedings of the 17th ACM international conference on Multimedia (MM '09), P509
   Chu Wei-Ta., 2008, P 16 ACM INT C MULTI, P829, DOI DOI 10.1145/1459359.1459498
   CHU WT, 2009, P ACM MULT C MULT GR, P1129
   DORKO G, 2003, P IEEE INT C COMP VI
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Ke Y, 2004, PROC CVPR IEEE, P506
   Ke Y., 2004, ACM MULTIMEDIA 04, P869
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MONAY F, 2006, P C COMP VIS PATT RE
   Platt JC, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P6
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sivic J, 2008, P IEEE, V96, P548, DOI 10.1109/JPROC.2008.916343
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang F, 2008, ADVANCES IN MATRIX THEORY AND ITS APPLICATIONS, VOL 1, P238
   Wu A. G., 2007, P ACM MM, P218
   Wu X, 2008, IEEE T MULTIMEDIA, V10, P188, DOI 10.1109/TMM.2007.911778
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
   Zhao WL, 2009, IEEE T IMAGE PROCESS, V18, P412, DOI 10.1109/TIP.2008.2008900
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
NR 29
TC 8
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2010
VL 21
IS 3
BP 256
EP 268
DI 10.1016/j.jvcir.2010.01.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 584PT
UT WOS:000276765400007
DA 2024-07-18
ER

PT J
AU Shen, F
   Zhao, YM
   Jiang, XZ
   Suwa, M
AF Shen, Feng
   Zhao, Yuming
   Jiang, Xingzhi
   Suwa, Masaki
TI Recovering high dynamic range by Multi-Exposure Retinex
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HDR image generation; Multi-Exposure Retinex; SNR; Dynamic range;
   Luminance; Reflectance; Reflectance value selection; R image stitching;
   Poisson editing
ID COLOR; COMPUTATION; FRAMEWORK; LIGHTNESS
AB The matter of generating high dynamic range (HDR) image from a number of differently exposed pictures arises to satisfy the needs of high-quality imaging and industrial applications. A number of HDR image generation algorithms have been proposed in the past. However, the HDR radiance map recovered by these classical methods cannot completely exclude the noisy pixels in the input images and thus are unable to produce the optimal result with highest possible SNR. In this paper we are going to introduce a new HDR generation algorithm based on the Multi-Exposure Retinex model deduced in this paper for HDR image composition. The luminance component L and the reflectance R are synthesized independently before being combined together. A novel R image composition method is introduced to help the composed result image reach the highest possible SNR. The method is tested on grey-level images in this paper, but it can be easily extended to the color-image version. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Shen, Feng] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Zhao, Yuming; Jiang, Xingzhi] Shanghai Jiao Tong Univ, Dept Automat, Shanghai 200240, Peoples R China.
   [Suwa, Masaki] Omron Corp, Sensing & Control Lab, Kizugawa City, Kyoto, Japan.
C3 University of Notre Dame; Shanghai Jiao Tong University; Omron
   Corporation
RP Shen, F (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM fshen1@nd.edu; arola_zym@sjtu.edu.cn; jiangxz@sjtu.edu.cn;
   suwa@ari.ncl.omron.co.jp
RI Shen, Feng/GSD-2508-2022
OI Shen, Feng/0009-0008-0415-5559
CR Akyüz AO, 2007, J VIS COMMUN IMAGE R, V18, P366, DOI 10.1016/j.jvcir.2007.04.001
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 2005, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting (The Morgan Kaufmann Series in Computer Graphics
   [Anonymous], ACM T GRAPHICS
   Ashikhmin M., 2002, EUR WORKSH REND, P1
   Berthold KP, 1974, Comput. Graph. Image Process., V3, P277, DOI [DOI 10.1016/0146-664X(74)90022-7, 10.1016/0146-664X(74)90022-7]
   BLAKE A, 1985, COMPUT VISION GRAPH, V32, P314, DOI 10.1016/0734-189X(85)90054-4
   Debevec P., 1997, P ACM SIGGRAPH, P369, DOI DOI 10.1145/258734.258884
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Elad M, 2005, LECT NOTES COMPUT SC, V3459, P217
   Fattal R, 2002, ACM T GRAPHIC, V21, P249
   FAUGERAS OD, 1979, IEEE T ACOUST SPEECH, V27, P380, DOI 10.1109/TASSP.1979.1163262
   FINLAYSON G, 2002, REMOVING SHADOWS IMA, P823
   Frankle J. A., 1983, US Patent, Patent No. [4 384 336, 4384336, US, 4384336]
   Funt B, 2000, EIGHTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P112
   FUNT BV, 1992, LECT NOTES COMPUT SC, V588, P124
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1983, P NATL ACAD SCI USA, V80, P5163, DOI 10.1073/pnas.80.16.5163
   LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078
   MANN S, 2001, P CVPR IEEE COMP SOC
   MANN S, 1996, P IS T 46 ANN C, P422
   McCann J, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P1
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   RASKAR R, 2004, IMAGE FISSION CONTEX
   SHEN F, 2007, M IM REC UND
   SOCOLINSKY D, 1999, CVPR, V99, P319
   STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767
   XIAO Y, 2006, M IM REC UND
NR 33
TC 12
Z9 15
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 521
EP 531
DI 10.1016/j.jvcir.2009.07.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400003
DA 2024-07-18
ER

PT J
AU Yang, CH
   Lin, YC
AF Yang, Cheng-Hsing
   Lin, Yi-Cheng
TI Reversible data hiding of a VQ index table based on referred counts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Reversible embedding; Vector quantization; Codebook
   clustering; Lossless compression; Steganography; Side-match; Predictive
   coding
ID SIDE-MATCH; VECTOR; IMAGES
AB This paper presents a new reversible VQ-based hiding scheme that can recover the original VQ compressed codes after data extraction. Our scheme sorts a VQ codebook using the referred counts. The VQ codebook is then divided into 2(B) clusters and half of these clusters are used to embed secret data, in which B denotes the size of the secret data embedded into each VQ index. Compared to Chang et al.'s scheme, which divides a sorted VQ codebook into 2(B-1) x 3 clusters and uses the front one-third clusters to embed secret data, our method can embed more data. Moreover, indicator, index exchanging, and side-match prediction schemes are proposed to further improve our scheme. Under the same sorted VQ codebook, the experimental results demonstrate that our data hiding algorithm has higher capacities and better compression rates. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Yang, Cheng-Hsing; Lin, Yi-Cheng] Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 900, Taiwan.
C3 National Pingtung University
RP Yang, CH (corresponding author), Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 900, Taiwan.
EM chyang@mail.npue.edu.tw
FU National Science Council of the Republic of China [NCS
   97-2221E-153-001]; TWISC@NCKU; National Science Council [NSC
   97-2219-E-006-003]
FX This research was partially supported by the National Science Council of
   the Republic of China under the Grants NCS 97-2221E-153-001 and the
   TWISC@NCKU, National Science Council under the Grants NSC
   97-2219-E-006-003.
CR Chang CC, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P947
   CHANG CC, 2005, P KNOWL BAS INT INF, P1101
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2006, J SYST SOFTWARE, V79, P1120, DOI 10.1016/j.jss.2005.11.576
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Huang JW, 2002, IEEE T CIRC SYST VID, V12, P916, DOI 10.1109/TCSVT.2002.804897
   Jo M, 2002, IEICE T INF SYST, VE85D, P1054
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lin CC, 2009, INFORM SCIENCES, V179, P140, DOI 10.1016/j.ins.2008.09.001
   Lin IC, 2009, COMPUT STAND INTER, V31, P458, DOI 10.1016/j.csi.2008.05.010
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Wu HC, 2005, COMPUT SECUR, V24, P460, DOI 10.1016/j.cose.2005.05.001
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yang CH, 2008, PATTERN RECOGN, V41, P2674, DOI 10.1016/j.patcog.2008.01.019
NR 16
TC 55
Z9 56
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2009
VL 20
IS 6
BP 399
EP 407
DI 10.1016/j.jvcir.2009.04.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 471FR
UT WOS:000268041900004
DA 2024-07-18
ER

PT J
AU Xie, J
   Chia, LT
AF Xie, Jun
   Chia, Liang-Tien
TI Study on the distribution of DCT residues and its application to R-D
   analysis of video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discrete cosine transform; Quantization; Video coding; Statistical
   analysis; Probability; Rate-distortion; Rate control; DCT Residues
ID RATE CONTROL SCHEME; QUANTIZATION ERRORS; MPEG-4 VIDEO; IMAGES;
   STANDARD; MODEL
AB Quantization errors in discrete-cosine-transform (DCT) video compression are known as DCT residues. Knowledge on their distribution is essential in understanding rate-distortion (R-D) behaviors of generic video coding. Traditional R-D analysis adopted a simplified distortion model. Those distortion models took only quantization parameter into account. They lack adaptability to variation of video sources, as the distribution of coding errors also depends on the statistics of video source. Another common approach models the distribution of DCT residues by fitting experimental data from coded pictures to conjectured statistical distributions, but it did not provide insights into what gives rise to the distribution of DCT residues. This paper intends to quantify the distribution of DCT residues with respect to video source and with respect to the quantization strategy by understanding the quantization of DCT frequency components. Moreover, it is applied to derive an R-D model to show the advantage of the proposed distribution model. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Xie, Jun; Chia, Liang-Tien] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chia, LT (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM xiejun@pmail.ntu.edu.sg; asltchia@ntu.edu.sg
RI Chia, Liang-Tien/A-9874-2008
CR [Anonymous], 1996, 138182 ISOIEC
   [Anonymous], 30 AS C SIGN SYST CO
   [Anonymous], 144962 ISOIEC
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   DAI M, 2003, INT C IM PROC, V3
   GHANBARI M, 1995, IEEE T CIRC SYST VID, V5, P171, DOI 10.1109/76.388066
   Gibbons JD, 2014, Nonparametric Statistical Inference
   Hang HM, 1997, IEEE T CIRC SYST VID, V7, P287
   He ZH, 2002, IEEE T CIRC SYST VID, V12, P840, DOI 10.1109/TCSVT.2002.804883
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   *ISO IEC, 1993, 11722 ISOIEC
   *ISO IEC, 1993, MISOIECJTC1SC29WG11
   *ISO IEC, 2001, NJTC1SC29WG11 ISOIEC
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   KUSHNER HB, 1991, IEEE T INSTRUM MEAS, V40, P682, DOI 10.1109/19.85334
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Li Z., 2003, ISOIECJTC1SC29WG11
   Liao JY, 2000, IEEE T CIRC SYST VID, V10, P30, DOI 10.1109/76.825855
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Pan F, 2003, IEEE T CIRC SYST VID, V13, P440, DOI 10.1109/TCSVT.2003.811603
   REININGER RC, 1983, IEEE T COMMUN, V31, P835, DOI 10.1109/TCOM.1983.1095893
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Robertson MA, 2005, IEEE T CIRC SYST VID, V15, P27, DOI 10.1109/TCSVT.2004.839995
   SRIPAD AB, 1977, IEEE T ACOUST SPEECH, V25, P442, DOI 10.1109/TASSP.1977.1162977
   STEPHEN R, 1996, SPEI S HUM VIS EL IM, V2657, P403
   Triantafyllidis GA, 2002, IEEE T CIRC SYST VID, V12, P877, DOI 10.1109/TCSVT.2002.804880
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhou SM, 2007, IEEE T CIRC SYST VID, V17, P996, DOI 10.1109/TCSVT.2007.903123
NR 32
TC 8
Z9 10
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2008
VL 19
IS 7
BP 411
EP 425
DI 10.1016/j.jvcir.2008.07.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 363NU
UT WOS:000260274800001
DA 2024-07-18
ER

PT J
AU Wu, YW
   Gao, YY
   Chen, Y
AF Wu, Yuwen
   Gao, Yongying
   Chen, Ying
TI Bit-depth scalability compatible to H.264/AVC-scalable extension
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video coding; H.264/AVC; H.264/AVC-scalable extension (SVC);
   H.264/AVC-Fidelity Range Extension (FRExt); bit-depth scalability;
   inter-layer prediction; bit-depth upsampling; tone mapping
AB While eight-bit playback and display devices will be dominating the marketplaces in the near future, superior visual quality by high bit-depth videos is desirable for applications such as high standard entertainment and healthcare. Hence, conventional eight-bit and high bit-depth digital imaging systems will coexist in marketplaces. Content distributors supporting both of them need to provide different contents for different users, e.g., simulcastly code the different representations for the same video content. This requires more storage or bandwidth for video content delivery. Bit-depth scalability is an efficient tool to solve this problem. However, video coding techniques can allow flexible usage of various versions of the same visual content that may have spatial resolutions and even alterations in color. In this paper, we propose a bit-depth scalable coding solution that is compatible to the scalable extension of H.264/AVC, also known as Scalable Video Coding (SVC). The proposed bit-depth scalable coding is capable of providing an 8-bit AVC main profile or high profile compliant base layer which is multiplexed with a high bit depth (e.g., 10-, 12-, or up to 14-bit) enhancement layer through macroblock level inter-layer bit-depth prediction. New decoding processes for inter-layer bit-depth prediction are introduced to enable bit-depth scalability. Combination with other types of scalability: temporal, spatial and SNR scalability, as well as single-loop decoding is also supported since our algorithm is implemented based on the up-to-date SVC reference software. Furthermore, the proposed solution supports adaptive inter-layer prediction to determine whether or not the inter-layer bit-depth prediction shall be invoked for each Macroblock. The coding efficiency of the proposed bit-depth scalable coding can be further improved by incorporating advanced inter-layer bit-depth prediction algorithms. Experimental results are presented for 8-bit to high bit (10 or 12) scalability and also the combined bit-depth and spatial scalability. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Wu, Yuwen; Gao, Yongying] Technol Fortune Ctr, Thomson Corp Res Beijing, Beijing 100085, Peoples R China.
   [Chen, Ying] Tampere Univ Technol, Dept Signal Proc, Tampere 33720, Finland.
C3 Tampere University
RP Gao, YY (corresponding author), Technol Fortune Ctr, Thomson Corp Res Beijing, 8-F,Bldg A,8 Xue Qing Rd, Beijing 100085, Peoples R China.
EM wuyw@pku.org.cn; yongying_gao@hotmail.com; ying.chen@tut.fi
CR GAO Y, 2007, JVTV061
   GAO Y, 2007, JVT 23 M SAN JOS US
   GAO Y, 2006, JVTU049
   *ISO IEC IS, 2004, 144961 ISOIEC IS
   *ISO IEC IS, 1994, 138182 ISOIEC IS 2
   LIU S, 2008, SPIE C VIS COMM IM P
   MANTIUK P, 2004, ACM T GRAPHICS
   REICHEL J, 2007, JVTW202
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SEGALL A, 2007, JVT 24 M GEN SWITZ J
   SEGALL A, 2006, JVTT060
   SEGALL A, 2007, JVT 23 M SAN JOS US
   SEGALL A, 2007, JVT 25 M SHENZH CHIN
   Segall A, 2007, IEEE IMAGE PROC, P1
   SUN S, 2004, JVTL015
   Swartz CharlesS., 2005, Understanding Digital Cinema
   WARD G, 2004, ACM INT C P SERIES, V73, P83
   WINKEN M, 2007, JVTX057
   WINKEN M, 2007, JVT 25 M SHENZH CHIN
   Winken M, 2007, IEEE IMAGE PROC, P5
   Wu YW, 2008, IEEE INT SYMP CIRC S, P3442, DOI 10.1109/ISCAS.2008.4542199
   Wu YW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1139
NR 22
TC 3
Z9 20
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2008
VL 19
IS 6
BP 372
EP 381
DI 10.1016/j.jvcir.2008.06.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 343KS
UT WOS:000258853100003
DA 2024-07-18
ER

PT J
AU Park, S
   Kim, J
AF Park, SangHoon
   Kim, JongWon
TI An adaptive media playout for intra-media synchronization of
   networked-video applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE intra-media synchronization; adaptive media playout; discontinuity
   model; media streaming
ID INTERNET; DELAY
AB Adaptive media playout (AMP) aims to improve the media synchronization quality of streaming applications by regulating the playout time interval among media units (MUs) at a receiver. In this paper, we introduce an AMP scheme based on a discontinuity model for intra-media synchronization of video applications over the best-effort networks. We analyze the temporal distortion (i.e., discontinuity) cases, such as playout pause and skip, to define a unified discontinuity model. Based on the discontinuity model, an objective intra-media synchronization quality metric is defined as the root mean square error (RMSE) of discontinuity. After that, we establish a practical algorithm that enables an efficient playout speed control to enhance the intra-media synchronization quality. Simulation results verify the enhanced intra-media synchronization quality through comparison with a conventional buffer-threshold-based scheme. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Park, SangHoon; Kim, JongWon] GwangJu Inst Sci & Technol, Dept Informat & Commun, Networked Media Lab, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Kim, J (corresponding author), GwangJu Inst Sci & Technol, Dept Informat & Commun, Networked Media Lab, Kwangju 500712, South Korea.
EM shpark@nm.gist.ac.kr; jongwon@nm.gist.ac.kr
CR Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   ISHIBASHI Y, 1995, IEEE INFOCOM SER, P1010, DOI 10.1109/INFCOM.1995.515977
   ISHIBASHI Y, 2001, P IEEE INFOCOM 01
   JACOBSON V, 1988, P ACM SIGCOMM 98
   *JOINT VID TEAM, 2005, JOINT SCAL VID MOD J
   Kalman M, 2004, IEEE T CIRC SYST VID, V14, P841, DOI 10.1109/TCSVT.2004.828335
   KATO M, 1997, P IEEE PIMRC 97, V3, P1049
   KOENEN R, 2001, JTC1SC29WG11 ISO IEC
   Laoutaris N, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-10, CONFERENCE RECORD, P969, DOI 10.1109/ICC.2001.937381
   Laoutaris N, 2002, IEEE NETWORK, V16, P30, DOI 10.1109/MNET.2002.1002997
   LIU F, 2001, P IEEE INT C AC SPEE, V3, P1461
   Liu H, 1999, IEEE J SEL AREA COMM, V17, P1660, DOI 10.1109/49.790488
   Liu H., 2003, P PACK VID WORKSH 20
   MILLS DL, 1991, IEEE T COMMUN, V39, P1482, DOI 10.1109/26.103043
   Moon SB, 1998, MULTIMEDIA SYST, V6, P17, DOI 10.1007/s005300050073
   RAMJEE R, 1994, IEEE INFOCOM SER, P680, DOI 10.1109/INFCOM.1994.337672
   Rangan PV, 1996, IEEE J SEL AREA COMM, V14, P52, DOI 10.1109/49.481693
   ROTHERMAL K, 1995, LNCS, V1018, P189
   Schulzrinne H., 1996, 1889 IETF RFC
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   VERHELST W, 1993, P IEEE INT C AC SPEE, V2, P27
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Yuang MC, 1997, IEEE J SEL AREA COMM, V15, P136, DOI 10.1109/49.552064
NR 23
TC 12
Z9 15
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2008
VL 19
IS 2
BP 106
EP 120
DI 10.1016/j.jvcir.2007.09.002
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 264MD
UT WOS:000253290600003
DA 2024-07-18
ER

PT J
AU Bouguila, N
   Ziou, D
AF Bouguila, Nizar
   Ziou, Djemel
TI Unsupervised learning of a finite discrete mixture: Applications to
   texture modeling and image databases summarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE multinomial dirichlet; finite mixture models; maximum likelihood; EM;
   semantic features; image retrieval; vistex; cooccurrence matrix
ID MAXIMUM-LIKELIHOOD-ESTIMATION; DENSITIES
AB This paper presents an unsupervised learning algorithm for fitting a finite mixture model based on the Multinomial Dirichlet distribution (MDD). This mixture is particularly useful for modeling discrete data (vectors of counts). The algorithm proposed is based on the expectation maximization (EM) approach. This mixture is used to improve image databases categorization by integrating semantic features and to produce a new texture model. For the texture modeling problem, the results are reported on the Vistex texture image database from the MIT Media Lab. (c) 2007 Elsevier Inc. All rights reserved.
C1 Univ Sherbrooke, Fac Sci, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada.
   Concordia Univ, Fac Engn & Comp Sci, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
C3 University of Sherbrooke; Concordia University - Canada
RP Bouguila, N (corresponding author), Univ Sherbrooke, Fac Sci, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada.
EM bouguila@ciise.concordia.ca; ziou@usherbrooke.ca
RI Bouguila, Nizar/AGN-5929-2022; Bouguila, Nizar/AAJ-2518-2020
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], 1983, Matrices with Applications in Statistics
   [Anonymous], 1965, Table of Integrals, Series, and Products
   BANFIELD JD, 1993, BIOMETRICS, V49, P803, DOI 10.2307/2532201
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Bezdek James C., 1981, PATTERN RECOGN
   BLACKWELL D, 1973, ANN STAT, V1, P353, DOI 10.1214/aos/1176342372
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664
   BOUGUILA N, 2004, P 14 C FRNC AFRIF AF, P469
   Cadez IV, 2002, MACH LEARN, V47, P7, DOI 10.1023/A:1013679611503
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Church K. W., 1995, Natural Language Engineering, V1, P163, DOI DOI 10.1017/S1351324900000139
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fielitz B. D., 1975, Decision Sciences, V6, P1, DOI [10.1111/j.1540-5915.1975.tb00992.x, DOI 10.1111/J.1540-5915.1975.TB00992.X]
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Garge NR, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S2-S10
   GRIFFITHS DA, 1973, BIOMETRICS, V29, P637, DOI 10.2307/2529131
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hsu CN, 2003, MACH LEARN, V53, P235, DOI 10.1023/A:1026367023636
   Katz S., 1996, Natural Language Engineering, V2, P15, DOI 10.1017/S1351324996001246
   Kherfi ML, 2003, J VIS COMMUN IMAGE R, V14, P428, DOI 10.1016/S1047-3203(03)00043-9
   Kotz S., 1990, SYMMETRIC MULTIVARIA
   Lewis D.D., 1998, LECT NOTES COMPUTER, V1398, P4
   LOWE SA, 1999, P DARPA BROADC NEWS
   McLachlan J., 1997, The EM Algorithm and Extensions
   MCLACHLAN JG, 2000, FINITE MIXTURE METHO
   MOSIMANN JE, 1962, BIOMETRIKA, V49, P65, DOI 10.2307/2333468
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Rao C.R., 1952, ADV STAT METHODS BIO
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Rennie J.D., 2003, Proceedings of the 20th International Conference on Machine Learning, P616
   RENNIE JDM, 2002, P NEUR INF PROC SYST, P721
   Ripley BD, 1996, PATTERN RECOGNITION
   RISSANEN J, 1978, AUTOMATICA, V49, P65
   Rong Z., 2001, IEEE T PATTERN ANAL, V23, P713
   Salah AA, 2004, INT C PATT RECOG, P276, DOI 10.1109/ICPR.2004.1334106
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   TEEVAN J, 2003, P 26 ANN INT ACMSIGI, P1825
   Tuceryan M., 1998, HDB PATTERN RECOGNIT, V2nd
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   VICKERS AL, 1982, IEEE T PATTERN ANAL, V4, P61, DOI 10.1109/TPAMI.1982.4767197
NR 45
TC 38
Z9 42
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2007
VL 18
IS 4
BP 295
EP 309
DI 10.1016/j.jvcir.2007.02.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 200NU
UT WOS:000248770900001
DA 2024-07-18
ER

PT J
AU Buciu, I
   Pitas, I
AF Buciu, I.
   Pitas, I.
TI NMF, LNMF, and DNMF modeling of neural receptive fields involved in
   human facial expression perception
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image representation; receptive fields; facial expressions
ID OBJECT RECOGNITION; FACE; CORTEX; STATISTICS; COMPONENTS; RESPONSES;
   NEURONS; SPARSE; PARTS
AB Recently, three learning algorithms, namely non-negative matrix factorization (NMF), local non-negative matrix factorization (LNMF), and discriminant non-negative matrix factorization (DNMF) have been proposed to produce sparse image representations. However, when their input is a database of human facial images, they decompose the images into sparse representations with quite different degree of sparseness. Within a continuum of sparseness ranging from holistic to local image representation, the first algorithm rather tends towards the first extreme, while the second algorithm produces a local representation. The third algorithm provides an image representation that is in between these two extremes. These algorithms decompose the facial images in the database into basis images and their corresponding coefficients. The basis images are learned by the algorithm when human face images are given as input. By analogy to neurophysiology, the basis images could be associated with the receptive fields of neuronal cells involved in encoding human faces. Taken from this point of view, the paper presents an analysis of these three representations in connection to the receptive field parameters such as spatial frequency, frequency orientation, position, length, width, aspect ratio, etc. By analyzing the tiling properties of these bases we can have an insight of how suitable these algorithms are to resemble biological visual perception systems. (c) 2006 Elsevier Inc. All rights reserved.
C1 Aristotle Univ Thessaloniki, Dept Informat, GR-54124 Thessaloniki, Greece.
   Univ Oradea, Fac Elect Engn & Infomat Technol, Dept Elect, Oradea 410087, Romania.
C3 Aristotle University of Thessaloniki; University of Oradea
RP Buciu, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Box 451, GR-54124 Thessaloniki, Greece.
EM ibuciu@uoradea.ro; pitas@aiia.csd.auth.gr
RI Buciu, Ioan/AGL-7329-2022
OI Buciu, Ioan/0000-0002-2220-9476
CR [Anonymous], 2002, The Handbook of Brain Theory and Neural Networks
   ATICK JJ, 1992, NEURAL COMPUT, V4, P196, DOI 10.1162/neco.1992.4.2.196
   Aticky JJ, 2011, NETWORK-COMP NEURAL, V22, P4, DOI 10.3109/0954898X.2011.638888
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Buciu I, 2004, MACHINE LEARN SIGN P, P539
   COTTRELL GW, 1997, PHILOS T ROY SOC LON, V352, P1203
   Dailey MN, 1999, NEURAL NETWORKS, V12, P1053, DOI 10.1016/S0893-6080(99)00050-7
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DESIMONE R, 1991, J COGNITIVE NEUROSCI, V3, P1, DOI 10.1162/jocn.1991.3.1.1
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Ellison JW, 1997, J EXP PSYCHOL HUMAN, V23, P213, DOI 10.1037/0096-1523.23.1.213
   FYFE C, 1995, NETWORK-COMP NEURAL, V6, P333, DOI 10.1088/0954-898X/6/3/002
   HANCOCK PJB, 1992, NETWORK-COMP NEURAL, V3, P61, DOI 10.1088/0954-898X/3/1/008
   HASSELMO ME, 1989, BEHAV BRAIN RES, V32, P203, DOI 10.1016/S0166-4328(89)80054-3
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Körding KP, 2004, J NEUROPHYSIOL, V91, P206, DOI 10.1152/jn.00149.2003
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   LI SZ, 2001, LEARNING SPATIALLY L, P207
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   PERRETT DI, 1982, EXP BRAIN RES, V47, P329
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Rolls ET, 1990, NETWORK-COMP NEURAL, V1, P407, DOI 10.1088/0954-898X/1/4/002
   TANAKA JW, 1993, Q J EXP PSYCHOL-A, V46, P225, DOI 10.1080/14640749308401045
   TANAKA K, 1990, MEMORY TEMPORAL LOBE, P101
   VALENTINE T, 1991, Q J EXP PSYCHOL-A, V43, P161, DOI 10.1080/14640749108400966
NR 28
TC 19
Z9 22
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 958
EP 969
DI 10.1016/j.jvcir.2006.06.001
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700002
DA 2024-07-18
ER

PT J
AU Hung, MH
   Hsieh, CH
   Kuo, CM
AF Hung, Mao-Hsiung
   Hsieh, Chaur-Heh
   Kuo, Chung-Ming
TI Similarity retrieval of shape images based on database classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE shape similarity retrieval; database classification; MPEG-7 ART
   descriptor
ID RELEVANCE FEEDBACK; DESCRIPTORS
AB Shape is a key visual feature used to describe image content. This paper develops a novel shape-based similarity retrieval system based on database classification which exploits the contour and interior region of a shape efficiently. In this system, the database of shape images is categorized automatically into I I classes by a simple contour feature. In query, the contour feature of the input image is used to decide which class the query image belongs to. Then, the possible classes are selected dynamically from the database and to form candidate sets with different priority orders. Then, ART region feature is employed to compare the query with the candidate sets according to the priority order. Instead of using the original contour of a shape image directly, we employ a rough version of the original contour for the classification of shapes. The similarity test results indicate that the proposed method improves retrieval accuracy and speed significantly, as compared to ART. (c) 2005 Elsevier Inc. All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Hsieh, CH (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM hsieh@isu.edu.tw
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Abbasi S, 2000, IMAGE VISION COMPUT, V18, P199, DOI 10.1016/S0262-8856(99)00019-0
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Ciocca G, 2001, PATTERN RECOGN, V34, P1639, DOI 10.1016/S0031-3203(00)00055-8
   Ciocca G, 1999, INFORM PROCESS MANAG, V35, P605, DOI 10.1016/S0306-4573(99)00021-7
   Eakins JP, 1998, IEEE MULTIMEDIA, V5, P53, DOI 10.1109/93.682526
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   KIM WY, 1999, ISOIECMPEG99M5472TR1
   Lowe D. G., 1985, Perceptual Organization and Visual Recognition
   Manjunath B.S., 2002, INTRO MPEG 7
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   *MPEG, 2001, ISOIECJTC1WG11N3914
   *MPEG, ISOIECJTC1SC29WG11N4
   RAMAMURTHI B, 1986, IEEE T COMMUN, V34, P1105, DOI 10.1109/TCOM.1986.1096468
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Yin PY, 2002, PATTERN RECOGN LETT, V23, P113, DOI 10.1016/S0167-8655(01)00091-5
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2003, MULTIMEDIA SYST, V9, P15, DOI 10.1007/s00530-002-0075-y
NR 20
TC 12
Z9 14
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 970
EP 985
DI 10.1016/j.jvcir.2005.09.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700003
DA 2024-07-18
ER

PT J
AU Aujol, JF
   Kang, SH
AF Aujol, Jean-Francois
   Kang, Sung Ha
TI Color image decomposition and restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE total variation; structure; texture; color; image decomposition; image
   restoration
ID TOTAL VARIATION MINIMIZATION; ENHANCEMENT; TV
AB Meyer has recently introduced an image decomposition model to split an image into two components: a geometrical component and a texture (oscillatory) component. Inspired by his work, numerical models have been developed to carry out the decomposition of gray scale images. In this paper, we propose a decomposition algorithm for color images. We introduce a generalization of Meyer's G norm to RGB vectorial color images, and use Chromaticity and Brightness color model with total variation minimization. We illustrate our approach with numerical examples. (C) 2005 Elsevier Inc. All rights reserved.
C1 Univ Kentucky, Dept Math, Lexington, KY 40506 USA.
   Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90095 USA.
C3 University of Kentucky; University of California System; University of
   California Los Angeles
RP Kang, SH (corresponding author), Univ Kentucky, Dept Math, 715 Patterson Off Tower, Lexington, KY 40506 USA.
EM aujol@math.ucla.edu; skang@ms.uky.edu
RI cai, bo/G-1491-2010; Aujol, Jean-Francois/AHC-7262-2022
OI Aujol, Jean-Francois/0000-0001-6716-0509; Kang, Sung
   Ha/0000-0002-0312-6595
CR AUBERT G, 2005, IN PRESS APPL MATH O
   AUBERT G, 2002, APPL MATH SCI, V147
   Aujol JF, 2003, LECT NOTES COMPUT SC, V2695, P297
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   AUJOL JF, 2004, 0473 UCLA CAM
   AUJOL JF, 2005, IN PRESS INT J COMPU
   Bect J, 2004, LECT NOTES COMPUT SC, V2034, P1
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Blomgren P, 1998, IEEE T IMAGE PROCESS, V7, P304, DOI 10.1109/83.661180
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan T, 2000, SIAM J APPL MATH, V61, P1338, DOI 10.1137/S003613999935799X
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P231, DOI 10.1109/83.902288
   DAUBECHIES I, 2004, UNPUB APPL COMPUT HA
   Ekeland I., 1974, ETUDES MATH
   Kimmel R, 2002, J VIS COMMUN IMAGE R, V13, P238, DOI 10.1006/jvci.2001.0501
   LE T, 2004, 0436 UCLA CAM
   Meyer Y., 2001, U LECT SERIES AMS, V22
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195
   Rockafellar T., 1983, GRUNDLEHREN MATH WIS, V224
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   STARCK JL, 2005, IN PRESS IEEE T IMAG
   Tang B, 2001, IEEE T IMAGE PROCESS, V10, P701, DOI 10.1109/83.918563
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Vese LA, 2004, J MATH IMAGING VIS, V20, P7, DOI 10.1023/B:JMIV.0000011316.54027.6a
NR 29
TC 56
Z9 63
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 916
EP 928
DI 10.1016/j.jvcir.2005.02.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500014
DA 2024-07-18
ER

PT J
AU Lim, SJ
   Jeong, YY
   Ho, YS
AF Lim, Seong-Jae
   Jeong, Yong-Yeon
   Ho, Yo-Sung
TI Automatic liver segmentation for volume measurement in CT images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE liver segmentation; volume measurement; morphological filtering;
   deformable contouring; computer-aided diagnosis
AB Computed tomography (CT) images have been widely used for diagnosis of liver disease and volume measurement for liver surgery or transplantation. Automatic liver segmentation and volume measurement based on the segmentation are the most essential parts in computer-aided diagnosis for liver CT as well as computer-aided surgery. However, liver segmentation, in general, has been performed by outlining the medical image manually or segmenting CT images semi-automatically because surface features of the liver and partial-volume effects make automatic discrimination from other adjacent organs or tissues very difficult. Accordingly, in this paper, we propose a new approach to automatic segmentation of the liver for volume measurement in sequential CT images. Our method analyzes the intensity distribution of several abdominal CT samples and exploits a priori knowledge, such as CT numbers and location of the liver to identify coherent regions that correspond to the liver. The proposed scheme utilizes recursively morphological filter with region-labeling and clustering to detect the search range and to generate the initial liver contour. In this search range, we deform liver contour using the labeling-based search algorithm following pattern features of the liver contour. Lastly, volume measurement is automatically performed on the segmented liver regions. The experimental measurement of area and volume is compared with those using manual tracing method as a gold standard by the radiological doctors, and demonstrates that this algorithm is effective for automatic segmentation and volume measurement method of the liver. (C) 2005 Elsevier Inc. All rights reserved.
C1 Gwangju Inst Sci & Technol, Kwangju 500712, South Korea.
   Chonnam Natl Univ, Sch Med, Kwangju 501757, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Chonnam National
   University
RP Lim, SJ (corresponding author), Gwangju Inst Sci & Technol, 1 Oryong Dong, Kwangju 500712, South Korea.
EM sjlim@gist.ac.kr; yjeong@chonnam.ac.kr; hoyo@gist.ac.kr
CR Chen EL, 1998, IEEE T BIO-MED ENG, V45, P783, DOI 10.1109/10.678613
   Giger ML, 2001, IEEE T MED IMAGING, V20, P1205, DOI 10.1109/TMI.2001.974915
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gose E., 1996, PATTERN RECOGNITION
   Kim H.Y., 2002, THESIS CHUNGNAM NATL
   Kim M, 1999, IEEE T CIRC SYST VID, V9, P1216, DOI 10.1109/76.809157
   Lim SJ, 2004, P SOC PHOTO-OPT INS, V5370, P1658, DOI 10.1117/12.533586
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   MORTENSEN EN, 1998, GRAPH MODEL IM P, V60
   Mukhopadhyay S, 2003, IEEE T IMAGE PROCESS, V12, P533, DOI 10.1109/TIP.2003.810757
   REITINGER B, 2003, P SPRING C COMP GRAP
   Shiffman S, 2000, IEEE T MED IMAGING, V19, P1064, DOI 10.1109/42.896782
NR 12
TC 98
Z9 111
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 860
EP 875
DI 10.1016/j.jvcir.2005.07.001
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500011
DA 2024-07-18
ER

PT J
AU Ghandi, MM
   Ghanbari, M
AF Ghandi, M. M.
   Ghanbari, M.
TI Layered H.264 video transmission with hierarchical QAM
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE scalable video coding; error resilience; unequal priority control
ID CONCEALMENT
AB In multimedia communication systems, channel bandwidth and probability of error are the two main limitations that affect the quality of service. Therefore, in applications such as video over mobile networks, a video codec should cope with the erroneous situations of the channel as well as the bandwidth limitation. There are several techniques to make a video bitstream robust to the channel error. Layered video coding in conjunction with unequal error protection is a common method that provides error resilience. Hierarchical quadratic amplitude modulation is an efficient method that provides the unequal priority control for communication channels without adding any redundancy to the transmitted data. To generate the layers in the H.264/AVC video coding standard, the data partitioning technique has been included. Scalability is another efficient layering technique that is not entirely supported in the current specification of H.264/AVC. This paper proposes an SNR scalable scheme to adapt to the H.264/AVC codec. It contains new features that make it more efficient than the previous SNR scalable codecs. In this paper applying unequal error protection by hierarchical coding to both scalable and data partitioned bitstreams is analyzed. Simulation results show that the scalable scheme is more successful in conjunction with unequal error protection. (c) 2005 Elsevier Inc. All rights reserved.
C1 Univ Essex, Dept Elect Syst Engn, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Ghandi, MM (corresponding author), Univ Essex, Dept Elect Syst Engn, Wivenhoe Pk, Colchester CO4 3SQ, Essex, England.
EM mahdi@essex.ac.uk; ghan@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378
CR ALFONSO D, 2003, P INT C PICT COD S S
   [Anonymous], 1996, 138182 ISOIEC
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEE TELECOMMUNICATIO
   BARMADA B, 2002, P IEE C 3G MOB COMM
   BLASZAK L, 2003, JTC1SC29WG11 ISOIEC
   *EUR BROADC UN DVB, 2001, ETSI EN 300 744 V1 4
   GALLANT M, 2001, IEEE T CIRCUITS SYST, V11
   GHANDI MM, 2004, P IEEE INT C IM PROC
   HALABACH T, 2003, P C VIS COMM IM PROC
   Hanzo L., 2000, WLANS BROADCASTING
   HE Y, 2002, ISCAS, V4, P548
   *ISO IEC MPEG, 1999, 144962 ISOIEC
   JOCH A, 2002, P INT PACK VID WORKS
   *MPEG VID SUBGR CH, JTC1SC29WG11M10569 I
   SHWARZ H, 2003, JVTI032D1 ISOIEC JTC
   Shyu HC, 1999, IEEE T CIRC SYST VID, V9, P937, DOI 10.1109/76.785732
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   WANG YK, 2002, P IEEE INT C IM PROC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P688, DOI 10.1109/TCSVT.2003.815168
   ZHOU P, 2003, P IEEE INT S CIRC SY, V2, P956
NR 21
TC 32
Z9 33
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 451
EP 466
DI 10.1016/j.jvcir.2005.05.005
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000014
DA 2024-07-18
ER

PT J
AU Mouravliansky, N
   Matsopoulos, GK
   Delibasis, K
   Asvestas, P
   Nikita, KS
AF Mouravliansky, N
   Matsopoulos, GK
   Delibasis, K
   Asvestas, P
   Nikita, KS
TI Combining a morphological interpolation approach with a surface
   reconstruction method for the 3-D representation of tomographic data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE medical interpolation; mathematical morphology; 3-D visualization;
   surface reconstruction; marchina cubes algorithm
ID MR
AB In this paper, a new interpolation scheme, based on Mathematical Morphology and a modified Marching Cubes (MC) Algorithm to reconstruct 3-D anatomical structures is presented. The proposed interpolation technique is implemented using morphological operations and incorporates a distance function to improve the computational effectiveness of the technique. The morphological interpolation technique is compared to an existing shape based interpolation method and its advantages include superiority capability on handling various cases such as the branching and holes problem (appearance and disappearance of information) and more accurate volume estimation. Furthermore, the morphological technique is companied with a 3-D reconstruction algorithm capable of representing any anatomical structure from real 3-D medical data. Introducing a novel general rule.. the algorithm triangulates all standard cube configurations introduced from the standard MC algorithm, without producing topologically incoherent surfaces or holes. Finally, the technique is implemented in JAVA and its output is in VRML 1.0 format; therefore it can be executed over the internet and implemented for telemedicine applications. (C) 2003 Elsevier Inc. All rights reserved.
C1 Natl Tech Univ Athens, Dept Elect & Comp Engn, Inst Commun & Comp Syst, Athens, Greece.
C3 National Technical University of Athens
RP Natl Tech Univ Athens, Dept Elect & Comp Engn, Inst Commun & Comp Syst, Athens, Greece.
EM nikos@isihellas.com; gmatso@esd.ece.ntua.gr
RI Asvestas, Pantelis/U-8912-2019
OI Asvestas, Pantelis/0000-0002-0570-0909; Nikita,
   Konstantina/0000-0001-8255-4354; Delibasis,
   Konstantinos/0000-0003-1055-3007
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Baker L, 1989, EDUC PSYCHOL REV, V1, P3, DOI 10.1007/BF01326548
   BEUCHER S, 1998, MATH MORPHOLOGY ITS
   BURR DJ, 1981, IEEE T PATTERN ANAL, V3, P708, DOI 10.1109/TPAMI.1981.4767176
   CHEN SY, 1990, IEEE T MED IMAGING, V9, P71, DOI 10.1109/42.52984
   Delibasis KS, 2001, COMPUT MED IMAG GRAP, V25, P343, DOI 10.1016/S0895-6111(00)00082-3
   GOSHTASBY A, 1992, IEEE T MED IMAGING, V11, P507, DOI 10.1109/42.192686
   Haralick R. M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P516
   Iwanowski M., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P50, DOI 10.1109/ICIAP.1999.797570
   Iwanowski M., 2002, P INT C COMP VIS GRA, P360
   JI L, 1989, PATTERN RECOGN LETT, V9, P201, DOI 10.1016/0167-8655(89)90055-X
   JOLIOT M, 1993, IEEE T MED IMAGING, V12, P269, DOI 10.1109/42.232255
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   MATSOPOULOS GK, 1995, J VIS COMMUN IMAGE R, V6, P196, DOI 10.1006/jvci.1995.1018
   Meijering EHW, 2001, MED IMAGE ANAL, V5, P111, DOI 10.1016/S1361-8415(00)00040-2
   Meyer F., 1996, MATH MORPHOLOGY ITS
   Ostuni JL, 1997, J COMPUT ASSIST TOMO, V21, P803, DOI 10.1097/00004728-199709000-00029
   RAUSIN PL, 1995, GRAPH MODEL IM PROC, V57, P483
   RAYA SP, 1990, IEEE T MED IMAGING, V9, P32, DOI 10.1109/42.52980
   Serra J., 1998, Mathematical Morphology and Its Applications to Image Processing
   Serra J., 1988, IMAGE ANAL MATH MORP
   Serra Jean., 1983, Image Analysis and Mathematical Morphology, V1
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Werahera PN, 1995, IEEE T MED IMAGING, V14, P765, DOI 10.1109/42.476120
   ZHOU C, 1994, COMPUT GRAPH-UK, V18, P845, DOI 10.1016/0097-8493(94)90011-6
NR 26
TC 6
Z9 7
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2004
VL 15
IS 4
BP 565
EP 579
DI 10.1016/j.jvcir.2003.12.003
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 868OZ
UT WOS:000224924200005
DA 2024-07-18
ER

PT J
AU Sheng, ZQ
   Xu, WB
   Lin, C
   Lu, W
   Ye, L
AF Sheng, Ziqi
   Xu, Wenbo
   Lin, Cong
   Lu, Wei
   Ye, Long
TI Length Deep generative network for image inpainting with gradient
   semantics and spatial-smooth attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image content security; Image inpainting; Deep generative model;
   Spatial-smooth attention
ID OBJECT REMOVAL; EDGE
AB As a powerful forgery operation in the image content security area, image inpainting based on deep generative networks can yield visually appealing outputs but often produces ambiguous artifacts, especially in boundary and high semantic areas. To address this issue, a novel end-to-end network with gradient semantics and spatial-smooth attention (GS-SSA) is proposed, which combines a gradient learning network and an image inpainting network. The gradient learning network is meant to properly anticipate the gradient semantics in the hole region and get a complete gradient semantic map. The image inpainting network utilizes the complete gradient semantic map to better repair the missing pixels and obtain the final inpainting results. Moreover, spatial-smooth attention is introduced into the image inpainting network, considering both the spatial structural relations and the surrounding information in the hole region. Experimental results on public datasets show the superiority of the proposed method, especially in large-hole region tasks.
C1 [Sheng, Ziqi; Xu, Wenbo; Lu, Wei] Sun Yat Sen Univ, Guangdong Prov Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp, Sch Comp Sci & Engn,Minist Educ, Guangzhou 510006, Peoples R China.
   [Lin, Cong] Guangdong Univ Finance & Econ, Sch Stat & Math, Appl Lab Dig Data & Educ Stat, Guangzhou 510320, Peoples R China.
   [Ye, Long] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
C3 Sun Yat Sen University; Guangdong University of Finance & Economics;
   Communication University of China
RP Lu, W (corresponding author), Sun Yat Sen Univ, Guangdong Prov Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp, Sch Comp Sci & Engn,Minist Educ, Guangzhou 510006, Peoples R China.
EM shengzq@mail2.sysu.edu.cn; xuwb25@mail2.sysu.edu.cn;
   lincong0310@gmail.com; luwei3@mail.sysu.edu.cn; yelong@cuc.edu.cn
FU National Natural Science Foundation of China [62072480, U2001202];
   Characteristic Innovation Project of Regular Institutions of Higher
   Learning of Guangdong Province (Natural Science) [2022KTSCX041]; Science
   and Technology Program of Guangzhou Haizhu District [hkgsxj 2022-45];
   Open Research Project of the State Key Laboratory of Media Convergence
   and Communication, Communication University of China, China
   [SKLMCC2022KF003]
FX This work was jointly supported by the National Natural Science
   Foundation of China (Grant No. 62072480, U2001202) ; the Characteristic
   Innovation Project of Regular Institutions of Higher Learning of
   Guangdong Province (Natural Science) (2022KTSCX041) ; Science and
   Technology Program of Guangzhou Haizhu District (hkgsxj 2022-45) ; the
   Open Research Project of the State Key Laboratory of Media Convergence
   and Communication, Communication University of China, China (No.
   SKLMCC2022KF003) .
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   Arias P, 2011, INT J COMPUT VISION, V93, P319, DOI 10.1007/s11263-010-0418-7
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Castleman K. R., 1996, Digital Image Processing
   Chen YT, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103776
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Gou Yuanbiao, 2020, P ADV NEUR INF PROC, V33, P17129, DOI DOI 10.5555/3495724.3497161
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Jaiswal G, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103690
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kingma D. P., 2014, arXiv
   Lahiri A, 2021, IEEE T CIRC SYST VID, V31, P1395, DOI 10.1109/TCSVT.2020.3007723
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Li HY, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103777
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Ma MY, 2010, IEEE T CIRC SYST VID, V20, P382, DOI 10.1109/TCSVT.2009.2035839
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Mazumdar A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103417
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Rares A, 2005, IEEE T IMAGE PROCESS, V14, P1454, DOI 10.1109/TIP.2005.854466
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun J, 2005, ACM T GRAPHIC, V24, P861, DOI 10.1145/1073204.1073274
   Tegolo D, 2001, IEEE IMAGE PROC, P265, DOI 10.1109/ICIP.2001.959004
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Wang N, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3748
   Wang WT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14539, DOI 10.1109/ICCV48922.2021.01429
   Wu HW, 2022, IEEE T MULTIMEDIA, V24, P4016, DOI 10.1109/TMM.2021.3111491
   Wu JY, 2006, INT C PATT RECOG, P810
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu B, 2015, Arxiv, DOI [arXiv:1505.00853, DOI 10.48550/ARXIV.1505.00853]
   Xu D, 2017, ADV NEUR IN, V30
   Xu SX, 2021, IEEE T CIRC SYST VID, V31, P1308, DOI 10.1109/TCSVT.2020.3001267
   Xu W, 2022, IEEE T CIRC SYST VID, V32, P5736, DOI 10.1109/TCSVT.2022.3153685
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yang CY, 2022, SIGNAL PROCESS, V191, DOI 10.1016/j.sigpro.2021.108363
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang JF, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1870, DOI 10.1145/3343031.3350912
   Zhang W., 2021, INT JOINT C ART INT, P1323
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 51
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104014
DI 10.1016/j.jvcir.2023.104014
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DT1Y8
UT WOS:001134245700001
DA 2024-07-18
ER

PT J
AU Tang, GY
   Yu, F
   Li, HY
   Shi, YK
   Liu, L
   Peng, T
   Hu, XR
   Jiang, MH
AF Tang, Guangyu
   Yu, Feng
   Li, Huiyin
   Shi, Yankang
   Liu, Li
   Peng, Tao
   Hu, Xinrong
   Jiang, Minghua
TI ClothSeg: semantic segmentation network with feature projection for
   clothing parsing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Clothing semantic segmentation; Transformer; Feature projection fusion;
   Pixel distance loss
AB Semantic segmentation of clothing presents a formidable challenge owing to the non-rigid geometric deforma-tion properties inherent in garments. In this paper, we use the Transformer as the encoder to better learn global information for clothing semantic segmentation. In addition, we propose a Feature Projection Fusion (FPF) module to better utilize local information. This module facilitates the integration of deep feature maps with shallow local details, thereby enabling the network to capture both high-level abstractions and fine-grained details of features. We also design a pixel distance loss in training to emphasize the impact of edge features. This loss calculates the mean of the shortest distances between all predicted clothing edges and the true clothing edges during the training process. We perform extensive experiments and our method achieves 56.30% and 74.97% mIoU on the public dataset CFPD and our self-made dataset LIC, respectively, demonstrating a competitive performance when compared to the state-of-the-art.
C1 [Tang, Guangyu; Yu, Feng; Li, Huiyin; Shi, Yankang; Liu, Li; Peng, Tao; Hu, Xinrong; Jiang, Minghua] Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan 430200, Hubei, Peoples R China.
   [Yu, Feng; Peng, Tao; Hu, Xinrong; Jiang, Minghua] Engn Res Ctr Hubei Prov Clothing Informat, Wuhan 430200, Hubei, Peoples R China.
C3 Wuhan Textile University
RP Yu, F (corresponding author), Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan 430200, Hubei, Peoples R China.
EM yufeng@wtu.edu.cn
RI Yu, Feng/JTD-1798-2023; tang, guangyu/AAM-5360-2021
OI Yu, Feng/0000-0001-8252-5131; tang, guangyu/0000-0001-9617-3632; Liu,
   Li/0000-0001-7851-531X
FU National natural science foundation of China [62202346]; Hubei key
   research and development program [2021BAA042]; Wuhan applied basic
   frontier research project [2022013988065212]; Hubei science and
   technology project of safe production special fund [SJZX20220908]
FX This work was supported by the National natural science foundation of
   China (No.62202346) , Hubei key research and development program
   (No.2021BAA042) ,Wuhan applied basic frontier research project (No.
   2022013988065212) , Hubei science and technology project of safe
   production special fund (No. SJZX20220908) .
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Dai JF, 2016, ADV NEUR IN, V29
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Ge YY, 2019, PROC CVPR IEEE, P5332, DOI 10.1109/CVPR.2019.00548
   Hasan Basela., 2010, BMVC
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2013, IEEE SYS MAN CYBERN, P2103, DOI 10.1109/SMC.2013.360
   Huang Zhexin, 2022, RICAI '22: Proceedings of the 2022 4th International Conference on Robotics, Intelligent Control and Artificial Intelligence, P722, DOI 10.1145/3584376.3584504
   Ihsan AM, 2020, NEURAL PROCESS LETT, V51, P2245, DOI 10.1007/s11063-019-10173-y
   Ji W, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P764
   Jue Wang, 2021, 2021 IEEE 4th International Conference on Electronics and Communication Engineering (ICECE), P49, DOI 10.1109/ICECE54449.2021.9674326
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Liu LL, 2019, NEUROCOMPUTING, V341, P156, DOI 10.1016/j.neucom.2019.03.011
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tangseng P, 2017, Arxiv, DOI arXiv:1703.01386
   Tian H., 2023, P IEEE CVF C COMP VI, P3534
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Xiao TT, 2018, LECT NOTES COMPUT SC, V11209, P432, DOI 10.1007/978-3-030-01228-1_26
   Xie EZ, 2021, ADV NEUR IN, V34
   Xu SL, 2022, LECT NOTES COMPUT SC, V13697, P545, DOI 10.1007/978-3-031-19836-6_31
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11752, DOI 10.1109/ICCV48922.2021.01156
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu WH, 2022, PROC CVPR IEEE, P10809, DOI 10.1109/CVPR52688.2022.01055
   Yunshan Ma, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P82, DOI 10.1145/3372278.3390677
   Zhang D, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108594
   Zhang QL, 2021, ADV NEUR IN, V34
NR 40
TC 1
Z9 1
U1 5
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103980
DI 10.1016/j.jvcir.2023.103980
EA NOV 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8M6
UT WOS:001149243200001
DA 2024-07-18
ER

PT J
AU Yuan, Y
   He, HJ
   Yang, YL
   Mao, NX
   Chen, F
   Ali, M
AF Yuan, Yuan
   He, Hongjie
   Yang, Yaoling
   Mao, Ningxiong
   Chen, Fan
   Ali, Muqadar
TI JPEG image encryption with grouping coefficients based on entropy coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE JPEG image encryption; Permutation encryption; Classification
   permutation; Modulo encryption; Undivided RSV; Coefficients group
ID COMPRESSION
AB In the existing JPEG image encryption schemes, the block feature values that can be used to reduce key search space are either difficult to be changed or need to be changed through overflow processing which leads to low generality and high encryption runtime. To change block feature values without overflow processing, a novel JPEG image encryption scheme is proposed. For AC encryption, the complete and end AC groups based on undivided RSV (run/size, value) (ACG-URSV) are permuted separately to change different features. Complete ACG-URSV containing different number of RSVs is used to change the non-zero coefficients count (NCC) and energy of AC coefficients (EAC). End ACG-URSV containing the zero coefficients after position of last non-zero AC coefficient (PLZ) is mainly used to change PLZ. Besides, the intra-block RSV permutation and block permutation are used to further destroy correlation. For DC encryption, the positive DC prediction error (PDC-PE) groups modulo encryption is proposed to avoid overflow processing. The experimental results show that this paper reduces encryption runtime by more than half, improves generality by at least 20%. When quality factor of 90, the average change rates of NCC, EAC and PLZ values are increased by 96.28%, 11.68% and 29.15%, respectively.
C1 [Yuan, Yuan; He, Hongjie; Yang, Yaoling; Mao, Ningxiong] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 611756, Peoples R China.
   [Chen, Fan; Ali, Muqadar] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
C3 Southwest Jiaotong University; Southwest Jiaotong University
RP Chen, F (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
EM fchen@swjtu.edu.cn
FU National Natural Science Foundation of China (NSFC) [U1936113, 61872303]
FX This work was supported in part by the National Natural Science
   Foundation of China (NSFC) under Grant U1936113 and 61872303.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Cheng H, 2016, J VIS COMMUN IMAGE R, V40, P111, DOI 10.1016/j.jvcir.2016.06.016
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Ferreira B, 2019, IEEE T CLOUD COMPUT, V7, P784, DOI 10.1109/TCC.2017.2669999
   He H, 2023, J Vis Commun Image Represent, V90, P1
   He JH, 2019, IEEE T CIRC SYST VID, V29, P3501, DOI 10.1109/TCSVT.2018.2882850
   He JH, 2018, IEEE T MULTIMEDIA, V20, P2645, DOI 10.1109/TMM.2018.2817065
   Hua ZY, 2023, IEEE T CIRC SYST VID, V33, P1003, DOI 10.1109/TCSVT.2022.3208030
   Independent jpeg group, 2019, About us
   Itier V, 2020, IEEE T CIRC SYST VID, V30, P646, DOI 10.1109/TCSVT.2019.2894520
   Kaur M, 2020, FUTURE GENER COMP SY, V107, P333, DOI 10.1016/j.future.2020.02.029
   Li PY, 2023, IEEE T INTELL TRANSP, V24, P7687, DOI 10.1109/TITS.2022.3217304
   Li PY, 2020, IET SIGNAL PROCESS, V14, P475, DOI 10.1049/iet-spr.2019.0276
   Li PY, 2019, J VIS COMMUN IMAGE R, V58, P12, DOI 10.1016/j.jvcir.2018.11.018
   Li PY, 2018, IEEE T MULTIMEDIA, V20, P1960, DOI 10.1109/TMM.2017.2786860
   Li PY, 2017, J VIS COMMUN IMAGE R, V44, P61, DOI 10.1016/j.jvcir.2017.01.021
   Li WH, 2007, INT J COMPUT MATH, V84, P1367, DOI 10.1080/00207160701294376
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Minemura K, 2012, IEEE IMAGE PROC, P261, DOI 10.1109/ICIP.2012.6466845
   Niu XA, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P308, DOI 10.1109/IIH-MSP.2008.207
   Ong S, 2013, IEEE IMAGE PROC, P4574, DOI 10.1109/ICIP.2013.6738942
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Peiya Li, 2021, Advances in Intelligent Information Hiding and Multimedia Signal Processing. Proceedings of the 16th International Conference on IIHMSP in Conjunction with the 13th International Conference on FITAT. Smart Innovation, Systems and Technologies (SIST 211), P140, DOI 10.1007/978-981-33-6420-2_18
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2023, IEEE T MULTIMEDIA, V25, P2528, DOI 10.1109/TMM.2022.3148591
   Qu LF, 2022, IEEE T MULTIMEDIA, V24, P2924, DOI 10.1109/TMM.2021.3090588
   Qu LF, 2022, IEEE T CIRC SYST VID, V32, P920, DOI 10.1109/TCSVT.2021.3069811
   Shimizu K, 2021, PICT COD SYMP, P166, DOI 10.1109/PCS50896.2021.9477508
   Shreyamsha Kumar BK, 2010, SIGNAL IMAGE VIDEO P, V4, P419, DOI 10.1007/s11760-009-0131-6
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Wang JC, 2023, FUTURE GENER COMP SY, V141, P116, DOI 10.1016/j.future.2022.10.034
   Wright M. A., 2001, Network Security, P11, DOI 10.1016/S1353-4858(01)01018-2
   Yu PP, 2023, IEEE T CLOUD COMPUT, V11, P2885, DOI 10.1109/TCC.2022.3233421
   Yuan Y, 2022, LECT NOTES COMPUT SC, V13180, P58, DOI 10.1007/978-3-030-95398-0_5
   [郑梦阳 Zheng Mengyang], 2018, [信息安全学报, Journal of Cyber Security], V3, P55
NR 40
TC 2
Z9 2
U1 10
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103975
DI 10.1016/j.jvcir.2023.103975
EA NOV 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z5UF7
UT WOS:001112715900001
DA 2024-07-18
ER

PT J
AU Hou, ZQ
   Zhao, JX
   Wang, Z
   Ma, SG
   Yu, WS
   Fan, JL
AF Hou, Zhiqiang
   Zhao, Jiaxin
   Wang, Zhuo
   Ma, Sugang
   Yu, Wangsheng
   Fan, Jiulun
TI Object drift determination network based on dual-template joint
   decision-making in long-term visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Long-term object visual tracking; Object drift determination network;
   Template update; Convolutional neural network; Computer vision; Deep
   learning
ID SEGMENTATION; FRAMEWORK
AB Object drift determination is a crucial issue in long-term tracking. Most existing object drift determination criteria require manually selecting different thresholds on different datasets to determine whether the object is lost. In this case, choosing the appropriate threshold is a complex problem. An object drift determination network based on dual-template joint decision-making is proposed to address this issue. The proposed object drift determination network not only does not require selection of thresholds on different datasets, and can be used as a plug-and-play module of short-term visual tracking algorithm to achieve long-term visual tracking tasks with good generalization ability. The proposed object drift determination network is applied to four short -term baseline trackers and constructs four long-term visual tracking algorithms. Experimental results verify that all four improved algorithms significantly improve long-term visual tracking performance compared to the original algorithms. In addition, the determined speed of the object drift determination network proposed in this paper reaches 111 FPS, which has little effect on the long-term visual tracking speed.
C1 [Hou, Zhiqiang; Zhao, Jiaxin; Wang, Zhuo; Ma, Sugang; Yu, Wangsheng] Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, Xian 710121, Peoples R China.
   [Hou, Zhiqiang; Zhao, Jiaxin; Wang, Zhuo; Ma, Sugang; Yu, Wangsheng] Key Lab Network Data Anal & Intelligent Proc Shaan, Xian 710121, Peoples R China.
   [Fan, Jiulun] Xian Univ Posts & Telecommun, Sch Commun & Informat Engn, Xian 710121, Peoples R China.
C3 Xi'an University of Posts & Telecommunications; Xi'an University of
   Posts & Telecommunications
RP Zhao, JX (corresponding author), Xian Univ Posts & Telecommun, Sch Comp Sci & Technol, Xian 710121, Peoples R China.
EM hzq@xupt.edu.cn; zjx160628xxx@163.com; wangzhuo971115@163.com;
   msg@xupt.edu.cn; xing_fu_yu@sina.com; jiulunf@xupt.edu.cn
FU National Natural Science Foundation of China [62072370]; Natural Science
   Foundation of Shaanxi Province, China [2023-JC-YB-598]
FX This work is supported by the National Natural Science Foundation of
   China under grant no. 62072370. Natural Science Foundation of Shaanxi
   Province, China Grant No. 2023-JC-YB-598.
CR Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen GC, 2020, IEEE T CIRC SYST VID, V30, P4810, DOI 10.1109/TCSVT.2019.2961999
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chien SY, 2013, IEEE T CIRC SYST VID, V23, P921, DOI 10.1109/TCSVT.2013.2242595
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Dai KN, 2019, PROC CVPR IEEE, P4665, DOI 10.1109/CVPR.2019.00480
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fan H, 2021, INT J COMPUT VISION, V129, P439, DOI 10.1007/s11263-020-01387-y
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fan H, 2019, IEEE T IMAGE PROCESS, V28, P4130, DOI 10.1109/TIP.2019.2904789
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fu ZH, 2021, PROC CVPR IEEE, P13769, DOI 10.1109/CVPR46437.2021.01356
   Gao Z, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119890
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Hachisuka T, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601138
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou ZQ, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.043052
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu WM, 2023, IEEE T PATTERN ANAL, V45, P3072, DOI 10.1109/TPAMI.2022.3172932
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang LH, 2020, AAAI CONF ARTIF INTE, V34, P11037
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M., 2020, COMPUTER VISION ECCV, P547
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lukezič A, 2018, Arxiv, DOI arXiv:1804.07056
   Lukezic A, 2019, LECT NOTES COMPUT SC, V11362, P595, DOI 10.1007/978-3-030-20890-5_38
   Mayer C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13424, DOI 10.1109/ICCV48922.2021.01319
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Tang F, 2020, IEEE T CIRC SYST VID, V30, P4739, DOI 10.1109/TCSVT.2019.2957748
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wang N, 2019, IEEE T CIRC SYST VID, V29, P730, DOI 10.1109/TCSVT.2018.2816570
   Wang WG, 2018, IEEE T CIRC SYST VID, V28, P1727, DOI 10.1109/TCSVT.2017.2701279
   Wang X, 2022, IEEE T NEUR NET LEAR, V33, P6931, DOI 10.1109/TNNLS.2021.3083933
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu X, 2023, IEEE T CIRC SYST VID, V33, P1291, DOI 10.1109/TCSVT.2022.3210245
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yu L, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104374
   Zhang YH, 2018, Arxiv, DOI arXiv:1809.04320
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhao HJ, 2023, IEEE T PATTERN ANAL, V45, P460, DOI 10.1109/TPAMI.2022.3153645
   Zhou ZK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9846, DOI 10.1109/ICCV48922.2021.00972
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 56
TC 0
Z9 0
U1 1
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103974
DI 10.1016/j.jvcir.2023.103974
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y5BG7
UT WOS:001105403900001
DA 2024-07-18
ER

PT J
AU Gou, AR
   Sun, HM
   Liu, C
   Zeng, XY
   Fan, YB
AF Gou, Aorui
   Sun, Heming
   Liu, Chao
   Zeng, Xiaoyang
   Fan, Yibo
TI A novel fast intra algorithm for VVC based on histogram of oriented
   gradient
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Versatile video coding; Histogram of oriented gradient; Fast mode
   decision; Fast partition decision; Intra prediction
ID CU SIZE DECISION; MODE DECISION; PARTITION DECISION; PREDICTION;
   SELECTION; COST
AB The latest Versatile Video Coding (VVC) standard incorporates a series of effective and complex new intra coding tools, which obtains superior coding efficiency than the High Efficiency Video Coding (HEVC). However, this makes the intra coding more complicated and time-consuming. A fast algorithm for VVC from two aspects of fast mode decision and fast partition decision is proposed in this paper. For the fast mode decision, the relationship between bins with Histogram of Oriented Gradient (HOG) and intra modes is created for the mode selection, decreasing the planar modes for SATD and RDO. Moreover, we analyze the maximum bins to determine the final modes, and we use the modes of left and upper blocks as a reference for the current CU, which can early terminate RDO. Moreover, a two-step fast partition algorithm is proposed based on HOG for fast partition decision, in which two thresholds are investigated to control the uniformity of textures. The proposed fast algorithm is implemented on the VVC test model, and the experimental results show that it can achieve 69.07% time savings with only 2.96% BDBR increases averagely, which outperforms other relatively existing state-of-the-art methods. Moreover, to convince the universality of our algorithm, we further implement our method in Fraunhofer Versatile Video Encoder (VVenc) and Fraunhofer Versatile Video Decoder (VVdec), which have five settings to control the trade-off between encoding quality and efficiency for intra coding. The fast intra mode decision algorithm and fast partition algorithm decrease the complexity of intra coding for both VTM and VVenc, which shows the efficiency and universality of the proposed fast partition and fast mode decision algorithms.
C1 [Gou, Aorui; Liu, Chao; Zeng, Xiaoyang; Fan, Yibo] Fudan Univ, Acad Engn & Technol, Shanghai 200437, Peoples R China.
   [Sun, Heming] Yokohama Natl Univ, Fac Engn, Yokohama, Kanagawa 2400067, Japan.
C3 Fudan University; Yokohama National University
RP Sun, HM (corresponding author), Yokohama Natl Univ, Fac Engn, Yokohama, Kanagawa 2400067, Japan.
EM sun-heming-vg@ynu.ac.jp
RI yang, kun/JGM-4169-2023; ZHENG, YI/KAM-6536-2024; Li,
   Jiawei/JOJ-9277-2023; li, mengyang/JWO-9551-2024; Zhang,
   Bo/JVD-9890-2024; wang, wang/JQW-3034-2023; Chen, Chao/JHS-6563-2023;
   LI, YUN/JTV-7108-2023; zhang, hao/JOJ-7093-2023; feng,
   feng/KBR-1814-2024; wang, xi/JNT-5162-2023; Liu, qi/JZT-5038-2024; Lin,
   Lin/JTU-1595-2023; Wang, Zejun/KBB-8454-2024; Li, Kun/JLL-6505-2023;
   Jing, Jing/JSK-6237-2023; Heming, Sun/G-6882-2018; yang,
   zhou/KBB-6972-2024; yang, le/KFB-5420-2024; zheng, yan/JKJ-3632-2023;
   Wang, Xintong/JJE-1189-2023; Chen, Xiao/KBD-1464-2024; Li,
   Fan/KBB-8931-2024; chen, gang/JRX-1197-2023; liu, feng/KCL-0778-2024;
   Li, Xinyue/JVN-4601-2024; Zhang, yuxuan/JXM-9935-2024; Liu,
   Zhe/KEJ-5299-2024; li, rui/JVM-8999-2024; LI, LI/KCJ-5600-2024; Yang,
   Mei/JNS-2225-2023; xiao, wei/KCK-6954-2024
OI Li, Kun/0000-0002-3638-2974; 
FU "Ling Yan" Program for Tackling Key Problems in Zhejiang Province
   [2022C010980]; National Natural Science Foundation of China [62031009];
   Alibaba Innovative Research (AIR) Program; Alibaba Research Fellow (ARF)
   Program; Fudan-ZTE Joint Lab; CCF-Alibaba Innovative Research Fund For
   Young Scholars; Japan Society for the Promotion of Science (JSPS)
   [21K17770]; Japan Society for the Promotion of Science (JSPS) [23K16861]
FX This work was supported in part by the the "Ling Yan" Program for
   Tackling Key Problems in Zhejiang Province (No.2022C010980), in part by
   National Natural Science Foundation of China under Grant 62031009, in
   part by Alibaba Innovative Research (AIR) Program, in part by in part by
   Alibaba Research Fellow (ARF) Program, in part by the Fudan-ZTE Joint
   Lab, in part by the in part by CCF-Alibaba Innovative Research Fund For
   Young Scholars, in part by the Japan Society for the Promotion of
   Science (JSPS) under Grant 21K17770, in part by the Japan Society for
   the Promotion of Science (JSPS) under Grant 23K16861.& nbsp;
CR Amestoy T, 2019, INT CONF ACOUST SPEE, P1837, DOI [10.1109/icassp.2019.8683413, 10.1109/ICASSP.2019.8683413]
   Bjontegaard G., 2001, Document VCEG-M33
   Bossen F., 2019, JVET 14 M MAR
   Bross B., 2018, JVETJ1001, P40
   Chen F, 2020, MULTIMED TOOLS APPL, V79, P27923, DOI 10.1007/s11042-020-09401-8
   Chen YM, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102849
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Choi K, 2022, IEEE T CONSUM ELECTR, V68, P119, DOI 10.1109/TCE.2022.3145397
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De-Luxán-Hernández S, 2019, IEEE IMAGE PROC, P1203, DOI [10.1109/ICIP.2019.8803777, 10.1109/icip.2019.8803777]
   Dong XC, 2022, IEEE T MULTIMEDIA, V24, P400, DOI 10.1109/TMM.2021.3052348
   Duanmu F, 2016, IEEE J EM SEL TOP C, V6, P517, DOI 10.1109/JETCAS.2016.2597698
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Galpin F, 2019, IEEE DATA COMPR CONF, P162, DOI 10.1109/DCC.2019.00024
   Gao LF, 2015, IEEE INT SYMP CIRC S, P517, DOI 10.1109/ISCAS.2015.7168684
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Heming Sun, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1085, DOI 10.1109/ICME.2012.4
   Hu N, 2015, IEEE T CIRC SYST VID, V25, P1521, DOI 10.1109/TCSVT.2015.2395772
   Jamali M, 2019, IEEE T BROADCAST, V65, P109, DOI 10.1109/TBC.2018.2847464
   Jamali M, 2015, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2015.21
   Jie Leng, 2011, 2011 International Conference on Multimedia and Signal Processing (CMSP), P56, DOI 10.1109/CMSP.2011.167
   Jin ZP, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Kuang W, 2020, IEEE T IMAGE PROCESS, V29, P170, DOI 10.1109/TIP.2019.2924810
   Laude T, 2016, PICT COD SYMP
   Lei JJ, 2017, IEEE T BROADCAST, V63, P48, DOI 10.1109/TBC.2016.2623241
   Li TY, 2021, IEEE T IMAGE PROCESS, V30, P5377, DOI 10.1109/TIP.2021.3083447
   Li Y, 2021, IEEE T BROADCAST, V67, P710, DOI 10.1109/TBC.2021.3073556
   Li Y, 2017, IEEE T MULTIMEDIA, V19, P1431, DOI 10.1109/TMM.2017.2669863
   Liu XG, 2019, IEEE T CIRC SYST VID, V29, P144, DOI 10.1109/TCSVT.2017.2777903
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Liu ZY, 2016, IEEE INT SYMP CIRC S, P2270, DOI 10.1109/ISCAS.2016.7539036
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Piao Y., 2018, JCTVCC207
   Ryu S, 2018, IEEE T IMAGE PROCESS, V27, P5525, DOI 10.1109/TIP.2018.2857404
   Saldanha M, 2022, IEEE T CIRC SYST VID, V32, P3947, DOI 10.1109/TCSVT.2021.3108671
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tang G., 2019, P IEEE VIS COMM IM P, P1
   Tang N, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P361, DOI [10.1109/apccas47518.2019.8953076, 10.1109/APCCAS47518.2019.8953076]
   Tariq J, 2018, J VIS COMMUN IMAGE R, V51, P1, DOI 10.1016/j.jvcir.2017.12.008
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Wang DY, 2022, IEEE T BROADCAST, V68, P83, DOI 10.1109/TBC.2021.3126277
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wang Z, 2018, IEEE IMAGE PROC, P2550, DOI 10.1109/ICIP.2018.8451258
   Wang Z, 2017, IEEE DATA COMPR CONF, P23, DOI 10.1109/DCC.2017.70
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wieckowski Adam, 2021, APPL DIGITAL IMAGE P, V11842, P118
   Wu GQ, 2021, IEEE INT SYMP CIRC S
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yuan H, 2010, OPT ENG, V49, DOI 10.1117/1.3377968
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang QW, 2021, IEEE ACCESS, V9, P70382, DOI 10.1109/ACCESS.2021.3079350
   Zhang QW, 2021, MULTIMEDIA SYST, V27, P1, DOI 10.1007/s00530-020-00688-z
   Zhang QW, 2020, IEEE ACCESS, V8, P117539, DOI 10.1109/ACCESS.2020.3004580
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2012, IEEE T BROADCAST, V58, P10, DOI 10.1109/TBC.2011.2174282
   Zhao L., 2018, JVETJ0065, V3
   Zuo X., 2018, JVETJ0065, V3
NR 64
TC 0
Z9 0
U1 3
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103888
DI 10.1016/j.jvcir.2023.103888
EA JUL 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA O9LY8
UT WOS:001046973900001
OA hybrid
DA 2024-07-18
ER

PT J
AU Gilo, O
   Mathew, J
   Mondal, S
   Sanodiya, RK
AF Gilo, Obsa
   Mathew, Jimson
   Mondal, Samrat
   Sanodiya, Rakesh Kumar
TI Unsupervised sub-domain adaptation using optimal transport
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Domain adaptation; Subdomain adaptation; Sliced wasserstein metric;
   Optimal transport
ID DOMAIN ADAPTATION; CORRELATION ALIGNMENT; KERNEL
AB We focus on domain adaptation, a branch of transfer learning that concentrates on transferring knowledge from one domain to another when the data distributions differ. Specifically, we investigate unsupervised domain adaptation methods, which have abundant labeled examples from a source domain and unlabeled examples from a target domain available. We aim to minimize the distribution divergences between the domains using optimal transport with subdomain adaptation. Previous methods have mainly focused on reducing global distribution discrepancies between the domains, but these approaches cannot capture fine-grained information and do not consider the structure or geometry of the data. To handle these limitations, we propose Optimal Transport via Subdomain Adaptation (OTSA). Our method utilizes the sliced Wasserstein metric to reduce transportation costs while preserving geometrical data information and the Local Maximum Discrepancy (LMMD) to compute the local discrepancy in each domain category, which helps capture relevant features. Experiments were conducted on six standard domain adaptation datasets, and our method outperformed the majority of baselines. Our approach increased the average accuracy when compared with baselines on the OfficeHome (67.7% to 68.31%), Office-Caltech10 (91.8% to 96.33%), IMAGECLEF-DA (87.9% to 89.9%), VisDA-2017 (79.6% to 81.83%), Office31 (88.17% to 89.11%), and PACS (69.08% to 83.72%) datasets, respectively.
C1 [Gilo, Obsa; Mathew, Jimson; Mondal, Samrat] Indian Inst Technol Patna, Comp Sci & Engn, Bihar 801106, India.
   [Sanodiya, Rakesh Kumar] Indian Inst Informat Technol, Comp Sci & Engn, Chittoor 801106, India.
C3 Indian Institute of Technology (IIT) - Patna
RP Gilo, O (corresponding author), Indian Inst Technol Patna, Comp Sci & Engn, Bihar 801106, India.
EM obsa_1921cs33@iitp.ac.in
OI Gilo Wakuma, Obsa/0000-0002-9562-8129
CR Aritake T, 2022, NEURAL COMPUT, V34, P2432, DOI 10.1162/neco_a_01549
   Ben-David S., 2006, NEURIPS, V19
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bonneel N, 2015, J MATH IMAGING VIS, V51, P22, DOI 10.1007/s10851-014-0506-3
   Bonnotte N., 2013, Ph.D. thesis
   Bousquet O, 2004, LECT NOTES ARTIF INT, V3176, P169
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen C, 2019, AAAI CONF ARTIF INTE, P3296
   Chen XY, 2019, PR MACH LEARN RES, V97
   Choi J., 2019, BRIT MACHINE VISION
   Courty N, 2017, ADV NEUR IN, V30
   Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921
   Cuturi M., 2013, ADV NEURAL INFORM PR, P2292, DOI DOI 10.48550/ARXIV.1306.0895
   Cuturi M, 2014, PR MACH LEARN RES, V32, P685
   Damodaran BB, 2018, LECT NOTES COMPUT SC, V11208, P467, DOI 10.1007/978-3-030-01225-0_28
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2021, IEEE T CIRC SYST VID, V31, P29, DOI 10.1109/TCSVT.2020.2968484
   Durrett R., 1992, SIAM Rev., V34, P147
   El Hamri M, 2022, MACH LEARN, V111, P4159, DOI 10.1007/s10994-022-06231-7
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Han J, 2011, 22 INT JOINT C ART I
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helgason S, 2011, INTEGRAL GEOMETRY AND RADON TRANSFORMS, P1, DOI 10.1007/978-1-4419-6055-9
   Hoffman J, 2014, INT J COMPUT VISION, V109, P28, DOI 10.1007/s11263-014-0719-3
   Huang J., 2006, Adv. Neural Inf. Process. Syst., V19
   KANDPAL M, 2015, P ANN IEEE IND C IND, P1
   KANTOROVITCH L, 1958, MANAGE SCI, V5, P1, DOI 10.1287/mnsc.5.1.1
   Kouw WM, 2016, J MACH LEARN RES, V17
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A., 2018, ADV NEURAL INF PROCE, V31
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Liu GQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103310
   Long M., 2017, PMLR, P2208
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MS, 2014, PROC CVPR IEEE, P1410, DOI 10.1109/CVPR.2014.183
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Luo YW, 2021, PROC CVPR IEEE, P13984, DOI 10.1109/CVPR46437.2021.01377
   Luo You-Wei, 2020, IEEE Trans. Pattern Anal. Mach. Intell.
   Kouw WM, 2019, Arxiv, DOI arXiv:1901.05335
   Mengxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13933, DOI 10.1109/CVPR42600.2020.01395
   Nguyen A.T., 2021, IEEE T MOBILE COMPUT
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Paszke A, 2019, ADV NEUR IN, V32
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Peng XC, 2018, IEEE COMPUT SOC CONF, P2102, DOI 10.1109/CVPRW.2018.00271
   Rabin J, 2012, LECT NOTES COMPUT SC, V6667, P435, DOI 10.1007/978-3-642-24785-9_37
   Redko I, 2017, LECT NOTES ARTIF INT, V10535, P737, DOI 10.1007/978-3-319-71246-8_45
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Shen J, 2018, AAAI CONF ARTIF INTE, P4058
   Solomon J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766963
   Sun BC, 2017, ADV COMPUT VIS PATT, P153, DOI 10.1007/978-3-319-58347-1_8
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tao JW, 2015, J VIS COMMUN IMAGE R, V33, P134, DOI 10.1016/j.jvcir.2015.09.005
   Truong TD, 2022, INT C PATT RECOG, P2850, DOI 10.1109/ICPR56361.2022.9956335
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Villani C, 2009, GRUNDLEHR MATH WISS, V338, P1, DOI 10.1007/978-3-540-71050-9
   Wang BQ, 2022, IEEE SENS J, V22, P8891, DOI 10.1109/JSEN.2022.3163425
   Wang Q, 2020, AAAI CONF ARTIF INTE, V34, P6243
   Wang W, 2023, IEEE T NEUR NET LEAR, V34, P264, DOI 10.1109/TNNLS.2021.3093468
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Wang ZJ, 2022, IEEE T IND ELECTRON, V69, P8430, DOI 10.1109/TIE.2021.3108726
   Webber J.W., 2018, RADON TRANSFORMS MIC
   Wei PF, 2022, IEEE T CYBERNETICS, V52, P11698, DOI 10.1109/TCYB.2021.3071244
   Wu JQ, 2019, PROC CVPR IEEE, P3708, DOI 10.1109/CVPR.2019.00383
   Wu X., 2021, IEEE T NEUR NET LEAR
   Xie S., 2018, P 35 INT C MACHINE L, P5423
   Yosinski J, 2014, ADV NEUR IN, V27
   Zhang W.-D, 2020, 2020 45th International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz46771.2020.9370821
   Zhang WC, 2018, PROC CVPR IEEE, P3801, DOI 10.1109/CVPR.2018.00400
   Zhang X, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102863
   Zhang Y, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103974
   Zhang Z, 2020, IEEE T PATTERN ANAL, V42, P1741, DOI 10.1109/TPAMI.2019.2903050
   Zhao D, 2022, INFORM SCIENCES, V611, P301, DOI 10.1016/j.ins.2022.07.113
   Zhu YC, 2021, IEEE T NEUR NET LEAR, V32, P1713, DOI 10.1109/TNNLS.2020.2988928
NR 89
TC 4
Z9 4
U1 6
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103857
DI 10.1016/j.jvcir.2023.103857
EA MAY 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA K2NO4
UT WOS:001014860400001
DA 2024-07-18
ER

PT J
AU Ye, Q
   Wang, XK
   Li, R
   Zhang, YM
AF Ye, Qing
   Wang, Xikun
   Li, Rui
   Zhang, Yongmei
TI Human object interaction detection based on feature optimization and key
   human-object enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human object interaction detection; FOFR-CNN; Key human-object
   enhancement; Graph convolutional network
AB Aiming at the problem of unclear or missing human object interaction behavior objects in complex background, we propose a human object interaction detection algorithm based on feature optimization and key human-object enhancement. In order to solve the problem of missing human behavior objects, we propose Feature Optimized Faster Region Convolutional Neural Network (FOFR-CNN). FOFR-CNN is an object detection network optimized by multi-scale feature optimization algorithm, taking into account both image semantics and image structure. In order to reduce the interference of complex background, we propose a Key Human-Object Enhancement Network. The network uses an instance-based method to enhance the features of interactive objects. In order to enrich the interaction information, we use the graph convolutional network. Experimental results on HICO-DET, V-COCO and HOI-A datasets show that the proposed algorithm has significantly improved accuracy and multi-scale object detection ability compared with other human object interaction algorithms.
C1 [Ye, Qing; Wang, Xikun; Li, Rui; Zhang, Yongmei] North China Univ Technol, Sch Informat Sci & Technol, Beijing 100144, Peoples R China.
C3 North China University of Technology
RP Ye, Q (corresponding author), North China Univ Technol, Sch Informat Sci & Technol, Beijing 100144, Peoples R China.
EM yeqing@ncut.edu.cn; zhangym@ncut.edu.cn
RI YE, QING/KIG-8170-2024
FU Key Research and Development Program [2020YFC0811004]; Technology
   Project of Beijing Municipal Education Commission [SQKM201810009002];
   National Natural Science Foundation of China [4192022]; Beijing Natural
   Science Foundation [2018A03029]; Ministry of Education Science and
   Technology Development Center Project [61371143]; Beijing Innovation
   Team, Key scientific research direction construction project of North
   China University of Technology;  [61806008]
FX This paper is supported by Key Research and Development Program
   (No.2020YFC0811004) , Technology Project of Beijing Municipal Edu-cation
   Commission (No. SQKM201810009002) , National Natural Sci-ence Foundation
   of China (No.61371143) , National Natural Science Foundation of China
   (No.61806008) , Beijing Natural Science Founda-tion (No.4192022) ,
   Ministry of Education Science and Technology Development Center Project
   (No. 2018A03029) , Beijing Innovation Team, Key scientific research
   direction construction project of North China University of Technology.
   The authors also gratefully acknowl-edge the helpful comments and
   suggestions of the reviewers, which have improved the presentation.
CR Ahmed K, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   [Anonymous], 2019, PIC leaderboard
   [Anonymous], 2005, 2005 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2005.177
   [Anonymous], 2010, 2010 IEEE COMP SOC C
   Asad M, 2022, INT J PATTERN RECOGN, V36, DOI 10.1142/S0218001422550023
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chen Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P696, DOI 10.1007/978-3-030-58610-2_41
   Chen MF, 2021, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR46437.2021.00889
   Chen SQ, 2019, IEEE DATA COMPR CONF, P560, DOI 10.1109/DCC.2019.00072
   Chiou MJ, 2021, ICDAR '21: PROCEEDINGS OF THE 2021 WORKSHOP ON INTELLIGENT CROSS-DATA ANALYSIS AND RETRIEVAL, P9, DOI 10.1145/3463944.3469097
   Delaitre V., 2010, Proceedings of the British Machine Vision Conference, P1, DOI DOI 10.5244/C.24.97
   Fang HS, 2018, LECT NOTES COMPUT SC, V11214, P52, DOI 10.1007/978-3-030-01249-6_4
   Fu SC, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3412846
   Gao C., 2018, ARXIV
   Girshick R., 2017, rich feature hierarchies for accurate object detection and semantic segmentation tech report (v5)
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Guo S., 2021, IEEE T CYBERNETICS, P1, DOI DOI 10.1109/TCYB.2021.3049537
   Gupta A, 2007, PROC CVPR IEEE, P2564
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Gupta S., 2015, arXiv
   Hai Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P248, DOI 10.1007/978-3-030-58520-4_15
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Heidari N., 2021, 2021 INT JOINT C NEU, P1
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jingxiao Zheng, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P194, DOI 10.1109/TBIOM.2020.2973504
   KangH B. KimT. ChoiJ., KIMUNIONDET UNION LE
   Kogashi K, 2021, PROCEEDINGS OF 17TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA 2021), DOI 10.23919/MVA51890.2021.9511361
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li YL, 2022, IEEE T PATTERN ANAL, V44, P3870, DOI 10.1109/TPAMI.2021.3054048
   Liang Z., 2021, 2021 IEEE INT C ROBO
   Liang Z., 2020, ARXIV
   Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu HC, 2021, COMPUT VIS MEDIA, V7, P229, DOI 10.1007/s41095-020-0188-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moon G, 2019, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2019.00796
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong JC, 2019, IEEE IMAGE PROC, P929, DOI [10.1109/icip.2019.8803786, 10.1109/ICIP.2019.8803786]
   Ulutan Oytun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13614, DOI 10.1109/CVPR42600.2020.01363
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang T., 2020, 2020 IEEE CVF C COMP
   Wang Z., 2022, COMPUT APPL SOFTWARE, V39, P6
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235
   Zeng Q.X., 2022, J CHENGDU U INFORM T, V37, P6
   Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432
NR 54
TC 1
Z9 1
U1 4
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103824
DI 10.1016/j.jvcir.2023.103824
EA APR 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G6QW9
UT WOS:000990391400001
DA 2024-07-18
ER

PT J
AU Wang, H
   Chi, JN
   Wu, CD
   Yu, XS
   Wu, H
AF Wang, Huan
   Chi, Jianning
   Wu, Chengdong
   Yu, Xiaosheng
   Wu, Hao
TI Cross-view information interaction and feedback network for face
   hallucination
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Super-resolution; Face frontalization; Neural networks
AB Hallucinating a photo-realistic frontal face image from a low-resolution (LR) non-frontal face image is beneficial for a series of face-related applications. However, previous efforts either focus on super-resolving high -resolution (HR) face images from nearly frontal LR counterparts or frontalizing non-frontal HR faces. It is necessary to address all these challenges jointly for real-world face images in unconstrained environment. In this paper, we develop a novel Cross-view Information Interaction and Feedback Network (CVIFNet), which simultaneously handles the non-frontal LR face image super-resolution (SR) and frontalization in a unified framework and interacts them with each other to further improve their performance. Specifically, the CVIFNet is composed of two feedback sub-networks for frontal and profile face images. Considering the reliable correspondence between frontal and non-frontal face images can be crucial and contribute to face hallucination in a different manner, we design a cross-view information interaction module (CVIM) to aggregate HR representations of different views produced by the SR and frontalization processes to generate finer face hallucination results. Besides, since 3D rendered facial priors contain rich hierarchical features, such as low-level (e.g., sharp edge and illumination) and perception level (e.g., identity) information, we design an identity-preserving consistency loss based on 3D rendered facial priors, which can ensure that the high -frequency details of frontal face hallucination result are consistent with the profile. Extensive experiments demonstrate the effectiveness and advancement of CVIFNet.
C1 [Wang, Huan; Chi, Jianning; Wu, Chengdong; Yu, Xiaosheng] Northeastern Univ, 195 Chuangxin Rd, Shenyang, Peoples R China.
   [Wu, Hao] Univ Sydney, Sydney, NSW 2006, Australia.
C3 Northeastern University - China; University of Sydney
RP Wu, CD (corresponding author), Northeastern Univ, 195 Chuangxin Rd, Shenyang, Peoples R China.
EM wanghuan.95@foxmail.com; wuchengdong_neu@126.com
RI Wu, Chengdong/IST-5302-2023
FU National Natural Science Foundation of China [U20A20197, 61973063,
   61901098, 61971118]
FX Acknowledgments The authors would like to thank Xiaoqiang Li and Zhiyi
   Sun for helpful discussions and fruitful feedback along the way. This
   work was supported the National Natural Science Foundation of China
   under Grant nos. U20A20197, 61973063, 61901098, 61971118.
CR Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen L, 2021, IEEE T IMAGE PROCESS, V30, P5600, DOI 10.1109/TIP.2021.3086595
   Dai Q., 2021, arXiv, DOI [10.1145/3474085.3475356, DOI 10.1145/3474085.3475356]
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Di X., 2021, Heterogeneous face frontalization via domain agnostic learning, DOI 10.1109/fg52635.2021.9666962
   Duan QY, 2022, IEEE T CIRC SYST VID, V32, P3761, DOI 10.1109/TCSVT.2021.3111648
   Fu CY, 2022, IEEE T PATTERN ANAL, V44, P2938, DOI 10.1109/TPAMI.2021.3052549
   Gao GW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107539
   Hassner T, 2015, PROC CVPR IEEE, P4295, DOI 10.1109/CVPR.2015.7299058
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kang ZQ, 2021, IEEE INT CONF COMP V, P2485, DOI 10.1109/ICCVW54120.2021.00281
   Kingma D. P., 2014, arXiv
   Liu L., 2021, IEEE Transactions on Neural Networks and Learning Systems
   Liu L., 2020, IEEE Trans Cybern, P1
   Liu LC, 2018, IEEE T CYBERNETICS, V48, P1189, DOI 10.1109/TCYB.2017.2682853
   Liu YF, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103526
   Liu ZS, 2021, IEEE T IMAGE PROCESS, V30, P4157, DOI 10.1109/TIP.2021.3069554
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Ma C, 2020, PROC CVPR IEEE, P5568, DOI 10.1109/CVPR42600.2020.00561
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Qi L, 2021, KNOWL-BASED SYST, V220, P106938, DOI [10.1016/j.knosys.2021.106938, DOI 10.1016/J.KNOSYS.2021.106938]
   Qian YC, 2019, PROC CVPR IEEE, P9843, DOI 10.1109/CVPR.2019.01008
   Qiu HB, 2022, IEEE T PATTERN ANAL, V44, P6939, DOI 10.1109/TPAMI.2021.3098962
   Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Tu XG, 2022, IEEE T CIRC SYST VID, V32, P1285, DOI 10.1109/TCSVT.2021.3078517
   Wang H, 2021, KNOWL-BASED SYST, V222, DOI 10.1016/j.knosys.2021.106987
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yi D, 2014, Arxiv, DOI arXiv:1411.7923
   Yu X, 2018, LECT NOTES COMPUT SC, V11213, P219, DOI 10.1007/978-3-030-01240-3_14
   Yu X, 2020, IEEE T PATTERN ANAL, V42, P2148, DOI 10.1109/TPAMI.2019.2914039
   Yu X, 2017, AAAI CONF ARTIF INTE, P4327
   Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Yuxiang Wei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P558, DOI 10.1007/978-3-030-58610-2_33
   Zhang Y, 2021, IEEE T IMAGE PROCESS, V30, P1728, DOI 10.1109/TIP.2020.3046918
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhao J, 2019, Arxiv, DOI arXiv:1902.04755
   Zhong YY, 2021, IEEE T IMAGE PROCESS, V30, P2587, DOI 10.1109/TIP.2020.3048632
   Zhou X., 2021, 2021 IEEE INT C MULT, P1, DOI [10.1109/icme51207.2021.9428396, DOI 10.1109/ICME51207.2021.9428396]
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
   Zhu Z, 2021, PROC CVPR IEEE, P10487, DOI 10.1109/CVPR46437.2021.01035
NR 55
TC 0
Z9 0
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103758
DI 10.1016/j.jvcir.2023.103758
EA JAN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8G6BQ
UT WOS:000920428800001
DA 2024-07-18
ER

PT J
AU Guo, C
   Wang, Q
   Dai, HN
   Li, P
AF Guo, Cai
   Wang, Qian
   Dai, Hong-Ning
   Li, Ping
TI Multi-stage feature-fusion dense network for motion deblurring
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion deblurring; Multi-stage network; Feature-fusion dense
   connections; Channel-based multi-layer perceptrons
ID SPARSE REPRESENTATION; REGULARIZATION; DARK
AB Although convolutional neural networks (CNNs) have recently shown considerable progress in motion deblur-ring, most existing methods that adopt multi-scale input schemes are still challenging in accurately restoring the heavily-blurred regions in blurry images. Several recent methods aim to further improve the deblurring effect using larger and more complex models, but these methods inevitably result in huge computing costs. To address the performance-complexity trade-off, we propose a multi-stage feature-fusion dense network (MFFDNet) for motion deblurring. Each sub-network of our MFFDNet has the similar structure and the same scale of input. Meanwhile, we propose a feature-fusion dense connection structure to reuse the extracted features, thereby improving the deblurring effect. Moreover, instead of using the multi-scale loss function, we only calculate the loss function at the output of the last stage since the input scale of our sub-network is invariant. Experimental results show that MFFDNet maintains a relatively small computing cost while outperforming state-of-the-art motion-deblurring methods. The source code is publicly available at: https://github.com/CaiGuoHS/MFFDNet_ release.
C1 [Guo, Cai] Hanshan Normal Univ, Sch Comp & Informat Engn, Chaozhou, Guangdong, Peoples R China.
   [Guo, Cai; Wang, Qian] Macau Univ Sci & Technol, Sch Comp Sci & Engn, Cotai, Peoples R China.
   [Dai, Hong-Ning] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China.
   [Li, Ping] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
C3 Hanshan Normal University; Macau University of Science & Technology;
   Hong Kong Baptist University; Hong Kong Polytechnic University
RP Dai, HN (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China.
EM hndai@ieee.org
RI Li, Ping/AAO-2019-2020; Dai, Hong-Ning/B-1931-2012; Guo,
   Cai/HZI-6956-2023
OI Li, Ping/0000-0002-1503-0240; Dai, Hong-Ning/0000-0001-6165-4196; Guo,
   Cai/0000-0001-7524-2272
FU Science and Technology Planning Project of Guangdong Province of China
   [GD-KTP202004920, 2022A1515011551]; Natural Science Foundation of
   Guangdong Province of China [2018A0303070009, 2021A1515011091]; Project
   of Educational Commission of Guangdong Province of China [2018KTSCX143,
   2020ZDZX3056, 2021KTSCX07, 2021KQNCX051]; Special Basic Cooperative
   Research Programs of Yunnan Provincial Undergraduate Universities'
   Association [202101BA070001-045]; Hong Kong Polytechnic University
   [P0030419, P0042740, P0035358]
FX The work described in this paper was partially supported by Science and
   Technology Planning Project of Guangdong Province of China
   (GD-KTP202004920, 2022A1515011551) , Natural Science Foundation of
   Guangdong Province of China (2018A0303070009, 2021A1515011091) , Project
   of Educational Commission of Guangdong Province of China (2018KTSCX143,
   2020ZDZX3056, 2021KTSCX07, 2021KQNCX051) , Special Basic Cooperative
   Research Programs of Yunnan Provincial Undergraduate Universities'
   Association (No. 202101BA070001-045) and the Hong Kong Polytechnic
   University under Grant P0030419, Grant P0042740, and Grant P0035358.
CR [Anonymous], 2016, IEEE C COMP VIS PATT
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cai JR, 2020, IEEE T IMAGE PROCESS, V29, P6885, DOI 10.1109/TIP.2020.2995048
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dongwon Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P327, DOI 10.1007/978-3-030-58539-6_20
   Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo C, 2022, J SYST ARCHITECT, V129, DOI 10.1016/j.sysarc.2022.102584
   Guo C, 2022, COMPUT ANIMAT VIRT W, V33, DOI 10.1002/cav.2066
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaesung Rim, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P184, DOI 10.1007/978-3-030-58595-2_12
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li J., 2021, P IEEE CVF INT C COM, P4116
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li YW, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103149
   Lim S, 2020, IEEE SIGNAL PROC LET, V27, P835, DOI 10.1109/LSP.2020.2995106
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Liu Y., 2021, IEEE Trans. Multimed.
   Mao XJ, 2016, ADV NEUR IN, V29
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Pan JS, 2018, IEEE T PATTERN ANAL, V40, P2315, DOI 10.1109/TPAMI.2017.2753804
   Pan JS, 2019, IEEE T PATTERN ANAL, V41, P1412, DOI 10.1109/TPAMI.2018.2832125
   Pan JS, 2016, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2016.56
   Pan JS, 2013, SIGNAL PROCESS-IMAGE, V28, P1156, DOI 10.1016/j.image.2013.05.001
   Paszke A, 2019, ADV NEUR IN, V32
   Purohit K, 2020, AAAI CONF ARTIF INTE, V34, P11882
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shao WZ, 2015, J VIS COMMUN IMAGE R, V33, P42, DOI 10.1016/j.jvcir.2015.08.017
   Shen ZY, 2019, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2019.00567
   Sheng B, 2020, IEEE T CIRC SYST VID, V30, P955, DOI 10.1109/TCSVT.2019.2901629
   Shi XJ, 2015, ADV NEUR IN, V28
   Suin M, 2020, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR42600.2020.00366
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Wang M, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102648
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Yu X, 2014, IEEE T MULTIMEDIA, V16, P1510, DOI 10.1109/TMM.2014.2321734
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhao HT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102921
NR 48
TC 1
Z9 1
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103717
DI 10.1016/j.jvcir.2022.103717
EA DEC 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8UK
UT WOS:000906926200001
DA 2024-07-18
ER

PT J
AU Zhang, JW
   Miao, ME
   Zhang, HL
   Wang, JC
   Zhao, YC
   Chen, ZW
   Qiao, JW
AF Zhang, Jianwei
   Miao, Mengen
   Zhang, Huanlong
   Wang, Jingchao
   Zhao, Yanchun
   Chen, Zhiwu
   Qiao, Jianwei
TI Object semantic-guided graph attention feature fusion network for
   Siamese visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Siamese network; Semantic -guided; Graph attention
ID ROBUST
AB The similarity matching between the template and the search area plays a key role in Siamese-based trackers. Most Siamese-based trackers adopt correlation operation to perform feature fusion on the template branch and search branch for similarity matching. However, the correlation operation directly uses the template feature to slide the window on the search area feature without distinguishing the discriminant part of the target and the background noise, which blurs the spatial information of the response feature. To address this issue, this work proposes a novel object semantic-guided graph attention feature fusion network that both removes background information and focuses on the discriminative part of the object. The proposed network effectively removes background noise by utilizing an adaptive template instead of the fixed-size template used by the correlation operation. The network also models the contextual semantic relations of the target and uses the resulting se-mantic relations to guide the feature fusion process in a part-based manner, thereby accurately highlighting the discriminative parts of the target. Therefore, the problem of blurring response feature caused by correlation operation is effectively resolved. Furthermore, we propose an object-aware prediction network to learn object -aware features for classification and regression task, which effectively improves the discriminative ability of the prediction network. Experiments on many challenging benchmarks like OTB-100, LaSOT, TColor-128, GOT -10k and VOT2019, show that our methods achieves excellent performance.
C1 [Zhang, Jianwei; Miao, Mengen; Wang, Jingchao] Zhengzhou Univ Light Ind, Coll Software Engn, Zhengzhou 450001, Peoples R China.
   [Zhang, Huanlong; Chen, Zhiwu] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
   [Zhao, Yanchun] Univ Elect Sci & Technol China, Yangtze Delta Reg Inst Huzhou, Huzhou 313001, Peoples R China.
   [Qiao, Jianwei] Wolong Elect Nanyang Explos Proof Motor Grp, Nanyang 473000, Peoples R China.
C3 Zhengzhou University of Light Industry; Zhengzhou University of Light
   Industry; University of Electronic Science & Technology of China
RP Zhang, HL (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
EM zzuli407@163.com
RI Zhang, Jianwei/AAL-5062-2020
FU National Natural Science Foundation of China; Program for Science \ &
   Technology Innovation Talents in Universities of Henan Province;
   Zhongyuan Science and Technology Innovation Lead- ership Program;
   Natural Science Foundation of Henan Province;  [62072416];  [61873246]; 
   [62102373];  [21HASTIT028];  [214200510026];  [202300410495]
FX This work is supported by the National Natural Science Foundation of
   China (62072416, 61873246, 62102373) , Program for Science \ &
   Technology Innovation Talents in Universities of Henan Province
   (21HASTIT028) , Zhongyuan Science and Technology Innovation Lead- ership
   Program (214200510026) , Natural Science Foundation of Henan Province
   (202300410495) .
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bingyan Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P429, DOI 10.1007/978-3-030-58542-6_26
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M., 2019, P IEEE CVF C COMP VI, P4660
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2020, AAAI CONF ARTIF INTE, V34, P11037
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jing YC, 2022, Arxiv, DOI arXiv:2207.11681
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Jing Yongcheng, 2021, P IEEE CVF INT C COM, P5301
   Kristanl M, 2019, IEEE INT CONF COMP V, P2206, DOI 10.1109/ICCVW.2019.00276
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li ZY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103107
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liang ZY, 2020, IEEE T IMAGE PROCESS, V29, P3351, DOI 10.1109/TIP.2019.2959256
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Maksai A, 2016, Arxiv, DOI arXiv:1612.00604
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O., 2015, INT J COMPUT VISION, V115, P211
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tripp AiliMari., 2019, Oxford Research Encyclopedia of Politics, DOI DOI 10.1093/ACREFORE/9780190228637.013.713
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu K., 2018, arXiv, DOI DOI 10.48550/ARXIV.1810.00826
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang T., 2018, P ECCV, P152
   Yang YD, 2021, PROC CVPR IEEE, P8070, DOI 10.1109/CVPR46437.2021.00798
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Z, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103465
   Zhang HY, 2021, PROC CVPR IEEE, P8510, DOI 10.1109/CVPR46437.2021.00841
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang JW, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103451
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 57
TC 1
Z9 1
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103705
DI 10.1016/j.jvcir.2022.103705
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8AW
UT WOS:000906875200005
DA 2024-07-18
ER

PT J
AU Kim, H
   Hong, S
   Han, B
   Myeong, H
   Lee, KM
AF Kim, Heewon
   Hong, Seokil
   Han, Bohyung
   Myeong, Heesoo
   Lee, Kyoung Mu
TI Fine-grained neural architecture search for image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image super-resolution; Neural architecture search; Convolutional neural
   network
AB Designing efficient deep neural networks has achieved great interest in image super-resolution (SR). However, exploring diverse network structures is computationally expensive. More importantly, each layer in a network has a distinct role that leads to the design of a specialized structure. In this work, we present a novel neural architecture search (NAS) algorithm that efficiently explores layer-wise structures. Specifically, we construct a supernet allowing flexibility in choosing the number of channels and per-channel activation functions according to the role of each layer. The search process runs efficiently via channel pruning since gradient descent jointly optimizes the Mult-Adds and the accuracy of the searched models. We facilitate estimating the model Mult-Adds in a differentiable manner using relaxations in the backward pass. The searched model, named FGNAS, outperforms the state-of-the-art NAS-based SR methods by a large margin.
C1 [Kim, Heewon; Hong, Seokil; Han, Bohyung; Lee, Kyoung Mu] Seoul Natl Univ, Dept Elect & Comp Engn, ASRI, Seoul, South Korea.
   [Han, Bohyung; Lee, Kyoung Mu] Seoul Natl Univ, Interdisciplinary Program Artificial Intelligence, Seoul, South Korea.
   [Myeong, Heesoo] Qualcomm Korea YH, Seoul, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Lee, KM (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, ASRI, Seoul, South Korea.
EM kyoungmu@snu.ac.kr
OI Myeong, Heesoo/0000-0002-5889-6060
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, Arxiv, DOI arXiv:1803.08664
   [Anonymous], 2010, INT C CURVES SURFACE
   Baker B., 2017, ICLR
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai Han, 2019, INT C LEARN REPR
   Chu X., 2019, ARXIV190101074
   Chu XX, 2020, Arxiv, DOI arXiv:1901.07261
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Y, 2020, IEEE SIGNAL PROC LET, V27, P1255, DOI 10.1109/LSP.2020.3003517
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XY, 2019, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2019.00183
   Hong C., 2022, WACV
   Hong C., 2022, ECCV
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jing YC, 2021, PROC CVPR IEEE, P7768, DOI 10.1109/CVPR46437.2021.00768
   Jing YC, 2021, PROC CVPR IEEE, P15704, DOI 10.1109/CVPR46437.2021.01545
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kim Hanul, 2021, ICCV
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma DP., 2014, ADAM METHOD STOCHAST
   Kong XT, 2021, PROC CVPR IEEE, P12011, DOI 10.1109/CVPR46437.2021.01184
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu H, 2019, INT C LEARNING REPRE, DOI DOI 10.1109/CVPR42600.2020.00243
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu Ming, 2020, ECCVW
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mei J., 2020, INT C LEARN REPR, P1
   Muhammad T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249828
   Oh Junghun, 2022, CVPR
   Pham H, 2018, PR MACH LEARN RES, V80
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Song DH, 2020, AAAI CONF ARTIF INTE, V34, P12007
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tan M., 2019, ARXIV190709595
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang L, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103300
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yang YD, 2020, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR42600.2020.00710
   Yang Yiding, 2020, NEURIPS
   Yu J., 2018, BMVC
   Zhang HR, 2021, IEEE J-STSP, V15, P253, DOI 10.1109/JSTSP.2020.3045282
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zoph B., 2017, ICLR, P1, DOI DOI 10.1109/ICAIIC48513.2020.9065031
NR 63
TC 1
Z9 1
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103654
DI 10.1016/j.jvcir.2022.103654
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300009
DA 2024-07-18
ER

PT J
AU Luo, MK
   Yang, Z
   Ai, WW
   Liu, JH
AF Luo, Mingkai
   Yang, Zhao
   Ai, Weiwei
   Liu, Jiehao
TI Confidence based class weight and embedding discrepancy constraint
   network for partial domain adaptation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Partial domain adaptation; Deep transfer learning; Adversarial
   alignment; Classification learning
AB Partial domain adaptation (PDA) is a special domain adaptation task where the label space of the target domain is a subset of the source domain. In this work, we present a novel adversarial PDA method named Confidence Based Class Weight and Embedding Discrepancy Constraint Network (CEN). Specifically, we design a robust weighting scheme that takes sample confidence and class information into account. It can automatically distinguish outlier samples in the source domain and reduce their importance. Besides, we consider the rela-tionship between feature norm and domain shift. We limit the expectation of the feature norms of both domains to an adaptive value. By this means, we can align the feature distributions and help the deep model learn domain -invariant representations. Comprehensive experiments on three domain adaptation datasets Office-31, Office -home, and Visda2017 show that our approach surpasses state-of-the-art methods on various PDA tasks.
C1 [Yang, Zhao] Guangzhou Univ, Sch Elect & Commun Engn, Guangzhou, Peoples R China.
   Guangzhou Univ, Huangpu Res & Grad Sch, Guangzhou, Peoples R China.
C3 Guangzhou University; Guangzhou University
RP Yang, Z (corresponding author), Guangzhou Univ, Sch Elect & Commun Engn, Guangzhou, Peoples R China.
EM yangzhao@gzhu.edu.cn
FU Guangzhou University's training program for excellent new-recruited
   doctors [YB201712]
FX This research was supported by Guangzhou University's training program
   for excellent new-recruited doctors (No. YB201712) .
CR Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Bucci S, 2019, LECT NOTES COMPUT SC, V11752, P70, DOI 10.1007/978-3-030-30645-8_7
   Cao ZJ, 2018, LECT NOTES COMPUT SC, V11212, P139, DOI 10.1007/978-3-030-01237-3_9
   Cao ZJ, 2019, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR.2019.00310
   Cao ZJ, 2018, PROC CVPR IEEE, P2724, DOI 10.1109/CVPR.2018.00288
   Chen J, 2022, IEEE T NEUR NET LEAR, V33, P539, DOI 10.1109/TNNLS.2020.3028078
   Donahue J, 2014, PR MACH LEARN RES, V32
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghifary M., 2018, EUROPEAN C COMPUTER, P597
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grandvalet Y., 2005, CAP, V367, P281
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Hsu TMH, 2015, IEEE I CONF COMP VIS, P4121, DOI 10.1109/ICCV.2015.469
   Hu J., 2019, BRIT MACHINE VISION
   Jian Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P632, DOI 10.1007/978-3-030-58583-9_38
   Jiao JY, 2020, IEEE T IND INFORM, V16, P5965, DOI 10.1109/TII.2019.2956294
   Li Lusi, 2021, IEEE Trans Cybern, V51, P3404, DOI 10.1109/TCYB.2020.2983337
   Li S, 2021, IEEE T PATTERN ANAL, V43, P2329, DOI 10.1109/TPAMI.2020.2964173
   Liang J., 2020, INT C MACH LEARN, P6028
   Liang J, 2019, IEEE T PATTERN ANAL, V41, P1027, DOI 10.1109/TPAMI.2018.2832198
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Peng XC, 2017, Arxiv, DOI arXiv:1710.06924
   Pytorch, PYT ORG
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Steinwart I, 2006, IEEE T INFORM THEORY, V52, P4635, DOI 10.1109/TIT.2006.881713
   Taotao Jing, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P1606, DOI 10.1145/3394171.3413986
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Wang XM, 2019, AAAI CONF ARTIF INTE, P5345
   Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151
   Ying Jin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P464, DOI 10.1007/978-3-030-58589-1_28
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang L, 2020, Arxiv, DOI arXiv:1903.04687
   Zohrizadeh F., 2019, CVPR WORKSH
NR 41
TC 0
Z9 0
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103630
DI 10.1016/j.jvcir.2022.103630
EA SEP 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800010
DA 2024-07-18
ER

PT J
AU Ye, X
   Zhang, YS
   Zhao, RY
   Lan, RS
   Xiang, Y
AF Ye, Xi
   Zhang, Yushu
   Zhao, Ruoyu
   Lan, Rushi
   Xiang, Yong
TI PRA-TPE: Perfectly Recoverable Approximate Thumbnail-Preserving Image
   Encryption
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Difference expansion; Privacy protection; Perfect recoverability;
   Approximate thumbnail-preserving encryption
ID SEARCH
AB With the popularity of cloud servers, an increasing number of people are willing to store their images in the cloud due to many conveniences such as online browsing and managing images. On the other hand, this inevitably causes users' concerns about image privacy leakage. Many image encryption schemes are proposed to prevent privacy leakage, while most of them focus only on privacy protection and ignore the usability of encrypted images. For this purpose, Marohn et al. (2017) designed two approximate thumbnail-preserving encryption (TPE) schemes to balance image privacy and usability. However, the decrypted image in these two schemes are only perceptually close to the original one and the original image cannot be perfectly recovered. To this end, we design a perfectly recoverable approximate TPE scheme in this paper, which combines reversibledata hiding (RDH) with encryption schemes. The thumbnails of the original and processed images are similar to balance image privacy and usability well. Meanwhile, the reversibility of RDH and encryption schemes is utilized to ensure the perfect recoverability in the proposed scheme. Experiments show that the proposed approximate TPE scheme is no longer limited to balancing usability and privacy but attains perfect recovery.
C1 [Ye, Xi; Zhang, Yushu; Zhao, Ruoyu] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Zhang, Yushu] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Lan, Rushi] Guilin Univ Elect Technol, Guangxi Key Lab Image & Graph Intelligent Proc, Guilin 541004, Peoples R China.
   [Xiang, Yong] Deakin Univ, Sch Informat Technol, Burwood, Vic 3125, Australia.
C3 Nanjing University of Aeronautics & Astronautics; Guangxi Normal
   University; Guilin University of Electronic Technology; Deakin
   University
RP Zhang, YS (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM yushu@nuaa.edu.cn
RI ye, xi/KTH-8756-2024
OI Zhao, Ruoyu/0000-0003-3631-1890; Xiang, Yong/0000-0003-3545-7863
FU National Natural Science Foundation of China [62072237]; Research Fund
   of Guangxi Key Lab of Multisource Information Mining & Security, China
   [MIMS20-02]; Basic Research Program of Jiangsu Province, China
   [BK20201290]
FX The work was supported by National Natural Science Foundation of China
   (No. 62072237), Research Fund of Guangxi Key Lab of Multisource
   Information Mining & Security, China (No. MIMS20-02), and Basic Research
   Program of Jiangsu Province, China (No. BK20201290).
CR Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Cao XW, 2017, J VIS COMMUN IMAGE R, V44, P236, DOI 10.1016/j.jvcir.2016.08.003
   Chaudhary C, 2020, IEEE T MULTIMEDIA, V22, P897, DOI 10.1109/TMM.2019.2937181
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Ferreira B, 2015, SYM REL DIST SYST, P11, DOI 10.1109/SRDS.2015.27
   Ferreira B, 2015, LECT NOTES COMPUT SC, V8872, P311, DOI 10.1007/978-3-319-17016-9_20
   Fu ZJ, 2018, IEEE T INF FOREN SEC, V13, P2359, DOI 10.1109/TIFS.2018.2819121
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Greenberg A., 2014, WIRED
   Gregory RL, 1997, PHILOS T ROY SOC B, V352, P1121, DOI 10.1098/rstb.1997.0095
   Harada A, 2006, LECT NOTES COMPUT SC, V3853, P338
   Hayashi Eiji., 2008, Proceedings of the 4th symposium on Usable privacy and security, P35, DOI DOI 10.1145/1408664.1408670
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Jianping He, 2016, 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). Proceedings, P359, DOI 10.1109/DSN.2016.40
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Lou DC, 2011, DISPLAYS, V32, P118, DOI 10.1016/j.displa.2011.02.001
   Ma H, 2010, IEEE T MULTIMEDIA, V12, P462, DOI 10.1109/TMM.2010.2051360
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Marohn B, 2017, PROCEEDINGS OF THE 2017 WORKSHOP ON MULTIMEDIA PRIVACY AND SECURITY (MPS'17), P33, DOI 10.1145/3137616.3137621
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   OBrien K. J., 2012, New York Times, V21
   Qian XM, 2014, IEEE T CYBERNETICS, V44, P2493, DOI 10.1109/TCYB.2014.2309593
   Ra M.-R., 2013, P USENIX S NETW SYST, P515
   Robertson J., 2016, Bloomberg
   Tajik K, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23432
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   von Zezschwitz E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4320, DOI 10.1145/2858036.2858120
   Wang B, 2014, IEEE INFOCOM SER, P2112, DOI 10.1109/INFOCOM.2014.6848153
   Wang HP, 2020, IEEE ACCESS, V8, P55815, DOI 10.1109/ACCESS.2020.2981828
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang R, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102699
   Wright C.V., 2015, P 3 ACM WORKSH INF H, P141, DOI 10.1145/2756601.2756618
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang KY, 2011, IEEE T MULTIMEDIA, V13, P662, DOI 10.1109/TMM.2011.2147777
   Yu J, 2018, IEEE T INF FOREN SEC, V13, P1317, DOI 10.1109/TIFS.2017.2787986
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang YS, 2022, IEEE T CIRC SYST VID, V32, P947, DOI 10.1109/TCSVT.2021.3070348
   Zhao RY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108019
NR 43
TC 9
Z9 9
U1 5
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103589
DI 10.1016/j.jvcir.2022.103589
EA JUL 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3S1ZS
UT WOS:000839401800003
DA 2024-07-18
ER

PT J
AU Rahman, MF
   Zhuang, Y
   Tseng, TL
   Pokojovy, M
   McCaffrey, P
   Walser, E
   Moen, S
   Vo, A
AF Rahman, Md Fashiar
   Zhuang, Yan
   Tseng, Tzu-Liang (Bill)
   Pokojovy, Michael
   McCaffrey, Peter
   Walser, Eric
   Moen, Scott
   Vo, Alex
TI Improving lung region segmentation accuracy in chest X-ray images using
   a two-model deep learning ensemble approach*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lung segmentation; Chest X-ray; Deep learning; UNet; CNNs; Ensemble
ID COMPUTER-AIDED DIAGNOSIS; RADIOGRAPH
AB We propose a deep learning framework to improve segmentation accuracy of the lung region in Chest X-Ray (CXR) images. The proposed methodology implements a "divide and conquer" strategy where the original CXRs are subdivided into smaller image patches, segmented them individually, and then reassembled to achieve the complete segmentation. This approach ensembles two models, the first of which is a traditional Convolutional Neural Network (CNN) used to classify the image patches and subsequently merge them to obtain a presegmentation. The second model is a modified U-Net architecture to segment the patches and subsequently combines them to obtain another pre-segmented image. These two pre-segmented images are combined using a binary disjunction operation to get the initial segmentation, which is later post-processed to obtain the final segmentation. The post-processing steps consist of traditional image processing techniques such as erosion, dilation, connected component labeling, and region-filling algorithms. The robustness of the proposed methodology is demonstrated using two public (MC, JPCL) and one proprietary (The University of Texas Medical Branch - UTMB) datasets of CXR images. The proposed framework outperformed many state-of-the-arts competitions presented in the literature.
C1 [Rahman, Md Fashiar; Tseng, Tzu-Liang (Bill)] Univ Texas El Paso, Dept Ind Mfg & Syst Engn, El Paso, TX 79968 USA.
   [Zhuang, Yan] Univ Texas El Paso, Elect & Comp Engn, El Paso, TX 79968 USA.
   [Pokojovy, Michael] Univ Texas El Paso, Dept Math Sci, Dept Math Sci, El Paso, TX 79968 USA.
   [Pokojovy, Michael] Univ Texas El Paso, Dept Math Sci, Computat Sci Program, El Paso, TX 79968 USA.
   [McCaffrey, Peter; Walser, Eric; Moen, Scott; Vo, Alex] Univ Texas Med Branch Galveston, Galveston, TX 77550 USA.
C3 University of Texas System; University of Texas El Paso; University of
   Texas System; University of Texas El Paso; University of Texas System;
   University of Texas El Paso; University of Texas System; University of
   Texas El Paso; University of Texas System; University of Texas Medical
   Branch Galveston
RP Tseng, TL (corresponding author), Univ Texas El Paso, Dept Ind Mfg & Syst Engn, El Paso, TX 79968 USA.
EM btseng@utep.edu
RI Pokojovy, Michael/KIA-8822-2024; Howard, Michael P/F-1587-2019
OI Pokojovy, Michael/0000-0002-2122-2572; Howard, Michael
   P/0000-0002-9561-4165; Mccaffrey, Peter/0000-0002-4450-8143; Rahman, Md
   Fashiar/0000-0002-0437-2587; Tseng, Bill/0000-0002-3903-529X
FU National Science Foundation [ECR-PEER-1935454, ERC-ASPIRE-1941524]
FX This work was partially supported by the National Science Foundation
   (ECR-PEER-1935454) and (ERC-ASPIRE-1941524) . The authors wish to
   express sincere gratitude for their financial support. We also
   acknowledge to the medical doctors from the University of Texas at
   Medical Branch for their continuous support, information, and providing
   the proprietary dataset used in this research.
CR Ahmad WSHMW, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0014-8
   [Anonymous], 2018, Vietnam J. Sci. Technol. Eng, DOI DOI 10.31276/VJSTE.60(3).19
   Bertels J, 2019, LECT NOTES COMPUT SC, V11765, P92, DOI 10.1007/978-3-030-32245-8_11
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Chen C, 2018, LECT NOTES COMPUT SC, V11046, P143, DOI 10.1007/978-3-030-00919-9_17
   Chung H, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2837901
   Dallal AH, 2017, PROC SPIE, V10134, DOI 10.1117/12.2254136
   de Moor T, 2018, PROC SPIE, V10718, DOI 10.1117/12.2318326
   Gaal G., 2020, CEUR WORKSHOP PROC, DOI DOI 10.48550/ARXIV.2003.10304
   Gil J, 2002, IEEE T PATTERN ANAL, V24, P1606, DOI 10.1109/TPAMI.2002.1114852
   Gómez O, 2020, NEURAL COMPUT APPL, V32, P15949, DOI 10.1007/s00521-019-04532-y
   Hendee WR, 2010, RADIOLOGY, V257, P240, DOI 10.1148/radiol.10100063
   Katsuragawa S, 2007, COMPUT MED IMAG GRAP, V31, P212, DOI 10.1016/j.compmedimag.2007.02.003
   Kholiavchenko M, 2020, INT J COMPUT ASS RAD, V15, P425, DOI 10.1007/s11548-019-02115-9
   Kiran M, 2019, J AMB INTEL HUM COMP, V10, P4179, DOI 10.1007/s12652-019-01281-7
   Lee RS, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.177
   LODWICK GS, 1963, RADIOLOGY, V81, P185, DOI 10.1148/81.2.185
   MACKAY RS, 1984, MED IMAGES DISPLAYS
   Mahomed N, 2020, PEDIATR RADIOL, V50, P482, DOI 10.1007/s00247-019-04593-0
   Munawar F, 2020, IEEE ACCESS, V8, P153535, DOI 10.1109/ACCESS.2020.3017915
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Novikov AA, 2018, IEEE T MED IMAGING, V37, P1865, DOI 10.1109/TMI.2018.2806086
   Onofrey JA, 2019, I S BIOMED IMAGING, P348, DOI [10.1109/ISBI.2019.8759295, 10.1109/isbi.2019.8759295]
   Palmer W. J., DIAGN IMAGING
   Park JM, 2000, COMPUTERS AND THEIR APPLICATIONS, P373
   Quekel LGBA, 1999, CHEST, V115, P720, DOI 10.1378/chest.115.3.720
   Rahman M.F., 2018, INT MAN SCI ENG C, V51371
   Rahman M.F., P SPIE
   Rashid R, 2018, LECT NOTES COMPUT SC, V10882, P71, DOI 10.1007/978-3-319-93000-8_9
   Reamaroon N, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-00514-y
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Saad MN, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM COMPUTING AND ENGINEERING, P46, DOI 10.1109/ICCSCE.2014.7072687
   Saidy L, 2018, IEEE INT C ELECTR TA
   Santos Marcel Koenigkam, 2019, Radiol Bras, V52, P387, DOI 10.1590/0100-3984.2019.0049
   Shaziya H, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P643, DOI 10.1109/ICCSP.2018.8524484
   Souza JC, 2019, COMPUT METH PROG BIO, V177, P285, DOI 10.1016/j.cmpb.2019.06.005
   Torres-Mejía G, 2015, BMC CANCER, V15, DOI 10.1186/s12885-015-1399-2
   van Ginneken B, 2001, IEEE T MED IMAGING, V20, P1228, DOI 10.1109/42.974918
   Wen YX, 2022, MEASUREMENT, V187, DOI 10.1016/j.measurement.2021.110276
   Xu T, 2012, COMPUT MED IMAG GRAP, V36, P452, DOI 10.1016/j.compmedimag.2012.04.005
   Yan CC, 2018, ACM-BCB'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, P103, DOI 10.1145/3233547.3233573
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Zakirov A., 2015, Appl. Math. Sci, V9, P4361, DOI 10.12988/ams.2015.54348
NR 47
TC 9
Z9 10
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103521
DI 10.1016/j.jvcir.2022.103521
EA APR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1P5AF
UT WOS:000802020500002
OA Bronze
DA 2024-07-18
ER

PT J
AU Yang, Z
   Wen, CH
   Luo, LK
   Gan, HP
   Zhang, T
AF Yang, Zhen
   Wen, Chaohe
   Luo, Lingkun
   Gan, Hongping
   Zhang, Tao
TI ACSiam: Asymmetric convolution structures for visual tracking with
   Siamese network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Siamese network; Asymmetric convolution; FD; Occlusion
   target
ID ROBUST
AB Object trackers based on Siamese network usually transform the tracking task into a matching problem between the candidate samples and the target template. However, with the increasing depth and width of backbone networks, researches on Siamese trackers using backbone networks are not very advanced. Therefore, it is necessary for us to further investigate the characteristics of backbone network. As a fact, the ability of backbone network to extract features can directly determine the performance of object tracker. Given this, in this paper, we first propose an asymmetric convolutional network to improve the representational capability of backbone network. And then, the strip convolution is employed to enhance the operational capability of square kernel convolution in the backbone network. Besides, we also construct a novel module named Feature Dropblock (i.e., FD) to simulate the occlusion of hidden space, which goal is to improve the performance of backbone network in the target tracking under occlusion. To demonstrate the effectiveness of the proposed tracker, extensive ablation studies are conducted. Better results are obtained on the tracking benchmarks OTB100 and VOT2018, compared to other state-of-the-art trackers.
C1 [Yang, Zhen; Wen, Chaohe] Jiangxi Sci & Technol Normal Univ, Sch Commun & Elect, Nanchang, Jiangxi, Peoples R China.
   [Yang, Zhen] Guangdong Atv Acad Performing Arts, Dongguan, Peoples R China.
   [Luo, Lingkun] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
   [Gan, Hongping] Northwestern Polytech Univ, Sch Software, Xian, Peoples R China.
   [Zhang, Tao] Shanghai Jiao Tong Univ, Shanghai Key Lab Intelligent Sensing & Recognit, Shanghai, Peoples R China.
C3 Jiangxi Science & Technology Normal University; Shanghai Jiao Tong
   University; Northwestern Polytechnical University; Shanghai Jiao Tong
   University
RP Zhang, T (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Intelligent Sensing & Recognit, Shanghai, Peoples R China.
EM sjtu-zt@sjtu.edu.cn
OI Gan, Hongping/0000-0002-4853-5077
FU National Natural Science Foundation of China [61866016, 62006152,
   62101455]; Double First-Class Construction Foundation, China
   [WH22050303]; Jiangxi Provincial Natural Science Foundation, China
   [20212BAB202013]; Key project of Jiangxi Education Department, China
   [GJJ201107]; Key Laboratory of System Control and Information
   Processing, China; Ministry of Education, China [Scip202106]; Youth Top
   Talent Foundation of Jiangxi Science and Technology Normal University,
   China [2018QNBJRC002]; Basic Research Programs of Taicang, China
   [TC2020JC07]; Fundamental Research Funds for the Central Universities,
   China [D5000210693]; Natural Science Basic Research Program of Shaanxi
   Province, China [2021JQ126]
FX This work was supported by the National Natural Science Foundation of
   China (61866016, 62006152, 62101455), the Double First-Class
   Construction Foundation, China (WH22050303), the Jiangxi Provincial
   Natural Science Foundation, China (20212BAB202013), the Key project of
   Jiangxi Education Department, China (GJJ201107), the Key Laboratory of
   System Control and Information Processing, China, the Ministry of
   Education, China (Scip202106), the Youth Top Talent Foundation of
   Jiangxi Science and Technology Normal University, China (2018QNBJRC002),
   the Basic Research Programs of Taicang, China (TC2020JC07), the
   Fundamental Research Funds for the Central Universities, China
   (D5000210693), and the Natural Science Basic Research Program of Shaanxi
   Province, China (2021JQ126). We thank the reviewers and editors for
   their comments and suggestions.
CR [Anonymous], 2017, INT C LEARN REPR
   Baisa NL, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2020.102952
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P1327, DOI 10.1109/TIP.2016.2520358
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Denton E, 2014, ADV NEUR IN, V27
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Duan LY, 2019, IEEE MULTIMEDIA, V26, P8, DOI 10.1109/MMUL.2018.2873564
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Gal Y, 2016, ADV NEUR IN, V29
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Ghiasi G, 2018, ADV NEUR IN, V31
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Jiang ZQ, 2018, IEEE T IMAGE PROCESS, V27, P1361, DOI 10.1109/TIP.2017.2779856
   Jin J., 2014, INT C LEARN REPR 201
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li J, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103109
   Li Y., 2019, ARXIV PREPRINT ARXIV
   Li ZY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103107
   Lo S. Y., 2019, P ACM MULTIMEDIA ASI, P1, DOI DOI 10.1145/3338533.3366558
   Memisevic R, 2016, INT C LEARN REPR ICL
   Paszke A., 2016, ARXIV160602147
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Tek FB, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2020.103015
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
NR 63
TC 7
Z9 7
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103465
DI 10.1016/j.jvcir.2022.103465
EA FEB 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7YP
UT WOS:000779631900002
DA 2024-07-18
ER

PT J
AU Liu, YH
   Song, SA
   Yang, L
   Bian, GB
   Yu, HN
AF Liu, Yanhong
   Song, Shouan
   Yang, Lei
   Bian, Guibin
   Yu, Hongnian
TI A novel dynamic gesture understanding algorithm fusing convolutional
   neural networks with hand-crafted features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic gesture understanding; Transfer learning; Feature fusion;
   Dempster-Shafer evidence theory; Support vector machine
ID RECOGNITION; EXTRACTION; MATRIX; SHAPE
AB Dynamic gestures have attracted much attention in recent years due to their user-friendly interactive characteristics. However, accurate and efficient dynamic gesture understanding remains a challenge due to complex scenarios and motion information. Conventional handcrafted features are computationally cheap but can only extract low-level image features. This leads to performance degradation when dealing with complex scenes. In contrast, deep learning-based methods have a stronger feature expression ability and hence can capture more abstract and high-level image features. However, they critically rely on a large amount of training data. To address the above issues, a novel dynamic gesture understanding algorithm based on feature fusion is proposed for accurate dynamic gesture prediction. It leverages the advantages of handcrafted features and transfer learning. Aimed at small-scale dynamic gesture data, transfer learning is introduced for capturing effective feature expression. To precisely model the critical temporal information associated with dynamic gestures, a novel feature descriptor, namely, AlexNet(2), is proposed for effective feature expression of dynamic gestures from the spatial and temporal domain. On this basis, a decision-level feature fusion framework based on support vector machine (SVM) and Dempster-Shafer (DS) evidence theory is constructed to utilize handcrafted features and AlexNet(2) to realize high-precision dynamic gesture understanding. To verify the effectiveness and robustness of the proposed recognition algorithm, analysis and comparison experiments are performed on the public Cambridge gesture dataset and Northwestern University hand gesture dataset. The proposed gesture recognition algorithm achieves prediction accuracies of 99.50% and 96.97% on these two datasets. Experimental results show that the proposed recognition framework exhibits a better recognition performance in comparison with related prediction algorithms.
C1 [Liu, Yanhong; Song, Shouan; Yang, Lei; Bian, Guibin; Yu, Hongnian] Zhengzhou Univ, Sch Elect Engn, Zhengzhou 450001, Henan, Peoples R China.
   [Liu, Yanhong; Song, Shouan; Yang, Lei] Robot Percept & Control Engn Lab Henan Prov, Zhengzhou 450001, Peoples R China.
   [Bian, Guibin] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
   [Yu, Hongnian] Edinburgh Napier Univ, Built Environm, Edinburgh EH10 5DT, Midlothian, Scotland.
C3 Zhengzhou University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Edinburgh Napier University
RP Yang, L (corresponding author), Zhengzhou Univ, Sch Elect Engn, Zhengzhou 450001, Henan, Peoples R China.
EM leiyang2019@zzu.edu.cn
RI Yang, Lei/K-8424-2018; liu, yan/HCI-5542-2022; Yu,
   Hongnian/JUV-0863-2023; YANG, LEI/GQH-4271-2022; Yu,
   Hongnian/AFV-5287-2022
OI Yang, Lei/0000-0003-1212-9445; Yu, Hongnian/0000-0003-2894-2086; Liu,
   Yanhong/0000-0002-7349-5871
FU National Natural Science Foundation of China [62003309]; National Key
   Research & Development Project of China [2020YFB1313701]; Science &
   Technology Research Project in Henan Province of China [202102210098];
   Outstanding Foreign Scientist Support Project in Henan Province of China
   [GZS2019008]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62003309), the National Key Research & Development Project of
   China (2020YFB1313701), Science & Technology Research Project in Henan
   Province of China (No. 202102210098) and Outstanding Foreign Scientist
   Support Project in Henan Province of China (No. GZS2019008).
CR Antoshchuk Svitlana., 2018, Digitisation of Culture: Namibian and International Perspectives, P269
   Baraldi L, 2014, IEEE COMPUT SOC CONF, P702, DOI 10.1109/CVPRW.2014.107
   Chen XH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020239
   Chen XH, 2017, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2017.8296809
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Choudhury A, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P136, DOI 10.1109/SPIN.2014.6776936
   Chung HY, 2019, IEEE INT CONF INDUST, P853, DOI 10.1109/ICIT.2019.8755038
   Alejo DAC, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111114
   Duan HJ, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5991
   Duta IC, 2016, INT WORK CONTENT MUL
   Fang LP, 2019, NEURAL COMPUT APPL, V31, P8533, DOI 10.1007/s00521-018-3719-3
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   He Y, 2019, CLUSTER COMPUT, V22, P10935, DOI 10.1007/s10586-017-1237-1
   Jiang D, 2007, IEEE INT CONF MOB, P1001
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   John V, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P31
   Kane L, 2019, PATTERN RECOGN LETT, V120, P24, DOI 10.1016/j.patrec.2019.01.003
   Karabasi M, 2014, INT CONF ADV COMPUT, P195, DOI 10.1109/ACSAT.2013.46
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuang HL, 2016, IEEE INTELL SYST, V31, P57, DOI 10.1109/MIS.2016.17
   Lei HX, 2020, CHIN CONTR CONF, P6633, DOI [10.23919/ccc50068.2020.9189409, 10.23919/CCC50068.2020.9189409]
   Li J, 2019, ENG LET, V27, P490
   Lim KC, 2020, ICMLSC 2020: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND SOFT COMPUTING, P108, DOI 10.1145/3380688.3380711
   Liu L., 2013, IEEE INT CONF AUTOMA, P1
   Liu Y., 2020, ENG LET, V28
   Liu Y, 2012, PROCEDIA ENGINEER, V29, P1678, DOI 10.1016/j.proeng.2012.01.194
   Lu Z, 2019, MACH VISION APPL, V30, P1157, DOI 10.1007/s00138-019-01043-7
   Maqueda AI, 2015, COMPUT VIS IMAGE UND, V141, P126, DOI 10.1016/j.cviu.2015.07.009
   Nyaga C.N., 2018, 1 AFRICA WEEK C ISTA, P1
   Peng YQ, 2020, IET IMAGE PROCESS, V14, P2480, DOI 10.1049/iet-ipr.2019.1248
   Qiu-yu Z., 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition, V8, P105, DOI DOI 10.14257/IJSIP.2015.8.5.11
   Sanin A, 2013, IEEE WORK APP COMP, P103, DOI 10.1109/WACV.2013.6475006
   Sentz K., 2002, Tech. Rep. SAND2002-0835
   Sharma K, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103045
   Shen XH, 2012, IMAGE VISION COMPUT, V30, P227, DOI 10.1016/j.imavis.2011.11.003
   Shin JH, 2006, INT J COMPUT SCI NET, V6, P216
   Stergiopoulou E, 2014, ENG APPL ARTIF INTEL, V35, P54, DOI 10.1016/j.engappai.2014.06.006
   Sun Y, 2020, ALEX ENG J, V59, P1149, DOI 10.1016/j.aej.2020.01.015
   Suni S., 2020, International Journal of Computational Vision and Robotics, V10, P449, DOI DOI 10.1504/IJCVR.2020.109396
   Tang H, 2019, NEUROCOMPUTING, V331, P424, DOI 10.1016/j.neucom.2018.11.038
   Ting Sun, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5913, DOI 10.1109/ICRA.2017.7989696
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Wu YH, 2018, CHIN AUTOM CONGR, P2446, DOI 10.1109/CAC.2018.8623035
   Xing M, 2019, MULTIMED TOOLS APPL, V78, P10649, DOI 10.1007/s11042-018-6553-9
   Yang L, 2018, INT J ADV MANUF TECH, V94, P1209, DOI 10.1007/s00170-017-0991-9
   Yui Man Lui, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P97, DOI 10.1109/FG.2011.5771378
   Zhang E, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121511
   Zhao Z., 2008, Proc. British Machine Vision Conference, P1
   Zheng JQ, 2017, MULTIMED TOOLS APPL, V76, P20525, DOI 10.1007/s11042-016-3988-8
NR 50
TC 2
Z9 2
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103454
DI 10.1016/j.jvcir.2022.103454
EA FEB 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6OC
UT WOS:000819856800004
DA 2024-07-18
ER

PT J
AU Liu, Y
   Al-Shehari, H
   Zhang, HY
AF Liu, Yan
   Al-Shehari, Hassan
   Zhang, Hongying
TI Attention mechanism enhancement algorithm based on cycle consistent
   generative adversarial networks for single image dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Attention mechanism; Deep learning; Generative
   adversarial networks
AB This paper proposes AMEA-GAN, an attention mechanism enhancement algorithm. It is cycle consistency-based generative adversarial networks for single image dehazing, which follows the mechanism of the human retina and to a great extent guarantees the color authenticity of enhanced images. To address the color distortion and fog artifacts in real-world images caused by most image dehazing methods, we refer to the human visual neurons and use the attention mechanism of similar Horizontal cell and Amazon cell in the retina to improve the structure of the generator adversarial networks. By introducing our proposed attention mechanism, the effect of haze removal becomes more natural without leaving any artifacts, especially in the dense fog area. We also use an improved symmetrical structure of FUNIE-GAN to improve the visual color perception or the color authenticity of the enhanced image and to produce a better visual effect. Experimental results show that our proposed model generates satisfactory results, that is, the output image of AMEA-GAN bears a strong sense of reality. Compared with state-of-the-art methods, AMEA-GAN not only dehazes images taken in daytime scenes but also can enhance images taken in nighttime scenes and even optical remote sensing imagery.
C1 [Liu, Yan; Al-Shehari, Hassan] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Sichuan, Peoples R China.
   [Zhang, Hongying] Southwest Univ Sci & Technol, Robot Technol Used Special Environm Key Lab, Mianyang 621010, Sichuan, Peoples R China.
C3 Southwest Jiaotong University; Southwest University of Science &
   Technology - China
RP Liu, Y (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Sichuan, Peoples R China.
EM 56200552@qq.com; me@hassan.sh; zhywyd@163.com
RI Liu, Yan/HPD-4621-2023
OI Liu, Yan/0000-0002-5965-3976
FU State Administration of Science, Technology and Industry for National
   Defense [1276]; Department of science, Technology and Industry for
   National Defense [JCKY2019204B007]
FX Acknowledgments This research was supported by the State Administration
   of Science, Technology and Industry for National Defense 2019 No. 1276,
   No. 2 Department of science, Technology and Industry for National
   Defense (JCKY2019204B007) . The authors would like to thank the
   anonymous reviewers for their valuable comments, which help to improve
   the quality of this paper.
CR Ancuti C, 2020, IEEE T IMAGE PROCESS, V29, P6264, DOI 10.1109/TIP.2020.2988203
   Ancuti C, 2016, IEEE IMAGE PROC, P2256, DOI 10.1109/ICIP.2016.7532760
   [Anonymous], 2019, ARXIV190100600V1
   Arjovsky M., 2014, ARXIV EPRINTS
   Berman D, 2020, IEEE T PATTERN ANAL, V42, P720, DOI 10.1109/TPAMI.2018.2882478
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen ZH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2626, DOI 10.1109/ICASSP.2018.8462078
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu ZH, 2020, IEEE T IMAGE PROCESS, V29, P3239, DOI 10.1109/TIP.2019.2958144
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hong M, 2020, PROC CVPR IEEE, P3459, DOI 10.1109/CVPR42600.2020.00352
   Gulrajani I, 2017, ADV NEUR IN, V30
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8100844
   Kolb H, 2003, AM SCI, V91, P28, DOI 10.1511/2003.11.841
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Li YA, 2019, IEEE I CONF COMP VIS, P3275, DOI 10.1109/ICCV.2019.00337
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Mejjati YA, 2018, ADV NEUR IN, V31
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Pang YW, 2020, PROC CVPR IEEE, P5930, DOI 10.1109/CVPR42600.2020.00597
   Pei SC, 2012, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2012.6467020
   Qian W, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2020), P329, DOI [10.1109/ICCCS49078.2020.9118601, 10.1109/icccs49078.2020.9118601]
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Shen H., 2020, IEEE T GEOSCI ELECT, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1994, DOI 10.1145/3394171.3416270
   Tang H, 2019, IEEE IJCNN
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang WH, 2019, IEEE ACCESS, V7, P173485, DOI 10.1109/ACCESS.2019.2957057
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2014, IEEE IMAGE PROC, P4557, DOI 10.1109/ICIP.2014.7025924
   Zhang Jing., 2018, J L ATEX CLASS FILES, V14
   Zheng ZR, 2021, PROC CVPR IEEE, P16180, DOI 10.1109/CVPR46437.2021.01592
   Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 59
TC 10
Z9 10
U1 4
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103434
DI 10.1016/j.jvcir.2021.103434
EA JAN 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0QY
UT WOS:000783929200007
OA hybrid
DA 2024-07-18
ER

PT J
AU Kim, W
AF Kim, Wonjun
TI Low-light image enhancement by diffusion pyramid with residuals
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low-light image enhancement; Scene illumination; Diffusion pyramid with
   residuals
ID RETINEX
AB With the advancement of the camera-related technology in mobile devices, the vast amount of photos have been taken and shared in our daily life. However, many users still have unsatisfactory experiences with low-visible photos, which are frequently acquired under complicated real-world environments. In this paper, a novel yet simple method for low-light image enhancement has been proposed without any learning procedure. The key idea of the proposed method is to estimate properties of the scene illumination both in global and local manner by exploiting the diffusion pyramid with residuals. Specifically, the residual of each scale level in the diffusion pyramid is combined with the corresponding input. This restored result efficiently highlights local details across different scale spaces, thus it is helpful for preserving the boundary of illuminations. By conducting max-pooling with restored results from different levels of the diffusion pyramid, which are resized to the original resolution, the illumination component is accurately inferred from a given image. Compared to recent learning-based approaches, one important advantage of the proposed method is to effectively avoid the overfitting problem to the specific training dataset. Experimental results on various benchmark datasets demonstrate the efficiency and robustness of the proposed method for low-light image enhancement in real-world scenarios.
C1 [Kim, Wonjun] Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
C3 Konkuk University
RP Kim, W (corresponding author), Konkuk Univ, Dept Elect & Elect Engn, Seoul 05029, South Korea.
EM wonjkim@konkuk.ac.kr
RI Kim, Wonjun/JXN-3386-2024
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2020R1F1A1068080]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2020R1F1A1068080).
CR [Anonymous], 2018, P BRIT MACH VIS C
   [Anonymous], 2001, RET IM PROC
   Bychkovsky V, 2011, PROC CVPR IEEE, P97
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chen YS, 2018, PROC CVPR IEEE, P6306, DOI 10.1109/CVPR.2018.00660
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Gu K, 2018, IEEE T IMAGE PROCESS, V27, P394, DOI 10.1109/TIP.2017.2733164
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kim W, 2019, IEEE ACCESS, V7, P129150, DOI 10.1109/ACCESS.2019.2940452
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Koh Y.J., 2020, P EUR C COMP VIS, P1
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liang ZT, 2018, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2018.00500
   Liang ZT, 2016, IEEE T IMAGE PROCESS, V25, P673, DOI 10.1109/TIP.2015.2507405
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moran S., 2020, CVPR, p12 826
   Park J, 2018, PROC CVPR IEEE, P5928, DOI 10.1109/CVPR.2018.00621
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Rousson M, 2003, PROC CVPR IEEE, P699
   Sen P, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366222
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Ueda Y, 2019, IEEE IMAGE PROC, P939, DOI [10.1109/ICIP.2019.8803035, 10.1109/icip.2019.8803035]
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
NR 44
TC 5
Z9 5
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103364
DI 10.1016/j.jvcir.2021.103364
EA NOV 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XD4BM
UT WOS:000722656700001
DA 2024-07-18
ER

PT J
AU Wang, H
   Liu, WB
   Xing, WW
AF Wang, Hui
   Liu, Weibin
   Xing, Weiwei
TI Video object segmentation via random walks on two-frame graphs
   comprising superpixels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Random walks; Video object segmentation; Optical flow gradient;
   Spatiotemporal consistency
ID TRACKING; MOTION; EXTRACTION
AB We propose a novel video object segmentation method employing random walkers to travel on graphs constructed on two consecutive frames. First, we estimate the initial foreground and background distributions by minimising an energy function that incorporates the stationary distributions of the random walks. The random walkers frequently travel between similar nodes of the graph constructed on two adjacent frames, which enables the incorporation of the inter-frame information into the energy function effectively and elegantly. Then, we refine the initial results by simulating the movements of multiple random walkers. We process the sequence in a recursive manner, which naturally propagates the previous segmentation labels to the subsequent frames. Additionally, we develop a strategy for adjusting the superpixel number using region similarity and the average Frobenius norm of optical flow gradient. This strategy can improve performance significantly. Furthermore, we discuss the feature selection problem in the method to select a more effective feature representation. Extensive and comparable experiments on Segtrack and Segtrack v2 demonstrate that the proposed algorithm yields higher performance than several recent state-of-the-art approaches.
C1 [Wang, Hui; Liu, Weibin] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Xing, Weiwei] Beijing Jiaotong Univ, Sch Software Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Liu, WB (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM wbliu@bjtu.edu.cn
FU Beijing Natural Science Foundation, China [4212025]; National Natural
   Science Founda-tion of China [61876018, 61976017]
FX This research is partially supported by the Beijing Natural Science
   Foundation, China (No. 4212025) , National Natural Science Founda-tion
   of China (No. 61876018, No. 61976017) .
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ayvaci A, 2012, IEEE T PATTERN ANAL, V34, P1942, DOI 10.1109/TPAMI.2011.271
   Badrinarayanan V, 2013, IEEE T PATTERN ANAL, V35, P2751, DOI 10.1109/TPAMI.2013.54
   Bergen L., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P531, DOI 10.1007/BFb0054763
   Brostow G. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P8, DOI 10.1109/ICCV.1999.791190
   Budvytis I., 2012, P BRIT MACH VIS C BM, P1
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Cai ZW, 2014, IEEE T IMAGE PROCESS, V23, P5497, DOI 10.1109/TIP.2014.2364919
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Carreira J, 2012, INT J COMPUT VISION, V98, P243, DOI 10.1007/s11263-011-0507-2
   Chen L, 2015, IEEE T MULTIMEDIA, V17, P2225, DOI 10.1109/TMM.2015.2481711
   Chen YB, 2013, J VIS COMMUN IMAGE R, V24, P829, DOI 10.1016/j.jvcir.2013.05.010
   Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276
   Dong XP, 2017, IEEE T CIRC SYST VID, V27, P2518, DOI 10.1109/TCSVT.2016.2595321
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Faktor Alon, 2014, BMVC
   Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883
   Fulkerson B, 2009, IEEE I CONF COMP VIS, P670
   Galasso F, 2014, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2014.14
   Galasso Fabio., 2012, ACCV, P760
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Grant M., 2014, CVX MATLAB SOFTWARE
   Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Gulshan V, 2010, PROC CVPR IEEE, P3129, DOI 10.1109/CVPR.2010.5540073
   Hao CY, 2020, NEUROCOMPUTING, V401, P28, DOI 10.1016/j.neucom.2020.03.020
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hu WC, 2012, J VIS COMMUN IMAGE R, V23, P303, DOI 10.1016/j.jvcir.2011.10.008
   Jain SD, 2014, LECT NOTES COMPUT SC, V8692, P656, DOI 10.1007/978-3-319-10593-2_43
   Jang W.-D., 2016, P BRIT MACH VIS C BM, P1
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374
   Khoreva A, 2015, PROC CVPR IEEE, P951, DOI 10.1109/CVPR.2015.7298697
   Koh YJ, 2017, PROC CVPR IEEE, P7417, DOI 10.1109/CVPR.2017.784
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Liu C, 2019, IEEE T CYBERNETICS, V49, P3665, DOI 10.1109/TCYB.2018.2846361
   Liu LW, 2012, INT C PATT RECOG, P2222
   Liu Y, 2019, IEEE T CYBERNETICS, V49, P159, DOI 10.1109/TCYB.2017.2769097
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Märki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   Maier M., 2009, ADV NEURAL INFORM PR, V22, P1025
   Milan A, 2015, PROC CVPR IEEE, P5397, DOI 10.1109/CVPR.2015.7299178
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Palou G, 2013, PROC CVPR IEEE, P2099, DOI 10.1109/CVPR.2013.273
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Pun CM, 2016, J VIS COMMUN IMAGE R, V41, P391, DOI 10.1016/j.jvcir.2016.10.017
   Ramakanth SA, 2014, PROC CVPR IEEE, P376, DOI 10.1109/CVPR.2014.55
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T CIRC SYST VID, V24, P1088, DOI 10.1109/TCSVT.2014.2302545
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Taylor B, 2015, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2015.7299055
   Tsai D, 2012, INT J COMPUT VISION, V100, P190, DOI 10.1007/s11263-011-0512-5
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Varas D, 2014, PROC CVPR IEEE, P3470, DOI 10.1109/CVPR.2014.444
   Voigtlaender P., 2017, 2017 DAV CHALL VID O
   Voigtlaender P, 2019, PROC CVPR IEEE, P9473, DOI 10.1109/CVPR.2019.00971
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3508, DOI 10.1109/TPAMI.2021.3055780
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2019, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2019.00318
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P985, DOI 10.1109/TPAMI.2018.2819173
   Wang WG, 2017, IEEE T IMAGE PROCESS, V26, P5645, DOI 10.1109/TIP.2017.2745098
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wen LY, 2015, PROC CVPR IEEE, P2226, DOI 10.1109/CVPR.2015.7298835
   Xi Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9381, DOI 10.1109/CVPR42600.2020.00940
   Xu CL, 2012, LECT NOTES COMPUT SC, V7577, P626, DOI 10.1007/978-3-642-33783-3_45
   Yang YC, 2013, IEEE I CONF COMP VIS, P201, DOI 10.1109/ICCV.2013.32
   Yeo D, 2017, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2017.62
   Zach Christopher, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563089
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhou TF, 2020, IEEE T IMAGE PROCESS, V29, P8326, DOI 10.1109/TIP.2020.3013162
NR 90
TC 3
Z9 3
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103293
DI 10.1016/j.jvcir.2021.103293
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900012
DA 2024-07-18
ER

PT J
AU Amsaprabhaa, M
   Jane, YN
   Nehemiah, HK
AF Amsaprabhaa, M.
   Jane, Nancy Y.
   Nehemiah, Khanna H.
TI A survey on spatio-temporal framework for kinematic gait analysis in RGB
   videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human gait recognition; Spatio-temporal features; Gait databases; Gait
   recognition representation; Kinematic joint points; Gait prediction
ID PARKINSONS-DISEASE PATIENTS; REDUCTION TECHNIQUES; FEATURE-EXTRACTION;
   RECOGNITION; MODEL; PERFORMANCE; FEATURES; MANIFOLD; WALKING; ENERGY
AB Human gait recognition from videos is one of the promising research topics for analyzing human walking behavior. Spatio-temporal features and kinematics interesting points (three dimensional skeleton points) are the two key metrics in the gait examination. In general, input to gait recognition methods is categorized into 3 groups namely; two dimensional video-based, depth image-based and three dimensional (3D) skeleton-based methods. This work aims to present a survey on spatio-temporal and kinematic gait characteristics based on visual and 3D skeletal traits in RGB videos. A detailed insight on the various benchmarked gait databases, gait recognition representations based on model-based, model-free approaches and classifiers are presented in this review. Also, this paper investigates the performance metrics, application areas and covariate factors that influence the gait recognition process. Finally, the paper outlines the future perspective of gait recognition system based on kinematic joint points.
C1 [Amsaprabhaa, M.] Anna Univ, Madras Inst Technol, Dept Comp Technol, Chennai 600044, Tamil Nadu, India.
   [Jane, Nancy Y.] Anna Univ, Madras Inst Technol, Dept Comp Technol, Chennai 600044, Tamil Nadu, India.
   [Nehemiah, Khanna H.] Anna Univ, Ramanujan Comp Ctr, Chennai 600025, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Madras Institute of
   Technology; Anna University; Madras Institute of Technology; Anna
   University Chennai; Anna University; Anna University Chennai
RP Jane, YN (corresponding author), Anna Univ, Madras Inst Technol, Dept Comp Technol, Chennai 600044, Tamil Nadu, India.
EM amsaprabhaa@mitindia.edu; nancy@annauniv.edu; nehemiah@annauniv.edu
FU Anna Centenary Research Fellowship (ACRF) by Anna University, Chennai
FX The authors thank Anna Centenary Research Fellowship (ACRF) which is
   provided by Anna University, Chennai for the financial support of the
   research work.
CR Alarifi A, 2021, MEASUREMENT, V167, DOI 10.1016/j.measurement.2020.108258
   Alotaibi M, 2017, COMPUT VIS IMAGE UND, V164, P103, DOI 10.1016/j.cviu.2017.10.004
   [Anonymous], 2019, PATTERN RECOGN LETT, P1
   [Anonymous], 2015, IEEE T CYBERNETICS
   [Anonymous], 2014, IEEE T INF FORENSICS
   Aydemir E, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107701
   Bächlin M, 2010, IEEE T INF TECHNOL B, V14, P436, DOI 10.1109/TITB.2009.2036165
   Bales D, 2016, IEEE INTERNET THINGS, V3, P1259, DOI 10.1109/JIOT.2016.2582723
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   BenAbdelkader C, 2002, INT C PATT RECOG, P377, DOI 10.1109/ICPR.2002.1047474
   Borras Ricard, 2012, Image Analysis and Recognition, P98, DOI [10.1007/978-3-642-31298-4_12, DOI 10.1007/978-3-642-31298-4_12]
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Bouchrika I, 2014, I C SCI TECH AUTO CO, P519, DOI 10.1109/STA.2014.7086781
   Cano A, 2017, SOFT COMPUT, V21, P2069, DOI 10.1007/s00500-015-1907-y
   Carnevale A, 2020, 2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR INDUSTRY 4.0 & IOT (METROIND4.0&IOT), P106, DOI [10.1109/MetroInd4.0IoT48571.2020.9138267, 10.1109/metroind4.0iot48571.2020.9138267]
   Carter John N, 2014, ENCY COMPUTER VISION, P309
   Chang CD, 2012, J MED SYST, V36, P1769, DOI 10.1007/s10916-010-9636-3
   Chao Fan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14213, DOI 10.1109/CVPR42600.2020.01423
   Chellappa Rama, 2004, IEEE COMPUTER SOC C, P1, DOI [10.1109/cvpr.2004.1315104, DOI 10.1109/CVPR.2004.1315104]
   Chen Yuxin, 2020, Pattern Recognition, P143
   Cheng QO, 2009, PROCEEDINGS OF INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY (ISCSCT 2009), P124
   Choi S, 2019, IEEE T INF FOREN SEC, V14, P2577, DOI 10.1109/TIFS.2019.2901823
   Chu Kuo-Chung, 2019, IEEE Internet of Things Journal, P1
   Chuen BKY, 2015, ASIAPAC SIGN INFO PR, P800, DOI 10.1109/APSIPA.2015.7415382
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Deng MQ, 2020, J FRANKLIN I, V357, P2471, DOI 10.1016/j.jfranklin.2019.12.041
   Deng MQ, 2019, IEEE T CIRC SYST VID, V29, P3636, DOI 10.1109/TCSVT.2018.2883449
   Dinesh R, 2016, INT C COMP COMM AUT, P1368
   Ehatisham-ul-Haq M, 2020, 2020 INT C EM TRENDS, DOI [10.1109/icetst49965.2020.9080735, DOI 10.1109/ICETST49965.2020.9080735]
   Elboushaki Abdessamad, 2019, Expert Syst. Appl., P1
   Etemad Ali., IEEE T BIOMETRICS BE, V3, P124
   Flora JB, 2015, IEEE T HUM-MACH SYST, V45, P304, DOI 10.1109/THMS.2015.2398732
   GAGE JR, 1995, J BONE JOINT SURG AM, V77, P1607, DOI 10.2106/00004623-199510000-00017
   Gross J., 2001, Tech. Rep. CMU-RI-TR-01-18, V45, P1
   Gu JX, 2010, IEEE T SYST MAN CY B, V40, P1021, DOI 10.1109/TSMCB.2010.2043526
   Guffanti D, 2020, IEEE ACCESS, V8, P95734, DOI 10.1109/ACCESS.2020.2995474
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hema M., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1163, DOI 10.1109/ICOEI.2019.8862788
   Hofmann M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P390, DOI 10.1109/ICB.2012.6199782
   Hosni N, 2020, IEEE COMPUT SOC CONF, P3716, DOI 10.1109/CVPRW50498.2020.00434
   Hsu YL, 2014, IEEE J BIOMED HEALTH, V18, P1822, DOI 10.1109/JBHI.2014.2325413
   Hu MD, 2011, IEEE T SYST MAN CY B, V41, P1429, DOI 10.1109/TSMCB.2011.2149518
   Huynh-The T, 2020, NEUROCOMPUTING, V397, P192, DOI 10.1016/j.neucom.2020.02.048
   Isaac ERHP, 2019, PATTERN RECOGN LETT, V126, P41, DOI 10.1016/j.patrec.2018.04.020
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Jain A, 2018, EXPERT SYST APPL, V93, P257, DOI 10.1016/j.eswa.2017.10.017
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   Johnson AY, 2001, LECT NOTES COMPUT SC, V2091, P301
   Judith M., 2010, J SPORTS SCI MED SLA, P119
   Juvonen A, 2015, COMPUT NETW, V91, P46, DOI 10.1016/j.comnet.2015.07.019
   Kastaniotis D, 2013, INT CONF DIGIT SIG
   Khamsemanan Nirattaya, 2017, IEEE T INF FOREN SEC, P119
   Khan MH, 2020, NEUROCOMPUTING, V402, P100, DOI 10.1016/j.neucom.2020.03.101
   Khandelwal S, 2017, GAIT POSTURE, V51, P84, DOI 10.1016/j.gaitpost.2016.09.023
   Kim D, 2010, IET COMPUT VIS, V4, P25, DOI 10.1049/iet-cvi.2009.0009
   Krzeszowski T, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P232, DOI 10.1109/AVSS.2013.6636645
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Kusakunniran W, 2011, IEEE IMAGE PROC, P545, DOI 10.1109/ICIP.2011.6116403
   Kwolek B, 2014, LECT NOTES ARTIF INT, V8398, P595, DOI 10.1007/978-3-319-05458-2_61
   Kwon B, 2021, IEEE ACCESS, V9, P28334, DOI 10.1109/ACCESS.2021.3058745
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Limcharoen P, 2020, IEEE T INF FOREN SEC, V15, P3430, DOI 10.1109/TIFS.2020.2985535
   Linnhoff-Popien Claudia, 2012, P 1 INT WORKSH KIN P, P1304
   Lishani AO, 2017, SIGNAL IMAGE VIDEO P, V11, P1123, DOI 10.1007/s11760-017-1066-y
   Liu Y., 2019, 2019 16 IEEE INT C A, P1, DOI [DOI 10.1109/AVSS.2019.8909881, 10.1109/AVSS.2019.8909881]
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Lu JW, 2010, IEEE T INF FOREN SEC, V5, P761, DOI 10.1109/TIFS.2010.2069560
   Luo Jiajia, 2014, Pattern Recogn. Lett., P1
   luo Jian., 2020, IEEE ACCESS, V8
   Ma J, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102578
   Mahavaishnavi V, 2020, MATER TODAY-PROC, P1
   Mahfouf Z, 2018, NEUROCOMPUTING, V283, P140, DOI 10.1016/j.neucom.2017.12.040
   Makihara Y., 2011, 2011 INT JOINT C BIO, P1, DOI 10.1109/IJCB.2011.6117531
   Makihara Y., 2015, IPSJ T COMPUTER VISI, V7, P74
   Makihara Y, 2017, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR.2017.718
   Mansur A, 2014, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2014.323
   Manzi A, 2018, IET COMPUT VIS, V12, P27, DOI 10.1049/iet-cvi.2017.0118
   Meng C, 2016, BRIEF BIOINFORM, V17, P628, DOI 10.1093/bib/bbv108
   Meng Xianye, 2018, IEEE T CIRC SYST VID, V1, P1
   Middleton Lee, 2005, 4 IEEE WORKSHOP AUTO, P1
   Naik P, 2008, MARKET LETT, V19, P201, DOI 10.1007/s11002-008-9036-3
   Nattee Cholwich., 2015, VIEW INDEPENDENT HUM, P245
   Nazmi N, 2019, BIOMED SIGNAL PROCES, V47, P334, DOI 10.1016/j.bspc.2018.08.030
   Niu ZX, 2016, PROC CVPR IEEE, P4920, DOI 10.1109/CVPR.2016.532
   Nutakki Chaitanya, 2020, Procedia Computer Science, V171, P395, DOI 10.1016/j.procs.2020.04.041
   Ozaki F, 2020, IEEE/SICE I S SYS IN, P213, DOI [10.1109/SII46433.2020.9025838, 10.1109/sii46433.2020.9025838]
   Parihar AS, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102991
   Peer Peter, 2014, Mathematical Problems in Engineering, P254
   Portillo-Portillo J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010006
   Ran Y, 2010, IEEE T SYST MAN CY B, V40, P1009, DOI 10.1109/TSMCB.2010.2044173
   Riaz Q, 2019, IEEE ACCESS, V7, P28510, DOI 10.1109/ACCESS.2019.2901959
   Saad A, 2017, INT J MACH LEARN CYB, V8, P941, DOI 10.1007/s13042-015-0480-0
   Sabzevari M, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.101950
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   schatz Martin, 2015, Biomed. Eng. Online, P82
   Severin AC, 2019, GAIT POSTURE, V73, P233, DOI 10.1016/j.gaitpost.2019.07.374
   Shao XQ, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1534, DOI [10.1109/itnec48623.2020.9084747, 10.1109/ITNEC48623.2020.9084747]
   Sheng WJ, 2020, NEUROCOMPUTING, V395, P86, DOI 10.1016/j.neucom.2020.01.098
   Sheshadri MGH, 2020, NATL CONF COMMUN, DOI 10.1109/ncc48643.2020.9056001
   Shi L., 2019, IEEE T INSTRUM MEAS, P1
   Shutler JD, 2006, IMAGE VISION COMPUT, V24, P343, DOI 10.1016/j.imavis.2005.12.001
   Shutler J. D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P291, DOI 10.1109/IAI.2000.839618
   Shutler JD, 2004, ADV SOFT COMP, P339
   Sinha Kumari Priyanka, 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0838, DOI 10.1109/ICCSP48568.2020.9182356
   Sudha LR, 2013, APPL ARTIF INTELL, V27, P62, DOI 10.1080/08839514.2013.747373
   Sun WW, 2017, IEEE T GEOSCI REMOTE, V55, P4032, DOI 10.1109/TGRS.2017.2686842
   Sundaresan A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P93
   Tafazzoli F, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013036
   Takeda T., 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P1204, DOI 10.1109/ICSMC.2010.5642383
   Tang Y, 2008, INT CONF ACOUST SPEE, P1569, DOI 10.1109/ICASSP.2008.4517923
   Teoh Andrew Beng Jin, 2016, IEEE T CYBERNETICS, P1
   Tong Suibing, 2018, IEEE INT C MULTIMEDI, P57583
   Tran L, 2020, IEEE ACCESS, V8, P12364, DOI 10.1109/ACCESS.2020.2966142
   Ngo TT, 2015, PATTERN RECOGN, V48, P1289, DOI 10.1016/j.patcog.2014.10.012
   Van Der Maaten Laurens, 2009, Journal of Machine Learning Research, V10, P13
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang T, 2021, IEEE SENS J, V21, P3260, DOI 10.1109/JSEN.2020.3022374
   Wang W, 2016, IEEE IMAGE PROC, P3151, DOI 10.1109/ICIP.2016.7532940
   Wei PN, 2020, IEEE ENG MED BIO, P1002, DOI 10.1109/EMBC44109.2020.9175655
   Weihao Hong, 2016, P INT C YOUNG COMP S, P77, DOI [10.1007/978-981-10-2053-7_8, DOI 10.1007/978-981-10-2053-7_8]
   Weizhi An, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P421, DOI 10.1109/TBIOM.2020.3008862
   Winter DA, 2009, BIOMECHANICS MOTOR C, DOI [10.1002/9780470549148, DOI 10.1002/9780470549148]
   Wu YL, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P155, DOI [10.1109/itnec48623.2020.9084819, 10.1109/ITNEC48623.2020.9084819]
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Xiang Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13306, DOI 10.1109/CVPR42600.2020.01332
   Xing HF, 2017, J SENSORS, V2017, DOI 10.1155/2017/6091261
   Xu C, 2021, IEEE T CIRC SYST VID, V31, P260, DOI 10.1109/TCSVT.2020.2975671
   Xu WJ, 2017, NEUROCOMPUTING, V224, P37, DOI 10.1016/j.neucom.2016.10.054
   Xu ZP, 2019, J VIS COMMUN IMAGE R, V59, P159, DOI 10.1016/j.jvcir.2019.01.023
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yan C., 2020, ACM Trans. Multimedia Comput. Commun. Appl., V16
   Yan C, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P642, DOI 10.1109/CISP.2015.7407957
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Yan Chenggang, 2020, IEEE Trans. Pattern Anal. Machine Intell.
   Yang Xu., 2019, IEEE Trans. Mob. Comput., P1
   Yao Lingxiang, 2018, DIGITAL IMAGE COMPUT, P657
   Yoneyama M, 2014, IEEE T NEUR SYS REH, V22, P613, DOI 10.1109/TNSRE.2013.2260561
   Yoo J., 2008, 1 WORKSHOPS IMAGE PR, P1
   Yoo JH, 2011, ETRI J, V33, P259, DOI 10.4218/etrij.11.1510.0068
   Yu CC, 2014, J INF SCI ENG, V30, P179
   Yu S Q, 2013, Biometric Recognition, V8232, P417
   Yu SQ, 2006, INT C PATT RECOG, P441
   Yu SQ, 2009, IEEE T IMAGE PROCESS, V18, P1905, DOI 10.1109/TIP.2009.2020535
   Yuan Mengjia, 2019, J VIS COMMUN IMAGE R, P111
   Zellers JA, 2019, GAIT POSTURE, V70, P59, DOI 10.1016/j.gaitpost.2019.02.027
   Zhang Bin., 2020, SIGNAL PROCESS-IMAGE, P1
   Zhang Lei, 2018, IEEE INTERNET THINGS, V6, P1
   Zhang SX, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987240
   Zhang Worapan, 2009, 2009 IEEE 12 INT C C, P1
   Zhang Y, 2018, PATTERN RECOGN, V76, P662, DOI 10.1016/j.patcog.2017.09.043
   Zhang Yanxin, 2020, Measurement, P1
   Zhang YB, 2020, IEEE T IMAGE PROCESS, V29, P1101, DOI 10.1109/TIP.2019.2938347
   Zhao A, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106273
   Zhao F, 2020, FUTURE GENER COMP SY, V111, P375, DOI 10.1016/j.future.2020.05.002
   Zhao Guoying, 2006, 7 INT C AUT FAC GEST, P29
NR 156
TC 4
Z9 4
U1 4
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103218
DI 10.1016/j.jvcir.2021.103218
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900001
DA 2024-07-18
ER

PT J
AU Chen, J
   Ou, JS
   Zeng, HQ
   Cai, CH
AF Chen, Jing
   Ou, Jianshan
   Zeng, Huanqiang
   Cai, Canhui
TI A fast algorithm based on gray level co-occurrence matrix and Gabor
   feature for HEVC screen content coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Screen content video coding; High efficiency video coding (HEVC); Intra
   prediction; Partition decision
ID QUALITY ASSESSMENT
AB To reduce the computational complexity of screen content video coding (SCC), a fast algorithm based on gray level co-occurrence matrix and Gabor feature model for HEVC-SCC, denoted as GGM, is proposed in this paper. By studying the correlation of non-zero number in gray level co-occurrence matrix with different partitioning depth, the coding unit (CU) size of intra coding can be prejudged, which selectively skips the intra prediction process of CU in other depth. With Gabor filter, the edge information reflecting the features of screen content images to the human visual system (HVS) are extracted. According to Gabor feature, CUs are classified into natural content CUs (NCCUs), smooth screen content CUs (SSCUs) and complex screen content CUs (CSCUs), with which, the calculation and judgment of unnecessary intra prediction modes are skipped. Under all-intra (AI) configuration, experimental results show that the proposed algorithm GGM can achieve encoding time saving by 42.13% compared with SCM-8.3, and with only 1.85% bit-rate increasement.
C1 [Chen, Jing; Ou, Jianshan] Huaqiao Univ, Sch Informat Sci & Engn, Xiamen, Peoples R China.
   [Zeng, Huanqiang; Cai, Canhui] Huaqiao Univ, Sch Engn, Quanzhou, Peoples R China.
   [Chen, Jing; Ou, Jianshan; Zeng, Huanqiang; Cai, Canhui] Xiamen Key Lab Mobile Multimedia Commun, Xiamen, Peoples R China.
C3 Huaqiao University; Huaqiao University
RP Zeng, HQ (corresponding author), Huaqiao Univ, Sch Engn, Quanzhou, Peoples R China.
EM zeng0043@hqu.edu.cn
RI Zeng, Huanqiang/U-2017-2018
FU National Natural Science Foundation of China [61871434, 61802136];
   Natural Science Foundation for Outstanding Young Scholars of Fujian
   Province [2019J06017]; Fujian-100 Talented People Program; Key Science
   and Technology Project of Xiamen City [3502ZCQ20191005]; High-Level
   Talent Project Foundation of Huaqiao University [16BS709, 14BS204]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos. 61871434 and 61802136), Natural Science Foundation
   for Outstanding Young Scholars of Fujian Province (Grant No.
   2019J06017), Fujian-100 Talented People Program, Key Science and
   Technology Project of Xiamen City (Grant No. 3502ZCQ20191005),
   High-Level Talent Project Foundation of Huaqiao University (Grant Nos.
   16BS709, and 14BS204).
CR [Anonymous], 2007, BEIJING SURV MAP, DOI DOI 10.19580/J.CNKI.1007-3000.2007.03.006
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Cheng S, 2020, IEEE T IMAGE PROCESS, V29, P8636, DOI 10.1109/TIP.2020.3018256
   Donghyun Lee, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166897
   Duanmu F, 2016, IEEE J EM SEL TOP C, V6, P517, DOI 10.1109/JETCAS.2016.2597698
   Duanmu F, 2015, IEEE IMAGE PROC, P4972, DOI 10.1109/ICIP.2015.7351753
   Gao Xiao-xing, 2008, Journal of Computer Applications, V28, P2625
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Kuang W., 2019, ACCEPTED BE APPEARED, P1
   Kuang W, 2017, IEEE IMAGE PROC, P2473, DOI 10.1109/ICIP.2017.8296727
   Lei JJ, 2017, IEEE T BROADCAST, V63, P48, DOI 10.1109/TBC.2016.2623241
   Li B., 2014, document JCTVC-S0085
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Maloney RT, 2015, NEUROIMAGE, V119, P129, DOI 10.1016/j.neuroimage.2015.06.034
   Marpe D, 2006, IEEE IMAGE PROC, P3157, DOI 10.1109/ICIP.2006.313039
   Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890
   Pang C, 2013, JCTVCN0256
   Pu W, 2016, IEEE J EM SEL TOP C, V6, P420, DOI 10.1109/JETCAS.2016.2605661
   Tsang SH, 2019, IEEE T MULTIMEDIA, V21, P2433, DOI 10.1109/TMM.2019.2907472
   Tsang SH, 2016, ASIAPAC SIGN INFO PR
   Tsang SH, 2015, INT CONF ACOUST SPEE, P1409, DOI 10.1109/ICASSP.2015.7178202
   Wu JJ, 2015, IEEE T IMAGE PROCESS, V24, P4602, DOI 10.1109/TIP.2015.2460467
   Xiao W, 2018, IEEE T CIRC SYST VID, V28, P1169, DOI 10.1109/TCSVT.2016.2643701
   Xu JZ, 2016, IEEE T CIRC SYST VID, V26, P50, DOI 10.1109/TCSVT.2015.2478706
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang H, 2017, IEEE IMAGE PROC, P2468, DOI 10.1109/ICIP.2017.8296726
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yu H., 2014, JCT-VC, document JCTVC-Q1015
   Zhang H, 2016, INT CONF ACOUST SPEE, P1377, DOI 10.1109/ICASSP.2016.7471902
   Zhang L, 2016, IEEE J EM SEL TOP C, V6, P446, DOI 10.1109/JETCAS.2016.2599860
   Zhang MM, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P390, DOI 10.1109/VCIP.2014.7051588
NR 32
TC 4
Z9 5
U1 2
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103128
DI 10.1016/j.jvcir.2021.103128
EA MAY 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1MD
UT WOS:000674618200004
DA 2024-07-18
ER

PT J
AU Mehra, A
   Narang, P
   Mandal, M
AF Mehra, Aryan
   Narang, Pratik
   Mandal, Murari
TI TheiaNet: Towards fast and inexpensive CNN design choices for image
   dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dehazing; Computation efficiency; Speed and memory tests; Design choices
AB This work examines inexpensive design choices for dehazing as an end-to-end image-to-image mapping problem without relying on the physical scattering model. The proposed TheiaNet is free from intermediate-computation of transmission map, enabling haze removal in a highly resource constrained environments. The simplicity of the network is augmented by a spatial cleaning bottleneck block, that adds faster feature extraction without adding to trainable parameters. We also analyze the effectiveness of multi-cue color space (RGB, HSV, LAB, YCbCr) over single cue color space (RGB) for end-to-end dehazing. A comprehensive set of experiments were conducted on HazeRD, D-Hazy and the more recent Reside datasets. The proposed TheiaNet significantly outperforms the existing CNN and GAN based state-of-the-art methods in terms of PSNR and SSIM on all these datasets. It also outperforms all existing methods in term of speed, compute and memory efficiency, making it more efficient. This work highlights how judicious application-specific components can augment simple CNNs to denoise faster, and more accurately than deeper heavier networks, which is supported by an ablation analysis as well.
C1 [Mehra, Aryan; Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
   [Mandal, Murari] IIIT Kota, Dept CSE, Kota, Rajasthan, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM pratik.narang@pilani.bits-pilani.ac.in
RI Mehra, Aryan/HPC-3885-2023; Mandal, Murari/GQI-2942-2022
OI Mandal, Murari/0000-0002-0157-0967; Mehra, Aryan/0000-0002-7258-2199
CR Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Ancuti C, 2016, IEEE IMAGE PROC, P2256, DOI 10.1109/ICIP.2016.7532760
   Berman D, 2017, IEEE INT CONF COMPUT, P115
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bianco S, 2019, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2019.00244
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen S., 2019, ARXIV PREPRINT ARXIV
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Dudhane A, 2019, IEEE COMPUT SOC CONF, P2014, DOI 10.1109/CVPRW.2019.00253
   Dudhane A, 2020, IEEE T IMAGE PROCESS, V29, P628, DOI 10.1109/TIP.2019.2934360
   Dudhane A, 2019, IEEE WINT CONF APPL, P1147, DOI 10.1109/WACV.2019.00127
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Golts A., 2018, ARXIV PREPRINT ARXIV
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Mandal M., 2020, ARXIV PREPRINT ARXIV
   Mandal M, 2020, IEEE GEOSCI REMOTE S, V17, P494, DOI 10.1109/LGRS.2019.2923564
   Mandal M, 2019, IEEE SIGNAL PROC LET, V26, P1882, DOI 10.1109/LSP.2019.2952253
   Mandal M, 2019, IET COMPUT VIS, V13, P31, DOI 10.1049/iet-cvi.2018.5206
   Mandal M, 2018, INT C PATT RECOG, P2468, DOI 10.1109/ICPR.2018.8545504
   McCartney E.J., 1976, OPTICS ATMOSPHERE SC, P421
   Mehra A., 2020, IEEE Trans. Intell. Transport. Syst., P1
   Mehta A, 2020, IEEE COMPUT SOC CONF, P846, DOI 10.1109/CVPRW50498.2020.00114
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Pang YW, 2019, IEEE I CONF COMP VIS, P4229, DOI 10.1109/ICCV.2019.00433
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2020, INT J COMPUT VISION, V128, P240, DOI 10.1007/s11263-019-01235-8
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P1895, DOI 10.1109/TIP.2018.2876178
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Sulami M, 2014, IEEE INT CONF COMPUT
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tufail Z, 2018, IEEE ACCESS, V6, P32576, DOI 10.1109/ACCESS.2018.2843261
   Yang D, 2018, LECT NOTES COMPUT SC, V11211, P729, DOI 10.1007/978-3-030-01234-2_43
   Yang X., 2019, IEEE Trans. Multimed
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Yi Wan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457892
   Zhang H, 2018, IEEE COMPUT SOC CONF, P1015, DOI 10.1109/CVPRW.2018.00135
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang TY, 2018, IEEE ACCESS, V6, P10644, DOI 10.1109/ACCESS.2018.2806372
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu HY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1234
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 57
TC 15
Z9 15
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103137
DI 10.1016/j.jvcir.2021.103137
EA APR 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VX
UT WOS:000663341200007
DA 2024-07-18
ER

PT J
AU Liu, XD
   Kong, J
   Jiang, M
   Li, S
AF Liu, Xudong
   Kong, Jun
   Jiang, Min
   Li, Sha
TI Interactive information module for person re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; Interactive Information Module; Global-map
   Attention Module; Labeled-class Mutual Learning
ID ATTENTION; NETWORK
AB In person re-identification (Re-ID) task, multi-branch networks acquire better performance by combining global features and local features. Obviously, local branch can obtain detailed information of person pictures but may work on invalid regions when person pictures have imprecise bounding boxes. On the contrary, global branch can be aware of the position of person but hard to acquire detailed information of person pictures. Meanwhile, lots of multi-branch networks ignore mutual information among different branches. Therefore, it is necessary to enhance interaction of global branch and local branch. For this purpose, we propose Interactive Information Module (IIM). IIM includes two components named Global-map Attention Module (GAM) and Labeled-class Mutual Learning (LML), respectively. GAM leverages heatmaps generated by global branch to guide calculation of local attention and obtains a composite global feature by combining local features. GAM relys more on the performance of global branch which decides the quality of heatmaps. To improve performance of global branch, we propose LML to promote convergent rate of global branch. Extensive experiments implemented on Market-1501, DukeMTMC-ReID, and CUHK03-NP datasets confirm that our method achieves state-of-the-art results.
C1 [Liu, Xudong; Kong, Jun; Jiang, Min] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
   [Li, Sha] Wuxi Taihu Univ, Jiangsu Key Construct Lab IoT Applicat Technol, Wuxi 214064, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Kong, J (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
EM kongjun@jiangnan.edu.cn
RI liu, xudong/HJG-8137-2022
FU National Natural Science Foundation of China [61362030, 61201429,
   61876072]; China Postdoctoral Science Foundation [2015M581720,
   2016M600360]; Jiangsu Postdoctoral Science Foundation, China [1601216C];
   Scientific and Technological Aid Program of Xinjiang, China [2017E0279]
FX This work was partially supported by the National Natural Science
   Foundation of China (61362030, 61201429, 61876072), China Postdoctoral
   Science Foundation (2015M581720, 2016M600360), Jiangsu Postdoctoral
   Science Foundation, China (1601216C), Scientific and Technological Aid
   Program of Xinjiang, China (2017E0279).
CR Almazan J., 2018, Re-ID done right: towards good practices for person re-identification
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Dean J., 2015, NIPS DEEP LEARNING R
   Dosovitskiy Alexey, 2015, ARXIV PREPRINT ARXIV
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LAN X, 2017, BRIT MACH VIS C
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K., 2014, 14091556 ARXIV
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   WU D, 2019, 31 AAAI C ARTIFICIAL, V324, P69
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M., 2020, IEEE T PATTERN ANAL
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Xucong, 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), V41, P162
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   ZHENG Z, 2018, PROC CVPR IEEE, V29, P3037
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou B., 2014, CORR, V1412, P6856
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 52
TC 1
Z9 1
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103033
DI 10.1016/j.jvcir.2021.103033
EA JAN 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BY
UT WOS:000633494500003
DA 2024-07-18
ER

PT J
AU Chaitanya, BSNV
   Mukherjee, S
AF Chaitanya, B. S. N., V
   Mukherjee, Snehasis
TI Single image dehazing using improved cycleGAN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CycleGAN; Cyclic consistency loss; AOD-NET; Single image dehazing; SSIM
   loss
AB Haze is an aggregation of very fine, widely dispersed, solid and/or liquid particles suspended in the atmosphere. In this paper, we propose an end-to-end network for single image dehazing, which enhances the CycleGAN model by introducing a transformer architecture within the generator, which is specific for haze removal. The proposed model is trained in an unpaired fashion with clear and hazy images altogether and does not require pairs of hazy and corresponding ground-truth clear images. Furthermore, the proposed model does not depend on estimating the parameters of the atmospheric scattering model. Rather, it uses a K-estimation module as the generator's transformer for complete end-to-end modeling. The feature transformer introduced in the proposed generator model transforms the encoded features into desired feature space and then feeds them into the CycleGAN decoder to create a clear image. In the proposed model we further modified the cycle consistency loss to include the SSIM loss along with pixel-wise mean loss to produce a new loss function specific for the reconstruction task, which enhances the performance of the proposed model. The model performs well even on the high-resolution images provided in the NTIRE 2019 challenge dataset for single image dehazing. Further, we perform experiments on NYU-Depth and reside beta datasets. Results of our experiments show the efficacy of the proposed approach compared to the state-of-the-art in removing the haze from the input image.
C1 [Chaitanya, B. S. N., V] Indian Inst Informat Technol, Sri City, India.
   [Mukherjee, Snehasis] Shiv Nadar Univ, Greater Noida, India.
C3 Shiv Nadar University
RP Mukherjee, S (corresponding author), Shiv Nadar Univ, Greater Noida, India.
EM viswachaitanya.b16@iiits.in; snehasis.mukherjee@snu.edu.in
FU NVIDIA company, United States
FX The authors wish to thank the NVIDIA company, United States for
   providing a TITAN X GPU card as a research grant, which is used for
   conducting the experiments reported in this paper.
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   [Anonymous], 2018, P IEEE C COMP VIS PA
   Bekaert Philippe, 2010, INT C IM PROC
   Borkar K, 2020, NEUROCOMPUTING, V400, P294, DOI 10.1016/j.neucom.2020.03.027
   Borkar Kushal, 2018, ARXIVE180808610
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai Zixing, 2010, 2010 INT C INT SYST, V1
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen YY, 2019, J VIS COMMUN IMAGE R, V61, P284, DOI 10.1016/j.jvcir.2019.04.008
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hore A., 2010, 2010 20 INT C PATT R
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang Zhiying, 2018, IEEE T POWER SYST, V99, P1
   Kumar H, 2019, IET IMAGE PROCESS, V13, P1931, DOI 10.1049/iet-ipr.2018.5240
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li Boyi, 2017, IEEE I CONF COMP VIS
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu Q, 2018, IEEE T IMAGE PROCESS, V27, P5178, DOI 10.1109/TIP.2018.2849928
   Liu Z., 2018, INT C LEARN REPR
   Mei Kangfu, 2018, AS C COMP VIS
   Morales Peter, 2019, P IEEE C COMP VIS PA
   Mukhopadhyay Sudipta, 2019, ARXIV PREPRINT ARXIV
   Qu Yanyun., 2019, COMPUTER VISION PATT
   Salazar Colores S, 2019, IET IMAGE PROCESS, V13, P2877, DOI 10.1049/iet-ipr.2018.6403
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Swami K., 2018, ARXIV PREPRINT ARXIV
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Timofte Radu, 2019, ARXIV PREPRINT ARXIV
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Xiao J, 2020, NEUROCOMPUTING
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H., 2017, ARXIV PREPRINT ARXIV
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 44
TC 0
Z9 0
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500007
DA 2024-07-18
ER

PT J
AU Hu, Z
   Liu, Z
   Li, GY
   Ye, LW
   Zhou, L
   Wang, Y
AF Hu, Zheng
   Liu, Zhi
   Li, Gongyang
   Ye, Linwei
   Zhou, Lei
   Wang, Yang
TI Weakly supervised instance segmentation using multi-stage erasing
   refinement and saliency-guided proposals ordering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised instance segmentation; Image-level annotations;
   Multi-stage erasing refinement; Saliency-guided proposals ordering
AB Weakly supervised instance segmentation is a new research topic in the field of computer vision. Compared with fully supervised instance segmentation, weakly supervised methods use weaker data annotations such as points, scribbles or class labels which are easy to obtain. Among these annotations, image-level instance segmentation using only class labels as supervision is the most challenging task. In this paper, we propose a novel weakly supervised instance segmentation framework using a multi-stage erasing refinement method and a saliency-guided proposals ordering method. Firstly, the multi-stage erasing refinement method is exploited to enhance the instance representation by iteratively discovering separate object-related regions, so as to obtain more complete discriminative regions. Then, the saliency-guided proposals ordering method utilizes the saliency map to alleviate the background noise and better select the object proposals for generating the instance segmentation result. Experimental results on the PASCAL VOC 2012 dataset and the COCO dataset demonstrate that our framework achieves superior performance compared with the state-of-the-art weakly supervised instance segmentation models and the ablation study shows the effectiveness of the proposed two methods.
C1 [Hu, Zheng; Liu, Zhi; Li, Gongyang] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Hu, Zheng; Liu, Zhi; Li, Gongyang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Ye, Linwei; Wang, Yang] Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
   [Zhou, Lei] Univ Shanghai Sci & Technol, Sch Med Instrument & Food Engn, Shanghai, Peoples R China.
C3 Shanghai University; Shanghai University; University of Manitoba;
   University of Shanghai for Science & Technology
RP Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI LIU, Zhi/D-4518-2012; Li, Gongyang/IXD-9078-2023; Lin,
   Fan/JZT-1441-2024; Wang, Zejun/KBB-8454-2024
OI LIU, Zhi/0000-0002-8428-1131; Lin, Fan/0000-0002-7330-3833; 
FU National Natural Science Foundation of China [61771301, 61906121]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771301 and 61906121.
CR Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Cholakkal H, 2019, PROC CVPR IEEE, P12389, DOI 10.1109/CVPR.2019.01268
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Emblemsvag Jan., 2020, INT J PAVEMENT ENG, V32, DOI [10.1108/TQM-12-2019-0295, DOI 10.1080/10298436.2018.1485917, 10.1080/07391102.2020.1801512.]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Ge WF, 2019, IEEE I CONF COMP VIS, P3344, DOI 10.1109/ICCV.2019.00344
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., P IEEE CVPR HON HI U
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang MK, 2019, NEUROCOMPUTING, V364, P310, DOI 10.1016/j.neucom.2019.07.054
   Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733
   Jin Bin, 2017, CVPR, P3626
   Khoreva A, 2017, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2017.181
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Laradji Issam H, 2019, ARXIV PREPRINT ARXIV
   Li KP, 2018, PROC CVPR IEEE, P9215, DOI 10.1109/CVPR.2018.00960
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Lin D, 2016, Arxiv, DOI [arXiv:1604.05144, DOI 10.1109/CVPR.2016.344]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Maninis KK, 2018, IEEE T PATTERN ANAL, V40, P819, DOI 10.1109/TPAMI.2017.2700300
   Pont-Tuset J, 2015, IEEE I CONF COMP VIS, P1546, DOI 10.1109/ICCV.2015.181
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wan F, 2018, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2018.00141
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150
   Wei YC, 2016, PATTERN RECOGN, V59, P234, DOI 10.1016/j.patcog.2016.01.015
   Ye LW, 2018, IEEE WINT CONF APPL, P1461, DOI 10.1109/WACV.2018.00164
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127
   Zhou YZ, 2018, PROC CVPR IEEE, P3791, DOI 10.1109/CVPR.2018.00399
   Zhu Y, 2019, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2019.00323
   Zhu Y, 2017, IEEE I CONF COMP VIS, P1859, DOI 10.1109/ICCV.2017.204
NR 43
TC 5
Z9 5
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102957
DI 10.1016/j.jvcir.2020.102957
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QT6TO
UT WOS:000626721200010
DA 2024-07-18
ER

PT J
AU Yedroudj, M
   Comby, F
   Chaumont, M
AF Yedroudj, Mehdi
   Comby, Frederic
   Chaumont, Marc
TI Steganography using a 3-player game
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganalysis; Deep learning; CNN; GAN
ID STEGANALYSIS
AB Image steganography aims to securely embed secret information into cover images. Until now, adaptive embedding algorithms such as S-UNIWARD or Mi-POD, were among the most secure and most often used methods for image steganography. With the arrival of deep learning and more specifically, Generative Adversarial Networks (GAN), new steganography techniques have appeared. Among them is the 3 -player game approach, where three networks compete against each other. In this paper, we propose three different architectures based on the 3-player game. The first architecture is proposed as a rigorous alternative to two recent publications. The second takes into account stego noise power. Finally, our third architecture enriches the second one with a better interaction between embedding and extracting networks. Our method achieves better results compared to existing works Hayes and Danezis (2017), Zhu et al. (2018), and paves the way for future research on this topic.
C1 [Yedroudj, Mehdi; Comby, Frederic; Chaumont, Marc] Univ Montpellier, CNRS, LIRMM, 161 Rue Ada, F-34095 Montpellier, France.
   [Chaumont, Marc] Univ Nimes, 7 Pl Gabriel Peri, F-30000 Nimes, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de
   Montpellier; Universite de Nimes
RP Yedroudj, M (corresponding author), Univ Montpellier, CNRS, LIRMM, 161 Rue Ada, F-34095 Montpellier, France.
EM Mehdi.Yedroudj@lirmm.fr; Frederic.Comby@lirmm.fr; Marc.Chaumont@lirmm.fr
RI Chaumont, Marc/T-2532-2019
OI Chaumont, Marc/0000-0002-4095-4410
FU French Direction Generale de l'Armement (DGA) through the Alaska project
   ANR [ANR-18-ASTR-0009]; Algerian Ministry of Higher Education/Scientific
   Research
FX The authors would like to thank the University of Montpellier (LIRMM)
   and the University of Nimes. We extend our gratitude to the French
   Direction Generale de l'Armement (DGA) for its support through the
   Alaska project ANR (ANR-18-ASTR-0009). We would also like to thank the
   Algerian Ministry of Higher Education/Scientific Research, for its
   scholarship support.
CR Abadi M., 2016, ARXIV REJECTED 5 INT
   [Anonymous], 2012, P INT WORKSH INF HID
   [Anonymous], 1883, Journal des Sciences Militaires
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., 2008, BOWS-2 Contest (Break Our Watermarking System)
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chaumont M., 2020, Digital Media Steganography, P321, DOI [DOI 10.1016/B978-0-12-819438-6.00022-0, 10.1016/B978-0-12-819438-6.00022-0]
   Deng XQ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P230, DOI 10.1145/3335203.3335739
   Filler T, 2010, PROC SPIE, V7541, DOI 10.1117/12.838002
   Fridrich J., 2009, INFORM HIDING
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Hu DH, 2018, IEEE ACCESS, V6, P38303, DOI 10.1109/ACCESS.2018.2852771
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P69
   Kouider S, 2013, IEEE INT CON MULTI
   Lerch-Hostalot D, 2016, ENG APPL ARTIF INTEL, V50, P45, DOI 10.1016/j.engappai.2015.12.013
   Maas AL., 2013, P ICML WORKSHOP DEEP, V28, P1
   Pibre L., 2016, Electronic Imaging, V2016, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-078
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schöttle P, 2016, IEEE T INF FOREN SEC, V11, P760, DOI 10.1109/TIFS.2015.2509941
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Simmons G.J., 1983, PROC ADV CRYPTOLOGY, P51
   Taburet T, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P57, DOI 10.1145/3335203.3335715
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Vaswani A, 2017, ADV NEUR IN, V30
   Yedroudj M., 2020, P ACM WORKSH INF HID
   Yedroudj M, 2018, ELECT IMAGING, DOI [10.2352/ISSN.2470-1173.2018.07.MWSF-317, DOI 10.2352/ISSN.2470-1173.2018.07.MWSF-317]
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhu J., 2018, LECT NOTES COMPUTER, V11219, P682
NR 35
TC 15
Z9 15
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102910
DI 10.1016/j.jvcir.2020.102910
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400019
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Yang, YK
   Jiao, SJ
   Li, JB
AF Yang, Yikun
   Jiao, Shengjie
   Li, Jiabo
TI Vision-based optimization of the generalized predictive active
   disturbance rejection controller
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mixing and spreading equipment for MOH material; Batching system; Active
   disturbance rejection control; Generalized prediction; Adaptive genetic
   algorithm
ID CONVERGENCE
AB The batching system of the integrated mixing and spreading equipment for MOH material is a nonlinear system with large uncertainty. It is difficult for conventional control strategies to meet the requirements for system performance. This research combines generalized predictive control and active disturbance rejection technique to propose a new generalized predictive active disturbance rejection controller (GPADRC) used in the batching system of MOH material. For the nonlinearity and uncertainty of the batching system, the extended state observer in the active disturbance rejection technique is used for estimation and compensation. The batching system model is converted into an integrator form, based on which the use of generalized predictive control can greatly reduce the impact of nonlinear models and uncertainties on the controller. Aiming at the problem that the parameters of the proposed new controller are numerous and difficult to tune, the adaptive genetic algorithm is used to realize the automatic tuning of the parameters. The simulation experiment shows that the designed GPADRC can well adapt to the working conditions of the batching system and can meet the requirements for various control indicators. At the same time, the adaptive genetic algorithm can realize the rapid tuning of the controller parameters, which reduce the difficulty and time consumption of the tuning process, and improve the applicability and achievability of the designed controller. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Yang, Yikun; Jiao, Shengjie; Li, Jiabo] Changan Univ, Natl Engn Lab Highway Maintenance Equipment, Xian 710100, Peoples R China.
   [Yang, Yikun] Yanan Univ, Coll Math & Comp Sci, Yanan 716000, Peoples R China.
C3 Chang'an University; Yanan University
RP Yang, YK (corresponding author), Changan Univ, Natl Engn Lab Highway Maintenance Equipment, Xian 710100, Peoples R China.; Yang, YK (corresponding author), Yanan Univ, Coll Math & Comp Sci, Yanan 716000, Peoples R China.
EM yangyikun_edu@sina.com
CR Guo BZ, 2013, SIAM J CONTROL OPTIM, V51, P1727, DOI 10.1137/110856824
   Guo BZ, 2011, SYST CONTROL LETT, V60, P420, DOI 10.1016/j.sysconle.2011.03.008
   Han J., 1998, Control and Decision, V13, P19
   Han J., 2008, The Technique for Estimating and Compensating the Uncertainties: Active Disturbance Rejection Control Technique
   Han JQ, 2009, IEEE T IND ELECTRON, V56, P900, DOI 10.1109/TIE.2008.2011621
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Huang Y, 2014, ISA T, V53, P963, DOI 10.1016/j.isatra.2014.03.003
   Qiu DM, 2014, IEEE T CONTR SYST T, V22, P1983, DOI 10.1109/TCST.2013.2296935
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xue WC, 2014, ISA T, V53, P955, DOI 10.1016/j.isatra.2014.02.002
   Yang RG, 2011, J SYST ENG ELECTRON, V22, P95, DOI 10.3969/j.issn.1004-4132.2011.01.012
NR 12
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102728
DI 10.1016/j.jvcir.2019.102728
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900012
DA 2024-07-18
ER

PT J
AU Chen, J
   Chen, ZF
   Su, KX
   Peng, Z
   Ling, N
AF Chen, Jian
   Chen, Zhifeng
   Su, Kaixiong
   Peng, Zheng
   Ling, Nam
TI Video compressed sensing reconstruction based on structural group
   sparsity and successive approximation estimation model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed sensing; Group sparsity; Interframe estimation;
   Reconstruction algorithms
ID ALGORITHMS; CS
AB The existing video compressed sensing (CS) algorithms for inconsistent sampling ignore the joint correlations of video signals in space and time, and their reconstruction quality and speed need further improvement. To balance reconstruction quality with computational complexity, we introduce a structural group sparsity model for use in the initial reconstruction phase and propose a weight-based group sparse optimization algorithm acting in joint domains. Then, a coarse-to-fine optical flow estimation model with successive approximation is introduced for use in the interframe prediction stage to recover non-key frames through alternating optical flow estimation and residual sparse reconstruction. Experimental results show that, compared with the existing algorithms, the proposed algorithm achieves a peak signal-to-noise ratio gain of 1-3 dB and a multi-scale structural similarity gain of 0.01-0.03 at a low time complexity, and the reconstructed frames not only have good edge contours but also retain textural details. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Chen, Jian; Chen, Zhifeng; Su, Kaixiong] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Fujian, Peoples R China.
   [Peng, Zheng] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Fujian, Peoples R China.
   [Ling, Nam] Santa Clara Univ, Dept Comp Engn, Santa Clara, CA 95053 USA.
C3 Fuzhou University; Fuzhou University; Santa Clara University
RP Chen, ZF (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Fujian, Peoples R China.
EM zhifeng@fzu.edu.cn
FU National Natural Science Foundation of China [NSFC 61671153, 11571074];
   Natural Science Foundation of Fujian Province [2017J01757, GXRC-17034]
FX This work was supported by the National Natural Science Foundation of
   China (NSFC 61671153 and 11571074), the Natural Science Foundation of
   Fujian Province (2017J01757), and theFuzhou University Fund
   (GXRC-17034).
CR [Anonymous], 2012, 2012 IEEE INT C COMP, DOI DOI 10.1109/ICCPHOT.2012.6215212
   [Anonymous], 1989, SIAM STUDIES APPL MA
   Azghani M, 2016, IEEE T CIRC SYST VID, V26, P627, DOI 10.1109/TCSVT.2015.2418586
   Baraniuk RG, 2017, IEEE SIGNAL PROC MAG, V34, P52, DOI 10.1109/MSP.2016.2602099
   BARZILAI J, 1988, IMA J NUMER ANAL, V8, P141, DOI 10.1093/imanum/8.1.141
   Bernal EA, 2017, IEEE IMAGE PROC, P2781, DOI 10.1109/ICIP.2017.8296789
   Bolstad A, 2011, IEEE T SIGNAL PROCES, V59, P2628, DOI 10.1109/TSP.2011.2129515
   Caiafa CF, 2015, IEEE T SIGNAL PROCES, V63, P780, DOI 10.1109/TSP.2014.2385040
   Chen G, 2017, SIGNAL PROCESS-IMAGE, V55, P146, DOI 10.1016/j.image.2017.03.021
   [陈建 Chen Jian], 2015, [运筹学学报, Operations Research Transaction], V19, P59
   Coluccia G., 2015, Compressed Sensing for Distributed Systems
   Deng W, 2013, PROC SPIE, V8858, DOI 10.1117/12.2024410
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dragotti PL, 2009, DISTRIBUTED SOURCE CODING: THEORY, ALGORITHMS, AND APPLICATIONS, P1
   Duarte MF, 2012, IEEE T IMAGE PROCESS, V21, P494, DOI 10.1109/TIP.2011.2165289
   Friedland S, 2014, IEEE T IMAGE PROCESS, V23, P4438, DOI 10.1109/TIP.2014.2348796
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gu GY, 2014, COMPUT OPTIM APPL, V59, P135, DOI 10.1007/s10589-013-9616-x
   He BS, 2015, IMA J NUMER ANAL, V35, P394, DOI 10.1093/imanum/drt060
   He BS, 2012, SIAM J NUMER ANAL, V50, P700, DOI 10.1137/110836936
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hosseini MS, 2014, IEEE T IMAGE PROCESS, V23, P3869, DOI 10.1109/TIP.2014.2332755
   Hung-Wei Chen, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P210, DOI 10.1109/PCS.2010.5702466
   Li CB, 2013, COMPUT OPTIM APPL, V56, P507, DOI 10.1007/s10589-013-9576-1
   Li Q, 2017, IEEE COMPUT SOC CONF, P218, DOI 10.1109/CVPRW.2017.33
   Li WH, 2017, IEEE IMAGE PROC, P2766, DOI 10.1109/ICIP.2017.8296786
   Li YS, 2018, IEEE T CIRC SYST VID, V28, P2233, DOI 10.1109/TCSVT.2017.2720175
   Lingala SG, 2015, IEEE T MED IMAGING, V34, P72, DOI 10.1109/TMI.2014.2343953
   Liu Ce, 2009, THESIS
   Liu C, 2016, CHIN CONTR CONF, P32, DOI 10.1109/ChiCC.2016.7553056
   Liu Fl., 2018, STATISTICS, V2, P1
   Majumdar A, 2012, IEEE J EM SEL TOP C, V2, P362, DOI 10.1109/JETCAS.2012.2212774
   Majumdar A, 2012, IEEE T MED IMAGING, V31, P2253, DOI 10.1109/TMI.2012.2215921
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Prades-Nebot J., 2009, 2009 Picture Coding Symposium, PCS 2009, P1, DOI DOI 10.1109/PCS.2009.5167431
   Rani M, 2018, IEEE ACCESS, V6, P4875, DOI 10.1109/ACCESS.2018.2793851
   Sankaranarayanan AC, 2015, SIAM J IMAGING SCI, V8, P1489, DOI 10.1137/140983124
   Su KX, 2016, MULTIMED TOOLS APPL, V75, P16417, DOI 10.1007/s11042-015-2975-9
   Tramel EW, 2011, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC.2011.26
   Vaswani N, 2010, IEEE T SIGNAL PROCES, V58, P4595, DOI 10.1109/TSP.2010.2051150
   Vivienne S., 2014, HIGH EFFCIENCY VIDEO, V2014th
   Wen JM, 2018, IEEE ACCESS, V6, P38179, DOI 10.1109/ACCESS.2018.2853158
   Wen JM, 2017, IEEE T SIGNAL PROCES, V65, P1370, DOI 10.1109/TSP.2016.2634550
   Zha ZY, 2018, NEUROCOMPUTING, V296, P55, DOI 10.1016/j.neucom.2018.03.027
   Zhang HC, 2004, SIAM J OPTIMIZ, V14, P1043, DOI 10.1137/S1052623403428208
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhao C, 2017, IEEE T CIRC SYST VID, V27, P1182, DOI 10.1109/TCSVT.2016.2527181
NR 48
TC 2
Z9 4
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102734
DI 10.1016/j.jvcir.2019.102734
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200013
DA 2024-07-18
ER

PT J
AU Liu, JY
AF Liu, Jingyi
TI Learning full-reference quality-guided discriminative gradient cues for
   lane detection based on neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lane detection; Full-reference IQA; CNN; RNN
ID IMAGE; MODEL
AB Learning an intelligent lane detection system is significant to autonomous vehicles, which is a crucial module to smart cars. Although conventional approaches have achieved impressive performance, they suffer from the following limitations: (1) lane perception are confronted with different weather conditions and varied illumination. Existing methods lack a unified framework for characterizing different sceneries and (2) the inefficiency of utilizing images due to the potential label noise. To solve these limitations, we propose a lane detection framework towards autonomous vehicles by learning a full-reference quality-aware discriminative gradient deep model, where two types of deep networks are proposed. More specifically, we first design a gradient-guided deep convolutional network to detect the presence of lane, since the gradient value of lane edge is larger than that of other regions. We leverage full-reference image quality assessment (FR-IQA) method to discover more discriminative gradient cues, and geometric attributes are exploited simultaneously. Subsequently, a recurrent neural layer is designed to represent the spatial distribution of detected lanes whose visual cues are difficult to explicitly define. Noticeably, we only utilize a small proportion of the labeled images, whereas the noisy features are abandoned using sparsity penalty. Extensive experiments have demonstrated the effectiveness of our proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Liu, Jingyi] Chongqing Coll Elect Engn, Sch Intelligent Mfg & Automobile, Chongqing, Peoples R China.
   [Liu, Jingyi] Peter Great St Petersburg Polytech Univ, Appl Math & Mech, St Petersburg, Russia.
C3 Chongqing College of Electronic Engineering; Peter the Great St.
   Petersburg Polytechnic University
RP Liu, JY (corresponding author), Chongqing Coll Elect Engn, Sch Intelligent Mfg & Automobile, Chongqing, Peoples R China.
EM liujy_ccee@126.com
RI xin, liang/JFS-5770-2023
FU Fund project: Research on Lightweight Innovation Technology of Electric
   Vehicle [XJZK201813]
FX This work was supported by Fund project: Research on Lightweight
   Innovation Technology of Electric Vehicle; Project (No. XJZK201813).
CR [Anonymous], 2016, IEEE Transactions on Intelligent Transportation Systems, DOI DOI 10.1109/TITS.2015.2464253
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Bezzine I, 2018, J VIS COMMUN IMAGE R, V57, P283, DOI 10.1016/j.jvcir.2018.10.025
   Cheng HY, 2006, IEEE T INTELL TRANSP, V7, P571, DOI 10.1109/TITS.2006.883940
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Cremean LB, 2006, IEEE INT CONF ROBOT, P1661, DOI 10.1109/ROBOT.2006.1641945
   Graves A., 2009, THESIS
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Haeusler R, 2009, 2009 24TH INTERNATIONAL CONFERENCE IMAGE AND VISION COMPUTING NEW ZEALAND (IVCNZ 2009), P448, DOI 10.1109/IVCNZ.2009.5378362
   Hinton G. E., 2012, IEEE SIGNAL PROCESSI, V29
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kaliyaperumal K, 2001, IEEE T VEH TECHNOL, V50, P170, DOI 10.1109/25.917913
   Karimi N, 2018, J VIS COMMUN IMAGE R, V55, P853, DOI 10.1016/j.jvcir.2018.04.001
   Kong H, 2009, PROC CVPR IEEE, P96, DOI 10.1109/CVPRW.2009.5206787
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li J, 2017, IEEE T NEUR NET LEAR, V28, P690, DOI 10.1109/TNNLS.2016.2522428
   Ma B, 2000, IEEE T INTELL TRANSP, V1, P135, DOI 10.1109/6979.892150
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Osberger W, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P414, DOI 10.1109/ICIP.1998.727227
   Sach LT, 2009, IEEE IMAGE PROC, P4273, DOI 10.1109/ICIP.2009.5413688
   Safranek R.J., 1989, PROC IEEE INT C ACOU, V3, P1945, DOI DOI 10.1109/ICASSP.1989.266837
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Takagi K, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P124
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan Jiang, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P114, DOI 10.1109/IASP.2010.5476151
   Yoo H, 2013, IEEE T INTELL TRANSP, V14, P1083, DOI 10.1109/TITS.2013.2252427
NR 30
TC 6
Z9 7
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102675
DI 10.1016/j.jvcir.2019.102675
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700018
DA 2024-07-18
ER

PT J
AU Yang, WW
AF Yang, Wenwei
TI Finite element model of concrete material based on CT image processing
   technology
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CT image; Numerical model; Concrete; Failure process
ID OBJECT DETECTION; HOLISTIC MODEL
AB With the development of concrete performance research, more and more attention has been paid to the study of concrete performance, resulting in a variety of micro-structure finite element models, such as lattice model, beam-particle model, random aggregate model, with the emergence of CT technology, the realization of the non-destructive state of concrete internal micro-structure with digital The rendering method is presented. If the real or near-real finite element model of meso-structure can be established by using the information of CT plane images, it will play a certain role in the numerical simulation of concrete. Concrete includes aggregate, cement mortar and pore three parts, from the image characteristics, aggregate close to white, pore tend to black, cement mortar is between the two. Because of the relative obvious density difference between aggregate, mortar and pore, after CT scanning and converting to image, each component of concrete has better contrast, and it is easier to observe and extract aggregate contour. In this paper, CT image processing technology is used to preprocess the section image of concrete cylinder specimens in order to obtain accurate aggregate geometry and position information. On this basis, the reconstructed micro-finite element model is simulated and simulated in MATLAB, and the results are compared with those of other finite element models. The results show that the finite element concrete micro-model can make up for the shortcomings of the traditional random aggregate concrete model, and better reflect the mechanical characteristics of concrete materials, which opens up a new way for the ultimate in-depth study of the micro-damage mechanism of concrete materials. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Yang, Wenwei] Minist Educ, Key Lab Mech Disaster & Environm Western China, Beijing, Peoples R China.
   [Yang, Wenwei] Lanzhou Univ, Sch Civil Engn & Mech, Lanzhou 730000, Gansu, Peoples R China.
C3 Lanzhou University
RP Yang, WW (corresponding author), Lanzhou Univ, Sch Civil Engn & Mech, Lanzhou 730000, Gansu, Peoples R China.
EM yangwenwei@lzu.edu.cn
FU Nation Natural Science Foundation of China [50808096, 50978128];
   Fundamental Research Funds for the Central Universities
   [lzujbky2015-173]
FX This work was financially supported by the Nation Natural Science
   Foundation of China (50808096, 50978128), and the Fundamental Research
   Funds for the Central Universities (lzujbky2015-173).
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Bian H, 2016, J MATER SCI, V51, P10066, DOI 10.1007/s10853-016-0233-9
   Boling H.E., 2016, ACTA MATERIAE COMPOS, V7, P220
   Cai M, 2016, COMPOS PART A-APPL S, V90, P589, DOI 10.1016/j.compositesa.2016.08.025
   Cho CG, 2015, ENG FAIL ANAL, V56, P320, DOI 10.1016/j.engfailanal.2015.01.009
   Gao H., 2016, FINITE ELEMENT ANAL
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Knezevic G, 2016, PERS INDIV DIFFER, V95, P214, DOI 10.1016/j.paid.2016.02.044
   Kumar M, 2017, INFORM SCIENCES, V418, P668, DOI 10.1016/j.ins.2017.08.048
   Liu XL, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-9008-0
   Manzanero AL, 2015, PAPEL PSICOL, V36, P125
   Montero-Chacón F, 2014, COMP MATER SCI, V90, P157, DOI 10.1016/j.commatsci.2014.03.066
   Nair D., 2017, J VIS COMMUN IMAGE R
   Petrova K., 2016, SIGNIFICANCE PUBLIC
   Pickering JD, 2016, MED TEACH, V38, P1242, DOI 10.1080/0142159X.2016.1210112
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Robinson OC, 2015, J ADULT DEV, V22, P38, DOI 10.1007/s10804-014-9199-5
   Sedgewick AJ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1039-0
   Tavares AA, 2016, POLYM TEST, V50, P26, DOI 10.1016/j.polymertesting.2015.11.020
   Wang JW, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2522380
   Xu LW, 2018, MOBILE NETW APPL, V23, P1496, DOI 10.1007/s11036-017-0982-y
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Zhang C, 2015, COMPOS STRUCT, V125, P104, DOI 10.1016/j.compstruct.2015.01.034
   Zhang H, 2016, IEEE T MED IMAGING, V35, P860, DOI 10.1109/TMI.2015.2498148
   Zhang M., 2018, J VIS COMMUN IMAGE R, P53
   Zhang WP, 2017, SAUDI J BIOL SCI, V24, P563, DOI 10.1016/j.sjbs.2017.01.027
   Zhang WY, 2017, ENERG CONVERS MANAGE, V136, P439, DOI 10.1016/j.enconman.2017.01.022
   Zhou Z., 2017, J GUANGXI U, V4, P73
NR 35
TC 15
Z9 15
U1 4
U2 49
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102631
DI 10.1016/j.jvcir.2019.102631
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600022
DA 2024-07-18
ER

PT J
AU Chen, ZL
   Wu, XW
AF Chen, Zhuolun
   Wu, Xiaowei
TI Research on regional energy efficiency based on GIS technology and image
   quality processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; GIS technology; Image quality analysis; Model; Quality
ID CHINA; POLICY; INNOVATION; VEHICLES; INDUSTRY; IMPACT
AB Economic development requires energy support, but the economy that relies too much on high energy consumption and high pollution is not sustainable. However, due to blind investment and low-level expansion of some new energy companies, some new energy industry has overcapacity and low production efficiency, slowing down the pace of new energy industry development, and limiting the development space of new energy companies. Thus, this paper is based on the GIS technology and image quality processing design improvement, around this idea, completed the new system simulation analysis, system development, experimental testing and so on. This paper focuses on the evaluation of the distribution efficiency of new energy industry based on image processing. Natural images have their own unique statistical properties, and interference can cause them to deviate from the original "natural statistical state." According to the image itself and the characteristics of the human visual system, the expression of the image is adjusted, which is more conducive to the transmission, storage and understanding of information. Therefore, this paper proposes a new energy industry distribution efficiency evaluation method based on GIS technology and image processing from three aspects of the nature of natural images, the expression of image information and the characteristics of human visual system. The research shows that the method can objectively and effectively evaluate the distribution efficiency of the new energy industry, and has certain practicability, which can effectively alleviate the bottleneck problems faced above. (C) 2019 Published by Elsevier Inc.
C1 [Chen, Zhuolun; Wu, Xiaowei] South China Univ Technol, Architectural Design & Res Inst, Sch Architecture, Guangzhou, Guangdong, Peoples R China.
   [Chen, Zhuolun] Tech Univ Denmark, Dept Technol Management & Econ, Copenhagen Ctr Energy Efficiency, UNEP DTU Partnership, Copenhagen, Denmark.
C3 South China University of Technology; Technical University of Denmark
RP Wu, XW (corresponding author), South China Univ Technol, Architectural Design & Res Inst, Sch Architecture, Guangzhou, Guangdong, Peoples R China.
EM arzlchen@scut.edu.cn; xwwu@scut.edu.cn
OI Chen, Zhuolun/0000-0001-5348-1117
FU National Scientific Fund [51108185, 51778235]; Province natural science
   fund of Guangdong [2016A030313513]; State Key Laboratory of Subtropical
   Building Science [2019ZA04, 2013KB24]; Guangzhou development and reform
   commission energy -saving special fund project (Technology research of
   regional energy based on the energy cascade utilization), Basic
   scientific research fund of South China University of Technology
   [2015ZM013]; fund of Guangdong modern architectural creation and
   engineering technology research centre [2016AZ28]
FX The research of this paper is funded by National Scientific Fund (No.
   51108185 and No. 51778235), Province natural science fund of Guangdong
   (No. 2016A030313513), State Key Laboratory of Subtropical Building
   Science (NO. 2019ZA04 and No. 2013KB24), Guangzhou development and
   reform commission energy -saving special fund project (Technology
   research of regional energy based on the energy cascade utilization),
   Basic scientific research fund of South China University of Technology
   (No. 2015ZM013) and fund of Guangdong modern architectural creation and
   engineering technology research centre (No. 2016AZ28).
CR Backman F, 2018, ENERGY RES SOC SCI, V42, P147, DOI 10.1016/j.erss.2018.03.027
   [陈国平 Chen Guoping], 2017, [中国电机工程学报, Proceedings of the Chinese Society of Electrical Engineering], V37, P20
   Chen Liuqin, 2012, ELECTRICITY, V33, P6
   Eichinger F. T., 1996, FUEL EN ABSTR, V6, P426
   Gong HM, 2013, MITIG ADAPT STRAT GL, V18, P207, DOI 10.1007/s11027-012-9358-6
   Hanley ND, 2006, RENEW ENERG, V31, P161, DOI 10.1016/j.renene.2005.08.023
   Javaid N., 2014, INT J DISTRIB SENS N, P224
   Juan Z, 2011, ENRGY PROCED, V5, P1003, DOI 10.1016/j.egypro.2011.03.177
   Kimble Chris, 2013, Journal of Business Strategy, V34, P13, DOI 10.1108/02756661311310413
   Koo C, 2014, ENERG POLICY, V68, P218, DOI 10.1016/j.enpol.2013.12.068
   Li WB, 2016, ENERG POLICY, V99, P33, DOI 10.1016/j.enpol.2016.09.050
   Li Ya, 2010, Journal of Plant Resources and Environment, V19, P73
   Liang S, 2011, ENERGY, V36, P6960, DOI 10.1016/j.energy.2011.09.013
   Lin J, 2008, ENERG POLICY, V36, P1090, DOI 10.1016/j.enpol.2007.11.019
   [刘胜强 Liu Shengqiang], 2012, [气候变化研究进展, Advances in Climate Change Research], V8, P48
   Liu XF, 2011, ENRGY PROCED, V5, P624, DOI 10.1016/j.egypro.2011.03.109
   Qiu CQ, 2016, ENERG CONVERS MANAGE, V119, P389, DOI 10.1016/j.enconman.2016.04.044
   Schot J, 2016, NAT ENERGY, V1, DOI 10.1038/NENERGY.2016.54
   Song H, 2009, PROCED EARTH PLAN SC, V1, P1712, DOI 10.1016/j.proeps.2009.09.262
   Wang QW, 2016, TECHNOL FORECAST SOC, V112, P254, DOI 10.1016/j.techfore.2016.04.019
   Wang ZL, 2015, ENERG ENVIRON SCI, V8, P2250, DOI 10.1039/c5ee01532d
   Wei YM, 2007, ENERGY, V32, P2262, DOI 10.1016/j.energy.2007.07.007
   Xia B, 2012, PHYSCS PROC, V25, P1277, DOI 10.1016/j.phpro.2012.03.233
   Yuan XL, 2015, RENEW SUST ENERG REV, V42, P298, DOI 10.1016/j.rser.2014.10.016
   Zhang X, 2017, RENEW SUST ENERG REV, V70, P24, DOI 10.1016/j.rser.2016.11.211
   Zhu G, 2015, NANO ENERGY, V14, P126, DOI 10.1016/j.nanoen.2014.11.050
NR 26
TC 3
Z9 3
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 410
EP 417
DI 10.1016/j.jvcir.2019.06.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science
GA IL0CB
UT WOS:000476962600038
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Revina, IM
   Emmanuel, WRS
AF Revina, I. Michael
   Emmanuel, W. R. Sam
TI Face Expression Recognition with the Optimization based Multi-SVNN
   Classifier and the Modified LDP Features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; MultiSVNN classifier; Grasshopper
   optimization algorithm; Whale optimization algorithm; Local Directional
   Pattern
AB Facial expression recognition (FER) is the interesting research area that enables us to recognize the expression of the human face in the day-to-day life. Most of the traditional methods fail to recognize the expressions accurately as the expressions are based on the movements of the parts in the human face. The paper proposes the effective method of FER using the proposed Whale- Grasshopper Optimization algorithm based Multi-Support Vector Neural Network (W-GOA-based MultiSVNN). The features from the facial image is extracted using the Scale-Invariant Feature Transform (SIFT) and the proposed Scatter Local Directional Pattern (SLDP). The extracted features are classified using the proposed classifier to recognize the expression of the face. The proposed method of facial recognition enhances the recognition accuracy. The experimentation of the proposed algorithm is performed using the databases, such as Cohn-Kanade AU-Coded Expression Database and The Japanese Female Facial Expression (JAFFE) Database. The proposed algorithm outperforms the existing methods in terms of the accuracy, TPR, and FPR and the values are found to be 0.96, 0.96, and 0.009, respectively. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Revina, I. Michael; Emmanuel, W. R. Sam] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Revina, IM (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM michaelrevina09@gmail.com
RI Revina, Michael/AAO-3279-2021; EMMANUEL, W R SAM/E-5526-2018
CR Agarwal S, 2017, MULTIMED TOOLS APPL, V76, P1073, DOI 10.1007/s11042-015-3103-6
   [Anonymous], 2015, 2015 International Joint Conference on Neural Networks (IJCNN)
   [Anonymous], 2016, IEEE T AFFECT COMPUT
   [Anonymous], 2017, MULTIMEDIA TOOLS APP
   Balntas V, 2018, IEEE T PATTERN ANAL, V40, P555, DOI 10.1109/TPAMI.2017.2679193
   Chakraborti T, 2017, Comput. vis. Pattern Recognition
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Ding YY, 2017, IEEE ACCESS, V5, P19409, DOI 10.1109/ACCESS.2017.2737821
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Duan Yueqi, 2017, P IEEE C COMP VIS PA
   Ghimire D, 2017, MULTIMED TOOLS APPL, V76, P7803, DOI 10.1007/s11042-016-3418-y
   Hao Guan, 2017, P IEEE C COMP VIS PA
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Khan SA, 2016, OPTIK, V127, P6195, DOI 10.1016/j.ijleo.2016.04.015
   Kim DH, 2008, PATTERN RECOGN LETT, V29, P1621, DOI 10.1016/j.patrec.2008.04.006
   Kumar S, 2016, IET COMPUT VIS, V10, P567, DOI 10.1049/iet-cvi.2015.0273
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Ludwig O, 2014, NEUROCOMPUTING, V124, P33, DOI 10.1016/j.neucom.2013.08.005
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Muttu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P102, DOI 10.1109/INFOP.2015.7489359
   Pandey N, 2016, 2016 INTERNATIONAL CONFERENCE ON EMERGING TRENDS IN ELECTRICAL ELECTRONICS & SUSTAINABLE ENERGY SYSTEMS (ICETEESES), P1, DOI 10.1109/ICETEESES.2016.7581342
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Sajjad M, 2018, CLUSTER COMPUT, V21, P549, DOI 10.1007/s10586-017-0935-z
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Sun N., 2017, PATTERN RECOGN LETT
   Tsai H-H, 2017, SOFT COMPUT, P1
   Uddin M. Z., 2017, COMPUT ELECT ENG
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yan HB, 2016, NEUROCOMPUTING, V208, P165, DOI 10.1016/j.neucom.2015.11.113
   Yin YL, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON MANUFACTURING ENGINEERING AND TECHNOLOGY FOR MANUFACTURING GROWTH (METMG 2017), P40, DOI 10.5729/metmg.2017.1.40
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
   Zhu YN, 2016, INT CONF SYST INFORM, P876, DOI 10.1109/ICSAI.2016.7811074
NR 34
TC 20
Z9 20
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 43
EP 55
DI 10.1016/j.jvcir.2019.04.013
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600004
DA 2024-07-18
ER

PT J
AU Anagun, Y
   Isik, S
   Seke, E
AF Anagun, Yildiray
   Isik, Sahin
   Seke, Erol
TI SRLibrary: Comparing different loss functions for super-resolution over
   various convolutional architectures
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Convolutional neural networks; Loss functions
ID NETWORKS
AB This study analyzes the effectiveness of various loss functions on performance improvement for Single Image Super-Resolution (SISR) using Convolutional Neural Network (CNN) models by surrogating the reconstructive map between Low Resolution (LR) and High Resolution (HR) images with convolutional filters. In total, eight loss functions are separately incorporated with Adam optimizer. Through experimental evaluations on different datasets, it is observed that some parametric and non-parametric robust loss functions promise impressive accuracies whereas remaining ones are sensitive to noise that misleads the learning process and consequently resulting in lower quality HR outcomes. Eventually, it turns out that the use of either Difference of Structural Similarity (DSSIM), Charbonnier or L1 loss functions within the optimization mechanism would be a proper choice, by considering their excellent reconstruction results. Among them, Charbonnier and Ll loss functions are fastest ones when the computational time cost is examined during training stage. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Anagun, Yildiray; Isik, Sahin] Eskisehir Osmangazi Univ, Dept Comp Engn, Meselik Campus, TR-26480 Eskisehir, Turkey.
   [Seke, Erol] Eskisehir Osmangazi Univ, Dept Elect & Elect Engn, Meselik Campus, TR-26480 Eskisehir, Turkey.
C3 Eskisehir Osmangazi University; Eskisehir Osmangazi University
RP Isik, S (corresponding author), Eskisehir Osmangazi Univ, Dept Comp Engn, Meselik Campus, TR-26480 Eskisehir, Turkey.
EM sahini@ogu.edu.tr
RI Anagun, Yildiray/AAH-6965-2021; isik, sahin/H-5373-2018
OI Anagun, Yildiray/0000-0002-7743-0709; isik, sahin/0000-0003-1768-7104
CR Agustsson Eirikur, 2017, IEEE CVF C COMP VIS, P126, DOI DOI 10.1109/CVPRW.2017.150
   Anagun Y., 2019, SRLIBRAY KERAS
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen B. H., 2017, IEEE T CIRC SYST VID
   Chen BH, 2018, IEEE T NEUR NET LEAR, V29, P3828, DOI 10.1109/TNNLS.2017.2741975
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Janocha Katarzyna., 2017, On Loss Functions for Deep Neural Networks in Classification
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai W-S, 2017, PROC CVPR IEEE, P624, DOI DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   OMalley T.a.B., 2019, KERASTUNER
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yin JL, 2018, IEEE T MULTIMEDIA, V20, P3045, DOI 10.1109/TMM.2018.2820910
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
NR 30
TC 44
Z9 46
U1 3
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 178
EP 187
DI 10.1016/j.jvcir.2019.03.027
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100019
DA 2024-07-18
ER

PT J
AU Luo, T
   Jiang, GY
   Yu, M
   Zhong, CM
   Xu, HY
   Pan, ZY
AF Luo, Ting
   Jiang, Gangyi
   Yu, Mei
   Zhong, Caiming
   Xu, Haiyong
   Pan, Zhiyong
TI Convolutional neural networks-based stereo image reversible data hiding
   method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network (CNN); Predictor; Prediction error
   expansion (PEE); Reversible data hiding (RDH); Stereo image
ID WATERMARKING SCHEME; DIFFERENCE EXPANSION; TRANSFORM
AB For copyright and integrity protection of stereo images, a stereo image reversible data hiding (SIRDH) method based on the convolutional neural network (CNN) is presented. To increase the pixel prediction, a CNN-based predictor is designed. Firstly, pixels are divided into two types. For predicting one type of pixels in one view, the other type of pixels in the same view is considered as the low-resolution (LR) image. Secondly, a LR difference view between the LR image and the other view is computed, since the difference view consists of the texture and depth information. Then, CNN is trained to recover the high-precision difference view from the LR difference view, and the high-resolution image is computed to predict pixels accurately. Moreover, the prediction error expansion (PEE) is employed to embed data. Experimental results show that the proposed method is superior to existing SIRDH methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Luo, Ting; Zhong, Caiming; Xu, Haiyong] Ningbo Univ, Coll Sci & Technol, Ningbo 315212, Zhejiang, Peoples R China.
   [Jiang, Gangyi; Yu, Mei; Xu, Haiyong; Pan, Zhiyong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University; Ningbo University
RP Jiang, GY; Yu, M (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM jianggangyi@126.com; yumei2@126.com
RI Zhong, Caiming/GYD-5551-2022; jiang, gang/KII-8233-2024
OI Zhong, Caiming/0000-0001-5126-8849
FU Natural Science Foundation of China [61501270, 61671258, 61871247];
   National High-tech R&D Program of China [2015AA015901]; Zhejiang
   Provincial Natural Science Foundation of China [LY19F020009]; K. C. Wong
   Magna Fund in Ningbo University
FX This work was supported by Natural Science Foundation of China under
   Grant No. 61501270, 61671258, 61871247, National High-tech R&D Program
   of China under Grant No. 2015AA015901, Zhejiang Provincial Natural
   Science Foundation of China under Grant No. LY19F020009. It was also
   sponsored by the K. C. Wong Magna Fund in Ningbo University.
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Arham A, 2017, SIGNAL PROCESS, V137, P52, DOI 10.1016/j.sigpro.2017.02.001
   Cao F, 2019, MULTIMED TOOLS APPL, V78, P7911, DOI 10.1007/s11042-018-6031-4
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen Y, 2018, C IND ELECT APPL, P1553, DOI 10.1109/ICIEA.2018.8397956
   El Jaafari I, 2017, SIGNAL IMAGE VIDEO P, V11, P267, DOI 10.1007/s11760-016-0932-3
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Gan WH, 2018, J VIS COMMUN IMAGE R, V53, P180, DOI 10.1016/j.jvcir.2018.03.016
   Gao P, 2017, IEEE T IMAGE PROCESS, V26, P2781, DOI 10.1109/TIP.2017.2690058
   Garg P, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501031
   Han TY, 2018, J VIS COMMUN IMAGE R, V51, P191, DOI 10.1016/j.jvcir.2018.01.018
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   He WG, 2018, OPTIK, V157, P68, DOI 10.1016/j.ijleo.2017.08.008
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Hiary S, 2017, MULTIMED TOOLS APPL, V76, P2131, DOI 10.1007/s11042-015-3161-9
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hou DD, 2018, SIGNAL PROCESS, V148, P41, DOI 10.1016/j.sigpro.2018.02.002
   Hwang DC, 2004, P SOC PHOTO-OPT INS, V5600, P182, DOI 10.1117/12.573832
   Hwang DC, 2003, P SOC PHOTO-OPT INS, V5241, P233, DOI 10.1117/12.511615
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Jiang QP, 2018, IEEE T CYBERNETICS, V48, P1276, DOI 10.1109/TCYB.2017.2690452
   Jung KH, 2018, J REAL-TIME IMAGE PR, V14, P159, DOI 10.1007/s11554-016-0618-7
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Karine A, 2018, J VIS COMMUN IMAGE R, V50, P27, DOI 10.1016/j.jvcir.2017.11.006
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khelifi F, 2018, SIGNAL PROCESS, V143, P336, DOI 10.1016/j.sigpro.2017.09.020
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Le L, 2016, 2016 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING, APPLICATIONS AND TECHNOLOGIES (BDCAT), P1, DOI 10.1145/3006299.3006312
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu J., 2017, NEW SMVQ BASED REVER, P539
   Liu XY, 2017, SIGNAL PROCESS-IMAGE, V54, P140, DOI 10.1016/j.image.2017.03.002
   Lu C., 2018, P 3 INT C MULT SYST, P56
   Luo H, 2011, INFORM SCIENCES, V181, P308, DOI 10.1016/j.ins.2010.09.022
   Luo T, 2018, MULTIMED TOOLS APPL, V77, P19027, DOI 10.1007/s11042-017-5356-8
   Luo T, 2014, IEEE IMAGE PROC, P5492, DOI 10.1109/ICIP.2014.7026111
   Luo T, 2016, DIGIT SIGNAL PROCESS, V48, P116, DOI 10.1016/j.dsp.2015.09.007
   Luo T, 2014, MULTIMED TOOLS APPL, V73, P1077, DOI 10.1007/s11042-013-1435-7
   Ma L, 2016, NEUROCOMPUTING, V215, P21, DOI 10.1016/j.neucom.2015.06.116
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Pan ZY, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7060526
   Qian ZX, 2016, J VIS COMMUN IMAGE R, V40, P732, DOI 10.1016/j.jvcir.2016.08.020
   Qiu YQ, 2018, J VIS COMMUN IMAGE R, V52, P86, DOI 10.1016/j.jvcir.2018.02.005
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schnev V., 2010, IEEE T CIRCUITS SYST, V5, P187
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang WQ, 2018, SIGNAL PROCESS, V150, P102, DOI 10.1016/j.sigpro.2018.04.008
   Wu H.-Z., 2016, PROC ACM WORKSHOP IN, P187
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Xu DW, 2017, J VIS COMMUN IMAGE R, V45, P34, DOI 10.1016/j.jvcir.2017.02.008
   Xu JJ, 2017, MULTIMED TOOLS APPL, V76, P3829, DOI 10.1007/s11042-016-3989-7
   Xue BW, 2017, MULTIMED TOOLS APPL, V76, P13473, DOI 10.1007/s11042-016-3763-x
   Yang WC, 2015, MULTIMED TOOLS APPL, V74, P7181, DOI 10.1007/s11042-014-1958-6
   Yin JH, 2017, PATTERN RECOGN, V71, P278, DOI 10.1016/j.patcog.2017.06.015
   Zhang YS, 2016, NEUROCOMPUTING, V205, P472, DOI 10.1016/j.neucom.2016.04.053
   2013, J SYST SOFTW, V86, P2620, DOI DOI 10.1016/J.JSS.2013.04.086
NR 63
TC 16
Z9 17
U1 1
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 61
EP 73
DI 10.1016/j.jvcir.2019.03.017
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100007
DA 2024-07-18
ER

PT J
AU Ma, CY
   Liu, D
   Peng, XL
   Li, L
   Wu, F
AF Ma, Changyue
   Liu, Dong
   Peng, Xiulian
   Li, Li
   Wu, Feng
TI Traffic surveillance video coding with libraries of vehicles and
   background
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Background; High Efficiency Video Coding (HEVC); Library-based coding;
   Traffic surveillance video; Vehicle
ID FRAME MOTION COMPENSATION; TERM REFERENCE FRAME; SELECTION; PREDICTION;
   HEVC
AB This paper presents a video coding scheme tailored for traffic surveillance videos, which features a prebuilt library that is utilized in both encoder and decoder to pursue higher compression efficiency. We are motivated by the observation that, in traffic surveillance videos, not only the background is steady for a long while, but also the foreground (e.g. vehicles) contains high redundancy. For example, in the video taken by a traffic monitoring camera, we can observe that the passing-through vehicles are usually similar. However, the redundancy in the vehicles and the background is not fully exploited in the current video coding schemes. To address this problem, we propose a library-based video coding scheme. Specifically, for each static monitoring camera, we can collect video in a period, and build a library of vehicles and background from that video. When encoding the following video of that camera, we utilize the pre-built library by searching similar vehicles and background from the library and using the retrieved vehicles and background to help encode. Accordingly, the decoder also refers to the same library to reconstruct the video. We design efficient algorithms for building the library, searching in the library, as well as utilizing the library for encoding/decoding, to fulfill the proposed scheme. Our scheme is implemented upon the state-of-the-art video coding system-High Efficiency Video Coding (HEVC), and is tested on our own collected traffic surveillance videos. Experimental results show that, compared to the HEVC anchor, our proposed scheme achieves as high as 47.0%, 37.1%, and 34.8% BD-rate reduction, under random-access, low-delay B, and low-delay P settings, respectively. Our scheme also achieves higher compression efficiency than the existing background-based methods for surveillance video coding. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ma, Changyue; Liu, Dong; Wu, Feng] Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
   [Peng, Xiulian] Microsoft Res Asia, Beijing 100080, Peoples R China.
   [Li, Li] Univ Missouri, 5100 Rockhill Rd, Kansas City, MO 64111 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Microsoft Research Asia; Microsoft; University of Missouri
   System; University of Missouri Kansas City
RP Liu, D (corresponding author), Univ Sci & Technol China, CAS Key Lab Technol Geospatial Informat Proc & Ap, Hefei 230027, Anhui, Peoples R China.
EM dongeliu@ustc.edu.cn
RI Liu, Dong/K-7488-2012; Wu, Feng/KCY-3017-2024
OI Liu, Dong/0000-0001-9100-2906
FU National Key Research and Development Plan [2016YFC0801001]; Natural
   Science Foundation of China [61390512, 61425026, 61632001]
FX This work was supported by the National Key Research and Development
   Plan under Grant 2016YFC0801001, and by the Natural Science Foundation
   of China under Grants 61390512, 61425026, and 61632001.
CR Aizawa K., 1989, Signal Processing: Image Communication, V1, P139, DOI 10.1016/0923-5965(89)90006-4
   [Anonymous], PICT COD S
   [Anonymous], MOTION ANAL IMAGE SE
   [Anonymous], 6 M JOINT COLL TEAM
   Babu R. V., 2006, INT C CONTROL AUTOMA, P1
   Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Chellappa V, 2003, CONF REC ASILOMAR C, P1539
   Chellappa V, 2008, IEEE T CIRC SYST VID, V18, P249, DOI 10.1109/TCSVT.2008.916575
   Chen FD, 2017, IEEE T CIRC SYST VID, V27, P2639, DOI 10.1109/TCSVT.2016.2593599
   Chu WQ, 2018, IEEE T IMAGE PROCESS, V27, P432, DOI 10.1109/TIP.2017.2762591
   Gorur P, 2014, IEEE T CIRC SYST VID, V24, P1156, DOI 10.1109/TCSVT.2014.2319611
   Hakeem A., 2005, 13th Annual ACM International Conference on Multimedia, P608, DOI 10.1145/1101149.1101289
   Haque M, 2008, INT C PATT RECOG, P1001
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Liu D, 2010, IEEE T CIRC SYST VID, V20, P325, DOI 10.1109/TCSVT.2009.2031442
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma CY, 2017, IEEE IMAGE PROC, P270, DOI 10.1109/ICIP.2017.8296285
   Paul M, 2014, IEEE T CIRC SYST VID, V24, P1729, DOI 10.1109/TCSVT.2014.2302555
   Paul M, 2011, IEEE T CIRC SYST VID, V21, P1242, DOI 10.1109/TCSVT.2011.2138750
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song XD, 2015, IEEE T CIRC SYST VID, V25, P1926, DOI 10.1109/TCSVT.2015.2416562
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tiwari M, 2008, IEEE SIGNAL PROC LET, V15, P249, DOI 10.1109/LSP.2007.914928
   Tsai TH, 2012, IEEE T MULTIMEDIA, V14, P669, DOI 10.1109/TMM.2011.2180705
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiao J, 2016, IEEE T MULTIMEDIA, V18, P1691, DOI 10.1109/TMM.2016.2581590
   Xiao J, 2015, IEEE DATA COMPR CONF, P33, DOI 10.1109/DCC.2015.37
   Yin LM, 2015, LECT NOTES COMPUT SC, V9314, P212, DOI 10.1007/978-3-319-24075-6_21
   Yue HJ, 2013, IEEE T MULTIMEDIA, V15, P845, DOI 10.1109/TMM.2013.2239629
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P4511, DOI 10.1109/TIP.2014.2352036
   Zhang XG, 2014, IEEE T IMAGE PROCESS, V23, P769, DOI 10.1109/TIP.2013.2294549
   Zuo XG, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043026
   Zuo XG, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P100, DOI 10.1109/PCS.2015.7170055
NR 36
TC 11
Z9 15
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 426
EP 440
DI 10.1016/j.jvcir.2019.03.009
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000046
DA 2024-07-18
ER

PT J
AU Tian, MW
   Yan, SR
   Tian, XX
   Liu, JA
AF Tian, Man-Wen
   Yan, Shu-Rong
   Tian, Xiao-Xiao
   Liu, Jing-Ai
TI Research on image recognition method of bank financing bill based on
   binary tree decision
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Finance bill; Mode identification; Image processing; Binary decision
   tree
AB Financial paper is a note without reason debt or consideration acceptance, issued for obtaining money financing. Financial paper identification system is a hot issue of the current file analysis and identification system, it covers paper classification, image processing, character segmentation and identification, file image compression and other series of processes. A research on multiple aspects of financial paper identification system is made in this paper. On which basis, a financial paper identification system with applied value is established. Through substantive experimental test and practical application, the method has better classification performance and higher processing efficiency, and has been used in bank bill identification processing system in a large scale. (C) 2018 Published by Elsevier Inc.
C1 [Tian, Man-Wen; Yan, Shu-Rong; Tian, Xiao-Xiao] Yango Univ, Res Inst Intellectual Finance, Fuzhou 350015, Fujian, Peoples R China.
   [Liu, Jing-Ai] Shandong Agr & Engn Univ, Jinan, Shandong, Peoples R China.
C3 Shandong Agriculture & Engineering University
RP Liu, JA (corresponding author), Shandong Agr & Engn Univ, Jinan, Shandong, Peoples R China.
EM yan6293@126.com
FU Key Project of the National Social Science Fundation [18AJY013];
   National Social Science foundation project [17CJY072]; Fujian Social
   Science Planning Project [FJ2018B067]; planning project of philosophy
   and social science of zhejiang province [18NDJC086YB]
FX This work was financially supported by the Key Project of the National
   Social Science Fundation of the year 2018 (18AJY013); the 2017 National
   Social Science foundation project (17CJY072); the 2018 planning project
   of philosophy and social science of zhejiang province (18NDJC086YB); the
   2018 Fujian Social Science Planning Project (FJ2018B067).
CR Bo Wang, 2015, ACTA OPTICA SINICA, V35
   Guang Wang, 2016, J AGR ENG, V32
   Guo Dongmin, 2015, LASER J, V36
   Han Ding, 2016, J AGR ENG, V32
   Huang Xuebin, 2014, COMPUT SIMUL, V31
   Jiang Lihui, 2003, ACTA OPTICA SINICA, V23
   Li Xiaofeng, 2011, INFRARED LASER ENG, V40
   Li Xiaofeng, 2010, CHINA LASER, V37
   Li Ziqin, 2004, CHINA LASER, V31
   Li Ziqin, 2003, INFRARED LASER ENG, V32
   Li Ziqin, 2003, CHINA LASER, V30
   Liang Xiaowei, 2014, PROG LASER OPTOELECT, V51
   Liu Zhengqing, 2007, LASER INFRARED, V37
   Liu Zhonghua, 2014, J SHANGHAI I ELECT E, V17
   Mao Wentao, 2016, COMPUT APPL, V36
   Sun Hua-yan Deed, 2009, LASER INFRARED, V39
   Wang Canjin, 2014, OPT PRECIS ENG, V22
   Wang Xiangke, 2008, INFRARED LASER ENG, V37
   Wu Yihong, 2016, J CHONGQING U TECHNO, P30
   Xu Weiran, 2002, CHIN J INF, V16
   Yan Weizhong, 2015, LASER J, V36
   Zhang Lihong, 2012, LASER J, V33
   Zhang Xiang, 2004, SIGNAL PROCESS, V20
NR 23
TC 10
Z9 11
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 123
EP 128
DI 10.1016/j.jvcir.2018.12.016
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000015
DA 2024-07-18
ER

PT J
AU Zhu, SG
   Fang, ZY
   Wang, Y
   Yu, J
   Du, JP
AF Zhu, Suguo
   Fang, Zhenying
   Wang, Yi
   Yu, Jun
   Du, Junping
TI Multimodal activity recognition with local block CNN and attention-based
   spatial weighted CNN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Activity recognition; Multimodal; Visual attention
AB Deep learning based human activity recognition approach combines spatial and temporal information to complete the recognition task. The temporal information is extracted by optical flow, which is always compensated by the warping method in order to achieve better performance. However, these methods usually take the global feature as the starting point, only consider global information of video frames, and ignore local information that reflects the changes of human behavior, causing the algorithm to be sensitive to the external environment such as occlusion, illumination change. In view of the above problems, this paper fuses the local spatial features of video frames, global spatial features and temporal features to recognize different actions, and further extracts the visual attention weight to make constraint on the global spatial features. Experiments show that the algorithm proposed in this paper has better accuracy compared with the existing methods. (C) 2018 Published by Elsevier Inc.
C1 [Zhu, Suguo; Fang, Zhenying; Yu, Jun] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Key Lab Complex Syst Modeling & Simulat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Wang, Yi] Zhejiang Univ City Coll, Artist Design & Creat Sch, Dept Visual Commun Design, Hangzhou 310000, Zhejiang, Peoples R China.
   [Du, Junping] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou City University; Beijing University
   of Posts & Telecommunications
RP Wang, Y (corresponding author), Zhejiang Univ City Coll, Artist Design & Creat Sch, Dept Visual Commun Design, Hangzhou 310000, Zhejiang, Peoples R China.
EM wangyi@zucc.edu.cn
RI ARSLAN, Okan/AAA-3232-2020
FU National Natural Science Foundation of China [6147210, 61501349,
   61601158, 61602136]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61472110 and Grant 61772161, by the
   National Natural Science Foundation of China under Grants 6147210,
   61501349, 61501349, 61601158, and 61602136.
CR [Anonymous], 2018, IEEE T PATTERN ANAL
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fernando B, 2015, PROC CVPR IEEE, P5378, DOI 10.1109/CVPR.2015.7299176
   Girdhar R., ATTENTIONAL POOLING
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jing  P., IEEE T CIRC SYST VID
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Ni BB, 2015, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2015.7298993
   Nie LQ, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2963105
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Peng XJ, 2016, COMPUT VIS IMAGE UND, V150, P109, DOI 10.1016/j.cviu.2016.03.013
   Sevilla-Lara L., INTEGRATION OPTICAL
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Song S., END TO END SPATIO TE
   Soomro K., COMPUT SCI
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Zang JL, 2018, IFIP ADV INF COMM TE, V519, P97, DOI 10.1007/978-3-319-92007-8_9
NR 28
TC 4
Z9 4
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 38
EP 43
DI 10.1016/j.jvcir.2018.12.026
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000005
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Lin, YP
AF Zhang, Yue
   Lin, Yaping
TI An interactive method for identifying the stay points of the trajectory
   of moving objects
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Trajectory; Stay point; Space-time cube
ID VISUALIZATION; DEEP
AB The stay points of trajectory include important semantic information. Identifying the stay points is an indispensable step for mining and analyzing the trajectory data. Current methods for identifying stay points generally require pre-setting thresholds, which have a major impact on the identification results. Meanwhile, the setting of these thresholds is heavily reliant on empirical experience. There are many types of moving objects, such as vehicles, ships, airplanes, people and animals. These moving objects have a large variation in their trajectory data due to their different geometric/physical properties and navigation environments. Therefore, setting the appropriate thresholds for the identification process is by no means easy for non-professionals. To cope with this challenge, an interactive visualization method is suggested in this paper in order to help users to set the thresholds. In the proposed method, the Space-Time Cube (STC) is used to visualize the trajectory as the first step. In the next step, users interactively choose the typical stay points of the trajectory. The threshold is atomically determined using the geometric characteristics of the 3-dimensional bounding box of the space where the moving object stays on. Finally, the sliding window method is used to extract the stay points. Experimental results demonstrate that the proposed method is an efficient method for determining the thresholds in an intuitive and fast manner. As a result, it can significantly improve the efficiency of identifying the stay points of the trajectory for non-professionals. (C) 2019 Published by Elsevier Inc.
C1 [Zhang, Yue; Lin, Yaping] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Zhang, Yue] Hunan Police Acad, Dept Informat Technol, Changsha 410138, Hunan, Peoples R China.
C3 Hunan University
RP Zhang, Y (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.; Zhang, Y (corresponding author), Hunan Police Acad, Dept Informat Technol, Changsha 410138, Hunan, Peoples R China.
EM zhengzhang137@126.com
CR Alvares L. O., 2007, P 15 ANN ACM INT S A, P22
   Andrienko G., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P213, DOI 10.1109/VAST.2010.5653580
   [Anonymous], P 16 ACM SIGSPATIAL
   Chen  Jinhai, 2012, CHINA WATER TRANSP, V35, P53
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Gao Qiang, 2017, Journal of Software, V28, P959, DOI 10.13328/j.cnki.jos.005143
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Kraak M.-J., 2003, P 21 INT CARTOGRAPHI, P1988, DOI [10. 1007 / 3 - 540 - 26772 - 7_15, DOI 10.1007/3-540-26772-7_15]
   Lundblad P, 2009, INFORMATION VISUALIZATION, IV 2009, PROCEEDINGS, P379, DOI 10.1109/IV.2009.38
   [牟乃夏 Mou Naixia], 2018, [测绘通报, Bulletin of Surveying and Mapping], P1
   Palma AT, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P863
   Rocha J.A.M., 2010, 2010 5 IEEE INT C IN, P114, DOI DOI 10.1109/IS.2010.5548396
   Scheepens R, 2014, IEEE PAC VIS SYMP, P17, DOI 10.1109/PacificVis.2014.13
   STOPHER PR, 2005, 2 INT C BEH FDN INT
   Tominski C, 2012, IEEE T VIS COMPUT GR, V18, P2565, DOI 10.1109/TVCG.2012.265
   Tran L. H., 2012, ROBUST HIERARCHICAL
   Willems N, 2011, COMPUT GRAPH FORUM, V30, P801, DOI 10.1111/j.1467-8659.2011.01929.x
   Willems N, 2009, COMPUT GRAPH FORUM, V28, P959, DOI 10.1111/j.1467-8659.2009.01440.x
   [向隆刚 Xiang Longgang], 2016, [测绘学报, Acta Geodetica et Cartographica Sinica], V45, P1122
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zhang ZH, 2010, RES TRAVEL INFORM EX
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
   Zheng  Zhentao, J COMPUT APPL
   Zimmermann M, 2009, COMM COM INF SC, V53, P275
NR 34
TC 7
Z9 8
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 387
EP 392
DI 10.1016/j.jvcir.2019.01.038
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600040
DA 2024-07-18
ER

PT J
AU Chen, J
   He, MF
   Zeng, TS
AF Chen, Jian
   He, Minfan
   Zeng, Taishan
TI A multiscale Galerkin method for second-order boundary value problems of
   Fredholm integro-differential equation II: Efficient algorithm for the
   discrete linear system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiscale Galerkin method (MGM); Multilevel augmentation method (MAM);
   Boundary value problems; Fredholm integro-differential equation
ID MULTILEVEL AUGMENTATION METHODS
AB A multiscale Galerkin method (MGM) was proposed recently by the same authors in order to solve second-order boundary value problems of Fredholm integro-differential equation. Although, the numerical solution of MGM is always stable because of the multiscale bases properties, obligatory of considerable computational cost and huge memory for achieving great approximation accuracy, are the main draw backs. To overcome MGM problems, in this paper, a new multilevel augmentation method (MAM) in order to solve discrete linear system is proposed. Applying the special matrix splitting techniques, approximate solution is obtained by (1) solving a linear system only at an initial lower level; (2) compensating the error by directly computing the product of matrices and vectors at the higher level without any iterations. Theoretical and experimental results approve that MAM and MGM have similar and optimum convergence orders, though MAM is more efficient than MGM. (C) 2018 Published by Elsevier Inc.
C1 [Chen, Jian; He, Minfan] Foshan Univ, Dept Math, Foshan 528000, Peoples R China.
   [Zeng, Taishan] South China Normal Univ, Sch Math Sci, Guangzhou 510631, Guangdong, Peoples R China.
C3 Foshan University; South China Normal University
RP Chen, J (corresponding author), Foshan Univ, Dept Math, Foshan 528000, Peoples R China.
EM chenjian704@163.com
FU Natural Science Foundation of China [11501106, 11226303, 11671159];
   Guangdong Natural Science Foundation [2016A030313835, 2015A030313373];
   Training Programme Foundation for Excellent Young Scholar of Guang-dong
   Province [YQ2015164]; Characteristic Innovation Project from the
   Educational Department of Guangdong Province [2016KTSCX024]; Science and
   Technology Innovation Commission of Shenzhen [JCYJ20150630114942315]
FX This work has been supported in part by the Natural Science Foundation
   of China under grant 11501106, 11226303, 11671159, by the Guangdong
   Natural Science Foundation 2016A030313835, 2015A030313373, by the
   Training Programme Foundation for Excellent Young Scholar of Guang-dong
   Province under grant YQ2015164, by the Characteristic Innovation Project
   from the Educational Department of Guangdong Province under grant
   2016KTSCX024, and by the Science and Technology Innovation Commission of
   Shenzhen under grants JCYJ20150630114942315.
CR Chen J, 2015, J COMPUT APPL MATH, V290, P633, DOI 10.1016/j.cam.2015.06.020
   Chen J, 2015, NUMER METH PART D E, V31, P1665, DOI 10.1002/num.21966
   Chen JA, 2011, COMPUT MATH APPL, V61, P612, DOI 10.1016/j.camwa.2010.12.007
   Chen XL, 2011, SIAM J NUMER ANAL, V49, P2231, DOI 10.1137/100807600
   Chen Z., 2005, Num. Math. Jl. Chinese Univ, V14, P31
   Chen ZY, 2006, ADV COMPUT MATH, V24, P213, DOI 10.1007/s10444-004-4092-6
   Chen ZY, 2001, J MATH ANAL APPL, V262, P688, DOI 10.1006/jmaa.2001.7599
   Long GQ, 2014, APPL MATH COMPUT, V246, P638, DOI 10.1016/j.amc.2014.08.058
   Xue Q, 2018, INT J COMPUT MATH, V95, P1015, DOI 10.1080/00207160.2017.1322201
   Yulan W, 2009, J COMPUT APPL MATH, V229, P1, DOI 10.1016/j.cam.2008.10.007
NR 10
TC 16
Z9 16
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 112
EP 118
DI 10.1016/j.jvcir.2018.11.027
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100012
DA 2024-07-18
ER

PT J
AU Huang, FH
   Yu, Y
   Feng, TH
AF Huang, Fenghua
   Yu, Ying
   Feng, Tinghao
TI Hyperspectral remote sensing image change detection based on tensor and
   deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tensor model; Deep learning; Support tensor machine; Hyperspectral
   remote sensing images; Change detection
AB Considering the bottleneck in improving the performance of the existing multi-temporal hyperspectral remote sensing (HSRS) image change detection methods, a HSRS image change detection solution based on tensor and deep learning is proposed in this study. At first, a tensor-based information model (TFS-Cube) of underlying features change in HSRS images is established. The wavelet texture feature change, spectral feature change and spatio-temporal autocorrelation coefficient of different-temporal related pixels are combined with three-order tensor, so as to make full use of the underlying features change information of HSRS images, optimize the organization mode and maintain the integrity of constraints between different underlying features. Secondly, a restricted Boltzmann Machine based on three-order tensor (Tensor3-RBM) is designed. The input, output and unsupervised learning of TFS-Cube tensor data are realized by multi-linear operations in Tensor3-RBMs. A large number of unlabeled samples are trained layer by layer through multilayer Tensor3-RBMs. Finally, the traditional BP neural network on the top layer of deep belief network (DBN) is replaced with support tensor machine (STM), and a deep belief network with multi-layer Tensor3-RBM and STM (TRS-DBN) is constructed. A small number of labeled samples are used for supervised learning and TRS-DBN global parameters optimization to improve the accuracy of TRS-DBN change detection. Two types of HSRS images from different sensors, AVIRIS and EO-1 Hyperion, are used as the data sources (double-temporal). Four representative experimental regions are randomly selected from the two areas covered by AVIRIS and EO-1 Hyperion HSRS images respectively (two regions in each area) to detect the land use changes. Experimental results demonstrate that TRS-DBN has higher change detection accuracy than similar methods and a good automation level. (C) 2018 Published by Elsevier Inc.
C1 [Huang, Fenghua; Yu, Ying] Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Fenghua; Yu, Ying] Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
   [Feng, Tinghao] Univ N Carolina, Coll Comp & Informat, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Huang, FH (corresponding author), Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
EM fenghuait@sina.com; thfeng@uncc.edu
RI Feng, Tinghao/JWO-1400-2024
OI Feng, Tinghao/0000-0003-2765-2765
FU National Natural Science Foundation of China (NSFC) [41501451]; Program
   for New Century Excellent Talents in Fujian Province Universities
   [MinjiaoKe [2016]23]; Program for Outstanding Youth Scientific Research
   Talents in Fujian Province Universities [MinjiaoKe [2015]54]
FX This work was funded by the National Natural Science Foundation of China
   (NSFC, 41501451), the Program for New Century Excellent Talents in
   Fujian Province Universities (MinjiaoKe [2016]23) and the Program for
   Outstanding Youth Scientific Research Talents in Fujian Province
   Universities (MinjiaoKe [2015]54). The authors would like to thank
   Zhengyuan Mao and Yinan He for their assistance, suggestions, and
   discussions.
CR [Anonymous], 2007, BEIJING SURV MAP, DOI DOI 10.19580/J.CNKI.1007-3000.2007.03.006
   [Anonymous], INSTRUM TECHN SENS
   [Anonymous], 2016, INT J EARTH SCI ENG
   [Anonymous], COMPUT APPL SOFTW
   Bezdek J. C., 2002, LECT NOTES COMPUT SC, V4, P288
   Borah S, 2007, J FOOD ENG, V79, P629, DOI 10.1016/j.jfoodeng.2006.02.022
   Cai Y. Y., 2010, W CHINA EXPLORAT ENG, V7, P131
   Chen H. J., 2014, China Patent, Patent No. [201410039584.3, 201410039584]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Du Q., 2012, 4 WORKSH HYP IM SIGN
   Erttirk A., 2017, IEEE GEOSCI REMOTE S, V6, P1252
   Guo D.J., 2005, FORESTRY MACHINERY W, V7, P21, DOI [10.3969/j.issn.2095-2953.2005.07.008, DOI 10.3969/J.ISSN.2095-2953.2005.07.008]
   Guo X., 2015, TENSOR BASED IMAGE N
   Guo X., 2013, ACTA GEOD CARTOGR SI, V2, P267
   [何宇婷 HE Yuting], 2008, [遥感技术与应用, Remote Sensing Technology and Application], V23, P571
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang C, 2002, INT J REMOTE SENS, V23, P725, DOI 10.1080/01431160110040323
   [黄恺 Huang Kai], 2016, [遥感信息, Remote Sensing Information], V31, P37
   [黄昕 HUANG Xin], 2006, [武汉大学学报. 信息科学版, Geomatics and information science of wuhan university.], V31, P66
   Jiang B. T., 2012, Patent No. [China Patent, 201210247785. 3, 201210247785]
   Kamarianakis Y, 2005, COMPUT GEOSCI-UK, V31, P119, DOI 10.1016/j.cageo.2004.05.012
   Li Xiaolong, 2014, Journal of Frontiers of Computer Science and Technology, V8, P305, DOI 10.3778/j.issn.1673-9418.1306023
   [陆成韬 Lu Chengtao], 2016, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V29, P633
   Lu D, 2004, INT J REMOTE SENS, V25, P2365, DOI 10.1080/0143116031000139863
   [吕启 Lu Qi], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P1911
   MA WY, 1995, P IEEE INT C IM PROC
   Manian V, 1998, PATTERN RECOGN, V31, P1937, DOI 10.1016/S0031-3203(98)00053-3
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Qi GL, 2016, IEEE IJCNN, P389, DOI 10.1109/IJCNN.2016.7727225
   REYNOLDS KM, 1988, PHYTOPATHOLOGY, V78, P240, DOI 10.1094/Phyto-78-240
   Sun Y. F., 2017, China Patent, Patent No. [201710141534. X, 201710141534]
   [王宇红 Wang Yuhong], 2016, [化工学报, CIESC Journal], V67, P5163
   Wang ZZ, 2008, IEEE T IMAGE PROCESS, V17, P1421, DOI 10.1109/TIP.2008.926150
   Wu C, 2013, IEEE J-STARS, V6, P815, DOI 10.1109/JSTARS.2013.2241396
   [武辰 Wu Chen], 2012, [遥感学报, Journal of Remote Sensing], V16, P545
   Yoo HY, 2009, INT J REMOTE SENS, V30, P6219, DOI 10.1080/01431160902842359
   [曾奎 Zeng Kui], 2014, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V50, P219
   Zhang L. F., 2013, TENSOR REPRESENTATIO
   Zhao L, 2012, J CENTRAL S U SCI TE, V10, P365
NR 39
TC 58
Z9 62
U1 1
U2 66
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 233
EP 244
DI 10.1016/j.jvcir.2018.11.004
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100024
DA 2024-07-18
ER

PT J
AU Wang, B
   Tang, S
   Xiao, JB
   Yan, QF
   Zhang, YD
AF Wang, Bin
   Tang, Sheng
   Xiao, Jun-Bin
   Yan, Quan-Feng
   Zhang, Yong-Dong
TI Detection and tracking based tubelet generation for video object
   detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Tubelet generation; Tubelet fusion
AB Video object detection (VID) is a more challenging task compared with still-image object detection, which not only needs to detect objects accurately per frame but also needs to track objects for a long period of time. In order to detect objects from videos, we propose a Detection And Tracking (DAT) based tubelet generation framework. Under this framework, we first propose a detection-based tubelet generation method which can generate tubelets with more accurate bounding boxes compared with traditional tracking-based methods. On the other hand, the latter can produce a higher recall of bounding boxes than the former in general. To take advantage of their complementary attributes, we further propose a novel tubelet fusion method to combine these multi-modal information (appearance information in independent images and contextual information in videos). Our extensive experiments on the well-known ILSVRC 2016 VID dataset show that our proposed method can achieve state-of-the-art performances. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Bin; Tang, Sheng; Xiao, Jun-Bin; Zhang, Yong-Dong] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Wang, Bin; Xiao, Jun-Bin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Yan, Quan-Feng] Hunan Inst Sci & Technol, Coll Comp Sci, Yueyang 414006, Hunan, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Hunan Institute of Science & Technology
RP Tang, S (corresponding author), Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing 100190, Peoples R China.
EM ts@ict.ac.cn
FU National Key Research and Development Program of China [2017YFB1002202];
   National Natural Science Foundation of China [61572472, 61525206,
   U1703261, 61571424]
FX This work was supported by National Key Research and Development Program
   of China (2017YFB1002202), National Natural Science Foundation of China
   (61572472, 61525206, U1703261, 61571424).
CR [Anonymous], 2018, IEEE Trans. Circuits Syst. Video Technol.
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, P BRIT MACH VIS C YO
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, CVPR
   [Anonymous], 2013, INT C LEARN REPR ICL
   [Anonymous], 2014, ARXIV14121441
   [Anonymous], 2016, SEQ NMS VIDEO OBJECT
   Byungjae Lee, 2016, Computer Vision - ECCV 2016 Workshops. Proceedings: LNCS 9914, P68, DOI 10.1007/978-3-319-48881-3_6
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lin M., 2013, P 2 INT C LEARNING R
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065
   Puscas MM, 2015, IEEE I CONF COMP VIS, P1653, DOI 10.1109/ICCV.2015.193
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma P, 2013, PROC CVPR IEEE, P3254, DOI 10.1109/CVPR.2013.418
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Weinzaepfel P, 2015, IEEE I CONF COMP VIS, P3164, DOI 10.1109/ICCV.2015.362
   Yang B, 2016, PROC CVPR IEEE, P6043, DOI 10.1109/CVPR.2016.650
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 44
TC 5
Z9 5
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 102
EP 111
DI 10.1016/j.jvcir.2018.11.014
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100011
DA 2024-07-18
ER

PT J
AU Yeh, CH
   Lin, JR
   Chen, MJ
   Yeh, CH
   Lee, CA
   Tai, KH
AF Yeh, Chih-Hsuan
   Lin, Jie-Ru
   Chen, Mei-Juan
   Yeh, Chia-Hung
   Lee, Cheng-An
   Tai, Kuang-Han
TI Fast prediction for quality scalability of High Efficiency Video Coding
   Scalable Extension
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High Efficiency Video Coding Scalable; Extension; SHVC; Quality
   scalability; Fast decision; Inter-layer prediction
ID HEVC; MODE; INTER
AB In response to the increased demand for high-resolution video, the new generation of video standards, High Efficiency Video Coding (HEVC) and its scalable extension (SHVC) have been finalized. The compression of HEVC/SHVC is efficiently improved and supports ultra-high resolution (UHD). Therefore, the coding complexity of HEVC/SHVC is much higher than those of previous standards. The framework of SHVC is based on HEVC and is divided into several types of scalable video. SHVC can be decoded into various video resolutions, frame rates and qualities, and only needs to be encoded once, but with higher complexity than HEVC. Thus, how to reduce the coding complexity of SHVC is the purpose of this paper. Our proposed algorithm accelerates the enhancement layer (EL) prediction by utilizing encoded Coding Unit (CU) sizes, prediction modes, motion vectors and Rate-Distortion Costs (RD-Costs) of the base layer (BL) and encoded CU sizes of the enhancement layer for quality scalability of SHVC. Experimental results show that the proposed algorithm can save lots of time while maintaining good video quality, and the performance is better than those of previous works. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yeh, Chih-Hsuan; Lin, Jie-Ru; Chen, Mei-Juan; Lee, Cheng-An; Tai, Kuang-Han] Natl Dong Hwa Univ, Dept Elect Engn, Shoufeng, Taiwan.
   [Yeh, Chia-Hung] Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.
   [Yeh, Chia-Hung] Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
C3 National Dong Hwa University; National Taiwan Normal University;
   National Sun Yat Sen University
RP Yeh, CH (corresponding author), Natl Taiwan Normal Univ, Dept Elect Engn, Taipei, Taiwan.; Yeh, CH (corresponding author), Natl Sun Yat Sen Univ, Dept Elect Engn, Kaohsiung, Taiwan.
EM 610223010@gms.ndhu.edu.tw; 810523001@gms.ndhu.edu.tw;
   cmj@gms.ndhu.edu.tw; chyeh@ntnu.edu.tw; 610523017@gms.ndhu.edu.tw;
   810123002@gms.ndhu.edu.tw
RI Tai, Kuang-Han/G-6768-2015
OI Tai, Kuang-Han/0000-0002-6214-0813; Chen, Mei-Juan/0000-0003-3382-8296
FU Ministry of Science and Technology, Taiwan [MOST 102-2221-E-259-022-MY3,
   105-2221-E-259-016-MY3, MOST 106-2221-E-110-083-MY2]
FX This work was supported by Ministry of Science and Technology, Taiwan,
   under grant MOST 102-2221-E-259-022-MY3, 105-2221-E-259-016-MY3 and MOST
   106-2221-E-110-083-MY2.
CR [Anonymous], 2001, ITU-T SG16/Q6
   Bailleul R, 2014, P 2014 IEEE INT C CO
   Bjontegaard G., 2008, SG16Q6 ITUT
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Chen C., 2014, JCTVCQ1007
   Chen ZY, 2017, J VIS COMMUN IMAGE R, V43, P77, DOI 10.1016/j.jvcir.2016.12.007
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Ge Q., 2014, P IEEE WORKSH ADV RE
   Gweon R., 2011, JCTVCF045
   Heindel A, 2017, IEEE T CIRC SYST VID, V27, P1749, DOI 10.1109/TCSVT.2016.2556338
   Helle P, 2012, IEEE T CIRC SYST VID, V22, P1720, DOI 10.1109/TCSVT.2012.2223051
   Katayama T., 2016, P 2016 IEEE INT C CO
   Katayama T., 2016, P 2016 IEEE REG 10 C
   Lin JL, 2013, IEEE J-STSP, V7, P957, DOI 10.1109/JSTSP.2013.2271975
   Liu ZY, 2016, J VIS COMMUN IMAGE R, V38, P474, DOI 10.1016/j.jvcir.2016.03.025
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shi N., 2014, P SPIE OPTOELECTRONI, V9723
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tohidypour H.R., 2013, P BCI, P61
   Tohidypour H. R., 2013, P 2013 IEEE INT C AC
   Tohidypour HR, 2017, IEEE T CIRC SYST VID, V27, P2204, DOI 10.1109/TCSVT.2016.2576738
   Tohidypour HR, 2016, IEEE T BROADCAST, V62, P664, DOI 10.1109/TBC.2016.2576600
   Tohidypour HR, 2016, IEEE T MULTIMEDIA, V18, P182, DOI 10.1109/TMM.2015.2510332
   Tohidypour HR, 2014, INT CONF ACOUST SPEE
   Wang PC, 2010, ETRI J, V32, P577, DOI 10.4218/etrij.10.0109.0622
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2010, IEEE T CIRC SYST VID, V20, P1661, DOI 10.1109/TCSVT.2010.2095692
   Ye Y, 2014, IEEE MULTIMEDIA, V21, P58, DOI 10.1109/MMUL.2014.47
   YIN P, 2013, JCTVC L0174
   Yoo HM, 2014, ELECTRON LETT, V50, P750, DOI 10.1049/el.2014.0451
   Zuo X., 2014, P 2014 IEEE VIS COMM
NR 31
TC 3
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 462
EP 476
DI 10.1016/j.jvcir.2018.12.021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100045
DA 2024-07-18
ER

PT J
AU Vishwakarma, A
   Bhuyan, MK
   Iwahori, Y
AF Vishwakarma, Amit
   Bhuyan, M. K.
   Iwahori, Yuji
TI An optimized non-subsampled shearlet transform-based image fusion using
   Hessian features and unsharp masking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Kaiser window; Optimized NSST; Canny edge detector;
   Hessian features; Unsharp masking
ID FILTERS; DESIGN
AB Existing image fusion approaches are not so efficient to seize significant edges, texture and fine features of the source images due to ineffective and non-adaptive fusion structure. Also for objective evaluation of fusion algorithms, there is a need of a metric to measure source image features which are preserved in the fused image. To address these issues, an optimized non-subsampled shearlet transform (NSST) is developed, which is applied to decompose the source images into low- and high frequency bands. The low frequency bands are fused using proposed descriptor obtained from superposition of scale multiplied Canny edge detector features and Hessian features. The high frequency bands are fused using unsharp masking based fusion rule. Moreover, a metric Q(E) is formulated on the basis of Karhunen-Loeve transform (KLT). The information of image pixel variance for both source and fused images can be measured by using the proposed metric Q(E), and it gives an indication of the amount of variance information transferred from the source images to the fused image. Both subjective and objective analysis show the efficacy of the proposed fusion structure and the metric Q(E). (C) 2018 Elsevier Inc. All rights reserved.
C1 [Vishwakarma, Amit; Bhuyan, M. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
   [Iwahori, Yuji] Chubu Univ, Dept Comp Sci, Kasugai, Aichi 4878501, Japan.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; Chubu University
RP Bhuyan, MK (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM a.vishwakarma@iitg.ac.in; mkb@iitg.ac.in; iwahori@cs.chubu.ac.jp
RI Vishwakarma, Amit/ABE-7268-2020; Iwahori, Yuji/AAH-4257-2020
OI Vishwakarma, Amit/0000-0002-0591-8940; Iwahori, Yuji/0000-0002-6421-8186
CR Adu JH, 2016, J VIS COMMUN IMAGE R, V40, P218, DOI 10.1016/j.jvcir.2016.06.026
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Bavirisetti DP, 2016, IEEE SENS J, V16, P203, DOI 10.1109/JSEN.2015.2478655
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   COLLIGNON A, 1995, COMP IMAG VIS, V3, P263
   Cruz-Roldan F, 2009, IEEE T CIRCUITS-I, V56, P168, DOI 10.1109/TCSI.2008.925350
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dony R., 2001, TRANSFORM DATA COMPR, V1, P1
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   Grohs P, 2013, PROC SPIE, V8858, DOI 10.1117/12.2022665
   Huang R, 2008, LINEAR ALGEBRA APPL, V428, P1551, DOI 10.1016/j.laa.2007.10.001
   Kaplan NH, 2016, J VIS COMMUN IMAGE R, V38, P848, DOI 10.1016/j.jvcir.2016.04.017
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2010, IEEE SENS J, V10, P1519, DOI 10.1109/JSEN.2010.2041924
   Liang JL, 2012, IEEE T IMAGE PROCESS, V21, P2898, DOI 10.1109/TIP.2012.2183140
   Liao B, 2016, J VIS COMMUN IMAGE R, V40, P559, DOI 10.1016/j.jvcir.2016.07.022
   Lin YP, 1998, IEEE SIGNAL PROC LET, V5, P132, DOI 10.1109/97.681427
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo XQ, 2017, J VIS COMMUN IMAGE R, V45, P46, DOI 10.1016/j.jvcir.2017.02.006
   Manchanda M, 2016, J VIS COMMUN IMAGE R, V40, P197, DOI 10.1016/j.jvcir.2016.06.021
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Mitianoudis N, 2008, IEEE SENS J, V8, P2016, DOI 10.1109/JSEN.2008.2007678
   Petrovic V, 2007, INFORM FUSION, V8, P208, DOI 10.1016/j.inffus.2005.05.001
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   Qu X.-B., 2009, OPT PRECIS ENG, V13
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   SCHREIBER WF, 1970, PATTERN RECOGN, V2, P117, DOI 10.1016/0031-3203(70)90007-5
   Summers D, 2003, J NEUROL NEUROSUR PS, V74, P288, DOI 10.1136/jnnp.74.3.288
   Tay DBH, 1993, IEEE T IMAGE PROCESS, V2, P466, DOI 10.1109/83.242356
   Wang T, 2010, IEEE SENS J, V10, P647, DOI 10.1109/JSEN.2009.2038657
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
NR 42
TC 5
Z9 7
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 48
EP 60
DI 10.1016/j.jvcir.2018.10.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400007
DA 2024-07-18
ER

PT J
AU Zhou, J
   Wang, T
   Lang, CY
   Feng, SH
   Jin, Y
AF Zhou, Jun
   Wang, Tao
   Lang, Congyan
   Feng, Songhe
   Jin, Yi
TI A novel hypergraph matching algorithm based on tensor refining
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hypergraph matching; Probabilistic; Tensor refining
AB Hypergraph matching utilizes high order constraints rather than unary or pairwise ones, which aims to establish a more reliable correspondence between two sets of image features. Although many hypergraph matching methods have been put forward over the past decade, it remains a challenging problem to be solved due to its combinatorial nature. Most of these methods are based on tensor marginalization, where tensor entries representing joint probabilities of the assignment are fixed during the iterations meanwhile the individual assignment probabilities evolving. This will cause some incomplete information which may hurt the matching performance. Addressing this issue, we propose a novel hypergraph matching algorithm based on tensor refining, accompanied with an alternative adjustment method to accelerate the convergence. We make a comparison between the proposed approach and several outstanding matching algorithms on three commonly used benchmarks. The experimental results validate the superiority of our method on both matching accuracy and robustness against noise and deformation. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhou, Jun; Wang, Tao; Lang, Congyan; Feng, Songhe; Jin, Yi] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Wang, T (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing 100044, Peoples R China.
EM 16120464@bjtu.edu.cn; twang@bjtu.edu.cn; cylang@bjtu.edu.cn;
   shfeng@bjtu.edu.cn; yjin@bjtu.edu.cn
OI Jin, Yi/0000-0001-8408-3816
FU National Key R&D Program of China [2018YFC0809800]; National Nature
   Science Foundation of China [61673048, 61872032]; Fundamental Research
   Funds for the Central universities [2018JBM015, 2018JBM017, 2017JBZ108];
   Joint Research Fund for The Ministry of Education of China and China
   Mobile [MCM20170201]
FX This work is supported by the National Key R&D Program of China
   (2018YFC0809800), the National Nature Science Foundation of China
   (61673048 and 61872032), the Fundamental Research Funds for the Central
   universities (2018JBM015, 2018JBM017 and 2017JBZ108), and the Joint
   Research Fund for The Ministry of Education of China and China Mobile
   (MCM20170201).
CR Chertok M, 2010, IEEE T PATTERN ANAL, V32, P2205, DOI 10.1109/TPAMI.2010.51
   Cho MS, 2014, PROC CVPR IEEE, P2091, DOI 10.1109/CVPR.2014.268
   Cho M, 2010, LECT NOTES COMPUT SC, V6315, P492
   Cong Y, 2018, IEEE T BIG DATA, V4, P78, DOI 10.1109/TBDATA.2017.2688360
   Cong Y, 2018, PATTERN RECOGN, V73, P33, DOI 10.1016/j.patcog.2017.07.012
   Cong Y, 2017, IEEE T IMAGE PROCESS, V26, P185, DOI 10.1109/TIP.2016.2619260
   Cong Y, 2013, IEEE T IMAGE PROCESS, V22, P3179, DOI 10.1109/TIP.2013.2260168
   Cour T., 2006, Advances in Neural Information Processing Systems, V19, P313, DOI [DOI 10.7551/MITPRESS/7503.003.0044, 10.7551/mitpress/7503.003.0044]
   Duchenne O, 2011, IEEE I CONF COMP VIS, P1792, DOI 10.1109/ICCV.2011.6126445
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Egozi A, 2013, IEEE T PATTERN ANAL, V35, P18, DOI 10.1109/TPAMI.2012.51
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Lê-Huu DK, 2017, PROC CVPR IEEE, P4914, DOI 10.1109/CVPR.2017.522
   Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Leordeanu M., 2009, NIPS, P1114
   Leordeanu M, 2012, INT J COMPUT VISION, V96, P28, DOI 10.1007/s11263-011-0442-2
   Peng Chu, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9900, P413, DOI 10.1007/978-3-319-46720-7_48
   Nguyen Q, 2017, IEEE T PATTERN ANAL, V39, P1054, DOI 10.1109/TPAMI.2016.2574706
   Ngoc QN, 2015, PROC CVPR IEEE, P5270, DOI 10.1109/CVPR.2015.7299164
   Wang D, 2018, MULTIMED TOOLS APPL, V77, P10939, DOI 10.1007/s11042-018-5666-5
   Wang T., IEEE T PATTERN ANAL, DOI [10.1109/TPAM1.2017.2767591, DOI 10.1109/TPAM1.2017.2767591]
   Wang T, 2016, AAAI CONF ARTIF INTE, P3625
   Wang T, 2018, IEEE T PATTERN ANAL, V40, P1494, DOI 10.1109/TPAMI.2017.2716350
   Wang T, 2016, LECT NOTES COMPUT SC, V9906, P508, DOI 10.1007/978-3-319-46475-6_32
   Wang T, 2016, PATTERN RECOGN, V60, P657, DOI 10.1016/j.patcog.2016.06.022
   Wang T, 2012, COMPUT VIS IMAGE UND, V116, P1168, DOI 10.1016/j.cviu.2012.08.002
   Yan JC, 2018, IEEE T CYBERNETICS, V48, P765, DOI 10.1109/TCYB.2017.2655538
   Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245
   Zass R, 2008, PROC CVPR IEEE, P1221
NR 30
TC 2
Z9 2
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 69
EP 75
DI 10.1016/j.jvcir.2018.10.012
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400009
DA 2024-07-18
ER

PT J
AU Yang, CL
   Wang, XL
   Pu, JX
   Xie, GS
   Liu, ZH
   Dong, YS
   Liang, LF
AF Yang, Chunlei
   Wang, Xiangluo
   Pu, Jiexin
   Xie, Guo-Sen
   Liu, Zhonghua
   Dong, Yongsheng
   Liang, Lingfei
TI Hybrid of extended locality-constrained linear coding and manifold
   ranking for salient object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Complex scene; Locality-constrained Linear
   Coding (LLC); Manifold ranking; Region classification; Region clustering
ID REGION DETECTION; MODEL; LEVEL
AB Recent years have witnessed great progress of salient object detection methods. However, due to the emerging complex scenes, two problems should be solved urgently: one is on the fast locating of the foreground while preserving the precision, and the other is about reducing the noise near the foreground boundary in saliency maps. In this paper, a hybrid method is proposed to ameliorate the above two issues. At first, to reduce the essential runtime of integrating the prior knowledge, a novel Prior Knowledge Learning based Region Classification (PKL-RC) method is proposed for classifying image regions and preliminarily locating foreground; furthermore, to generate more accurate saliency, a Locality-constrained Linear self-Coding based Region Clustering (LLsC-RC) model is proposed to improve the adjacency structure of the similarity graph for Manifold Ranking (MR). Experimental results demonstrate the effectiveness and superiority of the proposed method in both higher precision and better smoothness. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yang, Chunlei; Pu, Jiexin; Xie, Guo-Sen; Liu, Zhonghua; Dong, Yongsheng; Liang, Lingfei] Henan Univ Sci & Technol, 263 Kaiyuan Rd, Luoyang, Peoples R China.
   [Wang, Xiangluo] Luoyang Normal Univ, 6 Jiqing Rd, Luoyang, Peoples R China.
C3 Henan University of Science & Technology; Luoyang Normal University
RP Pu, JX (corresponding author), Henan Univ Sci & Technol, 263 Kaiyuan Rd, Luoyang, Peoples R China.
EM pjx2014stu@163.com
RI Xie, Guo-Sen/AAL-6674-2020; Chunlei, Yang/KJL-7321-2024
OI Xie, Guo-Sen/0000-0002-5487-9845; Chunlei, Yang/0000-0001-9709-3650
FU International S and T Cooperation Program of Henan [162102410021,
   152102410036]; Natural Science Foundation of China [61702163, U1604153,
   U1504610]; Program for Science & Technology Innovation Talents in
   Universities of Henan Province [19HAS-TIT026]
FX This work was supported in part by the International S and T Cooperation
   Program of Henan (Nos. 162102410021, 152102410036), and the Natural
   Science Foundation of China (Nos. 61702163, U1604153, U1504610). Program
   for Science & Technology Innovation Talents in Universities of Henan
   Province (No. 19HAS-TIT026).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alpert S, 2007, PROC CVPR IEEE, P359
   ANDO T, 1995, LINEAR ALGEBRA APPL, V224, P57
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, TECH REP
   [Anonymous], 2009, P ADV NEUR INF PROC
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P742, DOI 10.1109/TIP.2014.2383320
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Ding ZH, 2012, NEUROCOMPUTING, V76, P9, DOI 10.1016/j.neucom.2011.05.027
   Fan Q, 2014, J VIS COMMUN IMAGE R, V25, P1823, DOI 10.1016/j.jvcir.2014.09.003
   Fareed MMS, 2015, J VIS COMMUN IMAGE R, V32, P144, DOI 10.1016/j.jvcir.2015.08.002
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Huang Y, 2014, COMM COM INF SC, V483, P283
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang QP, 2015, SIGNAL PROCESS-IMAGE, V38, P57, DOI 10.1016/j.image.2015.04.007
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin MQ, 2016, NEUROCOMPUTING, V205, P301, DOI 10.1016/j.neucom.2016.04.036
   Liu J, 2015, NEUROCOMPUTING, V147, P435, DOI 10.1016/j.neucom.2014.06.041
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Margolin R, 2013, VISUAL COMPUT, V29, P381, DOI 10.1007/s00371-012-0740-x
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qiu YH, 2015, NEUROCOMPUTING, V168, P538, DOI 10.1016/j.neucom.2015.05.073
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Wu XM, 2014, I C CONT AUTOMAT ROB, P1207, DOI 10.1109/ICARCV.2014.7064487
   Xu LF, 2015, J VIS COMMUN IMAGE R, V30, P64, DOI 10.1016/j.jvcir.2015.03.011
   Xu M, 2015, VISUAL COMPUT, V31, P355, DOI 10.1007/s00371-014-0930-9
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yang CL, 2017, VISUAL COMPUT, V33, P1415, DOI 10.1007/s00371-016-1288-y
   Yang CL, 2017, IEEE SIGNAL PROC LET, V24, P1458, DOI 10.1109/LSP.2017.2737650
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhu J, 2014, J SIGNAL PROCESS SYS, V74, P33, DOI 10.1007/s11265-013-0768-9
   Zhu S., 2011, 2011 IEEE Workshop on Microelectronics and Electron Devices, P1
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 48
TC 1
Z9 1
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 27
EP 37
DI 10.1016/j.jvcir.2018.08.017
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500003
DA 2024-07-18
ER

PT J
AU Liu, YX
   Yang, CN
   Chou, YS
   Wu, SY
   Sun, QD
AF Liu, Yan-Xiao
   Yang, Ching-Nung
   Chou, Yung-Shun
   Wu, Song-Yu
   Sun, Qin-Dong
TI Progressive (<i>k</i>, <i>n</i>) secret image sharing Scheme with
   meaningful shadow images by GEMD and RGEMD
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Progressive secret sharing scheme; Meaningful shadow image; GEMD; RGEMD
ID VISUAL CRYPTOGRAPHY; AUTHENTICATION; STEGANOGRAPHY; SIZE
AB In (k, n) progressive secret image sharing (PSIS) schemes, a secret image is shared into n shadows in such way that: (1) fewer than k - 1 shadows get no information on the secret image; (2) k to n shadows can progressively recover the secret image. In most PSIS schemes, the shadows are noise-like images which would cause suspicious of attackers. The combination of secret image sharing and steganography can share a secret image into meaningful shadow images that can reduce attention of attackers. However most existing secret image sharing schemes with meaningful shadow images do not possess progressive property, a group of shadow images can either reconstruct entire secret image or get nothing on it. In this paper, we construct a new (k. n) PSIS with meaningful shadow images using GEMD and RGEMD. The property of progressive reconstruction is proved both in theoretical analysis and experimental results. The approaches of GEMD and RGEMD enable our Scheme high embedding capacity and resistance of RS detection. Comparing with other PSISs with meaningful shadow images, our Scheme has advantages in shadow size and shadow visual quality. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Liu, Yan-Xiao; Sun, Qin-Dong] XIAN Univ Technol, Dept Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
   [Yang, Ching-Nung; Chou, Yung-Shun; Wu, Song-Yu] Natl Dong Hwa Univ, Dept CSIE, Hualien, Taiwan.
C3 Xi'an University of Technology; National Dong Hwa University
RP Liu, YX (corresponding author), XIAN Univ Technol, Dept Comp Sci & Engn, Xian 710048, Shaanxi, Peoples R China.
EM liuyanxiao@xaut.edu.cn
RI Yang, Ching-Nung/HKV-1639-2023
FU National Natural Science Foundation of China [61502384, 61571360]; PhD
   research startup foundation of Xi'an University of Technology
   [112-451115008]; Ministry of Science and Technology (MOST)
   [107-2221-E-259-007-MY2]
FX This work was supported by National Natural Science Foundation of China
   under Grant Nos. 61502384, 61571360; and the PhD research startup
   foundation of Xi'an University of Technology No. 112-451115008. This
   research was supported in part by Ministry of Science and Technology
   (MOST), under Grant 107-2221-E-259-007-MY2.
CR Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Cheng Guo, 2011, Journal of Multimedia, V6, P341, DOI 10.4304/jmm.6.4.341-348
   Cheng TF, 2017, MULTIMED TOOLS APPL, V76, P9337, DOI 10.1007/s11042-016-3535-7
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Khan SS, 2004, PATTERN RECOGN LETT, V25, P1293, DOI 10.1016/j.patrec.2004.04.007
   Kuo WC, 2013, IMAGING SCI J, V61, P484, DOI 10.1179/1743131X12Y.0000000011
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Liu F, 2010, COMPUT J, V53, P107, DOI 10.1093/comjnl/bxn072
   Liu LT, 2018, MULTIMED TOOLS APPL, V77, P20569, DOI 10.1007/s11042-017-5435-x
   Liu YX, 2014, SECUR COMMUN NETW, V7, P2237, DOI 10.1002/sec.930
   Liu YX, 2017, SIGNAL PROCESS-IMAGE, V58, P49, DOI 10.1016/j.image.2017.06.011
   Tsai CS, 2002, J SYST SOFTWARE, V64, P163, DOI 10.1016/S0164-1212(02)00034-1
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang C. C., 2017, MULTIMED TOOLS APPL, P1, DOI DOI 10.1039/C7QM00201G
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2009, IEEE SIGNAL PROC LET, V16, P659, DOI 10.1109/LSP.2009.2021334
   Wang ZH, 2016, SECUR COMMUN NETW, V9, P4075, DOI 10.1002/sec.1589
   Wu YS, 2004, PATTERN RECOGN, V37, P1377, DOI 10.1016/j.patcog.2004.01.002
   Yang C. N., 2013, LNCS, V7809, P449
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Yang CN, 2012, IEEE T CIRC SYST VID, V22, P799, DOI 10.1109/TCSVT.2011.2180952
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2009, PATTERN RECOGN, V42, P1615, DOI 10.1016/j.patcog.2009.01.024
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 30
TC 16
Z9 17
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 766
EP 777
DI 10.1016/j.jvcir.2018.08.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100067
DA 2024-07-18
ER

PT J
AU Wang, Y
   Luo, XB
   Ding, L
   Hu, SQ
AF Wang, Yong
   Luo, Xinbin
   Ding, Lu
   Hu, Shiqiang
TI Multi-task based object tracking via a collaborative model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Collaborative model; Alternating direction method of multipliers;
   Multi-task sparse learning; Generative model; Discriminative model
ID VISUAL TRACKING
AB This paper presents a multi-task based object tracking algorithm via a collaborative model. Under the framework of particle filtering, we develop a multi-task sparse learning based generative and discriminative classifier model. In the generative model, we propose a histogram based subspace learning method which takes advantage of adaptive templates update. In the discriminative model, we introduce an effective method to compute the confidence value which assigns more weights to the foreground than the background. A decomposition model is employed to take the common features and outliers of each particle into consideration. The alternating direction method of multipliers (ADMM) algorithm guarantees the optimization problem can be solved robustly and accurately. Qualitative and quantitative comparisons with nine state-of-the-art methods demonstrate the effectiveness and efficiency of our method in handling various challenges during tracking. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Yong] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Luo, Xinbin] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Ding, Lu; Hu, Shiqiang] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
C3 University of Ottawa; Shanghai Jiao Tong University; Shanghai Jiao Tong
   University
RP Luo, XB (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM losinbin@sjtu.edu.cn
RI TIAN, YI/KHU-9704-2024; Ding, Lu/AAJ-2179-2020; Wang,
   Zejun/KBB-8454-2024
FU National Natural Science Foundation of China [61374161]; China Aviation
   Science Foundation [20142057006]
FX This work was jointly supported by the National Natural Science
   Foundation of China (No. 61374161) and China Aviation Science Foundation
   (No. 20142057006). We thank the anonymous editor and reviewers for their
   careful reading and many insightful comments and suggestions.
CR [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], ICCV
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], J VIS COMMUN IMAGE R
   [Anonymous], 2011, CVPR
   [Anonymous], 2015, IEEE T PATTERN ANAL
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, MASTERS THESIS
   [Anonymous], 2010, PASCAL VISUAL OBJECT
   [Anonymous], 2017, INT C MACH LEARN
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Cheng X, 2015, APPL SOFT COMPUT, V31, P81, DOI 10.1016/j.asoc.2015.03.002
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dinh T.B., 2011, P IEEE WORKSH APPL C, P642, DOI DOI 10.1109/WACV.2011.5711565
   Mei X, 2015, IEEE T NEUR NET LEAR, V26, P2874, DOI 10.1109/TNNLS.2015.2399233
   Mei X, 2013, IEEE T IMAGE PROCESS, V22, P2661, DOI 10.1109/TIP.2013.2255301
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wang Y, 2017, IEEE IMAGE PROC, P1132, DOI 10.1109/ICIP.2017.8296458
   Wang YH, 2017, IEEE T IMAGE PROCESS, V26, P3360, DOI 10.1109/TIP.2017.2678798
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Wu Y, 2014, IEEE T CIRC SYST VID, V24, P374, DOI 10.1109/TCSVT.2013.2278199
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2013, IEEE T IMAGE PROCESS, V22, P4664, DOI 10.1109/TIP.2013.2277800
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang T., 2012, IEEE C COMPUTER VISI, P1
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 42
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 698
EP 710
DI 10.1016/j.jvcir.2018.08.008
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100060
DA 2024-07-18
ER

PT J
AU Zhang, CY
   Huang, YT
   Wang, ZQ
   Jiang, HC
   Yan, DF
AF Zhang, Caiyou
   Huang, Yuteng
   Wang, Zhiqiang
   Jiang, Hongcheng
   Yan, Dongfeng
TI RETRACTED: Cross-camera multi-person tracking by leveraging fast graph
   mining algorithm (Retracted article. See vol. 67, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Multiple person; Tracking; Video surveillance; Matching
AB Multiple person tracking is a very useful task in intelligent video surveillance, which is hindered by many challenges such as the variations of illumination, the irregular changes of human shapes and the particle occlusions. To tackle these challenges, in this paper, we propose a new online learning tracking system to generate the complete trajectory for each tracking object. In detection stage, we build a classifier for each tracking object by online learning in order to provide more accurate detection results. Online learning could real-time update the classifier for an accurately tracking results in the future. In the tracklet generation stage, we apply the spatiotemporal constrain to generate a set of reliable tracklets. Finally, we propose a new Part-based matching method to get the correlation between different tracklets and apply linear programming and greedy algorithm to handle the data association problem to generate the complete trajectory for each tracking object. In particular, our approach is able to cast the multiple cameras tracking problem as a data association problem. The experiments on our proposed method demonstrate state-of-the-art performance in multiple person tracking. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Caiyou; Huang, Yuteng; Wang, Zhiqiang; Jiang, Hongcheng] Informat & Telecommun Co State Grid Zhejiang Elec, Hangzhou, Zhejiang, Peoples R China.
   [Yan, Dongfeng] Xiamen Great Power Geo Informat Technol Co Ltd, Xiamen, Peoples R China.
RP Zhang, CY (corresponding author), Informat & Telecommun Co State Grid Zhejiang Elec, Hangzhou, Zhejiang, Peoples R China.
EM 634423778@qq.com
RI Wang, Zhiqiang/AAO-7592-2021
CR [Anonymous], 2016, ARXIV161001708
   [Anonymous], ONLINE LEARNING ROBU
   [Anonymous], 2008, CVPR
   [Anonymous], 2008, CVPR
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Berclaz J., 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, V1, P744, DOI DOI 10.1109/CVPR.2006.258
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gehrig T., 2006, Multimodal Technologies for Perception of Humans. First International Evaluation Workshop on Classification of Events, Activities and Relationships, CLEAR 2006. Revised Selected Papers (Lecture Notes in Computer Science Vol.4122), P137
   Gorur P., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P386, DOI 10.1109/AVSS.2011.6027356
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Jiang Hao, 2007, CVPR
   Kasturi R, 2009, IEEE T PATTERN ANAL, V31, P319, DOI 10.1109/TPAMI.2008.57
   Leal-Taixé L, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130233
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Pellegrini S, 2010, LECT NOTES COMPUT SC, V6311, P452, DOI 10.1007/978-3-642-15549-9_33
   Yamaguchi K, 2011, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2011.5995468
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
NR 26
TC 2
Z9 2
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 711
EP 719
DI 10.1016/j.jvcir.2018.08.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100061
DA 2024-07-18
ER

PT J
AU Reta, C
   Cantoral-Ceballos, JA
   Solis-Moreno, I
   Gonzalez, JA
   Alvarez-Vargas, R
   Delgadillo-Checa, N
AF Reta, Carolina
   Cantoral-Ceballos, Jose A.
   Solis-Moreno, Ismael
   Gonzalez, Jesus A.
   Alvarez-Vargas, Rogelio
   Delgadillo-Checa, Nery
TI Color uniformity descriptor: An efficient contextual color
   representation for image indexing and retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval; Image representation; Contextual features; Color
   uniformity descriptor; Lab color space
ID SCALE; MANIFOLD; RANKING
AB Color is a rich source of visual information for the effective characterization of image content. The recognition of texture or shape elements in images is strongly associated with the analysis of the image color layout. This paper presents a contextual color descriptor designed especially to be applied to CBIR tasks in heterogeneous image databases. The proposed color uniformity descriptor (CUD) clusters perceptually similar image color regions according to the uniformity analysis of their neighbor pixels. CUD produces vast color image details with a thin histogram, whilst preserving the balance between uniqueness and robustness. CUD is computationally efficient and can achieve high precision and throughput rates when used in CBIR. Experimental results show that CUD performs comparably against local features and multiple features state-of-the-art approaches that require more complex data manipulation. Results demonstrate that CUD provides strong image discrimination even in the presence of significant content variation.
C1 [Reta, Carolina] CONACYT CIATEQ AC, Dept IT Control & Elect, Av Diesel Nacl 1 Ciudad Sahagun, Queretaro 43990, Hidalgo, Mexico.
   [Cantoral-Ceballos, Jose A.; Alvarez-Vargas, Rogelio; Delgadillo-Checa, Nery] CIA TEQ AC, Dept IT Control & Elect, Av Manantiales 23-A,Parque Ind Bernardo Quintana, El Marques 76246, Queretaro, Mexico.
   [Solis-Moreno, Ismael] IBM Corp, Mexico Software Lab, Carretera Castillo Km 2-2, El Salto 45686, Jalisco, Mexico.
   [Gonzalez, Jesus A.] Natl Inst Astrophys Opt & Elect, Dept Comp Sci, Luis Enrique Erro 1, Puebla 72840, Mexico.
C3 Instituto Nacional de Astrofisica, Optica y Electronica
RP Reta, C (corresponding author), CONACYT CIATEQ AC, Dept IT Control & Elect, Av Diesel Nacl 1 Ciudad Sahagun, Queretaro 43990, Hidalgo, Mexico.
EM carolina.reta@ciateq.mx; jose.cantoral@ciateq.mx; ismael@mx1.ibm.com;
   jagonzalez@inaoep.mx; ralvarez@ciateq.mx; nery.delgadillo@ciateq.mx
RI ; Reta, Carolina/M-3167-2018
OI Cantoral-Ceballos, Dr. Jose A./0000-0001-5597-939X; Reta,
   Carolina/0000-0002-0843-129X
CR Agrawal R, 2010, HDB MPEG APPL, P221
   [Anonymous], 2010, PROC ACM SIGMM INT C
   [Anonymous], 2015, MATLAB (R2015b)
   Castelli V., 2001, DIGITAL IMAGERY FUND, P1
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chatzichristofis SA, 2014, MULTIMED TOOLS APPL, V70, P1767, DOI 10.1007/s11042-012-1192-z
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deselaers T., 2008, INF RETR, V11
   Fujiwara Y, 2014, PROC VLDB ENDOW, V8, P341, DOI 10.14778/2735496.2735498
   Gevers T, 2004, IEEE T PATTERN ANAL, V26, P113, DOI 10.1109/TPAMI.2004.1261083
   Guo JM, 2013, J VIS COMMUN IMAGE R, V24, P1360, DOI 10.1016/j.jvcir.2013.09.005
   Iakovidou C, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0262-6
   Jain M., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1441
   Jegou H., 2010, INT J COMPUT VIS, V87
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jing H., 1997, COMP VIS PATT REC 19, P762
   Juneja K, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P67, DOI 10.1109/CICT.2015.92
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu SL, 2018, INFORM SCIENCES, V424, P235, DOI 10.1016/j.ins.2017.10.010
   Long FH, 2003, SIG COM TEC, P1
   Manjunath B. S., 2001, TEXTURE FEATURES IMA, P313
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Morovi J., 2008, COLOR REPROD DATA FL, P73
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Reta C., 2017, MULTIMEDIA TOOLS APP
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Schanda J, 2007, COLORIMETRY: UNDERSTANDING THE CIE SYSTEM, P25, DOI 10.1002/9780470175637.ch3
   Shao H, 2003, LECT NOTES COMPUT SC, V2728, P71
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Smith J. R., 2001, COLOR IMAGE RETRIEVA, P285
   Wong KM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P611
   Zhang SL, 2015, IEEE T PATTERN ANAL, V37, P2573, DOI 10.1109/TPAMI.2015.2417573
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
NR 42
TC 10
Z9 10
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 39
EP 50
DI 10.1016/j.jvcir.2018.04.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800005
DA 2024-07-18
ER

PT J
AU Coliban, RM
   Ivanovici, M
AF Coliban, Radu-Mihai
   Ivanovici, Mihai
TI Reducing the oversegmentation induced by quasi-flat zones for
   multivariate images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quasi-flat zones; Mathematical morphology; Color image segmentation;
   Hyperspectral pixel classification; EDICS: 4.4 morphological image
   analysis
ID SEGMENTATION
AB Quasi-flat zones are morphological operators which partition the image into homogeneous regions with respect to certain criteria. They are used in grayscale and multivariate image simplification and segmentation. However, they often induce an oversegmentation of the image, taking the shape of narrow transition regions between objects and small regions which are a few pixels wide. Various methods have been devised in order to reduce this oversegmentation, which remove the unwanted zones according to some criteria and then grow the remaining regions. In this paper we propose improvements in transition region and area threshold filtering. We also combine the two filtering methods for further-improved results. We apply the proposed approaches in color image segmentation and hyperspectral pixel classification.
C1 [Coliban, Radu-Mihai; Ivanovici, Mihai] Transilvania Univ, Dept Elect & Comp, Lab MIV2, Brasov 500024, Romania.
C3 Transylvania University of Brasov
RP Coliban, RM (corresponding author), Transilvania Univ, Dept Elect & Comp, Lab MIV2, Brasov 500024, Romania.
EM coliban.radu@unitbv.ro; mihai.ivanovici@unitbv.ro
RI Ivanovici, Mihai/ABE-1754-2020; Coliban, Radu-Mihai/AAW-8755-2021
OI Ivanovici, Mihai/0000-0002-0803-2918
CR Angulo J., 2003, ICIP 2003, V2, P11
   Aptoula E, 2014, INT J REMOTE SENS, V35, P3482, DOI 10.1080/01431161.2014.905729
   Aptoula E., 2013, VECTORIAL QUASI FLAT, P231
   Aptoula E., 2017, QUASI FLAT ZONES ANG, P342
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Barnett V., 1976, J ROY STAT SOC, V139
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brunner D, 2007, IMAGE VISION COMPUT, V25, P1352, DOI 10.1016/j.imavis.2006.09.002
   Carleer AP, 2005, PHOTOGRAMM ENG REM S, V71, P1285, DOI 10.14358/PERS.71.11.1285
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Derivaux S, 2010, PATTERN RECOGN LETT, V31, P2364, DOI 10.1016/j.patrec.2010.07.007
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239
   SERRA J, 1993, P SOC PHOTO-OPT INS, V2030, P65, DOI 10.1117/12.146672
   Serra J., 2009, FALSE COLOUR PROBLEM, P13
   Soille P., 2002, Morphological Image Analysis: Principles and Applications, Vsecond
   Soille P., 2011, PREVENTING CHAINING, P96
   Soille P., 2009, CONSTRAINED CONNECTI, P59
   Soille P, 2008, IEEE T PATTERN ANAL, V30, P1132, DOI 10.1109/TPAMI.2007.70817
   Soille P, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P487, DOI 10.1109/ICIAP.2007.4362825
   Tous M.F.Z., 2001, THESIS
   Weber J, 2013, J VIS COMMUN IMAGE R, V24, P397, DOI 10.1016/j.jvcir.2013.01.011
NR 23
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 281
EP 293
DI 10.1016/j.jvcir.2018.04.003
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800026
DA 2024-07-18
ER

PT J
AU Liu, H
   Fu, ZL
   Han, JG
   Shao, L
   Liu, HS
AF Liu, Heng
   Fu, Zilin
   Han, Jungong
   Shao, Ling
   Liu, Hongshen
TI Single satellite imagery simultaneous super-resolution and colorization
   using multi-task deep neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image super-resolution; Satellite image colorization; Deep neural
   networks; Multi-task learning
ID RECONSTRUCTION
AB Satellite imagery is a kind of typical remote sensing data, which holds preponderance in large area imaging and strong macro integrity. However, for most commercial space usages, such as virtual display of urban traffic flow, virtual interaction of environmental resources, one drawback of satellite imagery is its low spatial resolution, failing to provide the clear image details. Moreover, in recent years, synthesizing the color for grayscale satellite imagery or recovering the original color of camouflage sensitive regions becomes an urgent requirement for large spatial objects virtual reality interaction. In this work, unlike existing works which solve these two problems separately, we focus on achieving image super-resolution (SR) and image colorization synchronously. Based on multi-task learning, we provide a novel deep neural network model to fulfill single satellite imagery SR and colorization simultaneously. By feeding back the color feature representations into the SR network and jointly optimizing such two tasks, our deep model successfully achieves the mutual cooperation between imagery reconstruction and image colorization. To avoid color bias, we not only adopt the non-satellite imagery to enrich the color diversity of satellite image, but also recalculate the prior color distribution and the valid color range based on the mixed data. We evaluate the proposed model on satellite images from different data sets, such as RSSCN7 and AID. Both the evaluations and comparisons reveal that the proposed multi-task deep learning approach is superior to the state-of-the-art methods, where image SR and colorization can be accomplished simultaneously and efficiently.
C1 [Liu, Heng; Fu, Zilin; Liu, Hongshen] Anhui Univ Technol, Maanshan 243032, Anhui, Peoples R China.
   [Han, Jungong] Univ Lancaster, Lancaster LA1 4YW, England.
   [Shao, Ling] Univ East Anglia, Norwich NR4 7TJ, Norfolk, England.
C3 Anhui University of Technology; Lancaster University; University of East
   Anglia
RP Han, JG (corresponding author), Univ Lancaster, Lancaster LA1 4YW, England.
EM jungong.han@lancaster.ac.uk
RI Han, Jungong/ABE-6812-2020; Shao, Ling/D-3535-2011
OI Han, Jungong/0000-0003-4361-956X; Shao, Ling/0000-0002-8264-6117; Liu,
   Heng/0000-0001-7563-2676
FU Major Project of Natural Science of Anhui Provincial Department of
   Education [KJ2015ZD09]; Anhui Provincial Natural Science Foundation
   [1608085MF129]
FX This work is partly supported by the Major Project of Natural Science of
   Anhui Provincial Department of Education (Grant No. KJ2015ZD09). It is
   also supported by Anhui Provincial Natural Science Foundation (Grant No.
   1608085MF129).
CR [Anonymous], SUPER RESOLUTION S 1
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, Psicologia O Portal dos Psicologos, DOI DOI 10.1109/MSMW.2016.7538183
   [Anonymous], INT J REMOTE SENS AP
   [Anonymous], SUPER RESOLVING MULT
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng ZZ, 2015, IEEE I CONF COMP VIS, P415, DOI 10.1109/ICCV.2015.55
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   IIZUKA S, 2016, ACM T GRAPHIC, V35, DOI DOI 10.1145/2897824.2925974
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Liang YD, 2016, NEUROCOMPUTING, V194, P340, DOI 10.1016/j.neucom.2016.02.046
   Liebel L, 2016, INT ARCH PHOTOGRAMM, V41, P883, DOI 10.5194/isprsarchives-XLI-B3-883-2016
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Pickup Lyndsey., 2007, MACHINE LEARNING MUL
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen W, 2016, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2016.31
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Xia G S, 2017, IEEE Transactions on Geoscience and Remote Sensing, P1
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang J., 2010, SUPER RESOLUTION IMA, P20
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang HY, 2014, REMOTE SENS-BASEL, V6, P637, DOI 10.3390/rs6010637
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhu H, 2016, ISPRS ANN PHOTO REM, V3, P213, DOI 10.5194/isprsannals-III-7-213-2016
   Zou Q, 2015, IEEE GEOSCI REMOTE S, V12, P2321, DOI 10.1109/LGRS.2015.2475299
NR 37
TC 27
Z9 31
U1 1
U2 60
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 20
EP 30
DI 10.1016/j.jvcir.2018.02.016
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sengar, SS
   Mukhopadhyay, S
AF Sengar, Sandeep Singh
   Mukhopadhyay, Susanta
TI Motion detection using block based bi-directional optical flow method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Optical flow; Motion detection; Normalization; Block; Morphology
ID MANY-CORE PROCESSORS; PARALLEL FRAMEWORK; OBJECT TRACKING; ALGORITHM;
   PEOPLE
AB Detecting moving objects from video frame sequences has a lot of useful applications in computer vision. This proposed method of moving object detection first estimates the bi-directional optical flow fields between (i) the current frame and the previous frame and between (ii) the current frame and the next frame. The bi-directional optical flow field is then subjected to normalization and enhancement. Each normalized and enhanced optical flow field is then divided into non-overlapping blocks. The moving objects are finally detected in the form of binary blobs by examining the histogram based thresholded values of such optical flow field of each block as well as the optical flow field of the candidate flow value. Our technique has been conceptualized, implemented and tested on real video data sets with complex background environment. The experimental results and quantitative evaluation establish that our technique achieves effective and efficient results than other existing methods. (c) 2017 Elsevier Inc. All rights reserved.
C1 [Sengar, Sandeep Singh; Mukhopadhyay, Susanta] Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Sengar, SS (corresponding author), Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad 826004, Bihar, India.
EM sandeep.iitdhanbad@gmail.com
OI Sengar, Dr. Sandeep Singh/0000-0003-2171-9332
CR [Anonymous], 2011, CAVIAR TEST CASE SCE
   [Anonymous], 2012, HDB SOFT COMPUT VIDE
   [Anonymous], COMPUT SCI REV
   [Anonymous], 2001, PYRAMIDAL IMPLEMENTA
   [Anonymous], SIGNAL IMAGE VIDEO P
   [Anonymous], 2006, DAT IM VID CLIPS
   [Anonymous], INT C COMP VIS PATT
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Candamo J, 2010, IEEE T INTELL TRANSP, V11, P206, DOI 10.1109/TITS.2009.2030963
   Chen EK, 2013, DIGIT SIGNAL PROCESS, V23, P118, DOI 10.1016/j.dsp.2012.07.017
   Choi IH, 2015, MEASUREMENT, V75, P338, DOI 10.1016/j.measurement.2015.07.020
   Collins R., 2000, CMURITR0012
   DENG G, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1615, DOI 10.1109/NSSMIC.1993.373563
   Dougherty E., 2003, HANDS MORPHOLOGICAL, V71
   Fernández-Caballero A, 2010, ROBOT AUTON SYST, V58, P1273, DOI 10.1016/j.robot.2010.06.002
   Foresti GL, 2005, PATTERN RECOGN LETT, V26, P2232, DOI 10.1016/j.patrec.2005.03.031
   FOY WH, 1976, IEEE T AERO ELEC SYS, V12, P187, DOI 10.1109/TAES.1976.308294
   García J, 2013, IEEE T IND ELECTRON, V60, P3991, DOI 10.1109/TIE.2012.2206330
   Halidou A, 2014, COMPUT ELECTR ENG, V40, P375, DOI 10.1016/j.compeleceng.2014.10.003
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Kim J, 2010, IEEE IMAGE PROC, P4669, DOI 10.1109/ICIP.2010.5652848
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liu DJ, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 1, PROCEEDINGS, P344, DOI 10.1109/HIS.2009.74
   Maddox LTJS, 2012, WOUNDS, P21
   Megrhi S, 2016, J VIS COMMUN IMAGE R, V41, P375, DOI 10.1016/j.jvcir.2016.10.016
   Motlagh O, 2014, NEURAL COMPUT APPL, V24, P1569, DOI 10.1007/s00521-013-1393-z
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Paul N., 2016, J SUPERCOMPUT, P1
   Prasad D.K., 2016, ARXIV161105842, P1
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Sengar S.S., 2017, OPTIK INT J LIGHT EL
   Sengar SS, 2017, ARAB J SCI ENG, V42, P3621, DOI 10.1007/s13369-017-2672-2
   Sengar SS, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P2345, DOI 10.1109/WiSPNET.2016.7566561
   Sengar SS, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN INFORMATION TECHNOLOGY (RAIT), P467, DOI 10.1109/RAIT.2016.7507946
   Sengar SS, 2016, OPTIK, V127, P6258, DOI 10.1016/j.ijleo.2016.03.061
   Tagliasacchi M, 2007, IMAGE VISION COMPUT, V25, P141, DOI 10.1016/j.imavis.2006.01.021
   Vyver J.V.D., 2016, THESIS
   XIN YH, 2014, INT J LIGHT ELECT OP, V125, P5690, DOI DOI 10.1016/J.IJLEO.2014.06.092
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhao N, 2016, J VIS COMMUN IMAGE R, V37, P25, DOI 10.1016/j.jvcir.2015.04.011
NR 44
TC 15
Z9 16
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 89
EP 103
DI 10.1016/j.jvcir.2017.08.007
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800008
DA 2024-07-18
ER

PT J
AU Xia, CX
   Zhang, HL
   Gao, XJ
AF Xia, Chenxing
   Zhang, Hanling
   Gao, Xiuju
TI Combining multi-layer integration algorithm with background prior and
   label propagation for saliency detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Corner; Objectness; Energy function; Integration algorithm; Multi-layer
ID VISUAL SALIENCY; OBJECT DETECTION
AB In this paper, we propose a novel approach to automatically detect salient regions in an image. Firstly, some corner superpixels serve as the background labels and the saliency of other superpixels are determined by ranking their similarities to the background labels based on ranking algorithm. Subsequently, we further employ an objectness measure to pick out and propagate foreground labels. Furthermore, an integration algorithm is devised to fuse both background-based saliency map and foreground-based saliency map, meanwhile an original energy function is acted as refinement before integration. Finally, results from multiscale saliency maps are integrated to further improve the detection performance. Our experimental results on five benchmark datasets demonstrate the effectiveness of the proposed method. Our method produces more accurate saliency maps with better precision-recall curve, higher F-measure and lower mean absolute error than other 13 state-of-the-arts approaches on ASD, SED, ECSSD, iCoSeg and PASCAL-S datasets. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Xia, Chenxing; Zhang, Hanling; Gao, Xiuju] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Zhang, Hanling] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
C3 Hunan University; Nanjing University of Information Science & Technology
RP Zhang, HL (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM starry@hnu.edu.cn; starry1614@163.com; s131010061@hnu.edu.cn
RI Xia, Chenxing/GYQ-6472-2022
OI Xia, Chenxing/0000-0003-0750-1265
FU National Natural Science Foundation of China [61672222, 61572183,
   61472131]; Science and Technology Key Projects of Hunan province
   [2015TP1004]; Priority Academic Program Development of Jiangsu Higer
   Education Institutions; Jiangsu Collaborative Innovation Center on
   Atmospheric Environment and Equipment Technology
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61672222, 61572183, 61472131), Science and Technology
   Key Projects of Hunan province (No.2015TP1004), the Priority Academic
   Program Development of Jiangsu Higer Education Institutions, Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Achanta Radhakrishna, 2010, Tech. Rep.
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alpert S, 2012, IEEE T PATTERN ANAL, V34, P315, DOI 10.1109/TPAMI.2011.130
   [Anonymous], 2012, P ACM MULT
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Batra D, 2011, INT J COMPUT VISION, V93, P273, DOI 10.1007/s11263-010-0415-x
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chenxing Xia, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P11, DOI 10.1007/978-3-319-48890-5_2
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fu KR, 2015, IEEE T IMAGE PROCESS, V24, P5671, DOI 10.1109/TIP.2015.2485782
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Scharfenberger C, 2013, PROC CVPR IEEE, P979, DOI 10.1109/CVPR.2013.131
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Shi KY, 2013, PROC CVPR IEEE, P2115, DOI 10.1109/CVPR.2013.275
   Song ML, 2014, INFORM SCIENCES, V281, P573, DOI 10.1016/j.ins.2013.09.036
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2014, IEEE SIGNAL PROC LET, V21, P1035, DOI 10.1109/LSP.2014.2323407
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2011, IEEE IMAGE PROC, P645, DOI 10.1109/ICIP.2011.6116634
   Xu M, 2015, VISUAL COMPUT, V31, P355, DOI 10.1007/s00371-014-0930-9
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Yang YZ, 2010, LECT NOTES COMPUT SC, V6315, P631, DOI 10.1007/978-3-642-15555-0_46
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2017, IEEE T INF FOREN SEC, V12, P1005, DOI 10.1109/TIFS.2016.2636090
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 60
TC 8
Z9 8
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 110
EP 121
DI 10.1016/j.jvcir.2017.06.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700009
DA 2024-07-18
ER

PT J
AU Luo, XQ
   Zhang, ZC
   Zhang, CY
   Wu, XJ
AF Luo, Xiaoqing
   Zhang, Zhancheng
   Zhang, Cuiying
   Wu, Xiaojun
TI Multi-focus image fusion using HOSVD and edge intensity
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Multi-focus; HOSVD; Edge intensity; Sigmoid function
ID WAVELET TRANSFORM; SHARPNESS; ALGORITHM
AB The purpose of multi-focus image fusion is to integrate the partially focused images into one single image which is focused everywhere. To achieve this purpose, higher order singular value decomposition (HOSVD) and edge intensity (EDI) based multi-focus image fusion method is proposed. The main characteristics of the proposed method includes: I. an effective and robust sharpness measure based on edge intensity is presented; 2. considering the fact that HOSVD is an effective data-driven decomposition technique and shows the outstanding ability in the representation of high-dimensional data, it is used to decompose multi-focus images; and 3. a multi-strategy fusion rule based on sigmoid function is used to fuse the decomposition coefficients. Furthermore, several experiments are conducted to verify the superiority of the proposed fusion framework in terms of visual and statistical analyses. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Luo, Xiaoqing; Zhang, Cuiying; Wu, Xiaojun] Jiangnan Univ, Sch Internet Things, 1800 Lihu Rd, Wuxi 214122, Peoples R China.
   [Zhang, Zhancheng] Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou 215009, Peoples R China.
C3 Jiangnan University; Suzhou University of Science & Technology
RP Zhang, ZC (corresponding author), Suzhou Univ Sci & Technol, Coll Elect & Informat Engn, Suzhou 215009, Peoples R China.
EM cimszhang@163.com
FU National Natural Science Foundation of P.R. China [61300151, 61373055];
   Postdoctoral Science Foundation of China [2013M541601, 1301079C];
   Provincial research [BK20151358, BK20151202]; Ministry of Housing and
   Urban-rural Development of the People's Republic of China [2015-K8-035];
   The Fundamental Research Funds for the Central Universities
   [JUSRP51618B]; Equipment Development and Ministry of Education union
   fund
FX This work was supported by the National Natural Science Foundation of
   P.R. China under grant nos. 61300151 and 61373055, the Postdoctoral
   Science Foundation of China under grant nos. 2013M541601 and 1301079C
   and the Provincial research grant nos. BK20151358 and BK20151202. The
   Ministry of Housing and Urban-rural Development of the People's Republic
   of China under grant no. 2015-K8-035. The Fundamental Research Funds for
   the Central Universities JUSRP51618B and the Equipment Development and
   Ministry of Education union fund.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   DEVLIN SJ, 1975, BIOMETRIKA, V62, P531, DOI 10.1093/biomet/62.3.531
   Geng P, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.6.067005
   Goshtasby A., 2006, SPIE DEF SEC S 17 21
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, PATTERN RECOGN LETT, V29, P1295, DOI 10.1016/j.patrec.2008.02.002
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liang JL, 2012, IEEE T IMAGE PROCESS, V21, P2898, DOI 10.1109/TIP.2012.2183140
   Liu Y, 2015, OPT COMMUN, V341, P101, DOI 10.1016/j.optcom.2014.12.015
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Miao QG, 2005, P SOC PHOTO-OPT INS, V5778, P704, DOI 10.1117/12.603092
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Shah P, 2014, SIGNAL IMAGE VIDEO P, V8, P723, DOI 10.1007/s11760-013-0585-4
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Shi C, 2013, NEUROCOMPUTING, V117, P47, DOI 10.1016/j.neucom.2012.10.025
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Wee CY, 2007, INFORM SCIENCES, V177, P2533, DOI 10.1016/j.ins.2006.12.023
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
NR 27
TC 38
Z9 41
U1 4
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 46
EP 61
DI 10.1016/j.jvcir.2017.02.006
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100005
DA 2024-07-18
ER

PT J
AU Zhang, QW
   Zhang, N
   Wei, T
   Huang, KQ
   Qian, XL
   Gan, Y
AF Zhang, Qiuwen
   Zhang, Na
   Wei, Tao
   Huang, Kunqiang
   Qian, Xiaoliang
   Gan, Yong
TI Fast depth map mode decision based on depth-texture correlation and edge
   classification for 3D-HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; Depth map; Mode decision; Edge classification
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; MULTIVIEW VIDEO;
   ALGORITHM
AB The 3D extension of High Efficiency Video Coding (3D-HEVC) has been adopted as the emerging 3D video coding standard to support the multi-view video plus depth map (MVD) compression. In the joint model of 3D-HEVC design, the exhaustive mode decision is required to be checked all the possible prediction modes and coding levels to find the one with least rate distortion cost in depth map coding. Furthermore, new coding tools (such as depth-modeling mode (DMM) and segment-wise depth coding (SDC)) are exploited for the characteristics of depth map to improve the coding efficiency. These achieve the highest possible coding efficiency to code depth map, but also bring a significant computational complexity which limits 3D-HEVC from real-time applications. In this paper, we propose a fast depth map mode decision algorithm for 3D-HEVC by jointly using the correlation of depth map-texture video and the edge information of depth map. Since the depth map and texture video represent the same scene at the same time instant (they have the same motion characteristics), it is not efficient to use all the prediction modes and coding levels in depth map coding. Therefore, we can skip some specific prediction modes and depth coding levels rarely used in corresponding texture video. Meanwhile, the depth map is mainly characterized by sharp object edges and large areas of nearly constant regions. By fully exploiting these characteristics, we can skip some prediction modes which are rarely used in homogeneity regions based on the edge classification. Experimental results show that the proposed algorithm achieves considerable encoding time saving while maintaining almost the same rate-distortion (RD) performance as the original 3D-HEVC encoder. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Zhang, Qiuwen; Zhang, Na; Huang, Kunqiang; Gan, Yong] Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, 5 Dongfeng Rd, Zhengzhou 450002, Peoples R China.
   [Wei, Tao] China Natl Digital Switching Syst Engn Technol R&, Zhengzhou 450002, Peoples R China.
   [Wei, Tao] Henan Inst Engn, Coll Comp, Zhengzhou 451191, Peoples R China.
   [Qian, Xiaoliang] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Zhengzhou 450002, Peoples R China.
C3 Zhengzhou University of Light Industry; Zhengzhou University of Light
   Industry
RP Zhang, QW (corresponding author), Zhengzhou Univ Light Ind, Coll Comp & Commun Engn, 5 Dongfeng Rd, Zhengzhou 450002, Peoples R China.
EM zhangqwen@126.com
RI Qian, Xiaoliang/AAV-1480-2020
FU National Natural Science Foundation of China [61302118, 61401404,
   61501407, 61572445, 61502435]; Program for Science and Technology
   Innovation Talents in Universities of Henan Province [17HASTIT022];
   Funding Scheme of Young Key Teacher of Henan Province Universities
   [2016GGJS-087]; Scientific and Technological Project of Henan Province
   [142300410248, 15102210357]; Scientific and Technological of the
   Education Department of Henan Province [15A520033, 17B510011, 16A520030,
   15A413006, 16A520028]; Doctorate Research Funding of Zhengzhou
   University of Light Industry [2013BSJJ047]
FX The authors would like to thank the editors and anonymous reviewers for
   their valuable comments. This work was supported in part by the National
   Natural Science Foundation of China under grant No. 61302118, 61401404,
   61501407, 61572445, and 61502435, the Program for Science and Technology
   Innovation Talents in Universities of Henan Province under grant No.
   17HASTIT022, the Funding Scheme of Young Key Teacher of Henan Province
   Universities under grant No. 2016GGJS-087, the Scientific and
   Technological Project of Henan Province under grant No. 142300410248,
   and 15102210357, the Scientific and Technological of the Education
   Department of Henan Province under grant No. 15A520033, 17B510011,
   16A520030, 15A413006, and 16A520028, and in part by the Doctorate
   Research Funding of Zhengzhou University of Light Industry, under grant
   No. 2013BSJJ047.
CR [Anonymous], 2012, INT C 3D IMAGING
   [Anonymous], 2015, D HEVC SOFTWARE HTM
   [Anonymous], IEEE T CONSUM ELECT
   [Anonymous], 2012, P ASIA PAC SIG INF P
   Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Cernigliaro G, 2013, IEEE T CIRC SYST VID, V23, P769, DOI 10.1109/TCSVT.2012.2223632
   Chen Y., 2015, 11 M GEN CH 12 18 FE
   Chen Y, 2014, IEEE MULTIMEDIA, V21, P90, DOI 10.1109/MMUL.2014.31
   Chung KL, 2016, IEEE T CIRC SYST VID, V26, P1859, DOI 10.1109/TCSVT.2015.2473296
   Conceicao R., 2016, P IEEE INT C IM PROC, V2016, P2381
   da Silva TL, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P229, DOI 10.1109/VCIP.2014.7051546
   Gu ZY, 2015, DISPLAYS, V40, P2, DOI 10.1016/j.displa.2015.05.007
   Gu ZY, 2013, IEEE INT CONF MULTI
   Kau P., SIGN PROCESS IMAGE C, V22
   Lee JY, 2011, IEEE T CIRC SYST VID, V21, P1859, DOI 10.1109/TCSVT.2011.2154730
   Lei J., 2016, IEEE T CIRC SYST VID
   Lei JJ, 2015, IEEE T IND INFORM, V11, P978, DOI 10.1109/TII.2015.2446769
   Lucas LFR, 2015, IEEE T IMAGE PROCESS, V24, P4055, DOI 10.1109/TIP.2015.2456509
   Mora EG, 2014, IEEE T CIRC SYST VID, V24, P1554, DOI 10.1109/TCSVT.2013.2283110
   Mueller K., 2014, JOINT COLLABORATIVE
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Park CS, 2015, ELECTRON LETT, V51, P756, DOI 10.1049/el.2014.3874
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Sanchez G, 2014, IEEE IMAGE PROC, P3209, DOI 10.1109/ICIP.2014.7025649
   Shen LQ, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700298
   Shen LQ, 2014, IEEE T BROADCAST, V60, P128, DOI 10.1109/TBC.2013.2289635
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Winken M, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P53, DOI 10.1109/PCS.2012.6213284
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhang H., 2016, IEEE T CIRC SYST VID
   Zhang MM, 2013, IEEE INT SYMP CIRC S, P2852, DOI 10.1109/ISCAS.2013.6572473
   Zhang QW, 2017, MULTIDIM SYST SIGN P, V28, P1203, DOI 10.1007/s11045-016-0388-1
   Zhang QW, 2014, ELECTRON LETT, V50, P994, DOI 10.1049/el.2014.0065
   Zhang QW, 2011, IEEE T CONSUM ELECTR, V57, P1857, DOI 10.1109/TCE.2011.6131164
NR 39
TC 28
Z9 32
U1 1
U2 47
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 170
EP 180
DI 10.1016/j.jvcir.2017.03.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100015
DA 2024-07-18
ER

PT J
AU Masoumi, M
   Ben Hamza, A
AF Masoumi, Majid
   Ben Hamza, A.
TI Spectral shape classification: A deep learning approach
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Spectral graph wavelet; Bag-of-features; Classification
ID DESCRIPTOR; SIGNATURE
AB In this paper, we propose a deep learning approach to 3D shape classification using spectral graph wavelets and the bag-of-features paradigm. In order to capture both the local and global geometry of a 3D shape, we present a three-step feature description strategy. Local descriptors are first extracted via the spectral graph wavelet transform having the Mexican hat wavelet as a generating kernel. Then, mid-level features are obtained by embedding local descriptors into the visual vocabulary space using the soft-assignment coding step of the bag-of-features model. A global descriptor is subsequently constructed by aggregating mid-level features weighted by a geodesic exponential kernel, resulting in a matrix representation that describes the frequency of appearance of nearby codewords in the vocabulary. Experimental results on two standard 3D shape benchmarks demonstrate the much better performance of the proposed approach in comparison with state-of-the-art methods. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Masoumi, Majid; Ben Hamza, A.] Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
C3 Concordia University - Canada
RP Ben Hamza, A (corresponding author), Concordia Univ, Concordia Inst Informat Syst Engn, Montreal, PQ, Canada.
EM hamza@ciise.concordia.ca
RI Hamza, Abdessamad Ben/G-4571-2013
OI Ben Hamza, Abdessamad/0000-0002-3778-8167
CR [Anonymous], 2015, Geometric methods in signal and image analysis
   [Anonymous], 2011, PROC EUROGRAPHICS 20, P79, DOI DOI 10.2312/3DOR/3DOR11/079-088
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Chaudhari AJ, 2014, PHYS MED BIOL, V59, P961, DOI 10.1088/0031-9155/59/4/961
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Gao ZH, 2014, COMPUT AIDED DESIGN, V53, P62, DOI 10.1016/j.cad.2014.03.008
   Gebal K, 2009, COMPUT GRAPH FORUM, V28, P1405, DOI 10.1111/j.1467-8659.2009.01517.x
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Khabou MA, 2007, PATTERN RECOGN, V40, P141, DOI 10.1016/j.patcog.2006.01.002
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Li CY, 2013, INT J MULTIMED INF R, V2, P261, DOI 10.1007/s13735-013-0041-9
   Li CY, 2014, MULTIMEDIA SYST, V20, P253, DOI 10.1007/s00530-013-0318-0
   Li CY, 2013, VISUAL COMPUT, V29, P513, DOI 10.1007/s00371-013-0815-3
   Lian Z., 2010, Eurographics Workshop on 3D Object Retrieval, V10, P101, DOI [10.2312/3DOR/3DOR10/101-108, 10.1109/CVPR.2014.491, DOI 10.2312/3DOR/3DOR10/101-108]
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Meyer M., 2002, VISUALIZATION MATH, V6, P35, DOI DOI 10.1007/978-3-662-05105-4_2
   Pickup D., 2014, Proceedings of the 7th Eurographics workshop on 3D Object Retrieval, EG 3DOR'14, P1
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rosenberg S., 1997, The Laplacian on a Riemannian Manifold: An Introduction to Analysis on Manifolds
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Tarmissi K, 2009, EXPERT SYST APPL, V36, P9409, DOI 10.1016/j.eswa.2008.12.062
   Wardetzky M., 2007, P EUROGRAPHICS S GEO, P33, DOI [DOI 10.2312/SGP/SGP07/033-037, 10.2312/SGP/SGP07/033-037]
NR 32
TC 22
Z9 23
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 198
EP 211
DI 10.1016/j.jvcir.2017.01.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400019
DA 2024-07-18
ER

PT J
AU Kuo, CCJ
AF Kuo, C. -C. Jay
TI Understanding convolutional neural networks with a mathematical model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network (CNN); Nonlinear activation; RECOS model;
   Rectified linear unit (ReLU); MNIST dataset
AB This work attempts to address two fundamental questions about the structure of the convolutional neural networks (CNN): (1) why a nonlinear activation function is essential at the filter output of all intermediate layers? (2) what is the advantage of the two-layer cascade system over the one-layer system? A mathematical model called the "REctified-COrrelations on a Sphere" (RECOS) is proposed to answer these two questions. After the CNN training process, the converged filter weights define a set of anchor vectors in the RECOS model. Anchor vectors represent the frequently occurring patterns (or the spectral components). The necessity of rectification is explained using the RECOS model. Then, the behavior of a two-layer RECOS system is analyzed and compared with its one-layer counterpart. The LeNet-5 and the MNIST dataset are used to illustrate discussion points. Finally, the RECOS model is generalized to a multilayer system with the AlexNet as an example. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Kuo, CCJ (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU DARPA; Air Force Research Laboratory (AFRL) [FA8750-16-2-0173]
FX The author would like to thank Mr. Zhehang Ding's help in running
   experiments and drawing figures for this article. This material is based
   on research sponsored by DARPA and Air Force Research Laboratory (AFRL)
   under agreement number FA8750-16-2-0173. The U.S. Government is
   authorized to reproduce and distribute reprints for Governmental
   purposes notwithstanding any copyright notation thereon. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of DARPA and Air Force
   Research Laboratory (AFRL) or the U.S. Government.
CR [Anonymous], DEEP INSIDE CONVOLTI
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], GENERATIVE MODELING
   [Anonymous], MATHEMATICAL THEORY
   Audhkhasi K, 2016, NEURAL NETWORKS, V78, P15, DOI 10.1016/j.neunet.2015.09.014
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Coates A., 2011, P 14 INT C ART INT S, V15, P215
   Cohen Nadav., On the Expressive Power of Deep Learning: A Tensor Analysis
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Juang BH, 2016, APSIPA TRANS SIGNAL, V5, DOI 10.1017/ATSIP.2016.9
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   McCulloch WS, 2016, EMBODIMENTS OF MIND, P19
   Montavon G., Explaining NonLinear Classification Decisions with Deep Taylor Decomposition
   Szegedy C., INTRIGUING PROPERTIE
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang L, 1999, IEEE T NEURAL NETWOR, V10, P925, DOI 10.1109/72.774263
   Zhou Bolei., 2014, Object detectors emerge in deep scene cnns
NR 20
TC 212
Z9 232
U1 2
U2 59
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 406
EP 413
DI 10.1016/j.jvcir.2016.11.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000035
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Megrhi, S
   Jmal, M
   Souidene, W
   Beghdadi, A
AF Megrhi, Sameh
   Jmal, Marwa
   Souidene, Wided
   Beghdadi, Azeddine
TI Spatio-temporal action localization and detection for human recognition
   in big dataset
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatio-temporal action detection; Dense SURF; Optical flow; Action
   recognition; Selective temporal segmentation; Interest points trajectory
ID MOTION; SEGMENTATION; FEATURES; OBJECT; MODELS; VIDEOS; SCENE
AB Human action recognition is still attracting the computer vision research community due to its various applications. However, despite the variety of methods proposed to solve this problem, some issues still need to be addressed. In this paper, we present a human action detection and recognition process on large datasets based on Interest Points trajectories. In order to detect moving humans in moving field of views, a spatio-temporal action detection is performed basing on optical flow and dense speed-up-robust features (SURF). Then, a video description based on a fusion process that combines motion, trajectory and visual descriptors is proposed. Features within each bounding box are extracted by exploiting the bag-of-words approach. Finally, a support-vector-machine is employed to classify the detected actions. Experimental results on the complex benchmark UCF101, KTH and HMDB51 datasets reveal that the proposed technique achieves better performances compared to some of the existing state-of-the-art action recognition approaches. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Megrhi, Sameh; Souidene, Wided; Beghdadi, Azeddine] Univ Paris 13, Inst Galilee, L2TI, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
   [Jmal, Marwa; Souidene, Wided] Univ Carthage, SERCom Lab, Ecole Polytech Tunisie, BP 743, La Marsa 2078, Tunisia.
   [Jmal, Marwa] Telnet Holding, Telnet Innovat Labs, Ariana, Tunisia.
C3 Universite Paris 13; Universite de Carthage
RP Jmal, M (corresponding author), Univ Carthage, SERCom Lab, Ecole Polytech Tunisie, BP 743, La Marsa 2078, Tunisia.
EM sameh.megrhi@univ-paris13.fr; marwa.jmal@ser-com-lab.com;
   wided.mseddi@univ-paris13.fr; azeddine.beghdadi@univ-paris13.fr
RI Beghdadi, Azeddine/ABF-9801-2022; Mseddi, Wided/AAD-7732-2021
OI Beghdadi, Azeddine/0000-0002-5595-0615; Mseddi,
   Wided/0000-0002-3002-4033
FU European Union under the PASRI project
FX The research and innovation work of the second author is carried out
   within a MOBIDOC thesis funded by the European Union under the PASRI
   project and administered by the ANPR.
CR [Anonymous], PATTERN RECOGN
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2009, BMVC 09
   [Anonymous], 2001, Pyramidal implementation of the affine lucas kanade feature tracker description of the algorithm5.1-10
   [Anonymous], 2013, ICCV WORKSH ACT REC
   [Anonymous], ABS12120402 CORR
   [Anonymous], 2004, ECCV
   [Anonymous], 2013, ICCV WORKSHOP ACTION
   [Anonymous], UNSUPERVISED LEARNIN
   [Anonymous], 2008, P BMVC 2008 19 BRIT
   [Anonymous], 2012, LNCS, DOI DOI 10.1007/978-3-642-35749-7_17
   [Anonymous], 2008, TEMPLATE MATCHING TE
   [Anonymous], ACTION RECOGNITION V
   [Anonymous], THESIS
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], 1994, INTRO COMPUTER GRAPH
   [Anonymous], THUMOS
   Ballas N, 2013, IEEE I CONF COMP VIS, P2704, DOI 10.1109/ICCV.2013.336
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Brox T, 2010, IMAGE VISION COMPUT, V28, P376, DOI 10.1016/j.imavis.2009.06.009
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cuntoor N.P., 2007, P IEEE COMPUTER SOC, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Fanti C, 2005, PROC CVPR IEEE, P1166
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844
   Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646
   Gaidon A., 2012, BMVC 2012-British Machine Vision Conference, P30
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hongjuan Wang, 2015, 2015 International Symposium on VLSI Technology, Systems and Applications (VLSI-TSA), P1, DOI 10.1109/VLSI-TSA.2015.7117563
   HORN BKP, 1981, P SOC PHOTO-OPT INST, V281, P319
   Ikizler N., Proceedings from International Conference on Pattern Recognition, 2008, P1
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Ishikawa S., 2008, Proceedings of the British Machine Vision Conference (BMVC'08), P1
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Jiang Y., 2014, ECCV WORKSH
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I., 2007, IEEE 11 INT C COMPUT, P1
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li WQ, 2008, IEEE T CIRC SYST VID, V18, P1499, DOI 10.1109/TCSVT.2008.2005597
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Megrhi Sameh, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P505, DOI 10.1007/978-3-319-03731-8_47
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Moosmann F., 2006, NIPS, V2, P4
   Murthy OVR, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P412, DOI 10.1109/ICCVW.2013.61
   Nga DH, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P420, DOI 10.1109/ICCVW.2013.62
   Ni BB, 2015, INT J COMPUT VISION, V111, P229, DOI 10.1007/s11263-014-0742-4
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Noguchi Akitsugu., 2012, Trends and Topics in Computer Vision, P153
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Piriou G, 2006, IEEE T IMAGE PROCESS, V15, P3417, DOI 10.1109/TIP.2006.881963
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shao L, 2012, PATTERN RECOGN LETT, V33, P438, DOI 10.1016/j.patrec.2011.05.015
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Sun J, 2010, IEEE INT CON MULTI, P322, DOI 10.1109/ICME.2010.5583046
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Tran K.N., 2011, Bmvc, V11, P1
   Uijlings JRR, 2010, IEEE T MULTIMEDIA, V12, P665, DOI 10.1109/TMM.2010.2052027
   Vrigkas M, 2014, COMPUT VIS IMAGE UND, V119, P27, DOI 10.1016/j.cviu.2013.11.007
   Wang Heng., 2013, International Journal of Computer Vision
   Wang-Chou Lu, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P315, DOI 10.1109/AVSS.2010.79
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Yu T.-H., 2010, P BRIT MACHINE VISIO, P56
   Zappella L, 2008, FRONT ARTIF INTEL AP, V184, P398, DOI 10.3233/978-1-58603-925-7-398
NR 86
TC 21
Z9 24
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 375
EP 390
DI 10.1016/j.jvcir.2016.10.016
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000033
DA 2024-07-18
ER

PT J
AU Xiao, JS
   Pang, GL
   Zhang, YQ
   Kuang, YL
   Yan, YC
   Wang, YX
AF Xiao, Jinsheng
   Pang, Guanlin
   Zhang, Yongqin
   Kuang, Yuli
   Yan, Yuchen
   Wang, Yixiang
TI Adaptive shock filter for image super-resolution and enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image enhancement; Image super-resolution; Image interpolation; Partial
   differential equation; Shock filter
ID MANY-CORE PROCESSORS; SPARSE REPRESENTATION; PARALLEL FRAMEWORK;
   DIFFUSION EQUATION; INTERPOLATION
AB In view of that image interpolation methods generally tend to produce considerable edge halos, blurring and aliasing artifacts for image super-resolution. A novel image enhancement algorithm based on adaptive shock filter for image super-resolution is proposed to solve this problem. The weight of shock filter can be adjusted adaptively according to the gradients of the interpolated high-resolution image. Thus the diffusion of image edges is suppressed and the artifacts are removed by the forward diffusion. Compared with the traditional shock filter, the proposed algorithm eliminates edge halos and jagged artifacts, whereas the fine image structures are reserved effectively. Theoretical analysis and experimental results demonstrate that the proposed algorithm can achieve better results than the state-of-the-art methods both subjectively and objectively in most cases. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Xiao, Jinsheng; Pang, Guanlin; Kuang, Yuli; Yan, Yuchen; Wang, Yixiang] Wuhan Univ, Sch Elect Informat, Wuhan 430072, Peoples R China.
   [Zhang, Yongqin] Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
   [Xiao, Jinsheng] Wuhan Univ, Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
C3 Wuhan University; Northwest University Xi'an; Wuhan University
RP Zhang, YQ (corresponding author), Northwest Univ, Sch Informat Sci & Technol, Xian 710127, Peoples R China.
EM xiaojs@whu.edu.cn; zhangyongqin@pku.edu.cn
RI Xiao, Jinsheng/AAG-2392-2019
OI Xiao, Jinsheng/0000-0002-5403-1895
FU National Natural Science Foundation of China [61471272, 61201442];
   Natural Science Basis Research Plan in Shaanxi Province of China
   [2016JQ6068]; China Postdoctoral Science Foundation [2013M530481]; State
   Scholarship Fund of China
FX This work was supported by National Natural Science Foundation of China
   (Grant Nos. 61471272, 61201442), State Scholarship Fund of China,
   Natural Science Basis Research Plan in Shaanxi Province of China (Grant
   No. 2016JQ6068), and China Postdoctoral Science Foundation (Grant No.
   2013M530481).
CR ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], 2011, P 19 ACM INT C MULT
   Battiato S, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P572, DOI 10.1109/ICIAP.2003.1234111
   Bettahar S, 2008, IMAGE VISION COMPUT, V26, P1481, DOI 10.1016/j.imavis.2008.02.010
   Bettahar S, 2012, IEEE T IMAGE PROCESS, V21, P2500, DOI 10.1109/TIP.2011.2177844
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Fu SJ, 2006, LECT NOTES COMPUT SC, V4153, P387
   [付树军 FU ShuJun], 2008, [计算机学报, Chinese Journal of Computers], V31, P529
   Getreuer P, 2011, SIAM J IMAGING SCI, V4, P954, DOI 10.1137/100802785
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Guemri K, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P279, DOI 10.1109/SOCPAR.2014.7008019
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Kornprobst P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P458, DOI 10.1109/ICIP.1997.638807
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Wang LF, 2013, IEEE T CIRC SYST VID, V23, P1289, DOI 10.1109/TCSVT.2013.2240915
   Xiao JS, 2016, SIGNAL PROCESS, V125, P171, DOI 10.1016/j.sigpro.2016.01.014
   Xiao JS, 2016, COLOR RES APPL, V41, P22, DOI 10.1002/col.21931
   Xiao JS, 2014, IET COMPUT VIS, V8, P358, DOI 10.1049/iet-cvi.2013.0230
   Xie J, 2015, IEEE T MULTIMEDIA, V17, P1525, DOI 10.1109/TMM.2015.2457678
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yu H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030259
   Zhang YQ, 2015, IEEE T IMAGE PROCESS, V24, P2797, DOI 10.1109/TIP.2015.2431435
NR 26
TC 22
Z9 22
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 168
EP 177
DI 10.1016/j.jvcir.2016.06.015
PN A
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500017
DA 2024-07-18
ER

PT J
AU Yang, Y
   Guo, L
   Ye, YD
AF Yang, Yong
   Guo, Ling
   Ye, Yangdong
TI Robust natural image segmentation by using spatially constrained
   multivariate mixed Student's <i>t</i>-distribution and TV flow edge
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatially constrained image segmentation; Total variation flow edge
   (TVFE); Expectation Maximum and Multilayer graph cut (EM(2)GC)
   algorithm; Spatially constrained multivariate mixed; Student's
   t-distribution
ID GRAPH-CUT; EXPECTATION-MAXIMIZATION; MIXTURE MODEL; EM ALGORITHM;
   RECOGNITION; RETRIEVAL
AB In this paper, a new method of spatially constrained energy function and total variation flow edge (TVFE) model is proposed for natural image segmentation. As the segmentation process of natural image is sensitive to corrupted noise, the Markov random field (MRF) based spatially constrained information is combined with Graph cut model. Secondly, a total variation flow edge is extracted by calculating the accumulated gradient difference from a nonlinear diffusion filter image. Thirdly, to improve the segmentation performance, the spatially constrained region term and the TVFE edge term are combined together. As the optimization solution of the proposed model is NP hard problem, and then an Expectation Maximum and Multilayer graph cut (EM(2)GC) algorithm is presented. Lastly, testing experiments are carried out on some synthetic images and real natural scene images, which demonstrate the superiority of our proposed method, such as the effectiveness, robustness, and high accuracy. (C) 2016 Published by Elsevier Inc.
C1 [Yang, Yong; Ye, Yangdong] Zhengzhou Univ, Sch Informat Engn, Zhengzhou 450063, Peoples R China.
   [Yang, Yong; Guo, Ling] Huang He Sci & Technol Coll, Sch Informat Engn, Zhengzhou 450063, Peoples R China.
   [Yang, Yong] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Zhengzhou University; Huazhong University of Science & Technology
RP Yang, Y (corresponding author), Huang He Sci & Technol Coll, Sch Informat Engn, Zhengzhou 450063, Peoples R China.
EM yangyong_825825@163.com
FU National Natural Science Foundation of China [61170223, 61502432]; Joint
   funds of the National Natural Science Foundation of China [U1204610];
   science research program of education department and technology
   department in Henan province [14A520054, 20130704]; Postdoctoral project
   of Henan province [2014022]; Henan province department of key scientific
   research project [152102210001]; intelligent image processing and
   pattern recognition key laboratory program of technology department of
   Zhengzhou city, in China [ZHENG[2013]2 Files]
FX The research has been supported by the National Natural Science
   Foundation of China (Grants 61170223, 61502432), Joint funds of the
   National Natural Science Foundation of China (Grant U1204610), the
   science research program of education department and technology
   department in Henan province (Grants 14A520054 and 20130704),
   Postdoctoral project of Henan province (Grant 2014022), Henan province
   department of key scientific research project (Grants 152102210001) and
   the intelligent image processing and pattern recognition key laboratory
   program of technology department of Zhengzhou city (Grant ZHENG[2013]2
   Files) is also gratefully acknowledged, in China.
CR [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587416
   Bae E, 2011, INT J COMPUT VISION, V92, P112, DOI 10.1007/s11263-010-0406-y
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Brox T, 2004, LECT NOTES COMPUT SC, V3022, P578
   Brox T, 2006, J VIS COMMUN IMAGE R, V17, P1053, DOI 10.1016/j.jvcir.2005.06.001
   Nguyen CH, 2014, IEEE T NEUR NET LEAR, V25, P1407, DOI 10.1109/TNNLS.2013.2292975
   Carpineto C, 2012, IEEE T PATTERN ANAL, V34, P2315, DOI 10.1109/TPAMI.2012.80
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chang JH, 2005, IEEE SIGNAL PROC LET, V12, P325, DOI 10.1109/LSP.2005.843763
   Chen SF, 2010, IEEE T IMAGE PROCESS, V19, P2254, DOI 10.1109/TIP.2010.2047164
   Chen XJ, 2012, IEEE T MED IMAGING, V31, P1521, DOI 10.1109/TMI.2012.2191302
   Cosker D, 2013, IEEE MULTIMEDIA, V20, P18, DOI 10.1109/MMUL.2012.61
   Dinits E. A., 1970, SOVIET MATH DOKLAD, V11, P1277
   Diplaros A, 2007, IEEE T NEURAL NETWOR, V18, P798, DOI 10.1109/TNN.2007.891190
   Fatakdawala H, 2010, IEEE T BIO-MED ENG, V57, P1676, DOI 10.1109/TBME.2010.2041232
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Fulkerson D., 1962, FLOW IN NETWORKS
   Gruslys A, 2014, IEEE T MED IMAGING, V33, P2118, DOI 10.1109/TMI.2014.2332370
   Han SD, 2009, IEEE T IMAGE PROCESS, V18, P2289, DOI 10.1109/TIP.2009.2025560
   Hao M, 2014, IEEE GEOSCI REMOTE S, V11, P210, DOI 10.1109/LGRS.2013.2252879
   Ilea DE, 2008, IEEE T IMAGE PROCESS, V17, P1926, DOI 10.1109/TIP.2008.2001047
   Khan ZH, 2011, IEEE T CIRC SYST VID, V21, P74, DOI 10.1109/TCSVT.2011.2106253
   Kolmogorov V, 2007, IEEE T PATTERN ANAL, V29, P1274, DOI 10.1109/TPAMI.2007.1031
   Le TH, 2010, ELECTRON LETT, V46, P1121, DOI 10.1049/el.2010.1692
   Lim CH, 2014, IEEE T FUZZY SYST, V22, P1541, DOI 10.1109/TFUZZ.2014.2298233
   Liu LM, 2011, PATTERN RECOGN, V44, P2819, DOI 10.1016/j.patcog.2011.04.031
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Reddy CK, 2008, IEEE T PATTERN ANAL, V30, P1146, DOI 10.1109/TPAMI.2007.70775
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   Sirmaçek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   Tang Z, 2011, IET IMAGE PROCESS, V5, P630, DOI 10.1049/iet-ipr.2010.0335
   Nguyen TM, 2013, IEEE T CIRC SYST VID, V23, P621, DOI 10.1109/TCSVT.2012.2211176
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Xing MD, 2011, IEEE T AERO ELEC SYS, V47, P214, DOI 10.1109/TAES.2011.5705671
   Yang XD, 2014, IEEE T HUM-MACH SYST, V44, P234, DOI 10.1109/THMS.2014.2302814
   Yang Y, 2013, PATTERN RECOGN, V46, P1101, DOI 10.1016/j.patcog.2012.09.024
   Zhang H, 2013, IEEE SIGNAL PROC LET, V20, P117, DOI 10.1109/LSP.2012.2230626
   Zhang R, 2010, IEEE T IMAGE PROCESS, V19, P2947, DOI 10.1109/TIP.2010.2051624
   Zhao F, 2013, IEEE IMAGE PROC, P2762, DOI 10.1109/ICIP.2013.6738569
NR 44
TC 1
Z9 1
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 178
EP 196
DI 10.1016/j.jvcir.2016.06.022
PN A
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500018
DA 2024-07-18
ER

PT J
AU Pandey, S
   Khanna, P
   Yokota, H
AF Pandey, Shreelekha
   Khanna, Pritee
   Yokota, Haruo
TI Clustering of hierarchical image database to reduce inter-and
   intra-semantic gaps in visual space for finding specific image semantics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Content based semantic retrieval; Visual search space; Clustering;
   Semantic gap; Semantic assignment; Semantically categorized image
   database
ID RETRIEVAL; FEATURES; ANNOTATION
AB Empowering content based systems to assign image semantics is an interesting concept. This work explores semantically categorized image database and forms a hierarchical visual search space. Overlapping of visual features of images from different categories and subcategories are possible reasons behind inter-semantic and intra-semantic gaps. Usually each category/node in the image database has a single representation, but variability and broadness of semantic limit the usage of such representation. This work explores the application of agglomerative hierarchical clustering to automatically identify groups within a semantic in the visual space. Visual signatures of dominant clusters corresponding to a node represent its semantic. Adaptive selection of branches on this clustered data facilitates efficient semantic assignment to query image in reduced search cost. Based on the concept, content based semantic retrieval system is developed and tested on hierarchical and non-hierarchical databases. Results showcase capability of the proposed system to reduce inter- and intra-semantic gaps. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Pandey, Shreelekha; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg Ja, Dumna Airport Rd, Jabalpur 482005, MP, India.
   [Yokota, Haruo] Tokyo Inst Technol, Grad Sch Informat Sci & Engn, Meguro Ku, 2-12-1 Ookayama, Tokyo 1528552, Japan.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Tokyo Institute of Technology
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg Ja, Dumna Airport Rd, Jabalpur 482005, MP, India.
EM shreelekha@iiitdmj.ac.in; pkhanna@iiitdmj.ac.in; yokota@cs.titech.ac.jp
RI Khanna, Pritee/V-5418-2019; Yokota, Haruo/N-6975-2014
OI Khanna, Pritee/0000-0003-0518-2133; Yokota, Haruo/0000-0001-9788-0443
CR [Anonymous], JCIS
   [Anonymous], 2014, INT C IND INF SYST I
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Belkhatir M, 2011, MULTIMEDIA SYST, V17, P135, DOI 10.1007/s00530-010-0207-8
   Chang EY, 1999, P SOC PHOTO-OPT INS, V3846, P281, DOI 10.1117/12.360433
   Chen YX, 2005, IEEE T IMAGE PROCESS, V14, P1187, DOI 10.1109/TIP.2005.849770
   Chou CH, 2004, PATTERN ANAL APPL, V7, P205, DOI 10.1007/s10044-004-0218-1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Deselaers T, 2011, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR.2011.5995474
   Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595
   Elkamel A., 2014, APPL INTELL, P1
   Gali R., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P243, DOI 10.1109/CICSyN.2012.52
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Goldberger J., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P158
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Hui H.W., 2010, INT J IMAGE PROCESS, V4, P192
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jia D, 2011, PROC CVPR IEEE, P785, DOI 10.1109/CVPR.2011.5995516
   Kinnaree P, 2011, PROCEDIA ENGINEER, V8, P36, DOI 10.1016/j.proeng.2011.03.007
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Malik F., 2012, 2012 International Conference on Innovation Management and Technology Research, P624, DOI 10.1109/ICIMTR.2012.6236471
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Nie WN, 2016, MASS SPECTROM REV, V35, P331, DOI 10.1002/mas.21439
   Pandey S, 2015, J VIS COMMUN IMAGE R, V30, P136, DOI 10.1016/j.jvcir.2015.03.010
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Sheikholeslami G, 2002, IEEE T KNOWL DATA EN, V14, P988, DOI 10.1109/TKDE.2002.1033769
   Sternberg R.J., 2008, COGNITIVE PSYCHOL, V5th
   Takahashi T, 2015, IEEE T PATTERN ANAL, V37, P1469, DOI 10.1109/TPAMI.2014.2382092
   Vassilieva NS, 2009, PROGRAM COMPUT SOFT+, V35, P158, DOI 10.1134/S0361768809030049
   Wang M, 2014, INFORM SCIENCES, V262, P159, DOI 10.1016/j.ins.2013.11.005
   Wang WY, 2014, LECT NOTES COMPUT SC, V8689, P756, DOI 10.1007/978-3-319-10590-1_49
   Wang XY, 2011, COMPUT STAND INTER, V33, P59, DOI 10.1016/j.csi.2010.03.004
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
NR 48
TC 4
Z9 4
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 704
EP 720
DI 10.1016/j.jvcir.2016.04.013
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100059
DA 2024-07-18
ER

PT J
AU Singh, D
   Singh, SK
AF Singh, Durgesh
   Singh, Sanjay K.
TI Effective self-embedding watermarking scheme for image tampered
   detection and localization with recovery capability
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fragile watermarking; Image authentication; Tamper localization; Image
   recovery; Discrete Cosine Transformation
ID SEMI-FRAGILE WATERMARKING; PARALLEL FRAMEWORK; AUTHENTICATION; HEVC;
   RECONSTRUCTION; STEGANALYSIS
AB This paper presents a Discrete Cosine Transformation (DCT) based effective self-recoverable fragile watermarking scheme. For each 2 x 2 non-overlapping block, two authentication bits, and ten recovery bits are generated from the five most significant bits (MSBs) of pixels. Authentication bits are embedded in the three least significant bits (LSBs) of the block itself while recovery bits are embedded in the three LSBs of the corresponding mapped block. The proposed watermarking scheme is also effective because the authentication of each block is based on two levels hierarchical tampered detection mechanisms. So the detection of tampered block can be ensured with high probability. The experimental results demonstrate that the proposed scheme not only outperforms high-quality restoration effectively, but also removes the blocking artifacts and improves the accuracy of tamper localization due to the use of very small size blocks, smoothing function and two levels tampering detection mechanisms. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Singh, Durgesh; Singh, Sanjay K.] Indian Inst Technol BHU Varanasi, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, D (corresponding author), Indian Inst Technol BHU Varanasi, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
EM durgesh.rs.cse13@iitbhu.ac.in; sks.cse@iitbhu.ac.in
RI Singh, Sanjay Kumar/AAC-2031-2022; Singh, Durgesh/AAZ-2801-2020; kumar,
   Sanjay/ITT-3680-2023; Singh, Sanjay Prithviraj/IQV-1492-2023
OI Singh, Sanjay Kumar/0000-0002-9061-6313; Singh,
   Durgesh/0000-0002-6078-1502; Singh, Sanjay
   Prithviraj/0000-0001-5043-8762
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2008 9 INT C SIGN PR
   [Anonymous], 2014, MASTERS THESIS
   Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   FRIEDMAN GL, 1993, IEEE T CONSUM ELECTR, V39, P905, DOI 10.1109/30.267415
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Korus P, 2014, IEEE T INF FOREN SEC, V9, P169, DOI 10.1109/TIFS.2013.2295154
   Korus P, 2013, IEEE T IMAGE PROCESS, V22, P1134, DOI 10.1109/TIP.2012.2227769
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Peng F, 2010, COMPUT AIDED DESIGN, V42, P1207, DOI 10.1016/j.cad.2010.08.004
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Qi XJ, 2011, J VIS COMMUN IMAGE R, V22, P187, DOI 10.1016/j.jvcir.2010.12.005
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   Shivani Shivendra, 2013, Pattern Recognition and Image Analysis. 6th Iberian Conference, IbPRIA 2013. Proceedings. LNCS 7887, P640
   Shivani S., 2011, P 2011 INT C COMM CO, P221
   Singh D., 2013, Intelligent Interactive Technologies and Multimedia, P111, DOI [10.1007/978-3-642-37463-010, DOI 10.1007/978-3-642-37463-010]
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Song CL, 2012, J VIS COMMUN IMAGE R, V23, P549, DOI 10.1016/j.jvcir.2012.01.017
   Tian LH, 2011, SIGNAL PROCESS-IMAGE, V26, P427, DOI 10.1016/j.image.2011.06.001
   Xia Z., 2014, MULTIMEDIA TOOLS APP, P1
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang X, 2007, IEEE SIGNAL PROC LET, V14, P727, DOI 10.1109/LSP.2007.896436
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2011, MULTIMED TOOLS APPL, V54, P385, DOI 10.1007/s11042-010-0541-z
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 37
TC 95
Z9 99
U1 1
U2 45
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 775
EP 789
DI 10.1016/j.jvcir.2016.04.023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100065
DA 2024-07-18
ER

PT J
AU Wójtowicz, W
   Ogiela, MR
AF Wojtowicz, Wioletta
   Ogiela, Marek R.
TI Digital images authentication scheme based on bimodal biometric
   watermarking in an independent domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking; Image authentication; Biometric watermarking;
   Independent Component Analysis (ICA); Biometric verification;
   Multibiometrics; Fingerprint recognition; Iris recognition
AB With the growing accessibility and usability of internet there is a growing concern over content protection of digital images. Recently, to eliminate the traditional use of passwords and to ensure that the access to the image is restricted only to legitimate users, security solutions are increasingly combined with biometrics. Consequently, biometric-based watermarking algorithms, that involve embedding the identity of the owner, are proposed to solve ownership disputes. This paper presents a new scheme for protecting and authenticating invisibly watermarked digital images. It applies Independent Component Analysis to the cover image and enables the insertion of two independent watermarks based on fingerprint and iris biometrics. In this approach biometric techniques are used for watermarks generation and for owners authentication. The main advantage of proposed algorithm is construction of ICA based watermarking domain to enable insertion of two independent watermarks, that improve authentication accuracy and makes scheme more robust. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wojtowicz, Wioletta; Ogiela, Marek R.] AGH Univ Sci & Technol, Cryptog & Cognit Informat Res Grp, Al Mickiewicza 30, PL-30059 Krakow, Poland.
C3 AGH University of Krakow
RP Wójtowicz, W (corresponding author), AGH Univ Sci & Technol, Cryptog & Cognit Informat Res Grp, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM wioletta.wojtowicz26@gmail.com; mogiela@agh.edu.pl
RI Ogiela, Marek R/A-7735-2013
FU program "Doctus - Malopolski fundusz stypendialny dla doktorantow"
FX Research of Wioletta Wojtowicz was supported by the program "Doctus -
   Malopolski fundusz stypendialny dla doktorantow".
CR Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Alilou V. K., 2013, FINGERPRINT MATCHING
   [Anonymous], 2008, HDB BIOMETRICS
   [Anonymous], 2011, INT J COMPUT APPL, DOI DOI 10.5120/1842-2493
   [Anonymous], J MACHINE LEARNING R
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   [Anonymous], 2006, Handbook of Multibiometrics
   Bringer J, 2011, SECUR COMMUN NETW, V4, P548, DOI 10.1002/sec.206
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Dittmann J., 2001, IEEE Multimedia, V8, P54, DOI 10.1109/93.959103
   Dutta M., 2014, P 2014 REC ADV ENG C, P1
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Hajisami A., 2012, WATERMARKING, V1
   Hassanien A., 2007, PATTEN RECOGN IMAGE, V16, P637
   Hyvarinen A, 1997, NEURAL COMPUT, V9, P1483, DOI 10.1162/neco.1997.9.7.1483
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Hyvärinen A, 2013, PHILOS T R SOC A, V371, DOI 10.1098/rsta.2011.0534
   Inamdar VS, 2014, SADHANA-ACAD P ENG S, V39, P3, DOI 10.1007/s12046-013-0208-3
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   JIN C, 2007, 8 INT WORKSH IM AN M, P70
   Koldovsky Z, 2006, IEEE T NEURAL NETWOR, V17, P1265, DOI 10.1109/TNN.2006.875991
   Komninos N, 2007, LECT NOTES COMPUT SC, V4642, P114
   Krishneswari K., 2012, Journal of Computer Science, V8, P431, DOI 10.3844/jcssp.2012.431.435
   Malekinezhad H, 2012, INT J ENG RES TECHNO, V1, P1
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Masek L., 2003, THESIS U W AUSTR
   Ogiela MR, 2008, SECTECH: 2008 INTERNATIONAL CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P125, DOI 10.1109/SecTech.2008.15
   Okman OE, 2007, J OPT SOC AM A, V24, P243, DOI 10.1364/JOSAA.24.000243
   Paunwala M, 2014, MACH VISION APPL, V25, P263, DOI 10.1007/s00138-013-0533-x
   Rao NN, 2009, INT J COMPUT SCI NET, V9, P157
   THAI R, 2003, THESIS U W AUSTR PER
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang CK, 2008, MUE: 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P263, DOI 10.1109/MUE.2008.45
   Wójtowicz W, 2015, SECUR COMMUN NETW, V8, P1672, DOI 10.1002/sec.1114
   Yin YL, 2011, LECT NOTES COMPUT SC, V7098, P260, DOI 10.1007/978-3-642-25449-9_33
NR 36
TC 26
Z9 26
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 1
EP 10
DI 10.1016/j.jvcir.2016.02.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100001
DA 2024-07-18
ER

PT J
AU Zhu, XG
   Hong, WH
   Xu, H
   Yu, L
   Zhao, Y
AF Zhu, Xingguo
   Hong, Wenhao
   Xu, Hu
   Yu, Lu
   Zhao, Yin
TI Spatial quality index based rate perceptual-distortion optimization for
   video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Perceptual video coding; Rate distortion optimization; Contrast masking;
   Motion masking; Spatial Quality Index
AB Spatial Quality Index (SQI) is a recently proposed video quality assessment metric that can predict video quality much close to subjective judgments. Since current video coding still has much redundancy in the sense of visual perception, in this paper, we incorporate SQI into video coding to further improve compression ratio without visual quality loss. Firstly, contributions of different human visual system (HVS) properties used in SQI are analyzed. Then two most important HVS properties, i.e. contrast masking effect (CME) and motion masking effect (MME), are extracted to measure perceptual-distortion D-p in video coding. Finally, based on D-p, a rate perceptual-distortion optimization (RpDO) algorithm is presented by adopting a suitable Lagrange multiplier from previous study. Experimental results show that, RpDO can averagely achieve 14% bitrate reduction when compared to HM14.0 under the same visual quality. At the same time, there is no significant change in the encoding time. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhu, Xingguo; Hong, Wenhao; Xu, Hu; Yu, Lu] Zhejiang Univ, Inst Informat & Commun Engn, Zhejiang Prov Key Lab Informat Proc Commun & Netw, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhao, Yin] Huawei Technol Co Ltd, Cent Res Inst, Hangzhou 310052, Zhejiang, Peoples R China.
C3 Zhejiang University; Huawei Technologies
RP Yu, L (corresponding author), Zhejiang Univ, Inst Informat & Commun Engn, Zhejiang Prov Key Lab Informat Proc Commun & Netw, Hangzhou 310027, Zhejiang, Peoples R China.
EM 05xxgcsgx@zju.edu.cn; hongwh@zju.edu.cn; 3090104746@zju.edu.cn;
   yul@zju.edu.cn; yin.zhao@huawei.com
OI Yu, Lu/0000-0002-0550-7754
FU National Natural Science Foundation of China [61371162, 61431015]
FX The authors would like to thank all volunteers who help us finish the
   subjective assessment. Thank Dr. Shen for his kindly help. This work is
   supported by National Natural Science Foundation of China (Nos. 61371162
   and 61431015).
CR Adzic V, 2014, PROC SPIE, V9014, DOI 10.1117/12.2043130
   Adzic V, 2014, PROC SPIE, V9014, DOI 10.1117/12.2043150
   Bjontegaard G., 13 VCEG M AUST TEX U
   Bossen F., JCTVCL1100
   Cen F, 2014, I SYMP CONSUM ELECTR, P19
   Chen ZZ, 2010, IEEE INT CON MULTI, P784, DOI 10.1109/ICME.2010.5582549
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1614, DOI 10.1109/TCSVT.2010.2087472
   Lee JS, 2012, IEEE J-STSP, V6, P684, DOI 10.1109/JSTSP.2012.2215006
   Li N., 1992, Proceedings of the SPIE - The International Society for Optical Engineering, V1818, P1116, DOI 10.1117/12.131383
   Mai ZY, 2005, LECT NOTES COMPUT SC, V3708, P435
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wang SQ, 2012, IEEE T CIRC SYST VID, V22, P516, DOI 10.1109/TCSVT.2011.2168269
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   WESTERINK JHDM, 1995, DISPLAYS, V16, P89, DOI 10.1016/0141-9382(95)91178-5
   Wu HR, 2013, P IEEE, V101, P2025, DOI 10.1109/JPROC.2013.2262911
   Xu L., 2013, VISUAL COMMUNICATION, P1
   Yang CL, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P291, DOI 10.1109/ICICISYS.2009.5357689
   Yeo CH, 2013, IEEE T CIRC SYST VID, V23, P1170, DOI 10.1109/TCSVT.2013.2240918
   Zhao Y, 2011, IEEE T CIRC SYST VID, V21, P1890, DOI 10.1109/TCSVT.2011.2157189
NR 21
TC 3
Z9 3
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 423
EP 432
DI 10.1016/j.jvcir.2016.03.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100036
DA 2024-07-18
ER

PT J
AU Bondi, L
   Baroffio, L
   Cesana, M
   Tagliasacchi, M
   Chiachia, G
   Rocha, A
AF Bondi, L.
   Baroffio, L.
   Cesana, M.
   Tagliasacchi, M.
   Chiachia, G.
   Rocha, A.
TI Rate-energy-accuracy optimization of convolutional architectures for
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional architectures; Convolutional Neural Networks (CNNs);
   Optimization; Coding; Face recognition; Analyze-then-Compress (ATC);
   Deep learning; Deep neural networks
ID REPRESENTATIONS
AB Face recognition systems based on Convolutional Neural Networks (CNNs) or convolutional architectures currently represent the state of the art, achieving an accuracy comparable to that of humans. Nonetheless, there are two issues that might hinder their adoption on distributed battery-operated devices (e.g., visual sensor nodes, smartphones, and wearable devices). First, convolutional architectures are usually computationally demanding, especially when the depth of the network is increased to maximize accuracy. Second, transmitting the output features produced by a CNN might require a bitrate higher than the one needed for coding the input image. Therefore, in this paper we address the problem of optimizing the energy-rate-accuracy characteristics of a convolutional architecture for face recognition. We carefully profile a CNN implementation on a Raspberry Pi device and optimize the structure of the neural network, achieving a 17-fold speedup without significantly affecting recognition accuracy. Moreover, we propose a coding architecture custom-tailored to features extracted by such model. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Bondi, L.; Baroffio, L.; Cesana, M.; Tagliasacchi, M.] Politecn Milan, Dipartimento Elettron Informaz & Bioingg, Piazza Leonardo Da Vinci 32, I-20133 Milan, Italy.
   [Chiachia, G.; Rocha, A.] Univ Estadual Campinas, Inst Comp, Reasoning Complex Data RECOD Lab, UNICAMP, Campinas, SP, Brazil.
C3 Polytechnic University of Milan; Universidade Estadual de Campinas
RP Baroffio, L (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingg, Piazza Leonardo Da Vinci 32, I-20133 Milan, Italy.
EM luca.bondi@polimi.it; luca.baroffio@polimi.it; matteo.cesana@polimi.it;
   marco.taglisacchi@polimi.it; chiachia@ic.unicamp.br; rocha@ic.unicamp.br
RI Cesana, Matteo/B-5443-2012; Bondi, Luca/L-4871-2015; Rocha,
   Anderson/KHU-9621-2024
OI Bondi, Luca/0000-0003-3974-7542; 
FU Future and Emerging Technologies (FET) programme within the Seventh
   Framework Programme for Research of the European Commission, under
   FET-Open Grant [296676]; Brazilian National Research Council (CNPq);
   Brazilian Coordination for the Improvement of Higher Education Personnel
   (CAPES), through the DeepEyes project; Sao Paulo Research Foundation
   (FAPESP) [2013/11359-0]; Fundacao de Amparo a Pesquisa do Estado de Sao
   Paulo (FAPESP) [13/11359-0] Funding Source: FAPESP
FX The project GreenEyes acknowledges the financial support of the Future
   and Emerging Technologies (FET) programme within the Seventh Framework
   Programme for Research of the European Commission, under FET-Open Grant
   No.: 296676. We also thank the financial support of the Brazilian
   National Research Council (CNPq) and the Brazilian Coordination for the
   Improvement of Higher Education Personnel (CAPES), through the DeepEyes
   project, and of the Sao Paulo Research Foundation (FAPESP) through Grant
   No. 2013/11359-0.
CR [Anonymous], 2008, HDB BIOMETRICS
   [Anonymous], 1973, THESIS KYOTO U
   [Anonymous], 2013, Biometrics (ICB), 2013 International Conference on
   [Anonymous], INTRO BIOMETRICS
   [Anonymous], MODEL METHOD FACIAL
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Baroffio L, 2014, IEEE T IMAGE PROCESS, V23, P2262, DOI 10.1109/TIP.2014.2312617
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Chiachia G, 2014, IEEE T INF FOREN SEC, V9, P2089, DOI 10.1109/TIFS.2014.2359543
   Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Huang GB, 2012, PROC CVPR IEEE, P2518, DOI 10.1109/CVPR.2012.6247968
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Li S.Z., 2005, Handbook of Face Recognition
   Makar M, 2013, INT J SEMANT COMPUT, V7, P5, DOI 10.1142/S1793351X13400011
   Phillips P. Jonathon, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P346, DOI 10.1109/FG.2011.5771424
   Pinto Z., 2011, CVPR 2011 WORKSH, P35, DOI DOI 10.1109/CVPRW.2011.5981788
   Redondi A, 2013, IEEE IMAGE PROC, P2910, DOI 10.1109/ICIP.2013.6738599
   Redondi A, 2013, IEEE INT WORKSH MULT, P278, DOI 10.1109/MMSP.2013.6659301
   Rotshtein P, 2005, NAT NEUROSCI, V8, P107, DOI 10.1038/nn1370
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
NR 25
TC 3
Z9 3
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 142
EP 148
DI 10.1016/j.jvcir.2015.12.015
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, XX
   Wang, RG
   Jiang, XB
   Wang, WM
   Gao, W
AF Zhang, Xinxin
   Wang, Ronggang
   Jiang, Xiubao
   Wang, Wenmin
   Gao, Wen
TI Spatially variant defocus blur map estimation and deblurring from a
   single image
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatially variant blur; Edge information; Defocus image deblurring;
   Image deblurring; Blur map estimation; Ringing artifacts removal; Image
   restoration; Non-blind deconvolution
ID PARALLEL FRAMEWORK; RESTORATION; CAMERA; MOTION; DEPTH
AB In this paper, we propose a single image deblurring algorithm to remove spatially variant defocus blur based on the estimated blur map. Firstly, we estimate the blur map from a single image by utilizing the edge information and K nearest neighbors (KNN) matting interpolation. Secondly, the local kernels are derived by segmenting the blur map according to the blur amount of local regions and image contours. Thirdly, we adopt a BM3D-based non-blind deconvolution algorithm to restore the latent image. Finally, ringing artifacts and noise are detected and removed, to obtain a high quality in-focus image. Experimental results on real defocus blurred images demonstrate that our proposed algorithm outperforms some state-of-the-art approaches. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhang, Xinxin; Wang, Ronggang; Jiang, Xiubao; Wang, Wenmin; Gao, Wen] Peking Univ, Shenzhen Grad Sch, Beijing, Peoples R China.
C3 Peking University
RP Wang, RG (corresponding author), Peking Univ, Shenzhen Grad Sch, Beijing, Peoples R China.
EM rgwang@pkusz.edu.cn
RI Zhang, Xinxin/HZJ-1742-2023; Wang, Wenmin/W-3511-2019
OI Zhang, Xinxin/0000-0001-6069-5391; Wang, Wenmin/0000-0003-2664-4413
FU National Science Foundation of China [61370115, 61402018]; China 863
   project [2015AA015905]; Shenzhen Peacock Plan; Fundamental Research
   Project
FX Thanks to National Science Foundation of China 61370115 and 61402018,
   China 863 project of 2015AA015905, Shenzhen Peacock Plan and Fundamental
   Research Project for funding.
CR [Anonymous], IPSJ T COMPUT VIS AP
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Bando Y, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P363, DOI 10.1109/PG.2007.22
   Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954
   Chan SH, 2011, IEEE IMAGE PROC, P677, DOI 10.1109/ICIP.2011.6116643
   Chen QF, 2013, IEEE T PATTERN ANAL, V35, P2175, DOI 10.1109/TPAMI.2013.18
   Cheong H, 2015, SENSORS-BASEL, V15, P880, DOI 10.3390/s150100880
   Dabov K., 2008, ELECT IMAGING 2008
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hu Z, 2014, PROC CVPR IEEE, P2893, DOI 10.1109/CVPR.2014.370
   Hu Z, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.136
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Lin YB, 2015, J VIS COMMUN IMAGE R, V26, P80, DOI 10.1016/j.jvcir.2014.11.004
   Mori G, 2005, IEEE I CONF COMP VIS, P1417
   Namboodiri V.P., 2008, 2008 IEEE C COMPUTER, P1, DOI [10.1109/CVPR.2008.4587779, DOI 10.1109/CVPR.2008.4587779]
   Oliveira JP, 2014, IEEE T IMAGE PROCESS, V23, P466, DOI 10.1109/TIP.2013.2286328
   SHEN CT, 2012, INT C AC SPEECH SIGN, P1069
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Tai Y.W., INT C IM PROC ICIP, P1797
   Tang C, 2013, OPT LETT, V38, P1706, DOI 10.1364/OL.38.001706
   Vu DT, 2014, IEEE T IMAGE PROCESS, V23, P3428, DOI 10.1109/TIP.2014.2329389
   Whyte O., 2011, P CPCV WORKSH INT C, P185
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xue F, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2014.2380174
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhou CY, 2011, INT J COMPUT VISION, V93, P53, DOI 10.1007/s11263-010-0409-8
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 31
TC 57
Z9 67
U1 2
U2 38
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2016
VL 35
BP 257
EP 264
DI 10.1016/j.jvcir.2016.01.002
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DD4GD
UT WOS:000369879600023
OA hybrid
DA 2024-07-18
ER

PT J
AU Song, KC
   Yan, YH
   Zhao, YJ
   Liu, CS
AF Song, Kechen
   Yan, Yunhui
   Zhao, Yongjie
   Liu, Changsheng
TI Adjacent evaluation of local binary pattern for texture classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adjacent evaluation; Local binary pattern; Completed local binary
   pattern; Local ternary pattern; Rotation invariance; Texture
   classification; Texture descriptor; Texture database
ID RETRIEVAL; REPRESENTATION; OPERATOR
AB This paper presents a novel, simple, yet robust texture descriptor against noise named the adjacent evaluation local binary patterns (AELBP) for texture classification. In the proposed approach, an adjacent evaluation window is constructed to modify the threshold scheme of LBP. The neighbors of the neighborhood center g(c) are set as the evaluation center a(p). Surrounding the evaluation center, we set up an evaluation window and calculate the value of a(p), and then extract the local binary codes by comparing the value of a(p) with the value of the neighborhood center g(c). Moreover, this adjacent evaluation method is generalized and can be integrated with the existing LBP variants such as completed local binary pattern (CLBP) and local ternary pattern (LTP) to derive new image features against noise for texture classification. The proposed approaches are compared with the state-of-the-art approaches on Outex and CUReT databases, and evaluated on three challenging databases (i.e. UIUC, UMD and ALOT databases) for texture classification. Experimental results demonstrate that the proposed approaches present a solid power of texture classification under illumination and rotation variations, significant viewpoint changes, and significant large-scale challenging conditions. Furthermore, the proposed approaches are more robust against noise and consistently outperform all the basic approaches in comparison. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Song, Kechen; Yan, Yunhui; Zhao, Yongjie] Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Peoples R China.
   [Liu, Changsheng] Northeastern Univ, Key Lab Anisotropy & Texture Mat, Minist Educ, Shenyang, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Song, KC (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Peoples R China.
EM unkechen@gmail.com
RI Yan, Yunhui/HDL-7343-2022; Liu, Chang/ISV-3950-2023; Song,
   Kechen/T-1896-2019
OI Yan, Yunhui/0000-0001-7121-2367; Song, Kechen/0000-0002-7636-3460; Zhao,
   Yongjie/0000-0002-1865-258X
FU National Natural Science Foundation of China [51374063]; Fundamental
   Research Funds for the Central Universities [N140303008, N141008001,
   N130810001]
FX This work is supported by the National Natural Science Foundation of
   China (51374063) and the Fundamental Research Funds for the Central
   Universities (N140303008, N141008001, N130810001). The authors would
   like to sincerely thank MVG and Guo for sharing the source codes of LBP
   and CLBP.
CR Abbadeni N, 2010, J VIS COMMUN IMAGE R, V21, P651, DOI 10.1016/j.jvcir.2010.04.004
   Aptoula E, 2012, J VIS COMMUN IMAGE R, V23, P1213, DOI 10.1016/j.jvcir.2012.08.005
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Burghouts GJ, 2009, PATTERN RECOGN LETT, V30, P306, DOI 10.1016/j.patrec.2008.10.005
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   El Maliani AD, 2014, J VIS COMMUN IMAGE R, V25, P1717, DOI 10.1016/j.jvcir.2014.06.004
   Fathi A, 2012, PATTERN RECOGN LETT, V33, P1093, DOI 10.1016/j.patrec.2012.01.017
   Fernández A, 2013, J MATH IMAGING VIS, V45, P76, DOI 10.1007/s10851-012-0349-8
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Julesz B., 1962, IEEE T INFORM THEORY, V8, P84, DOI DOI 10.1109/TIT.1962.1057698
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Khellah FM, 2011, IEEE T IMAGE PROCESS, V20, P3270, DOI 10.1109/TIP.2011.2143422
   Krishnamoorthi R, 2012, J VIS COMMUN IMAGE R, V23, P18, DOI 10.1016/j.jvcir.2011.07.011
   Lategahn H, 2010, IEEE T IMAGE PROCESS, V19, P1548, DOI 10.1109/TIP.2010.2042100
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Maani R, 2013, IEEE T IMAGE PROCESS, V22, P2409, DOI 10.1109/TIP.2013.2249081
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P193, DOI 10.1007/978-0-85729-748-8_13
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Sokal R.R., 1969, BIOMETRY
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang X, 2010, J VIS COMMUN IMAGE R, V21, P29, DOI 10.1016/j.jvcir.2009.09.010
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Zand M, 2015, J VIS COMMUN IMAGE R, V26, P305, DOI 10.1016/j.jvcir.2014.10.005
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhou H, 2008, INFORM SCIENCES, V178, P4314, DOI 10.1016/j.ins.2008.07.015
NR 42
TC 38
Z9 39
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 323
EP 339
DI 10.1016/j.jvcir.2015.09.016
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700029
DA 2024-07-18
ER

PT J
AU Kazmi, W
   Andersen, HJ
AF Kazmi, Wajahat
   Andersen, Hans Jorgen
TI A comparison of interest point and region detectors on structured, range
   and texture images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Affine invariant regions; Edge shapes; Local features; Detectors;
   Descriptors; Image retrieval; Harris corners; Hessian; SIFT; SURF
ID PERFORMANCE EVALUATION; AFFINE; SCALE
AB This article presents an evaluation of the image retrieval and classification potential of local features. Several affine invariant region and scale invariant interest point detectors in combination with well known descriptors were evaluated. Tests on building, range and texture databases were carried out in order to understand the effects of the nature and the variability of the data on the performance of the detectors in terms of their invariance to affine deformations and scale changes. Furthermore, a novel multi-scale edge shape detector, Twin Leaf Regions (TLR) is also proposed using a graph based image decomposition. In TLR, Affine adaptation is avoided in order to reduce the offset from the edges so that pure edges shapes are captured in multiple scales. In the evaluation of building recognition, both homogeneous affine regions (such as Maximally Stable Extremal Regions (MSER)) and corner based detectors (such as Hessian and Harris with both Affine/Laplace variants, SURF with determinant of Hessian based corners and SIFT with difference of Gaussians) acquired more than 90% mean average precision, whereas on range images, homogeneous region detector did not work well. TLR offered good performance than MSER and comparable performance to Harris Affine and Harris Laplace in range image classification and texture retrieval. But its performance was low in building recognition. In general, it was observed that the affine and scale invariance becomes less effective in range and textured images. It is also shown that in a bi-channel approach, combining surface and edge regions (MSER and TLR) boosts the overall performance. Among the descriptors, SIFT and SURF generally offer higher performance but low dimensional descriptors such as Steerable Filters follow closely. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Kazmi, Wajahat; Andersen, Hans Jorgen] Aalborg Univ, Dept Architecture Design & Media Technol, DK-9000 Aalborg, Denmark.
C3 Aalborg University
RP Kazmi, W (corresponding author), Aalborg Univ, Dept Architecture Design & Media Technol, Rendsburggade 14-5, DK-9000 Aalborg, Denmark.
EM wajahat.kazmi@outlook.com; hja@create.aau.dk
RI Andersen, Hans Jørgen/J-3540-2016
OI Andersen, Hans Jørgen/0000-0002-0940-0698; Kazmi,
   Wajahat/0000-0002-4608-6810
FU Danish Council for Strategic Research under ASETA [09-067027]
FX This research was supported by the Danish Council for Strategic Research
   under ASETA project (www.aseta.dk), Grant No. 09-067027. Special thanks
   to late Dr. Nikolai Chernov, Department of Mathematics, University of
   Alabama at Birmingham, USA and Dr. Richard Brown, Massey University, New
   Zealand for their help and cooperation.
CR Abdelmounaime Safia, 2013, ISRN Machine Vision, DOI 10.1155/2013/876386
   [Anonymous], 2003, P BRIT MACHINE VISIO, DOI [DOI 10.5244/C.17.79.2, 10.5244/C.17.79, DOI 10.5244/C.17.79]
   Arandjelovic R., 2011, INTERNATIONAL CONFER
   Avrithis Y, 2011, IEEE I CONF COMP VIS, P1724, DOI 10.1109/ICCV.2011.6126436
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cormack G. V., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P533, DOI 10.1145/1148170.1148262
   Distasi R, 1997, IEEE T COMMUN, V45, P1095, DOI 10.1109/26.623074
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gilles S., 1998, THESIS
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kazmi W, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P165
   Kim J, 2011, PROC CVPR IEEE, P1553, DOI 10.1109/CVPR.2011.5995526
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning C.D., 2008, EVALUATION IN INFORM
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Meyer GE, 2008, COMPUT ELECTRON AGR, V63, P282, DOI 10.1016/j.compag.2008.03.009
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE I CONF COMP VIS, P1792
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Picard R. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P638, DOI 10.1109/CVPR.1993.341050
   Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4
   Shao H., 2003, TECH REPORT NO 206
   Shotton J, 2008, IEEE T PATTERN ANAL, V30, P1270, DOI 10.1109/TPAMI.2007.70772
   Steder B., 2010, WORKSHOP ON DEFINING
   Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Varytimidis C., 2012, EUROPEAN CONFERENCE, DOI DOI 10.1007/978-3-642-33709-3\_56
   Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263
NR 42
TC 6
Z9 7
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 156
EP 169
DI 10.1016/j.jvcir.2015.08.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300013
DA 2024-07-18
ER

PT J
AU Hung, KW
   Siu, WC
AF Hung, Kwok-Wai
   Siu, Wan-Chi
TI Learning-based image interpolation via robust <i>k</i>-NN searching for
   coherent AR parameters estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image interpolation; Autoregressive model; Learning-based algorithms;
   Super-resolution; Soft-decision estimation; K-means clustering; Weighted
   least squares; Robust estimation
ID SIMILARITY
AB Image interpolation is to convert a low-resolution (LR) image into a high-resolution (HR) image through mathematical modeling. An accurate model usually leads to a better reconstruction quality, and the autoregressive (AR) model is a widely adopted model for image interpolation. Although a large amount of works have been done on AR models for image interpolation, there are plenty of rooms for improvements. In this work, we propose a robust and precise k-nearest neighbors (k-NN) searching scheme to form an accurate AR model of the local statistic. We make use of both LR and HR information obtained from a large amount of training data, in order to form a coherent soft-decision estimation of both AR parameters and high-resolution pixels. Experimental results show that the proposed learning-based AR interpolation algorithm has a very competitive performance compared with the state-of-the-art image interpolation algorithms in terms of PSNR and SSIM values. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hung, Kwok-Wai; Siu, Wan-Chi] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Hung, KW (corresponding author), PolyU, DE503, EIE, Hong Kong, Hong Kong, Peoples R China.
EM kwokwai.hung@connect.polyu.hk
FU Center for Signal Processing; Hong Kong Polytechnic University (G.YBAS);
   Research Grant Council of the Hong Kong SAR Government
   [PolyU5243/13E(B-Q38S)]
FX This work is supported by the Center for Signal Processing, the Hong
   Kong Polytechnic University (G.YBAS) and the Research Grant Council of
   the Hong Kong SAR Government: PolyU5243/13E(B-Q38S).
CR [Anonymous], 1992, R. woods digital image processing
   Chen HY, 2012, J VIS COMMUN IMAGE R, V23, P343, DOI 10.1016/j.jvcir.2011.11.006
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   GOSHTASBY A, 1984, IEEE T PATTERN ANAL, V6, P374, DOI 10.1109/TPAMI.1984.4767532
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Li MD, 2013, IEEE INT SYMP CIRC S, P2143, DOI 10.1109/ISCAS.2013.6572298
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu J, 2013, IEEE INT SYMP CIRC S, P765, DOI 10.1109/ISCAS.2013.6571959
   Liu XM, 2011, IEEE T IMAGE PROCESS, V20, P3455, DOI 10.1109/TIP.2011.2150234
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Ni KS, 2009, IEEE T IMAGE PROCESS, V18, P1976, DOI 10.1109/TIP.2009.2023706
   Niu Y, 2012, J VIS COMMUN IMAGE R, V23, P1144, DOI 10.1016/j.jvcir.2012.07.001
   Papamakarios G., 2009, P SOC PHOTO-OPT INS, V7444
   Ren J, 2011, IEEE IMAGE PROC, P1177, DOI 10.1109/ICIP.2011.6115639
   Sun X, 2008, PROC SPIE, V7074, DOI 10.1117/12.796332
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan B, 2013, J VIS COMMUN IMAGE R, V24, P661, DOI 10.1016/j.jvcir.2011.12.002
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 19
TC 7
Z9 7
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 305
EP 311
DI 10.1016/j.jvcir.2015.07.006
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600027
DA 2024-07-18
ER

PT J
AU Hu, WC
   Chen, CH
   Chen, TY
   Huang, DY
   Wu, ZC
AF Hu, Wu-Chih
   Chen, Chao-Ho
   Chen, Tsong-Yi
   Huang, Deng-Yuan
   Wu, Zong-Che
TI Moving object detection and tracking from video captured by moving
   camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Moving camera; Object tracking; Feature
   classification; Image difference; Object motion; Motion history;
   Ego-motion compensation
ID MOTION ESTIMATION; RANDOM-FIELD; SEGMENTATION
AB This paper presents an effective method for the detection and tracking of multiple moving objects from a video sequence captured by a moving camera without additional sensors. Moving object detection is relatively difficult for video captured by a moving camera, since camera motion and object motion are mixed. In the proposed method, the feature points in the frames are found and then classified as belonging to foreground or background features. Next, moving object regions are obtained using an integration scheme based on foreground feature points and foreground regions, which are obtained using an image difference scheme. Then, a compensation scheme based on the motion history of the continuous motion contours obtained from three consecutive frames is applied to increase the regions of moving objects. Moving objects are detected using a refinement scheme and a minimum bounding box. Finally, moving object tracking is achieved using a Kalman filter based on the center of gravity of a moving object region in the minimum bounding box. Experimental results show that the proposed method has good performance. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hu, Wu-Chih] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Penghu, Taiwan.
   [Chen, Chao-Ho; Chen, Tsong-Yi] Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.
   [Huang, Deng-Yuan] Dayeh Univ, Dept Elect Engn, Dacun, Taiwan.
   [Wu, Zong-Che] Whetron Elect Co Ltd, Taipei, Taiwan.
C3 National Penghu University of Science & Technology; National Kaohsiung
   University of Science & Technology; Da Yeh University
RP Chen, CH (corresponding author), Natl Kaohsiung Univ Appl Sci, Dept Elect Engn, Kaohsiung 807, Taiwan.
EM wchu@npu.edu.tw; thouho@cc.kuas.edu.tw; chentso@cc.kuas.edu.tw;
   kevin@mail.dyu.edu.tw; zongche.wu@whetron.com.tw
FU Ministry of Science and Technology, Taiwan [MOST103-2221-E-151-030,
   MOST103-2221-E-346-007]
FX This work was partly supported by the Ministry of Science and
   Technology, Taiwan, under Grants MOST103-2221-E-151-030 and
   MOST103-2221-E-346-007. The authors would like to thank Mr. Jhih-Bin Guo
   for his help with the experiments. The authors also gratefully
   acknowledge the helpful comments and suggestions of reviewers, which
   have improved the quality and presentation.
CR [Anonymous], 2014, ADV INTELLIGENT SYST
   Arvanitidou MG, 2013, SIGNAL PROCESS-IMAGE, V28, P1420, DOI 10.1016/j.image.2013.09.008
   Borges PVK, 2013, IEEE T CIRC SYST VID, V23, P1993, DOI 10.1109/TCSVT.2013.2270402
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   Tran D, 2014, IEEE T PATTERN ANAL, V36, P404, DOI 10.1109/TPAMI.2013.137
   Ferone A, 2014, IEEE T SYST MAN CY-S, V44, P571, DOI 10.1109/TSMC.2013.2280121
   Ghosh A, 2012, IEEE T CIRC SYST VID, V22, P1127, DOI 10.1109/TCSVT.2012.2190476
   Hu W.-C., 2010, ICIC EXPRESS LETT B, V1, P45
   Hu WC, 2012, J VIS COMMUN IMAGE R, V23, P303, DOI 10.1016/j.jvcir.2011.10.008
   Hu WC, 2011, J VIS COMMUN IMAGE R, V22, P543, DOI 10.1016/j.jvcir.2011.03.009
   Hu WC, 2011, INT J INNOV COMPUT I, V7, P1845
   Huang KQ, 2008, PATTERN RECOGN, V41, P432, DOI 10.1016/j.patcog.2007.05.017
   Jodoin PM, 2007, IEEE T IMAGE PROCESS, V16, P2535, DOI 10.1109/TIP.2007.903841
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Lian FL, 2013, IEEE T IND INFORM, V9, P172, DOI 10.1109/TII.2012.2209664
   Qi B, 2008, IEEE T IMAGE PROCESS, V17, P958, DOI 10.1109/TIP.2008.921985
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Somasundaram G, 2013, IEEE T INTELL TRANSP, V14, P69, DOI 10.1109/TITS.2012.2209877
   Sugandi B, 2009, INT J INNOV COMPUT I, V5, P1179
   Tian YL, 2011, IEEE T SYST MAN CY C, V41, P565, DOI 10.1109/TSMCC.2010.2065803
   Wang Y, 2010, IEEE T IMAGE PROCESS, V19, P2491, DOI 10.1109/TIP.2010.2048970
   Zhang GY, 2006, INT C COMMUN CIRCUIT, P437, DOI 10.1109/ICCCAS.2006.284671
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 24
TC 63
Z9 74
U1 1
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 164
EP 180
DI 10.1016/j.jvcir.2015.03.003
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900015
DA 2024-07-18
ER

PT J
AU Pazhoumand-Dar, H
   Lam, CP
   Masek, M
AF Pazhoumand-Dar, Hossein
   Lam, Chiou-Peng
   Masek, Martin
TI Joint movement similarities for robust 3D action recognition using
   skeletal data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Similarity function; Longest common
   subsequence algorithm; Kinect camera; Motion capture system;
   Discriminative features; Motion pattern; Trajectory modeling
ID MODEL
AB Human action analysis based on 3D imaging is an emerging topic. This paper presents an approach for the problem of action recognition using information from a number of action descriptors calculated from a skeleton fitted to the body of a tracked subject. In the proposed approach, a novel technique that automatically determines discriminative sequences of relative joint positions for each action class is employed. In addition, we use an extended formulation of the longest common subsequence algorithm as a similarity function, which allows the classifier to reliably find the best match for extracted features from noisy skeletal data. The proposed approach is evaluated using two existing datasets from the literature, one captured using a Microsoft Kinect camera and the other using a motion capture system. The experimental results show that the approach outperforms existing skeleton-based algorithms in terms of its classification accuracy and is more robust in the presence of noise when compared to the dynamic time warping algorithm for human action recognition. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Pazhoumand-Dar, Hossein; Lam, Chiou-Peng; Masek, Martin] Edith Cowan Univ, Sch Comp & Secur Sci, Perth, WA 6050, Australia.
C3 Edith Cowan University
RP Pazhoumand-Dar, H (corresponding author), Edith Cowan Univ, Sch Comp & Secur Sci, Perth, WA 6050, Australia.
EM hosseinp@ecu.edu.au
RI Cataldi, Antonio/AAM-7411-2021; Masek, Martin/O-1559-2017
OI Masek, Martin/0000-0001-8620-6779
CR Aggarwal J., 2014, PATTERN RECOGN LETT
   Al Shalabi L., 2006, Journal of Computer Sciences, V2, P735, DOI 10.3844/jcssp.2006.735.739
   Almotairi S., 2014, INT C COMP SCI COMP
   [Anonymous], P 2011 ACM SIGGRAPH
   [Anonymous], 2012, J Comput Vis Image Process
   [Anonymous], 3 CAN C COMP ROB VIS
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision, DOI DOI 10.1007/978-1-4471-4640-710
   Antonakaki P, 2009, SIGNAL PROCESS, V89, P1723, DOI 10.1016/j.sigpro.2009.03.016
   Arid T., 2013, MULTIMED TOOLS APPL, P1
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Chen Y., 2007, INT C INF ACQ 2007 I
   Chung PC, 2008, PATTERN RECOGN, V41, P1572, DOI 10.1016/j.patcog.2007.10.022
   Corradini A., 2001, P IEEE ICCV WORKSH R
   Corso JJ, 2008, COMPUTER, V41, P48, DOI 10.1109/MC.2008.141
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Hadfield S, 2013, PROC CVPR IEEE, P3398, DOI 10.1109/CVPR.2013.436
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   Jin S.-Y., 2013, COMP VIS ACCV 2012 W
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Lai K., 2012, IEEE SW S IM AN INT
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Masood S.Z., 2011, IEEE INT C COMP VIS
   Monir S., 2012, 12 INT C INT SYST DE
   Muller M., 2007, Tech. Rep. CG-2007-2
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Oshin O., 2011, IEEE INT C AUT FAC G
   Pierobon M., 2005, IEEE C ADV VID SIGN
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   Seki H, 2009, IEEE ENG MED BIO, P6187, DOI 10.1109/IEMBS.2009.5334614
   Sempena S., 2011, INT C EL ENG INF ICE
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sung J., 2012, IEEE INT C ROB AUT I
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Vlachos M., 2002, P 18 INT C DAT ENG 2
   Vrigkas M., 2013, VISAPP
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J., 2012, IEEE INT C COMP SCI
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
NR 50
TC 41
Z9 47
U1 0
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2015
VL 30
BP 10
EP 21
DI 10.1016/j.jvcir.2015.03.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CM5XI
UT WOS:000357761900002
DA 2024-07-18
ER

PT J
AU Tang, CW
   Yang, XK
   Zhai, GT
AF Tang, Chongwu
   Yang, Xiaokang
   Zhai, Guangtao
TI Wavelet-based hybrid natural image modeling using generalized Gaussian
   and α-stable distributions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Natural image statistics; Image modeling; Wavelet coefficients;
   Generalized Gaussian distribution; alpha-stable distribution; Hybrid
   model; Kullback-Leibler divergence; Image comparison
ID STATISTICS; PARAMETERS
AB Natural image is characterized by its highly kurtotic and heavy-tailed distribution in wavelet domain. These typical non-Gaussian statistics are commonly described by generalized Gaussian density (GGD) or alpha-stable distribution. However, each of the two models has its own deficiency to capture the variety and complexity of real world scenes. Considering the statistical properties of GGD and alpha-stable distributions respectively, in this paper we propose a hybrid statistical model of natural image's wavelet coefficients which is better in describing the leptokurtosis and heavy tails simultaneously. Based on a clever fusion of GGD and alpha-stable functions, we establish the optimal parametric hybrid model, and a close-formed Kullback-Leibler divergence of the hybrid model is derived for evaluating model accuracy. Experiment results and comparative studies demonstrate that the proposed hybrid model is closer to the true distribution of natural image's wavelet coefficients than the single modeling using GGD or alpha-stable, while is beneficial for applications such as image comparison. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Tang, Chongwu; Yang, Xiaokang; Zhai, Guangtao] Shanghai Jiao Tong Univ, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Tang, CW (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Labs Digital Media Proc & Commun, Shanghai 200240, Peoples R China.
EM tangcw@sjtu.edu.cn; xkyang@sjtu.edu.cn; zhaiguangtao@sjtu.edu.cn
RI Yang, Xiaokang/C-6137-2009; Zhai, Guangtao/X-5949-2019
OI Yang, Xiaokang/0000-0003-4029-3322; Zhai, Guangtao/0000-0001-8165-9322
FU National Nature Science Foundation of China (NSFC) [61025005, 60932006,
   61001145, 61102098, 61221001]; Science and Technology Commission of
   Shanghai Municipality (STCSM) [12DZ2272600]; 111 Project [B07022]
FX This work was supported by National Nature Science Foundation of China
   (NSFC) (61025005, 60932006, 61001145, 61102098, 61221001), Science and
   Technology Commission of Shanghai Municipality (STCSM) (12DZ2272600),
   111 Project (B07022).
CR Achim A, 2005, IEEE SIGNAL PROC LET, V12, P17, DOI 10.1109/LSP.2004.839692
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   DOMINGUEZMOLINA JA, PRACTICAL PROCEDURE
   KOUTROUVELIS IA, 1980, J AM STAT ASSOC, V75, P918, DOI 10.2307/2287182
   KOUTROUVELIS IA, 1981, COMMUN STAT B-SIMUL, V10, P17, DOI 10.1080/03610918108812189
   KULLBACK S, 1987, AM STAT, V41, P340
   Kuruoglu EE, 2003, PATTERN RECOGN LETT, V24, P339, DOI 10.1016/S0167-8655(02)00247-7
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Luo J., J VISUAL COMMUN IMAG, V14
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MULLER F, 1993, ELECTRON LETT, V29, P1935, DOI 10.1049/el:19931288
   Nolan J., 2013, Stable Distributions|Models for Heavy Tailed Data
   Nolan J. P., 2009, STABLE DISTRIBUTIONS, V22, P79
   Roth S, 2005, PROC CVPR IEEE, P860
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   Ruderman DL, 1997, VISION RES, V37, P3385, DOI 10.1016/S0042-6989(97)00008-4
   Sheikh H.R., 2006, IEEE Trans. Image Processing, V15
   Simoncelli EP, 1999, P SOC PHOTO-OPT INS, V3813, P188, DOI 10.1117/12.366779
   Smith G, 1997, PATTERN RECOGN LETT, V18, P1495, DOI 10.1016/S0167-8655(97)00132-3
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Wan T., 2007, P IEEE INT C IM PROC, V4, P357
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yousefi S, 2012, J VIS COMMUN IMAGE R, V23, P1051, DOI 10.1016/j.jvcir.2012.06.001
   Zhai GT, 2009, IEEE IMAGE PROC, P3845, DOI 10.1109/ICIP.2009.5414252
   Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983
   Zoran D., 2012, ADV NEURAL INFORM PR, P1
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 29
TC 1
Z9 1
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 61
EP 70
DI 10.1016/j.jvcir.2015.02.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100006
DA 2024-07-18
ER

PT J
AU Shu, X
   Pan, L
   Wu, XJ
AF Shu, Xin
   Pan, Lei
   Wu, Xiao-Jun
TI Multi-scale contour flexibility shape signature for Fourier descriptor
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Shape signature; Shape description; Fourier descriptor; Multi-scale
   contour flexibility; Descriptor matching; Shape retrieval; Shape
   matching; Content based image retrieval
ID REPRESENTATION; RETRIEVAL; RECOGNITION; ZERNIKE
AB Shape signature and Fourier descriptor are common techniques for shape description and they are widely used in pattern recognition and computer vision applications. In this paper, a novel shape signature is proposed, namely, multi-scale contour flexibility shape signature. After the discrete Fourier transform is performed on the multi-scale contour flexibility shape signature, the Fourier descriptor will be obtained. As a contour line function, contour flexibility based Fourier descriptor not only describes the whole deformation characteristics of the two dimensional shape profiles, but also reflects the local deformation characteristics of the contour sampling points. Thus, the proposed method incorporates the global and local features of the shape. Multi-scale technique could solve the problem of elastic parameter selection skillfully and describe the shape features from coarse to fine. In addition, contour flexibility is also easy to be calculated. Experiments conducted in the MPEG-7 shape database show that the best retrieval results are achieved by the multi-scale contour flexibility based Fourier descriptor compared with other representative shape signatures based Fourier descriptor. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Shu, Xin; Pan, Lei] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Peoples R China.
   [Shu, Xin; Wu, Xiao-Jun] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Peoples R China.
C3 Jiangsu University of Science & Technology; Jiangnan University
RP Shu, X (corresponding author), Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Peoples R China.
EM shuxin@just.edu.cn
FU National Natural Science Foundation of PR China [61103128, 61471182];
   111 Project of Chinese Ministry of Education [B12018]; Key Grant Project
   of Chinese Ministry of Education [311024]; Natural Science Foundation of
   Jiangsu Province of PR China [BK20130473]; Innovation funds of
   industry-academy-research cooperation of Jiangsu Province of PR China
   [BY2013066-03]
FX This work was supported in part by National Natural Science Foundation
   of PR China (Grant Nos. 61103128, 61471182), 111 Project of Chinese
   Ministry of Education (Grant No. B12018), Key Grant Project of Chinese
   Ministry of Education (Grant No. 311024), Natural Science Foundation of
   Jiangsu Province of PR China (Grant No. BK20130473) and Innovation funds
   of industry-academy-research cooperation of Jiangsu Province of PR China
   (Grant No. BY2013066-03). The authors wish also to thank the reviewers
   for their helpful and constructive comments.
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Amanatiadis A, 2011, IET IMAGE PROCESS, V5, P493, DOI 10.1049/iet-ipr.2009.0246
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   Attalla E, 2005, PATTERN RECOGN, V38, P2229, DOI 10.1016/j.patcog.2005.02.009
   Bartolini I, 2005, IEEE T PATTERN ANAL, V27, P142, DOI 10.1109/TPAMI.2005.21
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Costa L. da F., 2001, SHAPE ANAL CLASSIFIC
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Direkoglu C, 2011, PATTERN RECOGN, V44, P2134, DOI 10.1016/j.patcog.2011.02.016
   El Oirrak A, 2002, PATTERN RECOGN LETT, V23, P1109, DOI 10.1016/S0167-8655(02)00027-2
   El-Ghazal A, 2009, SIGNAL PROCESS-IMAGE, V24, P572, DOI 10.1016/j.image.2009.04.001
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   Frejlichowski D, 2008, LECT NOTES COMPUT SC, V5112, P537, DOI 10.1007/978-3-540-69812-8_53
   Frejlichowski D, 2010, LECT NOTES COMPUT SC, V6374, P376, DOI 10.1007/978-3-642-15910-7_43
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ismail MA, 2000, PATTERN RECOGN, V33, P1727, DOI 10.1016/S0031-3203(99)00047-3
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Kokkinos I, 2012, PROC CVPR IEEE, P159, DOI 10.1109/CVPR.2012.6247671
   Latecki L., 2000, P CVPR
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Luengo-Oroz MA, 2005, LECT NOTES COMPUT SC, V3523, P199
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   Nguyen T.P., 2010, P ICPR
   PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799
   Rauber T.W., 1992, P MVA 92 IAPR WORKSH
   Remy E, 2005, IMAGE VISION COMPUT, V23, P167, DOI 10.1016/j.imavis.2004.06.007
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   van Kaick O, 2011, COMPUT GRAPH FORUM, V30, P1681, DOI 10.1111/j.1467-8659.2011.01884.x
   Wang B, 2011, OPT COMMUN, V284, P3504, DOI 10.1016/j.optcom.2011.03.063
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Xu CJ, 2009, IEEE T PATTERN ANAL, V31, P180, DOI 10.1109/TPAMI.2008.199
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 38
TC 16
Z9 22
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 161
EP 167
DI 10.1016/j.jvcir.2014.11.007
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000014
DA 2024-07-18
ER

PT J
AU Dong, FF
   Peng, JL
AF Dong, Fangfang
   Peng, Jialin
TI Brain MR image segmentation based on local Gaussian mixture model and
   nonlocal spatial regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE MR image; Inhomogeneous intensity; Bias field; Image segmentation;
   Variational approach; Local Gaussian mixture model; Nonlocal spatial
   regularization; Structure preservation
ID BIAS FIELD ESTIMATION; INTENSITY INHOMOGENEITY; FUZZY SEGMENTATION;
   ALGORITHM; FRAMEWORK; NONUNIFORMITY
AB Brain Magnetic Resonance (MR) images often suffer from the inhomogeneous intensities caused by the bias field and heavy noise. The most widely used image segmentation algorithms, which typically rely on the homogeneity of image intensities in different regions, often fail to provide accurate segmentation results due to the existence of bias field and heavy noise. This paper proposes a novel variational approach for brain image segmentation with simultaneous bias correction. We define an energy functional with a local data fitting term and a nonlocal spatial regularization term. The local data fitting term is based on the idea of local Gaussian mixture model (LGMM), which locally models the distribution of each tissue by a linear combination of Gaussian function. By the LGMM, the bias field function in an additive form is embedded to the energy functional, which is helpful for eliminating the influence of the intensity inhomogeneity. For reducing the influence of noise and getting a smooth segmentation, the nonlocal spatial regularization is drawn upon, which is good at preserving fine structures in brain images. Experiments performed on simulated as well as real MR brain data and comparisons with other related methods are given to demonstrate the effectiveness of the proposed method. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Dong, Fangfang] Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Zhejiang, Peoples R China.
   [Peng, Jialin] Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
C3 Zhejiang Gongshang University; Huaqiao University
RP Dong, FF (corresponding author), Zhejiang Gongshang Univ, Sch Math & Stat, Hangzhou 310018, Zhejiang, Peoples R China.
EM fangdong06@gmail.com
RI Dong, Fangfang/JGE-5095-2023
OI Dong, Fangfang/0000-0003-2914-3227; Peng, Jialin/0000-0002-1797-0762
FU National Natural Science Foundation of China [11101365, 11001239];
   Zhejiang Provincial Natural Science Foundation of China [LQ12A01016]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 11101365 and 11001239), Zhejiang Provincial Natural
   Science Foundation of China (Grant No. LQ12A01016).
CR Acton PD, 2006, PHYS MED BIOL, V51, P3057, DOI 10.1088/0031-9155/51/12/004
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   [Anonymous], 1997, NEUROIMAGE
   AXEL L, 1987, AM J ROENTGENOL, V148, P418, DOI 10.2214/ajr.148.2.418
   Balafar M.A., 2012, ARTIF INTELL REV
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Bresson X., 2008, 0867 UCLA
   BREY WW, 1988, MED PHYS, V15, P241, DOI 10.1118/1.596255
   Cai W., PATTERN RECOGNIT, V40
   Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006
   Caldairou B, 2009, LECT NOTES COMPUT SC, V5702, P606, DOI 10.1007/978-3-642-03767-2_74
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen Fuhua, 2010, ADV MODELING OPTIMIZ, P339
   Chen Y., COMPUT MED IMAGING G, V33
   Chen YJ, 2011, NEUROCOMPUTING, V74, P3520, DOI 10.1016/j.neucom.2011.06.006
   Fan A, 2003, LECT NOTES COMPUT SC, V2732, P148
   Garcia-Sebastián M, 2007, PATTERN RECOGN LETT, V28, P1657, DOI 10.1016/j.patrec.2007.04.016
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Greenspan H, 2006, IEEE T MED IMAGING, V25, P1233, DOI 10.1109/TMI.2006.880668
   Guillemaud R, 1997, IEEE T MED IMAGING, V16, P238, DOI 10.1109/42.585758
   Gupta L, 1998, PATTERN RECOGN, V31, P315, DOI 10.1016/S0031-3203(97)00045-9
   Ji ZX, 2012, IEEE T INF TECHNOL B, V16, P339, DOI 10.1109/TITB.2012.2185852
   Jung MY, 2009, LECT NOTES COMPUT SC, V5567, P401, DOI 10.1007/978-3-642-02256-2_34
   KENNEDY DN, 1989, IEEE T MED IMAGING, V8, P1, DOI 10.1109/42.20356
   Li CM, 2009, IEEE I CONF COMP VIS, P702, DOI 10.1109/ICCV.2009.5459239
   Li CM, 2009, PROC CVPR IEEE, P218, DOI 10.1109/CVPRW.2009.5206553
   Li CM, 2009, LECT NOTES COMPUT SC, V5636, P288
   Li CM, 2008, LECT NOTES COMPUT SC, V5242, P1083
   Liew AWC, 2003, IEEE T MED IMAGING, V22, P1063, DOI 10.1109/TMI.2003.816956
   Liu J, 2013, J MATH IMAGING VIS, V46, P161, DOI 10.1007/s10851-012-0376-5
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Pham DL, 2001, COMPUT VIS IMAGE UND, V84, P285, DOI 10.1006/cviu.2001.0951
   Pham DL, 1999, IEEE T MED IMAGING, V18, P737, DOI 10.1109/42.802752
   Prima S., 2001, P MED IM COMP COMP A, V2208, P811, DOI DOI 10.1007/3-540-45468-3_97
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SIMMONS A, 1994, MAGNET RESON MED, V32, P121, DOI 10.1002/mrm.1910320117
   Styner M, 2000, IEEE T MED IMAGING, V19, P153, DOI 10.1109/42.845174
   Thompson PM, 2001, CEREB CORTEX, V11, P1, DOI 10.1093/cercor/11.1.1
   TINCHER M, 1993, IEEE T MED IMAGING, V12, P361, DOI 10.1109/42.232267
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P885, DOI 10.1109/42.811268
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   WICKS DAG, 1993, MAGN RESON IMAGING, V11, P183, DOI 10.1016/0730-725X(93)90023-7
   Zhang KH, 2010, IEEE IMAGE PROC, P4105, DOI 10.1109/ICIP.2010.5651554
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 46
TC 22
Z9 26
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 827
EP 839
DI 10.1016/j.jvcir.2014.01.014
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200012
DA 2024-07-18
ER

PT J
AU Hanhart, P
   Ebrahimi, T
AF Hanhart, Philippe
   Ebrahimi, Touradj
TI Calculation of average coding efficiency based on subjective quality
   scores
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Coding efficiency; Rate-distortion curves; Subjective quality
   assessment; Mean opinion scores; Objective quality assessment; PSNR;
   Bjontegaard delta; BD-Rate; BD-PSNR
AB The Bjontegaard model is widely used to calculate the coding efficiency between different codecs. However, this model might not be an accurate predictor of the true coding efficiency as it relies on PSNR measurements. Therefore, in this paper, we propose a model to calculate the average coding efficiency based on subjective quality scores, i.e., mean opinion scores (MOS). We call this approach Subjective Comparison of ENcoders based on fitted Curves (SCENIC). To consider the intrinsic nature of bounded rating scales, a logistic function is used to fit the rate-distortion (R-D) values. The average MOS and bit rate differences are computed between the fitted R-D curves. The statistical property of subjective scores is considered to estimate corresponding confidence intervals on the calculated average MOS and bit rate differences. The proposed model is expected to report more realistic coding efficiency as PSNR is not always correlated with perceived visual quality. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Hanhart, Philippe; Ebrahimi, Touradj] Ecole Polytech Fed Lausanne, Multimedia Signal Proc Grp, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Hanhart, P (corresponding author), EPFL STI IELGR EB, Stn 11, CH-1015 Lausanne, Switzerland.
EM philippe.hanhart@epfl.ch; touradj.ebrahimi@epfl.ch
OI Ebrahimi, Touradj/0000-0002-9900-3687
CR Alpert T, 1997, SIGNAL PROCESS-IMAGE, V9, P305, DOI 10.1016/S0923-5965(97)00004-0
   [Anonymous], 2011, JTC1SC29WG11 ISOIEC
   [Anonymous], BT50013 ITUR
   [Anonymous], J149 ITUT
   [Anonymous], 2008, VCEG-AI11
   Baroncini V., 2012, MPEG REPRESENTATION, P249
   Bjontegaard G., 2001, Document VCEG-M33
   Fenimore C, 2004, P SOC PHOTO-OPT INS, V5558, P503, DOI 10.1117/12.563519
   Goldmann L., 2009, P SPIE, V7443
   Hanhart P., 2013, P 7 INT WORKSH VID P, P1
   Hanhart P., 2012, P SPIE, V8499
   Hanhart P., 2012, 4 INT WORKSH QUAL MU
   Hanhart P., 2013, 7 INT WORKSH VID PRO
   Korhonen J, 2012, INT WORK QUAL MULTIM, P57, DOI 10.1109/QoMEX.2012.6263839
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   OELBAUM T, 2004, INT BROADC C IBC
   Oelbaum T, 2008, IEEE IMAGE PROC, P2772, DOI 10.1109/ICIP.2008.4712369
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Simone F., 2011, J VIS COMMUN IMAGE R, V22, P734
   Vetro A., 2012, P SPIE, V8499
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 22
TC 53
Z9 64
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 555
EP 564
DI 10.1016/j.jvcir.2013.11.008
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, P
   Tang, ZM
   Chen, CK
   Yang, ZJ
AF Huang, Pu
   Tang, Zhenmin
   Chen, Caikou
   Yang, Zhangjing
TI Local maximal margin discriminant embedding for face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local maximal margin discriminant embedding; Locality preserving
   projection; Maximum margin criterion; Small sample size problem; Local
   structure; Appearance-based; Dimensionality reduction; Manifold
   learning; Face recognition
ID SINGLE TRAINING IMAGE; DIMENSIONALITY REDUCTION; ONE SAMPLE;
   PROJECTIONS; EIGENFACES; FLDA
AB In this paper, a manifold learning based method named local maximal margin discriminant embedding (LMMDE) is developed for feature extraction. The proposed algorithm LMMDE and other manifold learning based approaches have a point in common that the locality is preserved. Moreover. LMMDE takes consideration of intra-class compactness and inter-class separability of samples lying in each manifold. More concretely, for each data point, it pulls its neighboring data points with the same class label towards it as near as possible, while simultaneously pushing its neighboring data points with different class labels away from it as far as possible under the constraint of locality preserving. Compared to most of the up-to-date manifold learning based methods, this trick makes contribution to pattern classification from two aspects. On the one hand, the local structure in each manifold is still kept in the embedding space; one the other hand, the discriminant information in each manifold can be explored. Experimental results on the ORL, Yale and FERET face databases show the effectiveness of the proposed method. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Huang, Pu; Tang, Zhenmin; Yang, Zhangjing] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Chen, Caikou] Yangzhou Univ, Coll Informat Engn, Yangzhou 225009, Peoples R China.
C3 Nanjing University of Science & Technology; Yangzhou University
RP Huang, P (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM huangpu3355@163.com
RI Tang, Zhenmin/AAY-6058-2020
OI Tang, Zhenmin/0000-0001-6708-2205
FU National Science Foundation of China [90820306, 61125305, 60875004];
   Grant of college postgraduate research and innovative project in Jiangsu
   province [CXZZ12_0204]
FX This work was supported by the Grants of the National Science Foundation
   of China, Nos. 90820306, 61125305 and 60875004; the Grant of college
   postgraduate research and innovative project in Jiangsu province, No.
   CXZZ12_0204.
CR [Anonymous], 2007, IJCAI
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Cai D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P3, DOI 10.1145/1076034.1076039
   Chen H.T., 2005, P CVPR
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Cheng J, 2005, NEUROCOMPUTING, V67, P443, DOI 10.1016/j.neucom.2004.08.006
   Deng WH, 2008, IEEE T PATTERN ANAL, V30, P1503, DOI 10.1109/TPAMI.2007.70783
   Fan MY, 2012, IEEE DATA MINING, P852, DOI 10.1109/ICDM.2012.99
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   Gopalan R, 2010, COMPUT VIS IMAGE UND, V114, P135, DOI 10.1016/j.cviu.2009.07.005
   Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017
   He X., 2004, MULTIMEDIA '04, P2
   He X.F., 2005, P 22 INT C MACH LEAR, P281, DOI DOI 10.1145/1102351.1102387
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   He XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P385, DOI 10.1109/ICCV.2003.1238370
   James AP, 2010, FACE RECOGNITION, P65
   Jiatao Song, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P1046, DOI 10.1109/ICCIS.2008.4670975
   Jorstad A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2353, DOI 10.1109/CVPR.2011.5995431
   Jorstad A, 2012, LECT NOTES COMPUT SC, V7575, P71, DOI 10.1007/978-3-642-33765-9_6
   Kanan HR, 2008, PATTERN RECOGN, V41, P3799, DOI 10.1016/j.patcog.2008.05.024
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Kuo CH, 2012, IET COMPUT VIS, V6, P489, DOI 10.1049/iet-cvi.2011.0248
   Li B, 2008, PATTERN RECOGN, V41, P3287, DOI 10.1016/j.patcog.2008.05.014
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li JB, 2008, INFORM SCIENCES, V178, P1825, DOI 10.1016/j.ins.2007.12.001
   Lu JW, 2011, IEEE I CONF COMP VIS, P1943, DOI 10.1109/ICCV.2011.6126464
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vapnik V., 1999, NATURE STAT LEARNING
   Vlassis N, 2002, NEURAL COMPUT, V14, P191, DOI 10.1162/089976602753284491
   Wang FAZ, 2010, J NETW COMPUT APPL, V33, P323, DOI 10.1016/j.jnca.2009.12.013
   Xu Y, 2010, PATTERN RECOGN, V43, P4165, DOI 10.1016/j.patcog.2010.06.016
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Yu WW, 2006, IMAGE VISION COMPUT, V24, P239, DOI 10.1016/j.imavis.2005.11.006
   Zhan-Li Sun, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P218, DOI 10.1109/ICSPCC.2012.6335726
   Zhang D., APPL MATH COMPUT, P163
   Zhang HG, 2010, MACH VISION APPL, V21, P577, DOI 10.1007/s00138-009-0213-z
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhao SQ, 2008, IEEE IMAGE PROC, P1664, DOI 10.1109/ICIP.2008.4712092
NR 47
TC 12
Z9 19
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 296
EP 305
DI 10.1016/j.jvcir.2013.11.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300006
DA 2024-07-18
ER

PT J
AU Potthast, C
   Sukhatme, GS
AF Potthast, Christian
   Sukhatme, Gaurav S.
TI A probabilistic framework for next best view estimation in a cluttered
   environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Next best view estimation; Sensor placement; Sensor planning; View
   planning; Robot exploration; 3-D perception; Cluttered environments;
   Missing points
AB In this article, we present an information gain-based variant of the next best view problem for occluded environment. Our proposed method utilizes a belief model of the unobserved space to estimate the expected information gain of each possible viewpoint. More precise, this belief model allows a more precise estimation of the visibility of occluded space and with that a more accurate prediction of the potential information gain of new viewing positions. We present experimental evaluation on a robotic platform for active data acquisition, however due to the generality of our approach it also applies to a wide variety of 3D reconstruction problems. With the evaluation done in simulation and on a real robotic platform, exploring and acquiring data from different environments we demonstrate the generality and usefulness of our approach for next best view estimation and autonomous data acquisition. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Potthast, Christian; Sukhatme, Gaurav S.] Univ So Calif, Robot Embedded Syst Lab, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Potthast, C (corresponding author), Univ So Calif, Robot Embedded Syst Lab, Los Angeles, CA 90089 USA.
EM potthast@usc.edu; gaurav@usc.edu
FU Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [1017134] Funding Source: National Science Foundation
CR Amanatides J., 1987, EUROGRAPHICS, P3, DOI DOI 10.2312/EGTP.19871000
   Amigoni F, 2005, IEEE INT CONF ROBOT, P3850
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blaer PS, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P423
   Connolly C., 1985, PROC IEEE INT C ROBO, V2, P432
   Dunn E., 2009, BRIT MACH VIS C BMVC
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720
   González-Baños HH, 2002, INT J ROBOT RES, V21, P829, DOI 10.1177/0278364902021010834
   Haner S., 2012, SSBA
   Haner S., 2011, SCAND C IM AN
   Holz D., 2010, ISR, P36
   Hornung A., 2008, CVPR
   Kittler J., 1984, Image and Vision Computing, V2, P13, DOI 10.1016/0262-8856(84)90040-4
   Krainin M., 2011, P IEEE INT C ROB AUT, P5031
   Makarenko AA, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P534, DOI 10.1109/IRDS.2002.1041445
   Massios N.A., 1998, P BMVC
   Nüchter A, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P222
   Pito R, 1999, IEEE T PATTERN ANAL, V21, P1016, DOI 10.1109/34.799908
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Rusu R.B., 2009, ICCV S3DV WORKSH
   Scott WR, 2003, ACM COMPUT SURV, V35, P64, DOI 10.1145/641865.641868
   Stachniss C., 2003, Proc IJCAI, P1127
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   TARABANIS KA, 1995, IEEE T ROBOTIC AUTOM, V11, P86, DOI 10.1109/70.345940
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Thrun S., 2002, EXPLORING ARTIFICIAL, P1, DOI DOI 10.5555/779343.779345
   Trummer Michael, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1642, DOI 10.1109/ICPR.2010.406
   Wenhardt S, 2006, INT C PATT RECOG, P103
   Wettach J., 2010, Robotics (isr), 2010 41st international symposium on and 2010 6th german conference on robotics (robotik) (, P1
   Yamauchi B, 1997, 1997 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION - CIRA '97, PROCEEDINGS, P146, DOI 10.1109/CIRA.1997.613851
NR 31
TC 101
Z9 119
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 148
EP 164
DI 10.1016/j.jvcir.2013.07.006
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900014
DA 2024-07-18
ER

PT J
AU Wei, X
   Phung, SL
   Bouzerdoum, A
AF Wei, Xue
   Phung, Son Lam
   Bouzerdoum, Abdesselam
TI Object segmentation and classification using 3-D range camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3-D range image segmentation; Range/intensity image processing; Feature
   extraction; Object classification; Assistive navigation; Pedestrian
   classification; Image segmentation evaluation; RGB-D image processing
ID IMAGE SEGMENTATION; PEOPLE; SHAPE
AB This paper proposes a vision system using a 3-D range camera for scene segmentation and pedestrian classification. The system detects and segments objects in the foreground, measures their distances to the camera, and classifies them into pedestrians and non-pedestrian obstacles. Combining range and intensity images enables fast and accurate object segmentation, and provides useful navigation cues such as the range and type of nearby objects and the ground surface. In the proposed approach, a 3-D range image is segmented using histogram processing and mean-shift clustering. The ground surface is detected by estimating its normal vector in 3-D space. Fourier and GIST descriptors are then applied on each detected region to extract shape and texture features. Finally, support vector machines are used to classify objects; in this paper we focus on differentiating pedestrian and non-pedestrian regions. The performance of the proposed system is evaluated with two datasets. One dataset for object segmentation and pedestrian classification is acquired by us using a 3-D range camera; the other is a public RGB-D dataset for people detection. Experimental results show that the proposed system performs favorably compared to some existing segmentation and feature extraction approaches. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wei, Xue; Phung, Son Lam; Bouzerdoum, Abdesselam] Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2522, Australia.
C3 University of Wollongong
RP Wei, X (corresponding author), Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2522, Australia.
EM xw158@uowmail.edu.au; phung@uow.edu.au; bouzer@uow.edu.au
RI Phung, Son Lam/A-9469-2013; Bouzerdoum, Abdesselam/A-4479-2012
OI Phung, Son Lam/0000-0002-3076-0540; Bouzerdoum,
   Abdesselam/0000-0002-9163-0045
CR [Anonymous], 2011, P CVPR WORKSHOPS JUN
   Bagon S., MATLAB WRAPPER GRAPH
   Bart E., IEEE C COMP VIS PATT, P1
   Bertozzi M, 2002, P IEEE, V90, P1258, DOI 10.1109/JPROC.2002.801444
   BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Coleman SA, 2010, IEEE T IMAGE PROCESS, V19, P2814, DOI 10.1109/TIP.2010.2050733
   Collins RT, 2001, P IEEE, V89, P1456, DOI 10.1109/5.959341
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das Dipankar, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P3485
   Demirkaya O, 2005, BIOINFORMATICS, V21, P2994, DOI 10.1093/bioinformatics/bti455
   Demirkaya O., 2008, Image Processing with MATLAB: Applications in Medicine and Biology
   Devarakota PR, 2007, IEEE T VEH TECHNOL, V56, P1983, DOI 10.1109/TVT.2007.897645
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Eunyoung Kim, 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P65, DOI 10.1109/3DIMPVT.2011.63
   Fardi B, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P225, DOI 10.1109/IVS.2006.1689632
   Farmer ME, 2005, IEEE T IMAGE PROCESS, V14, P2060, DOI 10.1109/TIP.2005.859374
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Gould Stephen., 2009, ADV NEURAL INFORM PR, P655
   Harati A., 2007, IFAC S INT AUT VEH
   Hegde GM, 2011, IEEE SYS MAN CYBERN, P3119, DOI 10.1109/ICSMC.2011.6084139
   Hegde GM, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4034, DOI 10.1109/IROS.2009.5353952
   HOFFMAN R, 1987, IEEE T PATTERN ANAL, V9, P608, DOI 10.1109/TPAMI.1987.4767955
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hoover A, 1996, IEEE T PATTERN ANAL, V18, P673, DOI 10.1109/34.506791
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mozos OM, 2010, INT J SOC ROBOT, V2, P31, DOI 10.1007/s12369-009-0041-3
   MEIJER PBL, 1992, IEEE T BIO-MED ENG, V39, P112, DOI 10.1109/10.121642
   MUKHERJEE J, 1992, PATTERN RECOGN, V25, P1141, DOI 10.1016/0031-3203(92)90017-D
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799
   Phung SL, 2007, INT CONF ACOUST SPEE, P1229
   Rapus M, 2008, IEEE INT VEH SYM, P421
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Su D., 2009, MATLAB CODE EFFICIEN
   Tivive FHC, 2010, APPL OPTICS, V49, pB1, DOI 10.1364/AO.49.0000B1
   Torralba A., 2005, ADV NEURAL INFORM PR, P1401
   Varadarajan K. M., 2011, 2011 15th International Conference on Advanced Robotics, P21, DOI 10.1109/ICAR.2011.6088647
   Wang X, 2004, PATTERN RECOGN LETT, V25, P367, DOI 10.1016/j.patrec.2003.10.017
   Zhang CX, 2010, LECT NOTES COMPUT SC, V6314, P708, DOI 10.1007/978-3-642-15561-1_51
NR 46
TC 16
Z9 18
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2014
VL 25
IS 1
SI SI
BP 74
EP 85
DI 10.1016/j.jvcir.2013.04.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 297MP
UT WOS:000330259900008
DA 2024-07-18
ER

PT J
AU Chiu, YH
   Chung, KL
   Yang, WN
   Lin, CH
   Huang, YH
AF Chiu, Yung-Hsiang
   Chung, Kuo-Liang
   Yang, Wei-Ning
   Lin, Chien-Hsiung
   Huang, Yong-Huai
TI Universal intra coding for arbitrary RGB color filter arrays in HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Arbitrary color filter arrays; BD-BR; BD-PSNR; Bitrate; Demosaicing;
   H.264/AVC; HEVC; Mosaic video sequences; PSNR; Universal intra coding
ID PATTERN VIDEO SEQUENCES; DEMOSAICKING; INTERPOLATION; COMPRESSION;
   DESIGN
AB Compressing mosaic video sequences is necessary for storage and transmission over the internet. However, mosaic video sequences with different red-green-blue (RGB) color filter arrays (CFAs) require different compression schemes. We propose a two-stage universal intra coding scheme for compressing mosaic video sequences with arbitrary RGB-CFAs in high efficiency video coding (HEVC). Based on the associated mosaic structure, the proposed scheme first demosaics the neighboring reference pixels and then predicts the color value of the target pixel using the color values of the identical color components in the demosaiced reference pixels. Experimental results demonstrate that the proposed universal intra coding scheme achieves substantial improvement on bitrate while preserving the quality of the reconstructed video sequences. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chiu, Yung-Hsiang; Chung, Kuo-Liang; Lin, Chien-Hsiung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Yang, Wei-Ning] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei 10672, Taiwan.
   [Huang, Yong-Huai] Jinwen Univ Sci & Technol, Inst Comp & Commun Engn, Dept Elect Engn, New Taipei City 23154, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Lin, CH (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Section 4,Keelung Rd, Taipei 10672, Taiwan.
EM d9409301@mail.ntust.edu.tw
FU National Science Council of ROC [NSC101-2221-E-011-139-MY3,
   NSC99-2221-E-011-078-MY3, NSC101-2218-E-011-001, NSC101-2218-E-011-005,
   NSC101-2221-E-228-010]
FX The work of K.-L. Chung and C.-H. Lin was supported by the National
   Science Council of ROC under contract NSC101-2221-E-011-139-MY3 and
   NSC99-2221-E-011-078-MY3. The work of W.-N. Yang was supported by the
   National Science Council of ROC under contracts NSC101-2218-E-011-001
   and NSC101-2218-E-011-005. The work of Y.-H. Huang was supported by the
   National Science Council of ROC under contract NSC101-2221-E-228-010.
CR [Anonymous], 1995, 13818 ISOIEC
   [Anonymous], 2003, ITU T REC F IN PRESS
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Bjotegaard G., 2001, VCEGM33
   Bross B., 2011, JCTVC F803 IN PRESS
   Chen H, 2009, IEEE T CIRC SYST VID, V19, P1891, DOI 10.1109/TCSVT.2009.2031370
   Chung KH, 2006, IEEE T IMAGE PROCESS, V15, P2944, DOI 10.1109/TIP.2006.877521
   Chung KL, 2008, IEEE T IMAGE PROCESS, V17, P2356, DOI 10.1109/TIP.2008.2005561
   Doutre C, 2008, IEEE T CIRC SYST VID, V18, P725, DOI 10.1109/TCSVT.2008.919111
   Doutre C, 2009, IEEE IMAGE PROC, P3401, DOI 10.1109/ICIP.2009.5413873
   Gastaldi F., 2005, P 13 EUR SIGN PROC C, P1
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Hirakawa K, 2008, IEEE T IMAGE PROCESS, V17, P1876, DOI 10.1109/TIP.2008.2002164
   Koh CC, 2003, IEEE T CONSUM ELECTR, V49, P1448, DOI 10.1109/TCE.2003.1261253
   Li JSJ, 2009, IEEE T IMAGE PROCESS, V18, P1946, DOI 10.1109/TIP.2009.2022291
   Lu WM, 2003, IEEE T IMAGE PROCESS, V12, P1194, DOI 10.1109/TIP.2003.816004
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Lukac R, 2005, PATTERN RECOGN, V38, P2208, DOI 10.1016/j.patcog.2005.04.008
   Lukac R, 2009, IMAGE PROCESS SER, P1
   Lukac R, 2006, SIGNAL PROCESS, V86, P1559, DOI 10.1016/j.sigpro.2005.09.005
   Menon D, 2009, IEEE T IMAGE PROCESS, V18, P2209, DOI 10.1109/TIP.2009.2025092
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Yang WJ, 2013, IEEE T CIRC SYST VID, V23, P591, DOI 10.1109/TCSVT.2012.2210805
   Zhang L, 2005, IEEE T IMAGE PROCESS, V14, P2167, DOI 10.1109/TIP.2005.857260
   Zhang L, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3600632
   Zhang L, 2010, IEEE T CIRC SYST VID, V20, P838, DOI 10.1109/TCSVT.2010.2045921
NR 26
TC 4
Z9 4
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 867
EP 884
DI 10.1016/j.jvcir.2013.05.012
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700013
DA 2024-07-18
ER

PT J
AU Gao, Y
   Xiu, XY
   Liang, J
   Lin, WS
AF Gao, Yu
   Xiu, Xiaoyu
   Liang, Jie
   Lin, Weisi
TI Fast synthesized and predicted just noticeable distortion maps for
   perceptual multiview video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiview video coding; Just noticeable distortion; Depth image based
   rendering; Motion estimation and compensation; Computational complexity;
   Perceptual video coding; Human visual system; Block based prediction
ID VIEW INTERPOLATION; COMPRESSION
AB The just noticeable distortion (JND) map is a useful tool for perceptual video coding. However, direct calculation of the JND map incurs high complexity, and the problem is aggravated in multiview video coding. In this paper, two fast methods are proposed to generate the JND maps of multiview videos. In the first method, the JND maps of some anchor views are used to synthesize the JND maps of other views via the depth image based rendering (DIBR), which can be much faster than direct JND computation. In the second method, the motion and disparity vectors obtained during the video coding are employed to predict the JND maps. If the prediction is not satisfactory, the JND block will be refreshed by calculating the JND directly. This method does not need any camera parameters and depth maps. The performances of the two fast JND map generation methods are evaluated in a perceptual MVC framework, where the residuals after spatial, temporal, or inter-view prediction are tuned according to the JND thresholds to save the bits without affecting the perceptual quality. Experimental results show that the JND prediction method has better accuracy and lower complexity. In addition, both fast JND methods lead to negligible degradation of the coding performance, compared to the direct JND method. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Gao, Yu; Xiu, Xiaoyu; Liang, Jie] Simon Fraser Univ, Burnaby, BC V5A 1S6, Canada.
   [Lin, Weisi] Nanyang Technol Univ, Singapore 639798, Singapore.
C3 Simon Fraser University; Nanyang Technological University
RP Gao, Y (corresponding author), Simon Fraser Univ, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
EM gaoyug@sfu.ca; xxa4@sfu.ca; jiel@sfu.ca; wslin@ntu.edu.sg
RI Liang, Jie/F-3241-2011; Lin, Weisi/A-3696-2011; Lin, Weisi/A-8011-2012
OI Lin, Weisi/0000-0001-9866-1947; Liang, Jie/0000-0003-3003-4343
FU Canada NSERC [RGPIN312262, STPGP350740, STPGP380875]
FX This work was supported in part by Canada NSERC under grants
   RGPIN312262, STPGP350740 and STPGP380875.
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Bjontegaard G., 2001, Document VCEG-M33
   Chou CH, 1996, IEEE T CIRC SYST VID, V6, P143, DOI 10.1109/76.488822
   Flierl M, 2007, IEEE SIGNAL PROC MAG, V24, P66, DOI 10.1109/MSP.2007.905699
   Gao Y, 2011, IEEE INT SYMP CIRC S, P2153
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   JMVC (Joint Multiview Video Coding), 2009, SOFTWARE
   Martinian E., 2006, PICT COD S BEIJ CHIN
   Merkle P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1717, DOI 10.1109/ICME.2006.262881
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiu X., 2009, PICT COD S CHIC US, P1
   Xiu XY, 2011, IEEE T CIRC SYST VID, V21, P693, DOI 10.1109/TCSVT.2011.2129230
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 15
TC 2
Z9 2
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2013
VL 24
IS 6
SI SI
BP 700
EP 707
DI 10.1016/j.jvcir.2012.04.004
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 164RJ
UT WOS:000320426900007
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wang, ZY
AF Wang Xingyuan
   Wang Zongyu
TI A novel method for image retrieval based on structure elements'
   descriptor
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Texture descriptor; Color descriptor; Quantization color space; Content
   based image retrieval; Structure elements' descriptor; Structure
   elements' histogram; Texton detection; HSV color space
ID COLOR
AB In this paper, structure elements' descriptor (SED) - a novel texture descriptor, is proposed. SED can effectively describe images and represent image local features. Moreover, SED can extract and describe color and texture features. The image structure elements' histogram (SEH) is computed by SED, and HSV color space is used (it has been quantized to 72 bins). SEH integrates the advantages of both statistical and structural texture description methods, and it can represent the spatial correlation of color and texture. The results demonstrate that the method has a better performance than other image retrieval methods in the experiments. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Wang Xingyuan; Wang Zongyu] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Wang, XY (corresponding author), Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
EM wangxy@dlut.edu.cn; chenxizongyu@163.com
RI LIU, Qing Yu/IWV-1159-2023; Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61173183, 60973152,
   60573172]; Superior University Doctor Subject Special Scientific
   Research Foundation of China [20070141014]; Program for Liaoning
   Excellent Talents in University [LR2012003]; National Natural Science
   Foundation of Liaoning Province [20082165]; Fundamental Research Funds
   for the Central Universities [DUT12JB06]
FX This research is supported by the National Natural Science Foundation of
   China (Nos. 61173183, 60973152, and 60573172), the Superior University
   Doctor Subject Special Scientific Research Foundation of China (No.
   20070141014), Program for Liaoning Excellent Talents in University (No.
   LR2012003), the National Natural Science Foundation of Liaoning Province
   (No. 20082165) and the Fundamental Research Funds for the Central
   Universities (No. DUT12JB06).
CR Aptoula E, 2009, IEEE T IMAGE PROCESS, V18, P2505, DOI 10.1109/TIP.2009.2027363
   Bian W, 2010, IEEE T IMAGE PROCESS, V19, P545, DOI 10.1109/TIP.2009.2035223
   Celik T, 2011, PATTERN RECOGN LETT, V32, P159, DOI 10.1016/j.patrec.2010.10.003
   Chen WT, 2010, IEEE T IMAGE PROCESS, V19, P2005, DOI 10.1109/TIP.2010.2051753
   El-ghazal A, 2012, J VIS COMMUN IMAGE R, V23, P622, DOI 10.1016/j.jvcir.2012.01.011
   Gouiffès M, 2011, J VIS COMMUN IMAGE R, V22, P48, DOI 10.1016/j.jvcir.2010.10.002
   He XF, 2010, IEEE T IMAGE PROCESS, V19, P254, DOI 10.1109/TIP.2009.2032342
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Kwitt R, 2010, IEEE T IMAGE PROCESS, V19, P241, DOI 10.1109/TIP.2009.2032313
   Lin CH, 2011, EXPERT SYST APPL, V38, P11412, DOI 10.1016/j.eswa.2011.03.014
   Liu GH, 2008, PATTERN RECOGN, V41, P3521, DOI 10.1016/j.patcog.2008.06.010
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu GH, 2010, PATTERN RECOGN, V43, P2380, DOI 10.1016/j.patcog.2010.02.012
   Liu Junling, 2011, Proceedings 2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC 2011), P921
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmoudi F, 2003, PATTERN RECOGN, V36, P1725, DOI [10.1016/S0031-3203(03)00010-4, 10.1016/S0031-3203(03)000104]
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Thang ND, 2011, INFORM SCIENCES, V181, P3162, DOI 10.1016/j.ins.2011.03.021
   Nister David, 2006, CVPR
   Quellec G, 2012, IEEE T IMAGE PROCESS, V21, P1613, DOI 10.1109/TIP.2011.2180915
   Quellec G, 2010, IEEE T IMAGE PROCESS, V19, P25, DOI 10.1109/TIP.2009.2030479
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Zagoris K, 2011, J VIS COMMUN IMAGE R, V22, P378, DOI 10.1016/j.jvcir.2011.03.002
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
NR 28
TC 117
Z9 131
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 63
EP 74
DI 10.1016/j.jvcir.2012.10.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600007
DA 2024-07-18
ER

PT J
AU Sánchez-Beato, A
AF Sanchez-Beato, Alfonso
TI Coordinate-descent super-resolution and registration for parametric
   global motion models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-frame registration; Multi-frame restoration; Registration; Image
   restoration; Super-resolution; Joint registration and super-resolution;
   Parametric motion; Coordinate-descent
AB We present a method for simultaneously obtaining registration and super-resolution from a sequence of low resolution images, based on a coordinate-descent approach. The novelty of the algorithm resides on the registration step, which can be applied easily to any parametric global motion model. We prove the validity of the model with synthetic and real data experiments, being of special interest the good performance achieved in the difficult case of images registered under a projective transformation. (C) 2012 Elsevier Inc. All rights reserved.
C1 UNED, Dept Informat & Automat, Madrid 28040, Spain.
C3 Universidad Nacional de Educacion a Distancia (UNED)
RP Sánchez-Beato, A (corresponding author), UNED, Dept Informat & Automat, C Juan del Rosal 16, Madrid 28040, Spain.
EM abeato@ieee.org
CR [Anonymous], MATLAB and Octave functions for computer vision and image processing
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   He Y, 2007, IEEE T IMAGE PROCESS, V16, P2830, DOI 10.1109/TIP.2007.908074
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Robinson D, 2006, IEEE T IMAGE PROCESS, V15, P1413, DOI 10.1109/TIP.2006.871079
   Robinson D, 2009, COMPUT J, V52, P31, DOI 10.1093/comjnl/bxm007
   Sánchez-Beato A, 2008, IEEE T IMAGE PROCESS, V17, P1817, DOI 10.1109/TIP.2008.2002833
   Segall CA, 2004, IEEE T IMAGE PROCESS, V13, P898, DOI 10.1109/TIP.2004.827230
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Vandewalle P, 2007, IEEE T SIGNAL PROCES, V55, P3687, DOI 10.1109/TSP.2007.894257
   ZOMET A, 2001, P 2001 IEEE COMP SOC, V1
NR 13
TC 4
Z9 4
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1060
EP 1067
DI 10.1016/j.jvcir.2012.07.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900010
DA 2024-07-18
ER

PT J
AU Xu, PF
   Miao, QQ
   Shi, C
   Zhang, JY
   Li, WS
AF Xu, Pengfei
   Miao, Qiguang
   Shi, Cheng
   Zhang, Junying
   Li, Weisheng
TI An edge detection algorithm based on the multi-direction shear transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Edge detection; The multi-direction shear transform; Edge fusion; The
   wavelet transform; The directional edges; The multi-direction edge
   detection; The weighted average method; Symmetric extension
AB Wavelet multi-resolution analysis allows us to detect edges at different scales. However, the wavelet transform can only capture edge information in three directions, horizontal, vertical and diagonal. In addition, the extracted edges are discontinuous. A new edge detection method to solve these problems is proposed in his paper. Firstly, the image is extended symmetrically by applying horizontal and vertical reflections. Secondly, shear transform is taken on the extended images according to various shear matrixes. Thirdly, the edges of the sheared images are detected by means of wavelet transform. The edges detected in different directions have some difference and can complement each other, so we fuse them with a fusion rule. Finally, a threshold is set to refine the edges. The proposed method works efficiently on the images, and the continuity of the edge is getting better. Besides, the method is able to distinguish the real edges from the noise. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Xu, Pengfei; Miao, Qiguang; Shi, Cheng; Zhang, Junying] Xidian Univ, Sch Comp Sci, Xian 710071, Shaanxi, Peoples R China.
   [Li, Weisheng] Chongqing Univ Posts & Telecommun, Coll Comp Sci & Technol, Chongqing 400065, Peoples R China.
C3 Xidian University; Chongqing University of Posts & Telecommunications
RP Xu, PF (corresponding author), Xidian Univ, Sch Comp Sci, Xian 710071, Shaanxi, Peoples R China.
EM xpf1987071500@126.com; QGMiao@163.com
OI Miao, Qiguang/0000-0002-2872-388X
FU National Natural Science Foundations of China [61072109, 61142011];
   Fundamental Research Funds for the Central Universities; Creative
   Project of the Science and Technology State of xi'an [CXY1133(1),
   CXY1119(6)]; Key Science and Technology Financing Projects of Ministry
   of Education [210184]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments and advices which contributed much to the improvement
   of this paper. The work was jointly supported by the National Natural
   Science Foundations of China under grant Nos. 61072109, 61142011, the
   Fundamental Research Funds for the Central Universities of 2012, the
   Creative Project of the Science and Technology State of xi'an under
   grant No. CXY1133(1) and CXY1119(6), the Key Science and Technology
   Financing Projects of Ministry of Education under grant No. 210184.
CR Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Deng CX, 2009, INT C WAVEL ANAL PAT, P355, DOI 10.1109/ICWAPR.2009.5207469
   [段瑞玲 Duan Ruiling], 2005, [光学技术, Optical Technology], V31, P415
   Galun Meirav., 2007, Computer Vision, P1
   Gonzalez Rafael C., 2008, DIGITAL IMAGE PROCES, P287
   Kimmel R, 2000, INT J COMPUT VISION, V39, P111, DOI 10.1023/A:1008171026419
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113
   Ma SF, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P58, DOI 10.1109/ICACC.2010.5487180
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   ROSENFELD A, 1981, IEEE T PATTERN ANAL, V3, P101, DOI 10.1109/TPAMI.1981.4767056
   Sobel I., 1970, 121 STANF U
   Tabb M, 1997, IEEE T IMAGE PROCESS, V6, P642, DOI 10.1109/83.568922
   [田岩岩 TIAN Yanyan], 2007, [大连海事大学学报, Journal of Dalian Maritime University], V33, P102
   Wan Li, 2003, COMPUTING TECHNOLOGY, V22, P24
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
NR 21
TC 12
Z9 15
U1 0
U2 34
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2012
VL 23
IS 5
BP 827
EP 833
DI 10.1016/j.jvcir.2012.04.008
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 079BO
UT WOS:000314145400012
DA 2024-07-18
ER

PT J
AU Chiang, PY
   Kuo, CCJ
AF Chiang, Pei-Ying
   Kuo, C. -C. Jay
TI Voxel-based shape decomposition for feature-preserving 3D thumbnail
   creation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Voxel-based shape decomposition; Volumetric shape representation;
   Primitive approximation; Skeleton extraction; Skeletonization; Skeleton
   refinement; Feature-preserving 3D thumbnail; Skeleton-guided shape
   decomposition
ID SIMPLIFICATION
AB In this work, we study the problem of voxel-based shape decomposition and simplification to create simplified 3D models, called 3D thumbnails, which preserve the salient features of their original models to facilitate users' interactive browsing. The proposed method decomposes a 3D model into multiple parts and simplifies each decomposed part individually. In this process, a 3D model is first converted into a voxel-based shape representation and a rough skeleton is extracted using the thinning operation. Then, a skeleton refinement algorithm is proposed to fine-tune the thinned skeleton and decompose the skeleton into multiple groups. The remaining processing steps include: (1) taking body measurements of each part with PCA transformation and (2) creating the 3D thumbnail by primitive approximation. It is shown by experimental results that the proposed voxel-based scheme outperforms the mesh-based scheme in the sense that the resultant 3D thumbnail can preserve more features when it is greatly simplified. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Chiang, Pei-Ying] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   Univ So Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Chiang, PY (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM peiyingc@usc.edu; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR [Anonymous], Thinvox. 3D thinning tool
   [Anonymous], Binvox. 3D mesh voxelizer
   Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P14
   Attene M, 2006, VISUAL COMPUT, V22, P181, DOI 10.1007/s00371-006-0375-x
   CHIANG RY, 2010, PAC RIM C MULT
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   GARLAND M, 1999, THESIS PITTSBURGH
   Gelfand Natasha, 2004, Proceedings of the 2004 Eurographics/ACM SIGGRAPH symposium on Geometry processing, P214
   He TS, 1995, VISUALIZATION '95 - PROCEEDINGS, P296, DOI 10.1109/VISUAL.1995.485142
   HERTEL S, 1984, ACTA INFORM, V21, P501, DOI 10.1007/BF00271644
   III JOT, 2004, SHORT SURV MESH SIMP
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343
   Lin HYS, 2007, IEEE T MULTIMEDIA, V9, P46, DOI 10.1109/TMM.2006.886344
   LIU RF, 2009, COMPUTER GRAPHICS FO, V28
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Luebke DP, 2001, IEEE COMPUT GRAPH, V21, P24, DOI 10.1109/38.920624
   Mortara M, 2009, COMPUT GRAPH-UK, V33, P280, DOI 10.1016/j.cag.2009.03.003
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Palágyi K, 1999, LECT NOTES COMPUT SC, V1568, P325
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Wang YS, 2008, IEEE T VIS COMPUT GR, V14, P926, DOI 10.1109/TVCG.2008.38
   Wu JH, 2005, COMPUT GRAPH FORUM, V24, P277, DOI 10.1111/j.1467-8659.2005.00852.x
NR 24
TC 9
Z9 9
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 1
EP 11
DI 10.1016/j.jvcir.2011.07.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100001
DA 2024-07-18
ER

PT J
AU Fookes, C
   Lin, F
   Chandran, V
   Sridharan, S
AF Fookes, Clinton
   Lin, Frank
   Chandran, Vinod
   Sridharan, Sridha
TI Evaluation of image resolution and super-resolution on face recognition
   performance
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Super-resolution; Image resolution; Evaluation
   framework; Surveillance; Robust optical flow; Hallucination; Principal
   component analysis; Eigenface; Elastic bunch graph matching
AB While researchers strive to improve automatic face recognition performance, the relationship between image resolution and face recognition performance has not received much attention. This relationship is examined systematically and a framework is developed such that results from super-resolution techniques can be compared. Three super-resolution techniques are compared with the Eigenface and Elastic Bunch Graph Matching face recognition engines. Parameter ranges over which these techniques provide better recognition performance than interpolated images is determined. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Fookes, Clinton; Lin, Frank; Chandran, Vinod; Sridharan, Sridha] Queensland Univ Technol, Image & Video Res Lab, Brisbane, Qld 4001, Australia.
C3 Queensland University of Technology (QUT)
RP Fookes, C (corresponding author), Queensland Univ Technol, Image & Video Res Lab, GPO Box 2434, Brisbane, Qld 4001, Australia.
EM c.fookes@qut.edu.au; fclin@ieee.org; v.chandran@qut.edu.au;
   s.sridharan@qut.edu.au
RI Chandran, Vinod/N-3053-2019; Fookes, Clinton/I-9786-2012
OI Chandran, Vinod/0000-0003-3185-0852; Fookes,
   Clinton/0000-0002-8515-6324; Sridharan, Sridha/0000-0003-4316-9001
FU Australian Government Department of the Prime Minister and Cabinet
   through the National Security Science and Technology Unit
FX This project was supported by the Australian Government Department of
   the Prime Minister and Cabinet through the National Security Science and
   Technology Unit.
CR [Anonymous], 1999, SUPER RESOLUTION OPT
   [Anonymous], THESIS U OXFORD
   [Anonymous], 2004, IEEE WORKSH INT TEL
   BAILLYBAILLIERE E, 2003, P AVBPA 2003
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   BLACK M, 1992, THESIS YALE UNIVERSE
   BOLME D, 2003, P INT C VIS SYST
   BOLME DS, 2003, THESIS COLORADO STAT
   BOOM B, 2006, P ICARCV 2006
   FOOKES C, 2010, IEEE IND EL S SPEC S
   FOOKES C, 2003, P APRS WORKSH DIG IM
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   LEMIEUX A, 2002, P ICPR 2002, V1
   LIN F, 2007, LECT NOTES COMPUTER, V4642
   LIN F, 2005, P APRS WORKSH DIG IM
   LIN F, 2006, P IEEE INT C ADV VID
   Martinez A., 1998, CVC Technical Report 24
   MESSER K, 1999, P AVBPA 1999
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   PHILLIPS P, 2005, P CVPR 05, V1
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   WANG J, 2004, P ACCV 2004
   WANG X, 2003, LECT NOTES COMPUTER, V2688
   WHEELER F, 2007, P BTAS 2007
   WISKOTT L, 1997, P CAIP 97
NR 28
TC 49
Z9 56
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 75
EP 93
DI 10.1016/j.jvcir.2011.06.004
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100008
DA 2024-07-18
ER

PT J
AU Forchhammer, S
   Li, HY
   Andersen, JD
AF Forchhammer, Soren
   Li, Huiying
   Andersen, Jakob Dahl
TI No-reference analysis of decoded MPEG images for PSNR estimation and
   post-processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No reference PSNR estimation; Quantization parameter estimation; I-frame
   detection; Image post-processing; Video post-processing; DCT; MPEG
ID DEBLOCKING FILTER; SEPARATE MODES
AB We propose no-reference analysis and processing of DCT (Discrete Cosine Transform) coded images based on estimation of selected MPEG parameters from the decoded video. The goal is to assess MPEG video quality and perform post-processing without access to neither the original stream nor the code stream. Solutions are presented for MPEG-2 video. A method to estimate the quantization parameters of DCT coded images and MPEG l-frames at the macro-block level is presented. The results of this analysis is used for deblocking and deringing artifact reduction and no-reference PSNR estimation without code stream access. An adaptive deringing method using texture classification is presented. On the test set, the quantization parameters in MPEG-2 l-frames are estimated with an overall accuracy of 99.9% and the PSNR is estimated with an overall average error of 0.3 dB. The deringing and deblocking algorithms yield improvements of 0.3 dB on the MPEG-2 decoded test sequences. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Forchhammer, Soren; Li, Huiying; Andersen, Jakob Dahl] Tech Univ Denmark, Dept Photon Engn, DK-2800 Lyngby, Denmark.
C3 Technical University of Denmark
RP Forchhammer, S (corresponding author), Tech Univ Denmark, Dept Photon Engn, Bldg 343, DK-2800 Lyngby, Denmark.
EM sofo@fotonik.dru.dk
OI Forchhammer, Soren/0000-0002-6698-8870
FU Danish Strategic Research Council
FX This work was supported in part by the Danish Strategic Research Council
   under the NABIIT programme.
CR [Anonymous], 2004, DIGITAL TELEVISION P
   [Anonymous], 2008, Subjective video quality assessment methods for multimedia applications. Recommendation P.910
   Averbuch AZ, 2005, IEEE T IMAGE PROCESS, V14, P200, DOI 10.1109/TIP.2004.840688
   BRANDAO T, 2007, PICT COD S LISB PORT
   BRANDAO T, 2008, P C EUSIPCO 2008 LAU
   Chen YY, 2008, J VIS COMMUN IMAGE R, V19, P231, DOI 10.1016/j.jvcir.2008.02.001
   Eden A, 2007, IEEE T CONSUM ELECTR, V53, P667, DOI 10.1109/TCE.2007.381744
   GUNTURK B, 2002, IEEE T CIRC SYST APR, P276
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P1221, DOI 10.1109/76.974677
   Ichigaya A, 2006, IEEE T CIRC SYST VID, V16, P251, DOI 10.1109/TCSVT.2005.858745
   *ISO IEC, 2000, 138182 ISOIEC
   Kim C, 2002, SIGNAL PROCESS-IMAGE, V17, P525, DOI 10.1016/S0923-5965(02)00026-7
   Kim SD, 1999, IEEE T CIRC SYST VID, V9, P156, DOI 10.1109/76.744282
   KNEE MJ, 2005, Patent No. 006895049
   Kwon DK, 2005, P SOC PHOTO-OPT INS, V5685, P702, DOI 10.1117/12.589575
   LI H, 2009, THESIS TECHNICAL U D
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   LIU S, 2002, IEEE T IMAGE P   DEC, P1139
   Martins B, 2002, IEEE T CIRC SYST VID, V12, P803, DOI 10.1109/TCSVT.2002.803227
   Oguz SH, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P628, DOI 10.1109/MMSP.1998.739051
   PETRICCA M, 2009, P 43 AS C SIGN SYST
   SANNINO D, 2010, THESIS TECHNICAL U D
   Shen MY, 1998, J VIS COMMUN IMAGE R, V9, P2, DOI 10.1006/jvci.1997.0378
   SONKA W, 1998, IMAGE PROCESSING ANA
   Tai SC, 2005, IEEE T CIRC SYST VID, V15, P733, DOI 10.1109/TCSVT.2005.848314
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Virk K, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P769, DOI 10.1109/ICME.2008.4607548
   VO DT, 2009, IEEE T IMAGE P   JUN, P1166
   Wang GY, 2006, ACM T GRAPHIC, V25, P1360, DOI 10.1145/1183287.1183292
   Wolff T, 2010, SIGNAL PROCESS, V90, P80, DOI 10.1016/j.sigpro.2009.05.018
   Zakhor A, 1992, IEEE T CIRC SYST VID, V2, P91, DOI 10.1109/76.134377
   1999, MPEG 4 VIDEO STAND 2
   MPEG 4 2
NR 33
TC 9
Z9 9
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2011
VL 22
IS 4
BP 313
EP 324
DI 10.1016/j.jvcir.2011.01.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 751AG
UT WOS:000289589100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Seiler, J
   Kaup, A
AF Seiler, Juergen
   Kaup, Andre
TI Motion Compensated Three-Dimensional Frequency Selective Extrapolation
   for improved error concealment in video communication
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Signal extrapolation; Sparse modeling; Frequency selective
   extrapolation; Motion compensation; Error concealment; Image
   restoration; Video communication; Hybrid video coding
ID H.264/AVC VIDEO; FADING SCHEME; INTERPOLATION; PREDICTION; ALGORITHM
AB During transmission of video data over error-prone channels the risk of getting severe image distortions due to transmission errors is ubiquitous. To deal with image distortions at decoder side, error concealment is applied. This article presents Motion Compensated Three-Dimensional Frequency Selective Extrapolation, a novel spatio-temporal error concealment algorithm. The algorithm uses fractional-pel motion estimation and compensation as initial step, being followed by the generation of a model of the distorted signal. The model generation is conducted by an enhanced version of Three-Dimensional Frequency Selective Extrapolation, an existing error concealment algorithm. Compared to this existent algorithm, the proposed one yields an improvement in concealment quality of up to 1.64 dB PSNR. Altogether, the incorporation of motion compensation and the improved model generation extends the already high extrapolation quality of the underlying Frequency Selective Extrapolation, resulting in a gain of more than 3 dB compared to other well-known error concealment algorithms. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Seiler, Juergen; Kaup, Andre] Univ Erlangen Nurnberg, Chair Multimedia Commun & Signal Proc, D-91058 Erlangen, Germany.
C3 University of Erlangen Nuremberg
RP Seiler, J (corresponding author), Univ Erlangen Nurnberg, Chair Multimedia Commun & Signal Proc, Cauerstr 7, D-91058 Erlangen, Germany.
EM seiler@lnt.de; kaup@lnt.de
OI Kaup, Andre/0000-0002-0929-5074
FU German Research Foundation Deutsche Forschungsgemeinschaft (DFG) [KA
   926/1-2]
FX The work of J. Seiler and A. Kaup was partly supported by the German
   Research Foundation Deutsche Forschungsgemeinschaft (DFG) under contract
   number KA 926/1-2.
CR Alkachouh Z, 2000, IEEE T IMAGE PROCESS, V9, P729, DOI 10.1109/83.841948
   Atzori L, 2001, IEEE T MULTIMEDIA, V3, P326, DOI 10.1109/6046.944476
   Belfiore S, 2003, SIGNAL PROCESS-IMAGE, V18, P907, DOI 10.1016/j.image.2003.08.008
   BOPARDIKAR AS, 2005, P EUR SUMM 2005 HEID
   CHEN Y, 2006, IEEE INT S CIRC SYST
   ERICSSON S, 1985, IEEE T COMMUN, V33, P1291, DOI 10.1109/TCOM.1985.1096251
   FECKER U, 2008, P INT WORKSH MULT SI, P267
   Flierl M, 2001, IEEE DATA COMPR CONF, P341, DOI 10.1109/DCC.2001.917165
   Friebe M, 2006, IEEE IMAGE PROC, P2237, DOI 10.1109/ICIP.2006.312807
   Friebe M, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P296, DOI 10.1109/MMSP.2006.285317
   Fumagalli M, 2006, SIGNAL PROCESS-IMAGE, V21, P829, DOI 10.1016/j.image.2006.08.007
   GIROD B, 1993, IEEE T COMMUN, V41, P604, DOI 10.1109/26.223785
   GIROD B, 1987, IEEE J SEL AREA COMM, V5, P1140, DOI 10.1109/JSAC.1987.1146632
   Hadar O, 2005, EURASIP J APPL SIG P, V2005, P1821, DOI 10.1155/ASP.2005.1821
   Hwang MC, 2008, IEICE T FUND ELECTR, VE91A, P740, DOI 10.1093/ietfec/e91-a.3.740
   *JOINT VID TEAM, 2008, H 264 AVC REF SOFTW
   *JOINT VID TEAM IS, 2003, JVTG050R1 ISO IEC MP
   Kaup A, 2005, AEU-INT J ELECTRON C, V59, P147, DOI 10.1016/j.aeue.2005.03.015
   Kung WY, 2006, IEEE T CIRC SYST VID, V16, P789, DOI 10.1109/TCSVT.2006.877391
   LAM WM, 1993, P ICASSP, V5, P417
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Meisinger K, 2007, IEEE T IMAGE PROCESS, V16, P2348, DOI 10.1109/TIP.2007.903261
   NATARAJAN BK, 1995, SIAM J COMPUT, V24, P227, DOI 10.1137/S0097539792240406
   OELBAUM T, 2007, P PICT COD S PCS LIS
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   PARK CS, 1994, ISCAS, V3, P229
   SEILER J, 2007, P PICT COD S PCS LIS
   SEILER J, 2008, P EUR SIGN PROC C EU
   Seiler J, 2008, INT CONF ACOUST SPEE, P781, DOI 10.1109/ICASSP.2008.4517726
   Song K, 2007, IEEE INT SYMP CIRC S, P973, DOI 10.1109/ISCAS.2007.378089
   Stockhammer T, 2005, IEEE WIREL COMMUN, V12, P6, DOI 10.1109/MWC.2005.1497853
   Sullivan GJ, 2005, P IEEE, V93, P18, DOI 10.1109/JPROC.2004.839617
   SUN HF, 1995, IEEE T IMAGE PROCESS, V4, P470, DOI 10.1109/83.370675
   Temlyakov VN, 2000, ADV COMPUT MATH, V12, P213, DOI 10.1023/A:1018917218956
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tsekeridou S, 2000, IEEE T CIRC SYST VID, V10, P646, DOI 10.1109/76.845010
   WANG Y, 1993, IEEE T COMMUN, V41, P1544, DOI 10.1109/26.237889
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wedi T, 2006, IEEE T CIRC SYST VID, V16, P484, DOI 10.1109/TCSVT.2006.870856
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
NR 43
TC 4
Z9 7
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2011
VL 22
IS 3
BP 213
EP 225
DI 10.1016/j.jvcir.2010.11.006
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 737SA
UT WOS:000288587300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lee, EK
   Ho, YS
AF Lee, Eun-Kyung
   Ho, Yo-Sung
TI Generation of high-quality depth maps using hybrid camera system for 3-D
   video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth map generation; Depth camera; Multi-view camera system; 3-D video;
   3-D TV; Multi-view video; Stereo matching; View synthesis
AB In this paper, we present a hybrid camera system combining one time-of-flight depth camera and multiple video cameras to generate multi-view video sequences and their corresponding depth maps. In order to obtain the multi-view video-plus-depth data using the hybrid camera system, we capture multi-view videos using multiple video cameras and a single view depth video with the depth camera. After performing a three-dimensional (3-D) warping operation to obtain an initial depth map at each viewpoint, we refine the initial depth map using segment-based stereo matching. To reduce mismatched depth values along object boundaries, we detect the moving objects using color difference between frames and extract occlusion and disocclusion areas with the initial depth information. Finally, we recompute the depth value of each pixel in each segment using pairwise stereo matching with a proposed cost function. Experimental results show that the proposed hybrid camera system produces multi-view video sequences with more accurate depth maps, especially along the boundary of objects. In addition, it is suitable for generating more natural 3-D views for 3-D TV than previous works.. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Lee, Eun-Kyung; Ho, Yo-Sung] GIST, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Lee, EK (corresponding author), GIST, 1 Oryong Dong, Kwangju 500712, South Korea.
EM eklee78@gist.ac.kr; hoyo@gist.ac.kr
FU MKE (The Ministry of Knowledge Economy), Korea, under the ITRC
   (Information Technology Research Center) [NIPA-2010-(C1090-1011-0003)]
FX This research was supported by the MKE (The Ministry of Knowledge
   Economy), Korea, under the ITRC (Information Technology Research Center)
   support program supervised by the NIPA (National IT Industry Promotion
   Agency) (NIPA-2010-(C1090-1011-0003)).
CR [Anonymous], CAMERA CALIBRATION T
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], CS20050821 UCSD CSE
   *CAN INC, CANESTAVISIONTM EL P
   CHO J, 2007, P 3DTV C
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fehn C, 2006, P IEEE, V94, P524, DOI 10.1109/JPROC.2006.870688
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Iddan GJ, 2001, P SOC PHOTO-OPT INS, V4298, P48, DOI 10.1117/12.424913
   *ISO, 2008, ISOIECJTC1SC29WG11M1
   *ISO, 2007, ISOIECJTC1SC29WG11N8
   Kang YS, 2008, MONOGR COTSEN INST A, P83
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kawakita M., 2002, INT C BROADCAST, P397
   Lee E., 2009, INT C IMM TEL IMMERS, pT5
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Schuon Sebastian, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563171
   Smolic A, 2004, IEEE T CIRC SYST VID, V14, P348, DOI 10.1109/TCSVT.2004.823395
   *SWISS CTR EL MICR, SWISS RANG SR 2
   Um GM, 2005, PROC SPIE, V5664, P271, DOI 10.1117/12.586764
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   ZHU J, 2008, P IEEE C COMP VIS PA, P231
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 24
TC 21
Z9 24
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2011
VL 22
IS 1
SI SI
BP 73
EP 84
DI 10.1016/j.jvcir.2010.10.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 710XW
UT WOS:000286551300007
DA 2024-07-18
ER

PT J
AU Xia, T
   Mei, T
   Hua, G
   Zhang, YD
   Hua, XS
AF Xia, Tian
   Mei, Tao
   Hua, Gang
   Zhang, Yong-Dong
   Hua, Xian-Sheng
TI Visual quality assessment for web videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual quality assessment; Web video; Non-reference; Domain specific
AB The advent of video-sharing sites such as YouTube has led to an unprecedented Internet delivery of community-contributed video content. However, most of these videos are not quality-controlled. This paper reports a first attempt towards assessing web videos in terms of visual quality with significant tests on 30k web videos. We regard the quality assessment as a two-class classification problem: features motivated from domain knowledge are extracted to be the visual representation while the overall quality is the two-class label. Observing that web videos are characterized by a much higher diversity of content, genres, capture devices, and skills than any other traditional video program, we propose to combine two types of domain knowledge to predict the perceived quality score. One of the domain knowledge types is the spatiotemporal factors affecting the overall perceived quality of web videos, including four spatial factors and two temporal factors. We study the effectiveness of various spatiotemporal factors and propose some novel spatial factors pertaining the characteristics of web videos. The other is the video editing style, including shot editing style, frame size, and black side ratio. Comprehensive experiments and evaluations over 30k web videos which add up to 1200 h in total demonstrated the effectiveness of the proposed approach. We show some preliminary results for application to filtering and re-ranking of retrieved web videos. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Xia, Tian; Zhang, Yong-Dong] Chinese Acad Sci, Adv Comp Res Lab, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Mei, Tao] Microsoft Res Asia, Beijing 100190, Peoples R China.
   [Hua, Gang] IBM Res Corp, TJ Watson Ctr, Armonk, NY USA.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Microsoft Research Asia; Microsoft; International Business Machines
   (IBM)
RP Xia, T (corresponding author), Chinese Acad Sci, Adv Comp Res Lab, Inst Comp Technol, Beijing 100190, Peoples R China.
EM txia@ict.ac.cn; tmei@microsoft.com; ganghua@gmail.com; zhyd@ict.ac.cn;
   xshua@microsoft.com
RI XIA, Tian/A-5392-2015; Mei, Tao/GQZ-0596-2022
OI Mei, Tao/0000-0002-5990-7307
CR [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   GEORGE A, 2002, IEEE T CIRCUITS SYST, V12, P877
   Hsu P, 2008, LECT NOTES COMPUT SC, V4903, P277
   Hsu W. H., 2006, MULTIMEDIA '06, P35
   KONRAD J, 1998, M3096 ISOIECJTC1SC29
   Lambrecht CJV, 1996, P SOC PHOTO-OPT INS, V2668, P450, DOI 10.1117/12.235440
   Lee C, 2006, OPT ENG, V45, DOI 10.1117/1.2160515
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Mei T, 2007, IEEE T CIRC SYST VID, V17, P699, DOI 10.1109/TCSVT.2007.896640
   Tong HH, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P247
   TORU Y, 2007, IEEE PACKET VIDEO 20, P288
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   *VQEG, 2003, FIN REP VID QUAL GRO
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Wu S, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P217
   Yang FZ, 2005, IEEE SIGNAL PROC LET, V12, P685, DOI 10.1109/LSP.2005.855553
   YANG LJ, 2004, P ACM SIGMM INT WORK, P265
NR 21
TC 7
Z9 7
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 826
EP 837
DI 10.1016/j.jvcir.2010.06.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500007
DA 2024-07-18
ER

PT J
AU Abbadeni, N
AF Abbadeni, Noureddine
TI Texture representation and retrieval using the causal autoregressive
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Texture Representation; Autoregressive model; Causality; Estimated
   parameters; Perceptual meaning; Texture Retrieval; CBIR;
   Precision/recall
ID FEATURES
AB In this paper we propose to revisit the well-known autoregressive model (AR) as a texture representation model. We consider the AR model with causal neighborhoods. First, we will define the AR model and discuss briefly the parameters estimation process. Then, we will present the synthesis algorithm and we will show some experimental results. A perceptual interpretation of the AR estimated parameters will be then proposed and discussed. In particular, a computational measure to estimate the degree of randomness/regularity of textures is proposed. The set of the estimated parameters will be then applied in content-based image retrieval (CBIR) to model texture content and experimental results are shown. Benchmarking, using the precision/recall measures conducted on the well-known Brodatz database, shows interesting results. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Abbadeni, Noureddine] King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
   [Abbadeni, Noureddine] Univ Sherbrooke, Sherbrooke, PQ J1K 2R1, Canada.
   [Abbadeni, Noureddine] Al Ain Univ Sci & Technol, Al Ain, U Arab Emirates.
C3 King Saud University; University of Sherbrooke
RP Abbadeni, N (corresponding author), King Saud Univ, Coll Comp & Informat Sci, POB 51178, Riyadh 11543, Saudi Arabia.
EM nabbadeni@ksu.edu.sa
CR ABBADENI N, 1998, 216 U SHERBR
   ABBADENI N, 2005, PERCEPTUAL INTERPRET
   Abbadeni N., 2003, P 3 INT WORKSH TEXT
   [Anonymous], 1999, Visual Information Retrieval
   [Anonymous], 1993, HDB PATTERN RECOGNIT
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Frankot R. T., 1987, IEEE T GEOSCIENCE RE, V25
   GOWER JC, 1971, BIOMETRICS, V27, P857, DOI 10.2307/2528823
   KASHYAP RL, 1983, IEEE T INFORM THEORY, V29, P60, DOI 10.1109/TIT.1983.1056610
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   RANDEN T, 1994, WORKING PAPERS HOGSK
   SOLBERG AHS, 1997, TEXTURE ANAL SAR IMA
   SONDGE M, 1983, THESIS U PIERRE MARI
   WEBER R, 1998, P 24 VER LARG DAT C
NR 19
TC 11
Z9 11
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 651
EP 664
DI 10.1016/j.jvcir.2010.04.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400005
DA 2024-07-18
ER

PT J
AU Bouguila, N
   Ghimire, MN
AF Bouguila, Nizar
   Ghimire, Mukti Nath
TI Discrete visual features modeling via leave-one-out likelihood
   estimation and applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discrete features; Finite mixture models; Multinomial; Dirichlet;
   Generalized Dirichlet; Leave-one-out likelihood; SVM;
   Generative/discriminative; Scene classification; Visual words
ID DIRICHLET DISTRIBUTION; IMAGE CLASSIFICATION; MAXIMUM-LIKELIHOOD;
   MIXTURE; PROBABILITIES
AB Discrete data are an important component in many image processing and computer vision applications. In this work we propose an unsupervised statistical approach to learn structures of this kind of data. The central ingredient in our model is the introduction of the generalized Dirichlet distribution as a prior to the multinomial. An estimation algorithm, based on leave-one-out likelihood and empirical Bayesian inference, for the parameters is developed. This estimation algorithm can be viewed as a hybrid expectation-maximization (EM) which alternates EM iterations with Newton-Raphson iterations using the Hessian matrix. We propose then the use of our model as a parametric basis for support vector machines within a hybrid generative/discriminative framework. In a series of experiments involving scene modeling and classification using visual words, and color texture modeling we show the efficiency of the proposed approach. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Bouguila, Nizar; Ghimire, Mukti Nath] Concordia Univ, Fac Engn & Comp Sci, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
C3 Concordia University - Canada
RP Bouguila, N (corresponding author), Concordia Univ, Fac Engn & Comp Sci, Concordia Inst Informat Syst Engn, Montreal, PQ H3G 2W1, Canada.
EM bouguila@ciise.concordia.ca; m_ghimir@encs.concordia.ca
RI Bouguila, Nizar/AGN-5929-2022; Bouguila, Nizar/AAJ-2518-2020
FU Natural Sciences and Engineering Research Council of Canada (NSERC);
   NATEQ
FX The authors thank the Natural Sciences and Engineering Research Council
   of Canada (NSERC) and a NATEQ Nouveaux Chercheurs Grant.
CR [Anonymous], 8 EUR C COMP VIS ECC
   [Anonymous], 1983, Theory of Point Estimation
   [Anonymous], 1983, Matrices with Applications in Statistics
   [Anonymous], 1997, 14 INT C MACH LEARN
   BECK J, 1972, AM J PSYCHOL, V85, P1, DOI 10.2307/1420955
   Biederman I., 2017, PERCEPTUAL ORG, P213
   Biederman I., 1988, COMPUTATIONAL PROCES, P370
   Bouguila N, 2004, MACHINE LEARNING FOR SIGNAL PROCESSING XIV, P23
   Bouguila N, 2004, IEEE T IMAGE PROCESS, V13, P1533, DOI 10.1109/TIP.2004.834664
   Bouguila N, 2003, LECT NOTES ARTIF INT, V2734, P172
   BOUGUILA N, 1998, LECT NOTES ARTIF INT, V5012, P503
   Bouguila N, 2009, PATTERN RECOGN, V42, P33, DOI 10.1016/j.patcog.2008.06.022
   Bouguila N, 2008, IEEE T KNOWL DATA EN, V20, P462, DOI 10.1109/TKDE.2007.190726
   Bouguila N, 2007, IEEE T PATTERN ANAL, V29, P1716, DOI [10.1109/TPAMI.2007.1095, 10.1109/TPAMl.2007.1095]
   Bouguila N, 2007, J VIS COMMUN IMAGE R, V18, P295, DOI 10.1016/j.jvcir.2007.02.005
   Bouguila N, 2006, IEEE T IMAGE PROCESS, V15, P2657, DOI 10.1109/TIP.2006.877379
   Carlin BP, 2000, Bayes and empirical Bayes methods for data analysis
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dagan I, 1999, MACH LEARN, V34, P43, DOI 10.1023/A:1007537716579
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971
   Drimbarean A, 2001, PATTERN RECOGN LETT, V22, P1161, DOI 10.1016/S0167-8655(01)00058-7
   Dunning T., 1993, Computational Linguistics, V19, P61
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FIENBERG SE, 1973, J AM STAT ASSOC, V68, P683, DOI 10.2307/2284799
   Figueiredo M. A. T., 1999, Energy Minimization Methods in Computer Vision and Pattern Recognition. Second International Workshop, EMMCVPR'99. Proceedings (Lecture Notes in Computer Science Vol.1654), P54
   Good I., 1965, The Estimation of Probabilities: An Essay on Modern Bayesian Methods
   GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Lewis D.D., 1998, LECT NOTES COMPUTER, V1398, P4
   Li Y, 2005, IEEE I CONF COMP VIS, P1605
   LOCHNER RH, 1975, J ROY STAT SOC B MET, V37, P103
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Madsen R.E., 2005, P 22 INT C MACHINE L, P545
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   MINKA TP, ESTIMATING DIR UNPUB
   MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417
   MOSTELLER F, 1963, J AM STAT ASSOC, V58, P275, DOI 10.2307/2283270
   NEY H, 1995, IEEE T PATTERN ANAL, V17, P1202, DOI 10.1109/34.476512
   NEY H, 1991, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.1991.150464
   Palm C, 2004, PATTERN RECOGN, V37, P965, DOI 10.1016/j.patcog.2003.09.010
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Raina Rajat., 2003, Advances in Neural Information Processing Systems 16
   Rennie J.D., 2003, Proceedings of the 20th International Conference on Machine Learning, P616
   Ripley BD, 1996, PATTERN RECOGNITION
   ROBBINS H, 1956, P 2 BERK S MATH STAT, P131
   SCHYNS PG, 1994, PSYCHOL SCI, V5, P195, DOI 10.1111/j.1467-9280.1994.tb00500.x
   STOFFEL JC, 1974, IEEE T COMPUT, VC 23, P428, DOI 10.1109/T-C.1974.223958
   STONE M, 1974, BIOMETRIKA, V61, P509, DOI 10.1093/biomet/61.3.509
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tuceryan M., 1998, HDB PATTERN RECOGNIT, V2nd
   UNSER M, 1986, IEEE T PATTERN ANAL, V8, P118, DOI 10.1109/TPAMI.1986.4767760
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
   VICKERS AL, 1982, IEEE T PATTERN ANAL, V4, P61, DOI 10.1109/TPAMI.1982.4767197
   WITTEN IH, 1991, IEEE T INFORM THEORY, V37, P1085, DOI 10.1109/18.87000
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
   Zhu L, 2002, ACM T INFORM SYST, V20, P224, DOI 10.1145/506309.506313
NR 64
TC 9
Z9 9
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 613
EP 626
DI 10.1016/j.jvcir.2010.04.001
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400002
DA 2024-07-18
ER

PT J
AU Shen, MM
   Wang, C
   Xue, P
   Lin, WS
AF Shen, Minmin
   Wang, Ci
   Xue, Ping
   Lin, Weisi
TI Performance of reconstruction-based super-resolution with regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Reconstruction-based algorithms; Magnification factor;
   Regularization; Performance bound; Optimal regularization parameter;
   Condition number; PSF
ID RESOLUTION ENHANCEMENT; IMAGE-RECONSTRUCTION; VIDEO SEQUENCES;
   ALGORITHM; REGISTRATION; RESTORATION; LIMITS
AB From the perspective of linear algebra, the performance of super-resolution reconstruction (SR) depends on the conditioning of the linear system characterizing the degradation model. This is analyzed in the Fourier domain using the perturbation theory. By proposing a new SR error bound in terms of the point spread function (PSF), we reveal that the blur function dominates the condition number (CN) of degradation matrix, and the advantage of non-integer magnification factors (MFs) over the integer ones comes from sampling zero crossings of the DFT of the PSF. We also explore the effect of regularization by integrating it into the SR model, and investigate the influence of the optimal regularization parameter. A tighter error bound is derived given the optimal regularization parameter. Two curves of error bounds vs. MFs are presented, and verified by processing real images. It explains that with proper regularization, SR at the integer MFs is still valid. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Shen, Minmin; Wang, Ci; Xue, Ping; Lin, Weisi] Nanyang Technol Univ, Singapore 639798, Singapore.
   [Wang, Ci] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
C3 Nanyang Technological University; Shanghai Jiao Tong University
RP Shen, MM (corresponding author), Nanyang Technol Univ, Singapore 639798, Singapore.
EM sh0001in@ntu.edu.sg
RI Lin, Weisi/A-8011-2012; Liu, Anmin/A-4730-2012; Lin, Weisi/A-3696-2011;
   Xue, Ping/A-5155-2011
OI Lin, Weisi/0000-0001-9866-1947; 
FU I2R; NTU, Singapore [12R-NTU Joint RD(2)]
FX This work is supported by I2R and NTU, Singapore, through Grants
   "12R-NTU Joint R&D(2)".
CR Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Costa GH, 2007, IEEE T SIGNAL PROCES, V55, P2084, DOI 10.1109/TSP.2007.892704
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Galatsanos NP, 1992, IEEE T IMAGE PROCESS, V1, P322, DOI 10.1109/83.148606
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   He H, 2006, IEEE T IMAGE PROCESS, V15, P592, DOI 10.1109/TIP.2005.860599
   He H, 2004, J ELECTRON IMAGING, V13, P586, DOI 10.1117/1.1762889
   He H, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P933
   He H, 2003, P SOC PHOTO-OPT INS, V5022, P1123, DOI 10.1117/12.476613
   Lee ES, 2003, IEEE T IMAGE PROCESS, V12, P826, DOI 10.1109/TIP.2003.811488
   Lin ZC, 2004, IEEE T PATTERN ANAL, V26, P83, DOI 10.1109/TPAMI.2004.1261081
   OUWERKERK JDV, 2006, J IMAGE VIS COMPUT, V24, P1039
   Park MK, 2007, OPT ENG, V46, DOI 10.1117/1.2802611
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Robinson D, 2006, IEEE T IMAGE PROCESS, V15, P1413, DOI 10.1109/TIP.2006.871079
   Robinson D, 2009, COMPUT J, V52, P31, DOI 10.1093/comjnl/bxm007
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Tanaka M, 2005, PROC CVPR IEEE, P947
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   Wang ZZ, 2005, IMAGE VISION COMPUT, V23, P393, DOI 10.1016/j.imavis.2004.11.001
NR 24
TC 5
Z9 5
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 640
EP 650
DI 10.1016/j.jvcir.2010.04.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400004
DA 2024-07-18
ER

PT J
AU Tai, ZF
   Cheng, S
   Verma, P
   Zhai, Y
AF Tai, Zhenfei
   Cheng, Samuel
   Verma, Pramode
   Zhai, Yan
TI Braille document recognition using Belief Propagation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Braille image; Radon transform; Optical character recognition; Rotation
   angle; Line-spacing; Hidden Markov Model; Belief Propagation; Pattern
   recognition
AB There is a significant need for a system to recognize Braille documents in order to preserve them and make them available to a larger group of visually impaired people. A new system for Braille document recognition is proposed. We introduce a highly-adaptive Braille documents parameters estimation method to automatically determine the rotation angle, indentations, and spacing in both vertical and horizontal orientation. The key element in determining the rotation angle of the images is based on Radon transform. Also we introduce the method of Braille translation using Belief Propagation on the assumption that the Braille document is a Hidden Markov Model. We demonstrate the effectiveness of rotation angle correction as well as the accuracy of indentation and spacing in both orientations. We also prove that the translation algorithm is efficient and robust to errors made in the dot detection. The proposed method may be used for further applications. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Tai, Zhenfei; Cheng, Samuel; Verma, Pramode; Zhai, Yan] Univ Oklahoma, Sch Elect & Comp Engn, Norman, OK 73019 USA.
C3 University of Oklahoma System; University of Oklahoma - Norman
RP Tai, ZF (corresponding author), Univ Oklahoma, Sch Elect & Comp Engn, Norman, OK 73019 USA.
EM zhenfei.tai-1@ou.edu; samuel.cheng@ou.edu; pverma@ou.edu;
   yan.zhai-1@ou.edu
OI Cheng, Samuel/0000-0002-5439-1137
CR Antonacopoulos A., 2004, P IAPR INT WORKSH DO
   BEYLKIN G, 1987, IEEE T ACOUST SPEECH, V35, P162, DOI 10.1109/TASSP.1987.1165108
   BEYLKIN G, 1985, J MATH PHYS, V26, P99, DOI 10.1063/1.526755
   BEYLKIN G, 1982, THESIS NEW YORK U
   DUBUS JP, 1988, PROCEEDINGS OF THE ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, PTS 1-4, P1584, DOI 10.1109/IEMBS.1988.94726
   Franois G., 1985, P 5 INT WORKSH COMP
   Gómez TE, 2001, ULTRASON, P591, DOI 10.1109/ULTSYM.2001.991691
   Gonzales Rafael C., 1987, DIGITAL IMAGE PROCES
   GREGORY B, 1984, COMMUNICATIONS PURE, V37, P579
   Hentzschel TW, 1995, J MICROCOMPUT APPL, V18, P341, DOI 10.1016/S0745-7138(05)80034-X
   HERMANN K, 1975, SIGCAPH COMPUTATIONA, P60
   Judea P., 1988, PROBABILISTIC REASON
   Kourosh J., 1985, J MOD OPTIC, V32, P3
   Mennens J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P428, DOI 10.1109/ICDAR.1993.395702
   Ng C. M., 1999, Proceedings Third International Conference on Computational Intelligence and Multimedia Applications. ICCIMA'99 (Cat. No.PR00300), P302, DOI 10.1109/ICCIMA.1999.798547
   Oyama Y., 1997, SYSTEM COMPUTER JAPA, V28
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Radon J., 1986, IEEE Transactions on Medical Imaging, VMI-5, P170, DOI 10.1109/TMI.1986.4307775
   Ritchings R.T., 1994, P INT ASS PATT REC W
   Strang G., 1986, Introduction to Applied Mathematics
   Tanaka M, 2007, IEEE-ASME T MECH, V12, P430, DOI 10.1109/TMECH.2007.901923
   Wong L, 2004, INT C PATT RECOG, P586, DOI 10.1109/ICPR.2004.1334316
   ZHANG S, 2007, 2 INT C INN COMP INF, P223
NR 23
TC 8
Z9 8
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2010
VL 21
IS 7
BP 722
EP 730
DI 10.1016/j.jvcir.2010.05.006
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 650DO
UT WOS:000281829400011
DA 2024-07-18
ER

PT J
AU Wang, H
   Kuo, CCJ
AF Wang, Hui
   Kuo, C. -C. Jay
TI Robust video multicast with joint network coding and video interleaving
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Network coding; Cross-layer optimization; Interleaving; Real-time;
   H.264/SVC; Unequal erasure protection (UEP); IPTV; Video conference
ID AD HOC NETWORKS; ERROR-CORRECTION
AB In this work, we propose a cross-layer solution to robust video multicast in erasure networks based on random linear network coding (RLNC) in the network layer and video interleaving (VI) in the application layer, and call it the joint RLNC-VI scheme. In the RLNC implementation, we partition one video coding unit (VCU) into several priority levels using scalable properties of H.264/SVC video. Packets from the same priority level of several VCUs form one RLNC generation, and unequal protection is applied to different generations. RLNC provides redundancy for video packets in the network layer and has proved to be useful in a multicast environment. Then, we propose a new packet-level interleaving scheme, called the RLNC-facilitated interleaving scheme, where each received packet corresponds to a new constraint on source packets. As a result, it can facilitate the RLNC decoding at the destination node. Furthermore, we study the problem of optimal interleaving design, which selects the optimal interleaving degree and the optimal redundancy of each generation. The tradeoff between delay and received video quality due to the choice of different VCUs is also examined. It is shown by simulation results that the proposed RLNC-VI scheme outperforms the pure RLNC method for robust video multicast in erasure networks. This can be explained by two reasons. First, the VI scheme distributes the impact of the loss (or erasure) of one VCU into partial data loss over multiple neighboring VCUs. Second, the original video content can be easily recovered with spatial/temporal error concealment (EC) in the joint RLNC-VI scheme. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Wang, Hui] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   Univ So Calif, Inst Signal & Image Proc, Los Angeles, CA 90089 USA.
C3 University of Southern California; University of Southern California
RP Wang, H (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM wanghui@usc.edu; cckuo@sipi.usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU Okawa Foundation
FX This work was supported by the Okawa Foundation Research Grant.
CR Acedanski S., 2005, GOOD IS RANDOM LINEA
   Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   Albanese A, 1996, IEEE T INFORM THEORY, V42, P1737, DOI 10.1109/18.556670
   [Anonymous], 2003, P ANN ALL C COMM CON
   [Anonymous], P 51 ALL C COMM CONT
   Cai N, 2006, COMMUN INF SYST, V6, P37
   Chou PA, 2007, IEEE SIGNAL PROC MAG, V24, P77, DOI 10.1109/MSP.2007.904818
   *CISC, TEL NETW
   DEB S, P IEEE INFOCOM 2005
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   HALLOUSH M, 2008, ICC 08
   Ho T, 2006, IEEE T INFORM THEORY, V52, P4413, DOI 10.1109/TIT.2006.881746
   Jaggi S, 2005, IEEE T INFORM THEORY, V51, P1973, DOI 10.1109/TIT.2005.847712
   KAI X, 2006, J ZHEJIANG UNIV-SC A, V7, DOI DOI 10.1631/JZUS.2006.A0677
   KIM JG, 2001, P C VIS COMM IM PROC
   Koetter R, 2003, IEEE ACM T NETWORK, V11, P782, DOI 10.1109/TNET.2003.818197
   KOETTER R, ABSCS0703061 CORR
   Li SYR, 2003, IEEE T INFORM THEORY, V49, P371, DOI 10.1109/TIT.2002.807285
   Liang YJ, 2002, CONF REC ASILOMAR C, P1315
   LIMA L, IEEE INT S INF THEOR
   LUN D, P 42 ANN ALL C COMM
   Padmanabhan VN, 2003, 11TH IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P16, DOI 10.1109/ICNP.2003.1249753
   Peterson LL, 2003, COMPUTER NETWORKS SY
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   SILVA D, 2007, P IEEE CAN WORKSH IN
   Silva D, 2007, 2007 10TH CANADIAN WORKSHOP ON INFORMATION THEORY, P81, DOI 10.1109/CWIT.2007.375706
   Tourapis AM, 2005, IEEE T CIRC SYST VID, V15, P119, DOI 10.1109/TCSVT.2004.837021
   Wah BW, 2000, INTERNATIONAL SYMPOSIUM ON MULTIMEDIA SOFTWARE ENGINEERING, PROCEEDINGS, P17, DOI 10.1109/MMSE.2000.897185
   WALSH J, 2008, P 4 WORKSH NETW COD
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wu Y, 2005, IEEE J SEL AREA COMM, V23, P136, DOI 10.1109/JSAC.2004.837362
   Wu YN, 2005, IEEE T COMMUN, V53, P1906, DOI 10.1109/TCOMM.2005.857148
   Yeung RW, 2006, COMMUN INF SYST, V6, P19
   Zhang Z, 2008, IEEE T INFORM THEORY, V54, P209, DOI 10.1109/TIT.2007.909139
NR 34
TC 9
Z9 11
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 77
EP 88
DI 10.1016/j.jvcir.2009.06.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800002
DA 2024-07-18
ER

PT J
AU Ronse, C
   Agnus, V
AF Ronse, Christian
   Agnus, Vincent
TI Geodesy on label images, and applications to video sequence processing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE label images; mathematical morphology; geodesic (conditional) dilation
   and erosion; geodesic reconstruction; non-distributive lattice; complete
   lattice; connectivity
ID MATHEMATICAL MORPHOLOGY; CONNECTED OPERATORS; COMPLETE LATTICES;
   ALGEBRAIC BASIS; RECONSTRUCTION; OPENINGS; FILTERS
AB Morphological operators based on the numerical ordering of grey-levels are used to filter regional minima and maxima in images. It is argued that label images constitute an appropriate framework for morphological filtering of regions which are neither minima nor maxima. Following a previous paper where we introduced morphological operations on label images [C. Ronse, V. Agnus, Morphology on label images: flat-type operators and connections, journal of Mathematical Imaging and Vision 22 (2/3) (2005) 283-3071] we study geodesic dilation (or erosion) and reconstruction. Since the lattice of label images is not distributive, some strange results may happen, so the standard definition of geodesic dilation and reconstruction must be modified in order to be effective: standard properties of geodesic operations are preserved only if we make some restrictions on the labels present in the mask or marker image. We give the relation between geodesic reconstruction and the flat zone connection on label images. We illustrate the theory with an application of morphology and geodesy on label images, to the segmentation of moving objects in video sequences. (C) 2008 Elsevier Inc. All rights reserved.
C1 [Ronse, Christian] ULP, CNRS, LSIIT, UMR 7005, F-67412 Illkirch Graffenstaden, France.
   [Agnus, Vincent] IRCAD EITS VIRTUALS, F-67091 Strasbourg, France.
C3 Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg; Centre National de la Recherche Scientifique (CNRS)
RP Ronse, C (corresponding author), ULP, CNRS, LSIIT, UMR 7005, Parc Innovat,Blvd Sebastien Brant,BP 10413, F-67412 Illkirch Graffenstaden, France.
EM cronse@dpt-info.u-strasbg.fr; Vincent.Agnus@ircad.u-strasbg.fr
RI Agnus, Vincent/AAC-2413-2019
OI Agnus, Vincent/0000-0001-9554-6492
CR AGNUS V, 2000, 15 INT C PATT REC BA, V3
   AGNUS V, 2000, 1I C FRANC REC FORM, V1
   [Anonymous], 1994, Morphological Image Operators
   Barata T, 2006, IEEE GEOSCI REMOTE S, V3, P173, DOI 10.1109/LGRS.2005.861539
   Birkhoff G., 1995, AM MATH SOC C PUBLIC, V25
   Braga-Neto U, 2002, COMPUT VIS IMAGE UND, V85, P22, DOI 10.1006/cviu.2002.0961
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066
   BREMOND F, 1996, MATH MORPHOLOGY ITS
   COUPRIE M, 2000, LECT NOTES COMPUTER
   Crespo J, 1997, J MATH IMAGING VIS, V7, P85, DOI 10.1023/A:1008270125009
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Crespo J, 1995, SIGNAL PROCESS, V47, P201, DOI 10.1016/0165-1684(95)00108-5
   CRESPO J, 1993, THESIS SCH ELECT COM
   CRESPO J, 1993, P SPIE VISUAL COMMUN, V2094
   Gatica-Perez D, 2001, IEEE T IMAGE PROCESS, V10, P1332, DOI 10.1109/83.941857
   Gratzer G., 2003, GEN LATTICE THEORY
   HEIJMANS H, 1993, MATH MORPHOLOGY IMAG, V34, P171
   Heijmans H. J. A. M., 1992, Journal of Visual Communication and Image Representation, V3, P84, DOI 10.1016/1047-3203(92)90032-O
   Heijmans H. J. A. M., 1992, Journal of Visual Communication and Image Representation, V3, P24, DOI 10.1016/1047-3203(92)90028-R
   Heijmans HJAM, 2002, J MATH IMAGING VIS, V17, P55, DOI 10.1023/A:1020726725590
   HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O
   Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777
   Keshet R., 2000, Fundamenta Informaticae, V41, P33
   KRESCH R, 1998, MATH MORPHOLOGY ITS
   Naegel B, 2007, COMPUT MED IMAG GRAP, V31, P141, DOI 10.1016/j.compmedimag.2006.12.001
   Rohlfing T, 2007, IEEE T IMAGE PROCESS, V16, P153, DOI 10.1109/TIP.2006.884936
   Ronse C, 2005, J MATH IMAGING VIS, V22, P283, DOI 10.1007/s10851-005-4895-1
   Ronse C, 2001, FUND INFORM, V46, P349
   RONSE C, 1991, CVGIP-IMAG UNDERSTAN, V54, P74, DOI 10.1016/1049-9660(91)90076-2
   RONSE C, 2002, LECT NOTES COMPUTER, V2616
   Ronse C, 2008, APPL ALGEBR ENG COMM, V19, P51, DOI 10.1007/s00200-008-0064-2
   Ronse C, 2006, J MATH IMAGING VIS, V26, P185, DOI 10.1007/s10851-006-8304-1
   SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   SALEMBIER P, 1998, MATH MORPHOLOGY ITS
   Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475
   SERRA J, 1992, CIRC SYST SIGNAL PR, V11, P47, DOI 10.1007/BF01189221
   Serra J., 1983, IMAGE ANAL MATH MORP
   Serra J., 1988, IMAGE ANAL MATH MORP
   SERRA P, 1993, SPIE P, V2030
   Soille P, 2005, IMAGE VISION COMPUT, V23, P249, DOI 10.1016/j.imavis.2004.06.002
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   VINCENT L, 1989, SIGNAL PROCESS, V16, P365, DOI 10.1016/0165-1684(89)90031-5
   Vogt P, 2007, LANDSCAPE ECOL, V22, P171, DOI 10.1007/s10980-006-9013-2
   [No title captured]
NR 45
TC 2
Z9 2
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2008
VL 19
IS 6
BP 392
EP 408
DI 10.1016/j.jvcir.2008.04.002
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 343KS
UT WOS:000258853100005
DA 2024-07-18
ER

PT J
AU Kuang, JT
   Johnson, GM
   Fairchild, MD
AF Kuang, Jiangtao
   Johnson, Garrett M.
   Fairchild, Mark D.
TI iCAM06: A refined image appearance model for HDR image rendering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image appearance; HDR imaging-; tone mapping; rendering; vision
   modeling; tone-mapping operator testing
AB A new image appearance model, designated iCAM06, was developed for High-Dynamic-Range (HDR) image rendering. The model, based on the iCAM framework, incorporates the spatial processing models in the human visual system for contrast enhancement, photoreceptor light adaptation functions that enhance local details in highlights and shadows, and functions that predict a wide range of color appearance phenomena. Evaluation of the model proved iCAM06 to have consistently good HDR rendering performance in both preference and accuracy making iCAM06 a good candidate for a general-purpose tone-mapping operator with further potential applications to a wide-range of image appearance research and practice. (C) 2007 Elsevier Inc. All rights reserved.
C1 Rochester Inst Technol, Munsel Color Sci Lab, Rochester, NY 14623 USA.
C3 Rochester Institute of Technology
RP Kuang, JT (corresponding author), Rochester Inst Technol, Munsel Color Sci Lab, 54 Lomb Mem Dr, Rochester, NY 14623 USA.
EM jxk403l@cis.rit.edu
CR [Anonymous], 1999, 6196621 IEC
   [Anonymous], 2002, PROC ACM T GRAPH SIG, DOI DOI 10.1145/566570.566574
   Ebner F., 1998, IS T SID 6 COL IM C, P9
   Fairchild M.D., 2002, ISTSID 10 COLOR IMAG, P33
   Fairchild MD, 2004, J ELECTRON IMAGING, V13, P126, DOI 10.1117/1.1635368
   Fairchild MD, 2003, PROC SPIE, V5007, P149, DOI 10.1117/12.477370
   Hunt R.W. G., 1995, REPROD COLOUR, VSixth
   HUNT RWG, 2003, COLOR RES APPL, P79
   Johnson GM, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P36
   KUANG J, 2006, P 3 S APPL PERC GRAP
   KUANG J, 2007, IS T SID 15 COL IM C
   KUANG J, 2006, THESIS ROCHESTER I T
   Kuang JT, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265958
   Larson GW, 1997, IEEE T VIS COMPUT GR, V3, P291, DOI 10.1109/2945.646233
   MICHAELIS L, 1913, KINETIK INVERTINWIRK, P49
   Moroney N., 2002, COL IM C SOC IM SCI, P23
   Pattanaik S.N., 1998, P SIGGRAPH 98, P287
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   VALETON JM, 1983, VISION RES, V23, P1539, DOI 10.1016/0042-6989(83)90167-0
   Yamaguchi H, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P22
   Zhang X.M., 1996, Society of Information Display Symposium Technical Digest, V27, P731
NR 21
TC 262
Z9 318
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2007
VL 18
IS 5
BP 406
EP 414
DI 10.1016/j.jvcir.2007.06.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 220UY
UT WOS:000250184000007
DA 2024-07-18
ER

PT J
AU Celik, T
   Demirel, H
   Ozkaramanli, H
   Uyguroglu, M
AF Celik, Turgay
   Demirel, Hasan
   Ozkaramanli, Huseyin
   Uyguroglu, Mustafa
TI Fire detection using statistical color model in video sequences
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE fire detection; background subtraction; change detection; moving object
   detection; statistical color model
AB In this paper, we propose a real-time fire-detector that combines foreground object information with color pixel statistics of fire. Simple adaptive background model of the scene is generated by using three Gaussian distributions where each distribution corresponds to the pixel statistics in the respective color channel. The foreground information is extracted by using adaptive background subtraction algorithm., and then verified by the statistical fire color model to determine whether the detected foreground object is a fire candidate or not. A generic fire color model is constructed by statistical analysis of the sample images containing fire pixels. The first contribution of the paper is the application of real-time adaptive background subtraction method that aids the segmentation of the fire candidate pixels from the background. The second contribution is the use of a generic statistical model for refined fire-pixel classification. The two processes are combined to form the fire detection system and applied for the detection of fire in the consecutive frames of video sequences. The frame-processing rate of the detector is about 40 fps with image size of 176 x 144 pixels, and the algorithm's correct detection rate is 98.89%. (C) 2006 Elsevier Inc. All rights reserved.
C1 Eastern Mediterranean Univ, Adv Technol Res & Dev Inst, Gazimagusa TRNC, Mersin 10, Turkey.
C3 Eastern Mediterranean University
RP Celik, T (corresponding author), Eastern Mediterranean Univ, Adv Technol Res & Dev Inst, Gazimagusa TRNC, Mersin 10, Turkey.
EM turgay.celik@emu.edu.tr
RI Celik, Turgay/Q-9713-2018; Uyguroglu, Mustafa Kemal/ABF-9086-2020;
   Demirel, Hasan/H-5769-2013
OI Celik, Turgay/0000-0001-6925-6010; Uyguroglu, Mustafa
   Kemal/0000-0002-3489-6293; 
CR Çelik T, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P478, DOI 10.1109/SIU.2004.1338568
   Chen SH, 2003, IEEE SYS MAN CYBERN, P3775
   Cisbani E, 2002, INT GEOSCI REMOTE SE, P1506, DOI 10.1109/IGARSS.2002.1026163
   Cleary T., 1999, Survey of Fire Detection Technologies and System Evaluation/Certification Methodologies and Their Suitability for Aircraft Cargo Compartments
   Davis W., 1999, NASA FIRE DETECTION
   FOO SY, 1995, RULE BASED MACHINE B, V9, P531
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Healey G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P605, DOI 10.1109/CVPR.1993.341064
   MOUTINHO JN, 2003, IEEE C EM TECHN FACT, V12, P191
   Neily L. E., 1989, 12 CAN S REM SENS, V14, P2610
   Phillips W, 2002, PATTERN RECOGN LETT, V23, P319, DOI 10.1016/S0167-8655(01)00135-0
   PLUMB OA, 1996, DEV EC VIDEO BASED F
   Rafael CGonzalez Richard E Woods., 2002, DIGITAL IMAGE PROCES
   WREN C, 1997, IEEE T PATT AN MACH, V19
   Yamagishi H, 2000, IEEE IND ELEC, P824, DOI 10.1109/IECON.2000.972229
   YAMAGISHI H, 1999, P 1999 INT S MICR HU, P255
NR 16
TC 188
Z9 210
U1 3
U2 44
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 176
EP 185
DI 10.1016/j.jvcir.2006.12.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700008
DA 2024-07-18
ER

PT J
AU Zhang, DM
   Lin, SX
   Zhang, YD
   Yu, LJ
AF Zhang, Dongming
   Lin, Shouxun
   Zhang, Yongdong
   Yu, Lejun
TI Complexity controllable DCT for real-time H.264 encoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; integer DCT; pruned DCT; SSAVT; complexity controllable DCT
ID ALGORITHM
AB A new integer 4 x 4 transform is adopted in the new video coding standard H.264/AVC. It consumes a big account of computation of a real-time encoder. To reduce the computation load of the new transform, pruned DCT algorithm is applied. To avoid serious encoding performance loss, a new condition is derived based on statistical sum of absolute value test(SSAVT) to identify pruned block adaptively. Considering the variance of DCT coefficients' contribution, a novel efficient model based on statistical analysis is proposed. To achieve further control on DCT complexity and a good tradeoff between performance and computation load, a scheme to control the complexity of DCT is presented. Simulation results show that the novel statistical model can save more computation, so it is chose to control DCT complexity. Simulation results show that the complexity controllable scheme can control the complexity of DCT within the specified target with negligible encoding performance loss. (c) 2006 Elsevier Inc. All rights reserved.
C1 Chinese Acad Sci, Comp Technol Inst, Network & Pervas Comp Res Dept, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Zhang, DM (corresponding author), Chinese Acad Sci, Comp Technol Inst, Network & Pervas Comp Res Dept, Beijing 100080, Peoples R China.
EM dmzhang@ict.ac.cn; sxlin@ict.ac.cn; zhyd@ict.ac.cn; jlyu@ict.ac.cn
OI Zhang, Dongming/0000-0002-1237-7177
CR CHEN WH, 1977, IEEE T COMMUN, V25, P1004, DOI 10.1109/TCOM.1977.1093941
   FEIG E, 1992, IEEE T SIGNAL PROCES, V40, P2174, DOI 10.1109/78.157218
   GORMISH MJ, 1994, THESIS STANFORD U CA
   HALLAPURO A, 2002, LOW COMPLEXITY TRANS
   Hentschel C, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P342, DOI 10.1109/ICIP.2001.958121
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Lengwehasatit K, 2004, IEEE T CIRC SYST VID, V14, P1236, DOI 10.1109/TCSVT.2004.835151
   LENGWEHASATIT K, 1998, ICIP98
   Moon YH, 2005, IEEE T CIRC SYST VID, V15, P1053, DOI 10.1109/TCSVT.2005.852411
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Richardson IEG, 2002, REAL-TIME IMAGING, V8, P291, DOI 10.1006/rtim.2001.0275
   Skodras A., 1995, IEEE T SIGNAL PROCES, V43, P197
   WANG ZD, 1991, IEEE T COMMUN, V39, P640, DOI 10.1109/26.87153
NR 13
TC 6
Z9 9
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2007
VL 18
IS 1
BP 59
EP 67
DI 10.1016/j.jvcir.2006.10.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 133QI
UT WOS:000244027100005
DA 2024-07-18
ER

PT J
AU Weng, SK
   Kuo, CM
   Tu, SK
AF Shiuh-Ku Weng
   Chung-Ming Kuo
   Shu-Kang Tu
TI Video object tracking using adaptive Kalman filter
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HSI color space; adaptive Kalman filter; occlusion ratio
ID SEGMENTATION
AB In this paper, a new video moving object tracking method is proposed. In initialization, a moving object selected by the user is segmented and the dominant color is extracted from the segmented target. In tracking step, a motion model is constructed to set the system model of adaptive Kalman filter firstly. Then, the dominant color of the moving object in HSI color space will be used as feature to detect the moving object in the consecutive video frames. The detected result is fed back as the measurement of adaptive Kalman filter and the estimate parameters of adaptive Kalman filter are adjusted by occlusion ratio adaptively. The proposed method has the robust ability to track the moving object in the consecutive frames under some kinds of real-world complex situations such as the moving object disappearing totally or partially due to occlusion by other ones, fast moving object, changing lighting, changing the direction and orientation of the moving object, and changing the velocity of moving object suddenly. The proposed method is an efficient video object tracking algorithm. (C) 2006 Elsevier Inc. All rights reserved.
C1 Chinese Naval Acad, Dept Informat Management, Kaohsiung 813, Taiwan.
   I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
C3 I Shou University
RP Weng, SK (corresponding author), Chinese Naval Acad, Dept Informat Management, Zuoying Dist, Kaohsiung 813, Taiwan.
EM skweng@mail.cna.edu.tw
CR Borshukov GD, 1997, IEEE T IMAGE PROCESS, V6, P1591, DOI 10.1109/83.641420
   Chien SY, 2002, IEEE T CIRC SYST VID, V12, P577, DOI 10.1109/TCSVT.2002.800516
   FABER V, 1994, LOS ALAMOS SCI, P138
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Jang DS, 2002, PATTERN RECOGN, V35, P2041, DOI 10.1016/S0031-3203(01)00201-1
   Jang DS, 2000, PATTERN RECOGN, V33, P1135, DOI 10.1016/S0031-3203(99)00100-4
   Jepson A.D., 2001, P COMP VIS PATT REC
   JOHNSON I, 1999, REAL-TIME IMAGING, P295
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kim Jong Bae, REAL TIME REGION BAS
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Mason M, 2001, 30TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P154, DOI 10.1109/AIPR.2001.991219
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45
   Park DK, 2000, IEEE T CONSUM ELECTR, V46, P785, DOI 10.1109/30.883448
   Paul GV, 2001, 30TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P137, DOI 10.1109/AIPR.2001.991216
   Piroddi R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P353
   Rehrmann V., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P704, DOI 10.1007/BFb0055699
   Senior A., 2002, P INT WORKSH PERF EV
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Siebel NilsT., 2002, Proc. European Conf. Computer Vision, P373
   Song Y, 2000, PROC CVPR IEEE, P810, DOI 10.1109/CVPR.2000.855904
   Tao H, 2000, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2000.854760
   Vermaak J, 2002, LECT NOTES COMPUT SC, V2350, P645
   Wang Y, 2000, 29TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P95, DOI 10.1109/AIPRW.2000.953609
   WELCH G, 2002, 95041 TR UNC CHAP HI
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
NR 28
TC 204
Z9 255
U1 3
U2 39
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2006
VL 17
IS 6
BP 1190
EP 1208
DI 10.1016/j.jvcir.2006.03.004
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 122SX
UT WOS:000243248200005
DA 2024-07-18
ER

PT J
AU Gabarda, S
   Cristóbal, G
AF Gabarda, Salvador
   Cristobal, Gabriel
TI An evolutionary blind image deconvolution algorithm through the
   pseudo-Wigner distribution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE evolutionary algorithms; Wigner distribution; image fusion; image
   enhancement; quality assessment
ID FREQUENCY SIGNAL ANALYSIS; TOOL
AB This paper describes a new blind deconvolution method implemented by means of an evolutionary algorithm (EA). The EA is designed following a multi-objective optimisation problem approach. The last generation of the EA is assessed by different quality metrics for determining the solution that provides the best performance. It is shown that different restored images can be obtained from a given testing image. The selection of the best result is accomplished though the use of quality metrics. However, the existence of many quality metrics entails a difficult problem for determining the best output. Here, we present a new robust quality metric, based on the use of the local space-frequency information extracted from the Wigner distribution. We empirically compared its performance with other well-known perceptual metrics. In addition to that, a fusion procedure between all candidate restored output images from the EA is also proposed as an alternative to the selection process. The fusion method is also based on the use of this new measure recently developed by the authors with excellent experimental results. (c) 2005 Elsevier Inc. All rights reserved.
C1 CSIC, Inst Opt Daza Valdes, E-28006 Madrid, Spain.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto
   de Optica (Daza de Valdes)
RP Cristóbal, G (corresponding author), CSIC, Inst Opt Daza Valdes, Serrano 121, E-28006 Madrid, Spain.
EM gabriel@optica.csic.es
RI Cristobal, Gabriel/B-7216-2012
OI Cristobal, Gabriel/0000-0001-6408-2269
CR Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   [Anonymous], 1975, ANAL BEHAV CLASS GEN
   BRENNER KH, 1983, P EURASIP SIGN PROC, V2, P307
   Bronstein MM, 2005, IEEE T IMAGE PROCESS, V14, P726, DOI 10.1109/TIP.2005.847322
   BRONSTEIN MM, QUASI MAXIMUM  LIKEL
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P372
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P217
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P276
   Gabarda S, 2005, OPT ENG, V44, DOI 10.1117/1.1881412
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Haralick R. M., 1992, COMPUTER ROBOT VISIO, V1
   Katsaggelos A., 1991, Digital image restoration
   KUNDUR D, 1996, IEEE SIGNAL P MAG
   PARETO V, 1996, COURS EC POLITIQUE, V1
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Walnut D., 2002, WAVELET ANAL
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749
   WILLIAMS WJ, 1991, P SOC PHOTO-OPT INS, V1566, P144, DOI 10.1117/12.49818
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
   ZITZLER E, 1909, THESIS SWISS FEDERAL
NR 21
TC 7
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1040
EP 1052
DI 10.1016/j.jvcir.2005.07.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700007
DA 2024-07-18
ER

PT J
AU García, JA
   Rodriguez-Sánchez, R
   Fdez-Valdivia, J
AF Garcia, J. A.
   Rodriguez-Sanchez, Rosa
   Fdez-Valdivia, J.
TI Emergence of region-based transmission when computation is unconstrained
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE progressive transmission; image size; region-based approach;
   prioritization protocol; transmission costs; long-run loss
AB Here, we study the emergence of a region-based approach when transmission costs, rather than computation constraints, limit the information upon which decisions are conditioned. We obtain that the average long-run loss of the transmission problem of size n is greater than that of the transmission problem of size Kn following a region-based approach, when computation is unconstrained. Hence a transmission problem of size Kin can achieve average costs lower than those of a transmission problem of size n by dividing the image into K quantizers of equal size n that imitate the prioritization protocol of an image of size n. In this case we have that additive and symmetric transmission costs, linearity and monotony of long-run loss, existence of cost-minimizing prioritization protocols, symmetric joint distribution of processes, not perfectly correlated processes, are among others some of the robust properties of constraints that drive the emergence of region-based transmission. (c) 2006 Elsevier Inc. All rights reserved.
C1 Univ Granada, ETS Ingn Informat, Dept Ciencias Computac & IA, E-18071 Granada, Spain.
C3 University of Granada; University of Sevilla
RP García, JA (corresponding author), Univ Granada, ETS Ingn Informat, Dept Ciencias Computac & IA, E-18071 Granada, Spain.
EM jags@decsai.ugr.es
RI Rodriguez Sanchez, Rosa Maria/B-1847-2012; Garcia, Jose A./C-1703-2010;
   Fdez-Valdivia, J/B-1844-2012
OI Rodriguez Sanchez, Rosa Maria/0000-0001-7886-9329; Garcia, Jose
   A./0000-0001-7742-7270; Fdez-Valdivia, J/0000-0001-7181-1554
CR Garcia JA, 2005, OPT ENG, V44, DOI [10.1117/1.2009687, 10.1117/1.1928268]
   García JA, 2004, OPT ENG, V43, P615, DOI 10.1117/1.1646176
   García JA, 2002, OPT ENG, V41, P2216, DOI 10.1117/1.1496789
   García JA, 2001, IEEE T PATTERN ANAL, V23, P362, DOI 10.1109/34.917572
   GARCIA JA, 2004, PROGRESSIVE IMAGE TR, V140, P230
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Van Zandt T, 2001, ECON THEOR, V17, P545, DOI 10.1007/PL00004119
   VANZANDT T, 1999, REAL TIME DECENTRALI
NR 8
TC 1
Z9 1
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2006
VL 17
IS 5
BP 1024
EP 1039
DI 10.1016/j.jvcir.2006.04.001
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 201SU
UT WOS:000248853700006
DA 2024-07-18
ER

PT J
AU Huang, SY
AF Huang, Shih-Yu
TI Adaptive computation-aware scheme for software-based predictive block
   motion estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE predictive block motion estimation; computation-distortion optimization;
   video coding
ID SEARCH ALGORITHM
AB The progress in computer processing power makes the use of a software codec (encoder and decoder) a feasible solution in many real-time video applications. The efficient distribution of available processing power to frames and blocks by a software codec resulting in higher output quality comprises two phases: (1) frame-level computation distribution and (2) block-level computation allocation. Predictive block motion estimation algorithms are widely employed in current video coding standards to remove the temporal redundancy, but they do not have the ability to distribute available processing power. To overcome this problem, this paper proposes an efficient frame-level computation distribution scheme based on a sliding window approach and an adaptive block-level scheme which adaptively switches between a predictive computation distortion benefit list heuristic and a buffer control like procedure. Experimental results demonstrate that the output quality of software-based predictive block motion estimation algorithms can be uniformly improved by the proposed schemes. (C) 2005 Elsevier Inc. All rights reserved.
C1 Ming Chuan Univ, Dept Comp Sci & Informat Engn, Tao Yuan 333, Taiwan.
C3 Ming Chuan University
RP Huang, SY (corresponding author), Ming Chuan Univ, Dept Comp Sci & Informat Engn, 5 Teh Ming Rd, Tao Yuan 333, Taiwan.
EM syhuang@mcu.edu.tw
CR Andersson A, 1998, J COMPUT SYST SCI, V57, P74, DOI 10.1006/jcss.1998.1580
   [Anonymous], 144962 ISOIEC
   Braspenning R, 2002, PROC SPIE, V4671, P442, DOI 10.1117/12.453085
   *ISO IEC, 2001, JTCISC29WG11 ISOIEC
   KOGA T, 1981, P P NTC81 NEW ORL LA
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   LIN P, 2003, IEEE T CIRCUITS SYST, V35, P901
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   ZHAO Y, P IEEE DCC 2002 SNOW
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 11
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 767
EP 782
DI 10.1016/j.jvcir.2005.07.002
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500006
DA 2024-07-18
ER

PT J
AU Kang, LW
   Leou, JJ
AF Kang, Li-Wei
   Leou, Jin-Jang
TI An error resilient coding scheme for JPEG image transmission based on
   data embedding and side-match vector quantization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error resilient coding; JPEG image; transmission error; data embedding;
   side-match vector quantization
ID CONCEALMENT; ALGORITHM; PROTECTION
AB For an entropy-coded Joint Photographic Experts Group (JPEG) image, a transmission error in a codeword will not only affect the underlying codeword but also may affect subsequent codewords, resulting in a great degradation of the received image. In this study, an error resilient coding scheme for JPEG image transmission based on data embedding and side-match vector quantization (VQ) is proposed. To cope with the synchronization problem, the restart capability of JPEG images is enabled. The objective of the proposed scheme is to recover high-quality JPEG images from the corresponding corrupted images. At the encoder, the important data (the codebook index) for each Y (U or V) block in a JPEG image are extracted and embedded into another "masking" Y (U or V) block in the image by the odd-even data embedding scheme. At the decoder, after all the corrupted blocks within a JPEG image are detected and located, if the codebook index for a corrupted block can be correctly extracted from the corresponding "masking" block, the extracted codebook index will be used to conceal the corrupted block; otherwise, the side-match VQ technique is employed to conceal the corrupted block. Based on the simulation results obtained in this study, the performance of the proposed scheme is better than those of the five existing approaches for comparison. The proposed scheme can recover high-quality JPEG images from the corresponding corrupted images up to a block loss rate (BLR) of 30%. (C) 2005 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
   Acad Sinica, Inst Informat Sci, Taipei 115, Taiwan.
C3 National Chung Cheng University; Academia Sinica - Taiwan
RP Leou, JJ (corresponding author), Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
EM jjleou@cs.ccu.edu.tw
CR Baek S, 1997, IEEE SIGNAL PROC LET, V4, P325, DOI 10.1109/97.650035
   Gallant M, 2001, IEEE T CIRC SYST VID, V11, P357, DOI 10.1109/76.911161
   Kang LW, 2005, J VIS COMMUN IMAGE R, V16, P288, DOI 10.1016/j.jvcir.2004.11.004
   Kang LW, 2005, J VIS COMMUN IMAGE R, V16, P93, DOI 10.1016/j.jvcir.2004.04.003
   Kang LW, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P461
   Lee YC, 2002, IEEE T IMAGE PROCESS, V11, P1314, DOI 10.1109/TIR2002.804275
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Lin CY, 2001, P SOC PHOTO-OPT INS, V4518, P267, DOI 10.1117/12.448212
   Lin SW, 2004, J VIS COMMUN IMAGE R, V15, P214, DOI 10.1016/j.jvcir.2003.10.002
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lu CS, 2002, PROCEEDINGS OF THE 2002 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P316
   Meisinger K, 2004, IEEE IMAGE PROC, P813
   NATALE FGB, 2000, IEEE J SEL AREA COMM, V18, P1111
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Redmill DW, 1996, IEEE T IMAGE PROCESS, V5, P565, DOI 10.1109/83.491333
   SONG J, 2001, IEEE T MULTIMEDIA, V3, P415
   Stockhammer T, 2002, IEEE T CIRC SYST VID, V12, P465, DOI [10.1109/TCSVT.2002.800317, 10.1109/TCSVT.2002.806317]
   Tsai JC, 2000, IEEE T IMAGE PROCESS, V9, P1825, DOI 10.1109/83.877206
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   Wang Y., 2002, VIDEO PROCESSING COM
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wang Z, 1998, IEEE T IMAGE PROCESS, V7, P1056, DOI 10.1109/83.701166
   Wei HC, 2000, IEEE T CIRC SYST VID, V10, P51, DOI 10.1109/76.825858
   Yin P, 2001, INT CONF ACOUST SPEE, P1453, DOI 10.1109/ICASSP.2001.941204
   Yu HH, 2000, GLOB TELECOMM CONF, P1344, DOI 10.1109/GLOCOM.2000.891850
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P713, DOI 10.1109/76.728413
NR 29
TC 6
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 876
EP 891
DI 10.1016/j.jvcir.2005.08.003
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JZ
UT WOS:000242027500012
DA 2024-07-18
ER

PT J
AU Kang, DW
   Kim, KD
   Jung, KH
   Lee, SJ
AF Kang, Dong Wook
   Kim, Ki-Doo
   Jung, Kyeong Hoon
   Lee, Seung Jun
TI Forced <i>intra</i> refreshment method based on the propagation model of
   uncertainties in the reference pixels for H.264 streaming service
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE intra refreshment; H.264 encoding; propagation model for the uncertainty
   in the reference pixels
AB In this paper, we propose a novel propagation model for the uncertainty in the reference pixels and the model-based improved intra-refreshment method for the H.264 streaming service through the error-prone channel. The proposed intra-refreshment algorithm can incorporate with the SAD-based low-complexity mode decision as well as the RD-optimizing high-complexity mode decision. Simulations on RTP/IP transmission over mobile channels with the 42.7 and 85.3 kbps encoding of QCIF 30 frames/s sequences show that the proposed intra-refreshment scheme improves the average quality of decoded pictures by 1.36-0.47 dB compared with the conventional periodic GOB refreshment algorithms. (C) 2005 Elsevier Inc. All rights reserved.
C1 Kookmin Univ, Seoul, South Korea.
C3 Kookmin University
RP Kang, DW (corresponding author), Kookmin Univ, Seoul, South Korea.
EM dwkang@kookmin.ac.kr
CR BJONTEGAARD G, 2001, H 26L TEST MODEL LON
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P61, DOI 10.1109/79.855913
   WENGER S, 1999, H 263 TEST MODEL NUM
   ZHONGHUA M, 2002, ELECTRON LETT, V38, P1153
NR 4
TC 0
Z9 0
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 623
EP 629
DI 10.1016/j.jvcir.2005.08.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300008
DA 2024-07-18
ER

PT J
AU Li, ZG
   Gao, W
   Pan, F
   Ma, SW
   Lim, KP
   Feng, GN
   Lin, X
   Rahardja, S
   Lu, HQ
   Lu, Y
AF Li, Z. G.
   Gao, W.
   Pan, F.
   Ma, S. W.
   Lim, K. P.
   Feng, G. N.
   Lin, X.
   Rahardja, S.
   Lu, H. Q.
   Lu, Y.
TI Adaptive rate control for H.264
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264; rate control; adaptive; basic unit
AB This paper presents a rate control scheme for H.264 by introducing the concept of basic unit and. a linear prediction model. The basic unit can be a macroblock (MB), a slice, or a frame. The linear model is used to predict the mean absolute differences (MADs) of the remaining basic units in the current stored picture by those of the co-located basic units in the previous stored picture. The target bits for the current stored picture are computed by adopting a fluid flow traffic model and linear tracking theory, and are further bounded by two values that'are derived by taking the hypothetical reference decoder (HRD) into consideration. The remaining bits are allocated to the remaining basic units in the current stored picture according to their predicted MADs. The corresponding quantization parameter is computed by using a quadratic rate-distortion model. The rate distortion optimization (RDO) is then performed for all MBs in the current basic unit by the quantization parameter. Both constarit bit rate and variable bit rate cases are studied. The average PSNR is improved by up to 0.8 dB for an encoder using our scheme compared to an encoder using a fixed quantization parameter. With our scheme, an H.264 encoder can be adaptive to time varying channel bandwidth that is available for the coding process. (c) 2005 Elsevier Inc. All rights reserved.
C1 Inst Infocomm Res, Media Div, Singapore 119613, Singapore.
   Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Chinese Academy of Sciences; Institute of
   Computing Technology, CAS
RP Li, ZG (corresponding author), Inst Infocomm Res, Media Div, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM ezgli@i2r.a-star.edu.sg
CR Chen C.-T., 1998, Linear System Theory and Design
   *ISO IEC, 1449610 ISOIEC FDIS
   Jiang MQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 3, PROCEEDINGS, P813
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Li Z., 2005, Switched and Impulsive Systems
   LI Z, 2004, IEEE INT C MULT EXP, P27
   Li ZG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P581
   Li ZG, 2003, IEEE T CIRC SYST VID, V13, P472, DOI 10.1109/TCSVT.2003.813420
   Li ZG, 2002, INT CONF ACOUST SPEE, P2065
   LI ZG, 2003, 8 M GEN, P23
   LI ZG, 2004, IEEE 2004 INT C IM P
   LI Zhengguo, 2003, 7 M PATT THAIL, P7
   *MPEG 2 TEST MOD 5, 1993, WG1193400 ISOIEC JTC
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   SULLIVAN G, 2001, VCEG N81 14 M SANT B, P24
   Vetro A, 1999, IEEE T CIRC SYST VID, V9, P186, DOI 10.1109/76.744285
   Wiegand T., 2001, P IEEE INT C IM PROC
NR 17
TC 57
Z9 67
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2006
VL 17
IS 2
BP 376
EP 406
DI 10.1016/j.jvcir.2005.04.004
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JU
UT WOS:000242027000011
DA 2024-07-18
ER

PT J
AU Lee, AJT
   Chiu, HP
   Yu, P
AF Lee, Anthony J. T.
   Chiu, Han-Pang
   Yu, Ping
TI Similarity retrieval of videos by using 3D C-string knowledge
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video databases; spatio-temporal inference; similarity retrieval; 3D
   C-string
ID IMAGE DATABASE-SYSTEMS; SYMBOLIC PICTURES; MATRIX STRATEGY;
   MOVING-OBJECTS; SEGMENTATION
AB We have proposed a new spatio-temporal knowledge structure called 3D C-string to represent symbolic videos accompanying with the string generation and video reconstruction algorithms. In this paper, we extend the idea behind the similarity retrieval of images in 2D C-string to 3D C-string. Our extended approach consists of two phases. First, we infer the spatial relation sequence and temporal relations for each pair of objects in a video. Second, we use the inferred relations to define various types of similarity measures and propose the similarity retrieval algorithm. By providing various types of similarity between videos, our proposed similarity retrieval algorithm has discrimination power about different criteria. Finally, some experiments are performed to show the efficiency of the proposed approach. (c) 2004 Elsevier Inc. All rights reserved.
C1 Natl Taiwan Univ, Dept Informat Management, Taipei 106, Taiwan.
C3 National Taiwan University
RP Lee, AJT (corresponding author), Natl Taiwan Univ, Dept Informat Management, 1,Sect 4,Roosevelt Rd, Taipei 106, Taiwan.
EM jtlee@ntu.edu.tw
RI Lee, Anthony/B-5289-2009; Yu, Ping/B-1205-2008
OI Yu, Ping/0000-0002-7910-9396; Lee, Anthony/0000-0003-0320-7309
CR [Anonymous], P INT C MULT COMP SY
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   Chan YK, 2001, J VIS COMMUN IMAGE R, V12, P107, DOI 10.1006/jvci.2000.0460
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   CHANG SK, 1987, IEEE T PATTERN ANAL, V9, P413, DOI 10.1109/TPAMI.1987.4767923
   Chang YI, 2000, PATTERN RECOGN, V33, P1263, DOI 10.1016/S0031-3203(99)00115-6
   Chang YI, 2003, PATTERN RECOGN LETT, V24, P537, DOI 10.1016/S0167-8655(02)00275-1
   Chang YI, 2001, PATTERN RECOGN LETT, V22, P657, DOI 10.1016/S0167-8655(01)00009-5
   CHU WW, 1995, INFORM SYST, V20, P75, DOI 10.1016/0306-4379(95)98556-S
   Dimitrova N., 1994, Proceedings ACM Multimedia '94, P219, DOI 10.1145/192593.192659
   Doulamis AD, 2000, SIGNAL PROCESS, V80, P1049, DOI 10.1016/S0165-1684(00)00019-0
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   Guimaraes SJF, 2003, PATTERN RECOGN LETT, V24, P947, DOI 10.1016/S0167-8655(02)00218-0
   Güting RH, 2000, ACM T DATABASE SYST, V25, P1, DOI 10.1145/352958.352963
   Hsu FJ, 1998, J VISUAL LANG COMPUT, V9, P375, DOI 10.1006/jvlc.1998.0089
   HUANG PW, 1994, PATTERN RECOGN, V27, P1249, DOI 10.1016/0031-3203(94)90008-6
   JUNGERT E, 1988, LECT NOTES COMPUT SC, V301, P343
   Kokkoras F, 2002, MULTIMEDIA SYST, V8, P328, DOI 10.1007/s005300200054
   Lee AJT, 2003, PATTERN RECOGN LETT, V24, P3015, DOI 10.1016/S0167-8655(03)00162-4
   Lee AJT, 2002, PATTERN RECOGN, V35, P2521, DOI 10.1016/S0031-3203(01)00224-2
   LEE SY, 1992, PATTERN RECOGN, V25, P305, DOI 10.1016/0031-3203(92)90112-V
   LEE SY, 1990, PATTERN RECOGN, V23, P1077, DOI 10.1016/0031-3203(90)90004-5
   LEE SY, 1993, P SOC PHOTO-OPT INS, V1908, P25, DOI 10.1117/12.143653
   Lei ZB, 2000, J VIS COMMUN IMAGE R, V11, P41, DOI 10.1006/jvci.1999.0418
   Li JZ, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P336, DOI 10.1109/MMCS.1997.609625
   Liu CC, 2002, IEEE T KNOWL DATA EN, V14, P106, DOI 10.1109/69.979976
   Liu Y, 2003, COMPUT VIS IMAGE UND, V92, P147, DOI 10.1016/j.cviu.2003.06.003
   Lo CC, 2004, COMPUT STAND INTER, V26, P317, DOI 10.1016/j.csi.2003.11.004
   Nabil M, 2001, MULTIMED TOOLS APPL, V13, P35, DOI 10.1023/A:1009677223697
   Nagasaka A., 1992, VISUAL DATABASE SYST, pII
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   Ngo CW, 2003, IEEE T IMAGE PROCESS, V12, P341, DOI 10.1109/TIP.2003.809020
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Petraglia G, 2001, IEEE T KNOWL DATA EN, V13, P951, DOI 10.1109/69.971189
   Shearer K, 1996, J VIS COMMUN IMAGE R, V7, P325, DOI 10.1006/jvci.1996.0028
   SISTLA AP, 1997, P IEEE INT C DAT ENG, V1, P422
   SNOEK CG, 2004, IEEE T MULTIMEDIA, P1
   Yang Hui, 2003, P 11 ACM INT C MULT, P632, DOI DOI 10.1145/957013.957146
   ZHONG D, 1996, P STORAGE RETRIEVAL
NR 39
TC 5
Z9 5
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2005
VL 16
IS 6
BP 749
EP 773
DI 10.1016/j.jvcir.2004.11.006
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JQ
UT WOS:000242026600006
DA 2024-07-18
ER

PT J
AU Chan, YL
   Hui, KC
   Siu, WC
AF Chan, YL
   Hui, KC
   Siu, WC
TI Adaptive partial distortion search for block motion estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
ID PIXEL DECIMATION; PEANO SCAN; ALGORITHM
AB Block motion estimation using the exhaustive full search is computationally intensive. Fast search algorithms offered in the past tend to reduce the amount of computation by limiting the number of locations to be searched. All of these algorithms produce some quality degradation of the predicted image. To reduce the computational complexity of the full search algorithm without introducing any loss in the predicted image, we propose an adaptive partial distortion search algorithm (APDS) by selecting the most representative pixels with high activities, such as edges and texture which contribute most to the matching criterion. The APDS algorithm Groups the representative pixels based on the pixel activities in the Hilbert scan. By using the grouped information and computing the accumulated partial distortion of the representative pixels before that of the other pixels, impossible candidates can be rejected sooner and the remaining computation involved in the matching criterion can be reduced remarkably. Simulation results show that the proposed APDS algorithm has a significant computational speed-tip for all kinds of sequences and is the fastest when compared to the conventional partial distortion search algorithms. (C) 2003 Published by Elsevier Inc.
C1 Hong Kong Polytech Univ, Dept Elect & Informat Sci, Ctr Multimedia Signal Proc, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Hong Kong Polytech Univ, Dept Elect & Informat Sci, Ctr Multimedia Signal Proc, Kowloon, Hong Kong, Peoples R China.
EM enwcsiu@polyu.edu.hk
RI Chan, Yui-Lam/C-3799-2014
OI Chan, Yui-Lam/0000-0002-1473-094X
CR Andersson A, 1998, J COMPUT SYST SCI, V57, P74, DOI 10.1006/jcss.1998.1580
   [Anonymous], 1996, 138182 ISOIEC
   ANSARI A, 1992, IEEE T CONSUM ELECTR, V38, P436, DOI 10.1109/30.156720
   Chan YL, 1996, IEEE T CIRC SYST VID, V6, P113, DOI 10.1109/76.486426
   CHAN YL, 1995, ELECTRON LETT, V31, P1637, DOI 10.1049/el:19951116
   Chan YL, 1998, J VIS COMMUN IMAGE R, V9, P139, DOI 10.1006/jvci.1998.0388
   Chan YL, 1997, IEE P-VIS IMAGE SIGN, V144, P136, DOI 10.1049/ip-vis:19971199
   Cheung CK, 2000, IEEE T CIRC SYST VID, V10, P417, DOI 10.1109/76.836286
   ECKART S, 1995, P SOC PHOTO-OPT INS, V2419, P100, DOI 10.1117/12.206349
   GHARAVI H, 1990, IEEE T CIRCUITS SYST, V37, P649, DOI 10.1109/31.55010
   Hilbert David, 1891, MATH ANN, V38, P459, DOI [DOI 10.1007/BF01199431, 10.1007/bf01199431]
   *ISO IEC, 1993, 111722 ISOIEC
   *ISO IEC, 1997, 144962 ISOIEC CD
   *ITU T, 1995, H252 ITUT DIG VID CO
   *ITU T, 1996, H263 ITUT
   *ITU T, 1990, H261 ITUT
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   KAMATA S, 1997, IEICE T          FEB, P426
   KIRKPATRICK D, 1984, THEOR COMPUT SCI, V28, P263, DOI 10.1016/0304-3975(83)90023-3
   KOGA T, 1981, P NAT TEL C NOV 29 D
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   MUSMANN HG, 1985, P IEEE, V73, P523, DOI 10.1109/PROC.1985.13183
   PO LM, 1996, IEEE T CIRCUITS SYST, V6, P438
   SRINIVASAN R, 1985, IEEE T COMMUN, V33, P1011
   STEVENS RJ, 1983, IEEE T PATTERN ANAL, V5, P520, DOI 10.1109/TPAMI.1983.4767431
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   YANKANG, 2000, IEEE T CIRCUITS SYST, V10, P1006
NR 28
TC 12
Z9 13
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2004
VL 15
IS 4
BP 489
EP 506
DI 10.1016/S1047-3203(03)00046-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 868OZ
UT WOS:000224924200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yin, PY
AF Yin, PY
TI A discrete particle swarm algorithm for optimal polygonal approximation
   of digital curves
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE polygonal approximation; particle swarm optimization; genetic algorithm;
   local optimal solution; global optimal solution
ID PIECEWISE LINEAR-APPROXIMATION; OPTIMIZATION; CONVERGENCE
AB Polygonal approximation of digital curves is one of the crucial steps prior to many image analysis tasks. This paper presents a. new polygonal approximation approach based on the particle swarm optimization (PSO) algorithm. Each particle represented as a binary vector corresponds to a candidate solution to the polygonal approximation problem. A swarm of particles are initiated and fly through the solution space for targeting the optimal solution. We also propose to use a hybrid version of PSO embedding a local optimizer to enhance the performance. The experimental results manifest that the proposed discrete PSO is comparable to the genetic algorithm, and it outperforms another discrete implementation of PSO in the literature. The proposed hybrid version of PSO can significantly improve the approximation results in terms of the compression ratio, and the results obtained in different runs are more consistent. (C) 2003 Elsevier Inc. All rights reserved.
C1 Natl Chi Nan Univ, Dept Informat Management, Nantou 545, Taiwan.
C3 National Chi Nan University
RP Natl Chi Nan Univ, Dept Informat Management, Nantou 545, Taiwan.
EM pyyin@ncnu.edu.tw
CR ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   EBERHART CR, 1998, EVOLUTIONARY PROGRAM, V7
   Eberhart R.C., 1998, PROC 1998 INT C NEUR, pPL5
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   HELD A, 1994, IEEE T SYST MAN CYB, V24, P942, DOI 10.1109/21.293514
   HO YS, 2001, PATTERN RECOGN, V34, P2305
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9
   LEU JG, 1988, PATTERN RECOGN LETT, V7, P231, DOI 10.1016/0167-8655(88)90107-9
   Naka S, 2003, IEEE T POWER SYST, V18, P60, DOI 10.1109/TPWRS.2002.807051
   Parsopoulos K. E., 2002, Natural Computing, V1, P235, DOI 10.1023/A:1016568309421
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RAY BK, 1995, PATTERN RECOGN LETT, V16, P161, DOI 10.1016/0167-8655(94)00081-D
   RAY BK, 1993, PATTERN RECOGN, V26, P505, DOI 10.1016/0031-3203(93)90106-7
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Salman A, 2002, MICROPROCESS MICROSY, V26, P363, DOI 10.1016/S0141-9331(02)00053-4
   SATO Y, 1992, PATTERN RECOGN, V25, P1535, DOI 10.1016/0031-3203(92)90126-4
   SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X
   Tandon V., 2000, THESIS INDIANA U PUR
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   WU YW, 1993, CVGIP-GRAPH MODEL IM, V55, P79
   Yin PY, 1999, INT J PATTERN RECOGN, V13, P1061, DOI 10.1142/S0218001499000598
   Yin PY, 2003, PATTERN RECOGN, V36, P1783, DOI 10.1016/S0031-3203(02)00321-7
   YOSHIDA H, 1999, P INT C INT SYST APP, P117
   ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564
NR 31
TC 93
Z9 116
U1 1
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2004
VL 15
IS 2
BP 241
EP 260
DI 10.1016/j.jvcir.2003.12.001
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 817UG
UT WOS:000221201800008
DA 2024-07-18
ER

PT J
AU Xu, WT
   Wang, CX
   Zhang, Z
   Lin, GC
   Sun, Y
AF Xu, Wenting
   Wang, Chuanxu
   Zhang, Zhe
   Lin, Guocheng
   Sun, Yue
TI Intra-Inter Region Adaptive Graph Convolutional Networks for
   skeleton-based action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skeleton-based action recognition; Self-attention; Graph convolution
AB To effectively capture the spatio-temporal dependencies of the skeletal data, graph convolution has been widely applied. However, it tends to emphasize the dependence relationship between adjacent joints and does not consider long-distance dependence relationships among joints. Another problem is single-structure temporal convolution, which is difficult to extract global temporal features. To address the above issues, we propose Intra-Inter Region Adaptive Graph Convolutional Networks (IIR-AGCN), which models the long-distance relationships of skeleton sequences at temporal and spatial scales. Our contributions are three-fold: First, to enhance global topological learning capabilities of graph convolution, we propose a regional-coupled attention module, which divides joint features into multiple sub-regions, and then constructs coupled relationships between intra-inter regions by self-attention mechanism, which realizes global joint information interaction. Second, to address the issue of difficulty in extracting global temporal features, we propose a pyramid multi scale temporal module that extracts deep multi-scale temporal features and implements adaptive cross-scale feature fusion. Third, IIR-AGCN adopts a two-stream architecture, evaluating performances on two large-scale human skeleton datasets, NTU-RGB+D 60 and NTU-RGB+D 120, respectively.
C1 [Xu, Wenting; Wang, Chuanxu; Zhang, Zhe; Lin, Guocheng; Sun, Yue] Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Peoples R China.
C3 Qingdao University of Science & Technology
RP Wang, CX (corresponding author), Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Peoples R China.
EM wangchuanxu_qd@qust.edu.cn
CR Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Cheng K, 2021, IEEE T IMAGE PROCESS, V30, P7333, DOI 10.1109/TIP.2021.3104182
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan J., 2022, arXiv
   Ghorbani M, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102272
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Koniusz P, 2022, IEEE T PATTERN ANAL, V44, P648, DOI 10.1109/TPAMI.2021.3107160
   Lee J, 2023, IEEE I CONF COMP VIS, P10410, DOI 10.1109/ICCV51070.2023.00958
   Li C, 2018, Arxiv, DOI arXiv:1804.06055
   Li C, 2017, IEEE INT CONF MULTI
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Qin ZY, 2024, IEEE T NEUR NET LEAR, V35, P4783, DOI 10.1109/TNNLS.2022.3201518
   Shi L, 2020, Arxiv, DOI arXiv:2007.03263
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song YF, 2023, IEEE T PATTERN ANAL, V45, P1474, DOI 10.1109/TPAMI.2022.3157033
   Song YF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1625, DOI 10.1145/3394171.3413802
   Tang YY, 2019, Arxiv, DOI arXiv:1905.11799
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L, 2023, PROC CVPR IEEE, P5620, DOI 10.1109/CVPR52729.2023.00544
   Wang L, 2023, LECT NOTES COMPUT SC, V13844, P307, DOI 10.1007/978-3-031-26316-3_19
   Wang L, 2022, LECT NOTES COMPUT SC, V13681, P176, DOI 10.1007/978-3-031-19803-8_11
   Wang L, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4324, DOI 10.1145/3474085.3475572
   Wang L, 2019, IEEE I CONF COMP VIS, P8697, DOI 10.1109/ICCV.2019.00879
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang QT, 2021, Arxiv, DOI arXiv:2110.13385
   Xu KL, 2022, AAAI CONF ARTIF INTE, P2866
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Ye FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P55, DOI 10.1145/3394171.3413941
   Zhang H, 2023, LECT NOTES COMPUT SC, V13843, P541, DOI 10.1007/978-3-031-26313-2_33
   Zhang YH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3229, DOI 10.1145/3474085.3475473
   Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147
   Zhou HY, 2023, PROC CVPR IEEE, P10608, DOI 10.1109/CVPR52729.2023.01022
NR 38
TC 0
Z9 0
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104020
DI 10.1016/j.jvcir.2023.104020
EA DEC 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EK6Y0
UT WOS:001138871000001
OA Bronze
DA 2024-07-18
ER

PT J
AU Gao, XH
   Yu, AN
   Tan, J
   Gao, XZ
   Zeng, XP
   Wu, C
AF Gao, Xinghua
   Yu, Anning
   Tan, Jia
   Gao, Xingzhong
   Zeng, Xiaoping
   Wu, Chen
TI GSD-YOLOX: Lightweight and more accurate object detection models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vehicle detection; Lightweight; Detection accuracy; Detection speed;
   CCVTDB dataset
AB We present an enhanced YOLOX model for vehicle detection, addressing issues of slow detection speed, high parameter counts, and complex computations. Our model significantly improves inference speed while maintaining high detection accuracy. We introduce two lightweight modules, DG and DS, to reduce model size and enhance detection speed. The DG module eliminates redundant features during feature extraction, and the DS module optimizes the performance of DG, enhancing feature extraction efficiency. We utilize the CIoU loss function for accurate bounding box regression. Additionally, we introduce the Chinese Chongqing Vehicle Detection Benchmark (CCVTDB) dataset to address dataset limitations. Our lightweight model achieves an impressive 83.36% detection accuracy on CCVTDB at 65 FPS with 4.4 million parameters. Compared to the original model, our approach improves detection speed by 30% and reduces model size by 51%, while maintaining substantial detection performance.
C1 [Gao, Xinghua; Yu, Anning; Wu, Chen] Chongqing Univ Sci & Technol, Sch Intelligent Technol & Engn, Chongqing 401331, Peoples R China.
   [Tan, Jia] CISDI Informat Technol Chongqing Co Ltd, Chongqing 401329, Peoples R China.
   [Gao, Xingzhong] Chongqing Municipal Res Inst Design, Chongqing 400020, Peoples R China.
   [Zeng, Xiaoping] Sch Chongqing Univ, Coll Microelect & Commun Engn, Chongqing 400044, Peoples R China.
C3 Chongqing University of Science & Technology
RP Yu, AN (corresponding author), Chongqing Univ Sci & Technol, Sch Intelligent Technol & Engn, Chongqing 401331, Peoples R China.
EM anning865@cqust.edu.cn
FU Chongqing Municipal Undergraduate Universities and Chinese Academy of
   Sciences [HZ2021015]
FX We express our sincere gratitude to the Chongqing Municipal Design and
   Research Institute for providing us with the video data of road vehicles
   used in this study.This work was supported by the 2021 Cooperation
   Project between Chongqing Municipal Undergraduate Universities and
   Chinese Academy of Sciences under the project NO.HZ2021015.
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Cao JW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164646
   Chen C, 2021, IEEE T INTELL TRANSP, V22, P1840, DOI 10.1109/TITS.2020.3025687
   Chen L, 2020, IEEE T IND ELECTRON, V67, P10600, DOI [10.1109/TIE.2019.2962413, 10.1109/TITS.2020.3004655]
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong XD, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104914
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu C.-Y., 2017, arXiv
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jamiya SS, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165818
   Jeong J, 2017, Arxiv, DOI [arXiv:1705.09587, DOI 10.5244/C.31.76]
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Li C, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3238801
   Li JL, 2021, TRANSPORT RES C-EMER, V124, DOI 10.1016/j.trc.2020.102946
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tajar AT, 2021, J REAL-TIME IMAGE PR, V18, P2389, DOI 10.1007/s11554-021-01131-w
   Xiong C., 2022, Signal, Image Video Process, P1
   Xu Chaojun, 2020, 2020 2nd International Conference on Information Technology and Computer Application (ITCA), P433, DOI 10.1109/ITCA52113.2020.00097
   Yang YR, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3175213
   Yin DS, 2023, PROC CVPR IEEE, P20116, DOI 10.1109/CVPR52729.2023.01926
   Yue Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10183, DOI 10.1109/CVPR42600.2020.01020
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zheng W, 2021, PROC CVPR IEEE, P14489, DOI 10.1109/CVPR46437.2021.01426
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 42
TC 1
Z9 1
U1 6
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104009
DI 10.1016/j.jvcir.2023.104009
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EB0L3
UT WOS:001136326900001
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhang, SQ
   Li, YX
   Tan, L
   Yang, H
   Hou, GJ
AF Zhang, Siqi
   Li, Yuxuan
   Tan, Lu
   Yang, Huan
   Hou, Guojia
TI A no-reference underwater image quality evaluator via quality-aware
   features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image; No-reference image quality assessment; Quality-aware
   features; Gaussian process regression
ID ENHANCEMENT; MODEL; FRAMEWORK
AB In this paper, we propose a novel no-reference evaluator based on quality-aware features, called QA-UIQE, for underwater image quality assessment. QA-UIQE extracts and fuses a set of quality-aware features including naturalness, color, contrast, sharpness, and structure. Technically, we first present a new color-cast weighted colorfulness measurement as well as color consistency measurement to characterize color, and design a saliencyweighted contrast measurement to improve the distinguishing ability of measuring contrast. Also, the locally mean subtracted and contrast normalized, maximum local variation, and local entropy are incorporated to measure naturalness, sharpness and structure, respectively. Afterward, we integrate the feature vectors extracted from the training set into Gaussian process regression to predict the image quality. Moreover, we collect a realworld underwater image dataset for testing the generalization ability of our method. The experimental results illustrate that our QA-UIQE has a superior prediction accuracy and is highly consistent with human visual perception.
C1 [Zhang, Siqi; Li, Yuxuan; Yang, Huan; Hou, Guojia] Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
   [Tan, Lu] Univ Sydney, Fac Med & Hlth, Camperdown, NSW 2050, Australia.
C3 Qingdao University; University of Sydney
RP Hou, GJ (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao 266071, Peoples R China.
EM guojiahou@qdu.edu.cn
RI Wang, Jinlong/KHC-3829-2024; zhang, yingying/KGM-8162-2024; Li,
   Zexi/KFA-6939-2024
OI zhang, yingying/0000-0001-7479-3398; Hou, Guojia/0000-0001-6509-6259
FU National Natural Science Foundation of China [61901240, 62371431];
   Natural Science Foundation of Shandong Province, China [ZR2019BF042];
   China Postdoctoral Science Foundation [2017M612204]
FX Siqi Zhang and Yuxuan Li contributed equally to this work. This work was
   supported in part by the National Natural Science Foundation of China
   under Grant 61901240 and 62371431, in part by the Natural Science
   Foundation of Shandong Province, China, under Grant ZR2019BF042, in part
   by the China Postdoctoral Science Foundation under Grant 2017M612204.
CR Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Cheng JG, 2023, IEEE T CIRC SYST VID, V33, P6595, DOI 10.1109/TCSVT.2023.3264442
   Cong RM, 2023, IEEE T IMAGE PROCESS, V32, P4472, DOI 10.1109/TIP.2023.3286263
   De K, 2018, COGN COMPUT, V10, P980, DOI 10.1007/s12559-018-9562-0
   Hou GJ, 2024, IEEE T CIRC SYST VID, V34, P799, DOI 10.1109/TCSVT.2023.3290363
   Hu YX, 2022, APPL INTELL, V52, P11115, DOI 10.1007/s10489-021-03052-4
   Huang BX, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3103251
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang QP, 2022, IEEE T CIRC SYST VID, V32, P5959, DOI 10.1109/TCSVT.2022.3164918
   Jiang QP, 2022, IEEE T IMAGE PROCESS, V31, P2279, DOI 10.1109/TIP.2022.3154588
   Kang YZ, 2023, IEEE T CIRC SYST VID, V33, P988, DOI 10.1109/TCSVT.2022.3208100
   Kong YQ, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115779
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li XJ, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104759
   Li XJ, 2020, IEEE ACCESS, V8, P197448, DOI 10.1109/ACCESS.2020.3034275
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Matkovic K., 2015, Comput. Aesthet.
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narvekar ND, 2009, INT WORK QUAL MULTIM, P87, DOI 10.1109/QOMEX.2009.5246972
   Niu YZ, 2018, IEEE T CIRC SYST VID, V28, P849, DOI 10.1109/TCSVT.2016.2634590
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Qi Q, 2022, IEEE T IMAGE PROCESS, V31, P6816, DOI 10.1109/TIP.2022.3216208
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Si JW, 2022, IEEE T IMAGE PROCESS, V31, P3066, DOI 10.1109/TIP.2022.3164537
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Tang LJ, 2019, SIGNAL PROCESS-IMAGE, V79, P32, DOI 10.1016/j.image.2019.08.004
   Wang SQ, 2018, IEEE T CIRC SYST VID, V28, P1, DOI 10.1109/TCSVT.2016.2602764
   Wang Y, 2018, COMPUT ELECTR ENG, V70, P904, DOI 10.1016/j.compeleceng.2017.12.006
   Wu JJ, 2019, INFORM SCIENCES, V504, P487, DOI 10.1016/j.ins.2019.07.061
   Xie J, 2022, IEEE T CIRC SYST VID, V32, P3514, DOI 10.1109/TCSVT.2021.3115791
   Xie XW, 2019, SIGNAL PROCESS-IMAGE, V74, P218, DOI 10.1016/j.image.2019.02.006
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yang N, 2021, SIGNAL PROCESS-IMAGE, V94, DOI 10.1016/j.image.2021.116218
   Zhang DH, 2023, EXPERT SYST APPL, V231, DOI 10.1016/j.eswa.2023.120842
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang Y, 2017, SIGNAL PROCESS-IMAGE, V55, P130, DOI 10.1016/j.image.2017.03.020
   Zhou JC, 2023, IEEE J OCEANIC ENG, V48, P474, DOI 10.1109/JOE.2022.3223733
   Zhou JC, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3293912
   Zhou JC, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.105946
   Zhou JC, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.105952
   Zhou JC, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104785
   Zhou JC, 2022, APPL INTELL, V52, P16435, DOI 10.1007/s10489-022-03275-z
   Zhou ZH, 2020, NEURAL COMPUT APPL, V32, P12403, DOI 10.1007/s00521-019-04694-9
   Zhuang PX, 2022, IEEE T IMAGE PROCESS, V31, P5442, DOI 10.1109/TIP.2022.3196546
NR 55
TC 1
Z9 1
U1 6
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103979
DI 10.1016/j.jvcir.2023.103979
EA NOV 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z3CB9
UT WOS:001110875800001
DA 2024-07-18
ER

PT J
AU Zhang, J
   Sang, L
   Zhang, ZC
   Shao, MH
   Li, YS
AF Zhang, Jing
   Sang, Liu
   Zhang, Zhicheng
   Shao, Minhao
   Li, Yunsong
TI V-shaped neural network structure based on multi-scale features for
   image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Fixed-scale; Multi-scale; Sampling; V-shaped subnetwork
ID NONLOCAL ALGORITHM
AB Due to the good performance of deep learning, more and more image denoising methods incorporating deep learning are implemented, including fixed-scale-based methods and multi-scale-based methods. It is easy for fixed-scale-based neural networks to achieve a better denoising performance when their depth is increased, whereas feature extraction of multiple scales from images can be obtained using multi-scale-based neural networks. In this work, a multi-scale image denoising method has been proposed which is mainly based on fixed-scale but combines the method of obtaining feature information from shallow image sampling. We propose a diamond-shaped module and a V-shaped subnetwork for extracting the features of images obtained from shallow sampling and improve the up-sampling and down-sampling units to obtain a better sampling effect. Densely connecting images of same size in MSDN can solve the problem of gradient vanishing since increasing the depth of the network and shallow image sampling prevent the loss of image details due to excessive sampling. Experiments show that our method can efficiently retain the image details during image denoising, and this method is especially helpful for preserving minute image details as compared to the other state-of-the-art denoising algorithms.
C1 [Zhang, Jing; Sang, Liu; Zhang, Zhicheng; Shao, Minhao; Li, Yunsong] Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Zhang, J (corresponding author), Xidian Univ, Sch Telecommun Engn, State Key Lab Integrated Serv Networks, Xian 710071, Shaanxi, Peoples R China.
EM jingzhang@xidian.edu.cn
OI Zhang, Jing/0000-0002-8495-2804
FU National Natural Science Foundation of China [62371362]; General project
   of key R&D Plan of Shaanxi Province [2022GY-60]; Wuhu and Xidian
   University special fund for industry-university-research cooperation
   [XWYCXY-012021019]
FX This work was supported by National Natural Science Foundation of China
   under Grant 62371362, the General project of key R&D Plan of Shaanxi
   Province under Grant 2022GY-60 and Wuhu and Xidian University special
   fund for industry-university-research cooperation under grant
   XWYCXY-012021019.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   ALLMAN J, 1985, ANNU REV NEUROSCI, V8, P407, DOI 10.1146/annurev.ne.08.030185.002203
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger H.C., 2012, CoRR, P1211
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen M, 2018, J. Phys. Conf. Ser., V1087, P22
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dan Zhang, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1680, DOI 10.1109/CompComm.2018.8780788
   Deivalakshmi S., 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P363, DOI 10.1109/RAICS.2011.6069335
   Gan Y, 2015, I S BIOMED IMAGING, P667, DOI 10.1109/ISBI.2015.7163961
   Gonzalez, 2011, Digital Image Processing, P26
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Irsoy O, 2019, IEEE Trans. Neural Netw. Learn. Syst., P1
   Jain V., 2009, PROC ADV NEURAL INFO, P769
   Ji XC, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P626, DOI 10.1109/DSC.2016.104
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Liu X, 2019, INT GEOSCI REMOTE SE, P1951, DOI 10.1109/igarss.2019.8900642
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McClellan J. H., 1972, IEEE Transactions on Audio and Electroacoustics, VAU20, P66, DOI 10.1109/TAU.1972.1162342
   NARASIMHA MJ, 1978, IEEE T COMMUN, V26, P934, DOI 10.1109/TCOM.1978.1094144
   Pan JJ, 2007, INT C WAVEL ANAL PAT, P244
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santhanam V, 2017, PROC CVPR IEEE, P5395, DOI 10.1109/CVPR.2017.573
   Shan SS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTERS, COMMUNICATIONS, AND SYSTEMS (ICCCS), P154, DOI 10.1109/CCOMS.2015.7562892
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Wu J., 2019, J. Phys. Conf. Ser., P22
   Xie J., 2012, Adv. Neural Inf. Process. Syst., V1
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Xun Zhang, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P2120, DOI 10.1109/ICMA.2018.8484392
   Zhang J, 2020, IEEE GEOSCI REMOTE S, V17, P1363, DOI 10.1109/LGRS.2019.2943961
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 48
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103952
DI 10.1016/j.jvcir.2023.103952
EA OCT 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y3LD9
UT WOS:001104308600001
DA 2024-07-18
ER

PT J
AU Luo, SH
   Fang, GF
   Song, ML
AF Luo, Sihui
   Fang, Gongfan
   Song, Mingli
TI Deep semantic image compression via cooperative network pruning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep image compression; Network pruning; Semantic perception
AB Incorporating semantic analysis into image compression can significantly reduce the repetitive computation of fundamental semantic analysis in downstream applications such as semantic image retrieval. In this paper, we tackle the semantic image compression task, which embeds semantics in the compressed bitstream. An intuitive solution to this task is joint multi-task training, which generally results in the trade-off of one task to accommodate the other. We thus provide an alternative pilot solution: given a pair of pre-trained teacher networks that specialize in image compression and semantic inference respectively, we first fuse both models to acquire an ensemble model and then leverage cooperative network pruning and retraining to condense the knowledge. Various experiments on five benchmark datasets validate that the proposed method achieves on par and in many cases better performance than the teachers yet comes in a more compact size, and outperforms its multi-task learning and knowledge distillation counterparts.
C1 [Luo, Sihui] Ningbo Univ, Ningbo, Peoples R China.
   [Fang, Gongfan; Song, Mingli] Zhejiang Univ, Hangzhou, Peoples R China.
C3 Ningbo University; Zhejiang University
RP Luo, SH (corresponding author), Ningbo Univ, Ningbo, Peoples R China.
EM luosihui@nbu.edu.cn
RI zhang, zhang/KGK-5266-2024
OI Luo, Sihui/0000-0003-2822-0446
FU Natural Science Foundation Project of Zhejiang Province [LQ22F020020];
   Open Project Program of the State Key Lab of CADamp;CG, Zhejiang
   University [A2216]
FX This work is supported by the Natural Science Foundation Project of
   Zhejiang Province (LQ22F020020), and the Open Project Program of the
   State Key Lab of CAD & CG (Grant No. A2216), Zhejiang University.
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   [Anonymous], 1990, Adv Neural Inform Process Syst.
   Ayzik Sharon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P699, DOI 10.1007/978-3-030-58520-4_41
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Balle J., 2018, INT C LEARNING REPRE
   Balle J, 2017, 5 INT C LEARN REPR I
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Denton E, 2014, ADV NEUR IN, V27
   Fabrice B., 2014, BPG IMAGE FORMAT
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Gregor K, 2016, ADV NEUR IN, V29
   Guo J, 2017, PROC CVPR IEEE, P4867, DOI 10.1109/CVPR.2017.517
   Han S., 2015, ARXIV151000149
   Hassibi B., 1993, P ADV NEUR INF PROC, P164
   Hinton G., 2014, Distilling the knowledge in a neural network
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam K, 2021, IEEE COMPUT SOC CONF, P1875, DOI 10.1109/CVPRW53098.2021.00209
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Johnston N, 2018, PROC CVPR IEEE, P4385, DOI 10.1109/CVPR.2018.00461
   Kendall A., 2015, BRIT MACHINE VISION
   Khosla A., 2011, C COMP VIS PATT REC
   Kingma D, 2014, C LEARNING REPRESENT, P12
   Komodakis N, 2017, P ICLR
   Li M, 2021, IEEE T PATTERN ANAL, V43, P3446, DOI 10.1109/TPAMI.2020.2983926
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo SH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3087
   Pan G., 2022, EUROPEAN C COMPUTER
   Prakash A, 2017, IEEE DATA COMPR CONF, P250, DOI 10.1109/DCC.2017.56
   Raza SH, 2013, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2013.396
   Rippel O, 2017, PR MACH LEARN RES, V70
   Romero A., 2015, P INT C REPRESENTATI
   Shen CC, 2019, AAAI CONF ARTIF INTE, P3068
   Sihui Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P631, DOI 10.1007/978-3-030-58539-6_38
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2360, DOI 10.1109/ICCV48922.2021.00238
   Srinivas S., 2015, BRIT MACHINE VISION
   Theis L., 2017, ICLR
   Toderici G, 2017, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2017.577
   Tsubota K., 2023, IEEECVF WINTER C APP
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2021, PROC CVPR IEEE, P14908, DOI 10.1109/CVPR46437.2021.01467
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yang Y., 2020, INT C NEURAL INFORM
   Ye JW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4128
   Ye JW, 2019, PROC CVPR IEEE, P2824, DOI 10.1109/CVPR.2019.00294
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
NR 54
TC 1
Z9 1
U1 3
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103897
DI 10.1016/j.jvcir.2023.103897
EA JUL 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA P5VH7
UT WOS:001051346900001
DA 2024-07-18
ER

PT J
AU Hou, Y
   Luo, ZJ
   Deng, JM
   Gao, YZ
   Huang, KK
   Li, WG
AF Hou, Yueen
   Luo, Zhijian
   Deng, Jiaming
   Gao, Yanzeng
   Huang, Kekun
   Li, Weiguang
TI Attention meets involution in visual tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Involution; Attention
AB In visual tracking, both convolution and attention are widely employed for feature enhancement and fusion. However, convolution does not adequately model global dependencies of samples due to its operation on local neighbors, while attention gives too much attention to global dependencies and too little to local dependencies. It is intrinsically infeasible to combine both methods to integrate global and local information. However, a recently-proposed model called involution uses kernels differing in spatial extent but sharing across channels, making it possible to take advantage of both convolution and attention. We propose an attention-involution (Att-Inv) model that uses an attention mechanism to generate involution kernels to take both global and local dependencies of samples into account. To improve the performance of our tracker, we develop and implement strategies of backbone network modification, template updates, and regression of bounding box distributions. We evaluate our tracker using benchmarks such as GOT10k, LaSOT, TrackingNet and OxUvA. Experimental results show that it is competitive with state-of-the-art trackers.
C1 [Hou, Yueen; Huang, Kekun] Jiaying Univ, Guangdong Prov Key Lab Conservat & Precis Utilizat, Meizhou, Peoples R China.
   [Hou, Yueen; Luo, Zhijian; Gao, Yanzeng] Jiaying Univ, Comp Sch, Meizhou, Peoples R China.
   [Deng, Jiaming] Jiaying Univ, Informat Network Ctr, Meizhou, Peoples R China.
   [Li, Weiguang] South China Univ Technol, Sch Mech & Automot Engn, Guangzhou, Peoples R China.
C3 Jiaying University; Jiaying University; Jiaying University; South China
   University of Technology
RP Luo, ZJ (corresponding author), Jiaying Univ, Comp Sch, Meizhou, Peoples R China.
EM luozhijian@jyu.edu.cn
FU Natural Science Foundation of Guangdong, China [2018A030307064];
   National Natural Science Foundation of China [6197614]; Teaching Reform
   Project of Higher Education of Guangdong Province
FX This research was funded by the Natural Science Foundation of Guangdong,
   China grant number 2018A030307064, the National Natural Science
   Foundation of China grant number 6197614, and the 2019 Teaching Reform
   Project of Higher Education of Guangdong Province.
CR [Anonymous], 2017, ADV NEURAL INF PROCE
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chi C., 2020, P ADV NEUR INF PROC, P13564
   Cui YT, 2021, Arxiv, DOI arXiv:2104.00403
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Du F, 2020, PROC CVPR IEEE, P6835, DOI 10.1109/CVPR42600.2020.00687
   Fan H, 2021, INT J COMPUT VISION, V129, P439, DOI 10.1007/s11263-020-01387-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang LH, 2020, AAAI CONF ARTIF INTE, V34, P11037
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jaderberg M, 2014, Arxiv, DOI arXiv:1405.3866
   Kingma D. P., 2014, arXiv
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li D, 2021, PROC CVPR IEEE, P12316, DOI 10.1109/CVPR46437.2021.01214
   Li J, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103109
   Li X., 2020, NEURIPS, V33, P21002
   Li X, 2021, PROC CVPR IEEE, P11627, DOI 10.1109/CVPR46437.2021.01146
   Lin LT, 2022, Arxiv, DOI arXiv:2112.00995
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lüscher C, 2019, INTERSPEECH, P231, DOI 10.21437/Interspeech.2019-1780
   Meinhardt T, 2022, Arxiv, DOI arXiv:2101.02702
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Valmadre J, 2018, LECT NOTES COMPUT SC, V11207, P692, DOI 10.1007/978-3-030-01219-9_41
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yan B, 2021, PROC CVPR IEEE, P5285, DOI 10.1109/CVPR46437.2021.00525
   Yan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10428, DOI 10.1109/ICCV48922.2021.01028
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yang Z, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103465
   Zhang YH, 2021, INT J COMPUT VISION, V129, P2536, DOI 10.1007/s11263-021-01487-3
   Zhao HJ, 2023, IEEE T PATTERN ANAL, V45, P460, DOI 10.1109/TPAMI.2022.3153645
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 47
TC 2
Z9 2
U1 2
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103746
DI 10.1016/j.jvcir.2022.103746
EA JAN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8H9NW
UT WOS:000921357000001
DA 2024-07-18
ER

PT J
AU Nasseri, MH
   Babaee, M
   Moradi, H
   Hosseini, R
AF Nasseri, Mohammad Hossein
   Babaee, Mohammadreza
   Moradi, Hadi
   Hosseini, Reshad
TI Online relational tracking with camera motion suppression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multiple object tracking; Geometric interaction model; Camera motion
   suppression; Occlusion handling; Target re-identification; Cascade
   association
ID MULTIPLE TARGETS
AB To overcome challenges in multiple-object tracking (MOT) tasks, recent algorithms use interaction cues alongside motion and appearance features. These algorithms use graph neural networks or transformers to extract interaction features that lead to high computation costs. In this paper, a novel interaction cue based on geometric features is presented aiming to detect occlusion and reidentify lost targets with low computational costs. Moreover, in the majority of algorithms, camera motion is considered negligible, which is a strong assumption that is not always true and can lead to identity (ID) switching or mismatching of targets. In this paper, a method for measuring camera motion is presented that efficiently reduces its effect on tracking. The proposed algorithm is evaluated on MOT17 and MOT20 datasets and achieves state-of-the-art performance on MOT17 with comparable results on MOT20. The code is also publicly available.1
C1 [Nasseri, Mohammad Hossein; Moradi, Hadi; Hosseini, Reshad] Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
C3 University of Tehran
RP Moradi, H (corresponding author), Univ Tehran, Sch Elect & Comp Engn, Tehran, Iran.
EM mhnasseri@ut.ac.ir; reza.babaee@tum.de; moradih@ut.ac.ir;
   reshad.hosseini@ut.ac.ir
RI Hosseini, Reshad/AAD-8561-2021
OI Hosseini, Reshad/0000-0002-3669-760X; Nasseri, Mohammad
   Hossein/0000-0002-3946-1459; Moradi, Hadi/0000-0003-4916-9408
CR Babaee M, 2017, COMPUT VIS IMAGE UND, V154, P166, DOI 10.1016/j.cviu.2016.08.006
   Babaee M, 2016, LECT NOTES COMPUT SC, V9914, P692, DOI 10.1007/978-3-319-48881-3_49
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Brasó G, 2020, PROC CVPR IEEE, P6246, DOI 10.1109/CVPR42600.2020.00628
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao JK, 2023, Arxiv, DOI arXiv:2203.14360
   Cao Z., 2021, P IEEECVF INT C COMP, p15 457
   Chen JH, 2017, IEEE COMPUT SOC CONF, P2143, DOI 10.1109/CVPRW.2017.266
   Chu P, 2021, Arxiv, DOI arXiv:2104.00194
   Dehghan A, 2015, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2015.7298718
   Dendorfer P., 2020, arXiv
   Du YH, 2023, Arxiv, DOI [arXiv:2202.13514, 10.48550/ARXIV.2202.13514]
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Felzenszwalb P., 2008, 2008 IEEE C COMP VIS, DOI [10.1109/CVPR.2008.4587597, DOI 10.1109/CVPR.2008.4587597]
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Nasseri MH, 2021, Arxiv, DOI arXiv:2103.04147
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Liang C, 2022, IEEE T IMAGE PROCESS, V31, P3182, DOI 10.1109/TIP.2022.3165376
   Luiten J, 2021, INT J COMPUT VISION, V129, P548, DOI 10.1007/s11263-020-01375-2
   Meinhardt T, 2022, Arxiv, DOI arXiv:2101.02702
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Papakis I, 2020, arXiv
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shan CB, 2020, Arxiv, DOI arXiv:2010.09015
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang YX, 2021, IEEE INT CONF ROBOT, P13708, DOI 10.1109/ICRA48506.2021.9561110
   Weng XS, 2020, Arxiv, DOI arXiv:2006.07327
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xu YH, 2022, Arxiv, DOI arXiv:2103.15145
   Yang F, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104091
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Zeng F., 2021, arXiv
   Zhang Y., 2021, arXiv
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhichao Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14656, DOI 10.1109/CVPR42600.2020.01468
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P107, DOI 10.1007/978-3-030-58621-8_7
   Zhou XY, 2020, Arxiv, DOI arXiv:2004.01177
NR 49
TC 5
Z9 5
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103750
DI 10.1016/j.jvcir.2022.103750
EA JAN 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8L0TY
UT WOS:000923504400001
DA 2024-07-18
ER

PT J
AU Chen, S
   Lai, XY
   Yan, Y
   Wang, DH
   Zhu, SZ
AF Chen, Si
   Lai, Xinyu
   Yan, Yan
   Wang, Da-Han
   Zhu, Shunzhi
TI Learning an attention-aware parallel sharing network for facial
   attribute recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial attribute recognition; Multi-task learning; Attention mechanism;
   Parallel sharing network
ID NEURAL-NETWORK
AB Existing multi-task learning based facial attribute recognition (FAR) methods usually employ the serial sharing network, where the high-level global features are used for attribute prediction. However, the shared low-level features with valuable spatial information are not well exploited for multiple tasks. This paper proposes a novel Attention-aware Parallel Sharing network termed APS for effective FAR. To make full use of the shared low-level features, the task-specific sub-networks can adaptively extract important features from each block of the shared sub-network. Furthermore, an effective attention mechanism with multi-feature soft-alignment modules is employed to evaluate the compatibility of the local and global features from the different network levels for discriminating attributes. In addition, an adaptive Focal loss penalty scheme is developed to automatically assign weights to handle the problems of class imbalance and hard example mining for FAR. Experiments demonstrate that the proposed method achieves better performance than the state-of-the-art FAR methods.
C1 [Chen, Si; Lai, Xinyu; Wang, Da-Han; Zhu, Shunzhi] Xiamen Univ Technol, Sch Comp & Informat Engn, Fujian Key Lab Pattern Recognit & Image Understand, Xiamen 361024, Peoples R China.
   [Yan, Yan] Xiamen Univ, Sch Informat, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
C3 Xiamen University of Technology; Xiamen University
RP Chen, S (corresponding author), Xiamen Univ Technol, Sch Comp & Informat Engn, Fujian Key Lab Pattern Recognit & Image Understand, Xiamen 361024, Peoples R China.
EM chensi@xmut.edu.cn
OI Chen, Si/0000-0002-5631-7942
FU National Natural Science Foundation of China [62071404]; Natural Science
   Foundation of Fujian Province of China [2021J011185, 2020J01001]; Youth
   Innovation Foundation of Xiamen City of Fujian Province [3502Z20206068];
   Joint Funds of 5th Round of Health and Education Research Program of
   Fujian Province [2019-WJ-41]; Science and Technology Planning Project of
   Fujian Province [2020H0023]
FX This work was supported in part by the National Natural Science
   Foundation of China (No. 62071404) ; the Natural Science Foundation of
   Fujian Province of China (Nos. 2021J011185 and 2020J01001) ; the Youth
   Innovation Foundation of Xiamen City of Fujian Province (No.
   3502Z20206068) ; the Joint Funds of 5th Round of Health and Education
   Research Program of Fujian Province (No. 2019-WJ-41) ; and the Science
   and Technology Planning Project of Fujian Province (No. 2020H0023) .
CR Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Ben XY, 2022, IEEE T PATTERN ANAL, V44, P5826, DOI 10.1109/TPAMI.2021.3067464
   Bhattarai B, 2020, INT CONF ACOUST SPEE, P2308, DOI [10.1109/ICASSP40776.2020.9054252, 10.1109/icassp40776.2020.9054252]
   Cao JJ, 2018, PROC CVPR IEEE, P4290, DOI 10.1109/CVPR.2018.00451
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Caruana R., 1993, ICML, P41, DOI 10.1016/b978-1-55860-307-3.50012-5
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Ding H, 2018, AAAI CONF ARTIF INTE, P6789
   Fanhe XH, 2019, IEEE INT CONF INDUST, P877, DOI 10.1109/ICIT.2019.8755180
   Ge HK, 2020, LECT NOTES COMPUT SC, V11961, P253, DOI 10.1007/978-3-030-37731-1_21
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   Hand EM, 2017, AAAI CONF ARTIF INTE, P4068
   Hassanat ABA, 2022, INT J BIOMETRICS, V14, P453, DOI 10.1504/IJBM.2022.124683
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Kumar N, 2008, LECT NOTES COMPUT SC, V5305, P340, DOI 10.1007/978-3-540-88693-8_25
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lai X., 2020, INT C COMPUTING PATT, P2048
   Li JS, 2018, IEEE T IMAGE PROCESS, V27, P4651, DOI 10.1109/TIP.2018.2839521
   Li J, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103109
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mahbub U, 2020, IEEE T AFFECT COMPUT, V11, P601, DOI 10.1109/TAFFC.2018.2820048
   Mao LB, 2022, IEEE T AFFECT COMPUT, V13, P818, DOI 10.1109/TAFFC.2020.2969189
   Qi G.-J., 2009, P ACM INT C MULT, P243
   Qi GJ, 2012, IEEE T PATTERN ANAL, V34, P850, DOI 10.1109/TPAMI.2011.191
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Sharma AK, 2020, IEEE INT CONF AUTOMA, P329, DOI 10.1109/FG47880.2020.00085
   Shu Y, 2021, PROC CVPR IEEE, P11911, DOI 10.1109/CVPR46437.2021.01174
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun YC, 2018, J VIS COMMUN IMAGE R, V56, P83, DOI 10.1016/j.jvcir.2018.09.003
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang MH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2349, DOI 10.1145/3394486.3403284
   Wang SF, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107837
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang L, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106217
   Yang X, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103019
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zheng X., 2019, PATTERN RECOGN, V100
   Zhong Y, 2016, IEEE IMAGE PROC, P3239, DOI 10.1109/ICIP.2016.7532958
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhuang N, 2018, INT C PATT RECOG, P2069, DOI 10.1109/ICPR.2018.8545271
   Zhuang N, 2018, PATTERN RECOGN, V80, P225, DOI 10.1016/j.patcog.2018.03.018
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 50
TC 1
Z9 1
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103745
DI 10.1016/j.jvcir.2022.103745
EA JAN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5MQ8
UT WOS:000975985200001
DA 2024-07-18
ER

PT J
AU Papadopoulos, SI
   Koutlis, C
   Papadopoulos, S
   Kompatsiaris, I
AF Papadopoulos, Stefanos-Iordanis
   Koutlis, Christos
   Papadopoulos, Symeon
   Kompatsiaris, Ioannis
TI VICTOR: Visual incompatibility detection with transformers and
   fashion-specific contrastive pre-training
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Recommendation system; Outfit matching; Visual compatibility; Computer
   vision; Deep learning
AB For fashion outfits to be considered aesthetically pleasing, the garments that constitute them need to be compatible in terms of visual aspects, such as style, category and color. Previous works have defined visual compatibility as a binary classification task with items in a garment being considered as fully compatible or fully incompatible. However, this is not applicable to Outfit Maker applications where users create their own outfits and need to know which specific items may be incompatible with the rest of the outfit. To address this, we propose the Visual InCompatibility TransfORmer (VICTOR) that is optimized for two tasks: 1) overall compatibility as regression and 2) the detection of mismatching items and utilize fashion-specific contrastive language-image pre-training for fine tuning computer vision neural networks on fashion imagery. We build upon the Polyvore outfit benchmark to generate partially mismatching outfits, creating a new dataset termed Polyvore-MISFITs, that is used to train VICTOR. A series of ablation and comparative analyses show that the proposed architecture can compete and even surpass the current state-of-the-art on Polyvore datasets while reducing the instance-wise floating operations by 88%, striking a balance between high performance and efficiency. We release our code at https://github.com/stevejpapad/Visual-InCompatibility-Transformer
C1 [Papadopoulos, Stefanos-Iordanis; Koutlis, Christos; Papadopoulos, Symeon; Kompatsiaris, Ioannis] CERTH ITI, 6th Km Charilaou Thermi, GR-57001 Thessaloniki, Greece.
RP Papadopoulos, SI (corresponding author), CERTH ITI, 6th Km Charilaou Thermi, GR-57001 Thessaloniki, Greece.
EM stefpapad@iti.gr; ckoutlis@iti.gr; papadop@iti.gr; ikom@iti.gr
RI Papadopoulos, Stefanos-Iordanis/JDH-5285-2023; Koutlis,
   Christos/AAK-8028-2021; Kompatsiaris, Ioannis/P-8594-2015; Papadopoulos,
   Symeon/AET-0683-2022
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Papadopoulos,
   Stefanos-Iordanis/0000-0002-1424-2647; Koutlis,
   Christos/0000-0003-3682-408X
FU European Commission [951908]; H2020 - Industrial Leadership [951908]
   Funding Source: H2020 - Industrial Leadership
FX Funding This work is partially funded by the European Commission
   (Horizon 2020) ?eTryOn-virtual try-ons of garments enabling novel human
   fashion interactions?under grant agreement no. 951908.
CR Aggarwal D., 2018, GERM C PATT REC, P552, DOI [DOI 10.1007/978-3-030-12939-2_38, 10.1007/978-3-]
   Al-Halah Z, 2017, IEEE I CONF COMP VIS, P388, DOI 10.1109/ICCV.2017.50
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Cheng WH, 2021, ACM COMPUT SURV, V54, DOI [10.1145/3447239, 10.1145/3552468.3554360]
   Cucurull G, 2019, PROC CVPR IEEE, P12609, DOI 10.1109/CVPR.2019.01290
   Cui ZY, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P307, DOI 10.1145/3308558.3313444
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Han XT, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1078, DOI 10.1145/3123266.3123394
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwangbo H, 2018, ELECTRON COMMER R A, V28, P94, DOI 10.1016/j.elerap.2018.01.012
   Li KD, 2019, Arxiv, DOI arXiv:1906.07273
   Lin YL, 2020, PROC CVPR IEEE, P3308, DOI 10.1109/CVPR42600.2020.00337
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lorbert A., 2021, P IEEECVF C COMPUTER, P3931
   Mall U, 2019, IEEE I CONF COMP VIS, P411, DOI 10.1109/ICCV.2019.00050
   Papadopoulos Stefanos-Iordanis, 2022, Recommender Systems in Fashion and Retail: Proceedings of the Third Workshop at the Recommender Systems Conference (2021). Lecture Notes in Electrical Engineering (830), P95, DOI 10.1007/978-3-030-94016-4_7
   Papadopoulos S.I., 2022, arXiv
   Radford A, 2021, PR MACH LEARN RES, V139
   Sarkar R, 2022, IEEE COMPUT SOC CONF, P2262, DOI 10.1109/CVPRW56347.2022.00249
   Skenderi G, 2024, Arxiv, DOI arXiv:2109.09824
   Stefani M.A., 2019, 2019 10 INT C INFORM, P1
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tan RB, 2019, IEEE I CONF COMP VIS, P10372, DOI 10.1109/ICCV.2019.01047
   Taraviya M., 2021, P KDD 2021 INT WORKS, V1
   TOLSTIKHIN I., 2021, P 35 C NEUR INF PROC
   Tzeng GH, 2011, MULTIPLE ATTRIBUTE DECISION MAKING: METHODS AND APPLICATIONS, P1
   Vasileva MI, 2018, LECT NOTES COMPUT SC, V11220, P405, DOI 10.1007/978-3-030-01270-0_24
   Vaswani A, 2017, ADV NEUR IN, V30
   Veit A, 2015, IEEE I CONF COMP VIS, P4642, DOI 10.1109/ICCV.2015.527
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Zhan HJ, 2021, IEEE IMAGE PROC, P2663, DOI 10.1109/ICIP42928.2021.9506344
   Zhan HJ, 2022, IEEE T MULTIMEDIA, V24, P819, DOI 10.1109/TMM.2021.3059514
NR 32
TC 2
Z9 2
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103741
DI 10.1016/j.jvcir.2022.103741
EA JAN 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7Z7PI
UT WOS:000915746800001
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Liu, FQ
   Yang, XM
   De Baets, B
AF Liu, Feiqiang
   Yang, Xiaomin
   De Baets, Bernard
TI A deep recursive multi-scale feature fusion network for image
   super-resolution?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single Image Super-Resolution (SISR); Recursive networks; Multi-scale
   features; Progressive feature fusion
ID INTERPOLATION
AB Recently, Convolutional Neural Networks (CNNs) have achieved great success in Single Image Super-Resolution (SISR). In particular, the recursive networks are now widely used. However, existing recursion-based SISR networks can only make use of multi-scale features in a layer-wise manner. In this paper, a Deep Recursive Multi-Scale Feature Fusion Network (DRMSFFN) is proposed to address this issue. Specifically, we propose a Recursive Multi-Scale Feature Fusion Block (RMSFFB) to make full use of multi-scale features. Besides, a Progressive Feature Fusion (PFF) technique is proposed to take advantage of the hierarchical features from the RMSFFB in a global manner. At the reconstruction stage, we use a deconvolutional layer to upscale the feature maps to the desired size. Extensive experimental results on benchmark datasets demonstrate the superiority of the proposed DRMSFFN in comparison with the state-of-the-art methods in both quantitative and qualitative evaluations.
C1 [Liu, Feiqiang; Yang, Xiaomin] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Peoples R China.
   [Liu, Feiqiang; De Baets, Bernard] Univ Ghent, Dept Data Anal & Math Modelling, KERMIT, Coupure Links 653, B-9000 Ghent, Belgium.
C3 Sichuan University; Ghent University
RP Yang, XM (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610065, Peoples R China.
EM arielyang@scu.edu.cn
RI De Baets, Bernard/E-8877-2010
FU China Scholarship Council (CSC); Science Foundation of Sichuan Science
   and Technology Department; Sichuan University; Flemish Government; 
   [2021YFH0119];  [2020SCUNG205]
FX Acknowledgements Feiqiang Liu is supported by the China Scholarship
   Council (CSC) . This research work is partially supported by the Science
   Foundation of Sichuan Science and Technology Department 2021YFH0119 and
   the funding from Sichuan University under grant 2020SCUNG205. This
   research received funding from the Flemish Government under the
   ?Onderzoeksprogramma Artifici?le Intelligentie (AI)
   Vlaanderen?programme.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chen ZN, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3231742
   Cheng EJ, 2021, MULTIMED TOOLS APPL, V80, P16659, DOI 10.1007/s11042-020-09055-6
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Deng J., 2009, IEEE C COMP VIS PATT
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fan YC, 2020, AAAI CONF ARTIF INTE, V34, P10770
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P, 2014, 3 INT C LEARN REPR I, P1
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li Z, 2020, NEUROCOMPUTING, V398, P377, DOI 10.1016/j.neucom.2019.04.004
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin D, 2018, LECT NOTES COMPUT SC, V11207, P622, DOI 10.1007/978-3-030-01219-9_37
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K., 2014, CORR
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang MJ, 2021, J PARALLEL DISTR COM, V152, P57, DOI 10.1016/j.jpdc.2021.02.016
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 54
TC 8
Z9 9
U1 1
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103730
DI 10.1016/j.jvcir.2022.103730
EA DEC 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7L9TE
UT WOS:000906300300001
OA Green Published
DA 2024-07-18
ER

PT J
AU Zhong, X
   Wang, MD
   Liu, WX
   Yuan, JL
   Huang, WX
AF Zhong, Xian
   Wang, Mengdie
   Liu, Wenxuan
   Yuan, Jingling
   Huang, Wenxin
TI SCPNet: Self-constrained parallelism network for keypoint-based
   lightweight object detection?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Keypoint-based lightweight object detection; Parallel multi-scale
   fusion; Parallel shuffle block; Self-constrained detection
AB Keypoint-based object detection achieves better performance without positioning calculations and extensive prediction. However, they have heavy backbone, and high-resolution is restored using upsampling that obtain unreliable features. We propose a self-constrained parallelism keypoint-based lightweight object detection network (SCPNet), which speeds inference, drops parameters, widens receptive fields, and makes prediction accurate. Specifically, the parallel multi-scale fusion module (PMFM) with parallel shuffle blocks (PSB) adopts parallel structure to obtain reliable features and reduce depth, adopts repeated multi-scale fusion to avoid too many parallel branches. The self-constrained detection module (SCDM) has a two-branch structure, with one branch predicting corners, and employing entad offset to match high-quality corner pairs, and the other branch predicting center keypoints. The distances between the paired corners' geometric centers and the center keypoints are used for self-constrained detection. On MS-COCO 2017 and PASCAL VOC, SCPNet's results are competitive with the state-of-the-art lightweight object detection. https://github.com/mengdie-wang/SCPNet.git.
C1 [Zhong, Xian; Wang, Mengdie; Liu, Wenxuan; Yuan, Jingling] Wuhan Univ Technol, Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.
   [Huang, Wenxin] Hubei Univ, Comp Sci & Informat Engn, Wuhan 430062, Peoples R China.
   [Zhong, Xian] Peking Univ, Sch Elect Engn & Comp Sci, Beijing 100091, Peoples R China.
C3 Wuhan University of Technology; Hubei University; Peking University
RP Yuan, JL (corresponding author), Wuhan Univ Technol, Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.; Huang, WX (corresponding author), Hubei Univ, Comp Sci & Informat Engn, Wuhan 430062, Peoples R China.
EM yjl@whut.edu.cn; wenxinhuang_wh@163.com
RI Huang, Wenxin/AFN-5558-2022
OI Zhong, Xian/0000-0002-5242-0467
FU National Natural Science Foundation of China [62271361, 52271366];
   Department of Science and Technology, Hubei Provincial People's
   Government, China [2021CFB513, 2021CFB281]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 62271361 and 52271366, and the
   Department of Science and Technology, Hubei Provincial People's
   Government, China under Grant 2021CFB513 and 2021CFB281
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Çatalyürek ÜV, 2010, SIAM J SCI COMPUT, V32, P656, DOI 10.1137/080737770
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dong J., 2020, PROC IEEE INT C MULT, P1
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu C.-Y., 2017, arXiv
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang LC, 2015, Arxiv, DOI arXiv:1509.04874
   Huang X, 2021, Arxiv, DOI arXiv:2104.10419
   Jiang K, 2021, IEEE T IMAGE PROCESS, V30, P7404, DOI 10.1109/TIP.2021.3102504
   Jiansheng Dong, 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P548, DOI 10.1145/3372278.3390714
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Liang Liao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P683, DOI 10.1007/978-3-030-58583-9_41
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Ma X., 2022, PROC IEEECVF C COMPU
   Mehta R, 2019, LECT NOTES COMPUT SC, V11133, P659, DOI 10.1007/978-3-030-11021-5_41
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Qin YL, 2019, IEEE T MED IMAGING, V38, P2569, DOI 10.1109/TMI.2019.2905841
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   RangiLyu, 2021, Nanodet-plus: super fast and high accuracy lightweight anchor-free object detection model
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samet Nermin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P406, DOI 10.1007/978-3-030-58595-2_25
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Szegedy C., 2015, IEEE C COMPUT VIS PA, P1
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang JD, 2016, Arxiv, DOI arXiv:1605.07716
   Wang RJ, 2018, 32 C NEURAL INFORM P
   Wang X, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3380549
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu X, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107827
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Ye M, 2022, IEEE T IMAGE PROCESS, V31, P379, DOI 10.1109/TIP.2021.3131937
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P2655, DOI 10.1109/TIFS.2020.2970590
   Yu CQ, 2021, PROC CVPR IEEE, P10435, DOI 10.1109/CVPR46437.2021.01030
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zhang SF, 2021, IEEE T CIRC SYST VID, V31, P674, DOI 10.1109/TCSVT.2020.2986402
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao LM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3170
   Zhiwei Dong, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10516, DOI 10.1109/CVPR42600.2020.01053
   Zhong X, 2023, IEEE T MULTIMEDIA, V25, P1979, DOI 10.1109/TMM.2022.3141886
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
NR 62
TC 4
Z9 4
U1 1
U2 26
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103719
DI 10.1016/j.jvcir.2022.103719
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7K4XD
UT WOS:000905286500001
DA 2024-07-18
ER

PT J
AU Aydin, Y
AF Aydin, Yildiz
TI A new Copy-Move forgery detection method using LIOP*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move forgery; LIOP; YCbCr; Keypoint; Image processing
ID SEGMENTATION; FEATURES
AB The most prevalent type of digital image falsification occurs when a portion of a image is copied and pasted onto another section of the same image. Falsification of the image made in this way is called copy-move forgery (CMF). This study presents a new and effective approach for copy-move forgery detection (CMFD) using the Local Intensity Order Pattern (LIOP) to overcome the restrictions of existing CMFD techniques. The input image is first converted to a YCbCr color space and then split into Y, Cb, and Cr color channels. The LIOP features are then extracted from each color channel and all the features are combined. The feature vectors are ordered lexico-graphically and related features are detected by comparing the LIOP features. Although the LIOP feature has rarely been used in CMFD prior to this study, the success rate of the proposed method is high. In addition, since the channels are not correlated to each other in the YCbCr color space, each color channel is considered as a gray image, and the success rate is increased by combining the features extracted from each of the color channels. The proposed approach was assessed using the CoMoFoD and GRIP datasets. Experimental findings demonstrated that the suggested method was successful and displayed robustness in post-processing attacks.
C1 [Aydin, Yildiz] Erzincan Binali Yildirim Univ, Dept Comp Engn, TR-24000 Erzincan, Turkey.
C3 Erzincan Binali Yildirim University
RP Aydin, Y (corresponding author), Erzincan Binali Yildirim Univ, Dept Comp Engn, TR-24000 Erzincan, Turkey.
EM yciltas@erzincan.edu.tr
RI AYDIN, Yıldız/HCI-8582-2022
OI AYDIN, Yıldız/0000-0002-3877-6782
CR Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Alagu S., 2019, INT J RES ENG APPL M, V5, DOI [10.1051/itmconf/20224403052, DOI 10.1051/ITMCONF/20224403052]
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Babu SBGT, 2022, ICT EXPRESS, V8, P244, DOI 10.1016/j.icte.2021.08.016
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Bilal M, 2021, AUST J FORENSIC SCI, V53, P459, DOI 10.1080/00450618.2020.1715479
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Chen CC, 2019, MULTIMED TOOLS APPL, V78, P18293, DOI 10.1007/s11042-019-7165-8
   Chen JX, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116287
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gürbüz E, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/8124521
   Habibi M, 2021, INT J ENG-IRAN, V34, P443, DOI 10.5829/ije.2021.34.02b.16
   Jaiswal A.K., 2019, LECT NOTES ELECT ENG, V524, P289, DOI [10.1007/978-981-13-2685-1_28, DOI 10.1007/978-981-13-2685-1_28]
   Jessica FRIDRICH A., 1962, DETECTION COPY MOVE
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu YQ, 2018, MULTIMED TOOLS APPL, V77, P18269, DOI 10.1007/s11042-017-5374-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manu VT, 2018, SIGNAL IMAGE VIDEO P, V12, P549, DOI 10.1007/s11760-017-1191-7
   Meena KB, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102481
   Nawaz M, 2021, CMC-COMPUT MATER CON, V69, P1927, DOI 10.32604/cmc.2021.018052
   Niyishaka P, 2018, LECT NOTES COMPUT SC, V11114, P472, DOI 10.1007/978-3-030-00692-1_41
   Ojeniyi Joseph A., 2018, International Journal of Image, Graphics and Signal Processing, V10, P22, DOI 10.5815/ijigsp.2018.04.03
   Popescu A.C., 2004, EXPOSING DIGITAL FOR
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Tahaoglu G, 2022, MULTIMED TOOLS APPL, V81, P22867, DOI 10.1007/s11042-021-11503-w
   Thampi S. M., 2013, ADV INTELLIGENT SYST, V196
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Yang HY, 2018, MULTIMED TOOLS APPL, V77, P13615, DOI 10.1007/s11042-017-4978-1
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 42
TC 3
Z9 3
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103661
DI 10.1016/j.jvcir.2022.103661
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500004
DA 2024-07-18
ER

PT J
AU Chen, MH
   He, PS
   Liu, JY
AF Chen, Menghua
   He, Peisong
   Liu, Jiayong
TI HLTD-CSA: Cover selection algorithm based on hybrid local texture
   descriptor for color image steganography
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color image steganography; Cover selection; Hybrid local texture;
   Channel correlations
ID CLASSIFICATION; STEGANALYSIS
AB Cover selection is one of the important techniques to improve the security of image steganography. However, existing methods mostly focus on cover selection of grayscale image. In this paper, we propose a novel Cover Selection Algorithm of color images based on Hybrid Local Texture Descriptor, named HLTD-CSA. A green-channel related Local Binary Pattern (LBP) is designed which utilizes local statistics of intra-channel and cross-channel correlations efficiently. Besides, Local Phase Quantization is introduced to serve as a complementary component of our improved LBP. To further enhance the performance of cover selection for color image, a hybrid local texture descriptor (HLTD) is obtained by combining these two types of local texture descriptors with a proper combination strategy. Finally, the proposed algorithm selects images which have larger values of HLTD to construct the cover image set. Extensive experiments are conducted to verify the effectiveness of our method.
C1 [Chen, Menghua; He, Peisong; Liu, Jiayong] Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP He, PS; Liu, JY (corresponding author), Sichuan Univ, Sch Cyber Sci & Engn, Chengdu 610065, Peoples R China.
EM gokeyhps@scu.edu.cn; ljy@scu.edu.cn
RI LIU, JIAYONG/JKJ-6473-2023; He, Peisong/AAE-2082-2022
OI LIU, JIAYONG/0000-0002-1834-0877; He, Peisong/0000-0003-3121-0599
FU National Natural Science Founda-tion of China; China Postdoctoral
   Science Foundation;  [61902263];  [2020M673276]
FX Acknowledgments This work was supported by National Natural Science
   Founda-tion of China (61902263) , China Postdoctoral Science Foundation
   (2020M673276) .
CR Abdulrahman H., 2016, 4THACM WORKSHOP INF, P109
   Abdulrahman H, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P448, DOI 10.1109/ARES.2015.44
   Abed S, 2019, EURASIP J IMAGE VIDE, V2019, DOI 10.1186/s13640-019-0486-8
   Evsutin O, 2018, J DECIS SYST, V27, P256, DOI 10.1080/12460125.2018.1460163
   Fan JT, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P420, DOI 10.1109/BigMM.2015.87
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Goljan M, 2014, IEEE INT WORKS INFOR, P185, DOI 10.1109/WIFS.2014.7084325
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kang YH, 2019, CMC-COMPUT MATER CON, V59, P315, DOI 10.32604/cmc.2019.05242
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qin XH, 2019, IEEE ACCESS, V7, P8834, DOI 10.1109/ACCESS.2019.2891316
   Rashid RD, 2020, PROC SPIE, V11399, DOI 10.1117/12.2560720
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   SHAH PD, 2020, 2020 INT C EMERGING, P1, DOI DOI 10.1109/INCET49848.2020.9154032
   Subhedar MS, 2018, MULTIMED TOOLS APPL, V77, P8115, DOI 10.1007/s11042-017-4706-x
   Tang WX, 2016, IEEE SIGNAL PROC LET, V23, P197, DOI 10.1109/LSP.2015.2504583
   The ImageMagick Development Team, 2021, IM
   Wang YF, 2020, IEEE T INF FOREN SEC, V15, P2081, DOI 10.1109/TIFS.2019.2956590
   Wang ZC, 2020, IEEE SIGNAL PROC LET, V27, P71, DOI 10.1109/LSP.2019.2956416
   Wang ZC, 2019, IEEE ACCESS, V7, P57857, DOI 10.1109/ACCESS.2019.2914226
   Wang ZC, 2018, IEEE SIGNAL PROC LET, V25, P1530, DOI 10.1109/LSP.2018.2865888
   Zeng JS, 2019, IEEE T INF FOREN SEC, V14, P2735, DOI 10.1109/TIFS.2019.2904413
NR 31
TC 2
Z9 2
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103646
DI 10.1016/j.jvcir.2022.103646
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300003
DA 2024-07-18
ER

PT J
AU Shakeel, MS
   Zhang, YX
   Wang, X
   Kang, WX
   Mahmood, A
AF Shakeel, M. Saad
   Zhang, Yuxuan
   Wang, Xin
   Kang, Wenxiong
   Mahmood, Arif
TI Multi-scale attention guided network for end-to-end face alignment and
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Attention network; Feature alignment; Multi-scale features; Adaptive
   feature fusion
AB Attention modules embedded in deep networks mediate the selection of informative regions for object recog-nition. In addition, the combination of features learned from different branches of a network can enhance the discriminative power of these features. However, fusing features with inconsistent scales is a less-studied problem. In this paper, we first propose a multi-scale channel attention network with an adaptive feature fusion strategy (MSCAN-AFF) for face recognition (FR), which fuses the relevant feature channels and improves the network's representational power. In FR, face alignment is performed independently prior to recognition, which requires the efficient localization of facial landmarks, which might be unavailable in uncontrolled scenarios such as low-resolution and occlusion. Therefore, we propose utilizing our MSCAN-AFF to guide the Spatial Transformer Network (MSCAN-STN) to align feature maps learned from an unaligned training set in an end-to -end manner. Experiments on benchmark datasets demonstrate the effectiveness of our proposed MSCAN-AFF and MSCAN-STN.
C1 [Shakeel, M. Saad] Guangdong Univ Petrochem Technol, Sch Automat, Maoming 525000, Peoples R China.
   [Zhang, Yuxuan; Wang, Xin; Kang, Wenxiong] South China Univ Technol, Sch Automat Sci & Engn, Guangzhou 510641, Peoples R China.
   [Mahmood, Arif] Informat Technol Univ, Dept Comp Sci, Lahore 54000, Pakistan.
C3 Guangdong University of Petrochemical Technology; South China University
   of Technology
RP Shakeel, MS (corresponding author), Guangdong Univ Petrochem Technol, Sch Automat, Maoming 525000, Peoples R China.
EM saad.shakeel@gdupt.edu.cn; auyuxuan_zhang@mail.scut.edu.cn;
   auwx@mail.scut.edu.cn; auwxkang@scut.edu.cn; arif.mahmood@itu.edu.pk
RI Mahmood, Arif/R-7949-2019
OI Mahmood, Arif/0000-0001-5986-9876
FU Guangdong University of Petro-chemical Technology, China [702/519245]
FX Acknowledgment The work presented in this paper is supported by an
   internal grant (Project code: 702/519245) from Guangdong University of
   Petro-chemical Technology, China.
CR [Anonymous], 2007, Technical Report
   Anwar A., 2020, arXiv
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen J, 2015, IEEE ICC, P1801, DOI 10.1109/ICC.2015.7248586
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Hayat M, 2017, PROC CVPR IEEE, P1551, DOI 10.1109/CVPR.2017.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He MY, 2017, IEEE IMAGE PROC, P3904, DOI 10.1109/ICIP.2017.8297014
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang M, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102846
   Jiang M, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102775
   Kim I., 2020, P ASIAN C COMPUTER V
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shi YC, 2019, IEEE I CONF COMP VIS, P6901, DOI 10.1109/ICCV.2019.00700
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang Q., 2020, P IEEE CVF C COMP VI, P8326, DOI [DOI 10.1109/CVPR42600.2020.00835, 10.1109/CVPR42600.2020.00835]
   Wang Q., 2020, P IEEE C COMPUTER VI
   Wang QC, 2020, IEEE T INF FOREN SEC, V15, P1640, DOI 10.1109/TIFS.2019.2946938
   Wang XB, 2020, AAAI CONF ARTIF INTE, V34, P12241
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu WL, 2017, IEEE I CONF COMP VIS, P3792, DOI 10.1109/ICCV.2017.407
   Xie WD, 2018, LECT NOTES COMPUT SC, V11215, P811, DOI 10.1007/978-3-030-01252-6_48
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan QS, 2022, INT J COMPUT VISION, V130, P76, DOI 10.1007/s11263-021-01535-y
   Yan QS, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108342
   Yan QS, 2021, IEEE T BIG DATA, V7, P13, DOI 10.1109/TBDATA.2021.3056564
   Yan QS, 2021, IEEE J BIOMED HEALTH, V25, P2629, DOI 10.1109/JBHI.2020.3042069
   Yan QS, 2019, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2019.00185
   Yi D, 2014, Arxiv, DOI arXiv:1411.7923
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang YX, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108522
   Zheng T., 2018, Tech. Rep., V5
   Zheng TY, 2017, Arxiv, DOI arXiv:1708.08197
   Zhong YY, 2017, IEEE SIGNAL PROC LET, V24, P1213, DOI 10.1109/LSP.2017.2715076
NR 53
TC 4
Z9 4
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2022
VL 88
AR 103628
DI 10.1016/j.jvcir.2022.103628
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 4W9VR
UT WOS:000860502800011
DA 2024-07-18
ER

PT J
AU Lin, CD
   Xiong, SW
   Chen, YX
AF Lin, Chengde
   Xiong, Shengwu
   Chen, Yaxiong
TI Mutual information maximizing GAN inversion for real face with identity
   preservation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Generativeadversarialnetwork; GANinversion; Mutualinformationmaximizing;
   Faceidentitypreservation; Faceediting
AB Recent generative adversarial networks (GANs) have yielded remarkable performance in face image synthesis. GAN inversion embeds an image into the latent space of a pretrained generator, enabling it to be used for real face manipulation. However, current inversion approaches for real faces suffer the dilemma of initialization collapse and identity loss. In this paper, we propose a hierarchical GAN inversion for real faces with identity preservation based on mutual information maximization. We first use a facial domain guaranteed initialization to avoid the initialization collapse. Furthermore, we prove that maximizing the mutual information between inverted faces and their identities is equivalent to minimizing the distance between identity features from inverted and original faces. Optimization for real face inversion with identity preservation is implemented on this mutual information-maximizing constraint. Extensive experimental results show that our approach outperforms state-of-the-art solutions for inverting and editing real faces, particularly in terms of face identity preservation.
C1 [Lin, Chengde; Xiong, Shengwu; Chen, Yaxiong] Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.
   [Xiong, Shengwu; Chen, Yaxiong] Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Sanya 572000, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology
RP Xiong, SW (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Artificial Intelligence, Wuhan 430070, Peoples R China.
EM xiongsw@whut.edu.cn
RI Xiong, Shou-Mei/A-4225-2009; Chen, Yaxiong/AAR-7285-2020; Lin,
   CD/G-4112-2010
OI Chen, Yaxiong/0000-0002-2903-6723; 
FU NSFC, China [62176194, 62101393]; Major project of IoV, China
   [2020AAA001]; Sanya Science and Education Innovation Park of Wuhan
   University of Technology [2021KF0031]; CSTC [cstc2021jcyj-msxmX1148];
   Open Project of Wuhan University of Technology Chongqing Research
   Institute [ZL2021-6]
FX This work was in part supported by NSFC, China (Grant No. 62176194,
   Grant No. 62101393) , the Major project of IoV, China (Grant No.
   2020AAA001) , Sanya Science and Education Innovation Park of Wuhan
   University of Technology (Grant No. 2021KF0031) , CSTC (Grant No.
   cstc2021jcyj-msxmX1148) and the Open Project of Wuhan University of
   Technology Chongqing Research Institute (ZL2021-6) .
CR Abdal R., 2020, P IEEECVF C COMPUTER, P8296
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Barber D, 2004, ADV NEUR IN, V16, P201
   Bau D., 2019, ICLR WORKSH, V2, P4
   Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460
   Belghazi MI, 2018, PR MACH LEARN RES, V80
   Brock A., 2018, CORR ABS180911096 AR
   Chen QC, 2020, AAAI CONF ARTIF INTE, V34, P10567
   Chen X, 2016, ADV NEUR IN, V29
   Cheng PY, 2020, PR MACH LEARN RES, V119
   Colombo P., 2021, P 59 ANN M ASS COMPU, P6539, DOI 10.18653/v1/2021.acl-long.511
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P1967, DOI 10.1109/TNNLS.2018.2875194
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Feng ZY, 2019, IEEE I CONF COMP VIS, P3244, DOI 10.1109/ICCV.2019.00334
   Gao GG, 2021, PROC CVPR IEEE, P3403, DOI 10.1109/CVPR46437.2021.00341
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308
   Guan S., 2020, CORR ABS200701758 AR
   Han Y., 2021, ARXIV210512660, P715
   Harkonen E., 2020, P ADV NEUR INF PROC
   Hjelm R. Devon, 2018, LEARNING DEEP REPRES
   Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lipton Z.C., 2017, CORR ABS170204782 AR
   Ma FC, 2018, ADV NEUR IN, V31
   McAllester D, 2020, PR MACH LEARN RES, V108, P875
   Perarnau G., 2016, CORR ABS161106355 AR
   Poole B, 2019, PR MACH LEARN RES, V97
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen Yujun, 2020, P IEEE CVF C COMP VI, P9243, DOI DOI 10.1109/CVPR42600.2020.00926
   Song JM, 2019, PR MACH LEARN RES, V89
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Tian Y., 2020, INT C LEARNING REPRE
   van den Oord A., 2018, CORR ABS180703748 AR
   Xia W., 2021, CORR ABS210105278 AR
   Xu YH, 2021, PROC CVPR IEEE, P4430, DOI 10.1109/CVPR46437.2021.00441
   Yang N, 2021, IEEE SIGNAL PROC LET, V28, P553, DOI 10.1109/LSP.2021.3059371
   Yao Xu, 2021, P IEEE INT C COMP VI, P13789
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang ZX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102719
   Zhao H., 2021, CORR ABS211012184 AR
   Zhu H, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2362
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 49
TC 3
Z9 3
U1 2
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103566
DI 10.1016/j.jvcir.2022.103566
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100006
DA 2024-07-18
ER

PT J
AU Mukherjee, M
   Meenpal, T
   Goyal, A
AF Mukherjee, Moumita
   Meenpal, Toshanlal
   Goyal, Aarti
TI FuseKin: Weighted image fusion based kinship verification under
   unconstrained age group
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kinship verification; Image fusion; Feature selection; Face
   frontalization
ID DISCRIMINANT-ANALYSIS; RECOGNITION; FACE; CLASSIFICATION
AB Kinship verification using facial images is mainly performed with a single face sample per person. To perform with a single sample, it is very difficult to specify an age group where kin pairs may have higher similarities. To address the above problem, we propose a novel weighted multi sample fusion (WMSF) method. The proposed WMSF method combines kin signals present in multiple samples per person (MSPP) to form a FuseKin image. To select the most discriminant features from the extracted feature vector, we propose a patch based discriminative analysis (PDA) method. Weights are calculated using the PDA method so as to reduce the discrimination between positive FuseKin pairs. Experiments were conducted on two different datasets which contain multiple face image samples per person, namely Family101 and Family in the Wild (FIW) to validate the performance of the proposed methods. Our method achieves competitive results as compared to other state-of-the-art methods.
C1 [Mukherjee, Moumita; Meenpal, Toshanlal; Goyal, Aarti] Natl Inst Technol Raipur, Dept Elect & Commun, Raipur 492010, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Meenpal, T (corresponding author), Natl Inst Technol Raipur, Dept Elect & Commun, Raipur 492010, Chhattisgarh, India.
EM mmukherjee.phd2018.etc@nitrr.ac.in; meenpal.etc@nitrr.ac.in;
   agoyal.phd2016.etc@nitrr.ac.in
RI Mukherjee, Prof Moumita/GVS-4827-2022; Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606; Mukherjee,
   Moumita/0000-0002-2364-5501; Meenpal, Toshanlal/0000-0003-2809-075X
CR Alirezazadeh P, 2015, IEEE SIGNAL PROC LET, V22, P2459, DOI 10.1109/LSP.2015.2490805
   Dal Martello MF, 2006, J VISION, V6, P1356, DOI 10.1167/6.12.2
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dehshibi MM, 2019, VISUAL COMPUT, V35, P23, DOI 10.1007/s00371-017-1442-1
   Duan Qingyan, 2017, P ACM MM WORKSH RFIW, P21, DOI [DOI 10.1145/3134421.3134422, 10.1145/3134421.3134422]
   Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614
   Gao JQ, 2020, NEURAL PROCESS LETT, V51, P473, DOI 10.1007/s11063-019-10100-1
   Gao XZ, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112886
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Goyal A, 2021, IEEE T IMAGE PROCESS, V30, P191, DOI 10.1109/TIP.2020.3034027
   Goyal A, 2021, PATTERN ANAL APPL, V24, P119, DOI 10.1007/s10044-020-00906-4
   Handong Zhao, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163087
   Hassner T, 2015, PROC CVPR IEEE, P4295, DOI 10.1109/CVPR.2015.7299058
   Hu JL, 2018, IEEE T CIRC SYST VID, V28, P1875, DOI 10.1109/TCSVT.2017.2691801
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Laiadi O, 2019, IEEE INT CONF AUTOMA, P735, DOI 10.1109/fg.2019.8756627
   Laiadi O, 2021, INT J MACH LEARN CYB, V12, P171, DOI 10.1007/s13042-020-01163-x
   Laiadi O, 2020, NEUROCOMPUTING, V377, P286, DOI 10.1016/j.neucom.2019.10.055
   Li L, 2016, OPTIK, V127, P7408, DOI 10.1016/j.ijleo.2016.05.105
   Li YY, 2017, ADV SOC SCI EDUC HUM, V159, P13
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Moujahid A, 2019, MULTIMED TOOLS APPL, V78, P9335, DOI 10.1007/s11042-018-6517-0
   Mukherjee M., 2019, IEEE ICC, P1, DOI [DOI 10.1109/icc.2019.8761827, 10.1109/ICC.2019.8761827]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Patel B, 2017, COMPUT VIS IMAGE UND, V160, P24, DOI 10.1016/j.cviu.2017.04.009
   Qin XQ, 2015, IEEE T MULTIMEDIA, V17, P1855, DOI 10.1109/TMM.2015.2461462
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Robinson JP, 2018, IEEE T PATTERN ANAL, V40, P2624, DOI 10.1109/TPAMI.2018.2826549
   Somanath G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P105, DOI 10.1109/BTAS.2012.6374564
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tharwat A, 2017, AI COMMUN, V30, P169, DOI 10.3233/AIC-170729
   Wang MY, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patog.2020.10732
   Wang SY, 2019, IEEE T PATTERN ANAL, V41, P2783, DOI [10.1109/INTMAG.2018.8508542, 10.1109/TNNLS.2017.2771290, 10.1109/TPAMI.2018.2861871]
   Wang XL, 2014, IEEE IMAGE PROC, P5017, DOI 10.1109/ICIP.2014.7026016
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Yan HB, 2019, PATTERN RECOGN LETT, V117, P146, DOI 10.1016/j.patrec.2018.05.027
   Yan HB, 2015, IEEE T CYBERNETICS, V45, P2535, DOI 10.1109/TCYB.2014.2376934
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Zhang L, 2021, IEEE T CYBERNETICS, V51, P5883, DOI 10.1109/TCYB.2019.2959403
   Zhao YG, 2018, INFORM SCIENCES, V430, P247, DOI 10.1016/j.ins.2017.11.048
   Zhou X., 2011, ACM Multimedia, P953
NR 42
TC 7
Z9 7
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103470
DI 10.1016/j.jvcir.2022.103470
EA MAR 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PF
UT WOS:000783924700003
DA 2024-07-18
ER

PT J
AU Yogameena, B
   Jakkamsetti, G
   Aishwarya, S
AF Yogameena, B.
   Jakkamsetti, Geeta
   Aishwarya, S.
TI SpyGAN sketch: Heterogeneous Face Matching in video for crime
   investigation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE SpyGAN; Heterogeneous face matching; Generated sketch; Illumination; OWN
   short face-video linked dataset
ID IMAGE
AB Automatic retrieval of faces from videos based on query images effectively helps during the investigation. When the suspect's image is unavailable, a face sketch, drawn based on eyewitness's memory recollection, is used to search against photos. Present research works primarily focus on Heterogeneous Face Matching (HFM) sketches to mugshot images in databases. This paper proposes a sketch-face matching in a video that includes profile faces, different illumination, and poses, using a new Generative Adversarial Network called SpyGAN. Faces in the video detected using YOLOv3 are converted into realistic sketches by the proposed SpyGAN focusing on key facial regions. The generated sketches are represented using PCA-SIFT descriptors and are matched based on the cosine distance metric. Experimental results show that the proposed methodology has achieved an accuracy of 88.9% on the Chokepoint dataset and 78% on the OWN Short face-video linked dataset and has demonstrated effectiveness over the state-of-the-art methods.
C1 [Yogameena, B.; Jakkamsetti, Geeta; Aishwarya, S.] Thiagarajar Coll Engn, Elect & Commun Dept, Madurai, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Yogameena, B (corresponding author), Thiagarajar Coll Engn, Elect & Commun Dept, Madurai, Tamil Nadu, India.
EM ymece@tce.edu; j.geeta1998@gmail.com; aishpooja10@gmail.com
OI Balasubramanian, Yogameena/0000-0003-0410-2920
FU Video Analytics and Development System (VADS) kit - IISC Bangalore
   [DST/IISC/KRR/BY/IP/VADS/2014]
FX This work has been supported under Video Analytics and Development
   System (VADS) kit, sponsored by IISC Bangalore
   [DST/IISC/KRR/BY/IP/VADS/2014] . The authors are very much thankful to
   anonymous referrers for their valuable suggestions and comments that
   have always helped to improve the quality of this work.
CR Bhatt Himanshu S., 2010, 2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1, DOI DOI 10.1109/BTAS.2010.5634507
   Bhattacharyya A, 2019, SOFT COMPUT, V23, P8085, DOI 10.1007/s00500-018-3446-9
   Chen W., 2020, VISUAL COMPUT, DOI DOI 10.1007/s00371-020-01831-7
   Chen Xilin, 2019, 2019 14 IEEE INT C A, P1
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Everingham M., 2006, VOC 2006 DATABASE
   Galea C, 2018, IEEE T INF FOREN SEC, V13, P1421, DOI 10.1109/TIFS.2017.2788002
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Garg D., 2018, IEEE Punecon, P1, DOI 10.1109/PUNECON.2018.8745376
   Geng C, 2009, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2009.5413956
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Heo Young-Jin, 2021, Journal of Multimedia Information System, V8, P85, DOI 10.33851/JMIS.2021.8.2.85
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jang Y, 2019, COMPUT VIS IMAGE UND, V182, P17, DOI 10.1016/j.cviu.2019.01.006
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Kamencay P, 2012, 2012 35TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P758, DOI 10.1109/TSP.2012.6256399
   Kim JH, 2019, IEEE ACCESS, V7, P41273, DOI 10.1109/ACCESS.2019.2907327
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Li YS, 2021, INFORM FUSION, V67, P94, DOI 10.1016/j.inffus.2020.10.008
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P6521, DOI 10.1109/TGRS.2018.2839705
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Liang Y., 2012, P 2012 ASIA PACIFIC, P1
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nagpal S, 2017, IEEE I CONF COMP VIS, P5429, DOI 10.1109/ICCV.2017.579
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 34
TC 1
Z9 1
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103400
DI 10.1016/j.jvcir.2021.103400
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0SO
UT WOS:000783933400005
DA 2024-07-18
ER

PT J
AU Liu, Y
   Huang, BQ
   Yu, HW
   Zheng, Z
AF Liu, Yun
   Huang, Baoqing
   Yu, Hongwei
   Zheng, Zhi
TI No-reference stereoscopic image quality evaluator based on human visual
   characteristics and relative gradient orientation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic image quality; Binocularity; Monocular feature; Binocular
   feature; Features extraction and regression
ID SALIENCY; BRIGHTNESS; DISTORTION; SUMMATION
AB Stereoscopic image quality assessment (SIQA) is of great significance to the development of modern threedimensional (3D) display technology. In this work, by further mining the relationship between visual features and stereoscopic image quality perception, we build a new no-reference SIQA model, which combines the monocular and binocular features. Statistical quality-aware structural features from relative gradient orientation (RGO) map and texture features from the histogram of the weighted local binary pattern (LBP) in the texture image (TLBP) are not only extracted from both monocular view, but also extracted from binocular views to predict binocular quality perception. Meanwhile, the color statistical features ignored by most models and the binocularity feature is extracted to complement the monocular features and the above binocular features, respectively. Finally, all the extracted features and subjective scores are used to predict the objective quality score through the support vector regression (SVR) model. Experiments on four popular stereoscopic image databases show that the proposed model achieves high consistency with subjective assessment, and the performance of the model is very competitive with the latest models.
C1 [Liu, Yun; Huang, Baoqing; Yu, Hongwei] Liaoning Univ, Coll Informat, Shenyang 110036, Liaoning, Peoples R China.
   [Zheng, Zhi] Beijing Jiaotong Univ, Dept Elect & Informat Engn, Beijing 100044, Peoples R China.
C3 Liaoning University; Beijing Jiaotong University
RP Huang, BQ (corresponding author), Liaoning Univ, Coll Informat, Shenyang 110036, Liaoning, Peoples R China.
EM yunliu@tju.edu.cn; huangbq11@163.com
RI Yu, Hong-Wei/AAR-3342-2020
FU National Natural Science Foundation of China [61901205]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61901205. The authors would like to thank Prof. A. C.
   Bovik for providing the LIVE 3D IQA Databases and Prof. Jiheng Wang for
   providing the IVC 3D IQA Database.
CR [Anonymous], [No title captured]
   [Anonymous], 2010, P INT WORKSH VID PRO
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Boev A, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   Chen L, 2019, SIGNAL PROCESS-IMAGE, V76, P1, DOI 10.1016/j.image.2019.03.011
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Chen Y, 2020, IEEE ACCESS, V8, P85760, DOI 10.1109/ACCESS.2020.2992746
   De Silva HR, 1930, B J PSYCHOL-GEN SECT, V20, P241
   Ding Y, 2019, IET IMAGE PROCESS, V13, P1608, DOI 10.1049/iet-ipr.2018.5605
   ENGEL GR, 1967, VISION RES, V7, P753, DOI 10.1016/0042-6989(67)90038-7
   Fan Y, 2019, IEEE IMAGE PROC, P430, DOI [10.1109/icip.2019.8802956, 10.1109/ICIP.2019.8802956]
   Fezza SA, 2017, J VIS COMMUN IMAGE R, V49, P115, DOI 10.1016/j.jvcir.2017.08.009
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Howard I. P., 1995, BINOCULAR CORRES, V2, P407
   Jiang QP, 2019, IEEE T IMAGE PROCESS, V28, P1866, DOI 10.1109/TIP.2018.2881828
   Karimi M, 2019, DIGIT SIGNAL PROCESS, V91, P91, DOI 10.1016/j.dsp.2019.03.004
   Khan S, 2018, IEEE T IMAGE PROCESS, V27, P5892, DOI 10.1109/TIP.2018.2860279
   Lasmar NE, 2009, IEEE IMAGE PROC, P2281, DOI 10.1109/ICIP.2009.5414404
   Li KM, 2014, PROC SPIE, V9273, DOI 10.1117/12.2073641
   Li QH, 2017, NEUROCOMPUTING, V236, P93, DOI 10.1016/j.neucom.2016.09.105
   Li SM, 2020, SIGNAL IMAGE VIDEO P, V14, P565, DOI 10.1007/s11760-019-01582-6
   Li YF, 2019, IEEE ACCESS, V7, P46706, DOI 10.1109/ACCESS.2019.2909073
   LI ZP, 1994, NETWORK-COMP NEURAL, V5, P157, DOI 10.1088/0954-898X/5/2/003
   Lin CW, 2016, DES AUT CON, DOI 10.1145/2897937.2905006
   Ling S., 2018, J PERCEPTUAL IMAG, P10501
   Ling SY, 2021, IEEE T IMAGE PROCESS, V30, P517, DOI 10.1109/TIP.2020.3037504
   Lingafelter Steven W., 2020, Insecta Mundi, V754, P1
   Liu LX, 2018, NEUROCOMPUTING, V275, P1823, DOI 10.1016/j.neucom.2017.10.017
   Liu LX, 2017, SIGNAL PROCESS-IMAGE, V58, P287, DOI 10.1016/j.image.2017.08.011
   Liu TJ, 2019, IEEE ACCESS, V7, P8058, DOI 10.1109/ACCESS.2018.2890304
   Liu Y, 2020, IEEE ACCESS, V8, P33666, DOI 10.1109/ACCESS.2020.2974006
   Lu KX, 2016, 2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC, P420, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.169
   Lyu WJ, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102797
   Ma J, 2018, IEEE ACCESS, V6, P2768, DOI 10.1109/ACCESS.2017.2785282
   Maugey T., 2017, 2017 IEEE 19th International Workshop on Multimedia Signal Processing, P1
   May KA, 2012, CURR BIOL, V22, P28, DOI 10.1016/j.cub.2011.11.025
   Messai O, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115772
   Miao XK, 2019, SIGNAL PROCESS-IMAGE, V79, P54, DOI 10.1016/j.image.2019.08.013
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shen LL, 2021, NEUROCOMPUTING, V424, P132, DOI 10.1016/j.neucom.2020.10.024
   Shen LQ, 2019, IEEE TETCI, V3, P59, DOI 10.1109/TETCI.2018.2804885
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Wan ZL, 2020, IEEE T MULTIMEDIA, V22, P2024, DOI 10.1109/TMM.2019.2950533
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang X, 2019, CHIN AUTOM CONGR, P2070, DOI [10.1109/cac48633.2019.8997230, 10.1109/CAC48633.2019.8997230]
   Wang X, 2018, SIGNAL PROCESS, V145, P202, DOI 10.1016/j.sigpro.2017.12.002
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei LS, 2016, J ADV COMPUT INTELL, V20, P205
   Xiaoyin Duanmu, 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P200, DOI 10.1109/ITNG.2010.231
   Xu JH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3026443
   Yan JL, 2019, IEEE ACCESS, V7, P173657, DOI 10.1109/ACCESS.2019.2902659
   Yang JC, 2019, IEEE T MULTIMEDIA, V21, P1750, DOI 10.1109/TMM.2018.2889562
   Yang JC, 2018, APPL OPTICS, V57, P3915, DOI 10.1364/AO.57.003915
   Yang JC, 2018, INFORM SCIENCES, V430, P1, DOI 10.1016/j.ins.2017.10.053
   Yang JC, 2016, INFORM SCIENCES, V373, P251, DOI 10.1016/j.ins.2016.09.004
   Yue GH, 2018, SIGNAL PROCESS, V150, P204, DOI 10.1016/j.sigpro.2018.04.019
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zheng XL, 2020, IEEE ACCESS, V8, P31647, DOI 10.1109/ACCESS.2020.2972158
   Zhou WJ, 2017, IEEE T BROADCAST, V63, P404, DOI 10.1109/TBC.2016.2638620
NR 65
TC 1
Z9 1
U1 3
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103354
DI 10.1016/j.jvcir.2021.103354
EA NOV 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WW8ED
UT WOS:000718141700005
DA 2024-07-18
ER

PT J
AU Wang, L
   Shen, J
   Tang, E
   Zheng, SN
   Xu, LZ
AF Wang, Li
   Shen, Jie
   Tang, E.
   Zheng, Shengnan
   Xu, Lizhong
TI Multi-scale attention network for image super-resolution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Super-resolution; Multi-scale; Attention mechanism; Lightweight
AB ABSTR A C T The power of convolutional neural networks (CNN) has demonstrated irreplaceable advantages in super-resolution. However, many CNN-based methods need large model sizes to achieve superior performance, making them difficult to apply in the practical world with limited memory footprints. To efficiently balance model complexity and performance, we propose a multi-scale attention network (MSAN) by cascading multiple multi-scale attention blocks (MSAB), each of which integrates a multi-scale cross block (MSCB) and a multi-path wide-activated attention block (MWAB). Specifically, MSCB initially connects three parallel convolutions with different dilation rates hierarchically to aggregate the knowledge of features at different levels and scales. Then, MWAB split the channel features from MSCB into three portions to further improve performance. Rather than being treated equally and independently, each portion is responsible for a specific function, enabling internal communication among channels. Experimental results show that our MSAN outperforms most state-of-the-art methods with relatively few parameters and Mult-Adds.
C1 [Wang, Li; Shen, Jie; Tang, E.; Zheng, Shengnan; Xu, Lizhong] Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
   [Zheng, Shengnan] Nanjing Inst Technol, Sch Comp Engn, Nanjing, Peoples R China.
C3 Hohai University; Nanjing Institute of Technology
RP Xu, LZ (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
EM lzhxu@hhu.edu.cn
RI shen, jie/JJF-0994-2023
OI Wang, Li/0000-0003-2054-1392
FU National Natural Science Founda-tion of China [51979085, 61903124]
FX This work was supported by the National Natural Science Founda-tion of
   China (No. 51979085, 61903124) .
CR Ahn N, 2018, LECT NOTES COMPUT SC, V11214, P256, DOI 10.1007/978-3-030-01249-6_16
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cao FL, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102963
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chu XX, 2021, INT C PATT RECOG, P59, DOI 10.1109/ICPR48806.2021.9413080
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He XY, 2019, PROC CVPR IEEE, P1732, DOI 10.1109/CVPR.2019.00183
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Y, 2018, BLOCKCHAIN BASED SMA
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jie Liu, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P41, DOI 10.1007/978-3-030-67070-2_2
   Kim J.H., 2018, ARXIV181112043
   Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182
   Kim JH, 2020, NEUROCOMPUTING, V402, P38, DOI 10.1016/j.neucom.2020.03.069
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li J, 2018, PROC EUR C COMPUT VI, V11212, P517, DOI 10.1007/978-3-030-01237-3_32
   Li Z., ARXIV190705282, V2019
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu H, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106103
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shi WZ, 2017, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.2017.8296427
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tian C., 2021, ARXIV210313634
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang L., 2020, P IEEECVF C COMPUTER, P4917
   Wang LG, 2019, PROC CVPR IEEE, P12242, DOI 10.1109/CVPR.2019.01253
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu J., 2018, WIDE ACTIVATION EFFI
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HR, 2021, IEEE J-STSP, V15, P253, DOI 10.1109/JSTSP.2020.3045282
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
NR 44
TC 12
Z9 12
U1 3
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103300
DI 10.1016/j.jvcir.2021.103300
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900010
DA 2024-07-18
ER

PT J
AU Djerida, A
   Zhao, ZH
   Zhao, JK
AF Djerida, Achraf
   Zhao, Zhonghua
   Zhao, Jiankang
TI Development of scale and illumination invariant feature detector with
   application to UAV attitude estimation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature detection; Scale invariance; Illumination invariance; UAV
   attitude estimation
ID IMAGE FEATURES; ALGORITHM
AB Feature detection has great importance in many applications such as vision navigation. Examining the developed detectors, it is found in many recent studies that most of the scale-invariant detectors are sensitive to illumination. In this work, we propose a novel detector that has good robustness to both scale and illumination. Motivated by the good robustness of Log-Gabor kernels toward light changes, we employ these kernels as a basis to construct the scale space. To detect potential features, we develop an effective interest points measure which is motivated by the concept of the autocorrelation and Hessian matrices. To confirm the good performance of our detector, we hold experiments on many datasets and with comparisons to common state-ofthe-art methods. Furthermore, we evaluate the saliency of the detected features on a UAV attitude estimation task.
C1 [Djerida, Achraf; Zhao, Zhonghua; Zhao, Jiankang] Shanghai Jiao Tong Univ, Dept Instrument Sci & Engn, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Djerida, Achraf] Ctr Tech Spatiales, Agence Spatiale Algerienne, Arzew, Algeria.
C3 Shanghai Jiao Tong University; Algerian Space Agency (ASAL)
RP Zhao, ZH (corresponding author), Shanghai Jiao Tong Univ, Dept Instrument Sci & Engn, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM zhaozh@sjtu.edu.cn
RI Djerida, Achraf/AGW-9944-2022
OI Djerida, Achraf/0000-0001-5276-9362
CR Aanæs H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2010, 3 U MAL
   Arróspide J, 2013, IEEE T IMAGE PROCESS, V22, P2286, DOI 10.1109/TIP.2013.2249080
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Carrillo L.R.G., 2012, QUAD ROTORCRAFT CONT
   Cordes K, 2013, LECT NOTES COMPUT SC, V8047, P327, DOI 10.1007/978-3-642-40261-6_39
   Gebre-Egziabher D, 2004, IEEE T AERO ELEC SYS, V40, P627, DOI 10.1109/TAES.2004.1310010
   Gevrekci M, 2009, COMPUT VIS IMAGE UND, V113, P565, DOI 10.1016/j.cviu.2008.11.006
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Jinhuan Wang, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P2605, DOI 10.1109/IMCEC.2018.8469308
   Kao PY, 2019, LECT NOTES COMPUT SC, V11384, P128, DOI 10.1007/978-3-030-11726-9_12
   Kovesi P.D., 2000, MATLAB and Octave Functions for Computer Vision and Image Processing
   Lad H, 2017, ADV INTELL SYST, V508, P344, DOI 10.1007/978-981-10-2750-5_36
   Lakemond R, 2012, J MATH IMAGING VIS, V44, P150, DOI 10.1007/s10851-011-0317-8
   Lei Chen, 2010, 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1183, DOI 10.1109/ROBIO.2010.5723496
   Lenc Karel., 2012, VLBenchmarks
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li JY, 2020, IEEE T IMAGE PROCESS, V29, P3296, DOI 10.1109/TIP.2019.2959244
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mikolajczyk K., 2004, AFFINE COVARIANT FEA
   Nunes CFG, 2017, IEEE GEOSCI REMOTE S, V14, P1850, DOI 10.1109/LGRS.2017.2738632
   Peng X, 2017, IEEE T NEUR NET LEAR, V28, P791, DOI 10.1109/TNNLS.2016.2536741
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salibian-Barrera M, 2006, J COMPUT GRAPH STAT, V15, P414, DOI 10.1198/106186006X113629
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Truong Mai Thanh Nhat, 2016, P KOR INF PROC SOC C, P677
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165
   Wang YL, 2016, PROCEEDINGS OF 2016 SICE INTERNATIONAL SYMPOSIUM ON CONTROL SYSTEMS (ISCS 2016), P23, DOI 10.1109/SICEISCS.2016.7470176
   Yamaguchi K, 2013, COLLECTION DEV KIT M
   Yan H, 2015, AER ADV ENG RES, V20, P245
   Yang P, 2018, IEEE ACCESS, V6, P13336, DOI 10.1109/ACCESS.2018.2797072
   Yussof WNJHW, 2014, DIGIT SIGNAL PROCESS, V25, P190, DOI 10.1016/j.dsp.2013.10.011
   Zhang J, 2018, J VIS COMMUN IMAGE R, V55, P540, DOI 10.1016/j.jvcir.2018.07.007
   Zhang Q, 2019, J VIS COMMUN IMAGE R, V59, P415, DOI 10.1016/j.jvcir.2019.01.034
   Zhang Y, 2019, J VIS COMMUN IMAGE R, V59, P501, DOI 10.1016/j.jvcir.2019.02.007
NR 41
TC 2
Z9 2
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103258
DI 10.1016/j.jvcir.2021.103258
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800001
DA 2024-07-18
ER

PT J
AU Singh, K
   Parihar, AS
AF Singh, Kavinder
   Parihar, Anil Singh
TI Variational optimization based single image dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image dehazing; Transmission; Atmospheric light; Haze
ID VISIBILITY; HAZE
AB In this paper, we present a new approach for single image dehazing based on the proposed variational optimization. A hazy image captures the information about haze in terms of the transmission map and object details present in it. We propose to estimate the initial transmission map by performing the structure-aware smoothing of the hazy image. Further, we formulated a variational optimization for the estimation of final transmission, which refines the initial transmission of a hazy image. Atmospheric light can be considered to be constant throughout the scene for practical purposes. The uniform atmospheric light is computed from the dark channel of a hazy image. The exhaustive experimentation shows that the performance of the proposed method is comparable or better.
C1 [Singh, Kavinder; Parihar, Anil Singh] Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
C3 Delhi Technological University
RP Parihar, AS (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
EM parihar.anil@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671; Singh,
   Kavinder/0000-0002-2278-5270
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti CO, 2010, IEEE IMAGE PROC, P3541, DOI 10.1109/ICIP.2010.5651263
   [Anonymous], 2019, COMPUTER VISION ACCV
   Aridoss M, 2020, INT J GRID HIGH PERF, V12, P88, DOI 10.4018/IJGHPC.2020070106
   Babu GH, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jveir.2020.102912
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen MY, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105508
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Galdran A, 2018, PROC CVPR IEEE, P8212, DOI 10.1109/CVPR.2018.00857
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Ghosh S, 2020, IEEE T CIRC SYST VID, V30, P2015, DOI 10.1109/TCSVT.2019.2916589
   Gibson KB, 2011, INT CONF ACOUST SPEE, P1253
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Jain G., 2020, IEEE T COGN DEV SYST, P1
   Kaur M, 2020, INFORM SCIENCES, V521, P326, DOI 10.1016/j.ins.2020.02.048
   Koschmieder H, 1938, NATURWISSENSCHAFTEN, V26, P521, DOI 10.1007/BF01774261
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Lin GC, 2020, PRECIS AGRIC, V21, P160, DOI 10.1007/s11119-019-09662-w
   Lin ZC, 2011, PROG MOL BIOL TRANSL, V98, P1, DOI 10.1016/B978-0-12-385506-0.00001-6
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   McCartney E.J., 1976, Optics of the atmosphere: Scattering by molecules and particles, P421
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Parida A., 2020, 2020 5 IEEE INT C, P1, DOI [10.1109/PIICON49524.2020.9113018, DOI 10.1109/ICRAIE51050.2020.9358304]
   Parihar A.S., 2020, 2020 5 INT C COMM EL, P766
   Parihar AS, 2021, IET IMAGE PROCESS, V15, P1410, DOI 10.1049/ipr2.12114
   Parihar AS, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P619, DOI 10.1109/ICISC.2018.8398874
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shwartz S., 2006, 2006 IEEE COMP SOC C, V2, P1984, DOI DOI 10.1109/CVPR.2006.71
   Singh D, 2019, APPL INTELL, V49, P4276, DOI 10.1007/s10489-019-01504-6
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P9595, DOI 10.1007/s11042-017-5321-6
   Singh S., 2020, 2020 11 INT C COMPUT, P1, DOI DOI 10.1109/ICCCNT49239.2020.9225687
   Sulami M, 2014, IEEE INT CONF COMPUT
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tang YC, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00510
   Tang YC, 2019, ROBOT CIM-INT MANUF, V59, P36, DOI 10.1016/j.rcim.2019.03.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P3014, DOI 10.1109/TMM.2020.2967645
   Yin J, 2020, ADV CIV ENG, V2020, DOI 10.1155/2020/8890562
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 54
TC 11
Z9 11
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103241
DI 10.1016/j.jvcir.2021.103241
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800004
DA 2024-07-18
ER

PT J
AU Shao, H
   Wang, YX
AF Shao, Hang
   Wang, Yongxiong
TI Generative image inpainting with salient prior and relative total
   variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; GAN; Corruption recognition; Salient prior; Relative
   total variation
ID NETWORK
AB Image inpainting is an important research direction of image processing. The generative adversarial network (GAN), which can reconstruct new reasonable content in the corrupted region, is the most interesting tool in current inpainting technologies. However, the previous deep methods generally need to be pre-added the binary mask representing the corruption location as the extra input. A novel inpainting algorithm which does not require additional external labels is proposed in this paper. The algorithm consists of two parts: corruption recognition module and content inpainting module, which can recognize and fill random corruption. In the recognizer, the salient object from the uncorrupted region is used as the prior for distinguishing corruption. In the inpainting module, a two-stage network is applied to reconstruct the image from coarse content to texture details. To avoid the misdetection in recognition which has a negative impact on the restoration in inpainting, we perform relative total variational filtering on the corrupted image, and use the salient map as the supervision of detail reconstruction. Qualitative and quantitative experiments on multiple datasets verify the effectiveness of our recognition module, the competitive advantage of our inpainting module, and the enlightening significance of our total algorithm in image inpainting.
C1 [Shao, Hang; Wang, Yongxiong] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Shao, H (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM 932390809@qq.com; wyxiong@usst.edu.cn
RI Yuan, Yu/KBQ-0606-2024
OI Shao, Hang/0000-0002-2452-6985; Shao, Hang/0000-0002-1322-4789
FU National Natural Science Foundation of China [61673276]
FX This research is supported by the National Natural Science Foundation of
   China under Grant 61673276.
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Chan TF, 2005, COMMUN PUR APPL MATH, V58, P579, DOI 10.1002/cpa.20075
   Chen K, 2024, INT J LOGIST-RES APP, V27, P428, DOI [10.1080/13675567.2021.1940112, 10.1007/s12262-021-02908-w]
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chen YT, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02778-2
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Thanh DNH, 2021, SIGNAL PROCESS, V178, DOI 10.1016/j.sigpro.2020.107797
   Ding D, 2019, IEEE T IMAGE PROCESS, V28, P1705, DOI 10.1109/TIP.2018.2880681
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helbert D., 2019, J VIS COMMUN IMAGE R
   Hoeltgen L, 2019, APPL MATH-CZECH, V64, P281, DOI 10.21136/AM.2019.0206-18
   Hu CF, 2020, IEEE T IND ELECTRON, V67, P10922, DOI 10.1109/TIE.2019.2962437
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jam J, 2021, IEEE WINT CONF APPL, P2713, DOI 10.1109/WACV48630.2021.00276
   Jam J, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103147
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li JY, 2019, IEEE I CONF COMP VIS, P5961, DOI 10.1109/ICCV.2019.00606
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu Y, 2019, LECT NOTES COMPUT SC, V11935, P128, DOI 10.1007/978-3-030-36189-1_11
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Miyato T, 2018, INT C LEARN REPR
   Nazeri K., 2019, ARXIV190100212
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pen HB, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106722
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shao H, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115929
   Shin YG, 2021, IEEE T NEUR NET LEAR, V32, P252, DOI 10.1109/TNNLS.2020.2978501
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang NI, 2021, IEEE T IMAGE PROCESS, V30, P3720, DOI 10.1109/TIP.2021.3064268
   Wang N, 2021, IEEE T IMAGE PROCESS, V30, P1784, DOI 10.1109/TIP.2020.3048629
   Wang N, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107448
   Wang WZ, 2022, IEEE T IND INFORM, V18, P7059, DOI 10.1109/TII.2021.3084753
   Wang Y., 2020, EUR C COMP VIS
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Yang C, 2017, PROC CVPR IEEE, P4076, DOI 10.1109/CVPR.2017.434
   Yi Z., 2020, CVPR, P7508
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zhang YL, 2020, NEUROCOMPUTING, V396, P1, DOI 10.1016/j.neucom.2020.01.068
   Zhang Z., 2020, J VIS COMMUN IMAGE R
   Zhao L, 2020, PROC CVPR IEEE, P5740, DOI 10.1109/CVPR42600.2020.00578
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 54
TC 3
Z9 4
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103231
DI 10.1016/j.jvcir.2021.103231
EA JUL 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800002
DA 2024-07-18
ER

PT J
AU Bediako, DO
   Mou, XQ
AF Bediako, Daniel Oppong
   Mou, Xuanqin
TI Joint model of gradient magnitude and Gabor features via Spatio-Temporal
   slice
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Full-reference (FR) video quality assessment; Gradient magnitude; Gabor
   filter
ID BLIND QUALITY ASSESSMENT; IMAGE; SIMILARITY
AB To form a high-performance video quality predictor, we developed a framework for full-reference (FR) video quality assessment that integrates Spatio-temporal slice analysis (STS) to create a high-performance predictor of video quality. However, both gradient and Gabor are spatial-temporal structural capturers used for the simultaneous extraction of both spatial and temporal features. In this paper, we proposed a novel VQA algorithm via a joint model of gradient magnitude and Gabor features (JMG) between the STS images of the reference videos and their distorted counterparts to assess the degradation of video quality effectively. Firstly, gradient magnitude and the Gabor filter were constructed to extract the spatiotemporal features of the video sequence. However, the two-feature model combined to predict the perceptual quality of frames. This new proposed VQA model is known as the horizontal and time STS (HT-JMG) model. To further investigate the influence of spatial dissimilarity, we combined the frame-by-frame spatial T-JMG(S) factor with the HT-JMG and propose another VQA model, called the time, horizontal, and vertical STS (THV-JMG) model. Finally, the results of the experiment showed that the proposed method has a strong correlation with subjective perception and is competitive with state-of-the-art full reference VQA models.
C1 [Bediako, Daniel Oppong; Mou, Xuanqin] Xi An Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Mou, XQ (corresponding author), Xi An Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Xian, Peoples R China.
EM xqmou@mail.xjtu.edu
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   [Anonymous], 2005, 1 INT WORKSHOP VIDEO
   [Anonymous], FINAL REPORT VIDEO Q
   Bovik A.C., 2009, ESSENTIAL GUIDE IMAG
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen G.H., 2006, P INT C ACOUSTICS SP, V2, pII
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   De Simone F, 2010, INT CONF ACOUST SPEE, P2430, DOI 10.1109/ICASSP.2010.5496296
   De Simone F, 2009, INT WORK QUAL MULTIM, P204, DOI 10.1109/QOMEX.2009.5246952
   Freitas PG, 2018, SIGNAL PROCESS-IMAGE, V64, P1, DOI 10.1016/j.image.2018.02.010
   Girod B., 1991, P 7 WORKSH MULT SIGN, pP, DOI [10.1109/MDSP.1991.639240, DOI 10.1109/MDSP.1991.639240]
   Gu K, 2017, IEEE T IND ELECTRON, V64, P3903, DOI 10.1109/TIE.2017.2652339
   Huang SY, 2018, IEEE T IMAGE PROCESS, V27, P2650, DOI 10.1109/TIP.2018.2809472
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Laboratory of Computational Perception & Image Quality Oklahoma State University, 2013, CSIQ VID DAT
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li CF, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267087
   Li J, 2016, SIGNAL IMAGE VIDEO P, V10, P609, DOI 10.1007/s11760-015-0784-2
   Min XK, 2019, IEEE T INTELL TRANSP, V20, P2879, DOI 10.1109/TITS.2018.2868771
   Min XK, 2018, IEEE T MULTIMEDIA, V20, P2049, DOI 10.1109/TMM.2017.2788206
   Min XK, 2020, IEEE T IMAGE PROCESS, V29, P3790, DOI 10.1109/TIP.2020.2966081
   Min XK, 2019, IEEE T MULTIMEDIA, V21, P2319, DOI 10.1109/TMM.2019.2902097
   Min XK, 2018, IEEE T BROADCAST, V64, P508, DOI 10.1109/TBC.2018.2816783
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Moorthy A.K., 2009, **DATA OBJECT**, V7240
   Moorthy AK, 2010, PROC SPIE, V7527, DOI 10.1117/12.844198
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Narwaria M, 2012, IEEE T MULTIMEDIA, V14, P525, DOI 10.1109/TMM.2012.2190589
   Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890
   Pinson MH, 2013, IEEE INT WORKSH MULT, P458, DOI 10.1109/MMSP.2013.6659332
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Recommendation ITU-R BT, 2012, 1907 OBJ PERC VID QU, V26
   Serral-Gracià R, 2010, LECT NOTES COMPUT SC, V6074, P252
   Seshadrinathan K, 2010, PROC SPIE, V7527, DOI 10.1117/12.845382
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P335, DOI 10.1109/TIP.2009.2034992
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Simonyan K., 2014, CORR
   Vu PV, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.013016
   Wang SQ, 2018, IEEE COMPUT GRAPH, V38, P47, DOI 10.1109/MCG.2016.46
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Watson A.B., 1983, MOTION REPRESENTATIO
   Wolf S, 1999, P SOC PHOTO-OPT INS, V3845, P266, DOI 10.1117/12.371210
   Xu ZL, 2018, I C COMM SOFTW NET, P531, DOI 10.1109/ICCSN.2018.8488246
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yan P, 2019, PROC SPIE, V11187, DOI 10.1117/12.2536872
   Yan P, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.3.033019
   Yang AS, 2017, MULTIDIM SYST SIGN P, V28, P1249, DOI 10.1007/s11045-016-0395-2
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhai GT, 2019, DIGIT SIGNAL PROCESS, V91, P11, DOI 10.1016/j.dsp.2019.02.017
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
NR 57
TC 1
Z9 1
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103204
DI 10.1016/j.jvcir.2021.103204
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900006
DA 2024-07-18
ER

PT J
AU Xie, YF
   Zheng, JB
   Hou, X
   Xi, Y
   Tian, FM
AF Xie, Yefan
   Zheng, Jiangbin
   Hou, Xuan
   Xi, Yue
   Tian, Fengming
TI Dynamic Dual-Peak Network: A real-time human detection network in
   crowded scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anchor free; Crowded scenes; CNN; Human detection
ID NMS
AB Human detection in crowded scenes is challenging since the objects occlude and overlap each other. Compared to general pedestrian detection, there is also more variation in human posture. This paper proposes a real-time human detection network, Dynamic Dual-Peak Network (DDPNet), which specifically addresses human object detection in overlapping and crowded scenes. We design a deep cascade fusion module to enhance the feature extraction capability of the anchor-free model for small objects in crowded scenes. In the meantime, the head-body dual-peak activation module is used to improve the prediction score of the central region of the occluded individual through low occlusion components. By this improvement strategy, the network's ability is enhanced to discriminate individuals in crowded scenes and alleviate the problem caused by individual posture variation. Ultimately, we propose a novel Exhale-Inhale method to adjust the feature mapping ranges for various scale objects dynamically. In the process of ground truth mapping, the overlapping of individual feature information is reduced. Our DDPNet achieves competitive performance on the CrowdHuman dataset and executes real-time inference of almost 3x-7x faster than competitive methods.
C1 [Zheng, Jiangbin] Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
   Shaanxi Prov Key Lab Speech & Image Informat Proc, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Zheng, JB (corresponding author), Northwestern Polytech Univ, Sch Comp Sci & Engn, Xian 710072, Peoples R China.
EM zhengjb@nwpu.edu.cn
OI xie, yefan/0000-0001-9389-8902
FU National Natural Science Foundation of China [61972321]
FX This work was supported by National Natural Science Foundation of China,
   under Project 61972321.
CR [Anonymous], 2019, ARXIV PREPRINT ARXIV
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen K., 2019, arXiv preprint arXiv:1906.07155
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Dai Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.007
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Huang L., 2015, Comput. Sci.
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li RD, 2019, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR.2019.00292
   Lin CZ, 2018, LECT NOTES COMPUT SC, V11213, P745, DOI 10.1007/978-3-030-01240-3_45
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu ST, 2019, PROC CVPR IEEE, P6452, DOI 10.1109/CVPR.2019.00662
   Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38
   Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901
   Liu ZL, 2020, AAAI CONF ARTIF INTE, V34, P11685
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Nam W., 2014, ARXIV PREPRINT ARXIV
   Pang YW, 2019, IEEE I CONF COMP VIS, P4966, DOI 10.1109/ICCV.2019.00507
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shao S., 2018, CROWDHUMAN BENCHMARK
   Song T, 2018, LECT NOTES COMPUT SC, V11211, P554, DOI 10.1007/978-3-030-01234-2_33
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Wang ZW, 2020, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR42600.2020.00212
   Zhang, 2019, ARXIV PREPRINT ARXIV
   Zhang LL, 2016, LECT NOTES COMPUT SC, V9906, P443, DOI 10.1007/978-3-319-46475-6_28
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang SS, 2016, PROC CVPR IEEE, P1259, DOI 10.1109/CVPR.2016.141
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zhou CL, 2018, LECT NOTES COMPUT SC, V11205, P138, DOI 10.1007/978-3-030-01246-5_9
   Zhou K, 2016, DESTECH TRANS COMP
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 45
TC 3
Z9 3
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103195
DI 10.1016/j.jvcir.2021.103195
EA JUL 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100005
DA 2024-07-18
ER

PT J
AU Guo, JT
   Liu, Y
AF Guo, Jingtao
   Liu, Yi
TI Facial parts swapping with generative adversarial networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial parts swapping; Generative adversarial network; Deep leaning
AB In this paper, we present a novel deep generative facial parts swapping method: parts-swapping generative adversarial network (PSGAN). PSGAN independently handles facial parts, such as eyes (left eye and right eye), nose, mouth and jaw, which achieves facial parts swapping by replacing the target facial parts with source facial parts and reconstructing the entire face image with these parts. By separately modeling the facial parts in the form of region inpainting, the proposed method can successfully achieve highly photorealistic face swapping results, enabling users to freely manipulate facial parts. In addition, the proposed method is able to perform jaw editing based on sketch guidance information. Experimental results on the CelebA dataset suggest that our method achieves superior performance for facial parts swapping and provides higher user control flexibility.
C1 [Guo, Jingtao; Liu, Yi] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Sch Comp & Informat Technol, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Liu, Y (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM yiliu@bjtu.edu.cn
FU Natural Science Foundation of China [61300072, 31771475]
FX The authors acknowledge support from the Natural Science Foundation of
   China (No.61300072, 31771475) .
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Alexander O, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P176, DOI 10.1109/CVMP.2009.29
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2005, BMVC 2005 P BRIT MAC
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bao JM, 2017, IEEE I CONF COMP VIS, P2764, DOI 10.1109/ICCV.2017.299
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bitouk D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360638
   Chou JK, 2012, MULTIMED TOOLS APPL, V56, P569, DOI 10.1007/s11042-010-0624-x
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Kemelmacher-Shlizerman I, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925871
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Li M., 2016, THESIS CENTRAL S U
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mosaddegh S, 2015, LECT NOTES COMPUT SC, V9005, P159, DOI 10.1007/978-3-319-16811-1_11
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Seidel H.P., 2010, COMPUT GRAPH FORUM, V23, P669
   Shen W, 2017, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR.2017.135
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yuan L., 2012, IEEE INT C MULT EXP
   Zhou Shuchang, 2017, BMVC
   Zhuang BH, 2017, PROC CVPR IEEE, P2915, DOI 10.1109/CVPR.2017.311
NR 27
TC 3
Z9 3
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103152
DI 10.1016/j.jvcir.2021.103152
EA MAY 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1LJ
UT WOS:000674616200001
DA 2024-07-18
ER

PT J
AU Khalid, H
   Ali, M
   Ahmed, N
AF Khalid, Hassan
   Ali, Muhammad
   Ahmed, Nisar
TI Gaussian Process-based Feature-Enriched Blind Image Quality Assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment (IQA); No-reference (NR); Natural scene
   statistics; Feature selection; Gaussian process regression; Blind image
   quality assessment (BIQA)
ID NATURAL SCENE STATISTICS; SELECTION; DATABASE
AB The objective of blind-image quality assessment (BIQA) research is the prediction of perceptual quality of images, without reference information. The human's perceptual assessment of quality of an image is the backbone of BIQA research. Therefore, human-provided, mean opinion score (perceptual quality) has been analyzed in detail, and it has been observed to follow the Gaussian distribution and thus can be ideally modeled by the same. In this paper, we have proposed an integrated two-stage Gaussian process-based hybrid-feature selection algorithm for the BIQA problem. Moreover, a new consolidated feature set (obtained from the proposed algorithm), consisting of momentous Natural Scene Statistics (NSS)-based features is used in combination with the Gaussian process regression algorithm for the design of a new blind-image quality evaluator, referred to as GPR-BIQA. The proposed evaluator is tested on eight IQA legacy databases, and it is found that the proposed evaluator proficiently correlate with the human opinion, and outperformed a substantial number of existing approaches.
C1 [Khalid, Hassan; Ali, Muhammad] Univ Engn & Technol, Dept Elect Engn, Lahore 54890, Pakistan.
   [Ahmed, Nisar] Univ Engn & Technol, Dept Comp Engn, Lahore 54890, Pakistan.
C3 University of Engineering & Technology Lahore; University of Engineering
   & Technology Lahore
RP Khalid, H (corresponding author), Univ Engn & Technol, Dept Elect Engn, Lahore 54890, Pakistan.
EM engr_hassan09@ymail.com; m.ali@uet.edu.pk; nisarahmedrana@yahoo.com
RI Ahmad, Nisar/IAQ-3092-2023; Ahmed, Nisar/AAX-5519-2020
OI Ahmed, Nisar/0000-0002-6397-4860; Khalid, Hassan/0000-0002-5861-4377;
   Ali, Muhammad/0000-0002-0569-8087
CR [Anonymous], 2010, Categorical image quality (CSIQ) database
   [Anonymous], 1992, R. woods digital image processing
   Bankert R. L, 1996, LEARNING DATA ARTIFI, P199, DOI [DOI 10.1007/978-1-4612-2404-4_19, 10.1007/978-1-4612-2404-4_19]
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bovik Alan C, 2010, Handbook of image and video processing
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Ghadiyaram D., 2017, LIVE WILD IMAGE QUAL
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Gu K, 2013, IEEE INT SYMP CIRC S, P1095, DOI 10.1109/ISCAS.2013.6572041
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   HURVICH LM, 1957, PSYCHOL REV, V64, P384, DOI 10.1037/h0041403
   Ji WP, 2019, IEEE ACCESS, V7, P30925, DOI 10.1109/ACCESS.2019.2901063
   Kundu D, 2016, CONF REC ASILOMAR C, P1847, DOI 10.1109/ACSSC.2016.7869704
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Lim CL, 2016, J FRANKLIN I, V353, P4715, DOI 10.1016/j.jfranklin.2016.08.012
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Somol P., 2010, PATTERN RECOGN
   Ten Daubechies I., 1992, lecture on wavelets
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Yue GH, 2017, J VIS COMMUN IMAGE R, V49, P382, DOI 10.1016/j.jvcir.2017.09.011
   Zhang H, 2013, AEU-INT J ELECTRON C, V67, P799, DOI 10.1016/j.aeue.2013.04.001
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang Y, 2014, SIGNAL PROCESS-IMAGE, V29, P725, DOI 10.1016/j.image.2014.05.004
NR 49
TC 6
Z9 6
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
DI 10.1016/j.jvcir.2021.1030922019
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TM2UA
UT WOS:000675405700002
DA 2024-07-18
ER

PT J
AU Zhang, CJ
   Wang, DH
   Li, HS
AF Zhang, Chunjie
   Wang, Da-Han
   Li, Haisheng
TI Discriminative semantic region selection for fine-grained recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained recognition; Discriminative region selection; Semantic
   correlation; Object categorization
ID IMAGE CLASSIFICATION; REPRESENTATION
AB Performances of fine-grained recognition have been greatly improved thanks to the fast developments of deep convolutional neural networks (DCNN). DCNN methods often treat each image region equally. Besides, researchers often rely on visual information for classification. To solve these problems, we propose a novel discriminative semantic region selection method for fine-grained recognition (DSRS). We first select a few image regions and then use the pre-trained DCNN models to predict their semantic correlations with corresponding classes. We use both visual and semantic representations to represent image regions. The visual and semantic representations are then linearly combined for joint representation. The combination parameters are determined by considering both semantic distinctiveness and spatial-semantic correlations. We use the joint representations for classifier training. A testing image can be classified by obtaining the visual and semantic representations and encoded for joint representation and classification. Experiments on several publicly available datasets demonstrate the proposed method's superiority.
C1 [Zhang, Chunjie] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Zhang, Chunjie; Li, Haisheng] Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
   [Zhang, Chunjie] Beijing Jiaotong Univ, Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
   [Wang, Da-Han] Xiamen Univ Technol, Xiamen Engn Res Ctr Intelligent Traff Guidance Te, Sch Comp & Informat Engn, Xiamen 361024, Fujian, Peoples R China.
C3 Beijing Jiaotong University; Beijing Technology & Business University;
   Beijing Jiaotong University; Xiamen University of Technology
RP Li, HS (corresponding author), Beijing Technol & Business Univ, Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.; Wang, DH (corresponding author), Xiamen Univ Technol, Xiamen Engn Res Ctr Intelligent Traff Guidance Te, Sch Comp & Informat Engn, Xiamen 361024, Fujian, Peoples R China.
EM cjzhang@bjtu.edu.cn; wangdh@xmut.edu.cn; lihsh@btbu.edu.cn
RI LI, Haisheng/AAM-5232-2020
OI LI, Haisheng/0000-0003-4861-0513
FU National Natural Science Foundation of China [62072026]; Beijing Natural
   Science Foundation [JQ20022]; Open Research Fund of Beijing Key
   Laboratory of Big Data Technology for Food Safety, Beijing Technology
   and Business University; Natural Science Foundation of China [61773325,
   61806173]; Natural Science Foundation of Fujian Province [2019J05123]
FX This work is supported by National Natural Science Foundation of China:
   62072026; Beijing Natural Science Foundation: JQ20022; the Open Research
   Fund of Beijing Key Laboratory of Big Data Technology for Food Safety,
   Beijing Technology and Business University. This work is also in part
   supported by Natural Science Foundation of China under Grants 61773325,
   and 61806173, and Natural Science Foundation of Fujian Province under
   Grants 2019J05123.
CR [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], ARXIV14094842
   [Anonymous], ARXIV151205227
   [Anonymous], ARXIV14062952
   Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Han W, 2020, INFORM SCIENCES, V539, P177, DOI 10.1016/j.ins.2020.06.018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XT, 2019, IEEE T CIRC SYST VID, V29, P1394, DOI 10.1109/TCSVT.2018.2834480
   He XT, 2017, PROC CVPR IEEE, P7332, DOI 10.1109/CVPR.2017.775
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lam M, 2017, PROC CVPR IEEE, P6497, DOI 10.1109/CVPR.2017.688
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Liu Xiao., 2016, CoRR abs/1603.06765
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pan YS, 2019, IEEE T IMAGE PROCESS, V28, P4716, DOI 10.1109/TIP.2019.2908795
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shapiro L.G., 2003, Computer Vision, Vsecond
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Xie NH, 2010, PROC CVPR IEEE, P2313, DOI 10.1109/CVPR.2010.5539917
   Xu Z, 2018, IEEE T PATTERN ANAL, V40, P1100, DOI 10.1109/TPAMI.2016.2637331
   Zhang CJ, 2019, IEEE T NEUR NET LEAR, V30, P1013, DOI 10.1109/TNNLS.2018.2856096
   Zhang CJ, 2018, IEEE T CIRC SYST VID, V28, P428, DOI 10.1109/TCSVT.2016.2613125
   Zhang CJ, 2018, IEEE T CYBERNETICS, V48, P2012, DOI 10.1109/TCYB.2017.2726079
   Zhang CJ, 2017, IEEE T CIRC SYST VID, V27, P1691, DOI 10.1109/TCSVT.2016.2527380
   Zhang CJ, 2017, IEEE T NEUR NET LEAR, V28, P1550, DOI 10.1109/TNNLS.2016.2545112
   Zhang CJ, 2017, INFORM SCIENCES, V376, P125, DOI 10.1016/j.ins.2016.10.019
   Zhang CJ, 2016, INFORM SCIENCES, V369, P160, DOI 10.1016/j.ins.2016.06.029
   Zhang CJ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2485783
   Zhang CJ, 2014, NEUROCOMPUTING, V142, P248, DOI 10.1016/j.neucom.2014.03.059
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
NR 45
TC 1
Z9 1
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 103084
DI 10.1016/j.jvcir.2021.103084
EA MAR 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SF9SQ
UT WOS:000653087000004
DA 2024-07-18
ER

PT J
AU Kumar, M
   Singh, N
   Kumar, R
   Goel, S
   Kumar, K
AF Kumar, Munish
   Singh, Navdeep
   Kumar, Ravinder
   Goel, Shubham
   Kumar, Krishan
TI Gait recognition based on vision systems: A systematic survey
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gait recognition; Surveillance; Biometric; Person identification
ID CLASSIFICATION; EXTRACTION; VIDEO
AB With the growing popularity of biometrics technology in the pattern recognition field, especially identification of human has gained the attention of researchers from both academia and industry. One such type of biometric technique is Gait recognition, which is used to identify a human being based on their walking style. Generally, two types of approaches are adopted by any algorithm designed for gait recognition, namely model based and model free approaches. The key reason behind the popularity of gait recognition is that it can identify a person from a considerable distance while other biometrics has failed to do so. In this paper, the authors have conducted a survey of extant studies on gait recognition in consideration of gait recognition approaches and phases of a gait cycle. Moreover, some aspects like floor sensors, accelerometer based recognition, the influences of environmental factors, which are ignored by exiting surveys, are also covered in our survey study. The information of gait is usually obtained from different parts of silhouettes. This paper also describes different benchmark datasets for gait recognition. This study will provide firsthand knowledge to the researchers working on the gait recognition domain in any real-world field. It has been observed that work done on the gait recognition with sufficiently high accuracy is limited in comparison to research on various other biometric recognition systems and has enough potential for future research.
C1 [Kumar, Munish] Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Singh, Navdeep] Punjabi Univ, Dept Comp Sci & Engn, Univ Coll Engn, Patiala, Punjab, India.
   [Kumar, Ravinder; Goel, Shubham] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Kumar, Krishan] Panjab Univ, Univ Inst Engn & Technol, Dept Informat Technol, Chandigarh, India.
C3 Punjabi University; Thapar Institute of Engineering & Technology; Panjab
   University
RP Kumar, M (corresponding author), Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Krishan/F-6049-2016; Kumar, Ravinder/JLL-7567-2023; Singh,
   Navdeep/AAM-3038-2021; Kumar, Munish/P-7756-2018
OI Kumar, Krishan/0000-0001-9877-0238; Kumar, Ravinder/0000-0002-0271-2373;
   Singh, Navdeep/0000-0003-3874-9052; Kumar, Munish/0000-0003-0115-1620;
   Goel, Shubham/0000-0002-9039-0879
CR Bae J, 2011, MECHATRONICS, V21, P961, DOI 10.1016/j.mechatronics.2011.03.003
   Begg R, 2005, J BIOMECH, V38, P401, DOI 10.1016/j.jbiomech.2004.05.002
   Beleznai C., 2007, P 6 ACM INT C IM VID, P105, DOI [10.1145/1282280.1282297, DOI 10.1145/1282280.1282297]
   Bouchrika I, 2009, LECT NOTES COMPUT SC, V5558, P990, DOI 10.1007/978-3-642-01793-3_100
   Bouchrika I., 2008, 8th IEEE International Conference on Automatic Face Gesture Recognition, P1, DOI [10.1109/AFGR.2008.4813395., DOI 10.1109/AFGR.2008.4813395]
   Boulgouris NV, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P263
   Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114
   Chattopadhyay P, 2014, J VIS COMMUN IMAGE R, V25, P53, DOI 10.1016/j.jvcir.2013.02.010
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Dargan S, 2019, ARCH COMPUT METHOD E, V26, P1283, DOI 10.1007/s11831-018-9278-z
   Dedeoglu Y, 2006, LECT NOTES COMPUT SC, V3979, P64
   Dedeoglu Y, 2008, MULTIMED SYST APPL, P143, DOI 10.1007/978-0-387-76316-3_6
   Derawi M. O., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P306, DOI 10.1109/IIHMSP.2010.83
   Gafurov D, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P220, DOI 10.1109/AUTOID.2007.380623
   Hadid A, 2013, LECT NOTES COMPUT SC, V8157, P1, DOI 10.1007/978-3-642-41184-7_1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hong J, 2012, THESIS BRUNEL U SCH
   Huang PS, 2001, IEEE T SYST MAN CY B, V31, P818, DOI 10.1109/3477.956044
   Ioannidis D, 2007, IEEE T INF FOREN SEC, V2, P623, DOI 10.1109/TIFS.2007.902040
   Ismail A. P., 2012, 2012 IEEE 8th International Colloquium on Signal Processing & its Applications, P400, DOI 10.1109/CSPA.2012.6194757
   Kumar MSN, 2012, P 8 IND C COMP VIS G, P1
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Li YX, 2021, IEEE T CIRC SYST VID, V31, P2315, DOI 10.1109/TCSVT.2020.3023080
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Makhdoomi NA, 2013, IOP CONF SER-MAT SCI, V53, DOI 10.1088/1757-899X/53/1/012069
   Mäntyjärvi J, 2005, INT CONF ACOUST SPEE, P973
   Mazilu S., 2012, 2012 6th International Conference on Pervasive Computing Technologies for Healthcare, P123, DOI 10.4108/icst.pervasivehealth.2012.248680
   Middleton L, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P171, DOI 10.1109/AUTOID.2005.2
   Mu Y, 2010, NEUROCOMPUTING, V73, P895, DOI 10.1016/j.neucom.2009.09.017
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   Nirenberg M, 2018, SCI JUSTICE, V58, P292, DOI 10.1016/j.scijus.2018.03.002
   Nixon MS, 2006, P IEEE, V94, P2013, DOI 10.1109/JPROC.2006.886018
   Nowlan M.F, 2009, NETWORKED EMBEDDED S, P1
   Ongun MF, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102970
   Phillips P. J., 2002, Proceedings 2002 International Conference on Image Processing (Cat. No.02CH37396), pI, DOI 10.1109/ICIP.2002.1037956
   Pogorelc B, 2012, MULTIMED TOOLS APPL, V58, P333, DOI 10.1007/s11042-011-0786-1
   Procházka A, 2015, DIGIT SIGNAL PROCESS, V47, P169, DOI 10.1016/j.dsp.2015.05.011
   Roy A, 2015, IET COMPUT VIS, V9, P821, DOI 10.1049/iet-cvi.2014.0170
   Singh J. P., 2010, 2nd International Conference on Trendz in Information Sciences & Computing (TISC 2010), P248, DOI 10.1109/TISC.2010.5714649
   Singh JP, 2018, IEEE ACCESS, V6, P70497, DOI 10.1109/ACCESS.2018.2879896
   Sivapalan S, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Sundaresan A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P93
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Weber EF, 1992, MECH HUMAN WALKING A
   Whittle MW., 1993, GAIT ANAL SOFT TISSU, P187
   Yaacob N. I., 2012, 2012 IEEE Symposium on Humanities, Science and Engineering Research (SHUSER), P379, DOI 10.1109/SHUSER.2012.6268871
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang BL, 2009, PATTERN RECOGN, V42, P581, DOI 10.1016/j.patcog.2008.09.025
NR 53
TC 33
Z9 33
U1 4
U2 36
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103052
DI 10.1016/j.jvcir.2021.103052
EA FEB 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QS2SL
UT WOS:000625754300001
DA 2024-07-18
ER

PT J
AU Li, XX
   Xiao, J
   Zhou, YY
   Ye, YZ
   Lv, NZ
   Wang, XY
   Wang, SL
   Gao, SB
AF Li, Xiaoxia
   Xiao, Juan
   Zhou, Yingyue
   Ye, Yuanzheng
   Lv, Nianzu
   Wang, Xueyuan
   Wang, Shunli
   Gao, ShaoBing
TI Detail retaining convolutional neural network for image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Convolutional neural network; Detail retaining; Image
   restoration; Gaussian denoising
ID SPARSE REPRESENTATION; CNN; RESTORATION
AB Compared with the traditional image denoising method, although the convolutional neural network (CNN) has better denoising performance, there is an important issue that has not been well resolved: the residual image obtained by learning the difference between noisy image and clean image pairs contains abundant image detail information, resulting in the serious loss of detail in the denoised image. In this paper, in order to relearn the lost image detail information, a mathematical model is deducted from a minimization problem and an end-to-end detail retaining CNN (DRCNN) is proposed. Unlike most denoising methods based on CNN, DRCNN is not only focus to image denoising, but also the integrity of high frequency image content. DRCNN needs less parameters and storage space, therefore it has better generalization ability. Moreover, DRCNN can also adapt to different image restoration tasks such as blind image denoising, single image superresolution (SISR), blind deburring and image inpainting. Extensive experiments show that DRCNN has a better effect than some classic and novel methods. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Xiaoxia; Xiao, Juan; Zhou, Yingyue; Ye, Yuanzheng; Lv, Nianzu; Wang, Xueyuan; Wang, Shunli] Southwest Univ Sci & Technol, Sch Informat Engn, Robot Technol Used Special Environm Key Lab Sichu, Mianyang 621010, Sichuan, Peoples R China.
   [Gao, ShaoBing] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
C3 Southwest University of Science & Technology - China; Sichuan University
RP Li, XX; Zhou, YY (corresponding author), Southwest Univ Sci & Technol, Sch Informat Engn, Robot Technol Used Special Environm Key Lab Sichu, Mianyang 621010, Sichuan, Peoples R China.
EM 664368504@qq.com; zhouyingyue@swust.edu.cn
RI Wang, Shunli/AAR-6882-2020; Wang, Shunli/AAU-3174-2021
OI Wang, Shunli/0000-0003-0485-8082; 
FU National Natural Science Foundation of China [61401379]; Sichuan Science
   and Technology Program [2019YJ0449]; Postgraduate Innovation Fund of
   Southwest University of Science and Technology [18ycx121]
FX This research was supported by the National Natural Science Foundation
   of China (Grant Nos. 61771411); the Sichuan Science and Technology
   Program (Grant No. 2019YJ0449), the Postgraduate Innovation Fund of
   Southwest University of Science and Technology (Grant No. 18ycx121) and
   the National Natural Science Foundation of China (Grant No. 61401379).
   The authors would like to thank the anonymous reviewers for their
   valuable comments, which help to improve the quality of this paper.
CR Burger H.C., 2012, P IEEE INT C COMP VI
   Cha S., 2018, P IEEE INT C COMP VI, P4160
   Chen JW, 2018, PROC CVPR IEEE, P3155, DOI 10.1109/CVPR.2018.00333
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cho SI, 2019, IEEE T MULTIMEDIA, V21, P484, DOI 10.1109/TMM.2018.2859791
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Jain V., 2009, ADV NEURAL INFORM PR, P769, DOI DOI 10.5555/2981780.2981876
   Kang M, 2018, J VIS COMMUN IMAGE R, V54, P80, DOI 10.1016/j.jvcir.2018.04.010
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu Z, 2018, J VIS COMMUN IMAGE R, V52, P159, DOI 10.1016/j.jvcir.2018.02.011
   Lu XL, 2018, J VIS COMMUN IMAGE R, V55, P374, DOI 10.1016/j.jvcir.2018.05.021
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mao X., 2016, CoRR
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Su F, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P280, DOI 10.1109/ISCIT.2016.7751636
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tang YB, 2013, IEEE INT SYMP CIRC S, P2820, DOI 10.1109/ISCAS.2013.6572465
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Tian CW, 2019, CAAI T INTELL TECHNO, V4, P17, DOI 10.1049/trit.2018.1054
   Whyte O, 2012, INT J COMPUT VISION, V98, P168, DOI 10.1007/s11263-011-0502-7
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Zha Z., 2017, P IEEE INT C MULT EX
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhou YY, 2016, J VIS COMMUN IMAGE R, V41, P74, DOI 10.1016/j.jvcir.2016.09.007
NR 32
TC 22
Z9 23
U1 6
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102774
DI 10.1016/j.jvcir.2020.102774
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900019
DA 2024-07-18
ER

PT J
AU Zhang, C
   Liu, ST
   Li, HZ
AF Zhang, Chao
   Liu, Sitong
   Li, Huizi
TI Quality-guided video aesthetics assessment with social media context
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video aesthetic assessment; Structure correlation; SVM
ID SALIENCY DETECTION; SIMILARITY
AB Media aesthetic assessment is a key technique in computer vision, which is widely applied in computer game rendering, video/image classification. Low-level and high-level features fusion-based video aesthetic assessment algorithms have achieved impressive performance, which outperform photo- and motion-based algorithms, however, these methods only focus on aesthetic features of single-frame while ignore the inherent relationship between adjacent frames. Therefore, we propose a novel video aesthetic assessment framework, where structural cues among frames are well encoded. Our method consists of two components: aesthetic features extraction and structure correlation construction. More specifically, we incorporate both low-level and high-level visual features to construct aesthetic features, where salient regions are extracted for content understanding. Subsequently, we develop a structure correlation-based algorithm to evaluate the relationship among adjacent frames, where frames with similar structure property should have a strong correlation coefficient. Afterwards, a kernel multi-SVM is trained for video classification and high aesthetic video selection. Comprehensive experiments demonstrate the effectiveness of our method. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Zhang, Chao; Li, Huizi] Commun Univ China, Sch Mus & Recording Arts, Beijing, Peoples R China.
   [Liu, Sitong] Guilin Univ Aerosp Technol, Guilin, Peoples R China.
   [Li, Huizi] Cent Conservatory Mus, Beijing, Peoples R China.
C3 Communication University of China; Guilin University of Aerospace
   Technology; Central Conservatory of Music
RP Liu, ST (corresponding author), Guilin Univ Aerosp Technol, Guilin, Peoples R China.
EM liusitong@guat.edu.cn
RI Liu, Sisi/JBJ-5042-2023
FU Youth Fund for Humanities and Social Sciences Research of the Ministry
   of Education: "Research on the Audience Communication of Internet Rumors
   in the age of Big Data" [18YJC860021]
FX This work was supported by the Youth Fund for Humanities and Social
   Sciences Research of the Ministry of Education: "Research on the
   Audience Communication of Internet Rumors in the age of Big
   Data"(Project number: 18YJC860021).
CR [Anonymous], Categorical image quality (CSIQ) database
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Battisti F., 2009, P 4 INT WORKSH VID P
   Chen G.H., 2006, 2006 IEEE INT C AC S
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Mei T, 2007, IEEE T CIRC SYST VID, V17, P699, DOI 10.1109/TCSVT.2007.896640
   Meylan L, 2006, IEEE T IMAGE PROCESS, V15, P2820, DOI 10.1109/TIP.2006.877312
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, SIGNALS COMMUN TECHN, P3, DOI 10.1007/978-3-642-12802-8_1
   Ninassi A, 2006, PROC SPIE, V6057, DOI 10.1117/12.650780
   Ramachandran V. S., 1999, Journal of Consciousness Studies, V6, P15
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Sheikh H. R., IMAGE VIDEO QUALITY
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shi YY, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P329, DOI 10.1109/ICECT.2009.116
   Simond F, 2015, P INT C IM PROC ICIP
   Wang JY, 2015, IEEE IMAGE PROC, P2915, DOI 10.1109/ICIP.2015.7351336
   Wang Y., 2013, Proceedings of the 21st ACM international conference on Multimedia, P369
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang CY, 2011, INT CONF ACOUST SPEE, P1165
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 29
TC 0
Z9 0
U1 6
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102643
DI 10.1016/j.jvcir.2019.102643
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900020
DA 2024-07-18
ER

PT J
AU Zhao, YF
   Song, Y
   Li, X
   Sulaman, M
   Guo, ZK
   Yang, X
   Wang, FN
   Hao, Q
AF Zhao, Yufei
   Song, Yong
   Li, Xu
   Sulaman, Muhammad
   Guo, Zhengkun
   Yang, Xin
   Wang, Fengning
   Hao, Qun
TI IR saliency detection via a GCF-SB visual attention framework
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; IR images; Bayes formula; Visual attention
ID TARGET DETECTION; REGION DETECTION; MODEL
AB Infrared (IR) saliency detection with high detection accuracy is a challenging task due to the complex background and low contrast of IR images. In this paper, an IR saliency detection method via a new visual attention framework is proposed, which comprises two phases. In the first phase, a Gray & Contrast Features (GCF) model is established, in which the IR image is processed in two feature channels, a gray feature channel and a contrast feature channel. And then a primary feature map can be obtained by fusing the gray and contrast features from these two channels, which is the basis of the second phase. In the second phase, a Similarity-based Bayes (SB) model is established, in which two prior probabilities and two likelihood functions are calculated according to the previously obtained primary feature map. Finally, the saliency map is calculated with the obtained prior probabilities and likelihood functions by Bayes formula. Experimental results indicate that the proposed method can effectively reduce noise and enhance contrast of IR images with complex background and low contrast, and obtain a higher detection accuracy and robustness than seven state-of-the-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhao, Yufei; Song, Yong; Li, Xu; Sulaman, Muhammad; Guo, Zhengkun; Yang, Xin; Wang, Fengning; Hao, Qun] Beijing Inst Technol, Sch Opt & Photon, Beijing 100081, Peoples R China.
   [Zhao, Yufei; Li, Xu; Sulaman, Muhammad; Guo, Zhengkun; Yang, Xin; Wang, Fengning; Hao, Qun] Beijing Key Lab Precis Optoelect Measurement Inst, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Song, Y (corresponding author), Beijing Inst Technol, Sch Opt & Photon, Beijing 100081, Peoples R China.
EM zhaoyufei@bit.edu.cn; yongsong@bit.edu.cn
RI Sulaman, Muhammad/I-7661-2019; Zhao, Yufei/IZP-5479-2023
OI Sulaman, Muhammad/0000-0003-0702-653X; Zhao, Yufei/0000-0002-5919-7595
FU Natural Science Foundation of China (NSFC) [81671787]; Defense
   Industrial Technology Development Program [JCKY201620813001]; Lab of
   Space Optoelectronic Measurement Perception [LabSOMP-2018-03]
FX This work was supported by the Natural Science Foundation of China
   (NSFC) (81671787), Defense Industrial Technology Development Program
   (JCKY201620813001) and the Lab of Space Optoelectronic Measurement &
   Perception (LabSOMP-2018-03).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P251, DOI 10.1016/j.jvcir.2016.06.013
   Cheng HT, 2018, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2018.00154
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Dai SS, 2015, INFRARED PHYS TECHN, V68, P10, DOI 10.1016/j.infrared.2014.09.042
   Davis James W, 2007, OTCBVS Benchmark Dataset Collection
   Davis JD, 2005, PACT 2005: 14TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P51
   Dong XB, 2014, INFRARED PHYS TECHN, V65, P36, DOI 10.1016/j.infrared.2014.03.007
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C., 2012, ACTA OPT SIN, V32, P144
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Li L, 2015, OPT COMMUN, V350, P33, DOI 10.1016/j.optcom.2015.03.065
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Lindsey D.T., 2000, OPTOMETRY VISION SCI, V77, P233, DOI DOI 10.1097/00006324-200005000-00008
   Liu L, 2014, INFRARED PHYS TECHN, V62, P59, DOI 10.1016/j.infrared.2013.10.010
   Liu RS, 2014, PROC CVPR IEEE, P3866, DOI 10.1109/CVPR.2014.494
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Miezianko R., 2006, TERRAVIC RES INFRARE, V2
   Mumtaz A, 2016, INT BHURBAN C APPL S, P167, DOI 10.1109/IBCAST.2016.7429872
   Qi SX, 2016, INFRARED PHYS TECHN, V77, P440, DOI 10.1016/j.infrared.2016.06.026
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tian HW, 2014, IEEE T IMAGE PROCESS, V23, P4389, DOI 10.1109/TIP.2014.2350914
   Wang WG, 2019, PROC CVPR IEEE, P5961, DOI 10.1109/CVPR.2019.00612
   Wang XS, 2017, IET RENEW POWER GEN, V11, P707, DOI 10.1049/iet-rpg.2016.0526
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang Y.Y., 2018, SIGNAL PROCESS IMAGE
   Zhu L, 2017, IEEE I CONF COMP VIS, P5468, DOI 10.1109/ICCV.2017.583
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou BJ, 2015, J VIS COMMUN IMAGE R, V33, P378, DOI 10.1016/j.jvcir.2015.09.017
   Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78
NR 50
TC 2
Z9 2
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102706
DI 10.1016/j.jvcir.2019.102706
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200007
DA 2024-07-18
ER

PT J
AU Jin, Y
   Jiang, XB
   Jiang, WY
AF Jin, Yan
   Jiang, Xiaoben
   Jiang, Wenyu
TI An image denoising approach based on adaptive nonlocal total variation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Adaptive regularization parameter; Image denoising; NLTV model;
   Split-Bregman method
ID TOTAL VARIATION MINIMIZATION; SCALE-SPACE METHODS; REGULARIZATION
   METHOD; MEANS FILTER; SPARSE; MODEL; ALGORITHM; DECONVOLUTION;
   DECOMPOSITION
AB In the nonlocal total variation (NLTV) model the constant regularization parameter lambda cannot adaptively control the balance between the regularization term and the fidelity term, which may results in over-smoothing and the more losing image details in non-flat areas when lambda is small, or insufficient noise removal in flat areas when lambda is large. It is better that lambda has different values according to the characteristics of image areas. In this paper, we introduce an adaptive regularization parameter lambda(x) which can recognize flat areas and non-flat areas of an image and propose an improved NLTV model by replacing regularization parameter lambda in NLTV model with the function lambda(x). In addition, we calculate the similarity weight function of our model from the pre-filtered image to reduce the influence of noise on it. Experimental results demonstrate our approach outperforms some existing methods in terms of objective criteria and subjective visual perception. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Jin, Yan; Jiang, Xiaoben; Jiang, Wenyu] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Jin, Y (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Zhejiang, Peoples R China.
EM jy@zjut.edu.cn
OI Jin, Yan/0000-0001-8956-7684; Jiang, Xiaoben/0000-0002-9454-0037
FU Zhejiang Provincial Natural Science Foundation of China [LY17F010015]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments and valuable suggestions. This research was supported
   by Zhejiang Provincial Natural Science Foundation of China [grant number
   LY17F010015].
CR Bianco V, 2016, OPT LETT, V41, P5226, DOI 10.1364/OL.41.005226
   Bianco V, 2016, LIGHT-SCI APPL, V5, DOI 10.1038/lsa.2016.142
   Bresson X., 2009, SHORT NOTE NONLOCAL
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Burger M, 2006, COMMUN MATH SCI, V4, P179
   Burger M, 2005, LECT NOTES COMPUT SC, V3752, P25
   Campagna R, 2017, APPL MATH COMPUT, V315, P453, DOI 10.1016/j.amc.2017.08.001
   Campagna R, 2016, AIP CONF PROC, V1776, DOI 10.1063/1.4965319
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Chan TF, 1999, SIAM J NUMER ANAL, V36, P354, DOI 10.1137/S0036142997327075
   Cuomo S., P 9 ACM INT C PERVAS, DOI 10.1145/2910674.2910692
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Djurovic I, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0113-x
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P74, DOI 10.5201/ipol.2012.g-tvd
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Huang XR, 2018, J COMPUT BIOL, V25, P1050, DOI 10.1089/cmb.2018.0060
   Isogawa K, 2018, IEEE SIGNAL PROC LET, V25, P224, DOI 10.1109/LSP.2017.2782270
   Jiang L, 2015, NUMER ALGORITHMS, V69, P495, DOI 10.1007/s11075-014-9908-y
   Jifara W, 2019, J SUPERCOMPUT, V75, P704, DOI 10.1007/s11227-017-2080-0
   Jin Y, 2015, INVERSE PROBL IMAG, V9, P415, DOI 10.3934/ipi.2015.9.415
   Jin Y, 2014, J MATH IMAGING VIS, V48, P93, DOI 10.1007/s10851-012-0395-2
   Joshi N, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P650, DOI 10.1109/NGCT.2016.7877492
   Kim H, 2016, PHYS MED BIOL, V61, P6878, DOI 10.1088/0031-9155/61/18/6878
   Lazzaro D, 2019, APPL MATH COMPUT, V357, P139, DOI 10.1016/j.amc.2019.03.065
   Lee JS, 1999, IEEE T GEOSCI REMOTE, V37, P2363, DOI 10.1109/36.789635
   Lefkimmiatis S, 2017, PROC CVPR IEEE, P5882, DOI 10.1109/CVPR.2017.623
   Li F, 2009, J VIS COMMUN IMAGE R, V20, P293, DOI 10.1016/j.jvcir.2009.01.003
   Li G, 2017, AEU-INT J ELECTRON C, V80, P29, DOI 10.1016/j.aeue.2017.06.023
   Li WH, 2012, J VIS COMMUN IMAGE R, V23, P409, DOI 10.1016/j.jvcir.2011.12.003
   Lie J, 2007, J MATH IMAGING VIS, V27, P41, DOI 10.1007/s10851-006-9694-9
   Liu HY, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P336, DOI 10.1109/CISP.2013.6744014
   Liu JL, 2016, IEEE T MED IMAGING, V35, P2578, DOI 10.1109/TMI.2016.2587661
   Liu RW, 2015, MED PHYS, V42, P5167, DOI 10.1118/1.4927793
   Ma XS, 2016, IEEE T GEOSCI REMOTE, V54, P3421, DOI 10.1109/TGRS.2016.2517627
   Ma XS, 2014, INT GEOSCI REMOTE SE, P1670, DOI 10.1109/IGARSS.2014.6946770
   Marquina A, 2009, SIAM J IMAGING SCI, V2, P64, DOI 10.1137/080724289
   Mei JJ, 2016, APPL MATH MODEL, V40, P2322, DOI 10.1016/j.apm.2015.09.068
   Montefusco LB, 2012, IEEE T IMAGE PROCESS, V21, P1676, DOI 10.1109/TIP.2011.2173205
   Nie XL, 2017, DIGIT SIGNAL PROCESS, V68, P44, DOI 10.1016/j.dsp.2017.05.008
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Ren C, 2017, IEEE T IMAGE PROCESS, V26, P90, DOI 10.1109/TIP.2016.2619265
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S, 2010, J VIS COMMUN IMAGE R, V21, P193, DOI 10.1016/j.jvcir.2009.10.006
   Uzan A, 2013, APPL OPTICS, V52, pA195, DOI 10.1364/AO.52.00A195
   Wang XT, 2016, J VIS COMMUN IMAGE R, V38, P440, DOI 10.1016/j.jvcir.2016.03.024
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen TX, 2016, ULTRASONIC IMAGING, V38, P254, DOI 10.1177/0161734615600676
   Xu JL, 2016, AEU-INT J ELECTRON C, V70, P1128, DOI 10.1016/j.aeue.2016.05.008
   Zhang F, 2018, IET IMAGE PROCESS, V12, P485, DOI 10.1049/iet-ipr.2017.0389
   Zhang J, 2016, SIGNAL PROCESS, V128, P274, DOI 10.1016/j.sigpro.2016.04.012
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
   Zhou YY, 2016, J VIS COMMUN IMAGE R, V41, P74, DOI 10.1016/j.jvcir.2016.09.007
NR 59
TC 8
Z9 8
U1 6
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102661
DI 10.1016/j.jvcir.2019.102661
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700014
DA 2024-07-18
ER

PT J
AU Meng, Y
   Tu, SS
   Yu, JL
   Huang, FM
AF Meng, Yuan
   Tu, Shanshan
   Yu, Jinliang
   Huang, Fengming
TI Intelligent attack defense scheme based on DQL algorithm in mobile fog
   computing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Moving fog computing; Intelligent attack; Physical layer security;
   Prospect theory; Reinforcement learning
ID PROSPECT-THEORY; COMMUNICATION; SECURITY
AB Fog computing is a technology that can expands the network computing mode of cloud computing and extends network computing from the network center to the network edge. It adds fog layer between cloud data center layer and Internet of Things (IoT) device layer, and provides data storage, processing, forwarding and other functions for devices using the network edge. In mobile fog computing (MFC) networks, fog nodes communicate with end users through wireless networks. Malicious users can choose different attack modes to attack legitimate users. There is a lack of research on the subjective choice of attack modes for malicious users in current work. To solve this problem, an intelligent attack defense scheme based on Double Q-learning (DQL) algorithm in MFC is proposed. Firstly, the security model involving malicious users in MFC is described. Based on Prospect Theory (PT), a static method of subjective zero-sum game between malicious users and legitimate users is constructed. Secondly, a dynamic subjective game scheme based on DQL algorithm is proposed to resist intelligent attacks. The simulation results show that compared with the Q-learning-based method for resisting intelligent attacks, the proposed method can enhance the security of MFC network and enhance the protection performance. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Meng, Yuan; Tu, Shanshan; Yu, Jinliang; Huang, Fengming] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Meng, Yuan; Tu, Shanshan] Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Tu, SS (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM sstu@bjut.edu.cn
RI Zhang, Kai/KBD-3312-2024; Meng, Yuan/JUU-4880-2023; Zhang,
   Han/JMR-0670-2023
FU National Natural Science Foundation of China [61801008]; National Key
   R&D Program of China [2018YFB0803600]; Beijing Natural Science
   Foundation [L172049]; Scientic Research Common Program of Beijing
   Municipal Commission of Education [KM201910005025]
FX This work was partially supported by the National Natural Science
   Foundation of China (No. 61801008), National Key R&D Program of China
   (No. 2018YFB0803600), Beijing Natural Science Foundation National (No.
   L172049), Scientic Research Common Program of Beijing Municipal
   Commission of Education (No. KM201910005025).
CR Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026
   Bittencourt LF, 2017, IEEE CLOUD COMPUT, V4, P26, DOI 10.1109/MCC.2017.27
   Chaabouni S, 2019, J VIS COMMUN IMAGE R, V60, P79, DOI 10.1016/j.jvcir.2019.02.004
   Cisco, 2017, Cisco7 Feb.
   Dai WF, 2020, SOFT COMPUT, V24, P9429, DOI 10.1007/s00500-018-3017-0
   Garnaev A, 2016, IEEE T WIREL COMMUN, V15, P2155, DOI 10.1109/TWC.2015.2498934
   Hasselt A., 2015, AAAI C ARTIF INTELL, V30, P2094, DOI DOI 10.1609/AAAI.V30I1.10295.[18]P
   Hasselt HadoV., 2010, Double Q-learning, P2613
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Lee MC, 2018, HUM FACTOR ERGON MAN, V28, P383, DOI 10.1002/hfm.20748
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Mukherjee M, 2018, IEEE COMMUN SURV TUT, V20, P1826, DOI 10.1109/COMST.2018.2814571
   Mukherjee M, 2017, IEEE ACCESS, V5, P19293, DOI 10.1109/ACCESS.2017.2749422
   Ni JB, 2018, IEEE COMMUN SURV TUT, V20, P601, DOI 10.1109/COMST.2017.2762345
   Prelec D, 1998, ECONOMETRICA, V66, P497, DOI 10.2307/2998573
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Tu SS, 2018, IEEE ACCESS, V6, P74993, DOI 10.1109/ACCESS.2018.2884672
   TVERSKY A, 1992, J RISK UNCERTAINTY, V5, P297, DOI 10.1007/BF00122574
   Virrey RA, 2019, J VIS COMMUN IMAGE R, V61, P209, DOI 10.1016/j.jvcir.2019.03.023
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Xiao L, 2016, PROCEEDINGS OF 2015 2ND INTERNATIONAL CONFERENCE ON INDUSTRIAL ECONOMICS SYSTEM AND INDUSTRIAL SECURITY ENGINEERING, P247, DOI 10.1007/978-981-287-655-3_32
   Xiao L, 2016, IEEE T VEH TECHNOL, V65, P10037, DOI 10.1109/TVT.2016.2524258
   Xie  C., 2016, P IEEE INT C UB WIR, VPP, P1
NR 24
TC 7
Z9 7
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102656
DI 10.1016/j.jvcir.2019.102656
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700005
DA 2024-07-18
ER

PT J
AU Milotta, FLM
   Furnari, A
   Battiato, S
   Signorello, G
   Farinella, GM
AF Milotta, Filippo L. M.
   Furnari, Antonino
   Battiato, Sebastiano
   Signorello, Giovanni
   Farinella, Giovanni M.
TI Egocentric visitors localization in natural sites
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Egocentric (First Person) vision; Localization; GPS; Multimodal data
   fusion
AB Localizing visitors in natural environments is challenging due to the unavailability of pre-installed cameras or other infrastructure such as WiFi networks. We propose to perform localization using egocentric images collected from the visitor's point of view with a wearable camera. Localization can be useful to provide services to both the visitors (e.g., showing where they are or what to see next) and to the site manager (e.g., to understand what the visitors pay more attention to and what they miss during their visits). We collected and publicly released a dataset of egocentric videos asking 12 subjects to freely visit a natural site. Along with video, we collected GPS locations by means of a smartphone. Experiments comparing localization methods based on GPS and images highlight that image-based localization is much more reliable in the considered domain and small improvements can be achieved by combining GPS-and image-based predictions using late fusion. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Milotta, Filippo L. M.; Furnari, Antonino; Battiato, Sebastiano; Farinella, Giovanni M.] Univ Catania, Dept Math & Comp Sci, Via Santa Sofia 64, I-95125 Catania, Italy.
   [Signorello, Giovanni; Farinella, Giovanni M.] Univ Catania, CUTGANA, Via Santa Sofia 98, I-95123 Catania, Italy.
C3 University of Catania; University of Catania
RP Farinella, GM (corresponding author), Viale A Doria 6, I-95125 Catania, Italy.
EM gfarinella@dmi.unict.it
RI Signorello, Giovanni/L-7627-2015; Battiato, Sebastiano/O-7799-2019;
   Battiato, Sebastiano/ABI-1584-2020; FARINELLA, Giovanni
   Maria/L-8555-2015
OI Battiato, Sebastiano/0000-0001-6127-2470; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432
FU PON MISE - Horizon 2020, Project VEDI - Vision Exploitation for Data
   Interpretation [F/050457/02/X32 - CUP: B68117000800008 - COR: 128032];
   Piano della Ricerca 2016-2018 linea di Intervento 2 of DMI of the
   University of Catania
FX This research is supported by PON MISE - Horizon 2020, Project VEDI -
   Vision Exploitation for Data Interpretation, Prog. n. F/050457/02/X32 -
   CUP: B68117000800008 - COR: 128032, and Piano della Ricerca 2016-2018
   linea di Intervento 2 of DMI of the University of Catania. The authors
   would like to thank Costantino Laureanti for his invaluable help during
   data collection and labelling.
CR Ahmetovic D, 2016, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'16), P90, DOI 10.1145/2935334.2935361
   Alahi A, 2015, IEEE I CONF COMP VIS, P3289, DOI 10.1109/ICCV.2015.376
   [Anonymous], INT C COMP VIS
   [Anonymous], P 1998 IM UND WORKSH
   [Anonymous], 2016, ARXIV160207360
   [Anonymous], J COMPUT CULTURAL HE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2019 14 INT C COMP V
   [Anonymous], 2017, ICCV
   [Anonymous], 2017, EXPT IR MEETS MULTIL, DOI DOI 10.1007/978-3-319-65813-1_24
   [Anonymous], 2017, J VIS COMMUN IMAGE R, DOI DOI 10.1016/j.jvcir.2017.10.004
   Arandjelovic R., 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2711011
   Bettadapura V, 2015, IEEE WINT CONF APPL, P626, DOI 10.1109/WACV.2015.89
   Bishop C, 2007, RECOGNITION PATTERN
   Capi G, 2014, ADV ROBOTICS, V28, P1043, DOI 10.1080/01691864.2014.903202
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Furnari A, 2017, IEEE T HUM-MACH SYST, V47, P6, DOI 10.1109/THMS.2016.2612002
   Hays J, 2008, PROC CVPR IEEE, P3436
   Ishihara T, 2017, INT CONF ACOUST SPEE, P5950, DOI 10.1109/ICASSP.2017.7953298
   Ishihara T, 2017, IEEE WINT CONF APPL, P769, DOI 10.1109/WACV.2017.91
   Kapidis G, 2018, INT CONF PERVAS COMP, DOI 10.1109/PERCOMW.2018.8480258
   Karaman S, 2014, MULTIMED TOOLS APPL, V69, P743, DOI 10.1007/s11042-012-1117-x
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kitani K, 2012, IEEE PERVAS COMPUT, V11, P92, DOI 10.1109/MPRV.2012.28
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lin TY, 2013, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2013.120
   Lu Z, 2013, PROC CVPR IEEE, P2714, DOI 10.1109/CVPR.2013.350
   Mann S, 1997, IEEE T IMAGE PROCESS, V6, P1281, DOI 10.1109/83.623191
   Mann S, 1997, COMPUTER, V30, P25, DOI 10.1109/2.566147
   Mann S., 2001, EYE, V3, pP3
   Mann S., 2002, INTELLIGENT IMAGE PR, VFirst
   Mann S, 2014, IEEE COMPUT SOC CONF, P826, DOI 10.1109/CVPRW.2014.133
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Santarcangelo V, 2018, PATTERN RECOGN LETT, V112, P83, DOI 10.1016/j.patrec.2018.06.010
   Sargent G, 2016, MULTIMED TOOLS APPL, V75, P9073, DOI 10.1007/s11042-015-2863-3
   Simonyan K., 2014, 14091556 ARXIV
   Spriggs EH, 2009, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2009.5204354
   Starner T, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P50, DOI 10.1109/ISWC.1998.729529
   Van Horn Grant, 2017, ARXIV170706642
   Wegner JD, 2016, PROC CVPR IEEE, P6014, DOI 10.1109/CVPR.2016.647
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19
   Zemene E, 2019, IEEE T PATTERN ANAL, V41, P148, DOI 10.1109/TPAMI.2017.2787132
NR 46
TC 5
Z9 5
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102664
DI 10.1016/j.jvcir.2019.102664
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700010
DA 2024-07-18
ER

PT J
AU Cheng, LS
   Zhang, X
   Shen, J
AF Cheng, Lushan
   Zhang, Xu
   Shen, Jie
TI Road surface condition classification using deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Road condition; Activation function; Image recognition;
   Intelligent driving
AB Traditional image recognition technology currently cannot achieve the fast real-time high-accuracy performance necessary for road recognition in intelligent driving. Deep learning models have been recently emerging as promising tools to achieve this performance. The recognition performance of such models can be boosted using appropriate selection of the activation functions. This paper proposes a deep learning approach for the classification of road surface conditions, and constructs a new activation function based on the rectified linear unit Rectified Linear Units (ReLu) activation function. The experimental results show a classification accuracy of 94.89% on the road state database. Experiments on public data-sets demonstrate that the proposed convolutional neural network model with the improved activation function has better generalization and excellent classification performance. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Cheng, Lushan; Zhang, Xu] Shanghai Univ Engn Sci, Sch Mech & Automot Engn, Shanghai 201620, Peoples R China.
   [Shen, Jie] Univ Michigan, Dept Comp & Informat Sci, Dearborn, MI 48128 USA.
C3 Shanghai University of Engineering Science; University of Michigan
   System; University of Michigan
RP Zhang, X (corresponding author), Shanghai Univ Engn Sci, Sch Mech & Automot Engn, Shanghai 201620, Peoples R China.
EM zxu1116@126.com
RI shen, jie/JJF-0994-2023
FU National Natural Science Foundation of China [51205246, 51775328]
FX The work described in this paper was supported by the National Natural
   Science Foundation of China (Grant No. 51205246, 51775328).
CR [Anonymous], 2017, J SICHUAN NORM UNIV, DOI DOI 10.3969/j.issn.1001-8395.2017.01.020
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Fu Y, 2019, MINER ENG, V132, P183, DOI 10.1016/j.mineng.2018.12.011
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godin Frederic, 2017, ARXIV170708214
   Harvey D.R., 2006, J AGR ECON, V57, P8
   Hinton G, 2006, COGNITIVE SCI, V30, P725, DOI 10.1207/s15516709cog0000_76
   Keller J.M., 2017, FUNDAMENTALS COMPUTA, P378
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehnle A., 1998, APPL ADV TECHNOLOGIE
   Lan Du, 2016, J ELECT INFORM TECHN, V38, P3018
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Yuexia, 2018, GLOB INT IND C GIIC
   Liu ZM, 2010, IEEE T IMAGE PROCESS, V19, P2502, DOI 10.1109/TIP.2010.2048963
   Maddern W, 2017, INT J ROBOT RES, V36, P3, DOI 10.1177/0278364916679498
   Philipp P., 2017, NEURAL NETWORKS
   Shi K., 2017, 2017 13 INT C COMP I
   Vydana HK, 2017, NATL CONF COMMUN
   WIESEL TN, 1963, J NEUROPHYSIOL, V26, P978, DOI 10.1152/jn.1963.26.6.978
   Wu YC, 2017, PATTERN RECOGN, V65, P251, DOI 10.1016/j.patcog.2016.12.026
   Yu Y, 2014, APPL MECH MATER, V678, P162, DOI 10.4028/www.scientific.net/AMM.678.162
   Zhang SL, 2015, IEEE T IMAGE PROCESS, V24, P5723, DOI 10.1109/TIP.2015.2484068
   Zhao HZ, 2018, APPL INTELL, V48, P1707, DOI 10.1007/s10489-017-1028-7
NR 24
TC 22
Z9 22
U1 6
U2 59
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102638
DI 10.1016/j.jvcir.2019.102638
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600023
DA 2024-07-18
ER

PT J
AU Hong, T
   Romano, Y
   Elad, M
AF Hong, Tao
   Romano, Yaniv
   Elad, Michael
TI Acceleration of RED via vector extrapolation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inverse problem; RED - REgularization by Denoising; Fixed-point; Vector
   extrapolation; Acceleration
ID CONVERGENCE; SPARSE
AB Models play an important role in inverse problems, serving as the prior for representing the original signal to be recovered. REgularization by Denoising (RED) is a recently introduced general framework for constructing such priors using state-of-the-art denoising algorithms. Using RED, solving inverse problems is shown to amount to an iterated denoising process. However, as the complexity of denoising algorithms is generally high, this might lead to an overall slow algorithm. In this paper, we suggest an accelerated technique based on vector extrapolation (VE) to speed-up existing RED solvers. Numerical experiments validate the obtained gain by VE, leading to substantial savings in computations compared with the original fixed-point method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hong, Tao; Elad, Michael] Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
   [Romano, Yaniv] Stanford Univ, Dept Stat, Stanford, CA 94305 USA.
C3 Technion Israel Institute of Technology; Stanford University
RP Hong, T (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, IL-32000 Haifa, Israel.
EM hongtao@cs.technion.ac.il; yromano@stanford.edu; elad@cs.technion.ac.il
RI , Miki/AAH-4640-2019
FU Zuckerman Institute; ISEF Foundation; Viterbi Fellowship, Technion
FX Y. R. thanks the Zuckerman Institute, ISEF Foundation, and the Viterbi
   Fellowship, Technion, for providing additional research support.
CR [Anonymous], 2013, Introductory lectures on convex optimization: A basic course
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   CABAY S, 1976, SIAM J NUMER ANAL, V13, P734, DOI 10.1137/0713060
   Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   JBILOU K, 1991, J COMPUT APPL MATH, V36, P385, DOI 10.1016/0377-0427(91)90018-F
   Kirsch A, 2011, APPL MATH SCI, V120, P1, DOI 10.1007/978-1-4419-8474-6
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2833, DOI 10.1109/CVPR.2011.5995309
   Metzler CA, 2015, 2015 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P508, DOI 10.1109/SAMPTA.2015.7148943
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   RAJEEVAN N, 1992, IEEE T MED IMAGING, V11, P9, DOI 10.1109/42.126905
   Romano Y, 2017, SIAM J IMAGING SCI, V10, P1804, DOI 10.1137/16M1102884
   Rosman G, 2009, SIAM J IMAGING SCI, V2, P858, DOI 10.1137/080728391
   Sidi A, 1998, NUMER ALGORITHMS, V18, P113, DOI 10.1023/A:1019113314010
   SIDI A, 1991, J COMPUT APPL MATH, V36, P305, DOI 10.1016/0377-0427(91)90013-A
   SIDI A, 1986, SIAM J NUMER ANAL, V23, P178, DOI 10.1137/0723013
   SIDI A, 1986, SIAM J NUMER ANAL, V23, P197, DOI 10.1137/0723014
   SIDI A, 1988, J COMPUT APPL MATH, V22, P35, DOI 10.1016/0377-0427(88)90287-7
   Sidi A., 2017, VECTOR EXTRAPOLATION, V17
   Sidi A., 2015, ARXIV150500674
   Sidi A, 2017, ADV COMPUT MATH, V43, P151, DOI 10.1007/s10444-016-9481-0
   SKELBOE S, 1980, IEEE T CIRCUITS SYST, V27, P161, DOI 10.1109/TCS.1980.1084794
   SMITH DA, 1987, SIAM REV, V29, P199, DOI 10.1137/1029042
   Sreehari S, 2016, IEEE T COMPUT IMAG, V2, P408, DOI 10.1109/TCI.2016.2599778
   Venkatakrishnan S, 2013, IEEE GLOB CONF SIG, P945, DOI 10.1109/GlobalSIP.2013.6737048
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 37
TC 8
Z9 8
U1 1
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102575
DI 10.1016/j.jvcir.2019.102575
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, FH
   Yu, Y
   Feng, TH
AF Huang, Fenghua
   Yu, Ying
   Feng, Tinghao
TI Automatic building change image quality assessment in high resolution
   remote sensing based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep belief network; Building change detection; Morphological building
   index; Morphological shadow index; Extreme learning machine; Quality
   Assessment
ID URBAN-AREA
AB The multi-temporal high-resolution remote sensing (HRRS) images are usually acquired at different imaging angles, with serious noise interferences and obvious building shadows, so that detecting the changes of urban buildings is a problem. In order to address this challenge, a deep learning-based algorithm called ABCDHIDL is proposed to automatically detect the building changes from multi-temporal HRRS images. Firstly, an automatic selection method of labeled samples of building changes based on morphology (ASLSBCM) is proposed. Secondly, a deep learning model (DBN-ELM) for building changes detection based on deep belief network (DBN) and extreme learning machine (ELM) is proposed. A convolution operation is employed to extract the spectral, texture and spatial features and generate a combined low-level features vector for each pixel in the multi-temporal HRRS images. The unlabeled samples are introduced to pre-train the DBN, and the parameters of DBN-ELM are globally optimized by jointly using the ELM classifier and the labeled samples are offered by ASLSBCM to further improve the detection accuracy. In order to evaluate the performance of ABCDHIDL, four groups of double-temporal WorldView2 HRRS images in four different experimental regions are selected respectively as the test datasets, and five other representative methods are used and compared with ABCDHIDL in the experiments of buildings change detection. The results show that ABCDHIDL has higher accuracy and automation level than the other five methods despite its relatively higher time consumption. (C) 2019 Published by Elsevier Inc.
C1 [Huang, Fenghua; Yu, Ying] Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.
   [Huang, Fenghua; Yu, Ying] Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
   [Feng, Tinghao] Univ N Carolina, Coll Comp & Informat, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Huang, FH (corresponding author), Yango Univ, Spatial Data Min & Applicat Res Ctr Fujian Prov, Fuzhou 350015, Fujian, Peoples R China.; Huang, FH (corresponding author), Yango Univ, Informat Engn Coll, Fuzhou 350015, Fujian, Peoples R China.
EM huang_fenghua@126.com
RI Feng, Tinghao/JWO-1400-2024
OI Feng, Tinghao/0000-0003-2765-2765
FU National Natural Science Foundation of China [41501451]; Natural Science
   Foundation of Fujian Province in China [2019J01088]; Program for
   Outstanding Youth Scientific Research Talents in Fujian Province
   Universities [MinJiaoKe [2015]54]; Program for New Century Excellent
   Talents in Fujian Province Universities [MinJiaoKe [2016]23]
FX This work was funded by the National Natural Science Foundation of China
   (NSFC, 41501451), Natural Science Foundation of Fujian Province in China
   (No. 2019J01088), Program for Outstanding Youth Scientific Research
   Talents in Fujian Province Universities (MinJiaoKe [2015]54), and
   Program for New Century Excellent Talents in Fujian Province
   Universities (MinJiaoKe [2016]23). The authors would like to thank
   Wenzao Shi and Zhengyuan Mao in the Spatial Information Research Center
   (SIRC) of Fujian Province (China) for their assistance, suggestions, and
   discussions.
CR [Anonymous], COMPUT APPL SOFTW
   Argialas DP, 2013, SURV REV, V45, P441, DOI 10.1179/1752270613Y.0000000058
   Argyridis A, 2016, INT J IMAGE DATA FUS, V7, P148, DOI 10.1080/19479832.2016.1158211
   Bouziani M, 2010, ISPRS J PHOTOGRAMM, V65, P143, DOI 10.1016/j.isprsjprs.2009.10.002
   Chen H, 2014, IEEE SENS J, V14, DOI 10.1109/JSEN.2014.2316798
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   GAO C, 2014, ACTA GEODAET CARTOGR, P107
   HARIKRISHNAN V., 2014, INT J SCI RES IJSR, V3, P1220
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   [胡荣明 Hu Rongming], 2014, [测绘学报, Acta Geodetica et Cartographica Sinica], V43, P514
   HU Xiaowen, 2012, J NANJING U INFORM S, V4, P420
   Huang F., 2016, INT J EARTH SCI ENG, V9, P2172
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang X.., 2009, Master's Thesis
   Huang X, 2011, PHOTOGRAMM ENG REM S, V77, P721, DOI 10.14358/PERS.77.7.721
   [季顺平 JI Shunping], 2007, [遥感学报, Journal of Remote Sensing], V11, P323
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   [靳珍怡 Jin Zhenyi], 2016, [中国医学物理学杂志, Chinese Journal of Medical Physics], V33, P445
   Kang Yan, 2015, Instrument Technique and Sensor, P73
   Li Xiaolong, 2014, Journal of Frontiers of Computer Science and Technology, V8, P305, DOI 10.3778/j.issn.1673-9418.1306023
   Liu D. W., 2016, ACTA OPT SINICA, V36, P298
   Lu DS, 2011, INT J REMOTE SENS, V32, P2519, DOI 10.1080/01431161003698393
   [吕刚 Lu Gang], 2014, [计算机应用与软件, Computer Applications and Software], V31, P182
   [吕启 Lu Qi], 2014, [计算机研究与发展, Journal of Computer Research and Development], V51, P1911
   Matias T, 2014, NEUROCOMPUTING, V129, P428, DOI 10.1016/j.neucom.2013.09.016
   Ok AO, 2013, ISPRS J PHOTOGRAMM, V86, P21, DOI 10.1016/j.isprsjprs.2013.09.004
   Peng Gang, 2015, Computer Engineering and Design, V36, P1581, DOI 10.16208/j.issn1000-7024.2015.06.034
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   [施文灶 Shi Wenzao], 2016, [地球信息科学学报, Journal of Geo-Information Science], V18, P423
   Sirmaçek B, 2010, IEEE GEOSCI REMOTE S, V7, P146, DOI 10.1109/LGRS.2009.2028744
   Sirmaçek B, 2009, IEEE T GEOSCI REMOTE, V47, P1156, DOI 10.1109/TGRS.2008.2008440
   [谭勇 Tan Yong], 2012, [计算机仿真, Computer Simulation], V29, P245
   Tao C., 2012, THESIS
   [王宇红 Wang Yuhong], 2016, [化工学报, CIESC Journal], V67, P5163
   [徐涵秋 Xu Hanqiu], 2005, [遥感学报, Journal of Remote Sensing], V9, P589
NR 36
TC 20
Z9 21
U1 2
U2 57
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102585
DI 10.1016/j.jvcir.2019.102585
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200017
DA 2024-07-18
ER

PT J
AU Hu, YX
   Gao, Q
   Zhang, B
   Zhang, JT
AF Hu, Yanxiang
   Gao, Qian
   Zhang, Bo
   Zhang, Juntong
TI On the use of joint sparse representation for image fusion quality
   evaluation and analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image fusion; Quality evaluation; Sparse representation; joint sparse
   representation; Atom remnant analysis
ID MULTI-FOCUS; PERFORMANCE; TRANSFORM; RECOVERY
AB In this paper, a Spare Representation (SR) based fusion quality evaluation and analysis method is proposed. This method employs Joint Sparse Representation (JSR) to extract the source image remnants after fusion. These atom-level remnants indicate the fusion quality intuitively, and permit the analysis of fusion effect in learned feature space. Our analysis results indicate that high salient atoms always present poor expressions in fusion results. An improved fusion rule is designed to emphasis high salient atoms accordingly. In experiments, the effectiveness of our method was verified and the characteristics of atom JSR remnants were investigated in detail first. Then the new fusion rule was tested to demonstrate the value of JSR remnant analysis. The objective and subjective comparison results indicate that the proposed analytical evaluation metric can measure fusion quality and analysis atom fusion effect accurately. The new fusion rule provides a valuable alternative for SR fusion algorithm design. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Hu, Yanxiang; Gao, Qian; Zhang, Bo; Zhang, Juntong] Tianjin Normal Univ, Coll Comp & Informat Engn, 393 Binshui West Rd, Tianjin 300387, Peoples R China.
C3 Tianjin Normal University
RP Hu, YX (corresponding author), Tianjin Normal Univ, Coll Comp & Informat Engn, 393 Binshui West Rd, Tianjin 300387, Peoples R China.
EM huyanxiang@tjnu.edu.cn
OI Hu, Yanxiang/0000-0001-6659-2844
FU National Science Foundation of China [61274021]; Project of Tianjin
   Higher Educational Science and Technology Program [2017KJ119]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. We are grateful to Professors S. T. Li and Q. Zhang
   et al. for their excellent work on image fusion survey. We would also
   like to thank Yu Liu for providing the MST-SR fusion toolbox and
   universal dictionary. This work was supported by the National Science
   Foundation of China under Project Number 61274021 and Project of Tianjin
   Higher Educational Science and Technology Program (2017KJ119).
CR Adu JH, 2016, J VIS COMMUN IMAGE R, V40, P218, DOI 10.1016/j.jvcir.2016.06.026
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Duarte MF, 2005, 2005 39th Asilomar Conference on Signals, Systems and Computers, Vols 1 and 2, P1537
   Gao GR, 2013, IET IMAGE PROCESS, V7, P633, DOI 10.1049/iet-ipr.2012.0558
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hu YX, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500539
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kong WW, 2011, IET IMAGE PROCESS, V5, P113, DOI 10.1049/iet-ipr.2009.0425
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liao B, 2016, J VIS COMMUN IMAGE R, V40, P559, DOI 10.1016/j.jvcir.2016.07.022
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Luo XQ, 2017, J VIS COMMUN IMAGE R, V45, P46, DOI 10.1016/j.jvcir.2017.02.006
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Shutao Li, 2002, Information Fusion, V3, P17, DOI 10.1016/S1566-2535(01)00037-9
   Singh R, 2014, INFORM FUSION, V19, P49, DOI 10.1016/j.inffus.2012.09.005
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei CM, 2010, INFORM FUSION, V11, P301, DOI 10.1016/j.inffus.2009.10.006
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang B, 2014, OPTIK, V125, P4881, DOI 10.1016/j.ijleo.2014.04.036
   Yao Y, 2014, COGN COMPUT, V6, P281, DOI 10.1007/s12559-013-9235-y
   Yin HT, 2011, OPT ENG, V50, DOI 10.1117/1.3584840
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang  Q., 2013, OPT ENG, V52
   Zhang  Q., 2013, OPT ENG, V52
   Zhang Q, 2018, PATTERN RECOGN, V83, P299, DOI 10.1016/j.patcog.2018.06.003
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang Q, 2013, PATTERN RECOGN LETT, V34, P185, DOI 10.1016/j.patrec.2012.09.020
   Zhang T, 2011, IEEE T INFORM THEORY, V57, P6215, DOI 10.1109/TIT.2011.2162263
   2006, IEEE T SIGNAL PROCES, V54, P4311, DOI DOI 10.1109/TSP.2006.881199
NR 39
TC 9
Z9 9
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 225
EP 235
DI 10.1016/j.jvcir.2019.04.005
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100024
DA 2024-07-18
ER

PT J
AU Rao, PS
   Yedukondalu, K
AF Rao, Perumalla Srinivasa
   Yedukondalu, Kamatham
TI Hardware implementation of digital image skeletonization algorithm using
   FPGA for computer vision applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FPGA; Skeleton; Gray scale images; Computer vision; 2-D image
AB Nowadays embedded multimedia devices are designed for computationally intensive applications such as image processing in various multimedia systems. Image processing algorithms should be implemented on hardware platforms for improving the performance. Reconfigurable hardware implementation using Field Programmable Gate Arrays (FPGAs) provides low latency with high performance in real time applications. FPGAs offer the reprogrammability of an application specific solution while retaining the performance advantage. In real time applications as image sizes increase rapidly, only hardware systems must be used with low complex software. In this paper, main perspective of developing and implementing skeletonization algorithm as a part of computer vision, pattern recognition application is focused and presented. A simple algorithm to skeletonize the 2-D image using MATLAB is developed. An architecture and implementation of this skeletonization algorithm for 2-D gray scale images is proposed. For analyzing pixel values 3 x 3 windowing operator is used. The proposed architecture is tested for an image size of 8 x 8, but the approach presented in this paper can be used for images of any size (M x N), if the FPGA memory is sufficiently large. The implementation was carried out on Xilinx Vertex 5 board. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Rao, Perumalla Srinivasa; Yedukondalu, Kamatham] CVR Coll Engn, Dept Elect & Commun Engn, Hyderabad 501510, Telangana, India.
RP Rao, PS (corresponding author), CVR Coll Engn, Dept Elect & Commun Engn, Hyderabad 501510, Telangana, India.
EM psrao.cvr@gmail.com
RI Perumalla, Srinivasa Rao/AAU-3774-2020; Kamatham,
   Yedukondalu/AAH-1419-2019
OI Perumalla, Srinivasa Rao/0000-0003-4495-807X; Kamatham,
   Yedukondalu/0000-0002-9044-6553
CR ARCELLI C, 1995, IMAGE VISION COMPUT, V13, P159, DOI 10.1016/0262-8856(95)90836-W
   Batlle J, 2002, REAL-TIME IMAGING, V8, P345, DOI 10.1006/rtim.2001.0273
   Bourbakis N, 1997, IEEE T CIRCUITS-II, V44, P284, DOI 10.1109/82.566645
   Chaturvedi S, 2015, PROCEDIA COMPUT SCI, V62, P151, DOI 10.1016/j.procs.2015.08.428
   Ching-Hsi Lu, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P542, DOI 10.1109/IIH-MSP.2009.100
   Cui Chaoran, 2015, J LATEX CLASS FILES, V14, P1
   Davalle D, 2016, LECT NOTES ELECTR EN, V351, P169, DOI 10.1007/978-3-319-20227-3_22
   Gayathri S., 2013, INT J ENG SCI INNOV, V2, P264
   Hermanto L, 2010, INT CONF NETWORK INF, P187, DOI 10.1109/ICNIT.2010.5508534
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Lakshmi J. Komala, 2009, 2009 International Conference on Digital Image Processing, ICDIP, P260, DOI 10.1109/ICDIP.2009.21
   Lebourgeois Frank, 2017, INT C IM PROC, P1118
   Lopich A., 2005, CIRC THEOR DES, V3, P81
   Nie LQ, 2017, IEEE T CYBERNETICS, V47, P3680, DOI 10.1109/TCYB.2016.2577590
   Nie LQ, 2017, IEEE T NEUR NET LEAR, V28, P1508, DOI 10.1109/TNNLS.2016.2520964
   Perumalla Srinivasa Rao, 2018, 3 IEEE INT C REC TRE
   Qi Chang, 2005, J NAT SCI, V10, P1025
   Sintunata V, 2017, IEEE INT C ELECTR TA
   Sudha N, 2003, J VLSI SIG PROC SYST, V35, P61, DOI 10.1023/A:1023335904573
   Xu H., 2009, CHIN C, P1
   Youssef Rabaa, 2015, INT C DIG IM COMP TE
   Zhao WG, 2010, INT CONF COMP SCI, P680, DOI 10.1109/ICCSIT.2010.5564541
NR 23
TC 5
Z9 6
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 140
EP 149
DI 10.1016/j.jvcir.2019.01.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600014
DA 2024-07-18
ER

PT J
AU Wang, FY
   Lv, JH
   Ying, GD
   Chen, SH
   Zhang, C
AF Wang, Fengyuan
   Lv, Jianhua
   Ying, Guode
   Chen, Shenghui
   Zhang, Chi
TI Facial expression recognition from image based on hybrid features
   understanding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Convolutional neural networks;
   Scale-invariant feature transform; Deep-learning feature; Support vector
   machines
ID OBJECT; HISTOGRAMS; MODEL
AB Facial expression recognition (FER) plays an important role in the applications of human computer interaction. Given the wide use of convolutional neural networks (CNNs) in automatic video and image classification systems, higher-level features can be automatically learned from hierarchical neural networks with big data. However, learning CNNs require large amount of training data for adequate generalization, while the Scale-invariant feature transform (SIFT) does not need large training samples to generate useful feature, In this paper, we propose a new hybrid feature representation for the recognition of facial expressions from a single image frame that uses a combination of SIFT and deep-learning feature of different level extracted from the CNN model, then adopt the combined features and classify the expression by support vector machines (SVM). The performance of the proposed method has been validated on public CK+ databases. To evaluate the generalization ability of our method, we also performed an experiment on a cross-database environment. Experimental results show that the proposed approach can achieve better classification rates compared with state-of-art CNN methods, which indicate the considerable potential of combining shallow feature with deep-learning feature. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Wang, Fengyuan; Lv, Jianhua; Ying, Guode; Chen, Shenghui; Zhang, Chi] State Grid Taizhou Elect Power Supply Co, Taizhou, Peoples R China.
RP Wang, FY (corresponding author), State Grid Taizhou Elect Power Supply Co, Taizhou, Peoples R China.
EM Wang_fengyuan@zj.sgcc.com.cn; Lv_jianhua@zj.sgcc.com.cn;
   Ying_guode@zj.sgcc.com.cn; Chengxin7@139.com; Zhang_chi@zj.sgcc.com.cn
CR [Anonymous], 2016, ARXIV161001708
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Carcassoni Marco, 2003, CORRES MATCHING MODA, P1609
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y
   Everingham M., 2009, The PASCAL Visual Object Classes Challenge 2009 (VOC) Results
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb P.F., 2005, International Journal of Computer Vision
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee YJ, 2010, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2010.5540237
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y., 2017, INFORM SCI
   Luo MN, 2018, IEEE T NEUR NET LEAR, V29, P944, DOI 10.1109/TNNLS.2017.2650978
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Quelhas P, 2005, IEEE I CONF COMP VIS, P883
   Siddiqi K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P222, DOI 10.1109/ICCV.1998.710722
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Todorovic S, 2008, INT J COMPUT VISION, V78, P47, DOI 10.1007/s11263-007-0077-5
   WANG CH, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P440, DOI 10.1109/ICCV.1995.466906
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2621478
   Xu YW, 2004, COMPUT VIS IMAGE UND, V95, P334, DOI 10.1016/j.cviu.2004.04.003
   Yao Benjamin, 2007, ENERGY MINIMIZATION
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
NR 45
TC 22
Z9 22
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 84
EP 88
DI 10.1016/j.jvcir.2018.11.010
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600009
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Lin, YP
AF Zhang, Yue
   Lin, Yaping
TI Quantitative similarity calculation method for trajectory-directed line
   using sketch retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Trajectory; Directed line; Topological relationship; Key point;
   Similarity
ID OBJECT DETECTION; DEEP
AB Moving objects may have various kinds of topological events when they move relative to a directed line, such as moving in/out, folding back and stopping. This research develops a trajectory-directed line query mode using sketch-based retrieval in order to realize the query of topological relationship between a trajectory and a directed line. The research also proposes a quantitative similarity calculation method for trajectory-directed line. The sketched stroke-directed line is used as input query condition and is described as a sequence of key points for semantic association. The trajectory-directed line to be queried is also described as a sequence of key points. The time sequence distance metric is used to calculate the similarity between them. For the trajectory-directed line with different number of key points, the similarity calculation is carried out using two kinds of distance matching methods. The results show that the method is simple and feasible, and can realize the quantitative query of trajectory data. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Yue; Lin, Yaping] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Zhang, Yue] Hunan Police Acad, Dept Informat Technol, Changsha 410138, Hunan, Peoples R China.
C3 Hunan University
RP Zhang, Y (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM zhengzhang137@126.com
CR [安晓亚 An Xiaoya], 2017, [测绘学报, Acta Geodetica et Cartographica Sinica], V46, P1899
   [陈占龙 Chen Zhanlong], 2015, [测绘学报, Acta Geodetica et Cartographica Sinica], V44, P813
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Gao Qiang, 2017, Journal of Software, V28, P959, DOI 10.13328/j.cnki.jos.005143
   Gong Xudong, 2015, SIMILARITY SEARCH TR
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Shen Shi-qun, 2010, Acta Electronica Sinica, V38, P1819
   Tian Zeyu, 2017, RES SPATIAL SCENE SI
   Wang F, 2014, IEEE CONF VIS ANAL, P103, DOI 10.1109/VAST.2014.7042486
   Wang Fei, 2016, VISUAL QUERY METHOD
   Wang XY, 2013, DATA MIN KNOWL DISC, V26, P275, DOI 10.1007/s10618-012-0250-5
   [向隆刚 Xiang Longgang], 2016, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V41, P1292
   Xiang Longgang, 2016, Geomatics and Information Science of Wuhan University, V41, P1034, DOI 10.13203/j.whugis20140407
   [向隆刚 Xiang Longgang], 2014, [测绘学报, Acta Geodetica et Cartographica Sinica], V43, P982
   Yao Di, 2018, Journal of Software, V29, P2018, DOI 10.13328/j.cnki.jos.005576
   Yu Gong, 2011, PROG GEOGR, V30, P523
   Yuan G, 2017, ARTIF INTELL REV, V47, P123, DOI 10.1007/s10462-016-9477-7
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhang T, 2012, CEREB CORTEX, V22, P854, DOI 10.1093/cercor/bhr152
   Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025
   ZHOU Xingxing, 2018, GEOMATICS WORLD, V25, P11, DOI [10.3969/j.issn.1672-1586.2018.04.003, DOI 10.3969/J.ISSN.1672-1586.2018.04.003]
NR 31
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 448
EP 454
DI 10.1016/j.jvcir.2019.01.040
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600048
DA 2024-07-18
ER

PT J
AU Dong, X
   Zhang, HX
   Zhu, L
   Wan, WB
   Wang, ZH
   Wang, Q
   Guo, PL
   Ji, H
   Sun, JD
AF Dong, Xiao
   Zhang, Huaxiang
   Zhu, Lei
   Wan, Wenbo
   Wang, Zhenhua
   Wang, Qiang
   Guo, Peilian
   Ji, Hui
   Sun, Jiande
TI Weighted locality collaborative representation based on sparse subspace
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Collaborative representation; Sparse subspace; Linear representation;
   Face recognition
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION; FACE-RECOGNITION
AB This paper takes into account both unlabeled data and their local neighbors to learn their sparse representations, and proposes a face recognition approach named Weighted Locality Collaborative Representation Classifier based on sparse subspace (WLCRC). WLCRC firstly learns a subset of the original training data to build a much correlated dictionary, and then combines linear regression techniques together with weighted collaborative representation techniques to optimize the linear reconstruction of unlabeled data. It uses the newly built dictionary to learn the reconstruction coefficients for each unlabeled datum while considering the influence of its local neighbors. Classifications are performed according to the reconstruction residuals, and experimental results on benchmark datasets demonstrate that WLCRC is effective. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Dong, Xiao; Zhang, Huaxiang; Zhu, Lei; Wan, Wenbo; Wang, Zhenhua; Wang, Qiang; Guo, Peilian; Ji, Hui; Sun, Jiande] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang; Zhu, Lei; Wan, Wenbo; Wang, Zhenhua; Wang, Qiang; Guo, Peilian; Sun, Jiande] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@163.com
RI Zhu, Lei/AAC-6810-2019; Zhu, Lei/GQQ-1130-2022
OI Zhu, Lei/0000-0002-2993-7142; Zhu, Lei/0000-0002-5348-7532
FU National Natural Science Foundation of China [61572298, 61772322,
   61402268, 61401260, 61601268]; Key Research and Development Foundation
   of Shandong Province [2017GGX10117, 2016GGX101009]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61572298, 61772322, 61402268, 61401260,
   61601268), and the Key Research and Development Foundation of Shandong
   Province (Nos. 2017GGX10117, 2016GGX101009).
CR [Anonymous], NEURAL PROCESS LETT
   [Anonymous], IEEE SIGNAL PROCESSI
   [Anonymous], 2005, LOCALITY PRESERVING
   [Anonymous], ARXIV150200873
   [Anonymous], IEEE J SEL TOPICS SI
   [Anonymous], 1999, Subspace Linear Discriminant Analysis for Face Recognition
   [Anonymous], 2014, Math. Probl. Eng
   [Anonymous], CHIN C PATT REC CCPR
   [Anonymous], 2014, NIPS 2014 WORKSH OPT
   [Anonymous], 1999, GEORGIA TECH FACE DA
   [Anonymous], ARXIV12042358
   [Anonymous], COMPUTIONAL VISUAL M
   Buciu I, 2008, IEEE T NEURAL NETWOR, V19, P1090, DOI 10.1109/TNN.2008.2000162
   Dong X, 2017, J VIS COMMUN IMAGE R, V43, P21, DOI 10.1016/j.jvcir.2016.12.006
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jolliffe I.T., 2008, PRINCIPAL COMPONENT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li W, 2015, PATTERN RECOGN, V48, P3904, DOI 10.1016/j.patcog.2015.05.024
   Liu XB, 2010, IEEE T IMAGE PROCESS, V19, P1126, DOI 10.1109/TIP.2009.2039050
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Martinez A.M., 1998, AR FACE DATABASE
   Meng LL, 2014, IEEE T IMAGE PROCESS, V23, P582, DOI 10.1109/TIP.2013.2288928
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Peterson L.E., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Timofte R, 2012, INT C PATT RECOG, P1606
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu D, 2007, IEEE T IMAGE PROCESS, V16, P2811, DOI 10.1109/TIP.2007.906769
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Zhang HX, 2014, NEUROCOMPUTING, V139, P289, DOI 10.1016/j.neucom.2014.02.030
   Zhang HX, 2014, PATTERN RECOGN, V47, P3168, DOI 10.1016/j.patcog.2014.04.004
   Zhang HX, 2010, FUZZY SET SYST, V161, P1790, DOI 10.1016/j.fss.2009.11.013
   Zhou WG, 2016, IEEE T PATTERN ANAL, V38, P159, DOI 10.1109/TPAMI.2015.2430329
NR 48
TC 26
Z9 26
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 187
EP 194
DI 10.1016/j.jvcir.2018.11.030
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100020
DA 2024-07-18
ER

PT J
AU Kumar, SV
   Nagaraju, C
AF Kumar, Sagenela Vijaya
   Nagaraju, C.
TI T2FCS filter: Type 2 fuzzy and cuckoo search-based filter design for
   image restoration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cuckoo search optimization algorithm; Type If fuzzy system; Image
   de-noising and restoration; Second derivative like measure of
   enhancement
ID PEPPER NOISE; SALT; ALGORITHM; REMOVAL
AB A novel filter design for the restoration of the corrupted digital image is proposed in this paper, The filter design incorporates type II fuzzy system and cuckoo search optimization algorithm (T2FCS) based filter design for the restoration of the noise in the images. The noisy pixels in the images are detected using the proposed circular based searching scheme and the detected corrupt pixels are removed using the cuckoo search algorithm. The enhanced pixels in place of the corrupt pixels are acquired using the proposed type II fuzzy system. The proposed filter adapts to various noisy conditions such as random noise, salt and pepper noise and scratch noise. The experimentation of the proposed filter design is carried out over two images. The performance of the proposed T2FCS filter design is compared over the existing image restoration algorithms using metrics; Peak Signal to Noise ratio (PSNR), Structural Similarity Index (SSIM), Second Derivative Like Measure of Enhancement (SDME). The result obtained favours the performance of the proposed filter in the restoration of the noisy images. (C) 2018 Published by Elsevier Inc.
C1 [Kumar, Sagenela Vijaya] Raj Gandhi Mem Coll Engn & Technol, Nandyal, India.
   [Kumar, Sagenela Vijaya] JNTUH, Dept CSE, Hyderabad, India.
   [Nagaraju, C.] Yogivemana Univ, YSR Engn Coll, Dept CSE, Proddatur, India.
C3 Jawaharlal Nehru Technological University - Hyderabad; Yogi Vemana
   University
RP Kumar, SV (corresponding author), Raj Gandhi Mem Coll Engn & Technol, Nandyal, India.; Kumar, SV (corresponding author), JNTUH, Dept CSE, Hyderabad, India.
EM vijayakumarsr105@gmail.com
RI ; SAGENELA, VIJAYA KUMAR/G-8913-2019
OI nagaraju, chiluka/0000-0003-1617-6011; SAGENELA, VIJAYA
   KUMAR/0000-0002-2867-3093
CR [Anonymous], KNOWLEDGE INFORM SYS
   [Anonymous], PATTERN RECOGN LETT
   [Anonymous], COMPUT ELECT ENG
   [Anonymous], IEEE SIGNAL PROCESS
   [Anonymous], BRIEF TUTORIAL INTER
   [Anonymous], P C SIGN PROC AD SPA
   Chaudhry A, 2013, APPL SOFT COMPUT, V13, P817, DOI 10.1016/j.asoc.2012.10.017
   Chen BY, 2019, INT J COMPUT MATH, V96, P992, DOI 10.1080/00207160.2018.1478415
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cho TS, 2012, IEEE T PATTERN ANAL, V34, P683, DOI 10.1109/TPAMI.2011.166
   Doroodchi M, 1996, FUZZ-IEEE '96 - PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P2117, DOI 10.1109/FUZZY.1996.552789
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo X, 2013, ISPRS J PHOTOGRAMM, V83, P50, DOI 10.1016/j.isprsjprs.2013.06.001
   Hussain A, 2010, KNOWL INF SYST, V24, P77, DOI 10.1007/s10115-009-0236-9
   Lien CY, 2013, IEEE T COMPUT, V62, P631, DOI 10.1109/TC.2011.256
   Liu J, 2015, COMPUT MATH APPL, V70, P1255, DOI 10.1016/j.camwa.2015.06.029
   Liu P., 2004, International Journal of Computational Cognition, V2, P131
   Lu CT, 2012, PATTERN RECOGN LETT, V33, P1287, DOI 10.1016/j.patrec.2012.03.025
   Mitchell HB, 2005, INFORM SCIENCES, V170, P409, DOI 10.1016/j.ins.2004.02.027
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Panetta K, 2011, IEEE T INF TECHNOL B, V15, P918, DOI 10.1109/TITB.2011.2164259
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Varghese J., 2013, EFFICIENT ADAPTIVE F
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yuan GZ, 2015, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2015.7299175
   Yuan QQ, 2012, IEEE T GEOSCI REMOTE, V50, P3660, DOI 10.1109/TGRS.2012.2185054
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang Kai, 2017, COMPUT VISION PATTER, P1
   Zhang Q, 2018, IEEE T GEOSCI REMOTE, V56, P4274, DOI 10.1109/TGRS.2018.2810208
   Zhang XQ, 2015, AEU-INT J ELECTRON C, V69, P307, DOI 10.1016/j.aeue.2014.09.018
   Zhou YY, 2013, J VIS COMMUN IMAGE R, V24, P283, DOI 10.1016/j.jvcir.2013.01.004
NR 34
TC 26
Z9 26
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 619
EP 641
DI 10.1016/j.jvcir.2018.12.020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100060
DA 2024-07-18
ER

PT J
AU Li, PY
   Lo, KT
AF Li, Peiya
   Lo, Kwok-Tung
TI Joint image encryption and compression schemes based on 16 x 16 DCT
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image encryption; JPEG compression; 16 x 16 DCT; Statistical attack
ID JPEG; SYSTEM; DESIGN
AB Joint image encryption and compression schemes have shown their great potential values in protecting compressed images. To achieve the protection, a trade-off between encryption power and compression ability needs to be considered. In this paper, we propose two new joint encryption and compression schemes, where one scheme emphasizes compression performance, another highlights protection performance. For a given plain-image, we first raster scan it into non-overlapping 16 x 16 blocks, then apply various encryption techniques to it. In the first scheme, encryption operations are conducted at the transformation stage and quantization stage of JPEG. As for the second scheme, we add the run/size and value (RSV) pairs' shuffling operation at JPEG's entropy coding stage after first scheme's encryption operations. Performance evaluations using various criteria are conducted to show that the first scheme has better compression efficiency, while the second scheme has better defense ability against the statistical attack. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Li, Peiya] Jinan Univ, Coll Cyber Secur, Guangzhou 510632, Guangdong, Peoples R China.
   [Li, Peiya; Lo, Kwok-Tung] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Peoples R China.
C3 Jinan University; Hong Kong Polytechnic University
RP Li, PY (corresponding author), Jinan Univ, Coll Cyber Secur, Guangzhou 510632, Guangdong, Peoples R China.; Li, PY (corresponding author), Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Peoples R China.
EM yolanda.peiya@connect.polyu.hk; kwok.tung.lo@polyu.edu.hk
RI Lo, Kwok Tung KT/O-2143-2013
CR [Anonymous], 2017, 1SC29WG1 ISOIEC JTC
   Au Yeung SK, 2011, INT CONF ACOUST SPEE, P2436
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chuman T, 2017, INT CONF ACOUST SPEE, P2157, DOI 10.1109/ICASSP.2017.7952538
   Faragallah OS, 2015, SIGNAL IMAGE VIDEO P, V9, P1917, DOI 10.1007/s11760-014-0683-y
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   He K., 2016, ECCV, P1
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Jha S., 2014, THESIS
   Ji XY, 2015, COMMUN NONLINEAR SCI, V22, P321, DOI 10.1016/j.cnsns.2014.09.011
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Kurihara K, 2015, IEICE T FUND ELECTR, VE98A, P2238, DOI 10.1587/transfun.E98.A.2238
   Kurihara K, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P119, DOI 10.1109/PCS.2015.7170059
   Li P, 2015, MEDIAT INFLAMM, V2015, DOI 10.1155/2015/208491
   Li PY, 2017, J VIS COMMUN IMAGE R, V44, P61, DOI 10.1016/j.jvcir.2017.01.021
   Li Peiya, 2018, IEEE T MULTIMEDIA, V20
   Li WH, 2007, INT J COMPUT MATH, V84, P1367, DOI 10.1080/00207160701294376
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   [陆阳 Lu Yang], 2003, [计算机工程与应用, Computer Engineering and Application], V39, P130
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ponnain D, 2016, OPTIK, V127, P192, DOI 10.1016/j.ijleo.2015.09.207
   Qian Z., 2016, IEEE T DEPENDABLE SE
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Saarinen M., 2015, TECH REP
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Sesha Pallavi Indrakanti P.S. A., 2011, INT J COMPUT APPL, V28, P45
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu YY, 2014, J VIS COMMUN IMAGE R, V25, P805, DOI 10.1016/j.jvcir.2014.01.005
   Yeung SKA, 2011, IEEE T CIRC SYST VID, V21, P1341, DOI 10.1109/TCSVT.2011.2125630
   Yeung SKA, 2009, IEEE SIGNAL PROC LET, V16, P893, DOI 10.1109/LSP.2009.2026109
   Younes MAB, 2008, INT J COMPUT SCI NET, V8, P191
   Zeng B, 2014, IEEE T INF FOREN SEC, V9, P309, DOI 10.1109/TIFS.2013.2293955
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P1366, DOI 10.1016/j.cnsns.2013.09.019
   Zhou JT, 2007, IEEE SIGNAL PROC LET, V14, P201, DOI 10.1109/LSP.2006.884012
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 41
TC 23
Z9 23
U1 3
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 12
EP 24
DI 10.1016/j.jvcir.2018.11.018
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100002
DA 2024-07-18
ER

PT J
AU Chen, B
   Wu, XT
   Wei, YS
AF Chen, Bing
   Wu, Xiaotian
   Wei, Yun-Shan
TI Reversible data hiding in encrypted images with private-key homomorphism
   and public-key homomorphism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Encrypted images; Lossless recovery; Homomorphic
   encryption
ID DIFFERENCE
AB This paper proposes two reversible data hiding schemes in encrypted images that provide lossless recovery of directly decrypted images. The modified homomorphic encryption is introduced to encrypt the original image so that the private-key homomorphism and public-key homomorphism are both available. To embed secret message into encrypted image, a part of encrypted pixels are replaced with new ciphertexts by homomorphic property. Finally, the original image and embedded secret message can be restored by direct decryption. Optimal visual quality is obtained by the proposed schemes, since the directly decrypted pixel value is equal to the original pixel value. And the embedding rate is further improved. In addition, the proposed schemes are suitable for compressed multimedia, which extends the application scenarios. Experimental results are presented to demonstrate the effectiveness and superiority of the proposed schemes. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Chen, Bing] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Wu, Xiaotian] Jinan Univ, Dept Comp Sci, Guangzhou 510632, Guangdong, Peoples R China.
   [Wu, Xiaotian] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Wu, Xiaotian] Nanjing Univ Informat Sci & Technol, Nanjing 210044, Jiangsu, Peoples R China.
   [Wei, Yun-Shan] Guangzhou Univ, Sch Mech & Elect Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Jinan University; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS; Nanjing University of
   Information Science & Technology; Guangzhou University
RP Chen, B (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM chenbinny@qq.com
OI Wu, Xiaotian/0000-0002-1484-2247; Chen, Bing/0000-0002-1716-877X
FU National Natural Science Foundation of China [61602211]; Science and
   Technology Program of Guangzhou, China [201707010259]; Fundamental
   Research Funds for the Central Universities
FX This work was partially supported by National Natural Science Foundation
   of China (Grant No. 61602211), Science and Technology Program of
   Guangzhou, China (Grant No. 201707010259), Fundamental Research Funds
   for the Central Universities.
CR Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Di F., 2017, ADV INTERNETWORKING, P138
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Katz J., 2014, INTRO MODERN CRYPTOG
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Puech W., 2008, P SPIE ELECT IMAGING, V6819, p68191E
   Qian ZX, 2019, IEEE T CIRC SYST VID, V29, P351, DOI 10.1109/TCSVT.2018.2797897
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qian ZX, 2013, ADV INTEL SYS RES, V84, P869
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 31
TC 8
Z9 9
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 272
EP 282
DI 10.1016/j.jvcir.2018.11.017
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400032
DA 2024-07-18
ER

PT J
AU Li, J
   Ma, B
   Wang, CP
AF Li, Jian
   Ma, Bin
   Wang, Chunpeng
TI Extraction of PRNU noise from partly decoded video
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Forensics; Smartphone; Camera; Sensor noise; PRNU
ID SENSOR PATTERN NOISE; CAMERA IDENTIFICATION; IMAGE FORENSICS; SCHEME
AB This paper presents an algorithm for extracting PRNU noise from video files taken by a smartphone camera. We consider video because they are quite prevalent in our life, but are not often involved in the existing research works. Unlike most prior arts tending to extract PRNU noise from completely decompressed video frames, our proposed algorithm leaves out some procedures in the video decoding process to reduce the computational complexity. Besides, we design a maximum-likelihood-estimation algorithm for extracting PRNU noise from partly decoded video frames, and analyze the algorithm's suitability as well in theory. Experimental results further prove the validity and effectiveness of the proposed algorithm. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Li, Jian; Ma, Bin; Wang, Chunpeng] Qilu Univ Technol, Shandong Acad Sci, Dept Comp Sci & Technol, 3501 DaXue Rd, Jinan, Shandong, Peoples R China.
   [Li, Jian] Shenzhen Key Lab Media Informat Content Secur, Shenzhen, Peoples R China.
C3 Qilu University of Technology
RP Li, J (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Dept Comp Sci & Technol, 3501 DaXue Rd, Jinan, Shandong, Peoples R China.; Li, J (corresponding author), Shenzhen Key Lab Media Informat Content Secur, Shenzhen, Peoples R China.
EM ljian20@gmail.com
FU NSFC [61502241, 61703212, 61872203, 61802212]; NSFC Jiangsu Province
   [BK20160971]
FX This work is supported partly by NSFC (61502241, 61703212, 61872203,
   61802212), NSFC Jiangsu Province (BK20160971).
CR Al-Ani M, 2017, IEEE T INF FOREN SEC, V12, P1067, DOI 10.1109/TIFS.2016.2640938
   Amerini I, 2010, INT J DIGIT CRIME FO, V2, P21, DOI 10.4018/jdcf.2010040102
   [Anonymous], 2016, IEEE T VEH TECHNOL
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], EURASIP J IMAGE VIDE
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], SPIE ELECT IMAGING S
   [Anonymous], 2008, P 10 ACM WORKSH MULT, DOI DOI 10.1145/1411328.1411353
   [Anonymous], 2009, P SPIE
   [Anonymous], ELECT IMAGING 2007
   Bayram S, 2015, IEEE T INF FOREN SEC, V10, P597, DOI 10.1109/TIFS.2014.2385634
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen SX, 2015, IEEE T INF FOREN SEC, V10, P28, DOI 10.1109/TIFS.2014.2362848
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Villalba LJG, 2016, EXPERT SYST APPL, V55, P59, DOI 10.1016/j.eswa.2016.01.025
   Goljan M., 2016, Electronic Imaging, V2016, P1, DOI [10.2352/ISSN.2470-1173.2016.8.MWSF-086, DOI 10.2352/ISSN.2470-1173.2016.8.MWSF-086]
   Goljan M, 2011, IEEE T INF FOREN SEC, V6, P227, DOI 10.1109/TIFS.2010.2099220
   Horowitz M, 2003, IEEE T CIRC SYST VID, V13, P704, DOI 10.1109/TCSVT.2003.814967
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Lawgaly A, 2017, IEEE T INF FOREN SEC, V12, P392, DOI 10.1109/TIFS.2016.2620280
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Lin XF, 2016, IEEE SIGNAL PROC LET, V23, P381, DOI 10.1109/LSP.2016.2521349
   Lin XF, 2016, IEEE T INF FOREN SEC, V11, P126, DOI 10.1109/TIFS.2015.2478748
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mehrish A, 2016, IEEE SIGNAL PROC LET, V23, P693, DOI 10.1109/LSP.2016.2549059
   Muhit AA, 2010, IEEE T CIRC SYST VID, V20, P661, DOI 10.1109/TCSVT.2010.2045804
   Pande A, 2014, IEEE T CIRC SYST VID, V24, P157, DOI 10.1109/TCSVT.2013.2276869
   PRATT WK, 1972, IEEE T COMPUT, VC 21, P636, DOI 10.1109/T-C.1972.223567
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Sharabayko MP, 2017, J PHYS CONF SER, V803, DOI 10.1088/1742-6596/803/1/012141
   Shullani D, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0067-2
   Taspinar S, 2016, IEEE INT WORKS INFOR
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu GD, 2012, IEEE IMAGE PROC, P237, DOI 10.1109/ICIP.2012.6466839
   Yoon YJ, 2012, ETRI J, V34, P106, DOI 10.4218/etrij.12.0211.0042
NR 38
TC 8
Z9 8
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2018
VL 57
BP 183
EP 191
DI 10.1016/j.jvcir.2018.10.023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HD6XU
UT WOS:000452694400022
DA 2024-07-18
ER

PT J
AU Zhang, HY
   Liu, GX
   Hao, ZH
AF Zhang, Haoyang
   Liu, Guixi
   Hao, Zhaohui
TI Robust visual tracking via multi-feature response maps fusion using a
   collaborative local-global layer visual model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Collaborative visual model; Block color tracking; Correlation filter
   tracking; Response maps fusion; Online re-detection
ID OBJECT TRACKING; SELECTION
AB This paper addresses the issue of robust visual tracking, in which an effective tracker based on multi-feature fusion under a collaborative local-global layer visual model is proposed. In the local layer, we implement a novel block tracker using structural local color histograms feature based on the foreground -background discrimination analysis approach. In the global layer we implement a complementary correlation filters-based tracker using HOG feature. Finally, the local and global trackers are linearly merged in the response maps level. We choose the different merging factors according to the reliability of each combined tracker, and when both of the combined trackers are unreliable, an online trained SVM detector is activated to re-detect the target. Experiments conducted on challenging sequences show that our final merged tracker achieves favorable tracking performance and outperforms several state-of-the-art trackers. Besides, performance of the implemented block tracker is evaluated by comparing with some relevant color histograms-based trackers. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Zhang, Haoyang; Liu, Guixi; Hao, Zhaohui] Xidian Univ, Sch Mechanoelect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Zhang, Haoyang; Liu, Guixi] Shaanxi Key Lab Integrated & Intelligent Nav, Xian, Shaanxi, Peoples R China.
C3 Xidian University
RP Liu, GX (corresponding author), Xidian Univ, Sch Mechanoelect Engn, Xian 710071, Shaanxi, Peoples R China.
EM gxliu@xidian.edu.cn
RI Zhang, Yuyao/KEH-7175-2024
FU Foundation of Preliminary Research Field of China [6140001010201];
   National Key Research and Development Program Strategic High Technology
   Special Focus [H863-031]; Open Foundation of Shaanxi Key Laboratory of
   Integrated and Intelligent Navigation
FX This work is supported by the Foundation of Preliminary Research Field
   of China under Grant No. 6140001010201, the National Key Research and
   Development Program Strategic High Technology Special Focus under Grant
   No. H863-031, and the Open Foundation of Shaanxi Key Laboratory of
   Integrated and Intelligent Navigation.
CR Abdelali HA, 2016, J VIS COMMUN IMAGE R, V34, P219, DOI 10.1016/j.jvcir.2015.11.010
   Akin O, 2016, J VIS COMMUN IMAGE R, V38, P763, DOI 10.1016/j.jvcir.2016.04.018
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2014, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-10599-4_13
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Galoogahi HK, 2013, IEEE I CONF COMP VIS, P3072, DOI 10.1109/ICCV.2013.381
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Grabner H., 2006, P BRIT MACH VIS C, V1
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Khalid O.U., 2016, P BRIT MACH VIS C
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lee DY, 2014, PROC CVPR IEEE, P3486, DOI 10.1109/CVPR.2014.446
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li ZY, 2015, VISUAL COMPUT, V31, P1319, DOI 10.1007/s00371-014-1014-6
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Nguyen HT, 2006, INT J COMPUT VISION, V69, P277, DOI 10.1007/s11263-006-7067-x
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Wang N, 2013, P ADV NEURAL INFORM
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang BC, 2018, IEEE T IMAGE PROCESS, V27, P1038, DOI 10.1109/TIP.2017.2775060
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
NR 52
TC 7
Z9 7
U1 2
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 1
EP 14
DI 10.1016/j.jvcir.2018.08.018
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500001
DA 2024-07-18
ER

PT J
AU Han, QH
   Jung, C
AF Han, Qihui
   Jung, Cheolkon
TI Guided filtering based data fusion for light field depth estimation with
   <i>L</i><sub>0</sub> gradient minimization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data fusion; Guided filtering; Light field; L-0 gradient minimization;
   Defocus response; Occlusion; Stereo matching
ID IMAGE FUSION
AB In this paper, we propose guided filtering based data fusion for light field depth estimation with L-0 gradient minimization. Stereo disparity produces good depth edge, while defocus response yields good depth information in homogeneous regions. We fuse stereo disparity and defocus response from light filed data in a guided filtering framework. In the guided filtering framework, we adopt L-0 gradient minimization as the regularization term instead of penalizing linear coefficients to consider depth characteristics that have similar depth in the same object. Moreover, we utilize edge direction in stereo matching to prevent the confusion caused by occlusion. Experimental results on both synthetic and real light field datasets show that the proposed method achieves clearer edge and less error in depth than state-of-the-arts.
C1 [Han, Qihui; Jung, Cheolkon] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Jung, C (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM zhengzk@xidian.edu.cn
FU National Natural Science Foundation of China [61271298]; International
   S&T Cooperation Program of China [2014DFG12780]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61271298) and the International S&T Cooperation Program of
   China (No. 2014DFG12780).
CR [Anonymous], 2014, P IEEE INT C COMP VI
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   Bishop TomE., 2009, ICCP, IEEE International Conference on Computational Photography, P1, DOI DOI 10.1109/ICCPHOT.2009.5559010
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Dansereau DG, 2013, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2013.137
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hu L., 2016, J IMAGE GRAPHICS
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10
   Levin A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531403
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Neri A, 2015, IEEE IMAGE PROC, P3358, DOI 10.1109/ICIP.2015.7351426
   Ren NgMarc Levoy., 2005, Light field photography with a hand-held plenoptic camera
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Sheng H., 2017, PATTERN RECOGN, V74
   Sheng HM, 2018, IEEE T IND ELECTRON, V65, P300, DOI 10.1109/TIE.2017.2714127
   Si L., 2016, DENSE DEPTH MAP ESTI
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wanner S., 2013, DATASETS BENCHMARKS
   Williem W., 2016, P IEEE C COMP VIS PA
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Xu YT, 2015, IEEE IMAGE PROC, P3540, DOI 10.1109/ICIP.2015.7351463
   Xu Z., 2011, EUR SO OBS C WORKSH
   Yu Z, 2013, IEEE I CONF COMP VIS, P2792, DOI 10.1109/ICCV.2013.347
   Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007
NR 31
TC 2
Z9 2
U1 3
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 449
EP 456
DI 10.1016/j.jvcir.2018.06.020
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100039
DA 2024-07-18
ER

PT J
AU Jeyabharathi, D
   Dejey
AF Jeyabharathi, D.
   Dejey
TI Cut set-based Dynamic Key frame selection and Adaptive Layer-based
   Background Modeling for background subtraction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cut set-based Dynamic Key frame selection; Adaptive Layer-based
   Background Modeling; Background subtraction; Object tracking
ID PARALLEL FRAMEWORK; DECISION; TRACKING; MOTION
AB Background subtraction has been widely discussed in video surveillance, but it still has open challenges such as dynamic background, illumination variation. To address these challenges a novel Cut set-based Dynamic Key frame selection (CDK) and Adaptive Layer-based Background Modeling (ALBM) approach for background subtraction is proposed which adaptively changes layers in the background model for each scenario such as static, dynamic background and high illumination.
   The concept of key frame is used to choose representative frames from the video. In order to capture the invariant directional codes of each spatio-temporal patch symmetric operators such as line and rotational symmetry are used. The proposed method identifies highly similar static spatio-temporal patches and sets it as background there by reducing the computational complexity in the foreground detection step. Both qualitative and quantitative evaluations on challenging video sequences demonstrate that the proposed algorithm performs background subtraction more favorably than the state-of-the-art methods.
C1 [Jeyabharathi, D.] Sri Krishna Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
   [Dejey] Anna Univ, Dept Comp Sci & Engn, Reg Campus Tirunelveli, Tirunelveli, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Jeyabharathi, D (corresponding author), Sri Krishna Coll Technol, Dept Informat Technol, Coimbatore, Tamil Nadu, India.
EM bharathi.durai@gmail.com
RI bharathi, Jeya/T-6437-2019
OI Dharma, Dejey/0000-0002-5173-4878
CR Andrews S., 2014, COMPUT VISION IMAGE
   [Anonymous], COMPUT SCI REV
   [Anonymous], 1952, Symmetry
   [Anonymous], IMAGE VISION COMPUTI
   Caroline S., 10 INT JOINT C COMP
   Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12
   Han B, 2012, IEEE T PATTERN ANAL, V34, P1017, DOI 10.1109/TPAMI.2011.243
   Haque M, 2013, IEEE T CIRC SYST VID, V23, P2127, DOI 10.1109/TCSVT.2013.2273622
   Herrmann Diane L., NUMBER SHAPE SYMMETR, P257
   Jeyabharathi D, 2016, MULTIMED TOOLS APPL, V75, P17617, DOI 10.1007/s11042-016-3772-9
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Liu XB, 2013, IEEE T PATTERN ANAL, V35, P3010, DOI 10.1109/TPAMI.2013.84
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Manzanera A, 2007, LECT NOTES COMPUT SC, V4756, P42
   Panda DK, 2016, IEEE SIGNAL PROC LET, V23, P45, DOI 10.1109/LSP.2015.2498839
   Pawlak M, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P805, DOI 10.1109/SSP.2011.5967827
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Sigari MH, 2008, LECT NOTES ENG COMP, P717
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Suhr JK, 2011, IEEE T CIRC SYST VID, V21, P365, DOI 10.1109/TCSVT.2010.2087810
   Tsai DM, 2009, IEEE T IMAGE PROCESS, V18, P158, DOI 10.1109/TIP.2008.2007558
   Unzueta L, 2012, IEEE T INTELL TRANSP, V13, P527, DOI 10.1109/TITS.2011.2174358
   Wixson L, 2000, IEEE T PATTERN ANAL, V22, P774, DOI 10.1109/34.868680
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xin B, 2015, PROC CVPR IEEE, P4676, DOI 10.1109/CVPR.2015.7299099
   Xu M, 2004, IEEE IMAGE PROC, P2909
   Xue GJ, 2010, IEEE INT CON MULTI, P1050, DOI 10.1109/ICME.2010.5582601
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhao X, 2008, INT C PATT RECOG, P2006
   Zhou TB, 2011, INT J NEPHROL, V2011, DOI 10.4061/2011/360357
NR 36
TC 8
Z9 8
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 434
EP 446
DI 10.1016/j.jvcir.2018.06.024
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100037
DA 2024-07-18
ER

PT J
AU Ng, CJ
   Low, CY
   Toh, KA
   Kim, J
   Teoh, ABJ
AF Ng, Cong Jie
   Low, Cheng Yaw
   Toh, Kar-Ann
   Kim, Jaihie
   Teoh, Andrew Beng Jin
TI Orthogonal filter banks with region Log-TiedRank covariance matrices for
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Orthogonal filters; Region covariance matrices; Log-TiedRank; Face
   recognition
ID GABOR; REPRESENTATION; VERIFICATION; PATTERNS; MAGNITUDES; SAMPLE
AB With the capability of fusing varying features from a specific image region, the Region Covariance Matrices (RCM) image descriptor has been evidenced plausible in face recognition. However, a systematic study for RCM, regarding which features to be fused in particular, remains absent. This paper therefore explores several features derived from the orthogonal filter ensembles, i.e., Identity Transform, Discrete Haar Transform, Discrete Cosine Transform, and Karhunen-Loeve Transform, for feature encoding in RCM. Aside from that, we also outline a RCM variant, dubbed Region Log-TiedRank Covariance Matrices (RLTCM) in this paper. The RLTCM descriptor, on average, exhibits dramatic performance gain over RCM as well as state-of-the-art descriptors, especially when probe sets far deviated from the face gallery. Furthermore, we discern that the RLTCM descriptor defined based on Identity Transform, i.e., the simplest form of orthogonal filters, and other learning-free orthogonal filters yield impressive performance on par with the learning-based counterparts.
C1 [Ng, Cong Jie; Toh, Kar-Ann; Kim, Jaihie; Teoh, Andrew Beng Jin] Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul, South Korea.
   [Low, Cheng Yaw] Multimedia Univ, Fac Informat Sci & Technol, Melaka, Malaysia.
C3 Yonsei University; Multimedia University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul, South Korea.
EM chengyawlow@yonsei.ac.kr; katoh@yonsei.ac.kr; jhkim@yonsei.ac.kr;
   bjteoh@yonsei.ac.kr
RI Low, Cheng/AFS-4768-2022; Teoh, Andrew Beng Jin/F-4422-2010
OI Low, Cheng/0000-0002-6764-0614; 
FU National Research Foundation of Korea (NRF) - Korea government (MSIP)
   [2016R1A2B4011656]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (NO.
   2016R1A2B4011656).
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2006, Nonparametrics: Statistical Methods Based on Ranks
   [Anonymous], 1948, RANK CORRELATION MET
   [Anonymous], 2012, FACE RECOGNITION USI
   Arashloo SR, 2014, IEEE T INF FOREN SEC, V9, P2100, DOI 10.1109/TIFS.2014.2359587
   Arashloo ShervinRahimzadeh., 2013, BIOMETRICS THEORY AP, P1, DOI DOI 10.1109/BTAS.2013.6712721
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Arsigny V, 2006, MAGN RESON MED, V56, P411, DOI 10.1002/mrm.20965
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Berger M., 2003, PANORAMIC VIEW RIEMA
   Chai ZH, 2014, IEEE T INF FOREN SEC, V9, P14, DOI 10.1109/TIFS.2013.2290064
   Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809
   Chan T. -H., 2014, ARXIV14043606CS
   Haar A, 1910, MATH ANN, V69, P331, DOI 10.1007/BF01456326
   Hong XP, 2009, PROC CVPR IEEE, P1802, DOI 10.1109/CVPRW.2009.5206742
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Hu Junlin., 2014, COMPUTER VISION ACCV, P252
   Huang C., 2012, ARXIV12126094CS
   Hyvärinen A, 2009, COMPUT IMAGING VIS, V39, P1
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Juefei-Xu F, 2015, IEEE T IMAGE PROCESS, V24, P4780, DOI 10.1109/TIP.2015.2468173
   Kannala J, 2012, INT C PATT RECOG, P1363
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li H., 2014, MICROSOFT RES
   Li X., 2004, J VIS COMMUN IMAGE R, V49, P38
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Low CY, 2016, INT CONF ACOUST SPEE, P2094, DOI 10.1109/ICASSP.2016.7472046
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lu J, 2009, ELECTRON LETT, V45, P880, DOI 10.1049/el.2009.0871
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Ng CJ, 2016, INT CONF ACOUST SPEE, P2099, DOI 10.1109/ICASSP.2016.7472047
   Ng CJ, 2015, ASIAPAC SIGN INFO PR, P761, DOI 10.1109/APSIPA.2015.7415375
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ouamane A, 2015, IEEE INT CONF AUTOMA
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Pang YW, 2008, IEEE T SYST MAN CY B, V38, P1652, DOI 10.1109/TSMCB.2008.927276
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Qin HF, 2012, ELECTRON LETT, V48, P992, DOI 10.1049/el.2012.1519
   Qin HF, 2012, SENSORS-BASEL, V12, P7410, DOI 10.3390/s120607410
   RAY WD, 1970, IEEE T INFORM THEORY, V16, P663, DOI 10.1109/TIT.1970.1054565
   Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205
   Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Sra S, 2016, P AM MATH SOC, V144, P2787, DOI 10.1090/proc/12953
   Tahir MA, 2011, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2011.6116667
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P235
   Tran A. T., 2016, ARXIV161204904 CS
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Tuzel O, 2007, PROC CVPR IEEE, P1736
   Venables WN., 2002, MODERN APPL STAT S
   Vetterli Martin, 1995, Wavelets and Subband Coding
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866
   Wang R., 2012, Introduction to Orthogonal Transforms : With Applications in Data Processing and Analysis
   Wang RY, 2012, INTRODUCTION TO ORTHOGONAL TRANSFORMS: WITH APPLICATIONS IN DATA PROCESSING AND ANALYSIS, P1
   Wang Z., 1984, IEEE Transactions on Acoustics, Speech and Signal Processing, VASSP-32, P803, DOI 10.1109/TASSP.1984.1164399
   Wang ZZ, 2004, IEEE T MED IMAGING, V23, P930, DOI 10.1109/TMI.2004.831218
   Wolf L, 2011, CVPR, DOI DOI 10.1109/CVPR.2011.5995566
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Xi M, 2016, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP.2016.7532955
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yi D, 2013, PROC CVPR IEEE, P3539, DOI 10.1109/CVPR.2013.454
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Ylioinas Juha, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P516, DOI 10.1007/978-3-319-19665-7_44
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 74
TC 3
Z9 3
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 548
EP 560
DI 10.1016/j.jvcir.2018.07.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100048
DA 2024-07-18
ER

PT J
AU Unde, AS
   Deepthi, PP
AF Unde, Amit Satish
   Deepthi, P. P.
TI Fast BCS-FOCUSS and DBCS-FOCUSS with augmented Lagrangian and minimum
   residual methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Block compressive sensing; BCS-FOCUSS; DBCS-FOCUSS; BCS-augmented
   Lagrangian method; Minimum residual method
ID SENSOR NETWORKS; VIDEO; RECONSTRUCTION
AB Block compressive sensing FOCal Underdetermined System Solver (BCS-FOCUSS) and distributed BCS-FOCUSS (DBCS-FOCUSS) are iterative algorithms for individual and joint recovery of correlated images. The performance of both these algorithms was noticed to be best within BCS framework. However, both these algorithms suffer from high computational complexity and recovery time. This is caused by the need for an explicit computation of matrix inverse in each iteration and a slow convergence from a poor starting point. In this paper, we propose a methodology to obtain fast and good initial solution using the augmented Lagrangian method to improve the convergence rate of both algorithms. We also propose to incorporate the minimum residual method to avoid matrix inversion to reduce the computational cost. Simulation studies with the proposed modified BCS-FOCUSS and DBCS-FOCUSS demonstrate a significant reduction in the computational cost and recovery time while improving reconstruction quality for both individual and joint reconstruction algorithms.
C1 [Unde, Amit Satish; Deepthi, P. P.] Natl Inst Technol, Dept Elect & Commun Engn, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Unde, AS (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Calicut, Kerala, India.
EM amitsunde@gmail.com
RI Unde, Amit/AAG-5426-2021
OI Unde, Amit/0000-0002-3874-1272
CR Akyildiz IF, 2007, COMPUT NETW, V51, P921, DOI 10.1016/j.comnet.2006.10.002
   BARZILAI J, 1988, IMA J NUMER ANAL, V8, P141, DOI 10.1093/imanum/8.1.141
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Bertsekas D. P., 2014, CONSTRAINED OPTIMIZA
   Boyd S., 2004, CONVEX OPTIMIZATION
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   Gutknecht MH, 2007, Frontiers of Computational Science, P53, DOI 10.1007/978-3-540-46375-7_5
   Hua-bong M., 2006, J SOFTWARE, V9
   Li CB, 2013, COMPUT OPTIM APPL, V56, P507, DOI 10.1007/s10589-013-9576-1
   Mun S, 2009, IEEE IMAGE PROC, P3021, DOI 10.1109/ICIP.2009.5414429
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Namitha AS, 2015, WIRELESS PERS COMMUN, V83, P343, DOI 10.1007/s11277-015-2396-0
   Nocedal J, 2006, SPRINGER SER OPER RE, P101
   PAIGE CC, 1975, SIAM J NUMER ANAL, V12, P617, DOI 10.1137/0712047
   Puri R, 2006, IEEE SIGNAL PROC MAG, V23, P94, DOI 10.1109/MSP.2006.1657820
   Richardson Iain E, 2004, H. 264 and MPEG-4 Video Compression: Video Coding for Next-Generation Multimedia
   Saad Y, 2003, ITERATIVE METHODS SP, DOI DOI 10.1137/1.9780898718003
   Unde AS, 2017, J VIS COMMUN IMAGE R, V44, P187, DOI 10.1016/j.jvcir.2017.01.028
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiong ZX, 2004, IEEE SIGNAL PROC MAG, V21, P80, DOI 10.1109/MSP.2004.1328091
NR 25
TC 2
Z9 2
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 92
EP 100
DI 10.1016/j.jvcir.2018.02.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300009
DA 2024-07-18
ER

PT J
AU Ding, F
   Zhu, GP
   Dong, WQ
   Shi, YQ
AF Ding, Feng
   Zhu, Guopu
   Dong, Weiqiang
   Shi, Yun-Qing
TI An efficient weak sharpening detection method for image forensics
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image forensics; Sharpening detection; Overshoot artifact; Edge
   perpendicular binary coding; Ternary coding
ID JPEG COMPRESSION; ENHANCEMENT
AB In recent years, image sharpening detection has become one of the main topics in the field of image forensics. It is, however, still a challenge to detect the images sharpened with weak sharpening strength. To address this challenge, we propose an efficient method for image sharpening detection. In the proposed method, a ternary coding strategy with adaptive threshold is introduced to reveal the overshoot artifacts caused by weak sharpening. Extensive experiments are conducted to illustrate the superiority of the proposed method. The experimental results show that the proposed method can achieve a considerable improvement in sharpening detection, especially for slightly sharpened images.
C1 [Ding, Feng; Dong, Weiqiang; Shi, Yun-Qing] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ 07102 USA.
   [Zhu, Guopu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, GD, Peoples R China.
   [Zhu, Guopu] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 New Jersey Institute of Technology; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of
   Sciences; Institute of Information Engineering, CAS
RP Zhu, GP (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, GD, Peoples R China.
EM fd26@njit.edu; gp.zhu@siat.ac.cn; wd35@njit.edu; shi@njit.edu
RI Shi, Yun/JWP-3360-2024; zhen, wang/KBA-3844-2024
OI Dong, Weiqiang/0000-0001-7271-8853; Zhu, Guopu/0000-0001-7956-5343
FU National Natural Science Foundation of China [61572489, 61672554]; Youth
   Innovation Promotion Association of CAS [2015299]; Basic Research
   Program of Shenzhen [JCYJ20150630114942312, JCYJ20150630114942260];
   Natural Science Foundation of Guangdong Province [2016A050503035]
FX The authors sincerely appreciate the anonymous reviewers for their
   valuable comments and Prof. Yao Zhao for kindly offering the code of
   [13] for comparison. This work was supported in part by the National
   Natural Science Foundation of China under grants 61572489 and 61672554,
   in part by the Youth Innovation Promotion Association of CAS under grant
   2015299, in part by the Basic Research Program of Shenzhen under grants
   JCYJ20150630114942312 and JCYJ20150630114942260, and in part by the
   Natural Science Foundation of Guangdong Province under grant
   2016A050503035.
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], INT WORKSH DIG FOR W
   [Anonymous], 2013, ISRN SIGNAL PROCESS
   Bruna A., 2008, P SPIE, V6812
   Buemi A, 2009, LECT NOTES COMPUT SC, V5716, P863, DOI 10.1007/978-3-642-04146-4_92
   Canny J.F., 1983, Finding edges and lines in images, V1
   Cao G, 2011, IEEE SIGNAL PROC LET, V18, P603, DOI 10.1109/LSP.2011.2164791
   Cao G, 2009, IEEE INT CON MULTI, P1026, DOI 10.1109/ICME.2009.5202672
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Ding F., 2015, INT WORKSH DIG FOR W
   Ding F, 2015, IEEE SIGNAL PROC LET, V22, P327, DOI 10.1109/LSP.2014.2359033
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guanshuo Xu, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P392, DOI 10.1109/ICME.2012.87
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Kee E, 2011, P NATL ACAD SCI USA, V108, P19907, DOI 10.1073/pnas.1110747108
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li Z., 2012, INT WORKSH DIG FOR W
   Maini R., 2009, Int J Image Process, V3, P1
   Malin D. F., 1977, AM ASTR SOC PHOTO B, V16, P10
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Ramponi G, 1996, J ELECTRON IMAGING, V5, P353, DOI 10.1117/12.242618
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Thévenaz P, 2000, BIOMED EN S, P393
   Van Lanh T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P16
   Yang JQ, 2015, DIGIT SIGNAL PROCESS, V41, P90, DOI 10.1016/j.dsp.2015.03.014
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
NR 29
TC 24
Z9 26
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 93
EP 99
DI 10.1016/j.jvcir.2017.11.009
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700010
DA 2024-07-18
ER

PT J
AU Choi, DY
   Song, BC
AF Choi, Dong Yoon
   Song, Byung Cheol
TI Fast super-resolution algorithm using rotation-invariant ELBP classifier
   and hierarchical pattern matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reconstruction; Super-resolution; Classification; FIR filters;
   Up-scaling; Hierarchical addressing
ID IMAGE SUPERRESOLUTION
AB This paper proposes a fast super-resolution (SR) algorithm using content-adaptive two-dimensional (2D) finite impulse response (FIR) filters based on a rotation-invariant classifier. The proposed algorithm consists of a learning stage and an inference stage. In the learning stage, we cluster a sufficient number of low-resolution (LR) and high-resolution (HR) patch pairs into a specific number of groups using the rotation-invariant classifier, and choose a specific number of dominant clusters. Then, we compute the optimal 2D FIR filter(s) to synthesize a high-quality HR patch from an LR patch per cluster, and finally store the patch-adaptive 2D FIR filters in a dictionary. Also, we present a smart hierarchical addressing method for effective dictionary exploration in the inference stage. In the inference stage, the ELBP of each input LR patch is extracted in the same way as the learning stage, and the best matched FIR filter(s) to the input LR patch is found from the dictionary by the hierarchical addressing. Finally, we synthesize the HR patch by using the optimal 2D FIR filter. The experimental results show that the proposed algorithm produces better HR images than the existing SR methods, while providing fast running time. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Choi, Dong Yoon; Song, Byung Cheol] Inha Univ, Dept Elect Engn, 100 Inha Ro, Incheon 22212, South Korea.
C3 Inha University
RP Song, BC (corresponding author), Inha Univ, Dept Elect Engn, 100 Inha Ro, Incheon 22212, South Korea.
EM bcsong@inha.ac.kr
RI Song, Byungcheol/AAH-9770-2019
OI Song, Byung Cheol/0000-0001-8742-3433
FU National Research Foundation of Korea Grant - Korean Government
   [2016R1A2B4007353]; WCSL (World Class Smart Lab) research grant
FX This research was supported by National Research Foundation of Korea
   Grant funded by the Korean Government (2016R1A2B4007353), and was also
   supported by WCSL (World Class Smart Lab) research grant directed by
   Inha University.
CR [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2004, IEEE C COMP VIS PATT
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gonzalez R.C., DIGITAL IMAGE PROCES, P87
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Kondo T., 1995, US-patent, Patent No. [5,444,487, 5444487]
   Kunic Srecko, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P83
   Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614
   Martin D., 2010, P IEEE INT C COMP VI, P416
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yu JF, 2014, IEEE T NEUR NET LEAR, V25, P780, DOI 10.1109/TNNLS.2013.2281313
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
NR 25
TC 1
Z9 1
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 1
EP 15
DI 10.1016/j.jvcir.2017.05.013
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700001
DA 2024-07-18
ER

PT J
AU Liu, W
   Gao, YH
   Ma, HD
   Yu, S
   Nie, J
AF Liu, Wu
   Gao, Yihong
   Ma, Huadong
   Yu, Shui
   Nie, Jie
TI Online multi-objective optimization for live video forwarding across
   video data centers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Big video data; Video data center; Live video forwarding; Resource
   provisioning optimization
ID ALLOCATION
AB The proliferation of video surveillance has led to surveillance video forwarding services becoming a basic server in video data centers. End users in diverse locations require live video streams from the IP cameras through the inter-connected video data centers. Consequently, the resource scheduler, which is set up to assign the resources of the video data centers to each arriving end user, is in urgent need of achieving the global optimal resource cost and forwarding delay. In this paper, we propose a multi-objective resource provisioning (MORP) approach to minimize the resource provisioning cost during live video forwarding. Different from existed works, the MORP optimizes the resource provisioning cost from both the resource cost and forwarding delay. Moreover, as an approximate optimal approach, MORP adaptively assigns the proper media servers among video data centers, and connects these media servers together through network connections to provide system scalability and connectivity. Finally, we prove that the computational complexity of our online approach is only 0(log(vertical bar U vertical bar)) (vertical bar U vertical bar is the number of arrival end users). The comprehensive evaluations show that our approach not only significantly reduces the resource provisioning cost, but also has a considerably shorter computational delay compared to the benchmark approaches. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Wu; Gao, Yihong; Ma, Huadong] Beijing Univ Posts & Telecomm, Beijing Key Lab Intelligent Telecomm Software & M, Beijing 100876, Peoples R China.
   [Yu, Shui] Deakin Univ, Sch Informat Technol, Melbourne, Vic 3125, Australia.
   [Nie, Jie] Tsinghua Univ, Dept Comp Sci & Technol, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Deakin University;
   Tsinghua University
RP Liu, W (corresponding author), Beijing Univ Posts & Telecomm, Beijing Key Lab Intelligent Telecomm Software & M, Beijing 100876, Peoples R China.
EM liuwu@bupt.edu.cn; mhd@bupt.edu.cn; hii_gao@hotmail.com;
   shui.yu@deakin.edu.au; niejie@tsinghua.edu.cn
RI Yu, Shui/AFL-2699-2022; Liu, Wu/AAG-3615-2019
OI Yu, Shui/0000-0003-4485-6743; Liu, Wu/0000-0003-1633-7575
FU National Key Research and Development Plan [2016YFC0801005]; National
   Natural Science Foundation of China [61602049]; Funds for Creative
   Research Groups of China [61421061]; Beijing Training Project for the
   Leading Talents in ST [ljrc 201502]; CCF-Tencent Open Research Fund
   [AGR20160113]
FX This work is partially supported by the National Key Research and
   Development Plan (No. 2016YFC0801005), the National Natural Science
   Foundation of China (No. 61602049), the Funds for Creative Research
   Groups of China (No. 61421061), the Beijing Training Project for the
   Leading Talents in S&T (No. ljrc 201502), and the CCF-Tencent Open
   Research Fund (No. AGR20160113).
CR Adhikari V.K., 2010, Proc. 10th Internet Measurement Conference IMC, P431
   Adhikari VK, 2012, IEEE INFOCOM SER, P2521, DOI 10.1109/INFCOM.2012.6195644
   Adhikari VK, 2012, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2012.6195531
   [Anonymous], 2014, P IEEE INT S WORLD W
   Chen YY, 2011, IEEE INFOCOM SER, P1620, DOI 10.1109/INFCOM.2011.5934955
   Chu LY, 2015, PROC VLDB ENDOW, V8, P826, DOI 10.14778/2757807.2757808
   Feng Y., 2012, Proc. 20th ACM international conference on Multimedia, P259
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gao YH, 2015, INT CONF CLOUD COMP, P210, DOI 10.1109/CloudCom.2015.68
   Hao F, 2014, IEEE INFOCOM SER, P10, DOI 10.1109/INFOCOM.2014.6847919
   Hao T, 2016, INT J MOL SCI, V17, DOI 10.3390/ijms17060907
   Hu H., 2014, proceeding of The IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME.2014.6890134
   Hu ML, 2014, IEEE T PARALL DISTR, V25, P2169, DOI 10.1109/TPDS.2013.287
   Jiao L, 2014, IEEE INFOCOM SER, P28, DOI 10.1109/INFOCOM.2014.6847921
   Liao J, 2013, IEEE T MULTIMEDIA, V15, P670, DOI 10.1109/TMM.2012.2235416
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu W, 2015, PROC CVPR IEEE, P3707, DOI 10.1109/CVPR.2015.7298994
   Mukerjee M.K., 2015, Proceedings of the 2015 ACM Conference on Special Interest Group on Data Communication, P311
   Nie WZ, 2015, PROC CVPR IEEE, P4503, DOI 10.1109/CVPR.2015.7299080
   Nishida H, 2013, IEEE T PARALL DISTR, V24, P565, DOI 10.1109/TPDS.2012.169
   Felice MCS, 2014, LECT NOTES COMPUT SC, V8392, P574
   Si XB, 2012, IEEE INT WORKS INFOR, P1, DOI 10.1109/WIFS.2012.6412616
   Wang B, 2016, MOL BIOSYST, V12, P246, DOI 10.1039/c5mb00571j
   Wang F, 2012, IEEE INFOCOM SER, P199, DOI 10.1109/INFCOM.2012.6195578
   Wang Z, 2016, IEEE T PARALL DISTR, V27, P735, DOI 10.1109/TPDS.2015.2414941
   Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102
   Zhang G, 2015, IEEE T MULTIMEDIA, V17, P229, DOI 10.1109/TMM.2014.2383617
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
   Zhao YH, 2014, IEEE INFOCOM SER, P298, DOI 10.1109/INFOCOM.2014.6847951
   Zheng HY, 2016, IEEE T PARALL DISTR, V27, P271, DOI 10.1109/TPDS.2015.2388473
   Zheng HY, 2013, INT CON DISTR COMP S, P500, DOI 10.1109/ICDCS.2013.44
NR 33
TC 7
Z9 7
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 502
EP 513
DI 10.1016/j.jvcir.2017.01.010
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700044
DA 2024-07-18
ER

PT J
AU Yang, CN
   Wu, XT
   Chou, YC
   Fu, ZJ
AF Yang, Ching-Nung
   Wu, Xiaotian
   Chou, Yung-Chien
   Fu, Zhangjie
TI Constructions of general (<i>k</i>, <i>n</i>) reversible AMBTC-based
   visual cryptography with two decryption options
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Block truncation coding; Reversible; Meaningful
   shadows; OR decryption; XOR decryption
AB In this paper, a general method of (k, n) threshold Reversible Absolute moment block truncation coding Visual Cryptography Scheme (RAVCS) is introduced for sharing a binary secret image into multiple absolute moment block truncation coding (AMBTC) shadows. A (k, k) RAVCS is firstly proposed to encode a secret by referencing one ABMTC image. Then, the proposed (k, k) RAVCS is adopted to share the same secret into multiple groups of shadows by referencing multiple images. Those multiple groups of shadows are distributed to participants according to a matrix generated by the proposed shadow distribution algorithms. When any k or more participants share their shadows, the secret image is revealed by OR or XOR decryption. Further, those AMBTC shadows can be losslessly reverted to their original forms. Sufficient theoretical analysis and extensive experimental results are provided in this paper, showing the effectiveness and advantages of the proposed method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yang, Ching-Nung; Chou, Yung-Chien] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
   [Wu, Xiaotian] Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Wu, Xiaotian; Fu, Zhangjie] Nanjing Univ Informat Sci & Technol, Nanjing, Jiangsu, Peoples R China.
   [Wu, Xiaotian] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
C3 National Dong Hwa University; Jinan University; Nanjing University of
   Information Science & Technology; Chinese Academy of Sciences; Institute
   of Information Engineering, CAS
RP Wu, XT (corresponding author), Jinan Univ, Dept Comp Sci, Guangzhou, Guangdong, Peoples R China.
EM cnyang@gms.ndhu.edu.tw; wxt.sysu@gmail.com; wwwfzj@126.com
RI Yang, Ching-Nung/HKV-1639-2023
OI Wu, Xiaotian/0000-0002-1484-2247
FU National Natural Science Foundation of China [61602211]; Science and
   Technology Program of Guangzhou, China [201707010259]; Natural Science
   Foundation of Guangdong Province, China; Priority Academic Program
   Development of Jiangsu Higer Education Institutions (PAPD); Jiangsu
   Collaborative Innovation Center on Atmospheric Environment and Equipment
   Technology (CICAEET); Ministry of Science and Technology
   [105-2221-E259-015-MY2]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant No. 61602211), Science and Technology Program of
   Guangzhou, China (Grant No. 201707010259), Natural Science Foundation of
   Guangdong Province, China, Priority Academic Program Development of
   Jiangsu Higer Education Institutions (PAPD), Jiangsu Collaborative
   Innovation Center on Atmospheric Environment and Equipment Technology
   (CICAEET) and Ministry of Science and Technology, under Grant
   105-2221-E259-015-MY2.
CR Ou DH, 2014, J VIS COMMUN IMAGE R, V25, P1222, DOI 10.1016/j.jvcir.2013.12.018
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
NR 4
TC 12
Z9 12
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 182
EP 194
DI 10.1016/j.jvcir.2017.06.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700015
DA 2024-07-18
ER

PT J
AU Fitschen, JH
   Losch, K
   Steidl, G
AF Fitschen, Jan Henrik
   Losch, Katharina
   Steidl, Gabriele
TI Unsupervised multi class segmentation of 3D images with intensity
   inhomogeneities
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Image segmentation; Variational methods; Non-convex
   optimization; PALM; Biconvex model; Illumination correction; Intensity
   inhomogeneities; FIB tomography
ID FUZZY C-MEANS; RETINEX THEORY; VARIATIONAL MODEL; MEANS ALGORITHM; MRI
   DATA; OPTIMIZATION; MINIMIZATION; NONCONVEX
AB Intensity inhomogeneities in images cause problems in gray-value based image segmentation since the varying intensity often dominates over gray-value differences of the image structures. In this paper we propose a novel biconvex variational model that includes the intensity inhomogeneities to tackle this task. We combine a total variation approach for multi class segmentation with a multiplicative model to handle the inhomogeneities. In our model we assume that the image intensity is the product of a smoothly varying part and a component which resembles important image structures such as edges. Therefore, we penalize in addition to the total variation of the label assignment matrix a quadratic difference term to cope with the smoothly varying factor. A critical point of the resulting biconvex functional is computed by a modified proximal alternating linearized minimization method (PALM). We show that the assumptions for the convergence of the algorithm are fulfilled. Various numerical examples demonstrate the very good performance of our method. Particular attention is paid to the segmentation of 3D FIB tomographical images serving as a motivation for our work. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Fitschen, Jan Henrik; Steidl, Gabriele] Univ Kaiserslautern, Dept Math, Kaiserslautern, Germany.
   [Losch, Katharina; Steidl, Gabriele] Fraunhofer ITWM, Kaiserslautern, Germany.
C3 University of Kaiserslautern
RP Fitschen, JH (corresponding author), Univ Kaiserslautern, Dept Math, Kaiserslautern, Germany.
EM fitschen@mathematik.uni-kl.de; steidl@mathematik.uni-kl.de
FU German Research Foundation (DFG) within the Research Training Group 1932
FX Funding by the German Research Foundation (DFG) within the Research
   Training Group 1932 "Stochastic Models for Innovations in the
   Engineering Sciences", project area P3, is gratefully acknowledged. The
   authors thank K. Schladitz (Fraunhofer ITWM, Kaiser-slautern) and F.
   Balle, T. Beck and S. Schuff (Department of Mechanical and Process
   Engineering, University of Kaiserslautern) for fruitful discussions. We
   are thankful to T. Lober (Nano Structuring Center Kaiserslautern) for
   creating FIB/SEM data of the aluminum matrix composite used in Figs. 1,
   7 and 8.
CR Adelson E.H., 1995, CHECKERSHADOW ILLUSI
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Ali H, 2016, PATTERN RECOGN, V51, P27, DOI 10.1016/j.patcog.2015.08.022
   [Anonymous], 2008, DIGITAL IMAGE PROCES
   [Anonymous], TECHNICAL REPORT
   Attouch H, 2010, MATH OPER RES, V35, P438, DOI 10.1287/moor.1100.0449
   Bae E., 2009, 0975 CAM UCLA
   Bezdek James C., 1981, PATTERN RECOGN
   BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296
   BEZDEK JC, 1980, IEEE T PATTERN ANAL, V2, P1, DOI 10.1109/TPAMI.1980.4766964
   Bolte J., T AM MATH SOC, V362
   Bolte J, 2014, MATH PROGRAM, V146, P459, DOI 10.1007/s10107-013-0701-9
   Brinkmann B. H., IEEE T MED IMAG, V17
   Cai XH, 2013, SIAM J IMAGING SCI, V6, P368, DOI 10.1137/120867068
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Dawant B. M., IEEE T MED IMAG, V12
   Gilles S, 1996, LECT NOTES COMPUT SC, V1131, P153, DOI 10.1007/BFb0046950
   Gorski J, 2007, MATH METHOD OPER RES, V66, P373, DOI 10.1007/s00186-007-0161-1
   He YY, 2012, PATTERN RECOGN, V45, P3463, DOI 10.1016/j.patcog.2012.03.009
   Johnston B, 1996, IEEE T MED IMAGING, V15, P154, DOI 10.1109/42.491417
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lellmann J., 2009, INT C COMP VIS
   Lellmann J, 2009, LECT NOTES COMPUT SC, V5567, P150, DOI 10.1007/978-3-642-02256-2_13
   Li C.S., 2007, Simulation of Soil Organic Carbon Storage and Changes in Agricultural Cropland in China and Its Impact on Food Security, P1
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2008, LECT NOTES COMPUT SC, V5242, P1083
   Liang JW, 2015, J MATH IMAGING VIS, V52, P345, DOI 10.1007/s10851-015-0568-x
   Ma L, 2007, PATTERN RECOGN, V40, P3005, DOI 10.1016/j.patcog.2007.02.005
   Ma WY, 2011, PROC CVPR IEEE, P153, DOI 10.1109/CVPR.2011.5995422
   MEYER CR, 1995, IEEE T MED IMAGING, V14, P36, DOI 10.1109/42.370400
   Miyamoto S., 1996, P 4 INT WORKSH ROUGH, P255
   Morel JM, 2010, IEEE T IMAGE PROCESS, V19, P2825, DOI 10.1109/TIP.2010.2049239
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Pham DL, 1999, PATTERN RECOGN LETT, V20, P57, DOI 10.1016/S0167-8655(98)00121-4
   Pock T, 2009, PROC CVPR IEEE, P810, DOI 10.1109/CVPRW.2009.5206604
   Rockafellar R. T., 2015, CONVEX ANAL, DOI DOI 10.1515/9781400873173
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shafei B, 2012, J VIS COMMUN IMAGE R, V23, P611, DOI 10.1016/j.jvcir.2012.02.006
   Strang G, 2014, SIAM REV, V56, P525, DOI 10.1137/120897572
   TINCHER M, 1993, IEEE T MED IMAGING, V12, P361, DOI 10.1109/42.232267
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Zach C., 2008, VIS MOD VIS WORKSH
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
NR 45
TC 2
Z9 3
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 312
EP 323
DI 10.1016/j.jvcir.2017.04.011
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500028
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, GY
   Xu, HY
   Yu, M
   Luo, T
   Zhang, Y
AF Jiang, Gangyi
   Xu, Haiyong
   Yu, Mei
   Luo, Ting
   Zhang, Yun
TI Stereoscopic image quality assessment by learning non-negative matrix
   factorization-based color visual characteristics and considering
   binocular interactions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic image quality assessment; Non-negative matrix
   factorization; Schmidt orthogonalization; Monocular perception;
   Binocular interaction
ID COMPRESSION; SIMILARITY; OBJECTS; PARTS
AB In this paper, we propose a novel stereoscopic image quality assessment (SIQA) method by learning non negative matrix factorization (NMF)-based color visual characteristics for monocular perception and considering binocular interactions. In training phase, a feature basis matrix is learned based on NMF by considering color information and a feature detector is designed by performing Schmidt orthogonalization on the feature basis matrix. In construction of SIQA phase, for monocular perception, visual saliency regions are selected and parts -based feature similarity indexes of left and right views based on the feature vectors extracted by the feature detector are calculated. For binocular interactions, we calculate cyclopean feature similarity index by considering binocular fusion and rivalry. Finally, support vector regression is used to simulate nonlinear relationship between monocular perception and binocular interactions. Experimental results on LIVE 3D image databases and NBU 3D IQA database demonstrate that the proposed SIQA method is more consistent with human perception. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Jiang, Gangyi; Xu, Haiyong; Yu, Mei; Luo, Ting] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Xu, Haiyong; Luo, Ting] Ningbo Univ, Coll Sci & Technol, Ningbo 315211, Zhejiang, Peoples R China.
   [Zhang, Yun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
C3 Ningbo University; Ningbo University; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS
RP Jiang, GY; Xu, HY (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM jianggangyi@126.com; xuhaiyong@nbu.edu.cn
RI jiang, gang/KII-8233-2024; Zhang, Yun/V-7261-2019
OI Zhang, Yun/0000-0001-9457-7801
FU National Natural Science Foundation of China [U1301257, 61671258,
   61620106012, 61471348, 61501270]; National High-tech R&D Program of
   China [2015AA015901]; Zhejiang Provincial Natural Science Foundation of
   China [LY15F010005]; Natural Science Foundation of Ningbo [2016A610071];
   K.C. Wong Magna Fund in Ningbo University
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant U1301257, Grant 61671258, Grant
   61620106012, Grant 61471348, and Grant 61501270, the National High-tech
   R&D Program of China (2015AA015901), and in part by Zhejiang Provincial
   Natural Science Foundation of China under Grant LY15F010005, Natural
   Science Foundation of Ningbo under Grant No. 2016A610071, and in part by
   the K.C. Wong Magna Fund in Ningbo University.
CR Aflaki P, 2015, SIGNAL IMAGE VIDEO P, V9, P331, DOI 10.1007/s11760-013-0439-0
   [Anonymous], P SPIE
   [Anonymous], 2011, 2011 IEEE INT INSTRU, DOI DOI 10.1109/IMTC.2011.5944170
   [Anonymous], 2011, MICT Image Quality Evaluation Database
   [Anonymous], P INT WORKSH VID PRO
   [Anonymous], 2010, P 5 INT WORKSH VID P
   [Anonymous], 2014, INT S BROADB MULT SY
   Battisti F, 2015, SIGNAL PROCESS-IMAGE, V30, P78, DOI 10.1016/j.image.2014.10.005
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bensalma R, 2013, MULTIDIM SYST SIGN P, V24, P281, DOI 10.1007/s11045-012-0178-3
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Coria LE, 2011, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE 2011), P755, DOI 10.1109/ICCE.2011.5722846
   Ding J, 2006, P NATL ACAD SCI USA, V103, P1141, DOI 10.1073/pnas.0509629103
   Geng XQ, 2017, SIGNAL PROCESS-IMAGE, V52, P54, DOI 10.1016/j.image.2016.12.004
   Grossberg S, 1999, VISION RES, V39, P3796, DOI 10.1016/S0042-6989(99)00095-4
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Hewage CTER, 2011, IEEE T CONSUM ELECTR, V57, P1185, DOI 10.1109/TCE.2011.6018873
   Klaus A, 2006, INT C PATT RECOG, P15
   Le Callet P., 2005, Subjective quality assessment irccyn/ivc database
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee K, 2015, IEEE J-STSP, V9, P533, DOI 10.1109/JSTSP.2015.2393296
   Levelt W.J. M., 1968, BINOCULAR RIVALRY
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Lv YQ, 2016, SIGNAL PROCESS-IMAGE, V47, P346, DOI 10.1016/j.image.2016.07.003
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meegan DV, 2001, J EXP PSYCHOL-APPL, V7, P143, DOI 10.1037//1076-898X.7.2.143
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   PALMER SE, 1977, COGNITIVE PSYCHOL, V9, P441, DOI 10.1016/0010-0285(77)90016-0
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Ryu S, 2012, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2012.6466933
   Sazzad ZMP, 2009, INT WORK QUAL MULTIM, P180, DOI 10.1109/QOMEX.2009.5246956
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Shao F, 2015, IEEE T BROADCAST, V61, P154, DOI 10.1109/TBC.2015.2402491
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   WACHSMUTH E, 1994, CEREB CORTEX, V4, P509, DOI 10.1093/cercor/4.5.509
   Wang JH, 2017, IEEE T IMAGE PROCESS, V26, P1202, DOI 10.1109/TIP.2016.2642791
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Yang J.-C., 2009, 3DTV Conference: The True Vision- Capture, Transmission and Display of 3D Video, P1
   Yang JC, 2010, INT J IMAG SYST TECH, V20, P301, DOI 10.1002/ima.20246
   Yuan Y, 2015, NEUROCOMPUTING, V159, P227, DOI 10.1016/j.neucom.2015.01.066
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang Z, 2012, IEEE T PATTERN ANAL, V34, P436, DOI 10.1109/TPAMI.2011.157
   Zhou WJ, 2014, IEEE SIGNAL PROC LET, V21, P1003, DOI 10.1109/LSP.2014.2320956
NR 47
TC 19
Z9 20
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 269
EP 279
DI 10.1016/j.jvcir.2017.04.010
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500024
DA 2024-07-18
ER

PT J
AU Donevski, D
   Poljicak, A
   Kurecic, MS
AF Donevski, Davor
   Poljicak, Ante
   Kurecic, Maja Strgar
TI Colorimetrically accurate gray component replacement using the additive
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gray component replacement; Printing process model; Ink optimization;
   Radial basis functions
ID COLOR; INK
AB In four color printing, gray component replacement (GCR) is a method of replacing the achromatic component of a mixture of chromatic inks by a corresponding amount of the achromatic ink. Simple approaches to GCR lead to unacceptable color shifts. In this paper, the method using multiple processing steps is proposed. The novelty of the proposed method is augmentation of masking equations, which allows finding solutions for a pre-set amount of the black ink. The method performance was evaluated and compared with state of the art commercial solution. The experiments have shown that the proposed model is on average capable of achieving 40-55% ink savings with median colorimetric difference of less than 0.3, thus preserving the visual appearance of images.(C) 2017 Elsevier Inc. All rights reserved.
C1 [Donevski, Davor; Poljicak, Ante; Kurecic, Maja Strgar] Univ Zagreb, Fac Graph Arts, Getaldiceva 2, Zagreb, Croatia.
C3 University of Zagreb
RP Donevski, D (corresponding author), Univ Zagreb, Fac Graph Arts, Getaldiceva 2, Zagreb, Croatia.
EM davor.donevski@grf.hr; ante.poljicak@grf.hr; maja.strgar.kurecic@grf.hr
RI Poljicak, Ante/I-8394-2019; Donevski, Davor/JFA-5220-2023
OI Poljicak, Ante/0000-0002-4339-448X; 
CR Artusi A., 2000, P SOC PHOTO-OPT INS, V4300, P70
   Bakke AM, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.5.050502
   Balasubramanian R, 1999, J ELECTRON IMAGING, V8, P156, DOI 10.1117/1.482694
   BIRKENSHAW J, 1986, P TECH ASS GRAPH ART, V38, P403
   Broomhead D. S., 1988, Complex Systems, V2, P321
   Emmel P, 2003, EL EN AP SI, P173
   Gutteridge C.J., 1968, THESIS
   Hunt R.W. G., 2004, REPROD COLOUR, V6th
   Kang B., 2002, NIP21, P384
   Kang H. R., 2006, Computational color technology
   Kang H.R., 1994, P SOC PHOTO-OPT INS, V2171, P287, DOI DOI 10.1117/12.175317
   Kisilev P, 2011, NINETEENTH COLOR AND IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, P234
   Littlewood D, 2002, J IMAGING SCI TECHN, V46, P533
   Littlewood DJ, 2002, ACM T GRAPHIC, V21, P132, DOI 10.1145/508357.508361
   Luc DT, 2008, SPRINGER SER OPTIM A, V17, P481
   Mestha LK, 2009, NIP 25: DIGITAL FABRICATION 2009, TECHNICAL PROGRAM AND PROCEEDINGS, P350
   Nakamura C., 1990, Proceedings of the SPIE - The International Society for Optical Engineering, V1184, P50, DOI 10.1117/12.963897
   OGATSU H, 1995, P SOC PHOTO-OPT INS, V2414, P123, DOI 10.1117/12.206540
   Printing Inks Market - Global Industry Analysis, 2015, TECH REP
   Robert T, 2015, PROG ORG COAT, V78, P287, DOI 10.1016/j.porgcoat.2014.08.007
   SAYANAGI K, 1987, P TAGA, V39, P711
   Shapira L, 2012, COMPUT GRAPH FORUM, V31, P365, DOI 10.1111/j.1467-8659.2012.03015.x
   Sharma A, 2010, J IMAGING SCI TECHN, V54, DOI 10.2352/J.ImagingSci.Technol.2010.54.6.060504
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   TSUKADA M, 1995, P SOC PHOTO-OPT INS, V2413, P365, DOI 10.1117/12.207595
   Xia MH, 1999, IEEE T IMAGE PROCESS, V8, P700, DOI 10.1109/83.760337
   Xiong WH, 2005, THIRTEENTH COLOR IMAGING CONFERENCE, FINAL PROGRAM AND PROCEEDINGS, P200
   Yang L, 2006, NIP 22: 22ND INTERNATIONAL CONFERENCE ON DIGITAL PRINTING TECHNOLOGIES, FINAL PROGRAM AND PROCEEDINGS, P394
   Yule J. A, 1940, J OPT SOC AM, V30, P322
NR 29
TC 6
Z9 7
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2017
VL 44
BP 40
EP 49
DI 10.1016/j.jvcir.2017.01.018
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EM5ML
UT WOS:000395355600004
DA 2024-07-18
ER

PT J
AU Chen, ZY
   Chang, PC
AF Chen, Zong-Yi
   Chang, Pao-Chi
TI Rough mode cost-based fast intra coding for high-efficiency video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE High-efficiency video coding (HEVC); Fast intra coding; Coding unit
   (CU); Intra mode decision; Rough mode decision; Transform unit (TU)
ID CU SIZE DECISION; HEVC; ALGORITHM; TERMINATION
AB The quadtree-based coding unit (CU) and transform unit (TU) structure, as well as various prediction units (PUs) of HEVC, considerably increase encoding complexity in intra coding and inter coding. This paper proposes a rough mode cost (RMC)-based algorithm for accelerating CU/TU depth decisions and PU mode decisions in HEVC intra coding. For CU depth decisions, RMC values are used for the fast determination of CU partition. In the case of PU mode decisions, modes with higher RMCs are removed from the candidate list to reduce the number of test modes. For TU depth decisions, the TU partition of the mode with the least RMC is used to determine the TU partitions of remaining modes. The proposed TU partitioning method demonstrates superior performance to the default method in reference software. The proposed algorithm can reduce encoding time by approximately 51% on average, with a 0.69% increase in the Bjontegaard-Delta (BD) rate. (C) 2016 Published by Elsevier Inc.
C1 [Chen, Zong-Yi; Chang, Pao-Chi] Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
C3 National Central University
RP Chang, PC (corresponding author), Natl Cent Univ, Dept Commun Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
EM pcchang@ce.ncu.edu.tw
CR [Anonymous], 2015, P IEEE INT WORKSH MU
   [Anonymous], 2001, VCEG M
   Bai CX, 2013, 2013 IEEE International Conference on Consumer Electronics - China (ICCE-China), P28, DOI 10.1109/ICCE-China.2013.6780861
   Bossen F., 2013, document JCTVC-L1100,, V12
   Bross B., 2010, 3 JCT VC M GUANGZH C, P1
   Chiang PT, 2013, IEEE INT SYMP CIRC S, P1640, DOI 10.1109/ISCAS.2013.6572177
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Choi K, 2012, ELECTRON LETT, V48, P689, DOI 10.1049/el.2012.0277
   Gao LF, 2015, IEEE INT SYMP CIRC S, P517, DOI 10.1109/ISCAS.2015.7168684
   Gender W, 2015, IEEE IMAGE PROC, P242, DOI 10.1109/ICIP.2015.7350796
   Kang J, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P26, DOI 10.1109/CISP.2013.6743998
   Khan MUK, 2013, IEEE IMAGE PROC, P1578, DOI 10.1109/ICIP.2013.6738325
   Kim G, 2014, ELECTRON LETT, V50, P748, DOI 10.1049/el.2014.0647
   Kim I. K., 2014, 17 JCT VC M VAL ES A, P1
   Kim TS, 2015, IEEE INT SYMP CIRC S, P2792, DOI 10.1109/ISCAS.2015.7169266
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li W, 2014, ADV INTEL SYS RES, V109, P587
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Lv Z., 2014, P SOC PHOTO-OPT INS, V9029
   MALLIKARACHCHI T, 2014, IEEE INT CON MULTI, DOI DOI 10.1109/ICME.2014.6890319
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Nishikori T, 2013, IEEE SYMP INDUST EL, P52, DOI 10.1109/ISIEA.2013.6738966
   Palomino D, 2013, PICT COD SYMP, P209, DOI 10.1109/PCS.2013.6737720
   Qiu JW, 2013, IEEE INT CONF MULTI
   Radosavljevic M, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P1377, DOI 10.1109/GlobalSIP.2015.7418424
   Shang XW, 2015, IEEE IMAGE PROC, P1593, DOI 10.1109/ICIP.2015.7351069
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shi W, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P17, DOI 10.1109/APCCAS.2014.7032708
   Shi YY, 2013, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ELECTRIC AND ELECTRONICS, P450
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tariq J, 2016, J VIS COMMUN IMAGE R, V35, P112, DOI 10.1016/j.jvcir.2015.11.013
   Teng S.-W., 2011, VISUAL COMMUNICATION, P1
   Tseng CF, 2016, IET IMAGE PROCESS, V10, P215, DOI 10.1049/iet-ipr.2015.0154
   Wang CC, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P1195, DOI 10.1109/IS3C.2014.310
   Wang SS, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P241, DOI 10.1109/VCIP.2014.7051549
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang YF, 2013, CHINA COMMUN, V10, P155, DOI 10.1109/CC.2013.6650328
   Zhang Y, 2015, IEEE T IND INFORM, V11, P1492, DOI 10.1109/TII.2015.2491646
   Zhao L., 2011, 4 JCT VC M DAEG KR J, P1
NR 41
TC 12
Z9 12
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2017
VL 43
BP 77
EP 88
DI 10.1016/j.jvcir.2016.12.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EJ3YT
UT WOS:000393149400008
DA 2024-07-18
ER

PT J
AU Feng, L
   Sun, HJ
   Sun, QS
   Xia, GY
AF Feng, Lei
   Sun, Huaijiang
   Sun, Quansen
   Xia, Guiyu
TI Blind compressive sensing using block sparsity and nonlocal low-rank
   priors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind compressive sensing; Nonlocal low-rank regularization; Nuclear
   norm; Alternating direction method of multipliers
ID ALGORITHM
AB Without knowing the sparsity basis, Blind Compressive Sensing (BCS) can achieve similar results with those Compressive Sensing (CS) methods which rely on prior knowledge of the sparsity basis. However, BCS still suffers from two problems. First, compared with block-based sparsity, the global image sparsity ignores the local image features and BCS approaches based on it cannot obtain the competitive results. Second, since BCS only exploits the weaker sparsity prior than CS, the sampling rate required by BCS is still very high in practice. In this paper, we firstly propose a novel blind compressive sensing method based on block sparsity and nonlocal low-rank priors (BCS-BSNLR) to further reduce the sampling rate. In addition, we take alternating direction method of multipliers to solve the resulting optimization problem. Experimental results have demonstrated that the proposed algorithm can significantly reduce the sampling rate without sacrificing the quality of the reconstructed image. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Feng, Lei; Sun, Huaijiang; Sun, Quansen; Xia, Guiyu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Sun, HJ (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM fenglei492327278@126.com; sunhuaijiang@njust.edu.cn
FU Graduate Innovation Project of Jiangsu Province [KYZZ15_0124,
   KYZZ15_0125, KYLX_0380]; Project of Civil Space Technology Preresearch
   of the 12th Five-Year Plan
FX This work was supported by Graduate Innovation Project of Jiangsu
   Province KYZZ15_0124, KYZZ15_0125 and KYLX_0380, in part by Project of
   Civil Space Technology Preresearch of the 12th Five-Year Plan.
CR Aghagolzadeh M., DICT IMAGE RECOVERY
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2014, PHD DISSERTATION NAN
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dong WS, 2012, SIGNAL PROCESS-IMAGE, V27, P1109, DOI 10.1016/j.image.2012.09.003
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Eldar Y. C., BLIND COMPRESSED SEN
   Gleichman S, 2011, IEEE T INFORM THEORY, V57, P6958, DOI 10.1109/TIT.2011.2165821
   Hawe S, 2013, IEEE T IMAGE PROCESS, V22, P2138, DOI 10.1109/TIP.2013.2246175
   He LH, 2009, IEEE T SIGNAL PROCES, V57, P3488, DOI 10.1109/TSP.2009.2022003
   Nguyen H, 2015, NEUROCOMPUTING, V155, P32, DOI 10.1016/j.neucom.2014.12.051
   Hou YK, 2011, IEEE T IMAGE PROCESS, V20, P268, DOI 10.1109/TIP.2010.2052281
   Huang JZ, 2011, J MACH LEARN RES, V12, P3371
   Jean-Luc S., 2002, IEEE T IMAGE PROCESS, V11, P118
   Lingala SG, 2013, IEEE T MED IMAGING, V32, P1132, DOI 10.1109/TMI.2013.2255133
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   She QS, 2009, ASIA CONTROL CONF AS, P1570
   Studer C, 2012, INT CONF ACOUST SPEE, P3341, DOI 10.1109/ICASSP.2012.6288631
   Wei CP, 2014, IEEE T IMAGE PROCESS, V23, P3294, DOI 10.1109/TIP.2014.2329451
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Zhang J., SIGNAL PROCESS, V103
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang J, 2012, IEEE J EM SEL TOP C, V2, P380, DOI 10.1109/JETCAS.2012.2220391
   Zhao YQ, 2015, IEEE T GEOSCI REMOTE, V53, P296, DOI 10.1109/TGRS.2014.2321557
NR 29
TC 4
Z9 4
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2017
VL 42
BP 37
EP 45
DI 10.1016/j.jvcir.2016.11.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EI5XS
UT WOS:000392570200004
DA 2024-07-18
ER

PT J
AU Wei, JG
   Zhang, JS
   Ji, Y
   Fang, Q
   Lu, WH
AF Wei, Jianguo
   Zhang, Jingshu
   Ji, Yan
   Fang, Qiang
   Lu, Wenhuan
TI Morphological normalization of vowel images for articulatory speech
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Vocal tract normalization; Articulatory data; Acoustic data; Thin-Plate
   Spline; DNN; Articulatory recognition
ID MODEL
AB Minimizing morphological variances of the vocal tract across speakers is a challenge for articulatory analysis and modeling. In order to reduce morphological differences in speech organs among speakers and retain speakers' speech dynamics, our study proposes a method of normalizing the vocal-tract shapes of Mandarin and Japanese speakers by using a Thin-Plate Spline (TPS) method. We apply the properties of TPS in a two-dimensional space in order to normalize vocal-tract shapes. Furthermore, we also use DNN (Deep Neural Networks) based speech recognition for our evaluations. We obtained our template for normalization by measuring three speakers' palates and tongue shapes. Our results show a reduction in variances among subjects. The similar vowel structure of pre/post-normalization data indicates that our framework retains speaker specific characteristics. Our results for the articulatory recognition of isolated phonemes show an improvement of 25%. Moreover, our phone error rate of continuous speech reduced by 5.84%. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wei, Jianguo; Lu, Wenhuan] Tianjin Univ, Sch Comp Software, 135 Yaguan Rd, Tianjin 300350, Peoples R China.
   [Wei, Jianguo; Zhang, Jingshu; Ji, Yan] Tianjin Univ, Sch Comp Sci & Technol, Tianjin Key Lab Cognit Comp & Applicat, 135 Yaguan Rd, Tianjin 300350, Peoples R China.
   [Fang, Qiang] Chinese Acad Social Sci, Beijing, Peoples R China.
C3 Tianjin University; Tianjin University; Chinese Academy of Social
   Sciences
RP Lu, WH (corresponding author), Tianjin Univ, Sch Comp Software, 135 Yaguan Rd, Tianjin 300350, Peoples R China.
EM jianguo@tju.edu.cn; jingshu@tju.edu.cn; tjujiyan@tju.edu.cn;
   fangqiang@cass.org.cn; wenhuan@tju.edu.cn
RI Wei, Jianguo/KBA-3200-2024
OI Wei, Jianguo/0000-0002-8964-9759
FU National Basic Research Program of China [2013CB329305]; National
   Natural Science Foundation of China [61304250, 61471259]
FX This work was supported in part by the National Basic Research Program
   of China (No. 2013CB329305), and the National Natural Science Foundation
   of China (No. 61304250 and No. 61471259).
CR Adank P, 2004, J ACOUST SOC AM, V116, P3099, DOI 10.1121/1.1795335
   BEAUTEMPS D, 1995, SPEECH COMMUN, V16, P27, DOI 10.1016/0167-6393(94)00045-C
   BECKMAN ME, 1995, J ACOUST SOC AM, V97, P471, DOI 10.1121/1.412945
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Dang JW, 2004, J ACOUST SOC AM, V115, P853, DOI 10.1121/1.1639325
   DISNER SF, 1980, J ACOUST SOC AM, V67, P253, DOI 10.1121/1.383734
   Gales M, 2007, FOUND TRENDS SIGNAL, V1, P195, DOI 10.1561/2000000004
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Hashi M, 1998, J ACOUST SOC AM, V104, P2426, DOI 10.1121/1.423750
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Li Q, 2014, FRONT COMPUT SCI-CHI, V8, P905, DOI 10.1007/s11704-014-3398-x
   Lim J, 2005, PROC CVPR IEEE, P1196
   Liu H, 2013, ASIAPAC SIGN INFO PR
   Okadome T, 2001, J ACOUST SOC AM, V110, P453, DOI 10.1121/1.1377633
   Pitz M., 2000, C INT SPEECH COMM AS
   Saheer L., 2012, IEEE J-STSP, V8, P262
   SYRDAL AK, 1986, J ACOUST SOC AM, V79, P1086, DOI 10.1121/1.393381
   Ueda Y, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0278-y
   Wang Y., 2013, C INT SPEECH COMM AS
   Wei J., 2010, INT C AC SPEECH SIGN
   Wei J., 2015, MULTIMEDIA TOOLS APP
   Wei J., 2015, J MULTIMEDIA TOOLS A
   Wei JG, 2016, J SIGNAL PROCESS SYS, V82, P295, DOI 10.1007/s11265-015-1002-8
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   YANG CS, 1995, IEICE T INF SYST, VE78D, P732
   Zagorchev L, 2006, IEEE T IMAGE PROCESS, V15, P529, DOI 10.1109/TIP.2005.863114
   Zhang J., 2015, ASIA PACIFIC SIGNAL
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
NR 30
TC 2
Z9 2
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 352
EP 360
DI 10.1016/j.jvcir.2016.10.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000031
DA 2024-07-18
ER

PT J
AU Zhou, B
   Wang, XY
   Cao, SX
   Xiang, K
   Zhao, S
AF Zhou, Bin
   Wang, Xuanyin
   Cao, Songxiao
   Xiang, Ke
   Zhao, Shuo
TI Optimal bi-directional seam carving for compressibility-aware image
   retargeting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retargeting; Seam carving; Content; Significance map;
   Compressibility
ID HIGHLY PARALLEL FRAMEWORK; HEVC MOTION ESTIMATION
AB A novel compressibility-aware image retargeting method based on seam carving is introduced in this paper. We propose a new significance detection method, with both the edge information and visual saliency taken into consideration. A wall-seam model is constructed to evaluate the image compressibility and assign the right number of seams for each direction. By repeatedly carving out or inserting seams we can retarget the image to a new size while preserving the important content. Finally, our algorithm is completed with the supplement of uniformly scaling, the stretched image is re-sized to the target size with the least structure distortion brought. Experimental results on images show that those improvements are effective and our approach can preserve image content better compared to several state-ofthe-art image retargeting methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhou, Bin; Wang, Xuanyin; Cao, Songxiao; Xiang, Ke] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhao, Shuo] Inst Spacecraft Syst Engn, 104 Youyi Rd, Beijing 100094, Peoples R China.
C3 Zhejiang University
RP Wang, XY (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM zhoubin2013@zju.edu.cn; xywang@zju.edu.cn; caosongxiao@zju.edu.cn;
   xdj2008zju@163.com; zszl@sina.com
RI Cao, Songxiao/HKE-6408-2023; wang, xuan/GXF-3679-2022; wang,
   xuan/JBJ-6948-2023
CR Achanta R, 2009, IEEE IMAGE PROC, P1005, DOI 10.1109/ICIP.2009.5413815
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, P 18 ANN ACM S US IN
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Chen JH, 2011, WORLD WIDE WEB, V14, P281, DOI 10.1007/s11280-010-0105-1
   Conge D. D., 2010, Proceedings of the 2010 IEEE Workshop on Signal Processing Systems (SiPS 2010), P345, DOI 10.1109/SIPS.2010.5624813
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Gal R, 2006, FEATURE AWARE TEXTUR
   He Z., 2013, 2013 8 IEEE C IND EL, P738
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Shi ML, 2010, LECT NOTES COMPUT SC, V6249, P456
   Toony Z., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P175, DOI 10.1109/ICSIP.2010.5697464
   Wang SF, 2011, IEEE T IMAGE PROCESS, V20, P855, DOI 10.1109/TIP.2010.2076293
   Wang YS, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409071
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
NR 24
TC 16
Z9 18
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 21
EP 30
DI 10.1016/j.jvcir.2016.09.002
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000003
DA 2024-07-18
ER

PT J
AU Rabizadeh, M
   Amirmazlaghani, M
   Ahmadian-Attari, M
AF Rabizadeh, Mehdi
   Amirmazlaghani, Maryam
   Ahmadian-Attari, Mahmoud
TI A new detector for contourlet domain multiplicative image watermarking
   using Bessel K form distribution
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image watermarking; Contourlet transform; Likelihood ratio test;
   Statistical modeling
ID MANY-CORE PROCESSORS; ADDITIVE WATERMARKING; PARALLEL FRAMEWORK; OPTIMUM
   DETECTION; FILTER BANKS; DWT-DOMAIN; DCT; TRANSFORM; MODELS
AB This paper proposes a novel multiplicative contourlet domain watermark detector. We use contourlet transform since this transform represents image edges sparsely and this makes it suitable for human visual system. Watermark detection can be formulated as a binary statistical decision problem, so, its performance is dependent on the accuracy of statistical modeling. Studying the statistical properties of contourlet coefficients, we demonstrate the high efficiency of Bessel K form (BKF) distribution to model these coefficients. Consequently, we design an optimal detector for multiplicative watermarking based on using the Maximum Likelihood (ML) decision rule and BKF distribution. Also, we derive its receiver operating characteristics analytically. Experimental results demonstrate the high efficiency of the proposed scheme under different types of attacks. Finally, we compare our proposed detector with other related detectors experimentally using Monte Carlo simulations and verify the performance improvement in utilizing the new strategy. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Rabizadeh, Mehdi; Ahmadian-Attari, Mahmoud] KN Toosi Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Amirmazlaghani, Maryam] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
C3 K. N. Toosi University of Technology; Amirkabir University of Technology
RP Amirmazlaghani, M (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
EM mazlaghani@aut.ac.ir
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   [Anonymous], J STAT SOFTW
   BAMBERGER RH, 1992, IEEE T SIGNAL PROCES, V40, P882, DOI 10.1109/78.127960
   Barni M, 2003, IEEE T SIGNAL PROCES, V51, P1118, DOI 10.1109/TSP.2003.809371
   Barni M., 2004, WATERMARKING SYSTEMS, V1st
   Bian Y, 2013, IET IMAGE PROCESS, V7, P281, DOI 10.1049/iet-ipr.2012.0345
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Briassouli A, 2004, IEEE T IMAGE PROCESS, V13, P1604, DOI 10.1109/TIP.2004.837516
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 1999, PHILOS T R SOC A, V357, P2495, DOI 10.1098/rsta.1999.0444
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Efron B., 1979, BOOTSTRAP METHODS AN
   Fadili MM, 2005, IEEE T IMAGE PROCESS, V14, P231, DOI 10.1109/TIP.2004.840704
   Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579
   Guo Kanghui, 2005, J. WaveletsSplines, P3
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Jayalakshmi M., 2006, 18 INT C PATT REC 20, V3
   Jayalakshmi M., 2006, INT C INT INF HID MU
   Kay Steven M., 1998, DETECTION THEORY SIG, VII
   Kumar Sushil, 2015, International Journal of Computer and Communication Engineering, V4, P107, DOI 10.17706/IJCCE.2015.V4.389
   Kundur D, 2004, IEEE T MULTIMEDIA, V6, P185, DOI 10.1109/TMM.2003.819747
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P474, DOI 10.1109/TIP.2010.2064327
   Kwitt Roland, 2008, P 10 ACM WORKSH MULT
   Langelaar G.C., 2000, IEEE SIGNAL PROCESS, V17
   Li Haifeng, 2006, 18 INT C PATT REC 20, V3
   Lian Xueqiang, 2007, IEEE INT WORKSH ANT
   Lu YM, 2007, IEEE T IMAGE PROCESS, V16, P918, DOI 10.1109/TIP.2007.891785
   Mairgiotis AK, 2008, IEEE T INF FOREN SEC, V3, P29, DOI 10.1109/TIFS.2007.916290
   Maor A, 2005, IEEE T INFORM THEORY, V51, P3166, DOI 10.1109/TIT.2005.853315
   Merhav N, 2008, IEEE T INFORM THEORY, V54, P255, DOI 10.1109/TIT.2007.911210
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   PHOONG SM, 1995, IEEE T SIGNAL PROCES, V43, P649, DOI 10.1109/78.370620
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Selesnick IW, 2005, IEEE SIGNAL PROC MAG, V22, P123, DOI 10.1109/MSP.2005.1550194
   Solachidis Vassilios, 2004, EURASIP J ADV SIG PR, V2004, P1
   Srivastava A, 2002, IEEE T PATTERN ANAL, V24, P1200, DOI 10.1109/TPAMI.2002.1033212
   Van HL, 2001, DETECTION ESTIMATI 1
   Wang JW, 2008, SIGNAL PROCESS, V88, P117, DOI 10.1016/j.sigpro.2007.07.012
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 49
TC 41
Z9 41
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 324
EP 334
DI 10.1016/j.jvcir.2016.07.001
PN A
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500028
DA 2024-07-18
ER

PT J
AU Raj, N
   Sethunadh, R
   Aparna, PR
AF Raj, Nithin
   Sethunadh, R.
   Aparna, P. R.
TI Object detection in SAR image based on bandlet transform
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Geometrical transforms; Orthogonal bandlets; Despeckling; Generalized
   cross-validation; Object detection; CFAR detector
ID DOMAIN; NOISE; REPRESENTATION
AB detection in SAR images is a challenging task as these images are inherently affected with speckle noise. This paper presents a novel algorithm based on bandlet transform for object detection in Synthetic Aperture Radar (SAR) images. Here first a bandlet based despeckling scheme is employed on the input SAR image and then a constant false alarm rate (CFAR) detector is used for object detection. The input image is first decomposed using Bandlet transform and the bandlet coefficients so obtained are modified using soft thresholding rule on all sub bands, except for low frequency sub band. The optimum thresholds for each sub bands are computed using generalized cross-validation (GCV) technique which doesn't require the information on noise variance of the input image. The method takes advantage of the geometrical features of bandlet transform for retaining the edges and boundaries of the objects, present in SAR images while removing the speckle effectively. Thus CFAR detection on despeckled image can effectively find an optimum threshold for object detection to maintain a constant false alarm rate. The proposed Bandlet transform based scheme surpasses the traditional despeckling and object detection schemes in wavelet domain, in terms of numerical and visual quality. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Raj, Nithin; Aparna, P. R.] SreeChitraThirunal Coll Engn, Trivandrum, Kerala, India.
   [Sethunadh, R.] Indian Space Res Org, Trivandrum, Kerala, India.
C3 Department of Space (DoS), Government of India; Indian Space Research
   Organisation (ISRO)
RP Raj, N (corresponding author), SreeChitraThirunal Coll Engn, Trivandrum, Kerala, India.
EM nithinrajamohanan@gmail.com
OI RAJ, NITHIN/0000-0001-6686-5961
CR Argenti F, 2002, IEEE T GEOSCI REMOTE, V40, P2363, DOI 10.1109/TGRS.2002.805083
   Argenti F, 2009, SIGNAL PROCESS, V89, P1891, DOI 10.1016/j.sigpro.2009.03.028
   Brusch S, 2011, IEEE T GEOSCI REMOTE, V49, P1092, DOI 10.1109/TGRS.2010.2071879
   Candes E.J., 1999, CURVE SURFACE FITTIN
   Crisp D., 2004, STATE OF THE ART SHI
   Cui Y, 2011, IEEE GEOSCI REMOTE S, V8, P641, DOI 10.1109/LGRS.2010.2098434
   Dai M, 2004, IEEE T GEOSCI REMOTE, V42, P1642, DOI 10.1109/TGRS.2004.831231
   di Bisceglie M, 2005, IEEE T GEOSCI REMOTE, V43, P833, DOI 10.1109/TGRS.2004.843190
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Foucher S, 2001, IEEE T IMAGE PROCESS, V10, P49, DOI 10.1109/83.892442
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   Gao QW, 2009, PROC SPIE, V7489, DOI 10.1117/12.836817
   Gao YZ, 2013, PROG ELECTROMAGN RES, V139, P721, DOI 10.2528/PIER13031602
   Hou B, 2009, P APSAR 2009 2 AS PA, P1080, DOI DOI 10.1109/APSAR.2009.5374204
   Hou Biao, 2010, IEEE GEOSCI REMOTE S, V7
   Hu CB, 2013, REMOTE SENS-BASEL, V5, P6899, DOI 10.3390/rs5126899
   Huang XJ, 2015, REMOTE SENS-BASEL, V7, P7695, DOI 10.3390/rs70607695
   Jansen M, 1997, SIGNAL PROCESS, V56, P33, DOI 10.1016/S0165-1684(97)83621-3
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Liu J, 2011, IEEE T SIGNAL PROCES, V59, P5126, DOI 10.1109/TSP.2011.2164073
   Mallat S, 2008, COMMUN PUR APPL MATH, V61, P1173
   Novak L. M., 1997, Lincoln Laboratory Journal, V10, P187
   Pourmottaghi A, 2012, IEEE T AERO ELEC SYS, V48, P1747, DOI 10.1109/TAES.2012.6178094
   Sethunadh R, 2013, ELECTRON LETT, V49, P1183, DOI 10.1049/el.2013.2186
   Sethunadh R., 2013, ELECT LETT, V49
   Velisavljevic V, 2006, IEEE T IMAGE PROCESS, V15, P1916, DOI 10.1109/TIP.2006.877076
   Xiang Sun, 2009, Proceedings of the 2009 2nd Asian-Pacific Conference on Synthetic Aperture Radar (APSAR 2009), P725, DOI 10.1109/APSAR.2009.5374218
NR 30
TC 9
Z9 10
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 376
EP 383
DI 10.1016/j.jvcir.2016.07.010
PN A
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500033
DA 2024-07-18
ER

PT J
AU Yap, WS
   Phan, RCW
   Goi, BM
   Yau, WC
   Heng, SH
AF Yap, Wun-She
   Phan, Raphael C. -W.
   Goi, Bok-Min
   Yau, Wei-Chuen
   Heng, Swee-Huay
TI On the effective subkey space of some image encryption algorithms using
   external key
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image encryption; Chaos theory; Key schedule; Attacks; Key space
ID CHAOTIC SYSTEM; BREAKING; ATTACKS; CIPHERS; MAP
AB One of the general ways in designing a secure image encryption algorithm based on chaos theory is to derive a number of round subkeys from the Key Schedule algorithm under the control of an external secret key. A compulsory condition for the security of an image encryption algorithm is that the length of the external secret key should be sufficiently long in terms of bitlength. However, the sufficiently long secret key is not a guarantee that the algorithm is secure. In this paper, we emphasize the importance in designing a secure Key Schedule algorithm for such image based encryption techniques. Notably, we show why the effective space spanned by the subkeys should never be smaller than the external secret key space. To highlight the importance of this, we present our attacks on three recently proposed image encryption schemes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Yap, Wun-She; Goi, Bok-Min] Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Selangor, Malaysia.
   [Yap, Wun-She; Heng, Swee-Huay] Multimedia Univ, Fac Informat Sci & Technol, Melaka, Malaysia.
   [Phan, Raphael C. -W.; Yau, Wei-Chuen] Multimedia Univ, Fac Engn, Selangor, Malaysia.
C3 Universiti Tunku Abdul Rahman (UTAR); Multimedia University; Multimedia
   University
RP Yap, WS (corresponding author), Univ Tunku Abdul Rahman, Lee Kong Chian Fac Engn & Sci, Selangor, Malaysia.
EM yapws@utar.edu.my; raphael@mmu.edu.my; goibm@utar.edu.my;
   wcyau@mmu.edu.my; shheng@mmu.edu.my
RI Yap, Wun-She/N-3973-2016; Phan, Raphael C.-W./I-7266-2013; Heng,
   Swee-Huay/O-4388-2019; Yap, Wun-She/ABB-5158-2021
OI Yap, Wun-She/0000-0002-0007-6174; Heng, Swee-Huay/0000-0003-3627-2131;
   Goi, Bok Min/0000-0002-9854-7121; Phan, Raphael
   C.-W./0000-0001-7448-4595
FU UTAR through the UTAR Research Fund [UTARRF 6200/Y43]; Ministry of
   Education's Fundamental Research Grant Scheme (FRGS) under project
   ProvAdverse
FX Wun-She Yap would like to acknowledge UTAR for financially funding his
   research through the UTAR Research Fund number UTARRF 6200/Y43. Raphael
   Phan acknowledges the financial support by the Ministry of Education's
   Fundamental Research Grant Scheme (FRGS) under the project ProvAdverse.
CR Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Alvarez G, 2011, STUD COMPUT INTELL, V354, P257
   [Anonymous], NIST SPECIAL PUBLICA
   [Anonymous], 2010, IJ NETWORK SECURITY
   AOKI K, 2001, LNCS, V2012, P39
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   BIHAM E, 1994, J CRYPTOL, V7, P229, DOI 10.1007/BF00203965
   Bogdanov A, 2007, LECT NOTES COMPUT SC, V4727, P450
   Chen AM, 2006, PHYSICA A, V364, P103, DOI 10.1016/j.physa.2005.09.039
   Daemen D., 1820, LNCS, P277
   DIFFIE W, 1977, COMPUTER, V10, P74, DOI 10.1109/C-M.1977.217750
   Dworkin M., 1999, NIST SP
   Gao TG, 2009, CHAOS SOLITON FRACT, V39, P1849, DOI 10.1016/j.chaos.2007.06.125
   Gu GS, 2016, SIGNAL PROCESS-IMAGE, V40, P52, DOI 10.1016/j.image.2015.06.009
   Handschuh H, 2008, LECT NOTES COMPUT SC, V5157, P144, DOI 10.1007/978-3-540-85174-5_9
   Li CQ, 2014, SIGNAL PROCESS-IMAGE, V29, P914, DOI 10.1016/j.image.2014.06.011
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Li CQ, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413500752
   Li CQ, 2011, INT J BIFURCAT CHAOS, V21, P2067, DOI 10.1142/S0218127411029641
   Li CQ, 2010, INT J BIFURCAT CHAOS, V20, P2561, DOI 10.1142/S0218127410027192
   Li CQ, 2009, IMAGE VISION COMPUT, V27, P1371, DOI 10.1016/j.imavis.2008.12.008
   Niu YJ, 2010, COMMUN NONLINEAR SCI, V15, P3518, DOI 10.1016/j.cnsns.2009.12.005
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Qi GY, 2005, PHYSICA A, V352, P295, DOI 10.1016/j.physa.2004.12.040
   Qian ZX, 2015, J VIS COMMUN IMAGE R, V26, P9, DOI 10.1016/j.jvcir.2014.10.008
   Shirai T, 2007, LECT NOTES COMPUT SC, V4593, P181
   Solak E, 2011, INFORM SCIENCES, V181, P227, DOI 10.1016/j.ins.2010.09.009
   Tong XJ, 2015, J VIS COMMUN IMAGE R, V33, P219, DOI 10.1016/j.jvcir.2015.09.014
   Wadi SM, 2014, WIRELESS PERS COMMUN, V79, P811, DOI 10.1007/s11277-014-1888-7
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Zhou Q, 2011, J VIS COMMUN IMAGE R, V22, P85, DOI 10.1016/j.jvcir.2010.10.007
NR 34
TC 20
Z9 20
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 51
EP 57
DI 10.1016/j.jvcir.2016.06.005
PN A
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500006
DA 2024-07-18
ER

PT J
AU Zhao, CY
   Zhao, HC
AF Zhao, Chunyang
   Zhao, Huaici
TI Accurate and robust feature-based homography estimation using HALF-SIFT
   and feature localization error weighting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Homography estimation; Feature localization error; Covariance weighted
   MLESAC; Covariance weighted Levenberg-Marquardt
ID IMAGE; REGISTRATION
AB The goal of homography estimation is to find global transformation between two images of the same scene taken from different viewpoints. The feature-based homography estimation method uses a local feature extractor, a RANSAC-like method and the Levenberg-Marquardt method to estimate the homography matrix. However, in practical applications, the accuracy and robustness of homography estimation are significantly affected by feature localization error. In this paper, we first use the HALF-SIFT method to compensate for localization error caused by the feature extraction method and use the covariance matrix to represent localization error caused by image noise. Then, we proposed a new inliers selection method named CW MLESAC and a new homography matrix refinement method named CW L-M to improve accuracy and robustness. Experimental results show that the proposed method is more accurate and robust under different noise levels and inlier ratios than state-of-the-art methods such as LMedS, RANSAC, MSAC and MLESAC. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhao, Chunyang; Zhao, Huaici] Chinese Acad Sci, Shenyang Inst Automat, Nanta St, Shenyang 110016, Peoples R China.
   [Zhao, Chunyang] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhao, Chunyang; Zhao, Huaici] Chinese Acad Sci, Key Lab Optoelect Informat Proc, Shenyang 110016, Peoples R China.
C3 Chinese Academy of Sciences; Shenyang Institute of Automation, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences
RP Zhao, CY (corresponding author), Chinese Acad Sci, Shenyang Inst Automat, Nanta St, Shenyang 110016, Peoples R China.
EM zhaocy@sia.cn
CR Abdel-Hakim AE, 2008, INT C PATT RECOG, P124
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Brooks MJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P302, DOI 10.1109/ICCV.2001.937533
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Cordes Kai, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P31, DOI 10.1109/CVPR.2009.5204283
   CORDES KAI, 2015, P COMP AN IM PATT CA, P374
   Duan YN, 2014, IEEE T GEOSCI REMOTE, V52, P5164, DOI 10.1109/TGRS.2013.2287029
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Linger ME, 2015, IEEE T GEOSCI REMOTE, V53, P2137, DOI 10.1109/TGRS.2014.2356177
   Liu Q, 2016, IEEE T IMAGE PROCESS, V25, P316, DOI 10.1109/TIP.2015.2503238
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinel N, 2013, IEEE SIGNAL PROC LET, V20, P1024, DOI 10.1109/LSP.2013.2279014
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Piciarelli C, 2013, LECT NOTES COMPUT SC, V8157, P279, DOI 10.1007/978-3-642-41184-7_29
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Rockett P., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P392
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Steele RM, 2005, PROC CVPR IEEE, P1063
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wang HZ, 2010, IEEE T PATTERN ANAL, V32, P178, DOI 10.1109/TPAMI.2009.148
   Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109
   Ye P, 2014, IEICE T INF SYST, VE97D, P1927, DOI 10.1587/transinf.E97.D.1927
   Zaragoza J, 2014, IEEE T PATTERN ANAL, V36, P1285, DOI 10.1109/TPAMI.2013.247
   Zeisl B., 2009, P BRIT MACH VIS C LO
NR 30
TC 7
Z9 7
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 288
EP 299
DI 10.1016/j.jvcir.2016.07.002
PN A
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CX
UT WOS:000384398500025
DA 2024-07-18
ER

PT J
AU Wu, YL
AF Wu, Yulian
TI Speckle noise removal via nonlocal low-rank regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Speckle noise; Nonconvex optimization; Low-rank approximation; Augmented
   Lagrange multiplier; Structured sparsity
ID IMAGE; SPARSE
AB This paper presents a novel method for speckle noise removal. We propose a nonlocal low-rank regularization (NLR) approach toward exploiting structured sparsity and explore its application into speckle noise removal. A nonconvex surrogate functions for the rank instead of the convex nuclear norm is proposed. To further improve the computational efficiency of the proposed algorithm, we have developed a fast implementation using augmented Lagrange multiplier (ALM) method. We experimentally demonstrate the excellent performance of the technique, in terms of both Peak Signal to Noise Ratio (PSNR) and Structural Similarity (SSIM). (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wu, Yulian] Xian Med Univ, Dept Hlth Management, Xian 710021, Peoples R China.
   [Wu, Yulian] Xidian Univ, Sch Sci, Xian 710071, Peoples R China.
C3 Xi'an Medical University; Xidian University
RP Wu, YL (corresponding author), Xian Med Univ, Dept Hlth Management, Xian 710021, Peoples R China.
EM wyl_wp711@163.com
FU Shaanxi Provincial Department of Education Fund [15JK1371]; Xi'an
   Medical University Dr. Scientific Research Foundation [2015DOC25]
FX This paper is supported by the Shaanxi Provincial Department of
   Education Fund (15JK1371) and Xi'an Medical University Dr. Scientific
   Research Foundation (2015DOC25). The authors would like to thank for
   Doctor Wensen Feng and Yu Han to share their paper codes with us. The
   authors also would like to thank anonymous reviewers for their kind
   comments.
CR [Anonymous], 2014, P IEEE C COMP VIS PA
   Argenti F, 2012, IEEE GEOSCI REMOTE S, V9, P13, DOI 10.1109/LGRS.2011.2158798
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bioucas-Dias JM, 2010, IEEE T IMAGE PROCESS, V19, P1720, DOI 10.1109/TIP.2010.2045029
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Chen K, 2013, BIOMETRIKA, V100, P901, DOI 10.1093/biomet/ast036
   Chen YJ, 2014, IEEE SIGNAL PROC LET, V21, P1370, DOI 10.1109/LSP.2014.2337274
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Durand S, 2010, J MATH IMAGING VIS, V36, P201, DOI 10.1007/s10851-009-0180-z
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fazel M, 2003, P AMER CONTR CONF, P2156, DOI 10.1109/acc.2003.1243393
   Feng WS, 2014, IEEE T IMAGE PROCESS, V23, P1831, DOI 10.1109/TIP.2014.2308432
   Han Y, 2013, PATTERN RECOGN, V46, P989, DOI 10.1016/j.patcog.2012.10.010
   Hebar M, 2009, IEEE T GEOSCI REMOTE, V47, P2818, DOI 10.1109/TGRS.2009.2013697
   Huang YM, 2012, IEEE T IMAGE PROCESS, V21, P4534, DOI 10.1109/TIP.2012.2205007
   Huang YM, 2009, SIAM J IMAGING SCI, V2, P20, DOI 10.1137/080712593
   Li GT, 2013, IEEE GEOSCI REMOTE S, V10, P263, DOI 10.1109/LGRS.2012.2200875
   Liu B, 2010, PATTERN RECOGN, V43, P2028, DOI 10.1016/j.patcog.2010.01.002
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   Steidl G, 2010, J MATH IMAGING VIS, V36, P168, DOI 10.1007/s10851-009-0179-5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong SK, 2009, IEEE T AERO ELEC SYS, V45, P1017, DOI 10.1109/TAES.2009.5259180
NR 27
TC 9
Z9 9
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 172
EP 180
DI 10.1016/j.jvcir.2016.04.024
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900017
DA 2024-07-18
ER

PT J
AU Hu, YC
   Chang, H
   Nian, FD
   Wang, Y
   Li, T
AF Hu, Yaocong
   Chang, Huan
   Nian, Fudong
   Wang, Yan
   Li, Teng
TI Dense crowd counting from still images with convolutional neural
   networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Crowd counting; Convolutional neural networks; Feature learning;
   Regression
ID PEOPLE
AB For reasons of public security, modeling large crowd distributions for counting or density estimation has attracted significant research interests in recent years. Existing crowd counting algorithms rely on predefined features and regression to estimate the crowd size. However, most of them are constrained by such limitations: (1) they can handle crowds with a few tens individuals, but for crowds of hundreds or thousands, they can only be used to estimate the crowd density rather than the crowd count; (2) they usually rely on temporal sequence in crowd videos which is not applicable to still images. Addressing these problems, in this paper, we investigate the use of a deep-learning approach to estimate the number of individuals presented in a mid-level or high-level crowd visible in a single image. Firstly, a ConvNet structure is used to extract crowd features. Then two supervisory signals, i.e., crowd count and crowd density, are employed to learn crowd features and estimate the specific counting. We test our approach on a dataset containing 107 crowd images with 45,000 annotated humans inside, and each with head counts ranging from 58 to 2201. The efficacy of the proposed approach is demonstrated in extensive experiments by quantifying the counting performance through multiple evaluation criteria. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Hu, Yaocong; Chang, Huan; Nian, Fudong; Wang, Yan; Li, Teng] Anhui Univ, 111 Jiulong RD, Hefei 230061, Peoples R China.
C3 Anhui University
RP Li, T (corresponding author), Anhui Univ, 111 Jiulong RD, Hefei 230061, Peoples R China.
EM liteng@ahu.edu.cn
FU National Natural Science Foundation (NSF) of China [61300056, 61572029];
   Anhui Provincial Natural Science Foundation of China [1408085QF118];
   Science and Technology Project of Anhui Province [1501b042207]
FX This work is supported by the National Natural Science Foundation (NSF)
   of China (Nos. 61300056 and 61572029), the Anhui Provincial Natural
   Science Foundation of China (No. 1408085QF118) and Science and
   Technology Project of Anhui Province (No. 1501b042207).
CR An S, 2007, PROC CVPR IEEE, P1033
   [Anonymous], 1997, Image Processing for Security Applications, DOI DOI 10.1049/IC:19970387
   [Anonymous], 2011, INT JOINT C NEUR NET
   [Anonymous], 2008, CVPR
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   CHEN K, 2013, PROC CVPR IEEE, P2467, DOI [DOI 10.1109/CVPR.2013.319, 10.1109/CVPR.2013.319]
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb D.M.P., 2008, IEEE C COMP VIS PATT
   Ferryman J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P143, DOI 10.1109/AVSS.2010.90
   Ge Weina, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2913, DOI 10.1109/CVPRW.2009.5206621
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Glorot A.B. Xavier, 2011, INT C ART INT STAT
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lempitsky V., 2010, P ADV NEUR INF PROC, V23, P1, DOI DOI 10.5555/2997189.2997337
   Li J, 2013, IEEE T IMAGE PROCESS, V22, P4510, DOI 10.1109/TIP.2013.2274732
   Li M, 2008, INT C PATT RECOG, P1998
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu TL, 2016, IEEE T NEUR NET LEAR, V27, P1851, DOI 10.1109/TNNLS.2015.2458986
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu TL, 2014, INT CONF INFO SCI, P100, DOI 10.1109/ICIST.2014.6920341
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Loy CC, 2013, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2013.270
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   Pierre Sermanet S.C, 2012, INT C PATT REC
   Rodriguez M., 2011, P INT C COMP VIS
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Sainath TN, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P315, DOI 10.1109/ASRU.2013.6707749
   Smirnov E., 2013, Int. Conf. on Mach. Learn
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
NR 41
TC 80
Z9 88
U1 3
U2 44
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 530
EP 539
DI 10.1016/j.jvcir.2016.03.021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100045
OA Bronze
DA 2024-07-18
ER

PT J
AU Azam, S
   Islam, MM
AF Azam, Samiul
   Islam, Md Monirul
TI Automatic license plate detection in hazardous condition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Automatic license plate detection; Hazardous condition; Rain streaks;
   Fog affected; Horizontally tilted; Low contrast image; Fourier
   transform; Radon transform
ID RECOGNITION; ALGORITHM
AB Automatic detection of license plate (LP) is to localize a license plate region from an image without human involvement. So far a number of methods have been introduced for automatic license plate detection (ALPD), but most of them do not consider various hazardous image conditions that exist in many real driving situations. Hazardous image condition means an image can have rainy or foggy weather effects, low contrast environments, objects similar to LP in the background, and horizontally tilted LP area. All these issues create challenges in developing effective ALPD method. In this paper, we propose a new ALPD method which effectively detects LP area from an image in the hazardous conditions. For rain removal we apply a novel method that uses frequency domain mask to filter rain streaks from an image. A new contrast enhancement method with a statistical binarization approach is introduced in the proposed ALPD for handling low contrast indoor, night, blurry and foggy images. For correcting tilted LP, we apply Radon transform based tilt correction method for the first time. To filter non-LP regions, a new condition is used which is based on image entropy. We test the proposed ALPD method on 850 car images having different hazardous conditions, and achieve satisfactory results in LP detection. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Azam, Samiul] Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
   [Azam, Samiul; Islam, Md Monirul] Bangladesh Univ Engn & Technol, Dept Comp Sci & Engn, Dhaka, Bangladesh.
C3 University of Calgary; Bangladesh University of Engineering & Technology
   (BUET)
RP Azam, S (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
EM samiul.azam@ucalgary.ca; mmislam@cse.buet.ac.bd
CR Abo Samra GA, 2014, IEEE T EVOLUT COMPUT, V18, P244, DOI 10.1109/TEVC.2013.2255611
   Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   [Anonymous], 2015, 2015 INT C PERVASIVE
   [Anonymous], 2012, ASIAN T SCI TECHNOL
   [Anonymous], PATT REC IM AN IPRIA
   [Anonymous], ICIIEC 2015
   Benou I., 2012, IEEE 27 CONV EL EL E, P1
   Bernsen J., 1986, ICPR 86, P1251
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Deb K, 2009, J COMPUT, V4, P771, DOI 10.4304/jcp.4.8.771-777
   Dewan S, 2015, 2015 IEEE/ACIS 14TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS), P313, DOI 10.1109/ICIS.2015.7166612
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Dun JY, 2015, IEEE INTEL TRANSP SY, V7, P51, DOI 10.1109/MITS.2015.2412146
   Ghosh A., 2011, GLOBAL J COMPUT SCI, V11, P69
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Goyal M., 2011, IJCST, V4, P161
   Hasan M., 2013, REAL TIME DETECTION
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Huang YP, 2009, EXPERT SYST APPL, V36, P9260, DOI 10.1016/j.eswa.2008.12.006
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Jain A.K., 2003, FUNDAMENTALS DIGITAL
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Karwal H, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P8, DOI 10.1109/CICT.2015.13
   Kim S, 2002, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2002.1047833
   Kusakunniran Worapan, 2014, 2014 International Computer Science and Engineering Conference (ICSEC), P163, DOI 10.1109/ICSEC.2014.6978188
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Stockman George, 2001, Computer Vision
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Wang YR, 2011, EXPERT SYST APPL, V38, P3142, DOI 10.1016/j.eswa.2010.08.106
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Yousef KMA, 2015, 2015 6TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS), P124, DOI 10.1109/IACS.2015.7103214
   Zhang H, 2006, IEEE SYS MAN CYBERN, P2420, DOI 10.1109/ICSMC.2006.385226
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 35
TC 53
Z9 54
U1 1
U2 50
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 172
EP 186
DI 10.1016/j.jvcir.2016.01.015
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200015
DA 2024-07-18
ER

PT J
AU Bouagar, S
   Larabi, S
AF Bouagar, Saliha
   Larabi, Slimane
TI Discriminative outlines parts for shape retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Discriminative; Part; Matching; Partial; Shape; Retrieval; Outline;
   descriptor
ID RECOGNITION; REPRESENTATION; FEATURES; ROBUST
AB In this paper we propose a new method for shape retrieval using only discriminative parts which are sufficient for the recognition of many objects and their classes. The discriminative outline shape is firstly determined by performing psycho-visual tests and then described with geometric attributes of high curvature points located along the outline. This obtained description is invariant to scale change, rotation, mirroring and deformation. To study the performance of our approach, global approach which deals with the whole contour and partial approach which is based on the discriminative part are compared. Experiments conducted on our data set and a selection of MPEG-7 dataset demonstrated the usefulness of this approach and the results obtained are presented and discussed. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Bouagar, Saliha; Larabi, Slimane] Univ Sci & Technol Houari Boumediene, Dept Comp Sci, Algiers, Algeria.
C3 University Science & Technology Houari Boumediene
RP Larabi, S (corresponding author), Univ Sci & Technol Houari Boumediene, Dept Comp Sci, Algiers, Algeria.
EM sbouagar@usthb.dz; slarabi@usthb.dz
RI Larabi, Slimane/AAD-7871-2020
OI larabi, slimane/0000-0001-8994-5980
CR Adamek T, 2004, IEEE T CIRC SYST VID, V14, P742, DOI 10.1109/TCSVT.2004.826776
   Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Alajlan N, 2010, ARTIF LIFE ROBOT, V15, P309, DOI 10.1007/s10015-010-0814-7
   Andaló FA, 2010, PATTERN RECOGN, V43, P26, DOI 10.1016/j.patcog.2009.06.012
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bai X, 2008, PATTERN RECOGN, V41, P2189, DOI [10.1016/i.patcog.2007.12.016, 10.1016/j.patcog.2007.12.016]
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P3935, DOI 10.1109/TIP.2014.2336542
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bertamini M, 2005, ACTA PSYCHOL, V120, P35, DOI 10.1016/j.actpsy.2005.03.002
   BIEDERMAN I, 1985, COMPUT VISION GRAPH, V32, P29, DOI 10.1016/0734-189X(85)90002-7
   Chen Longbin, 2008, IEEE COMP SOC C COMP
   Chetverikov D., 1999, 23 WORKSHOP AUSTRIAN, P175
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Daliri MR, 2010, COMPUT VIS IMAGE UND, V114, P1097, DOI 10.1016/j.cviu.2010.07.002
   De Winter J, 2006, COGNITION, V99, P275, DOI 10.1016/j.cognition.2005.03.004
   Di Ruberto C, 2009, IMAGE VISION COMPUT, V27, P1097, DOI 10.1016/j.imavis.2008.10.009
   Donoser M., ACCV09
   Drew MS, 2009, IMAGE VISION COMPUT, V27, P748, DOI 10.1016/j.imavis.2008.07.011
   Giralt N, 2000, PSYCHOL SCI, V11, P497, DOI 10.1111/1467-9280.00295
   Hayward WG, 1998, J EXP PSYCHOL HUMAN, V24, P427, DOI 10.1037/0096-1523.24.2.427
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Hu RX, 2012, PATTERN RECOGN, V45, P3222, DOI 10.1016/j.patcog.2012.02.020
   Lakaemper R., IJCV09
   LARABI S, 2003, 13 SCAND C IM AN GOT
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Mokhtarian F., 2003, CURVATURE SCALE SPAC
   Mokhtarian F., 1996, Proceedings of International Workshop on Image Databases and Multimedia Search, P35
   Premachandran V., ICIP13
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Sedai S, 2013, PATTERN RECOGN, V46, P3223, DOI 10.1016/j.patcog.2013.05.019
   Shang L., 2012, PATTERN RECOGN LETT, V33, P74475
   Singh M, 1997, TRENDS COGN SCI, V1, P98, DOI 10.1016/S1364-6613(97)89055-9
   Singh Manish, 2001, ADV PSYCHOL, V130
   Wang L, 2013, PATTERN RECOGN, V46, P1832, DOI 10.1016/j.patcog.2012.08.016
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhao X., 2013, P ACM INT C MULT, P273
NR 39
TC 2
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 149
EP 164
DI 10.1016/j.jvcir.2015.08.019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700015
DA 2024-07-18
ER

PT J
AU Xue, F
   Liu, JQ
   Li, ZF
   Liu, SD
   Meng, G
   Zhang, L
AF Xue, Feng
   Liu, Jiaqi
   Li, Zhifeng
   Liu, Shengdong
   Meng, Gang
   Zhang, Li
TI Mallows' statistics CL: A novel criterion for parametric PSF estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind deconvolution; Parametric PSF estimation; Mallows' statistics;
   Smoother filtering; Frequency-dependent regularizer; Expected prediction
   error; Gaussian kernel; jinc function
ID BLIND IMAGE DECONVOLUTION; POINT-SPREAD FUNCTION; DATA RESTORATION
AB Considering blind image deconvolution as a statistical estimation problem, we propose an unbiased estimator of the prediction error - Mallows' statistics C-L - as a novel criterion for estimating a point spread function (PSF) from the degraded image only. The PSF is obtained by minimizing this new objective functional over a family of smoother filterings (with frequency-dependent regularization term). We then perform non-blind deconvolution using the popular BM3D algorithm. The C-L-based framework is exemplified with a number of parametric PSF's, involving a scaling factor that controls the blur size. A typical example of such parametrization is the Gaussian kernel.
   The experimental results show that the C-L-minimization yields highly accurate estimates of the PSF parameters, which also result in a negligible loss of visual quality, compared to that obtained with the exact PSF. The highly competitive results demonstrate the great potential of developing more powerful blind deconvolution algorithms based on the C-L-estimator. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Xue, Feng; Liu, Jiaqi; Li, Zhifeng; Liu, Shengdong; Meng, Gang; Zhang, Li] Natl Key Lab Sci & Technol Test Phys & Numer Math, Beijing 100076, Peoples R China.
RP Xue, F (corresponding author), Natl Key Lab Sci & Technol Test Phys & Numer Math, Beijing 100076, Peoples R China.
EM fxue2012@gmail.com; ljq006@vip.sina.com; zfli1976@163.com;
   liushdbit1019@163.com; mgang2012@yeah.net; zhangli60@163.com
RI liu, yi/GXE-9662-2022
FU National Natural Science Foundation of China [61401013]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61401013.
CR Afonso MV, 2011, IEEE T IMAGE PROCESS, V20, P681, DOI 10.1109/TIP.2010.2076294
   [Anonymous], 2009, ELEMENTS STAT LEARNI
   Babacan SD, 2009, IEEE T IMAGE PROCESS, V18, P12, DOI 10.1109/TIP.2008.2007354
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Boisbunon A., AIC CP ESTIMATORS LO
   Born M., 2006, PRINCIPLES OPTICS EL, V7th
   Cao Q, 2003, J OPT SOC AM A, V20, P661, DOI 10.1364/JOSAA.20.000661
   Carasso A. S., 2002, SIAM Journal on Applied Mathematics, V63, P593, DOI 10.1137/S0036139901389318
   Caron JN, 2002, APPL OPTICS, V41, P6884, DOI 10.1364/AO.41.006884
   Caron JN, 2001, OPT LETT, V26, P1164, DOI 10.1364/OL.26.001164
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen F, 2009, IEEE T SIGNAL PROCES, V57, P2467, DOI 10.1109/TSP.2009.2018358
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Chuang Y., 2002, THESIS
   Cooke BJ, 1996, P SOC PHOTO-OPT INS, V2743, P52, DOI 10.1117/12.241949
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Fujikoshi Y, 2011, ANN I STAT MATH, V63, P387, DOI 10.1007/s10463-009-0233-5
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Holst G.C., 2008, Electro-optical Imaging System Performance
   Kenig T., IEEE T PATTERN ANAL, V32
   Koptelova E, 2005, MON NOT R ASTRON SOC, V356, P323, DOI 10.1111/j.1365-2966.2004.08451.x
   Levin A., 2011 IEEE C COMP VIS, P2657
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li DL, 2009, IEEE GEOSCI REMOTE S, V6, P244, DOI 10.1109/LGRS.2008.2011569
   Liao H., 2011, IEEE T IMAGE PROCESS, V20, P3005
   MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380
   Markham J, 1999, J OPT SOC AM A, V16, P2377, DOI 10.1364/JOSAA.16.002377
   Michailovich O., IEEE T IMAGE PROCESS, V16
   MOFFAT AFJ, 1969, ASTRON ASTROPHYS, V3, P455
   Molina R, 2006, IEEE T IMAGE PROCESS, V15, P3715, DOI 10.1109/TIP.2006.881972
   Pankajakshan P, 2009, APPL OPTICS, V48, P4437, DOI 10.1364/AO.48.004437
   POROPAT GV, 1993, OPT ENG, V32, P2598, DOI 10.1117/12.146388
   Santos A, 2000, APPL OPTICS, V39, P2948, DOI 10.1364/AO.39.002948
   Sarder P, 2006, IEEE SIGNAL PROC MAG, V23, P32, DOI 10.1109/MSP.2006.1628876
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shim M., 2008, INTRO ENG MAT, P1
   THIEBAUT E, 1995, J OPT SOC AM A, V12, P485, DOI 10.1364/JOSAA.12.000485
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Tzikas DG, 2009, IEEE T IMAGE PROCESS, V18, P753, DOI 10.1109/TIP.2008.2011757
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Xu L, 2010, LECT NOTES COMPUT SC, V6311, P157
   Xue F, 2009, INFRARED PHYS TECHN, V52, P166, DOI 10.1016/j.infrared.2009.07.002
   Zhang B, 2007, APPL OPTICS, V46, P1819, DOI 10.1364/AO.46.001819
   Zhang JL, 2008, J OPT SOC AM A, V25, P710, DOI 10.1364/JOSAA.25.000710
   Zhang JL, 2008, OPT LETT, V33, P25, DOI 10.1364/OL.33.000025
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P873, DOI 10.1109/TIP.2011.2162739
NR 48
TC 4
Z9 4
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 115
EP 122
DI 10.1016/j.jvcir.2015.09.001
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700012
DA 2024-07-18
ER

PT J
AU Stanciu, SG
   Tranca, DE
   Coltuc, D
AF Stanciu, Stefan G.
   Tranca, Denis E.
   Coltuc, Dinu
TI Contrast enhancement influences the detection of gradient based local
   invariant features and the matching of their descriptors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; Histogram modification; Local invariant features;
   Feature detection; Feature description; Feature matching; SIFT; SURF
ID HISTOGRAM EQUALIZATION; IMAGE-ENHANCEMENT; PERFORMANCE EVALUATION; LIGHT
   ATTENUATION; SIFT; CLASSIFICATION; SPECIFICATION; COMPENSATION;
   LOCALIZATION; FRAMEWORK
AB Contrast enhancement (CE) plays an important role in digital photography, medical imaging or scientific visualization, compensating for deficient dynamic range aspects. Our experiments show that CE via histogram modification influences the detection of gradient based local invariant features (LIF) and the matching of their descriptors. We bring evidence that the number of keypoints that can be automatically extracted by gradient based detectors increases with CE, and that matching gradient based keypoint descriptors extracted from image sets processed by CE is negatively affected in terms of Precision-Recall. We observed the effects of several classical and state-of-the-art CE methods on two widely used LIF detection/description techniques: Scale Invariant Feature Transform (SIFT) and Speeded-Up Robust Features (SURF). (C) 2015 Elsevier Inc. All rights reserved.
C1 [Stanciu, Stefan G.; Tranca, Denis E.] Univ Politehn Bucuresti, Ctr Microscopy Microanal & Informat Proc, Bucharest 060042, Romania.
   [Stanciu, Stefan G.] ETH, Swiss Fed Inst Technol, Light Microscopy & Screening Ctr, Zurich, Switzerland.
   [Coltuc, Dinu] Valahia Univ Targoviste, Dept Elect Engn, Targoviste, Dambovita, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest; Swiss
   Federal Institutes of Technology Domain; ETH Zurich; Valahia University
   of Targoviste
RP Stanciu, SG (corresponding author), Univ Politehn Bucuresti, Ctr Microscopy Microanal & Informat Proc, 313 Splaiul Independentei,Sect 6, Bucharest 060042, Romania.
EM stefan.stanciu@cmmip-upb.org
RI Tranca, Denis/P-6928-2018; Tranca, Denis E./KTI-2160-2024; Coltuc,
   Dinu/F-1707-2016; Tranca, Denis E./D-9862-2019; Stanciu, Stefan
   G./AAJ-5568-2020; Tranca, Denis/C-8429-2015
OI Tranca, Denis/0000-0002-1966-8348; Stanciu, Stefan
   G./0000-0002-1676-3040; Coltuc, Dinu/0000-0003-1755-0044; Caciula,
   Ion/0000-0001-6394-949X
FU Rectors' Conference of the Swiss Universities (CRUS) [12.135]; Sectorial
   Operational Programme for Human Resources Development (SOP HRD) -
   European Social Fund (European Commission, Brussels); Romanian
   Government [POSDRU/159/1.5/S/137390/]; Romanian Executive Agency for
   Higher Education, Research, Development and Innovation Funding
   (UEFISCDI) [PN-II-PT-PCCA-2011-3.2-1162]
FX S.G. Stanciu gratefully acknowledges the thoughtful guidance of Dr.
   Gabor Csucs along the SCIEX NMS-CH Fellowship nr. 12.135 funded by the
   Rectors' Conference of the Swiss Universities (CRUS), implemented at ETH
   Zurich, which supported a part of this work. S.G. Stanciu acknowledges
   as well the financial support of the Sectorial Operational Programme for
   Human Resources Development (SOP HRD), funded by the European Social
   Fund (European Commission, Brussels) and the Romanian Government under
   the contract number POSDRU/159/1.5/S/137390/. The contribution of D.E.
   Tranca and D. Coltuc was supported by the PN-II-PT-PCCA-2011-3.2-1162
   Research Grant funded by the Romanian Executive Agency for Higher
   Education, Research, Development and Innovation Funding (UEFISCDI).
CR Ancuti CO, 2010, INT CONF ACOUST SPEE, P938, DOI 10.1109/ICASSP.2010.5495289
   [Anonymous], 1982, Digital Picture Processing
   [Anonymous], 2004, ECCV
   [Anonymous], SCI REP
   [Anonymous], 2011, 2011 17 KOREA JAPAN
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Caicedo JC, 2009, LECT NOTES ARTIF INT, V5651, P126, DOI 10.1007/978-3-642-02976-9_17
   Campos P, 2011, PROCEEDINGS OF THE 49TH ANNUAL ASSOCIATION FOR COMPUTING MACHINERY SOUTHEAST CONFERENCE (ACMSE '11), P365
   Capek M, 2006, MICROSC RES TECHNIQ, V69, P624, DOI 10.1002/jemt.20330
   Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Chang S., 2014, PLOS ONE, V10
   Cheng F. C., 2013, J DISP TECHNOL, V9, P44, DOI DOI 10.1109/JDT.2012.2226234
   Chung KL, 2008, J VIS COMMUN IMAGE R, V19, P299, DOI 10.1016/j.jvcir.2008.02.002
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gonzales R.C., 2002, Digital image processing
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   HUMMEL R, 1977, COMPUT VISION GRAPH, V6, P184, DOI 10.1016/S0146-664X(77)80011-7
   Jarillo G, 2008, MACH VISION APPL, V19, P125, DOI 10.1007/s00138-007-0088-9
   Jeong CB, 2011, J DIGIT IMAGING, V24, P424, DOI 10.1007/s10278-010-9273-x
   Khan MF, 2014, DIGIT SIGNAL PROCESS, V25, P198, DOI 10.1016/j.dsp.2013.10.015
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lei B, 2011, COMM COM INF SC, V224, P1
   Li H, 2010, BIOMED OPT EXPRESS, V1, P31, DOI 10.1364/BOE.1.000031
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mukherjee D, 2015, MACH VISION APPL, V26, P443, DOI 10.1007/s00138-015-0679-9
   Nercessian SC, 2013, IEEE T IMAGE PROCESS, V22, P3549, DOI 10.1109/TIP.2013.2262287
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   O'hara S., 2011, COMPUTING RES REPOSI
   Piccinini P, 2012, IMAGE VISION COMPUT, V30, P573, DOI 10.1016/j.imavis.2012.06.004
   Poddar S, 2013, IET IMAGE PROCESS, V7, P641, DOI 10.1049/iet-ipr.2012.0507
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Rajavel P, 2010, IEEE T CONSUM ELECTR, V56, P756, DOI 10.1109/TCE.2010.5505998
   Rosu M, 2009, OPTOELECTRON ADV MAT, V3, P376
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Stanciu SG, 2011, ULTRAMICROSCOPY, V111, P364, DOI 10.1016/j.ultramic.2011.01.014
   Stanciu SG, 2010, MICROSC RES TECHNIQ, V73, P165, DOI 10.1002/jemt.20767
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tamaki T, 2013, MED IMAGE ANAL, V17, P78, DOI 10.1016/j.media.2012.08.003
   Tsai C., 2008, EFFECTS 2 D PREPROCE
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Valgren C, 2010, ROBOT AUTON SYST, V58, P149, DOI 10.1016/j.robot.2009.09.010
   Wan Y, 2007, IEEE T IMAGE PROCESS, V16, P2245, DOI 10.1109/TIP.2007.902332
   Wang J, 2010, APPL GEOPHYS, V7, P249, DOI 10.1007/s11770-010-0247-4
   Xu PF, 2013, IEEE MULTIMEDIA, V20, P34, DOI 10.1109/MMUL.2013.18
   Yu CY, 2014, APPL MECH MATER, V479-480, P870, DOI 10.4028/www.scientific.net/AMM.479-480.870
   Zeng M, 2012, OPTIK, V123, P511, DOI 10.1016/j.ijleo.2011.05.017
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
   Zuo C, 2013, OPTIK, V124, P425, DOI 10.1016/j.ijleo.2011.12.057
NR 58
TC 8
Z9 8
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 246
EP 256
DI 10.1016/j.jvcir.2015.08.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300021
DA 2024-07-18
ER

PT J
AU Wu, QB
   Li, HL
   Meng, FM
   Ngan, KN
   Zhu, SY
AF Wu, Qingbo
   Li, Hongliang
   Meng, Fanman
   Ngan, King Ngi
   Zhu, Shuyuan
TI No reference image quality assessment metric via multi-domain structural
   information and piecewise regression
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No reference image quality assessment; Human vision system; Image
   representation; Quality aware feature; Multi-domain structural
   information; Gradient of wavelet domain; Piecewise regression; HEVC
ID NATURAL SCENE STATISTICS; CO-SEGMENTATION; SIMILARITY; SCALE
AB The general purpose no reference image quality assessment (NR-IQA) is a challenging task, which faces two hurdles: (1) it is difficult to develop one quality aware feature which works well across different types of distortion and (2) it is hard to learn a regression model to approximate a complex distribution for all training samples in the feature space. In this paper, we propose a novel NR-IQA method that addresses these problems by introducing the multi-domain structural information and piecewise regression. The main motivation of our method is based on two points. Firstly, we develop a new local image representation which extracts the structural image information from both the spatial-frequency and spatial domains. This multi-domain description could better capture human vision property. By combining our local features with a complementary global feature, the discriminative power of each single feature could be further improved. Secondly, we develop an efficient piecewise regression method to capture the local distribution of the feature space. Instead of minimizing the fitting error for all training samples, we train the specific prediction model for each query image by adaptive online learning, which focuses on approximating the distribution of the current test image's k-nearest neighbor (KNN). Experimental results on three benchmark IQA databases (i.e., LIVE II, TID2008 and CSIQ) show that the proposed method outperforms many representative NR-IQA algorithms. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wu, Qingbo; Li, Hongliang; Meng, Fanman; Ngan, King Ngi; Zhu, Shuyuan] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610054, Peoples R China.
   [Ngan, King Ngi] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 University of Electronic Science & Technology of China; Chinese
   University of Hong Kong
RP Wu, QB (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610054, Peoples R China.
EM wqb.uestc@gmail.com; hlli@uestc.edu.cn; fmmeng@uestc.edu.cn;
   knngan@ee.cuhk.edu.hk; eezsy@uestc.edu.cn
RI Ngan, N/E-8240-2014; Wu, Qingbo/AAF-6872-2019
OI Ngan, N/0000-0003-1946-3235; Wu, Qingbo/0000-0003-2936-6340
FU National Basic Research Program of China (973 Program) [2015CB351804];
   National Natural Science Foundation of China [61271289]; program for
   Science and Technology Innovative Research Team for Young Scholars in
   Sichuan Province, China [2014TD0006]; Fundamental Research Funds for the
   Central Universities [ZYGX2012YB007]
FX This work was supported in part by the National Basic Research Program
   of China (973 Program 2015CB351804), National Natural Science Foundation
   of China (No. 61271289), The program for Science and Technology
   Innovative Research Team for Young Scholars in Sichuan Province, China
   (No. 2014TD0006) and by The Fundamental Research Funds for the Central
   Universities (ZYGX2012YB007).
CR ABDULLAH MB, 1990, J ROY STAT SOC D-STA, V39, P455
   [Anonymous], Categorical image quality (CSIQ) database
   [Anonymous], 2008, A wavelet tour of signal processing: The sparse way
   BOTTOU L, 1992, NEURAL COMPUT, V4, P888, DOI 10.1162/neco.1992.4.6.888
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen ZY, 2014, PROC CVPR IEEE, P3003, DOI 10.1109/CVPR.2014.384
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fink GR, 1999, NEUROPSYCHOLOGIA, V37, P31
   Gao XB, 2013, IEEE T NEUR NET LEAR, V24, P2013, DOI 10.1109/TNNLS.2013.2271356
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Ghanem B, 2008, IEEE IMAGE PROC, P393, DOI 10.1109/ICIP.2008.4711774
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kaufman L., 2009, WILEY SERIES PROBABI, V344, DOI 10.1002/9780470316801
   Kong XF, 2013, IEEE I CONF COMP VIS, P2888, DOI 10.1109/ICCV.2013.359
   Li HL, 2014, IEEE T IMAGE PROCESS, V23, P3545, DOI 10.1109/TIP.2014.2330759
   Li HL, 2014, IEEE T CIRC SYST VID, V24, P789, DOI 10.1109/TCSVT.2013.2280851
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu HW, 2014, J VIS COMMUN IMAGE R, V25, P709, DOI 10.1016/j.jvcir.2013.03.012
   Loader C., 1999, Local Regression and Likelihood, V47
   Ma L, 2011, IEEE T MULTIMEDIA, V13, P824, DOI 10.1109/TMM.2011.2109701
   MACKAY DM, 1981, NATURE, V289, P117, DOI 10.1038/289117a0
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Meng FM, 2013, IEEE T IMAGE PROCESS, V22, P4809, DOI 10.1109/TIP.2013.2278461
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE SIGNAL PROC LET, V19, P75, DOI 10.1109/LSP.2011.2179293
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Muggeo VMR, 2003, STAT MED, V22, P3055, DOI 10.1002/sim.1545
   Narwaria M, 2010, IEEE T NEURAL NETWOR, V21, P515, DOI 10.1109/TNN.2010.2040192
   Nauge M., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P610, DOI 10.1109/PCS.2010.5702578
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Seber G. A. F., 2003, Wiley Series in Probability and Statistics
   Seo HJ, 2010, INT CONF ACOUST SPEE, P5578, DOI 10.1109/ICASSP.2010.5495239
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh H.R., Live Image Quality Assessment Database
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sokal RR, 1995, BIOMETRY PRINCIPLES
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   SPECHT DF, 1991, IEEE T NEURAL NETWOR, V2, P568, DOI 10.1109/72.97934
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Tang CW, 2014, J VIS COMMUN IMAGE R, V25, P1746, DOI 10.1016/j.jvcir.2014.06.007
   Verbesselt J, 2010, REMOTE SENS ENVIRON, V114, P106, DOI 10.1016/j.rse.2009.08.014
   Wainwright MJ, 2000, ADV NEUR IN, V12, P855
   Wang C, 2013, J VIS COMMUN IMAGE R, V24, P270, DOI 10.1016/j.jvcir.2013.01.001
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang ZJ, 2011, IEEE SIGNAL PROC MAG, V28, P2, DOI 10.1109/MSP.2011.940297
   Wu JJ, 2013, IEEE T IMAGE PROCESS, V22, P43, DOI 10.1109/TIP.2012.2214048
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P1158, DOI 10.1016/j.jvcir.2012.07.010
   Wu M., 2006, P C NEURAL INFORM PR, P1529
   Wu Mingrui, 2007, International Conference on Artificial Intelligence and Statistics, P628
   Wu Q, 2015, IEEE T CIRC SYST VID, DOI [http://dx.doi.org/10.1109/TCSVT.2015.2412773, DOI 10.1109/TCSVT.2015.2412773.IN]
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Yan JZ, 2014, PROC CVPR IEEE, P2987, DOI 10.1109/CVPR.2014.382
   Ye P, 2013, PROC CVPR IEEE, P987, DOI 10.1109/CVPR.2013.132
NR 64
TC 31
Z9 34
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 205
EP 216
DI 10.1016/j.jvcir.2015.08.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300017
DA 2024-07-18
ER

PT J
AU Wu, HT
   Huang, JW
   Shi, YQ
AF Wu, Hao-Tian
   Huang, Jiwu
   Shi, Yun-Qing
TI A reversible data hiding method with contrast enhancement for medical
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contrast enhancement; Medical image; Region of interest; Reversible data
   hiding; Authentication; Background segmentation; Histogram; Visual
   quality
ID PREDICTION-ERROR; ENCRYPTED IMAGES; WATERMARKING; EXPANSION; DIFFERENCE
AB In this paper, a reversible data hiding method with contrast enhancement is presented for medical images. Firstly, image background segmentation is performed and the principal gray-scale values in the segmented background are identified. By excluding the corresponding histogram bins from being expanded for data hiding, the contrast of region of interest (ROI) in medical images can be selectively enhanced. Considering the characteristics of pixel distribution, we develop a new pre-processing strategy to reduce the visual distortions that may be caused. With the proposed method, an original image can be exactly recovered from the corresponding enhanced image by hiding the side information within it. The experimental results on a set of medical images show that the visibility of ROI can be improved. Compared with the previous method, the proposed method can achieve more contrast enhancement effects and better visual quality for medical images. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Wu, Hao-Tian] Jiangnan Univ, Sch Digital Media, Wuxi 214122, JS, Peoples R China.
   [Huang, Jiwu] Shenzhen Univ, Coll Informat Engn, Shenzhen, Peoples R China.
   [Shi, Yun-Qing] New Jersey Inst Technol, Dept ECE, Newark, NJ 07103 USA.
C3 Jiangnan University; Shenzhen University; New Jersey Institute of
   Technology
RP Wu, HT (corresponding author), Jiangnan Univ, Sch Digital Media, Wuxi 214122, JS, Peoples R China.
EM htwu@jiangnan.edu.cn; jwhuang@szu.edu.cn; shi@njit.edu
RI Wu, Hao-Tian/S-5360-2019; huang, jw/KVY-9917-2024; Shi,
   Yun/JWP-3360-2024
OI Wu, Hao-Tian/0000-0001-6462-7193; 
FU National Natural Science Foundation of China [61100169, 61332012,
   U1135001]; Fundamental Research Funds for the Central Universities of
   China [JUSRP1047]; 973 Program of China [2011CB302204]
FX This work is supported by National Natural Science Foundation of China
   (No. 61100169, 61332012, U1135001), Fundamental Research Funds for the
   Central Universities of China (JUSRP1047) and 973 Program of China
   (2011CB302204).
CR [Anonymous], JIH MSP
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Gao M.-Z., 2013, Adv. Intell. Syst. Appl., V2, P331, DOI [10.1007/978-3-642-35473-133, DOI 10.1007/978-3-642-35473-133]
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Huang HC, 2013, EXPERT SYST APPL, V40, P34, DOI 10.1016/j.eswa.2012.07.010
   Huang HC, 2011, SENSORS-BASEL, V11, P9717, DOI 10.3390/s111009717
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   PAN W, 2009, 31 ANN INT IEEE C EN, P2172
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
NR 25
TC 94
Z9 99
U1 0
U2 54
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 146
EP 153
DI 10.1016/j.jvcir.2015.06.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600013
DA 2024-07-18
ER

PT J
AU Silva, E
   Carvalho, T
   Ferreira, A
   Rocha, A
AF Silva, Ewerton
   Carvalho, Tiago
   Ferreira, Anselmo
   Rocha, Anderson
TI Going deeper into copy-move forgery detection: Exploring image telltales
   via multi-scale analysis and voting processes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Copy-move forgery detection; Interest points; Speed-up Robust Features;
   Keypoints clustering; Multi-scale analysis; Scale-space; Voting
   processes; Realistic dataset
AB This work presents a new approach toward copy-move forgery detection based on multi-scale analysis and voting processes of a digital image. Given a suspicious image, we extract interest points robust to scale and rotation finding possible correspondences among them. We cluster correspondent points into regions based on geometric constraints. Thereafter, we construct a multi-scale image representation and for each scale, we examine the generated groups using a descriptor strongly robust to rotation, scaling and partially robust to compression, which decreases the search space of duplicated regions and yields a detection map. The final decision is based on a voting process among all detection maps. We validate the method using various datasets comprising original and realistic image clonings. We compare the proposed method to 15 others from the literature and report promising results. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Silva, Ewerton; Carvalho, Tiago; Ferreira, Anselmo; Rocha, Anderson] Univ Estadual Campinas, Inst Comp, RECOD Lab, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Carvalho, T (corresponding author), Univ Estadual Campinas, Inst Comp, RECOD Lab, Av Albert Einstein 1251,Cidade Univ Zeferino Vaz, BR-13083852 Campinas, SP, Brazil.
EM ewerton.silva@students.ic.unicamp.br; tjose@ic.unicamp.br;
   anselmoferreira@ic.unicamp.br; anderson.rocha@ic.unicamp.br
RI Carvalho, Tiago J/F-8589-2015; Rocha, Anderson/KHU-9621-2024; Ferreira,
   Anselmo/J-5210-2014
OI Almeida Silva, Ewerton/0000-0003-4021-5906; Ferreira,
   Anselmo/0000-0002-2196-7232; Carvalho, Tiago/0000-0002-7779-1950
FU Microsoft Research; Sao Paulo Research Foundation [2010/05647-4];
   National Council for Scientific and Technological Development
   [304352/2012-8, 477662/2013-7]; CAPES [0214-13-2]; CNPq [140916/2012-1];
   CAPES Deep Eyes Project; IF Sudeste MG; Fundacao de Amparo a Pesquisa do
   Estado de Sao Paulo (FAPESP) [10/05647-4] Funding Source: FAPESP
FX Supported by Microsoft Research, the Sao Paulo Research Foundation
   (Grant #2010/05647-4), the National Council for Scientific and
   Technological Development (Grants #304352/2012-8 and #477662/2013-7),
   CAPES (Grants #0214-13-2), CNPq (140916/2012-1), CAPES Deep Eyes
   Project, and IF Sudeste MG.
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2003, PROC DIGIT FORENSIC
   Ardizzone E, 2009, LECT NOTES COMPUT SC, V5716, P893, DOI 10.1007/978-3-642-04146-4_95
   Barnes C., 2010, LECT NOTES COMPUT SC, V6313, P29
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bashar M., 2010, T IMAGE PROCESS TIP
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bradski G., 2008, LEARNING OPENCV
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D., 2014, INT C IM PROC ICIP
   Farid H., 2006, P 8 WORKSHOP MULTIME, P29
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Intel, 2012, OPENCV REF MAN 2 4 3
   Li G., 2007, IEEE INT C MULT EXP, DOI DOI 10.1109/ICME.2007.4285009
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pan XY, 2010, INT CONF ACOUST SPEE, P1706, DOI 10.1109/ICASSP.2010.5495482
   Popescu AC, 2004, 2004515 DARTM COLL D
   Rocha Anderson, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4562987
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E., 2011, SAUDE ETICA JUSTICA, V16, P9
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   The Joint Photograph Expert Group, 2010, JPEG FIL INT FORM
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wong Y.-M., 2006, INVARIANT LOCAL FEAT
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Zhang J., 2010, INT C COMM SYST ICCS, P362, DOI [10.1177/1753193410362645, DOI 10.1177/1753193410362645]
NR 37
TC 155
Z9 166
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2015
VL 29
BP 16
EP 32
DI 10.1016/j.jvcir.2015.01.016
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CE8UH
UT WOS:000352119100003
DA 2024-07-18
ER

PT J
AU Ma, XX
   Pan, ZB
   Hu, S
   Wang, LF
AF Ma, Xiaoxiao
   Pan, Zhibin
   Hu, Sen
   Wang, Lingfei
TI High-fidelity reversible data hiding scheme based on multi-predictor
   sorting and selecting mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Steganography; Reversible data hiding; Prediction-error;
   Histogram modification; Multi-predictor; Predictor; Prediction-error
   histogram modification
ID LOSSLESS IMAGE COMPRESSION; JPEG-LS; WATERMARKING; EXPANSION
AB Reversible data hiding can completely recover the cover image without any distortion after the secret data is retrieved. In this paper, a new high-fidelity reversible data hiding scheme is proposed using the prediction-error histogram modification technique. A multi-predictor sorting and selecting mechanism is proposed to select an optimum predictor from a set of predictors. Then a smaller prediction-error is obtained to embed the secret data using the prediction-error histogram modification technique. Since the multi-predictor sorting and selecting mechanism can utilize the advantage of multi-predictor and information of current predicted pixel to obtain a more accurate prediction value, our proposed scheme can introduce less image distortion at the same embedding payload. Experimental results demonstrate that our proposed scheme outperforms the similar reversible data hiding schemes. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ma, Xiaoxiao; Pan, Zhibin; Hu, Sen; Wang, Lingfei] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Specialized Research Fund for the Doctoral Program of Higher Education
   [20130201110071]; Key Science and Technology Program of Shaanxi Province
   [2012GY2-30]; Open Project Program of the National Laboratory of Pattern
   Recognition [201407370]; Open Project Program of the State Key Lab of
   SKL, Nanjing University [KFKT2013B05]
FX This work is supported in part by Specialized Research Fund for the
   Doctoral Program of Higher Education (Grant No. 20130201110071), Project
   Supported by Key Science and Technology Program of Shaanxi Province
   (Grant No. 2012GY2-30), Open Project Program of the National Laboratory
   of Pattern Recognition (Grant No. 201407370) and Open Project Program of
   the State Key Lab of SKL (Grant No. KFKT2013B05), Nanjing University.
CR Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Hong W., 2014, INF SCI
   Hong WE, 2010, J SYST SOFTWARE, V83, P2653, DOI 10.1016/j.jss.2010.08.047
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Jiang J, 2000, IEE P-VIS IMAGE SIGN, V147, P575, DOI 10.1049/ip-vis:20000767
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lu TC, 2014, SIGNAL PROCESS, V104, P152, DOI 10.1016/j.sigpro.2014.04.001
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang HJ, 2006, IEICE T INF SYST, VE89D, P2250, DOI 10.1093/ietisy/e89-d.7.2250
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2014, J VIS COMMUN IMAGE R, V25, P1425, DOI 10.1016/j.jvcir.2014.04.005
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
NR 25
TC 56
Z9 59
U1 6
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2015
VL 28
BP 71
EP 82
DI 10.1016/j.jvcir.2015.01.012
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CD8DI
UT WOS:000351325000009
DA 2024-07-18
ER

PT J
AU Ding, WW
   Liu, K
   Cheng, F
   Zhang, J
AF Ding, Wenwen
   Liu, Kai
   Cheng, Fei
   Zhang, Jin
TI STFC: Spatio-temporal feature chain for skeleton-based human action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE View-invariant representation; Skeleton joints; 3D action feature
   representation; Computer vision; RGB-D dataset; 3D trajectory
   segmentation; B-spline fitting; SVM learning
AB Human action recognition and analysis has been of interest to researchers of computer vision for many years. This paper presents a method to recognize human actions from sequences of 3D joint positions. The major contributions of this paper include: (1) An action decomposition method that uses motion velocities, the direction of motion, and the curvatures of trajectories to encode the temporal decomposition of action into a sequence of meaningful atomic actions (actionlets); and (2) the concept of the Spatio-Temporal Feature Chain (STFC) that is introduced to represent the characteristic parameters of temporal sequential patterns, which exhibit greater robustness to noise and temporal misalignment. The effectiveness of the proposed method is evaluated on three challenging 3D action datasets captured by commodity depth cameras. The experimental evaluations show that the proposed approach achieves promising results compared to other state of the art algorithms. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Ding, Wenwen; Liu, Kai; Cheng, Fei; Zhang, Jin] Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
C3 Xidian University
RP Liu, K (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian, Peoples R China.
EM dww2048@163.com; kailiu@mail.xidian.edu.cn; chengfei8582@163.com;
   jinzhang.cv@gmail.com
RI liu, jianyang/JXL-6273-2024; Zhou, Jing/IVH-8073-2023; Liu,
   Kai/IST-6808-2023
OI , ding/0000-0001-8582-2078
FU National Natural Science Foundation of China [61350110239]; Fundamental
   Research Funds for the Central Universities [BDY191420]; Open Research
   Funds of State Key Lab. for Novel Software Technology [KFKT2012B16]
FX This material is based upon work supported by the National Natural
   Science Foundation of China under Grant No. 61350110239, the Fundamental
   Research Funds for the Central Universities under Grant No. BDY191420,
   the Open Research Funds of State Key Lab. for Novel Software Technology
   under Grant No. KFKT2012B16.
CR [Anonymous], VISUAL MOTION PERCEP
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   GJOYSTDAL H, 1981, GEOPHYSICS, V46, P972, DOI 10.1190/1.1441246
   Klette R., 2008, Understanding human motion: A historic review (Human Motion. Computational Imaging and Vision)
   Li K, 2012, LECT NOTES COMPUT SC, V7572, P286, DOI 10.1007/978-3-642-33718-5_21
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   MARTENS J, 2011, P 28 INT C MACH LEAR, P1033
   Mastorakis G., 2012, J. Real-Time Image Process
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Senin P., 2008, Information and Computer Science Department University of Hawaii at Manoa Honolulu, USA, V855, P40
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Villaroman N., 2011, Proceedings of the conference on Information technology education, P227
   Wang J, 2014, SPRINGERBRIEF COMPUT, P11, DOI 10.1007/978-3-319-04561-0_2
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 22
TC 34
Z9 34
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2015
VL 26
BP 329
EP 337
DI 10.1016/j.jvcir.2014.10.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AZ5GT
UT WOS:000348249000030
DA 2024-07-18
ER

PT J
AU Shen, XB
   Sun, QS
AF Shen, XiaoBo
   Sun, QuanSen
TI A novel semi-supervised canonical correlation analysis and extensions
   for multi-view dimensionality reduction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Canonical correlation analysis; Semi-supervised learning; Label
   propagation; Sparse representation; Multi-view learning; Feature
   extraction; Dimensionality reduction; Image recognition
ID RECOGNITION; CONSTRAINTS; FRAMEWORK; FEATURES; FUSION
AB Canonical correlation analysis (CCA) is an efficient method for dimensionality reduction on two-view data. However, as an unsupervised learning method, CCA cannot utilize partly given label information in multi-view semi-supervised scenarios. In this paper, we propose a novel two-view semi-supervised learning method, called semi-supervised canonical correlation analysis based on label propagation (LPbSCCA). LPbSCCA incorporates a new sparse representation based label propagation algorithm to infer label information for unlabeled data. Specifically, it firstly constructs dictionaries consisting of all labeled samples; and then obtains reconstruction coefficients of unlabeled samples using sparse representation technique; at last, by combining given labels of labeled samples, estimates label information for unlabeled ones. After that, it constructs soft label matrices of all samples and probabilistic within-class scatter matrices in each view. Finally, in order to enhance discriminative power of features, it is formulated to maximize the correlations between samples of the same class from cross views, while minimizing within-class variations in the low-dimensional feature space of each view simultaneously. Furthermore, we also extend a general model called LPbSMCCA to handle data from multiple (more than two) views. Extensive experimental results from several well-known datasets demonstrate that the proposed methods can achieve better recognition performances and robustness than existing related methods. Crown Copyright (C) 2014 Published by Elsevier Inc. All rights reserved.
C1 [Shen, XiaoBo; Sun, QuanSen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Sun, QS (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM njust.shenxiaobo@gmail.com; sunquansen@njustedu.cn
OI Shen, Xiaobo/0000-0001-8655-1265
FU National Science Foundation of China [61273251]
FX This work is supported by the National Science Foundation of China under
   Grant No. 61273251. The authors would like to thank the anonymous
   reviewers for their valuable comments and suggestions that helped
   greatly improve the quality of this paper.
CR [Anonymous], 2008, P 2008 INT C CONTENT, DOI DOI 10.1145/1386352.1386373
   [Anonymous], 2008, P 2008 SIAM INT C DA
   [Anonymous], 2007, PROC IEEE INT C COMP
   [Anonymous], 1998, UCI REPOSITORY MACHI
   [Anonymous], NEURAL PROCESS LETT
   [Anonymous], 2012, MATRIX COMPUTATIONS
   [Anonymous], Learning from labeled and unlabeled data with label propagation
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen XH, 2012, PATTERN RECOGN, V45, P2005, DOI 10.1016/j.patcog.2011.11.008
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   Chu D., 2013, IEEE T PATTERN ANAL
   Diethe T., 2008, NIPS WORKSH LEARN MU
   FRANKE J, 1993, 3 INT WORKSH FRONT H, P305
   Guan NY, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P51, DOI 10.1109/ICMLA.2012.18
   Ha HY, 2013, INT J MULTIMED DATA, V4, P46, DOI 10.4018/jmdem.2013040103
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hou CP, 2010, PATTERN RECOGN, V43, P720, DOI 10.1016/j.patcog.2009.07.015
   Hu Zhong-Shan, 1999, Chinese Journal of Computers, V22, P369
   Huang H, 2011, IEEE T NEURAL NETWOR, V22, P121, DOI 10.1109/TNN.2010.2089470
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Liu W, 2016, MULTIMED TOOLS APPL, V75, P1481, DOI 10.1007/s11042-014-2004-4
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lu JW, 2012, IEEE T INF FOREN SEC, V7, P944, DOI 10.1109/TIFS.2012.2188389
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Nie FP, 2009, PATTERN RECOGN, V42, P2615, DOI 10.1016/j.patcog.2009.04.001
   Nielsen AA, 2002, IEEE T IMAGE PROCESS, V11, P293, DOI 10.1109/83.988962
   Peng Y, 2010, NEURAL PROCESS LETT, V31, P1, DOI 10.1007/s11063-009-9123-3
   Peng Yan, 2008, Journal of Software, V19, P2822, DOI 10.3724/SP.J.1001.2008.02822
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Shen X., 2014, NEUROCOMPUTING
   Song YQ, 2008, PATTERN RECOGN, V41, P2789, DOI 10.1016/j.patcog.2008.01.001
   Sugiyama M, 2010, MACH LEARN, V78, P35, DOI 10.1007/s10994-009-5125-7
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun QS, 2005, PATTERN RECOGN, V38, P449, DOI 10.1016/j.patcog.2004.08.009
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Sun TK, 2008, IEEE DATA MINING, P1043, DOI 10.1109/ICDM.2008.28
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang JD, 2009, IEEE T PATTERN ANAL, V31, P1600, DOI 10.1109/TPAMI.2008.216
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xu C., 2013, arXiv
   Yu J., 2014, INFORM SCI
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu J, 2013, PATTERN RECOGN, V46, P483, DOI 10.1016/j.patcog.2012.08.006
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Yu J, 2011, IEEE T IMAGE PROCESS, V20, P3257, DOI 10.1109/TIP.2011.2158225
   Yuan YH, 2011, PATTERN RECOGN, V44, P1031, DOI 10.1016/j.patcog.2010.11.004
   ZHANG D, 2007, SDM
NR 54
TC 34
Z9 36
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1894
EP 1904
DI 10.1016/j.jvcir.2014.09.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300009
DA 2024-07-18
ER

PT J
AU Xu, J
   Wu, DP
AF Xu, Jun
   Wu, Dapeng
TI Gamma rate theory for causal rate control in source coding and video
   coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Causal rate control; Rate distortion function; Source coding; Video
   coding; Gamma rate function; Rate gamma function; Viewer friendliness;
   Network friendliness
ID DISTORTION; INTERNET; SCHEME
AB The rate distortion function in information theory provides performance bounds for lossy source coding. However, it is not clear how to causally encode a Gaussian sequence under rate constraints while achieving R-D optimality. This problem has significant implications in the design of rate control for video communication. To address this problem, we take distortion fluctuation into account and develop a new theory, called gamma rate theory, to quantify the trade-off between rate and distortion fluctuation. The gamma rate theory implies that, to evaluate the performance of causal rate controls in source coding, the traditional R-D metric needs to be replaced by a new GRD metric. The gamma rate theory identifies the trade-off between quality fluctuation and bandwidth, which is not known previously. To validate the gamma rate theory, we design a rate control algorithm for video coding; our experimental results demonstrate the utility of the gamma rate theory in video coding. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Xu, Jun; Wu, Dapeng] Univ Florida, Dept Elect & Comp Engn, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Wu, DP (corresponding author), Univ Florida, Dept Elect & Comp Engn, POB 116130, Gainesville, FL 32611 USA.
EM wu@ece.ufLedu
OI Wu, Dapeng/0000-0003-1755-0183
FU NSF [ECCS-1002214, CNS-1116970]; NSFC [61228101]; Division Of Computer
   and Network Systems; Direct For Computer & Info Scie & Enginr [1116970]
   Funding Source: National Science Foundation
FX This work was supported in part by NSF ECCS-1002214, CNS-1116970, and
   NSFC 61228101.
CR ALTUNBASAK Y, 2004, P IEEE INT C AC SPEE, V3
   [Anonymous], 2006, Elements of Information Theory
   Berger Toby, 1971, RATE DISTORTION THEO
   Bjontegaard G., 2001, Document VCEG-M33
   Cai JF, 2006, J VIS COMMUN IMAGE R, V17, P783, DOI 10.1016/j.jvcir.2004.11.005
   Chen JY, 2011, IEEE T BROADCAST, V57, P89, DOI 10.1109/TBC.2010.2079690
   Chen ZZ, 2007, IEEE T CIRC SYST VID, V17, P158, DOI 10.1109/TCSVT.2006.888022
   Chiang TH, 1997, IEEE T CIRC SYST VID, V7, P246, DOI 10.1109/76.554439
   Dong JP, 2009, IEEE T CIRC SYST VID, V19, P1108, DOI 10.1109/TCSVT.2009.2020338
   Gray R. M., 1989, Source coding theory, V83
   Huang CM, 2007, IEEE T MULTIMEDIA, V9, P1113, DOI 10.1109/TMM.2007.902840
   Jiang MQ, 2006, IEEE T MULTIMEDIA, V8, P467, DOI 10.1109/TMM.2006.870713
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Li Z. G., 2003, 7 M PATT 2 THAIL
   Netravali A.N., 1995, DIGITAL PICTURES REP, V2nd
   Ortega A, 1998, IEEE SIGNAL PROC MAG, V15, P23, DOI 10.1109/79.733495
   Sanz-Rodríguez S, 2010, IEEE T CIRC SYST VID, V20, P1139, DOI 10.1109/TCSVT.2010.2051369
   Shannon C., 1960, Information and decision processes, P93
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Wu DP, 2000, IEEE T CIRC SYST VID, V10, P923, DOI 10.1109/76.867930
   Wu DP, 2000, P IEEE, V88, P1855, DOI 10.1109/5.899055
   Wu DP, 2001, IEEE T CIRC SYST VID, V11, P282, DOI 10.1109/76.911156
   Xie B, 2006, IEEE T CIRC SYST VID, V16, P56, DOI 10.1109/TCSVT.2005.856911
   Zhou SM, 2007, IEEE T CIRC SYST VID, V17, P996, DOI 10.1109/TCSVT.2007.903123
NR 26
TC 0
Z9 1
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2014
VL 25
IS 8
BP 1886
EP 1893
DI 10.1016/j.jvcir.2014.09.008
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AS3XU
UT WOS:000344209300008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rai, P
   Khanna, P
AF Rai, Preeti
   Khanna, Pritee
TI A gender classification system robust to occlusion using Gabor features
   based (2<i>D</i>)<SUP>2</SUP>PCA
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Real Gabor space; Approximation face sub-image (2D)(2)PCA; Support
   Vector Machine; Region of Interest; Local features; Occlusion; Entropy
ID MUTUAL INFORMATION; FACE IMAGES; RECOGNITION; FUSION
AB Recognizing gender of a person from occluded face image is a recent challenge in gender classification research. This work investigates the issue and proposes a gender classification system that works for non-occluded face images to face images occluded up to 60%. Local information of the face, which carries the most discriminative features to find the gender, is gathered by dividing the face image into M x N sub-images. Subsequently, features are calculated for every sub-image by applying (2D)(2)PCA on each illumination invariant real Gabor space generated using Gabor filter. Support Vector Machine is used for classification. Experiments are performed on five databases. In case of non-occluded face images, the proposed approach gives 98.4% classification rate on FERET database. For occluded face images, occlusions ranging from 10% to 60%, results are quite competitive with accuracies around 90%. Present work also analyzes the impact of various face components in the context of gender classification. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Rai, Preeti; Khanna, Pritee] Pandit Dwarka Prasad Mishra Indian Inst Informat, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Khanna, P (corresponding author), Pandit Dwarka Prasad Mishra Indian Inst Informat, Jabalpur, India.
EM preeti@iiitdmj.ac.in; pritee@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019
OI Khanna, Pritee/0000-0003-0518-2133
CR Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   Andren Y, 2008, LECT NOTES COMPUT SC, V5197, P252, DOI 10.1007/978-3-540-85920-8_31
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2010, P 2010 IEEE INT C CO, DOI DOI 10.1109/ICCIC.2010.5705804
   [Anonymous], 24 CVC
   [Anonymous], 1992, 10 LECT WAVELETS
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Berbar M. A., 2013, VISUAL COMPUT, P1
   Golomb B.A., 1990, Advances in Neural Information Processing Systems (NIPS), P572
   Guo-Shiang Lin, 2011, Proceedings of the 2011 First International Conference on Robot, Vision and Signal Processing (RVSP 2011), P40, DOI 10.1109/RVSP.2011.69
   Huang GaryB., 2007, Labeled faces in the wild: A database for studying face recognition in unconstrained environments
   Jabid Taskeed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2162, DOI 10.1109/ICPR.2010.373
   Li B, 2012, NEUROCOMPUTING, V76, P18, DOI 10.1016/j.neucom.2011.01.028
   Lu HC, 2008, J REAL-TIME IMAGE PR, V3, P109, DOI 10.1007/s11554-008-0072-2
   Lu L, 2009, INT CONF ACOUST SPEE, P1065, DOI 10.1109/ICASSP.2009.4959771
   Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Perez C, 2012, INT J OPTOMECHATRONI, V6, P92, DOI 10.1080/15599612.2012.663463
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rai P., 2010, 2010 5th International Conference on Industrial and Information Systems (ICIIS 2010), P448, DOI 10.1109/ICIINFS.2010.5578661
   Rai P., 2012, Advances in Computer Science, Engineering Applications, P51, DOI [DOI 10.1007/978-3-642-30157-56, 10.1007/978-3-642-30157-56]
   Rai P., 2011, INT C ADV MOD OPT CO, P961
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Shih HC, 2013, PATTERN RECOGN, V46, P519, DOI 10.1016/j.patcog.2012.08.003
   Sonka M., DIGITAL IMAGE PROCES
   Sun N, 2006, LECT NOTES COMPUT SC, V3972, P194
   Tamura S, 1996, PATTERN RECOGN, V29, P331, DOI 10.1016/0031-3203(95)00073-9
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   Thomaz C.E., IMAGE VISION COMPUT, V28
   TURNER MR, 1986, BIOL CYBERN, V55, P71
   Wang CX, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 1, PROCEEDINGS, P312, DOI 10.1109/ISCSCT.2008.204
   Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003
   Wu TX, 2012, NEURAL COMPUT APPL, V21, P661, DOI 10.1007/s00521-011-0647-x
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zheng J, 2011, NEUROCOMPUTING, V74, P1926, DOI 10.1016/j.neucom.2010.07.032
NR 36
TC 26
Z9 30
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1118
EP 1129
DI 10.1016/j.jvcir.2014.03.009
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200038
DA 2024-07-18
ER

PT J
AU Shahamat, H
   Pouyan, AA
AF Shahamat, Hossein
   Pouyan, Ali A.
TI Face recognition under large illumination variations using homomorphic
   filtering in spatial domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Frequency domain filtering; Butterworth high-pass filter; Illumination
   normalization; Face image preprocessing; Face representation;
   Homomorphic parameters; Kernel function; Reflectance component
ID EIGENFACES; IMAGE
AB This paper proposes a homomorphic filtering in spatial domain for reducing of illumination effects in face recognition systems. Also, in this research a simple kernel of homomorphic filter is proposed. Application of this method causes considerable reduction in computational time in the preprocessing step. When a new face image with an arbitrary illumination is given, the homomorphic filter is applied and its reflectance component is extracted. Then the reflectance component is divided into several local regions and histograms of each local region are extracted using multi-resolution uniform local Gabor binary patterns (MULGBP). These histograms are combined for obtaining the overall histogram of the images. Finally, for face recognition, a simple histogram matching process is performed between new face image histogram and the gallery images histogram. The results show that the proposed method is robust for large illumination variation with a reasonable computational complexity. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Shahamat, Hossein; Pouyan, Ali A.] Shahrood Univ Technol, Dept Comp Engn & Informat Technol, Shahrood 3619995161, Semnan, Iran.
C3 Shahrood University of Technology
RP Shahamat, H (corresponding author), Shahrood Univ Technol, Dept Comp Engn & Informat Technol, 316 Daneshgah Ave, Shahrood 3619995161, Semnan, Iran.
EM Shahamat@shahroodut.ac.ir; apouyan@shahroodut.ac.ir
CR Adelmann HG, 1998, COMPUT BIOL MED, V28, P169, DOI 10.1016/S0010-4825(98)00004-3
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], DIGITAL IMAGE PROCES
   Baek K., 2007, P 6 WSEAS INT C SIGN, P7
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Delac K., 2006, International Conference on Systems, Signals and Image Processing, P95
   Du S, 2005, IEEE IMAGE PROC, P2129
   Fan CN, 2011, PATTERN RECOGN LETT, V32, P1468, DOI 10.1016/j.patrec.2011.03.023
   Fisher R., 1996, Hypermedia image processing reference
   Horn B.K.P, 1986, Robot Vision
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jun B, 2011, PATTERN RECOGN LETT, V32, P329, DOI 10.1016/j.patrec.2010.09.011
   Kao WC, 2010, PATTERN RECOGN, V43, P1736, DOI 10.1016/j.patcog.2009.11.016
   Lee H.S., 2008, Proc. IEEE Int. Conf. Automatic Face and Gesture Recognition, P1
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Matkovic K., 2005, Computational Aesthetics, P159
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Nam MY, 2004, LECT NOTES ARTIF INT, V3215, P843
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang HT, 2004, IEEE IMAGE PROC, P1397
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Xue H, 2009, NEUROCOMPUTING, V72, P1342, DOI 10.1016/j.neucom.2008.09.007
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 30
TC 26
Z9 27
U1 0
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 970
EP 977
DI 10.1016/j.jvcir.2014.02.007
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200025
DA 2024-07-18
ER

PT J
AU Yin, M
   Gao, JB
   Tien, D
   Cai, ST
AF Yin, Ming
   Gao, Junbin
   Tien, David
   Cai, Shuting
TI Blind image deblurring via coupled sparse representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind deblurring; Sparse representation; Coupled dictionary; Image
   patch; Deconvolution; Blur kernel; Total variance; Sub-pixel resolution
ID VARIATIONAL APPROACH; K-SVD; DECONVOLUTION
AB The problem of blind image deblurring is more challenging than that of non-blind image deblurring, due to the lack of knowledge about the point spread function in the imaging process. In this paper, a learning-based method of estimating blur kernel under the l(0) regularization sparsity constraint is proposed for blind image deblurring. Specifically, we model the patch-based matching between the blurred image and its sharp counterpart via a coupled sparse representation. Once the blur kernel is obtained, a non-blind deblurring algorithm can be applied to the final recovery of the sharp image. Our experimental results show that the visual quality of restored sharp images is competitive with the state-of-the-art algorithms for both synthetic and real images. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Yin, Ming; Cai, Shuting] Guangdong Univ Technol, Sch Automat, Guangzhou, Guangdong, Peoples R China.
   [Gao, Junbin; Tien, David] Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia.
C3 Guangdong University of Technology; Charles Sturt University
RP Gao, JB (corresponding author), Charles Sturt Univ, Sch Comp & Math, Bathurst, NSW 2795, Australia.
EM yiming@gdut.edu.cn; jbgao@csu.edu.au; dtien@csu.edu.au;
   shutingcai@126.com
RI Gao, Junbin/C-6566-2008; Gao, Junbin/A-1766-2009
OI Yin, Ming/0000-0002-7037-1048; Gao, Junbin/0000-0001-9803-0256
FU Australian Research Council (ARC) [DP130100364]; NSF China [61201392]
FX This work is supported under the Grant DP130100364 from the Australian
   Research Council (ARC). The work of the first and fourth authors is
   supported by NSF China under Grants No. 61201392.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2008, TECHNION
   [Anonymous], P 10 IEEE INT C COMP
   [Anonymous], 2007, Blind Image Deconvolution: Theory and Applications
   Babacan SD, 2009, IEEE T IMAGE PROCESS, V18, P12, DOI 10.1109/TIP.2008.2007354
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Bronstein MM, 2005, IEEE T IMAGE PROCESS, V14, P726, DOI 10.1109/TIP.2005.847322
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Dai S., 2008, P IEEE C COMPUTER VI, P1
   Daubechies I, 2010, COMMUN PUR APPL MATH, V63, P1, DOI 10.1002/cpa.20303
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13
   Hu Z, 2010, IEEE IMAGE PROC, P1169, DOI 10.1109/ICIP.2010.5651892
   Joshi N., 2008, P IEEE C COMPUTER VI, P1
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Krishnan D, 2011, PROC CVPR IEEE, P233, DOI 10.1109/CVPR.2011.5995521
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Likas AC, 2004, IEEE T SIGNAL PROCES, V52, P2222, DOI 10.1109/TSP.2004.831119
   Lou YF, 2011, J MATH IMAGING VIS, V39, P1, DOI 10.1007/s10851-010-0220-8
   Molina R, 2006, IEEE T IMAGE PROCESS, V15, P3715, DOI 10.1109/TIP.2006.881972
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhang HC, 2009, IEEE IMAGE PROC, P1293, DOI 10.1109/ICIP.2009.5413591
   [张华 ZHANG Hua], 2011, [高分子通报, Polymer Bulletin], P1
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
NR 31
TC 15
Z9 19
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 814
EP 821
DI 10.1016/j.jvcir.2014.02.003
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200010
DA 2024-07-18
ER

PT J
AU Liu, HM
   Wang, ZH
AF Liu, Hongmin
   Wang, Zhiheng
TI PLDD: Point-lines distance distribution for detection of arbitrary
   triangles, regular polygons and circles
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Point-lines distance distribution (PLDD); Geometric shape detection;
   Shape energy; Shape center; Shape radius; Circle detection; Arbitrary
   triangle detection; Regular polygon detection
ID TRAFFIC SIGN RECOGNITION; HOUGH-TRANSFORM; SHAPE; EXTRACTION; COLOR
AB In this paper, a general framework is presented for detection of arbitrary triangles, regular polygons, and circles, which is inspired by the common geometric property that the incenter of the shape is equidistant to the tangential lines of the contour points. The idea of point-lines distance distribution (PLDD) is introduced to compute the shape energy of each pixel. Then, shape centers can be exacted from the produced PLOD map, and shape radii are obtained simultaneously based on the distance distribution of the shape center. The shape candidates are thus determined and represented with three independent characteristics: shape center, shape radius, and contour points. Finally, distinguish different types of the shape from shape candidates using shape contour points information. Compared with exiting methods, the PLDD based method detects the shapes mainly using the inherent information of edge points, such as distance, and it is simple and general. Comparative experiments both on synthetic and natural images with the state of the art also prove that the PLDD based method performs more robustly and accurately with the maximal time complexity O(n(2)) at the worst condition. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Liu, Hongmin; Wang, Zhiheng] Henan Polytech Univ, Sch Comp Sci & Tech, Jiaozuo 454000, Peoples R China.
C3 Henan Polytechnic University
RP Wang, ZH (corresponding author), Henan Polytech Univ, Sch Comp Sci & Tech, Jiaozuo 454000, Peoples R China.
EM happylhm1372@yahoo.com.cn; wzhenry@eyou.com
OI Liu, Hongmin/0000-0001-9834-4087
FU National Natural Science Foundation of China [61201395, 61272394,
   61005033]; program for Science & Technology Innovation Talents in
   Universities of Henan Province [13HASTIT039]; Program for Young Backbone
   Teachers in Universities of Henan Province [2012GGJS-057, 2013GGJS-052]
FX This work is supported by the National Natural Science Foundation of
   China (61201395, 61272394 and 61005033), the program for Science &
   Technology Innovation Talents in Universities of Henan Province
   (13HASTIT039) and the Program for Young Backbone Teachers in
   Universities of Henan Province (2012GGJS-057, 2013GGJS-052).
CR [Anonymous], P IEEE INT C INT VEH
   [Anonymous], 1992, SHAPE DETECTION COMP
   Ayala-Ramirez V, 2006, PATTERN RECOGN LETT, V27, P652, DOI 10.1016/j.patrec.2005.10.003
   Barnes N., 2005, P 5 INT C FIELD SERV, P55
   Barnes N, 2010, PATTERN RECOGN, V43, P592, DOI 10.1016/j.patcog.2009.09.008
   Baró X, 2009, IEEE T INTELL TRANSP, V10, P113, DOI 10.1109/TITS.2008.2011702
   Birbil SI, 2004, J GLOBAL OPTIM, V30, P301, DOI 10.1007/s10898-004-8270-3
   Chaudhuri D, 2010, PATTERN RECOGN LETT, V31, P818, DOI 10.1016/j.patrec.2010.01.009
   Croitoru A, 2004, PHOTOGRAMM REC, V19, P311, DOI 10.1111/j.0031-868X.2004.00289.x
   Cuevas E, 2012, INFORM SCIENCES, V182, P40, DOI 10.1016/j.ins.2010.12.024
   Davies E., 2005, MACHINE VISION THEOR, P282
   Davies E R, 2005, MACHINE VISION THEOR, P387
   Dehmeshki J, 2007, COMPUT MED IMAG GRAP, V31, P408, DOI 10.1016/j.compmedimag.2007.03.002
   Este A, 2009, COMPUT NETW, V53, P2476, DOI 10.1016/j.comnet.2009.05.003
   Ferreira A., 2003, ENCONTRO PORTUGUES C
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XW, 2006, J VIS COMMUN IMAGE R, V17, P675, DOI 10.1016/j.jvcir.2005.10.003
   Garlipp T, 2006, COMPUT STAT DATA AN, V51, P1479, DOI 10.1016/j.csda.2006.04.022
   Gates JW, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P309, DOI 10.1109/ISCAS.2000.857426
   Goulermas JY, 1998, IMAGE VISION COMPUT, V16, P615, DOI 10.1016/S0262-8856(98)00075-4
   HO CT, 1995, PATTERN RECOGN, V28, P117, DOI 10.1016/0031-3203(94)00077-Y
   Holzer S., 2009, P C COMP VIS PATT RE
   Hsu SH, 2001, IMAGE VISION COMPUT, V19, P119, DOI 10.1016/S0262-8856(00)00050-0
   Ioannou D, 1999, IMAGE VISION COMPUT, V17, P15, DOI 10.1016/S0262-8856(98)00090-0
   Jaishankar S, 2011, PROCEDIA COMPUT SCI, V4, P1306, DOI 10.1016/j.procs.2011.04.141
   Jang JH, 2001, PATTERN RECOGN, V34, P1751, DOI 10.1016/S0031-3203(00)00103-5
   Jiménez PG, 2008, SIGNAL PROCESS, V88, P2943, DOI 10.1016/j.sigpro.2008.06.019
   Khoo KG, 2002, PATTERN RECOGN LETT, V23, P1589, DOI 10.1016/S0167-8655(02)00123-X
   Kiryati N, 2000, PATTERN RECOGN LETT, V21, P1157, DOI 10.1016/S0167-8655(00)00077-5
   Laha A, 2005, PARALLEL COMPUT, V31, P290, DOI 10.1016/j.parco.2004.12.006
   Liu H. M., 2011, P 4 INT C IM SIGN PR, VProceedings of the 4thInternational Congress on Image and Signal Processing
   Liu Hong-Min, 2011, Acta Automatica Sinica, V37, P1050, DOI 10.3724/SP.J.1004.2011.01050
   Liu RJ, 2010, PATTERN RECOGN, V43, P1907, DOI 10.1016/j.patcog.2009.11.022
   Liu Y, 2007, SIGNAL PROCESS, V87, P2649, DOI 10.1016/j.sigpro.2007.04.018
   Bascón SM, 2010, COMPUT VIS IMAGE UND, V114, P373, DOI 10.1016/j.cviu.2009.12.002
   Qi H, 2010, PATTERN RECOGN, V43, P2017, DOI 10.1016/j.patcog.2010.01.007
   ROSENFEL.A, 1966, J ACM, V13, P471
   ROSIN PL, 1995, GRAPH MODEL IM PROC, V57, P483, DOI 10.1006/gmip.1995.1041
   Ruta A, 2010, PATTERN RECOGN, V43, P416, DOI 10.1016/j.patcog.2009.05.018
   Timofte Radu, 2009, WORKSH APPL COMP VIS, P1
   Torii A, 2007, PATTERN RECOGN LETT, V28, P1186, DOI 10.1016/j.patrec.2007.02.002
   Wei W, 2005, PATTERN RECOGN LETT, V26, P1483, DOI 10.1016/j.patrec.2004.10.027
   WRIGHT MW, 1995, IMAGE VISION COMPUT, V13, P367, DOI 10.1016/0262-8856(95)99723-E
   Wu G., 2007, INT C IM PROC
   Zaklouta F., 2012, ROBOT AUTON SYST, DOI [10.1016/j.robot.2012.07.019, DOI 10.1016/J.R0B0T.2012.07.019]
NR 45
TC 11
Z9 13
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 273
EP 284
DI 10.1016/j.jvcir.2013.10.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300004
DA 2024-07-18
ER

PT J
AU Möller, M
   Burger, M
   Dieterich, P
   Schwab, A
AF Moeller, Michael
   Burger, Martin
   Dieterich, Peter
   Schwab, Albrecht
TI A framework for automated cell tracking in phase contrast microscopic
   videos based on normal velocities
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cell tracking; Phase contrast microscopy; Optical flow; Active contours;
   Melanoma cells; Variational methods; Level set methods; Topology
   preservation
ID ACTIVE CONTOURS; MIGRATING CELLS; SEGMENTATION; MOVEMENTS; MOBILITY;
   FLOW
AB This paper introduces a novel framework for the automated tracking of cells, with a particular focus on the challenging situation of phase contrast microscopic videos. Our framework is based on a topology preserving variational segmentation approach applied to normal velocity components obtained from optical flow computations, which appears to yield robust tracking and automated extraction of cell trajectories. In order to obtain improved trackings of local shape features we discuss an additional correction step based on active contours and the image Laplacian which we optimize for an example class of transformed renal epithelial (MDCK-F) cells. We also test the framework for human melanoma cells and murine neutrophil granulocytes that were seeded on different types of extracellular matrices. The results are validated with manual tracking results. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Moeller, Michael; Burger, Martin] Univ Munster, Inst Numer & Angew Math, D-48149 Munster, Germany.
   [Dieterich, Peter] Tech Univ Dresden, Med Fak Carl Gustav Carus, D-01307 Dresden, Germany.
   [Schwab, Albrecht] Univ Munster, Inst Physiol 2, D-48149 Munster, Germany.
C3 University of Munster; Technische Universitat Dresden; Carl Gustav Carus
   University Hospital; University of Munster
RP Burger, M (corresponding author), Univ Munster, Inst Numer & Angew Math, Einsteinstr 62, D-48149 Munster, Germany.
EM martin.burger@uni-muenster.de
RI Burger, Martin/D-9928-2012; Dieterich, Peter/G-8495-2016
OI Burger, Martin/0000-0003-2619-2912; Dieterich, Peter/0000-0002-3564-0193
FU Grant IZKF Munster [Schw2/30/08]; Grant DFG [Schw407/9-3]; German
   Ministery for Science and Technology (BMBF) under project "Segmentation
   and Cartoon Reconstruction in Optical Nanoscopy"
FX A.S. acknowledges support form the Grants IZKF Munster Schw2/30/08 and
   DFG Schw407/9-3. M.M. and M.B. acknowledge support from the German
   Ministery for Science and Technology (BMBF) under project "Segmentation
   and Cartoon Reconstruction in Optical Nanoscopy". Furthermore, the
   authors would like to thank Christian Stock and Otto Lindemann for
   providing data sets of migration experiments with human melanoma cells
   and murine neutrophil granulocytes, respectively.
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   AMIRA, VIS IM
   Barnhart EL, 2010, BIOPHYS J, V98, P933, DOI 10.1016/j.bpj.2009.10.058
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   BASCLE B, 1994, INT C PATT RECOG, P426, DOI 10.1109/ICPR.1994.576315
   BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P1003, DOI 10.1016/0167-8655(94)90032-9
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheezum MK, 2001, BIOPHYS J, V81, P2378, DOI 10.1016/S0006-3495(01)75884-5
   Debeir O, 2005, IEEE T MED IMAGING, V24, P697, DOI 10.1109/TMI.2005.846851
   Dieterich P, 2008, P NATL ACAD SCI USA, V105, P459, DOI 10.1073/pnas.0707603105
   DZYUBACHYK O, 2008, 5 IEEE INT S BIOM IM, P185, DOI DOI 10.1109/ISBI.2008.4540963
   Dzyubachyk O, 2010, IEEE T MED IMAGING, V29, P852, DOI 10.1109/TMI.2009.2038693
   Ersoy I, 2008, IEEE IMAGE PROC, P1804, DOI 10.1109/ICIP.2008.4712127
   Fedkiw R., 2003, LEVEL SET METHODS DY
   Friedl P, 2003, NAT REV CANCER, V3, P362, DOI 10.1038/nrc1075
   GEERTS H, 1987, BIOPHYS J, V52, P775, DOI 10.1016/S0006-3495(87)83271-X
   GELLES J, 1988, NATURE, V331, P450, DOI 10.1038/331450a0
   Gupta GP, 2006, CELL, V127, P679, DOI 10.1016/j.cell.2006.11.001
   Han X, 2003, IEEE T PATTERN ANAL, V25, P755, DOI 10.1109/TPAMI.2003.1201824
   Hand AJ, 2009, J MICROSC-OXFORD, V234, P62, DOI 10.1111/j.1365-2818.2009.03144.x
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   IRANI M, 1994, INT J COMPUT VISION, V12, P5, DOI 10.1007/BF01420982
   Krähling H, 2009, PFLUG ARCH EUR J PHY, V458, P1069, DOI 10.1007/s00424-009-0694-7
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Miura K, 2005, ADV BIOCHEM ENG BIOT, V95, P267, DOI 10.1007/b102218
   Nath S., 2006, MED IMAGE COMPUT COM, V2006, P9
   Olson MF, 2009, CLIN EXP METASTAS, V26, P273, DOI 10.1007/s10585-008-9174-2
   PAPIN C, 2000, LECT NOTES COMPUTER, V1843, P428, DOI DOI 10.1007/3-540-45053-X_
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Ranchordas A., 2007, VISAPP 2007 P 2 INT, V2
   Ray N, 2002, IEEE T MED IMAGING, V21, P1222, DOI 10.1109/TMI.2002.806291
   Rose DM, 2007, IMMUNOL REV, V218, P126, DOI 10.1111/j.1600-065X.2007.00536.x
   SCHMIDT T, 1995, J PHYS CHEM-US, V99, P17662, DOI 10.1021/j100049a030
   Schwab A, 2005, J PHYSIOL-LONDON, V568, P445, DOI 10.1113/jphysiol.2005.092957
   Schwab A, 2007, PFLUG ARCH EUR J PHY, V453, P421, DOI 10.1007/s00424-006-0138-6
   Tardin C, 2003, EMBO J, V22, P4656, DOI 10.1093/emboj/cdg463
   Vallotton P, 2003, BIOPHYS J, V85, P1289, DOI 10.1016/S0006-3495(03)74564-0
   Wang XX, 2007, I S BIOMED IMAGING, P101
   Wong CHY, 2010, CARDIOVASC RES, V86, P183, DOI 10.1093/cvr/cvq040
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang B, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P476
   Zimmer C, 2006, IEEE SIGNAL PROC MAG, V23, P54, DOI 10.1109/MSP.2006.1628878
   Zimmer C, 2002, IEEE T MED IMAGING, V21, P1212, DOI 10.1109/TMI.2002.806292
NR 44
TC 16
Z9 17
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 396
EP 409
DI 10.1016/j.jvcir.2013.12.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, SH
   Pan, HR
   Zhang, CY
   Tian, YL
AF Wang, Shuihua
   Pan, Hangrong
   Zhang, Chenyang
   Tian, Yingli
TI RGB-D image-based detection of stairs, pedestrian crosswalks and traffic
   signs
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind; Visually impaired; Wayfinding and navigation; RGB-D camera;
   Object recognition; Computer vision; Portable assistance; Scene
   recognition
ID SYSTEM; AID
AB A computer vision-based wayfinding and navigation aid can improve the mobility of blind and visually impaired people to travel independently. In this paper, we develop a new framework to detect and recognize stairs, pedestrian crosswalks, and traffic signals based on RGB-D (Red, Green, Blue, and Depth) images. Since both stairs and pedestrian crosswalks are featured by a group of parallel lines, we first apply Hough transform to extract the concurrent parallel lines based on the RGB (Red, Green, and Blue) channels. Then, the Depth channel is employed to recognize pedestrian crosswalks and stairs. The detected stairs are further identified as stairs going up (upstairs) and stairs going down (downstairs). The distance between the camera and stairs is also estimated for blind users. Furthermore, the traffic signs of pedestrian crosswalks are recognized. The detection and recognition results on our collected datasets demonstrate the effectiveness and efficiency of our proposed framework. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Wang, Shuihua; Pan, Hangrong; Zhang, Chenyang; Tian, Yingli] CUNY City Coll, Dept Elect Engn, New York, NY 10016 USA.
C3 City University of New York (CUNY) System; City College of New York
   (CUNY)
RP Tian, YL (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10016 USA.
EM swang15@ccny.cuny.edu; hpan05@ccny.cuny.edu; czhang10@ccny.cuny.edu;
   ytian@ccny.cuny.edu
RI ; Wang, shuihua/G-7326-2016
OI Tian, Yingli/0000-0003-4458-360X; Wang, shuihua/0000-0003-4713-2791
FU NSF [EFRI-1137172, IIP-1343402]; FHWA [DTFH61-12-H-00002]; ARO
   [W911NF-09-1-0565]; Microsoft Research; Div Of Industrial Innovation &
   Partnersh; Directorate For Engineering [1343402] Funding Source:
   National Science Foundation
FX This work was supported in part by NSF Grants EFRI-1137172, IIP-1343402,
   FHWA DTFH61-12-H-00002, ARO Grant W911NF-09-1-0565, and Microsoft
   Research. The authors thank the anonymous reviewers for their
   constructive comments and insightful suggestions that improved the
   quality of this paper.
CR Alefs B., 2007, IEEE INT VEH S JUN
   Bousbia-Salah M, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1003
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Coughlan J.M., 2006, Proc. 2nd Workshop on Applications of Computer Vision, in conjunction with ECCV, P2
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Charette R, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P333, DOI 10.1109/IROS.2009.5353941
   Everingham MR, 2003, INT J HUM-COMPUT INT, V15, P231, DOI 10.1207/S15327590IJHC1502_3
   Ivanchenko V, 2008, LECT NOTES COMPUT SC, V5105, P1122, DOI 10.1007/978-3-540-70540-6_168
   Kao G., 1996, TECHNICAL REPORT
   Kim HY, 2007, LECT NOTES COMPUT SC, V4872, P100
   Kuc R, 2002, IEEE T BIO-MED ENG, V49, P1173, DOI 10.1109/TBME.2002.803561
   Laurent B, 2007, INT J PHYS SCI, V2, P104
   Lausser L., 2008, ADV COMPUTATIONAL IN
   Lee Y., 2012, ICPR
   Lu X., 2005, ICRA
   Morland C., 2008, 14 INT C AUD DISPL J
   Omachi M, 2010, INT CONF SIGN PROCES, P809, DOI 10.1109/ICOSP.2010.5655932
   Omachi M, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P284, DOI 10.1109/ICCSIT.2009.5234518
   Pallejà T, 2010, SENSORS-BASEL, V10, P11322, DOI 10.3390/s101211322
   Radvanyi M, 2010, 2010 12 INT WORKSHOP, DOI [10.1109/cnna.2010.5430281, DOI 10.1109/CNNA.2010.5430281]
   Se S, 2000, PROC CVPR IEEE, P211, DOI 10.1109/CVPR.2000.854787
   Se Stephen., 2000, P 4 AS C COMP VIS AC, V1, P535
   Shoval S, 2001, INT SER COMPUTAT INT, P413
   Tian Y., 2010, 12 INT C COMP HELP P
   Tian YL, 2013, MACH VISION APPL, V24, P521, DOI 10.1007/s00138-012-0431-7
   Uddin M., 2005, P 2005 IEEE COMP SOC
   Wang S., 2009, INFORM COMMUNICATION
   Wang S., 2011, IT WORKSH BIOM HLTH
   Wang S., 2012, INT WORKSH BIOM HLTH
   Wang S, 2012, J COMPUT VISION IMAG, V2
   Yang X, 2010, INT C ACM MULT
   Yi CC, 2012, IEEE T IMAGE PROCESS, V21, P4256, DOI 10.1109/TIP.2012.2199327
NR 32
TC 105
Z9 113
U1 2
U2 43
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 263
EP 272
DI 10.1016/j.jvcir.2013.11.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300003
DA 2024-07-18
ER

PT J
AU Li, P
   Yang, CN
   Wu, CC
   Kong, Q
   Ma, YP
AF Li, Peng
   Yang, Ching-Nung
   Wu, Chih-Cheng
   Kong, Qian
   Ma, Yanpeng
TI Essential secret image sharing scheme with different importance of
   shadows
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Secret sharing; Secret image sharing; Essential shadow image; Lagrange's
   interpolation; Information hiding; Visual cryptography; Visual secret
   sharing; Image processing
ID STEGANOGRAPHY; AUTHENTICATION; IMPROVEMENTS
AB In (k, n) secret image sharing (SIS), a scheme encrypts a secret image into n shadow images. Any k or more shadow images can be collaborated together to reveal the secret image. Most of the previous SIS schemes don't distinguish the importance of shadows. However, in some application environments, some participants are accorded special privileges due to their status or importance. Thus, some shadows may be more important than others. In this paper, we consider the (t, s, k, n) essential SIS (ESIS) scheme. All n shadows are classified into s essential shadows and (n-s) non-essential shadows. When reconstructing the secret image, the (t, s, k, n)-ESIS scheme needs k shadows, which should include at least t essential shadows. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Li, Peng; Kong, Qian; Ma, Yanpeng] North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei, Peoples R China.
   [Yang, Ching-Nung; Wu, Chih-Cheng] Natl Dong Hwa Univ, Dept CSIE, Taipei, Taiwan.
C3 North China Electric Power University; National Dong Hwa University
RP Li, P (corresponding author), North China Elect Power Univ, Dept Math & Phys, Baoding 071003, Hebei, Peoples R China.
EM lphit@163.com
RI Kong, Qina/KFS-6817-2024; Jiang, Cheng/JHU-0179-2023; Li,
   Peng/D-7073-2012; Yang, Ching-Nung/HKV-1639-2023
OI Yang, Ching-Nung/0000-0002-3881-7329
FU Fundamental Research Funds for the Central Universities [13MS107]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (No. 13MS107). Thanks for the anonymous reviewers'
   constructive comments and suggestions.
CR Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen CC, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3268362
   Elsheh E, 2010, LECT NOTES COMPUT SC, V6419, P169
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Lin SJ, 2009, OPT ENG, V48, DOI 10.1117/1.3168644
   Rey A.M., 2008, LNCS, V5197, P635
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2009, LECT NOTES COMPUT SC, V5414, P988, DOI 10.1007/978-3-540-92957-4_86
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wu CC, 2011, J SYST SOFTWARE, V84, P2196, DOI 10.1016/j.jss.2011.06.021
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2012, OPT COMMUN, V285, P1725, DOI 10.1016/j.optcom.2011.12.003
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, IMAGE VISION COMPUT, V28, P1600, DOI 10.1016/j.imavis.2010.04.003
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
   Yang CN, 2011, VISUAL CRYPTOGRAPHY
NR 19
TC 77
Z9 78
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 1106
EP 1114
DI 10.1016/j.jvcir.2013.07.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700034
DA 2024-07-18
ER

PT J
AU Kang, JW
   Lou, CC
   Kim, SH
   Kuo, CCJ
AF Kang, Je-Won
   Lou, Chung-Cheng
   Kim, Seung-Hwan
   Kuo, C. -C. Jay
TI Efficient HD video coding with joint first-order-residual (FOR) and
   second-order-residual (SOR) coding technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE HD video; Video coding; HD video coding; Coding residual processing;
   H.264/AVC and FOR/SOR
ID TRANSFORMS
AB A new video coding algorithm called the first-order-residual/second-order-residual (FOR/SOR) codec is proposed for high definition (HD) video coding in this work. Several advanced coding techniques are adopted in the proposed FOR/SOR codec. For the FOR codec, the well known block-based motion compensated predictive codec is used to exploit temporal and spatial correlations in input image frames. However, it is observed that there still exists structured residual signal after the FOR coding, and a SOR coder is developed to encode residual image frames efficiently. To improve the coding performance furthermore, we consider bit allocation between the FOR and SOR coders at the same block and determine their optimal quantization parameters systematically. It is shown by experimental results that the proposed FOR/SOR codec outperforms H.264/AVC significantly in HD video coding. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Kang, Je-Won; Lou, Chung-Cheng; Kim, Seung-Hwan; Kuo, C. -C. Jay] Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Kang, JW (corresponding author), Univ So Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
EM jewonkan@usc.edu
RI Kang, Jewon/AAU-9722-2020; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
CR [Anonymous], 2006, VCEGAC07
   [Anonymous], 2010, JCTVCC405
   [Anonymous], 2011, JCTVCG399
   [Anonymous], 2010, Q6SG16 ITUT
   Bjontegaard G., 2001, ITU-T Q.6/16, Doc. VCEG-M33
   Boyd S., 2004, CONVEX OPTIMIZATION
   Chang CL, 2010, IEEE T IMAGE PROCESS, V19, P1740, DOI 10.1109/TIP.2010.2044964
   Dai Yunyang, 2008, P ICIP OCT
   Dong J, 2009, IEEE T CIRC SYST VID, V19, P1462, DOI 10.1109/TCSVT.2009.2026792
   Kim S. H., 2011, P ICASSP MAY
   Li S., 2009, P PICT COD S PCS MAY
   Ma S., 2007, P SPIE VISUAL COMMUN
   Naito S., 2006, P SPIE C VISUAL COMM
   Tao B, 2001, IEEE T IMAGE PROCESS, V10, P24, DOI 10.1109/83.892440
   Ye Yan, 2008, P ICIP OCT
   Zeng B, 2008, IEEE T CIRC SYST VID, V18, P305, DOI 10.1109/TCSVT.2008.918455
NR 16
TC 3
Z9 5
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2013
VL 24
IS 1
BP 1
EP 11
DI 10.1016/j.jvcir.2012.10.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 077BT
UT WOS:000314003600001
DA 2024-07-18
ER

PT J
AU Bas, E
   Erdogmus, D
   Draft, RW
   Lichtman, JW
AF Bas, E.
   Erdogmus, D.
   Draft, R. W.
   Lichtman, J. W.
TI Local tracing of curvilinear structures in volumetric color images:
   Application to the Brainbow analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Volumetric color images; Piecewise linear cylinder model; Principal
   curve; Brainbow; Axon tracing; Connectivity analysis; Topological
   skeleton; Ridge analysis
ID TUBULAR STRUCTURES; CORONARY-ARTERIES; MEAN SHIFT; NEURONS;
   SEGMENTATION; ALGORITHMS; RECONSTRUCTION; EXTRACTION; MODEL; AXONS
AB In this study, we compare two vectorial tracing methods for 3D color images: (i) a conventional piecewise linear generalized cylinder algorithm that uses color and edge information and (ii) a principal curve tracing algorithm that uses the gradient and Hessian of a given density estimate. We tested the algorithms on synthetic and Brainbow dataset to show the effectiveness of the proposed algorithms. Results indicate that the proposed methods can successfully trace multiple axons in dense neighborhoods. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Bas, E.; Erdogmus, D.] Northeastern Univ, Dept Elect & Comp Engn, Dana Res Ctr 409, Boston, MA 02148 USA.
   [Draft, R. W.; Lichtman, J. W.] Harvard Univ, Dept Mol & Cellular Biol, Cambridge, MA 02138 USA.
   [Draft, R. W.; Lichtman, J. W.] Harvard Univ, Ctr Brain Sci, Cambridge, MA 02138 USA.
C3 Northeastern University; Harvard University; Harvard University
RP Bas, E (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Dana Res Ctr 409, 360 Huntington Ave, Boston, MA 02148 USA.
EM bas@ece.neu.edu; erdogmus@ece.neu.edu; draft@fas.harvard.edu;
   jeff@mcb.harvard.edu
FU NSF Grant [IIS-0914808, BCS-1027724, IIS-1149570]
FX E.B. and D.E. acknowledge support by the NSF Grant IIS-0914808,
   BCS-1027724, IIS-1149570. The authors thank Dana Brooks and William Bosl
   for valuable discussions.
CR Al-Kofahi KA, 2003, IEEE T INF TECHNOL B, V7, P302, DOI 10.1109/TITB.2003.816564
   Al-Kofahi KA, 2002, IEEE T INF TECHNOL B, V6, P171, DOI 10.1109/TITB.2002.1006304
   Alley R.E., 1996, ALGORITHM THEORETICA
   [Anonymous], 1998, DENSITY ESTIMATION S, DOI DOI 10.1201/9781315140919
   [Anonymous], 4 IEEE INT S BIOM IM
   [Anonymous], EUR S ART NEUR NETW
   Ascher U. M., 1998, Computer methods for ordinary differential equations and differential-algebraic equations, V61, DOI DOI 10.1137/1.9781611971392
   Ascoli GA, 2007, J NEUROSCI, V27, P9247, DOI 10.1523/JNEUROSCI.2055-07.2007
   Aykac D, 2003, IEEE T MED IMAGING, V22, P940, DOI 10.1109/TMI.2003.815905
   Bauer R., 2000, J GUIDANCE CONTROL D
   Cai HM, 2006, NEUROIMAGE, V32, P1608, DOI 10.1016/j.neuroimage.2006.05.036
   Cai HM, 2008, MED IMAGE ANAL, V12, P666, DOI 10.1016/j.media.2008.03.002
   Cherkassky BV, 1996, MATH PROGRAM, V73, P129, DOI 10.1007/BF02592101
   COHEN AR, 1994, J MICROSC-OXFORD, V173, P103, DOI 10.1111/j.1365-2818.1994.tb03433.x
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deschamps T, 2001, MED IMAGE ANAL, V5, P281, DOI 10.1016/S1361-8415(01)00046-9
   Eberly D., 1996, RIDGES IMAGE DATA AN
   Feng GP, 2000, NEURON, V28, P41, DOI 10.1016/S0896-6273(00)00084-2
   FLETCHER R, 1963, COMPUT J, V6, P163, DOI 10.1093/comjnl/6.2.163
   Frangi AF, 1999, IEEE T MED IMAGING, V18, P946, DOI 10.1109/42.811279
   González G, 2010, PROC CVPR IEEE, P2799, DOI 10.1109/CVPR.2010.5540010
   Hampel S., 2011, NATURE METHODS
   HASTIE T, 1989, J AM STAT ASSOC, V84, P502, DOI 10.2307/2289936
   Kasthuri N, 2003, NATURE, V424, P426, DOI 10.1038/nature01836
   Kégl B, 2000, IEEE T PATTERN ANAL, V22, P281, DOI 10.1109/34.841759
   KITAMURA K, 1988, IEEE T MED IMAGING, V7, P173, DOI 10.1109/42.7779
   La Cruz A, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P393, DOI 10.1109/VISUAL.2004.72
   LEE HC, 1991, IEEE T SIGNAL PROCES, V39, P1181, DOI 10.1109/78.80971
   LEE TC, 1994, CVGIP-GRAPH MODEL IM, V56, P462, DOI 10.1006/cgip.1994.1042
   Lesage D, 2008, I S BIOMED IMAGING, P268, DOI 10.1109/ISBI.2008.4540984
   Lichtman JW, 2008, NAT REV NEUROSCI, V9, P417, DOI 10.1038/nrn2391
   Livet J, 2007, NATURE, V450, P56, DOI 10.1038/nature06293
   Lu J, 2011, NEUROINFORMATICS, V9, P159, DOI 10.1007/s12021-011-9101-6
   Meijering E, 2004, CYTOM PART A, V58A, P167, DOI 10.1002/cyto.a.20022
   Meijering E, 2010, CYTOM PART A, V77A, P693, DOI 10.1002/cyto.a.20895
   MIKAEL R, 2003, 4984 INRIA
   Miller J., 1998, THESIS U NC
   Nain D, 2004, LECT NOTES COMPUT SC, V3216, P51
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Ozertem U, 2011, J MACH LEARN RES, V12, P1249
   Palagyi K, 1998, PATTERN RECOGN LETT, V19, P613, DOI 10.1016/S0167-8655(98)00031-2
   Peng H., 2010, NATURE BIOTECHNOLOGY
   Santamaría-Pang A, 2007, LECT NOTES COMPUT SC, V4792, P486
   Sato Y, 1998, Med Image Anal, V2, P143, DOI 10.1016/S1361-8415(98)80009-1
   Schmitt S, 2004, NEUROIMAGE, V23, P1283, DOI 10.1016/j.neuroimage.2004.06.047
   Streekstra GJ, 2002, NETWORK-COMP NEURAL, V13, P381, DOI 10.1088/0954-898X/13/3/308
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tyrrell JA, 2007, IEEE T MED IMAGING, V26, P223, DOI 10.1109/TMI.2006.889722
   Vasilkoski Z, 2009, J NEUROSCI METH, V178, P197, DOI 10.1016/j.jneumeth.2008.11.008
   Waltz RA, 2006, MATH PROGRAM, V107, P391, DOI 10.1007/s10107-004-0560-5
   Wang J, 2007, I S BIOMED IMAGING, P81, DOI 10.1109/ISBI.2007.356793
   Wink O, 2004, IEEE T MED IMAGING, V23, P130, DOI 10.1109/TMI.2003.819920
   Zhang Y, 2008, NEURAL COMPUT, V20, P1899, DOI 10.1162/neco.2008.05-07-519
   Zhou WG, 2008, LECT NOTES COMPUT SC, V5242, P18, DOI 10.1007/978-3-540-85990-1_3
   Zhu X., P ISBI 09
NR 56
TC 7
Z9 9
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2012
VL 23
IS 8
BP 1260
EP 1271
DI 10.1016/j.jvcir.2012.09.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 040NT
UT WOS:000311330300009
DA 2024-07-18
ER

PT J
AU Michael, GKO
   Connie, T
   Teoh, ABJ
AF Michael, Goh Kah Ong
   Connie, Tee
   Teoh, Andrew Beng Jin
TI A contactless biometric system using multiple hand features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Contactless biometrics; Multimodal biometrics; Image processing; Hand
   vein recognition; Palm print recognition; Hand geometry recognition;
   Knuckle print recognition; Image quality assessment scheme
ID PALMPRINT; GEOMETRY; FUSION; IMAGE; PRINT
AB With the advent of modern computing technology, there is increased reliance on biometrics to provide stronger personal authentication. Among the variety of biometric solutions in the market, hand-based system is the oldest, and perhaps the most successful form of biometric technology. This paper describes a contactless hand-based biometric system by using visible and infrared imagery. An acquisition device is developed to capture both color and infrared hand images. We modify an ordinary web camera to capture the hand vein that normally requires specialized infrared sensor. The design is simple and low-cost. No additional installation of special apparatus is required. The device can capture the epidermal and subcutaneous features from the hand simultaneously. In specific, five features namely hand geometry, palm print, palmar knuckle print, palm vein, and finger vein are acquired from the hand for recognition. Rigorous experiments had been performed to testify the robustness of the system. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Michael, Goh Kah Ong; Connie, Tee] Multimedia Univ, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Coll Engn, Sch Elect & Elect Engn, Seoul 120749, South Korea.
   [Teoh, Andrew Beng Jin] Sunway Univ, Bandar Sunway 46150, Pj Selangor, Malaysia.
C3 Multimedia University; Yonsei University; Sunway University
RP Connie, T (corresponding author), Multimedia Univ, Jalan Ayer Keroh Lama 75450, Melaka, Malaysia.
EM michael.goh@mmu.edu.my; tee.connie@mmu.edu.my; bjteoh@yonsei.ac.kr
RI ; Teoh, Andrew Beng Jin/F-4422-2010; Goh, Kah Ong Michael/F-8404-2012
OI Tee, Connie/0000-0002-0901-3831; Teoh, Andrew Beng
   Jin/0000-0001-5063-9484; Goh, Kah Ong Michael/0000-0002-9217-6390
CR Amayeh G, 2009, COMPUT VIS IMAGE UND, V113, P477, DOI 10.1016/j.cviu.2008.11.007
   [Anonymous], 2009, CARD TECHNOL TODAY, V21, P8
   [Anonymous], WORK C SMART RES ADV
   [Anonymous], 2003, BIOMETRIC TECHNOLOGY, V11, P9, DOI DOI 10.1016/S0969-4765(03)07018-8
   [Anonymous], 2004, BIOMETRIC TECHNOL TO, V12, P6
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cross JM, 1995, 29TH ANNUAL 1995 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P20, DOI 10.1109/CCST.1995.524729
   Doublet J., 2007, First IEEE International Conference on Biometrics: Theory, Applications, and Systems, BTAS 2007, P1, DOI DOI 10.1109/BTAS.2007.4401935
   Goh M., 2003, ACM SIGMM 2003 Multimedia Biometrics Methods and Applications Workshop, P100
   Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237
   González S, 2003, 37TH ANNUAL 2003 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P281
   Han CC, 2004, IMAGE VISION COMPUT, V22, P909, DOI 10.1016/j.imavis.2004.05.008
   Hao Y, 2007, LECT NOTES COMPUT SC, V4844, P12
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He MX, 2010, PATTERN RECOGN, V43, P1789, DOI 10.1016/j.patcog.2009.11.018
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   Kumar A, 2003, LECT NOTES COMPUT SC, V2688, P668
   Li W, 2010, PROC CVPR IEEE, P795, DOI 10.1109/CVPR.2010.5540134
   Lin CL, 2004, IEEE T CIRC SYST VID, V14, P199, DOI 10.1109/TCSVT.2003.821975
   Matsumoto T, 2002, P SOC PHOTO-OPT INS, V4677, P275, DOI 10.1117/12.462719
   Michael GKO, 2010, I C CONT AUTOMAT ROB, P1268, DOI 10.1109/ICARCV.2010.5707951
   Morales A., 2008, EUR C SIGN PROC
   Nanni L, 2009, NEURAL COMPUT APPL, V18, P87, DOI 10.1007/s00521-007-0160-4
   Qiang Li, 2005, Advances in Biometrics. International Conference, ICB 2006. Proceedings (Lecture Notes in Computer Science Vol.3832), P744
   Ravikanth C., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Ribaric S, 2005, IEEE T PATTERN ANAL, V27, P1698, DOI 10.1109/TPAMI.2005.209
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Saviv T, 2007, PATTERN RECOGN, V40, P3152, DOI 10.1016/j.patcog.2007.03.005
   Toh KA, 2006, LECT NOTES COMPUT SC, V3832, P546
   Ulery B., 2006, Studies of biometric fusion
   Verlinde P., 1999, A Contribution to Multi-Modal Identity Verification Using Decision Fusion
   Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021
   Wang KJ, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P1790
   Wang L, 2007, IET COMPUT VIS, V1, P113, DOI 10.1049/iet-cvi:20070009
   Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805
   Yang F, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P247, DOI 10.1109/AUTOID.2007.380628
   Yörük E, 2006, IMAGE VISION COMPUT, V24, P483, DOI 10.1016/j.imavis.2006.01.020
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2010, PATTERN RECOGN, V43, P358, DOI 10.1016/j.patcog.2009.04.026
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
   Zheng G, 2007, IEEE T INF FOREN SEC, V2, P758, DOI 10.1109/TIFS.2007.908239
   Zhu LQ, 2010, PATTERN RECOGN LETT, V31, P1641, DOI 10.1016/j.patrec.2010.05.010
NR 44
TC 41
Z9 51
U1 1
U2 65
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1068
EP 1084
DI 10.1016/j.jvcir.2012.07.004
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900011
DA 2024-07-18
ER

PT J
AU Sun, YC
   Tsai, CJ
AF Sun, Yu-Chen
   Tsai, Chun-Jen
TI Perceptual-based distributed video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Distributed video coding; Perceptual-based coding; Wyner-Ziv coding;
   Region-of-interest analysis; Motion consistency analysis; Texture
   consistency analysis; Visual distortion estimation; Side-information
   error classification
ID SIDE INFORMATION; CODES
AB In this paper, we propose a perceptual-based distributed video coding (DVC) technique. Unlike traditional video codecs, DVC applies video prediction process at the decoder side using previously received frames. The predicted video frames (i.e., side information) contain prediction errors. The encoder then transmits error-correcting parity bits to the decoder to reconstruct the video frames from side information. However, channel codes based on i.i.d. noise models are not always efficient in correcting video prediction errors. In addition, some of the prediction errors do not cause perceptible visual distortions. From perceptual coding point of view, there is no need to correct such errors. This paper proposes a scheme for the decoder to perform perceptual quality analysis on the predicted side information. The decoder only requests parity bits to correct visually sensitive errors. More importantly, with the proposed technique, key frames can be encoded at higher rates while still maintaining consistent visual quality across the video sequence. As a result, even the objective PSNR measure of the decoded video sequence will increase too. Experimental results show that the proposed technique improves the R-D performance of a transform domain DVC codec both subjectively and objectively. Comparisons with a well-known DVC codec show that the proposed perceptual-based DVC coding scheme is very promising for distributed video coding framework. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Sun, Yu-Chen; Tsai, Chun-Jen] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, CJ (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
EM cjtsai@cs.nctu.edu.tw
RI Sun, Yuchen/JZD-1692-2024
CR Aaron A, 2002, IEEE DATA COMPR CONF, P252, DOI 10.1109/DCC.2002.999963
   AARON A, 2004, P VIS COMM IM PROC S
   Aaron A., 2005, P AS C SIGN SYST, V1
   Areia J.D., 2008, P 50 INT S ELMAR
   Artigas X., 2007, P PICT COD S LISB PO
   Ascenso J, 2008, J VIS COMMUN IMAGE R, V19, P600, DOI 10.1016/j.jvcir.2008.06.001
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bjontegaard G., 2008, 35 VCEG M JUL
   Brites C., 2007, P INT C IM PROC SAN
   Chiang J.-C., 2010, P INT S CIRC SYST PA
   Chiou B.-R., 2010, P 18 ACM INT C MULT
   Dikici C., 2009, SPIE EL IM VIS COMM
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Hua G., 2008, P INT C MULT EXP HAN
   Huang X, 2009, P IEEE INT C AC SPEE
   Kubasov D, 2007, P INT WORKSH MULT SI
   Li Z, 2007, IEEE T IMAGE PROCESS, V16, P98, DOI 10.1109/TIP.2006.884934
   Liu L., 2009, IEEE T CIRC SYST VID, V19
   Martins R, 2010, IET IMAGE PROCESS, V4, P28, DOI 10.1049/iet-ipr.2008.0133
   Mys J. Slowack. S., 2009, P PICT COD S CHIC IL
   Pai YS, 2012, J VIS COMMUN IMAGE R, V23, P63, DOI 10.1016/j.jvcir.2011.08.004
   Puri R, 2003, P INT C IM PROC BARC
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2010, SIGNAL PROCESS-IMAGE, V25, P660, DOI 10.1016/j.image.2010.06.002
   Sofke S, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/978581
   Song H.S., 2002, P VIS COMM IM PROC U
   Sun Y.-C., 2008, P INT S MULT WIR CRE
   Sun Y.-C., 2009, P PICT COD S CHIC IL
   Toto-Zarasoa V., 2010, P INT C IM PROC HONG
   Varodayan D, 2008, SIGNAL PROCESS-IMAGE, V23, P369, DOI 10.1016/j.image.2008.04.009
   Varodayan D, 2006, SIGNAL PROCESS, V86, P3123, DOI 10.1016/j.sigpro.2006.03.012
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 35
TC 4
Z9 4
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 535
EP 548
DI 10.1016/j.jvcir.2012.01.015
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800012
DA 2024-07-18
ER

PT J
AU Gómez, S
   Naranjo, V
   Miralles, R
AF Gomez, Soledad
   Naranjo, Valery
   Miralles, Ramon
TI Removing interference components in time-frequency representations using
   morphological operators
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Time-frequency representations; Morphological image processing;
   Elimination of cross-components; Underwater signal processing;
   Non-stationary signals; Wigner-Ville transform; Geodesic operator;
   Morphologic operator
AB Time-frequency representations have been of great interest in the analysis and classification of non-stationary signals. The use of highly selective transformation techniques is a valuable tool for obtaining accurate information for studies of this type. The Wigner-Ville distribution has high time and frequency selectivity in addition to meeting some interesting mathematical properties. However, due to the bi-linearity of the transform, interference terms emerge when the transform is applied over multi-component signals. In this paper, we propose a technique to remove cross-components from the Wigner-Ville transform using image processing algorithms. The proposed method exploits the advantages of non-linear morphological filters, using a spectrogram to obtain an adequate marker for the morphological processing of the Wigner-Ville transform. Unlike traditional smoothing techniques, this algorithm provides cross-term attenuations While preserving time-frequency resolutions. Moreover, it could also be applied to distributions with different interference geometries. The method has been applied to a set of different time-frequency transforms, with promising results. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Gomez, Soledad; Miralles, Ramon] Univ Politecn Valencia, iTEAM, Dpto Comunicac, Valencia 46022, Spain.
   [Naranjo, Valery] Univ Politecn Valencia, Inst Bioingn & Tecnol Orientada Ser Humano, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP Miralles, R (corresponding author), Univ Politecn Valencia, iTEAM, Dpto Comunicac, Camino Vera S-N, Valencia 46022, Spain.
EM sogogar@upvnet.upv.es; vnaranjo@dcom.upv.es; rmiralle@dcom.upv.es
RI Miralles, Ramon R/B-2213-2008
OI Miralles-Ricos, Ramon/0000-0003-0039-2553; Naranjo,
   Valery/0000-0002-0181-3412
FU National R&D Program (Spain) [TEC2008-02975]; FEDER; Generalitat
   Valenciana [CMAP 340]
FX This work was supported by the National R&D Program under Grant
   TEC2008-02975 (Spain), FEDER programme and Generalitat Valenciana CMAP
   340.
CR Auger F., 1996, TIME FREQUENCY TOOLB
   BARANIUK RG, 1993, SIGNAL PROCESS, V32, P263, DOI 10.1016/0165-1684(93)90001-Q
   Borda M, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1901677
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P276
   COHEN L, 1989, P IEEE, V77, P941, DOI 10.1109/5.30749
   FLANDRIN P, 1984, IEEE INT C ICASSP 84, V9, P266
   Flandrin Patrick, 1993, Temps-frequence (traite des nouvelles technologies, serie traitement du signal)
   GOMEZ S, 2007, P 19 INT C ACOUST MA
   Hlawatsch F, 1992, IEEE SIGNAL PROC MAG, V9, P21, DOI 10.1109/79.127284
   HLAWATSCH F, 1997, INTERFERENCE STRUCTU
   JANSSEN AJEM, 1985, IEEE T ACOUST SPEECH, V33, P1029, DOI 10.1109/TASSP.1985.1164622
   JI LA, 1992, IEEE T PATTERN ANAL, V14, P653, DOI 10.1109/34.141555
   JONES D, 1989, IEEE T ACOUST SPEECH, P2231
   JONES DL, 1995, IEEE T SIGNAL PROCES, V43, P2361, DOI 10.1109/78.469854
   Li T, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P243
   LIU W, 2004, P 4 IASTED INT C VIS
   Meyer F, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P47
   NARANJO V, 2004, P 4 IASTED INT C VIS
   Pachori RB, 2007, DIGIT SIGNAL PROCESS, V17, P466, DOI 10.1016/j.dsp.2006.10.004
   PACHORI RB, 2006, DIG SIGN PROC WORKSH, V4, P423
   PACHORI RB, 2008, P IEEE TENC C HYD IN
   SCHUSTER A, 2003, TERRESTRIAL MAGNETIS, V3, P13
   SERRA J, 1993, P SPIE IM ALG MATH M
   Serra J., 1988, IMAGE ANAL MATH MORP
   Serra J., 1988, IMAGE ANAL MATH MORP
   Soille P., 2002, Morphological Image Analysis: Principles and Applications, Vsecond
   Tagluk ME, 1997, P ANN INT IEEE EMBS, V19, P1320, DOI 10.1109/IEMBS.1997.756619
NR 27
TC 13
Z9 15
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2011
VL 22
IS 5
BP 401
EP 410
DI 10.1016/j.jvcir.2011.03.007
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 776ER
UT WOS:000291517800004
OA Green Published
DA 2024-07-18
ER

PT J
AU Lin, YB
   Han, MC
   Zheng, JH
   Zheng, XZ
   Lai, CC
   Zhang, P
AF Lin, Yongbing
   Han, Mingchen
   Zheng, Jianhua
   Zheng, Xiaozhen
   Lai, Changcai
   Zhang, Philipp
TI Improved motion vector scaling technique based on half-pixel offset
   compensation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion vector scaling; Half-pixel offset compensation; Motion vector
   predictor; Multipicture motion-compensated prediction; Interlaced
   sequence; Temporal distance; Motion vector derivation; Field picture
   coding
ID STANDARD
AB It is observed that there exists a half-pixel offset in vertical direction between top and bottom fields in interlaced sequence, and this half-pixel offset has an impact on performing motion vector scaling in multipicture motion-compensated prediction. However, the impact caused by this half-pixel offset is processed inconsiderately during motion vector derivation in the up-to-date video coding standards, where temporal motion vector predictor usually derives its forward or backward motion vector by performing motion vector scaling based on temporal distance. In this paper, an improved motion vector scaling technique is proposed to compensate the impact caused by the half-pixel offset between top and bottom fields. Motion vector scaling is performed on corresponding coordinates which represent the position relationship between top and bottom fields properly. Experimental results show that the proposed motion vector scaling technique improves coding efficiency for interlaced sequence, especially for bi-predictive pictures. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Lin, Yongbing; Han, Mingchen; Zheng, Jianhua; Zheng, Xiaozhen; Lai, Changcai; Zhang, Philipp] Hisilicon Technol Co Ltd, Res Dept, Beijing 100085, Peoples R China.
RP Lin, YB (corresponding author), Hisilicon Technol Co Ltd, Res Dept, Beijing 100085, Peoples R China.
EM yblin@huawei.com
CR [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2001, 13 VCEG M AUST TEX U
   [Anonymous], 138182 ISOIEC
   *AVS, AVS REF SOFTW
   *AVS P2, 2008, N1484R1 AVSP2
   *AVS P2, 2006, 2009022006 AVSP2 GBT
   *AVS VID WORKGR, 2007, 22 AVS M BEIJ CHIN S
   *ITU T, 2005, H264 ITUT
   Ji XY, 2008, SIGNAL PROCESS-IMAGE, V23, P31, DOI 10.1016/j.image.2007.10.003
   JI XY, 2004, IEEE INT C IM PROC I
   TAN T, 2008, 35 VCEG M BERL GERM
   Tourapis AM, 2005, IEEE T CIRC SYST VID, V15, P119, DOI 10.1109/TCSVT.2004.837021
   Wiegand T, 1999, IEEE T CIRC SYST VID, V9, P70, DOI 10.1109/76.744276
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   H 264 REFERENCE SOFT
NR 15
TC 0
Z9 0
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 865
EP 870
DI 10.1016/j.jvcir.2010.07.003
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500010
DA 2024-07-18
ER

PT J
AU Ellouze, M
   Boujemaa, N
   Alimi, AM
AF Ellouze, Mehdi
   Boujemaa, Nozha
   Alimi, Adel M.
TI IM(S)<SUP>2</SUP>: Interactive movie summarization system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video analysis; Video summarization; Users preferences; Interactive
   multimedia system; Content analysis; Pattern recognition; Genetic
   algorithm; One-class SVM
ID RETRIEVAL; IMAGE
AB The need of summarization methods and systems has become more and more crucial as the audio-visual material continues its critical growth. This paper presents a novel vision and a novel system for movies summarization. A video summary is an audio-visual document displaying the essential parts of an original document. However, the definition of the term "essential" is user-dependent. The advantage of this work, unlike the others, is the involvement of users in the summarization process. By means of IM(S)(2), people generate on the fly customized video summaries responding to their preferences. IM(S)(2) is made up of an offline part and an online part. In the offline, we segment the movies into shots and we compute features describing them. In the online part users inform about their preferences by selecting interesting shots. After that, the system will analyze the selected shots to bring out the user's preferences. Finally the system will generate a summary from the whole movie which will provide more focus on the user's preferences. To show the efficiency of IM(S)(2), it was tested on the database of the European project MUSCLE made up of five movies. We invited 10 users to evaluate the usability of our system by generating for every movie of the database a semi-supervised summary and to judge at the end its quality. Obtained results are encouraging and show the merits of our approach. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Ellouze, Mehdi; Alimi, Adel M.] Univ Sfax, ENIS, REGIM Res Grp Intelligent Machines, Sfax 3038, Tunisia.
   [Boujemaa, Nozha] INRIA IMEDIA Team, F-78153 Le Chesnay, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Ellouze, M (corresponding author), Univ Sfax, ENIS, REGIM Res Grp Intelligent Machines, BP 1173, Sfax 3038, Tunisia.
EM Mehdi.Ellouze@ieee.org; Nozha.Boujemaa@inria.fr; Adel.Alimi@ieee.org
RI Alimi, Adel M./A-5697-2012
OI Alimi, Adel M./0000-0002-0642-3384
FU General Direction of Scientific Research and Technological Renovation
   (DGRSRT), Tunisia [01/UR/11/02]; EGIDE; INRIA, France
FX The authors would like to thank several individuals and groups for
   making the implementation of this system possible. The authors would
   like to acknowledge the financial support of this work by grants from
   the General Direction of Scientific Research and Technological
   Renovation (DGRSRT), Tunisia, under the ARUB program 01/UR/11/02. We are
   also grateful, to EGIDE and INRIA, France, for sponsoring this work and
   the three-month research placement of Mehdi Ellouze from 1/11/2007 to
   31/1/2008 in INRIA IMEDIA Team in which parts of this work were done. We
   are also grateful to the European project MUSCLE and to Prof.
   Constantine Kotropoulos from Aristotle University of Thessaloniki for
   providing the data.
CR AGNIHOT L, 2003, P IEEE INT C MULT EX, P757
   [Anonymous], P WORKSH MULT INF RE
   Assfalg J, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P825, DOI 10.1109/ICME.2002.1035909
   BENAMMAR A, 2002, P EUR C IR RES, P124
   BENAMMAR A, 2004, P EUR C INF SYST
   Bezdek James C., 1981, PATTERN RECOGN
   BOUJEMAA N, 2001, P INT WORKSH MULT RO
   CASILLAS A, 2003, P INT C TEXT SPEECH, P43
   ELLOUZE M, MULTIMEDIA IN PRESS, DOI DOI 10.1007/S11042-009-0325-5
   ELLOUZE M, 2008, P INT C ACM MULT TRE, P105
   FERECATU M, 2005, THESIS U VESRSAILLES
   Ferecatu M, 2008, MULTIMEDIA SYST, V13, P309, DOI 10.1007/s00530-007-0094-9
   Ferman AM, 2003, IEEE T MULTIMEDIA, V5, P244, DOI 10.1109/TMM.2003.811617
   Furini M, 2007, P 6 ACM INT C IM VID, P635
   Furini M, 2006, CONSUM COMM NETWORK, P1209
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   HANJALIC A, 1999, P INT C VIS INF SYST, P229
   KARRAY H, 2009, INDEXING VIDEO SUMMA, P77
   KARRAY H, 2008, INT J INFORM COMMUNI, V1, P69
   KARRAY H, 2008, REGIM TRECVID2008 HI
   KHERALLAH M, 2008, P INT C PATT REC FLO, P1
   LEINHART R, 1997, COMMUNICATION AC DEC, P55
   Li BX, 2002, P SOC PHOTO-OPT INS, V4676, P202
   Lie WN, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P413, DOI 10.1109/ICME.2008.4607459
   Lu S., 2003, P 9 INT C DISTRIBUTE, P456
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Manevitz LM, 2002, J MACH LEARN RES, V2, P139, DOI 10.1162/15324430260185574
   Marcu D, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P137, DOI 10.1145/312624.312668
   MILLS M, 1992, P CHI 92, P93
   MONEY AG, 2007, J VISUAL COMMUNICATI, P121
   Omoigui N., 1999, P SIGCHI C HUMAN FAC, P136
   PARSHIN V, 2004, P C RECH INF ASS ORD
   Peker KA, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2055, DOI 10.1109/ICME.2004.1394669
   Petkovic M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P817, DOI 10.1109/ICME.2002.1035907
   Pfeiffer S, 1996, J VIS COMMUN IMAGE R, V7, P345, DOI 10.1006/jvci.1996.0030
   PONCELEON D, 1999, P 7 ACM INT C MULT O, P199
   SADLIER D, 2005, J IEEE T CIRCUITS SY, P1225
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   SMEATON AF, 2006, P ACM INT WORKSH MUL, P231
   Smith MA, 1997, PROC CVPR IEEE, P775, DOI 10.1109/CVPR.1997.609414
   Taniguchi Y, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P427
   Taniguchi Y., 1995, MULTIMEDIA 95 P 3 AC, P25
   TOKLU C, 2000, P IEEE INT C MULT EX, P268
   *TRECVID, 2003, TREC VID RETR EV
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tsoneva T, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P169, DOI 10.1109/ICSC.2007.42
   TSVETOMIRA T, 2007, THESIS U EINDHOVEN
   Uchihashi S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P383, DOI 10.1145/319463.319654
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   ZHUANG Y, 1998, P IEEE INT C IM PROC, P73
   LIBSVM 2 0
NR 53
TC 19
Z9 21
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 283
EP 294
DI 10.1016/j.jvcir.2010.01.007
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800002
DA 2024-07-18
ER

PT J
AU Yang, CH
   Lin, YC
AF Yang, Cheng-Hsing
   Lin, Yi-Cheng
TI Fractal curves to improve the reversible data embedding for VQ-indexes
   based on locally adaptive coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data embedding; Reversible embedding; Lossless embedding; Vector
   quantization; Fractal curve; Locally adaptive coding; Image compression;
   Index residual value coding
ID SIDE MATCH; COMPRESSION; RECOVERY; TABLE
AB The VQ reversible data embedding technology allows an original VQ coding to be completely restored after the extraction of embedded data. In this paper, we propose a new reversible scheme based on locally adaptive coding for VQ-compressed images. The fractal Hilbert curve is applied to replace the traditional trace of processing the VQ index table. The VQ index table is pre-processed to create a fractal Hilbert curve. Following the curve to process the VQ index table can get better compression rates in the data embedding procedure. Besides, compared to Chang et al.'s scheme, which compressed the inputted VQ index value only when the to-be-embedded bit b is 0, our method performs compressing operations in both cases that the to-be-embedded bits b are 0 and 1. The experimental results show that the proposed method has the best compression rate and the highest embedding capacity compared with other reversible VQ embedding methods. (C) 2010 Elsevier Inc. All rights reserved.
C1 [Yang, Cheng-Hsing; Lin, Yi-Cheng] Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 900, Taiwan.
C3 National Pingtung University
RP Yang, CH (corresponding author), Natl Pingtung Univ Educ, Dept Comp Sci, Pingtung 900, Taiwan.
EM chyang@mail.npue.edu.tw
FU National Science Council of the Republic of China [NSC
   98-2221-E-153-001]
FX This research was supported by the National Science Council of the
   Republic of China under the Grants NSC 98-2221-E-153-001.
CR [Anonymous], 2000, Digital Watermarking
   BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang C.C., 1997, P 1997 C COMP VIS GR, P93
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J SYST SOFTWARE, V82, P516, DOI 10.1016/j.jss.2008.08.024
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Chen WJ, 2009, DIGIT SIGNAL PROCESS, V19, P433, DOI 10.1016/j.dsp.2008.11.003
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   DAVIS RM, 1978, NBS SPECIAL PUBLICAT
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   Johnson N.F., 1998, IEEE Transactions on Image Processing., V31, P26, DOI [DOI 10.1109/MC.1998.4655281, 10.1109/MC.1998.4655281]
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lin CC, 2009, INFORM SCIENCES, V179, P140, DOI 10.1016/j.ins.2008.09.001
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Wu MN, 2008, J SYST SOFTWARE, V81, P1505, DOI 10.1016/j.jss.2007.09.017
   Wu YG, 2008, IMAGE VISION COMPUT, V26, P1171, DOI 10.1016/j.imavis.2008.02.007
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   Yu YH, 2005, PATTERN RECOGN, V38, P691, DOI 10.1016/j.patcog.2004.11.006
NR 20
TC 37
Z9 37
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2010
VL 21
IS 4
BP 334
EP 342
DI 10.1016/j.jvcir.2010.02.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 602TX
UT WOS:000278162800006
DA 2024-07-18
ER

PT J
AU Wang, X
   Guo, FX
   Xiao, B
   Ma, JF
AF Wang, Xuan
   Guo, Fang-xia
   Xiao, Bin
   Ma, Jian-feng
TI Rotation invariant analysis and orientation estimation method for
   texture classification based on Radon transform and correlation analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Correlation analysis; Radon transform; Rotation invariance; Texture
   analysis; Orientation estimation
ID GRAY-SCALE
AB Some recent rotation invariant texture analysis approaches such as multiresolution approaches yield high correct classification percentages, but present insufficient noise tolerance. This paper describes a new method for rotation invariant texture analysis. In the proposed method, Radon transform is utilized to project a texture image onto projection space to convert a rotation of the original texture image to a translation of the projection in the angle variable, and then Radon projection correlation distance is introduced. A k-nearest neighbors' classifier with Radon projection correlation distances is employed to implement texture classification and orientation estimation. Theoretical and experimental results show the high classification accuracy of this approach as a result of using the Radon projection correlation distance instead of repetitious usage of discrete transforms. It is also shown that the proposed method presents high noise tolerance and yields high accuracy in orientation estimation in comparison with Khouzani's method. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Wang, Xuan; Guo, Fang-xia; Xiao, Bin] Shaanxi Normal Univ, Sch Phys & Informat Technol, Xian 710062, Peoples R China.
   [Wang, Xuan; Ma, Jian-feng] Xidian Univ, Key Lab, Minist Educ Comp Networks & Informat Secur, Xian 710071, Peoples R China.
C3 Shaanxi Normal University; Xidian University
RP Wang, X (corresponding author), Shaanxi Normal Univ, Sch Phys & Informat Technol, Xian 710062, Peoples R China.
EM wxuan@snnu.edu.cn
RI Xiao, Bin/E-2722-2012; Ma, Jianfeng/GZB-0110-2022
FU Natural Science Foundation of Shaanxi Province, China [2009JM8003];
   National Natural Science Foundation of China [90204012]; National
   High-Tech Research and Development Plan of China [2002AA143021]
FX This work was supported by the Natural Science Foundation of Shaanxi
   Province, China under Grant Nos. 2009JM8003; the National Natural
   Science Foundation of China under Grant Nos. 90204012; the National
   High-Tech Research and Development Plan of China under Grant Nos.
   2002AA143021.
CR Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1976, DOI 10.1016/j.patrec.2006.05.008
   Arivazhagan S, 2006, PATTERN RECOGN LETT, V27, P1875, DOI 10.1016/j.patrec.2006.04.013
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   HALEY GM, 1994, P IEEE ICIP 95, P262
   Jafari-Khouzani K, 2005, IEEE T IMAGE PROCESS, V14, P783, DOI 10.1109/TIP.2005.847302
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   Li ST, 2005, PATTERN RECOGN LETT, V26, P633, DOI 10.1016/j.patrec.2004.09.013
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Muneeswaran K, 2005, PATTERN RECOGN, V38, P1495, DOI 10.1016/j.patcog.2005.03.021
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan W, 2008, SIGNAL PROCESS, V88, P189, DOI 10.1016/j.sigpro.2007.07.019
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Sengur A, 2007, EXPERT SYST APPL, V32, P527, DOI 10.1016/j.eswa.2005.12.013
   Wang X, 2007, PATTERN RECOGN, V40, P3503, DOI 10.1016/j.patcog.2007.04.020
   Xiao SS, 2006, J PHYS CONF SER, V48, P1459, DOI 10.1088/1742-6596/48/1/268
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
NR 18
TC 10
Z9 11
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2010
VL 21
IS 1
BP 29
EP 32
DI 10.1016/j.jvcir.2009.09.010
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 548MD
UT WOS:000273966200004
DA 2024-07-18
ER

PT J
AU Lizier, MAS
   Martins, DC
   Cuadros-Vargas, AJ
   Roberto, M
   Nonato, LG
AF Lizier, Mario A. S.
   Martins, David C., Jr.
   Cuadros-Vargas, Alex J.
   Cesar, Roberto M., Jr.
   Nonato, Luis G.
TI Generating segmented meshes from textured color images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mesh generation; Delaunay triangulation; Feature evaluation and
   selection; Texture classification; W-operators; Texture segmentation;
   Imesh image; Mesh modeling; Mesh generation from image data; Mesh
   segmentation
AB This paper presents a new framework for generating triangular meshes from textured color images. The proposed framework combines a texture classification technique, called W-operator, with Imesh, a method originally conceived to generate simplicial meshes from gray scale images. An extension of W-operators to handle textured color images is proposed, which employs a combination of RGB and HSV channels and Sequential Floating Forward Search guided by mean conditional entropy criterion to extract features from the training data. The W-operator is built into the local error estimation used by Imesh to choose the mesh vertices. Furthermore, the W-operator also enables to assign a label to the triangles during the mesh construction, thus allowing to obtain a segmented mesh at the end of the process. The presented results show that the combination of W-operators with Imesh gives rise to a texture classification-based triangle mesh generation framework that outperforms pixel based methods. Crown Copyright (C) 2009 Published by Elsevier Inc. All rights reserved.
C1 [Lizier, Mario A. S.; Cuadros-Vargas, Alex J.; Nonato, Luis G.] Univ Sao Paulo, ICMC, BR-13560970 Sao Carlos, SP, Brazil.
   [Martins, David C., Jr.; Cesar, Roberto M., Jr.] Univ Sao Paulo, IME, BR-05508090 Sao Paulo, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo
RP Lizier, MAS (corresponding author), Univ Sao Paulo, ICMC, Av Trab Sao Carlense 400,POB 668, BR-13560970 Sao Carlos, SP, Brazil.
EM lizier@icmc.usp.br
RI Lizier, Mario/G-1572-2012; Nonato, Luis Gustavo/D-5782-2011; Martins-Jr,
   David/G-2271-2012; Cesar-Jr, Roberto/C-4120-2012
OI Lizier, Mario/0000-0001-9123-5822; Martins-Jr,
   David/0000-0003-0398-8328; Cesar-Jr, Roberto/0000-0003-2701-4288;
   Cuadros-Vargas, Alex Jesus/0000-0001-7358-9002
FU FAPESP [2008/03349-6]; CNPq; CAPES
FX The authors are grateful to FAPESP (grant #2008/03349-6), CNPq and CAPES
   for financial support. The test images have been obtained from [31].
CR [Anonymous], 1992, Computing in Euclidean geometry, DOI DOI 10.1142/9789814355858_0006
   Berti G, 2004, ECCOMAS EUR C COMP M
   Bertin E, 1994, COMP IMAG VIS, V2, P209
   CEBRAL J.R., 1999, PROC 8 IMR, P321
   Ciampalini A, 1997, VISUAL COMPUT, V13, P228, DOI 10.1007/s003710050101
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   COLEMAN S, 2005, IEEE ICIP, P1342
   Cuadros-Vargas AJ, 2009, J MATH IMAGING VIS, V33, P11, DOI 10.1007/s10851-008-0105-2
   Dougherty ER, 2002, J MATH IMAGING VIS, V16, P181, DOI 10.1023/A:1020325626071
   Dougherty ER, 2001, J MATH IMAGING VIS, V14, P53, DOI 10.1023/A:1008311431244
   GARCIA MA, 1999, IEEE INT C IM PROC K, P168
   Garland M., 1995, CMUCS95181, P1
   Gevers T, 1997, PROC CVPR IEEE, P1021, DOI 10.1109/CVPR.1997.609455
   Guillaume L, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P10, DOI 10.1109/CGI.2004.1309187
   HALE D, 2001, 10 INT MESH ROUNDT, P185
   Hermes L, 2003, IEEE T IMAGE PROCESS, V12, P1243, DOI 10.1109/TIP.2003.817240
   HUANG CL, 1994, IEEE T CIRC SYST VID, V4, P42, DOI 10.1109/76.276171
   Kachouie NN, 2003, IEEE SYS MAN CYBERN, P2897
   Kocharoen P, 2005, IEEE ICC, P2052
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martins DC, 2006, PATTERN ANAL APPL, V9, P139, DOI 10.1007/s10044-006-0031-0
   PEDRINI H, 2001, WSCG 2001, P5
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   RUPPERT J, 1995, J ALGORITHM, V18, P548, DOI 10.1006/jagm.1995.1021
   SHEWCHUK J, 2000, CA94720 DEP EL ENG C
   Shewchuk JR, 2002, COMP GEOM-THEOR APPL, V22, P21, DOI 10.1016/S0925-7721(01)00047-5
   TERZOPOULOS D, 1991, IEEE INT C COMP VIS, P70
   Yan ZD, 2005, IEEE T CIRC SYST VID, V15, P138, DOI 10.1109/TCSVT.2004.837023
   Yang YY, 2003, IEEE T IMAGE PROCESS, V12, P866, DOI 10.1109/TIP.2003.812757
   Zhang H., 2005, PROC C VISION MODELI, P429
   Zhang Y., 2003, Proceedings of the eighth ACM symposium on Solid modeling and applications, SM '03, P286
NR 31
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2009
VL 20
IS 3
BP 190
EP 203
DI 10.1016/j.jvcir.2009.01.002
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 424VD
UT WOS:000264595500003
DA 2024-07-18
ER

PT J
AU Zou, W
   Li, Y
   Yuan, K
   Xu, D
AF Zou, Wei
   Li, Yuan
   Yuan, Kui
   Xu, De
TI Real-time elliptical head contour detection under arbitrary pose and
   wide distance range
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Elliptical head contour; Quadrant arc; Real time; Arbitrary head pose;
   Wide distance range; Gradient; Ellipse fitting; Robust
ID RANDOMIZED HOUGH TRANSFORM; TRACKING; IMAGES; FACE
AB In this paper, we propose a real time elliptical head contour detection method based on quadrant arcs, which is efficient and robust to arbitrary head pose and wide distance range. First, the moving object area is detected according to background model which is built on three color channels. Then, all the valid elliptical arcs are extracted out from connected edges, and classified into four kinds of quadrant arc sets according to their gradient information. Finally, the arcs lying in different sets are combined to fit out the elliptical head contour based on the least square method. Experimental results confirm the robustness and the accuracy of this method under arbitrary head pose and wider distance range, as well as the real time property, strong robustness to long or short hair and with or without hat. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Zou, Wei; Li, Yuan; Yuan, Kui; Xu, De] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Zou, W (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
EM wei.zou@mail.ia.ac.cn
FU National Natural Science Foundation of PRC [60705026, 60805038]; PRC
   [2006AA04Z258, 2006AA040202]
FX This work was supported in part by National Natural Science Foundation
   of PRC under Grant Nos. 60705026 and 60805038; also supported by
   National High Technology Development 863 Program of PRC under Grant Nos.
   2006AA04Z258 and 2006AA040202.
CR Barth A, 2005, LECT NOTES COMPUT SC, V3663, P442
   BENTZVI D, 1990, PATTERN RECOGN LETT, V11, P167, DOI 10.1016/0167-8655(90)90002-J
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   CHEN ML, 2005, P 2 CAN C COMP ROB V
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Grammalidis N, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P221, DOI 10.1109/CGI.2000.852337
   GUIDO A, 1997, P IEEE INT S IND EL, V3, P767
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Huang WM, 2002, 2002 IEEE REGION 10 CONFERENCE ON COMPUTERS, COMMUNICATIONS, CONTROL AND POWER ENGINEERING, VOLS I-III, PROCEEDINGS, P507, DOI 10.1109/TENCON.2002.1181324
   Kiriki T, 1999, RO-MAN'99: 8TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTION, P195, DOI 10.1109/ROMAN.1999.900339
   Leavers V. F., 1989, P 5 ALV VIS C READ U, P163
   LEAVERS VF, 1992, CVGIP-IMAG UNDERSTAN, V56, P381, DOI 10.1016/1049-9660(92)90049-9
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   Lu W, 2008, PATTERN RECOGN, V41, P1268, DOI 10.1016/j.patcog.2007.09.006
   McLaughlin RA, 1998, PATTERN RECOGN LETT, V19, P299, DOI 10.1016/S0167-8655(98)00010-5
   Niyogi S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P374, DOI 10.1109/AFGR.1996.557294
   Qiao Y, 2007, PATTERN RECOGN, V40, P1990, DOI 10.1016/j.patcog.2006.10.009
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YANG T, 2004, P 5 WORLD C INT CONT, P1910
   Yao ZR, 2006, IMAGE VISION COMPUT, V24, P573, DOI 10.1016/j.imavis.2005.09.007
   YOO JH, 1993, PATTERN RECOGN, V26, P307, DOI 10.1016/0031-3203(93)90039-Y
   YUEN HK, 1989, IMAGE VISION COMPUT, V7, P31, DOI 10.1016/0262-8856(89)90017-6
   Zhang SC, 2005, PATTERN RECOGN, V38, P273, DOI 10.1016/j.patcog.2004.03.014
NR 24
TC 8
Z9 11
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2009
VL 20
IS 3
BP 217
EP 228
DI 10.1016/j.jvcir.2009.01.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 424VD
UT WOS:000264595500005
DA 2024-07-18
ER

PT J
AU Aptoula, E
   Lefèvre, S
AF Aptoula, E.
   Lefevre, S.
TI α-Trimmed lexicographical extrema for pseudo-morphological image
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE multivariate mathematical morphology; vector ordering; vectorial
   processing; colour morphology
ID COLOR; CLASSIFICATION; OPERATORS
AB The extension of mathematical morphology to colour, and more generally to multivariate image data, continues to be an open problem. As its underlying theory is defined in terms of complete lattices, the main challenge lies in introducing a complete lattice structure on the image intensity range, hence vectorial extrema computation methods are necessary. In this paper, we circumvent the need for a multivariate ordering, and propose a method for directly computing the multivariate extrema of vector sets. To this end the alpha-trimming principle is employed in combination with lexicographical ordering. The resulting pseudo-morphological operators, although deprived of important properties, present the advantage of a "collective" calculation, taking into account the distribution of vectors within the structuring element. They are tested against state of the art methodologies in applications treating noise reduction and texture classification, where they are shown to exhibit superior performances. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Aptoula, E.; Lefevre, S.] ULP, CNRS, LSIIT, UMR 7005, F-67412 Illkirch Graffenstaden, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universites de
   Strasbourg Etablissements Associes; Universite de Strasbourg
RP Aptoula, E (corresponding author), ULP, CNRS, LSIIT, UMR 7005, Pole API,Blvd Sebastien Brant,POB 10413, F-67412 Illkirch Graffenstaden, France.
EM aptoula@lsiit.u-strasbg.fr
RI Lefevre, Sebastien/S-9444-2017; Aptoula, Erchan/AAI-1070-2020
OI Lefevre, Sebastien/0000-0002-2384-8202; Aptoula,
   Erchan/0000-0001-6168-2883
CR ANGULO J, 2005, P 7 ISMM COMP IM VIS, V30
   APTOULA E, PATTERN RECOGNITION
   BARNETT V, 1976, J ROY STAT SOC A STA, V139, P318, DOI 10.2307/2344839
   Birkhoff G., 1967, Lattice Theory, V3rd
   GOUTSIAS J, 1995, COMPUT VIS IMAGE UND, V62, P326, DOI 10.1006/cviu.1995.1058
   Hanbury A., 2002, IMAGE ANAL STEREOL, V21, P201, DOI DOI 10.5566/IAS.V21.P201-206
   HANBURY A, 2003, INT C IM PROC ITS AP
   Hanbury AG, 2001, IEEE T IMAGE PROCESS, V10, P1842, DOI 10.1109/83.974569
   LEZORAY O, 2005, P IEEE INT S SIGN PR
   Louverdis G, 2002, PATTERN RECOGN, V35, P1733, DOI 10.1016/S0031-3203(01)00166-2
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   Nowak A, 1999, EUR PHYS J A, V6, P1
   OJALA T, 2002, P 16 ICPR QUEB CAN, V1
   Ortiz F, 2001, P SOC PHOTO-OPT INS, V4572, P259, DOI 10.1117/12.444190
   Öten R, 2004, IEEE T IMAGE PROCESS, V13, P627, DOI 10.1109/TIP.2003.821115
   Plaza A, 2004, PATTERN RECOGN, V37, P1097, DOI 10.1016/j.patcog.2004.01.006
   RONSE C, 1990, SIGNAL PROCESS, V21, P129, DOI 10.1016/0165-1684(90)90046-2
   Serra J., 1993, MATH MORPHOLOGY IMAG, P483
NR 18
TC 23
Z9 28
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2008
VL 19
IS 3
BP 165
EP 174
DI 10.1016/j.jvcir.2007.10.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 290FT
UT WOS:000255109400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, YQ
   Rajan, D
   Chia, LT
AF Hu, Yiqun
   Rajan, Deepu
   Chia, Liang-Tien
TI Detection of visual attention regions in images using robust subspace
   analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE visual attention; subspace analysis; saliency; GPCA; scale-space;
   clustering; least square estimation
ID FEATURE COMBINATION STRATEGIES; SALIENCY; SCALE; OBJECTS; MODEL
AB In this paper, we describe a new framework to extract visual attention regions in images using robust subspace estimation and analysis techniques. We use simple features like hue and intensity endowed with scale adaptivity in order to represent smooth and textured areas in an image. A polar transformation maps homogeneity in the features into a linear subspace that also encodes spatial information of a region. A new subspace estimation algorithm based on the Generalized Principal Component Analysis (GPCA) is proposed to estimate multiple linear subspaces. Sensitivity to outliers is achieved by weighted least squares estimate of the subspaces in which weights calculated from the distribution of K nearest neighbors are assigned to data points. Iterative refinement of the weights is proposed to handle the issue of estimation bias when the number of data points in each subspace is very different. A new region attention measure is defined to calculate the visual attention of each region by considering both feature contrast and spatial geometric properties of the regions. Compared with existing visual attention detection methods, the proposed method directly measures global visual attention at the region level as opposed to pixel level. (c) 2007 Elsevier Inc. All rights reserved.
C1 [Hu, Yiqun; Rajan, Deepu; Chia, Liang-Tien] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Rajan, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Block N4,Nanyang Ave, Singapore 639798, Singapore.
EM asdrajan@ntu.edu.sg
RI Rajan, Deepu/A-3666-2011; Chia, Liang-Tien/A-9874-2008
CR [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   Bamidele A, 2004, BT TECHNOL J, V22, P151, DOI 10.1023/B:BTTJ.0000047129.83260.79
   BONET JSD, 1997, SIGGRAPH 97, P361
   Bormans J, 2003, IEEE SIGNAL PROC MAG, V20, P53, DOI 10.1109/MSP.2003.1184339
   Bradley AP, 2003, J VIS COMMUN IMAGE R, V14, P232, DOI 10.1016/S1047-3203(03)00037-3
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Duncan J, 1998, PHILOS T ROY SOC B, V353, P1307, DOI 10.1098/rstb.1998.0285
   Fu H, 2006, PATTERN RECOGN, V39, P1604, DOI 10.1016/j.patcog.2005.12.015
   Hu Y., 2004, P 12 ANN ACM INT C M, P340
   Hu Y., 2005, Proceedings of the ACM International Conference on Multimedia, P716
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Itti L, 1999, P SOC PHOTO-OPT INS, V3644, P473, DOI 10.1117/12.348467
   Kadir T, 2004, LECT NOTES COMPUT SC, V3021, P228
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   KE Q, 2004, P 2004 IEEE COMP SOC, V2, P592
   KOVESI P, J COMPUTER VISION, V1
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1477, DOI 10.1109/ICME.2006.262821
   Liu Hao., 2003, P ACM INT C MULTIMED, P148
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez-Baena J, 1997, PATTERN RECOGN LETT, V18, P1453, DOI 10.1016/S0167-8655(97)00133-5
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Rodriguez-Sánchez R, 1999, IEEE T PATTERN ANAL, V21, P1044, DOI 10.1109/34.799910
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   SANTELLA DDD, 2006, P ACM HUM FACT COMP, P771
   Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9
   Shao L, 2007, INFORM SCIENCES, V177, P1088, DOI 10.1016/j.ins.2006.09.003
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Sun YR, 2003, ARTIF INTELL, V146, P77, DOI 10.1016/S0004-3702(02)00399-5
   Toyama K, 1996, PROC CVPR IEEE, P189, DOI 10.1109/CVPR.1996.517073
   Vidal R, 2003, PROC CVPR IEEE, P621
   Vidal R., 2003, THESIS U CALIFORNIA
   Vu K, 2003, IEEE T KNOWL DATA EN, V15, P1045, DOI 10.1109/TKDE.2003.1209021
   Walther D, 2005, COMPUT VIS IMAGE UND, V100, P41, DOI 10.1016/j.cviu.2004.09.004
   Yang M, 2007, PROC CVPR IEEE, P1590, DOI 10.1109/CVPR.2007.383178
NR 37
TC 9
Z9 10
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2008
VL 19
IS 3
BP 199
EP 216
DI 10.1016/j.jvcir.2007.11.001
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 290FT
UT WOS:000255109400005
DA 2024-07-18
ER

PT J
AU Lie, WN
   Tseng, CH
   Lin, TCI
   Tseng, MY
   Ting, IC
AF Lie, Wen-Nung
   Tseng, Cheng-Hsiung
   Lin, Tom C. I.
   Tseng, Ming-Yang
   Ting, I-Cheng
TI Rate-distortion-smoothness optimized rate allocation schemes for
   Spectral Fine Granular Scalable video coding technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Proceedings Paper
CT IEEE International Conference on Multimedia and Expo (ICME)
CY JUN 27-30, 2004
CL Taipei, TAIWAN
SP IEEE
DE video streaming; MPEG-4 FGS; Fine Granular Scalability; scalable video
   coding; rate control; dynamic programming
ID SCALABILITY; FGS
AB Spectral Fine Granular Scalability (SFGS), a variation of MPEG-4 FGS, is proposed in this paper as a scalable coding technique for video streaming. SFGS re-arranges enhancement-layer bit-plane data according to spectral frequency orderings before they are further processed with traditional FGS bit-plane coding technique. Based on this data reordering within each bit-plane, spectral bands of lower frequency or higher rate-distortion properties are transmitted with priorities. In spite of this modification, SFGS retains similar properties as FGS, such as the coding efficiency, error resilience, and adaptation to channel bandwidth variation. However, SFGS is promising in yielding evener image quality and smoother video perception at the receiver side when the channel bandwidth is limited. Traditional FGS rate control techniques lack a systematic approach to making tradeoffs between image quality, motion smoothness (i.e., the frame rate), and video smoothness (PSNR difference between consecutive frames), according to limitations on system resources and users' preferences. In view of this drawback, we propose here a unified rate allocation scheme, based on rate-distortion-smoothness optimization criterion and multi-stage dynamic programming (DP) technique, to solve the above problems. Experiments show that our algorithm is capable of achieving a smoother video quality, and simultaneously guaranteeing no buffer overflow and underflow at encoder/decoder, under a target bit-rate constraint. Though our proposed algorithm was designed for SFGS, it can be also applied to other FGS variations. (C) 2005 Elsevier Inc. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
   Chung Shan Inst Sci & Technol, Mat & Electroopt Res Div, Tao Yuan 325, Taiwan.
   Inst Informat Ind, Network & Multimedia Inst, Taipei, Taiwan.
C3 National Chung Cheng University; Chung-Shan Institute of Science &
   Technology
RP Lie, WN (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
EM wnlie@ee.ccu.edu.tw
RI Lie, Wen-Nung/AFP-1266-2022
CR [Anonymous], 1978, Fundamentals of Computer Algorithms
   Cheng H, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P41
   Huang HC, 2002, IEEE T CIRC SYST VID, V12, P372, DOI 10.1109/TCSVT.2002.800314
   Hung BF, 2003, IEEE J SEL AREA COMM, V21, P1595, DOI 10.1109/JSAC.2003.815229
   Lee SH, 2002, IEEE T CONSUM ELECTR, V48, P444, DOI 10.1109/TCE.2002.1037026
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Lie WN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1747, DOI 10.1109/ICME.2004.1394592
   Lie WN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P655, DOI 10.1109/ICME.2004.1394277
   Lie WN, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, P880
   Rajendran RK, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL I, PROCEEDINGS, P445
   TSENG MY, 2002, THESIS NATL CHUNG CH
   van der Schaar M, 2002, IEEE T CIRC SYST VID, V12, P360, DOI 10.1109/TCSVT.2002.800319
   van der Schaar M, 2001, IEEE T CIRC SYST VID, V11, P318, DOI 10.1109/76.911158
   Wang Q, 2002, IEEE SIGNAL PROC LET, V9, P33, DOI 10.1109/97.991132
   Wu F, 2001, IEEE T CIRC SYST VID, V11, P332, DOI 10.1109/76.911159
   WU F, 2001, P IEEE INT S CIRC SY, P97
   Zhang XM, 2003, IEEE T CIRC SYST VID, V13, P121, DOI 10.1109/TCSVT.2002.808437
   Zhao LF, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL IV, PROCEEDINGS, P544
   Zhou J, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P361
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2006
VL 17
IS 4
BP 799
EP 829
DI 10.1016/j.jvcir.2005.04.003
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science
GA 105JZ
UT WOS:000242027500008
DA 2024-07-18
ER

PT J
AU Shih, FY
   Wu, YT
AF Shih, FY
   Wu, YT
TI Enhancement of image watermark retrieval based on genetic algorithms
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
AB A watermark hidden in an image is retrieved differently from the original watermark due to the frequently used rounding approach. The simple rounding will cause numerous errors in the embedded watermark especially when it is large. A novel technique based on genetic algorithms (GAs) is presented in this paper to correct the rounding errors. The fundamental is to adopt a fitness function for choosing the best chromosome which determines the conversion rule of real numbers into integers during the cosine transformation. Experimental results show that the dramatic improvement in reducing the errors is successful when GAs are used in decision making. Furthermore, we develop an initial chromosome by comparing the difference between the original image and the rounded watermarked image to speed up the process. In additional to correct fragile-watermarking rounding errors, our algorithm can also be applied in robust watermarking to achieve higher watermarked image quality. (c) 2004 Elsevier Inc. All rights reserved.
C1 New Jersey Inst Technol, Coll Comp Sci, Comp Vis Lab, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP New Jersey Inst Technol, Coll Comp Sci, Comp Vis Lab, Newark, NJ 07102 USA.
EM shih@njit.edu
RI Wang, Xiaojing/HNI-4384-2023
OI Wang, Xiaojing/0000-0001-6921-3619
CR Bas P, 2002, PATTERN RECOGN, V35, P545, DOI 10.1016/S0031-3203(01)00059-0
   Berghel H, 1996, COMPUTER, V29, P101, DOI 10.1109/2.511977
   Bruyndonckx O., 1995, PROC IEEE WORKSHOP N, P456
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Herrera F., 1994, FUZZY SYSTEMS ARTIFI, V3, P39
   Ho SY, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1567
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Tang KS, 1998, IEEE T IND ELECTRON, V45, P162, DOI 10.1109/41.661317
   Wong PW, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P455, DOI 10.1109/ICIP.1998.723526
NR 14
TC 58
Z9 62
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2005
VL 16
IS 2
BP 115
EP 133
DI 10.1016/j.jvcir.2004.05.002
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 915VY
UT WOS:000228340700001
DA 2024-07-18
ER

PT J
AU Hasimoto-Beltrán, R
   Baqai, S
   Khokhar, A
AF Hasimoto-Beltrán, R
   Baqai, S
   Khokhar, A
TI Transform domain inter-block interleaving schemes for robust image and
   video transmission in ATM networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
AB Data interleaving schemes have proven to be an important mechanism in reducing the impact of correlated network errors on image/video transmission. Current interleaving schemes fall into two main categories: (a) schemes that interleave pixel intensity values and (b) schemes that interleave JPEG/MPEG transform blocks. The schemes in the first category suffer in terms of lower compression ratio since highly correlated information in the spatial domain is de-correlated prior to compression. The schemes in the second category interleave DCT transformed blocks. In this case, in the absence of ARQ, if a packet is lost, an entire block may be lost thus yielding poor image quality and making the error concealment task difficult. Interleaving transform coefficients is tricky and error concealment in the presence of lost coefficients is challenging. In this paper, we develop three different interleaving schemes, namely Triangular, Quadrant, and Coefficient, that interleave frequency domain transform coefficients. The transform coefficients within each block are divided into small groups and groups are interleaved with the groups from other blocks in the image, hence they are referred to as inter-block interleaving schemes. The proposed schemes differ in terms of group size. In the Triangular interleaving scheme AC coefficients in each block are divided into two triangles and interleaving is performed among triangles from different blocks. In the Quadrant interleaving scheme, coefficients in each block are divided into four quadrants and quadrants are interleaved. In the Coefficient interleaving scheme, each coefficient in a block is a group and it is interleaved with the coefficients in other blocks. The compression ratio 3 of the proposed interleaving schemes is impressive ranging from 90 to 98% of the JPEG standard compression while providing much higher robustness in the presence of correlated losses. We also propose two new variable end-of-block (VEOB) techniques, one based on the number of AC coefficients per block (VAC-EOB) and the other based on the number of bits per block (VB-EOB). Our proposed interleaving techniques combined with VEOB schemes yield significantly better compression ratios compared to JPEG (2-11%) and MPEG-2 (3-6.7%) standards while at the same time improve the resilience of the coded data in the presence of transmission errors. (C) 2003 Elsevier Inc. All rights reserved.
C1 Univ Illinois, Dept CS, Chicago, IL 60607 USA.
   Univ Illinois, Dept ECE, Chicago, IL 60607 USA.
   Ctr Res Math, Guanajuato, Gto, Mexico.
   Lahore Univ Management Sci, Lahore, Pakistan.
C3 University of Illinois System; University of Illinois Chicago;
   University of Illinois Chicago Hospital; University of Illinois System;
   University of Illinois Chicago; University of Illinois Chicago Hospital;
   Lahore University of Management Sciences
RP Univ Illinois, Dept CS, 851 S Morgan St, Chicago, IL 60607 USA.
EM ashfaq@ece.uic.edu
OI Hasimoto-Beltran, Rogelio/0000-0001-7640-3576
CR ANCIS M, 2000, IEEE PACK VID WORKSH
   [Anonymous], 1996, Techniques and standards for image, video, and audio coding
   [Anonymous], 109181 ISOIEC IS
   Bolot J.-C., 1993, Journal of High Speed Networks, V2, P305
   CHIN SK, 2000, IEEE PACK VID WORKSH
   CHUNG YJ, 1998, P IEEE INT S CIRC SY, V6, P518
   CIDON I, 1993, IEEE T INFORM THEORY, V39, P98, DOI 10.1109/18.179347
   DEBRUNNER V, 1999, ISCAS 99, V4, P1314
   *ISO IEC JTC 1 SC, 1995, GEN COD MOV PICT A 2
   KINOSHITA T, 1993, IEEE T CIRC SYST VID, P3
   LEE VHL, 1995, DRUG TARG D, V4, P3
   LIANG YJ, 2002, P AS C SIGN SYST COM
   LLADOS RB, 1998, THESIS U NOTRE DAME
   Nelson M.A., 1992, The Data Compression Book
   POSNAK EJ, 1995, P MULT COMP NETW FEB, P243
   REDMILL DW, 1996, IEEE T IMAGE PROCESS, V5
   Rosdiana E, 2001, SIGNAL PROCESS-IMAGE, V16, P733, DOI 10.1016/S0923-5965(01)00004-2
   TOM AS, 1991, INT CONF ACOUST SPEE, P2857, DOI 10.1109/ICASSP.1991.150998
   TURNER C, 1992, COMPUT COMMUN REV, V22
   Varsa V., 2000, IEEE PACK VID WORKSH
   WEN J, 1999, P IEEE INT C IM PROC, V2
   Zhu QF, 1993, IEEE T CIRC SYST VID, V3, P248, DOI 10.1109/76.224235
   ZHU W, 1998, IEEE T CIRCUITS SYST, P8
NR 23
TC 5
Z9 5
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2004
VL 15
IS 4
BP 522
EP 547
DI 10.1016/j.jvcir.2003.11.001
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 868OZ
UT WOS:000224924200003
DA 2024-07-18
ER

PT J
AU Antani, S
   Lee, DJ
   Long, LR
   Thoma, GR
AF Antani, S
   Lee, DJ
   Long, LR
   Thoma, GR
TI Evaluation of shape similarity measurement methods for spine X-ray
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE content-based image retrieval; medical image databases; shape
   representation; performance evaluation
ID CONTENT-BASED RETRIEVAL; PATTERN-RECOGNITION; REPRESENTATION; MULTISCALE
AB Efficient content-based image retrieval (CBIR) of biomedical images is a challenging problem. Feature representation algorithms used in indexing medical images on the pathology of interest have to address conflicting goals of reducing feature dimensionality while retaining important and often subtle biomedical features. At the Lister Hill National Center for Biomedical Communications, an intramural R&D division of the U.S. National Library of Medicine, we are developing CBIR prototype for digitized images of a collection of 17,000 cervical and lumbar spine X-rays taken as a part of the second National Health and Nutrition Examination Survey (NHANES 11). The vertebra shape effectively describes various pathologies identified by medical experts as being consistently and reliably found in the image collection. A suitable shape algorithm must represent shapes in low dimension, be invariant to rotation, translation, and scale transforms, and retain relevant pathology. Additionally, supported similarity algorithms must be useful in retrieving images that are relevant to the queries posed by the intended target community, viz. medical researchers, physicians, etc. This paper describes an evaluation of two popular shape similarity methods from the literature on a set of 250 vertebra boundary shapes. The polygon approximation method achieved a performance score of 55.94% and bettered the Fourier descriptor algorithm which had a performance score of 46.96%. (C) 2004 Elsevier Inc. All rights reserved.
C1 US Dept HHS, Natl Lib Med, NIH, Lister Hill Natl Ctr Biomed Commun, Bethesda, MD 20894 USA.
   Brigham Young Univ, Dept Elect & Comp Engn, Provo, UT 84602 USA.
C3 National Institutes of Health (NIH) - USA; NIH National Library of
   Medicine (NLM); Brigham Young University
RP US Dept HHS, Natl Lib Med, NIH, Lister Hill Natl Ctr Biomed Commun, Bethesda, MD 20894 USA.
EM antani@nlm.nih.gov
RI Rohlf, F J/A-8710-2008; Antani, Sameer/GVS-8371-2022
OI Antani, Sameer/0000-0002-0040-1387
CR Adoram M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P597, DOI 10.1109/MMCS.1999.778552
   Ang Y. H., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P47, DOI 10.1117/12.205317
   [Anonymous], STAT MODELS APPEARAN
   Antani S, 2003, PROC SPIE, V5021, P405, DOI 10.1117/12.476289
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   ANTANI S, 1995, P IND C COMP VIS GRA, P242
   ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509
   BENGTSSON A, 1991, IEEE T PATTERN ANAL, V13, P85, DOI 10.1109/34.67634
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Del Bimbo A, 1999, IMAGE VISION COMPUT, V17, P245, DOI 10.1016/S0262-8856(98)00106-1
   Eakins JP, 2001, PROC SPIE, V4315, P196, DOI 10.1117/12.410929
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Gunsel B, 1998, PATTERN RECOGN, V31, P931, DOI 10.1016/S0031-3203(97)00076-9
   Hoffman ME, 2000, PROC SPIE, V3972, P86
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   IP HHS, 1997, 2 INT C VIS INF SYST, P301
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   Jain AK, 1998, PATTERN RECOGN, V31, P1369, DOI 10.1016/S0031-3203(97)00131-3
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim YS, 1997, PROC CVPR IEEE, P307
   Kliot M, 1998, COMPUT VIS IMAGE UND, V71, P182, DOI 10.1006/cviu.1998.0709
   Krainak DM, 2002, P SOC PHOTO-OPT INS, V4685, P108, DOI 10.1117/12.466995
   Kuo WJ, 2002, ULTRASOUND MED BIOL, V28, P903, DOI 10.1016/S0301-5629(02)00541-0
   Latecki LJ, 2001, COMPUT IMAGING VIS, V22, P69
   Latecki LJ, 2002, PATTERN RECOGN, V35, P1, DOI 10.1016/S0031-3203(01)00037-1
   Lee DJ, 2003, P SOC PHOTO-OPT INS, V5032, P1283, DOI 10.1117/12.481912
   LEHMANN TM, 2003, P IS T SPIE MED IM 2, V5033
   Long LR, 2001, J ELECTRON IMAGING, V10, P939, DOI 10.1117/1.1406503
   LONG LR, 2003, P IS T SPIE MED IM 2, V5033
   Mehrotra R., 1995, IEEE COMPUTER, V28, P23
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Quddus A, 2002, PATTERN RECOGN LETT, V23, P215, DOI 10.1016/S0167-8655(01)00090-3
   SONKA M, 1999, IMAGE PROCESS
   Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184, DOI 10.1136/jamia.1997.0040184
   Traina A, 2003, COMP MED SY, P163
   Traina AJM, 2003, COMP MED SY, P150
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
NR 38
TC 36
Z9 41
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 285
EP 302
DI 10.1016/j.jvcir.2004.04.005
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100003
DA 2024-07-18
ER

PT J
AU Pigeau, A
   Gelgon, M
AF Pigeau, A
   Gelgon, M
TI Organizing a personal image collection with statistical model-based ICL
   clustering on spatio-temporal camera phone meta-data
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE image retrieval; mobile applications; spatio-temporal meta-data;
   statistical clustering; mixture modelling
AB This paper addresses the issue of automated organization of a personal image collection, in particular to respond to the emerging needs from a mobile camera phones. The issues related to browsing through large image collections acquired from such devices are first discussed. In contrast with retrieval in meta-data-less collections, which necessarily relies on image content, we propose a collection organization technique based on picture geolocation and timestamps. These descriptors are indeed available and generally reliable in the proposed context. Collection organization is formulated as an unsupervised classification problem, in both space and time. The statistical integrated completed likelihood criterion is chosen, providing effective solutions both to model complexity determination and the cluster separability objective, in a setting which limits arbitrary algorithm parametrization. Reliability of space and time partitions obtained are then assessed to select a segmentation, which may then provide a calendar-type structured view for navigating in the picture collection. (C) 2004 Elsevier Inc. All rights reserved.
C1 Univ Nantes, INRIA Atlas Grp, LINA, F-44322 Nantes 03, France.
C3 Nantes Universite
RP Univ Nantes, INRIA Atlas Grp, LINA, 2,Rue Houssiniere,BP 92208, F-44322 Nantes 03, France.
EM Pigeau@lina.univ-nantes.fr; gelgon@lina.univ-nantes.fr
CR ANANDAN P, 2001, MMCBIR 2001 MULTIMED
   Ashbrook D, 2002, SIXTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P101, DOI 10.1109/ISWC.2002.1167224
   Biernacki C, 2000, IEEE T PATTERN ANAL, V22, P719, DOI 10.1109/34.865189
   Biernacki C, 2003, COMPUT STAT DATA AN, V41, P561, DOI 10.1016/S0167-9473(02)00163-9
   BISHOP CM, 1995, NEURAL NETWORLS PATT
   CHEN C, 2003, ACM INTERACT, V10, P15
   CHICKERING D, 1996, MSTTR9608
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578
   GARGI U, 2002, HPL2002LM
   Gelgon M, 2001, IEEE IMAGE PROC, P1062, DOI 10.1109/ICIP.2001.959232
   Gelgon M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA241
   GELGON M, 2002, 4 INT S HUM COMP INT, P36
   GRAHAM A, 2002, ACM JOINT C DIG LIB, P326
   GROS P, 2001, NEW DESCRIPTORS IMAG, P213
   Kang HM, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1539, DOI 10.1109/ICME.2000.871061
   Loui AC, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1125, DOI 10.1109/ICME.2000.871558
   Marmasse N, 2000, LECT NOTES COMPUT SC, V1927, P157
   MILLS TJ, 2000, 200010 MSR
   MULHEIM P, ADV DIGITAL HOME IMA
   MYKA A, 2002, Patent No. FI0200277
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   PLATT JC, 2002, MSTTR200217
   RODDEN K, 2003, ACM C HUM FACT COMP, P409
   SAVAKIS AE, 2000, SPIE C HUM VIS EL IM
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SORONEN A, 2002, 4 INT S MOB HCT 2002, P359
   SUGIURA N, 1978, COMMUN STAT A-THEOR, V7, P13, DOI 10.1080/03610927808827599
   Tadjudin S, 1999, IEEE T GEOSCI REMOTE, V37, P2113, DOI 10.1109/36.774728
   Ueda N, 2000, NEURAL COMPUT, V12, P2109, DOI 10.1162/089976600300015088
   van Beek P, 2003, IEEE SIGNAL PROC MAG, V20, P40, DOI 10.1109/MSP.2003.1184338
   Yrjänäinen J, 2002, WIREL COMMUN MOB COM, V2, P553, DOI 10.1002/wcm.91
   Zhao YL, 2002, IEEE COMMUN MAG, V40, P108, DOI 10.1109/MCOM.2002.1018015
NR 34
TC 7
Z9 12
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 425
EP 445
DI 10.1016/j.jvcir.2004.04.002
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, JT
   Chang, PC
AF Wang, JT
   Chang, PC
TI Error prevention and concealment for scalable video coding with
   dual-priority transmission
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE error propagation; error prevention; error concealment; video coding;
   asynchronous transfer mode; dual-priority
ID NETWORKS
AB In this work, we present an efficient error resilient system against ATM cell loss using a hybrid error concealment and error propagation prevention (ECP) technique with dual-priority transmission scheme (DPTS). DPTS performs traffic policing to form dual-priority cells in ATM connections and manages to make most cell losses occur in a low priority layer. However, cell loss may still occur in the high priority layer if the bandwidth is not reserved enough for the usually variable bitrate video traffic. Therefore, the ECP technique can still be utilized to reduce the error damage and limit the impact of cell loss to the erroneous slices. Simulation results of two-layer MPEG-2 coding over DPTS in ATM networks demonstrate that ECP with feedback over DPTS can effectively isolate errors and reduce the damage to yield a satisfactory performance, even when the cell-loss rate is as high as 8%. (C) 2003 Published by Elsevier Inc.
C1 Jin Wen Inst Technol, Dept Elect Engn, Shindian, Taiwan.
   Natl Cent Univ, Dept Elect Engn, Jungli, Taiwan.
C3 National Central University
RP Chang, PC (corresponding author), Jin Wen Inst Technol, Dept Elect Engn, Shindian, Taiwan.
CR AIGN S, 1995, P GLOB 95, P1778
   Aravind R, 1996, IEEE T CIRC SYST VID, V6, P426, DOI 10.1109/76.538925
   Fernandez CL, 1996, P SOC PHOTO-OPT INS, V2668, P372, DOI 10.1117/12.235432
   GHANBARI M, 1989, IEEE J SEL AREA COMM, V7, P771, DOI 10.1109/49.32340
   GHANBARI M, 1992, IEEE T COMMUN, V40, P1481, DOI 10.1109/26.163569
   HYMAN JM, 1991, IEEE J SEL AREA COMM, V9, P1052, DOI 10.1109/49.103552
   *ISO IEC JTC1 SC29, 1993, 93457 MPEG ISOIECJTC
   JENG FC, 1991, P IEEE INT C COMM 91, V1, P496
   KIEU LH, 1994, IEEE T IMAGE PROCESS, V3, P666, DOI 10.1109/83.334978
   Kinoshita T, 1993, IEEE T CIRC SYST VID, V3, P230, DOI 10.1109/76.224233
   LEGALL D, 1991, COMMUN ACM, V34, P47
   OHTA T, 1991, P IEEE INFOCOM 91 BA, V2, P781
   PANG Q, 1997, P IEEE SE 97, P126
   SAHAI A, 1995, P IEEE GLOBECOM 95 S, V1, P188
   Tubaro S., 1991, Signal Processing: Image Communication, V3, P129, DOI 10.1016/0923-5965(91)90005-M
   WADA M, 1989, IEEE J SEL AREA COMM, V7, P807, DOI 10.1109/49.32344
   Wang Y, 1999, BIOFACTORS, V9, P3, DOI 10.1002/biof.5520090102
NR 17
TC 0
Z9 0
U1 0
U2 1
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2003
VL 14
IS 4
BP 458
EP 473
DI 10.1016/S1047-3203(03)00040-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 752GM
UT WOS:000187152800005
DA 2024-07-18
ER

PT J
AU Xi, D
   Yang, HZ
   Tan, B
AF Xi, Dian
   Yang, Hengzhan
   Tan, Bo
TI Stereo matching algorithm based on improved census transform and minimum
   spanning tree cost aggregation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Census transform; Guided filter; Minimum spanning tree;
   Image segmentation
ID OF-THE-ART
AB Existing stereo matching algorithms suffer from issues such as susceptibility to distortion, weak noise resistance, and a high rate of mismatches in regions with weak textures and discontinuous disparities. To address these challenges, this paper proposes a stereo matching algorithm based on an improved census transform and minimum spanning tree (MST) cost aggregation. In the cost calculation phase, we employ a Gaussian-weighted transformation window and incorporate gradient and edge information to perform weighted fusion of the results. In the cost aggregation process, we introduce a collaborative adaptive window. Each pixel acquires information from the support window of the guided filter (GF) and other pixels within the MST. Furthermore, we integrate the SLIC superpixel segmentation algorithm into MST construction. These two components work synergistically to assign appropriate adaptive weights to pixels, facilitating coordinated cost volume aggregation. Different optimization methods are applied to address mismatched points of various types in post -disparity processing.Performance evaluation using the Middlebury dataset and KITTI dataset demonstrates that our proposed algorithm not only enhances matching accuracy in regions with discontinuous disparities and weak textures but also exhibits significantly improved robustness to interference. Additionally, the resulting disparity map displays smoother edges.
C1 [Xi, Dian; Yang, Hengzhan; Tan, Bo] Xian Technol Univ, Sch Elect Informat Engn, Xian 710021, Peoples R China.
C3 Xi'an Technological University
RP Xi, D (corresponding author), Xian Technol Univ, Sch Elect Informat Engn, Xian 710021, Peoples R China.
EM xidian@st.xatu.edu.cn
RI xi, dian/GRN-8028-2022
FU National Natural Science Foundations of China [61773016, 62073259]
FX <B>Acknowledgments</B> The work was supported by National Natural
   Science Foundations of China (No. 61773016, 62073259)
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Bleyer M, 2013, ADV COMPUT VIS PATT, P143, DOI 10.1007/978-1-4471-5520-1_6
   Brousseau PA, 2022, 2022 19TH CONFERENCE ON ROBOTS AND VISION (CRV 2022), P122, DOI 10.1109/CRV55824.2022.00024
   Chang J.-R., 2020, P ASIAN C COMPUTER V
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chang Q, 2022, J SYST ARCHITECT, V123, DOI 10.1016/j.sysarc.2021.102366
   Du X., 2019, Deep atrous multiscale stereo disparity estimation networks
   Faria M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19224849
   Fu CR, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103731
   Fu YL, 2021, IET IMAGE PROCESS, V15, P908, DOI 10.1049/ipr2.12071
   Guo ZC, 2019, ASIAPAC SIGN INFO PR, P1117, DOI 10.1109/APSIPAASC47483.2019.9023315
   Hallek M, 2022, J REAL-TIME IMAGE PR, V19, P233, DOI 10.1007/s11554-021-01180-1
   Hamzah RA, 2016, J SENSORS, V2016, DOI 10.1155/2016/8742920
   Han C., 2020, IAENG Int. J. Comput. Sci., V3, P47
   Han YL, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12193138
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hou YG, 2022, OPTIK, V249, DOI 10.1016/j.ijleo.2021.168186
   Huang CS, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00525-3
   Huang X, 2016, ISPRS ANN PHOTO REM, V3, P67, DOI 10.5194/isprsannals-III-3-67-2016
   Kadmin R., 2021, Indones. J. Electr. Eng. Comput. Sci., V22, P1312
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mozerov MG, 2015, IEEE T IMAGE PROCESS, V24, P1153, DOI 10.1109/TIP.2015.2395820
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Qi JY, 2022, IET IMAGE PROCESS, V16, P2803, DOI 10.1049/ipr2.12527
   Salehian B, 2018, OPTIK, V160, P1, DOI 10.1016/j.ijleo.2018.01.021
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Shi S., 2021, ARXIV
   Tanaka M, 2020, STRENGTH FRACT COMP, V12, P143, DOI 10.3233/SFC-190244
   Taniai T, 2018, IEEE T PATTERN ANAL, V40, P2725, DOI 10.1109/TPAMI.2017.2766072
   Tian M, 2019, ISPRS J PHOTOGRAMM, V155, P37, DOI 10.1016/j.isprsjprs.2019.06.015
   Umamaheswaran S., 2019, 2019 International Conference on Information Technology (ICIT), P201, DOI 10.1109/ICIT48102.2019.00042
   Wang HL, 2021, IEEE ROBOT AUTOM LET, V6, P4353, DOI 10.1109/LRA.2021.3068108
   Wang JX, 2023, PHOTOGRAMM REC, V38, P63, DOI 10.1111/phor.12440
   Wang LG, 2022, IEEE T PATTERN ANAL, V44, P2108, DOI 10.1109/TPAMI.2020.3026899
   [王云峰 Wang Yunfeng], 2018, [工程科学与技术, Advanced Engineering Sciences], V50, P153
   Wang ZX, 2020, OPTIK, V207, DOI 10.1016/j.ijleo.2020.164488
   Xie Y, 2021, IEEE MULTIMEDIA, V28, P38, DOI 10.1109/MMUL.2020.3030027
   Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yao P, 2018, IET COMPUT VIS, V12, P908, DOI 10.1049/iet-cvi.2017.0599
   Zeglazi O, 2018, PATTERN RECOGN LETT, V112, P205, DOI 10.1016/j.patrec.2018.07.020
   Zhang CX, 2019, IEEE ACCESS, V7, P177909, DOI 10.1109/ACCESS.2019.2958527
   Zhang J, 2021, MATH BIOSCI ENG, V18, P3215, DOI 10.3934/mbe.2021160
   Zhang K, 2014, PROC CVPR IEEE, P1590, DOI 10.1109/CVPR.2014.206
NR 46
TC 0
Z9 0
U1 16
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104023
DI 10.1016/j.jvcir.2023.104023
EA DEC 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FR4O4
UT WOS:001147570300001
DA 2024-07-18
ER

PT J
AU Wang, QQ
   Liu, Q
AF Wang, Qianqian
   Liu, Qiong
TI FDNet: Feature decoupling for single-stage pose estimation in complex
   scenes
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-person pose estimation; Complex scenes; Feature decoupling
AB Severe error accumulation is a key reason that makes existing multi -person pose estimation challenging in complex scenes. Single -stage pose estimation methods detect human and keypoints in parallel, avoiding serial error accumulation compared to two -stage methods. However, two distinct tasks share identical features in the existing method, which causes error accumulation. Therefore, we propose a Feature Decoupling Network (FDNet) to further extend the pipeline of single -stage methods and reconstruct task -specific features, including Feature Decoupling Module (FDM), Human Aware Loss (HAL) and Keypoint Aware Loss (KAL). FDM can adaptively perceive spatial and channel features and allocate separate feature domains for various tasks. To learn distinctive feature representation for compact human bodies, HAL and KAL measure and suppress feature similarities and distances for different human and keypoints, thus alienating feature interference. Experiments on crowded datasets show that our method is superior, outperforming the state-of-the-art method CID by 1.5%, 0.8% on OCHuman and CrowdPose.
C1 [Wang, Qianqian; Liu, Qiong] South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
C3 South China University of Technology
RP Liu, Q (corresponding author), South China Univ Technol, Sch Software Engn, Guangzhou 510006, Peoples R China.
EM 202121046584@mail.scut.edu.cn; liuqiong@scut.edu.cn
FU Guangdong Basic and Applied Basic Research Foundation [2021A1515011349]
FX This work was supported by Guangdong Basic and Applied Basic Research
   Foundation (No. 2021A1515011349) .
CR Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen XY, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103707
   Cheng BW, 2020, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR42600.2020.00543
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Geng ZG, 2021, PROC CVPR IEEE, P14671, DOI 10.1109/CVPR46437.2021.01444
   Hammam AA, 2020, NEURAL NETWORKS, V128, P331, DOI 10.1016/j.neunet.2020.05.017
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jin S., 2020, ECCV, P718
   Khezerlou F, 2023, J VIS COMMUN IMAGE R, V92, DOI 10.1016/j.jvcir.2023.103781
   Khirodkar R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3102, DOI 10.1109/ICCV48922.2021.00311
   Kingma D. P., 2014, arXiv
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li YP, 2023, NEURAL NETWORKS, V161, P297, DOI 10.1016/j.neunet.2023.01.036
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lingteng Qiu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P488, DOI 10.1007/978-3-030-58529-7_29
   Luo ZX, 2021, PROC CVPR IEEE, P13259, DOI 10.1109/CVPR46437.2021.01306
   Mao WA, 2021, PROC CVPR IEEE, P9030, DOI 10.1109/CVPR46437.2021.00892
   Newell A, 2017, ADV NEUR IN, V30
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie XC, 2019, IEEE I CONF COMP VIS, P6950, DOI 10.1109/ICCV.2019.00705
   Nishimura Y, 2020, NEURAL NETWORKS, V132, P521, DOI 10.1016/j.neunet.2020.09.019
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Paszke A, 2019, ADV NEUR IN, V32
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Tian Z, 2019, Arxiv, DOI arXiv:1911.07451
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang D, 2021, NeuIPS, P6278
   Wang DK, 2022, PROC CVPR IEEE, P11050, DOI 10.1109/CVPR52688.2022.01078
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12789
   Zhang SH, 2019, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2019.00098
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 42
TC 0
Z9 0
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2024
VL 98
AR 104007
DI 10.1016/j.jvcir.2023.104007
EA DEC 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IC2P5
UT WOS:001164062000001
DA 2024-07-18
ER

PT J
AU Shi, HW
   Yang, WZ
   Chen, DN
   Wang, M
AF Shi, Houwang
   Yang, Wenzhong
   Chen, Danni
   Wang, Min
TI CPA-YOLOv7: Contextual and pyramid attention-based improvement of YOLOv7
   for drones scene target detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Deep learning; Small target detection; Multi-scale feature fusion;
   Attention mechanism; Unmanned aerial vehicle view small object; Loss
   function
AB Target detection in unmanned aerial vehicle application scenarios has other problems, such as dense targets. The existing unmanned aerial vehicle target detection model with high computational complexity makes it difficult to meet real-time unmanned aerial vehicle target detection, and the detection accuracy of small targets is low. To address these problems, we propose an improved YOLOv7 small target detection model based on context and pyramidal attention that can cope with dense unmanned aerial vehicle scenarios CPA-YOLOv7. This model embeds our proposed lightweight multi-scale attentional feature spatial pyramid pooling module, which can better distinguish between small and large target features, reducing the computational effort while improving the detection accuracy of the model. Secondly, we design a contextual dynamic fusion attention module in the network to fuse global and local contextual information and dynamically assign features to multiple groups of channels; in the multi-scale fusion process, it effectively increases the characterization ability of small target features and enables the network to better focus on small target information. Finally, we improve Wise Intersection-over-Union loss as the regression loss function, add a moderation factor to retain some of the high and low-quality sample weights to improve the regression accuracy of high-quality anchor frames, and use the dynamic non-monotonic focusing mechanism to increase the model's focus on ordinary quality anchor frames to improve the model's localization performance and robustness to low-quality samples. Numerous experimental results show that on the unmanned aerial vehicle datasets VisDrone2021-DET and AI-TOD, the mAP values of our model are 2.3% and 1.1% higher than those of the YOLOv7 model with fewer parameters introduced, and the computational speed reaches 146 frames per second (FPS), which can meet the real-time requirements of unmanned aerial vehicle detection.
C1 [Shi, Houwang; Yang, Wenzhong; Chen, Danni; Wang, Min] Xinjiang Univ, Xinjiang Key Lab Multilingual Informat Technol, Urumqi 830046, Xinjiang, Peoples R China.
   Xinjiang Univ, Coll Comp Sci & Technol, Urumqi 830046, Xinjiang, Peoples R China.
C3 Xinjiang University; Xinjiang University
RP Yang, WZ (corresponding author), Xinjiang Univ, Xinjiang Key Lab Multilingual Informat Technol, Urumqi 830046, Xinjiang, Peoples R China.
EM shi514121@163.com; yangwenzhong@xju.edu.cn; kabuoxygen@163.com;
   wangmin@stu.xju.edu.cn
FU National Natural Science Foundation of China: "Research on Early
   Discovery and Situation Awareness of Multilingual Network Public Opinion
   Events" [202204120017]; Special research and development task of the
   autonomous region: "Research and development of key technologies
   [2022B01008-2]; Major science and technology projects of the autonomous
   region: "Research on common key technologies of blockchain"
   [2020A02001-1]; Research Project of "Tianshan Talents": "Research and
   Application of Multilingual and Multimodal Information Content Security"
   [SGXJXTOOJFJS2200076]; Optimization of low resolution equipment defect
   recognition algorithm based on image enhancement;  [202304120002]
FX This work was supported by the National Natural Science Foundation of
   China: "Research on Early Discovery and Situation Awareness of
   Multilingual Network Public Opinion Events" under the grant
   202204120017, Special research and development task of the autonomous
   region: "Research and development of key technologies for edge computing
   data security in digital monitoring scenarios" under the grant
   2022B01008-2, Major science and technology projects of the autonomous
   region: "Research on common key technologies of blockchain" under the
   grant 2020A02001-1, Optimization of low resolution equipment defect
   recognition algorithm based on image enhancement under the grant
   SGXJXTOOJFJS2200076, Research Project of "Tianshan Talents": "Research
   and Application of Multilingual and Multimodal Information Content
   Security" under the grant 202304120002.
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cao YR, 2021, IEEE INT CONF COMP V, P2847, DOI 10.1109/ICCVW54120.2021.00319
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DeVries T, 2017, Arxiv, DOI [arXiv:1708.04552, DOI 10.48550/ARXIV.1708.04552]
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Ghiasi G, 2021, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR46437.2021.00294
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jocher G., 2021, YouTube integrations
   Larsson G, 2017, Arxiv, DOI [arXiv:1605.07648, DOI 10.48550/ARXIV.1605.07648]
   Li C, 2023, arXiv, DOI 10.48550/arXiv.2301.05586
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li ZM, 2018, Arxiv, DOI arXiv:1804.06215
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma NN, 2021, PROC CVPR IEEE, P8028, DOI 10.1109/CVPR46437.2021.00794
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tong ZJ, 2023, Arxiv, DOI [arXiv:2301.10051, DOI 10.48550/ARXIV:2301.10051, DOI 10.48550/ARXIV.2301.10051]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang JW, 2021, INT C PATT RECOG, P3791, DOI 10.1109/ICPR48806.2021.9413340
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Weiqian Tang, 2021, 2021 China Automation Congress (CAC), P7746, DOI 10.1109/CAC53003.2021.9727887
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu C, 2022, LECT NOTES COMPUT SC, V13669, P526, DOI 10.1007/978-3-031-20077-9_31
   Zhang C, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3160007
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang S, 2020, P IEEECVF C COMPUTER
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
NR 43
TC 1
Z9 1
U1 13
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103965
DI 10.1016/j.jvcir.2023.103965
EA OCT 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z0ZS0
UT WOS:001109456500001
OA hybrid
DA 2024-07-18
ER

PT J
AU Yu, LF
   Li, YW
   Weng, SW
   Tian, HW
   Liu, J
AF Yu, Lifang
   Li, Yunwei
   Weng, Shaowei
   Tian, Huawei
   Liu, Jing
TI Adaptive multi-teacher softened relational knowledge distillation
   framework for payload mismatch in image steganalysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image steganalysis; PM (payload mismatch); BPDNets; AWA; SRKD
AB In this paper, we focus on improving the detection accuracy when payload mismatch occurs in steganalysis, by proposing an adaptive multi-teacher softened relational knowledge distillation framework, which combines multiple balanced payload difference networks (BPDNets), adaptive weight allocation (AWA) and softened relational knowledge distillation (SRKD). BPDNets aims to equivalently concern about the payload difference signal, so that the student can still achieve satisfactory detection accuracy even under unseen payloads due to that a stego signal can be considered as the sum of multiple payload difference signals. AWA assigns appropriate weights to each BPDNet based on the confidence evaluated using the cross entropy and batch entropy loss, thus effectively integrating the knowledge of BPDNets. SRKD combining the softmax with temperature ������ other than standard logits to guide the student to inherit more knowledge of relationships between images. Extensive experiments verify that the student achieves better detection performance than state-of-the-art networks.
C1 [Yu, Lifang; Li, Yunwei] Beijing Inst Graphic Commun, Dept Informat Engn, Beijing 102600, Peoples R China.
   [Weng, Shaowei] Fujian Univ Technol, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350108, Peoples R China.
   [Weng, Shaowei] Fujian Univ Technol, Sch Comp Sci & Math, Fuzhou 350118, Peoples R China.
   [Tian, Huawei] Peoples Publ Secur Univ China, Res Ctr Publ Secur Informat, Beijing 100038, Peoples R China.
   [Liu, Jing] Changsha Med Univ, Coll Informat Engn, Changsha 410000, Peoples R China.
C3 Fujian University of Technology; Fujian University of Technology;
   People's Public Security University of China; Changsha Medical
   University
RP Weng, SW (corresponding author), Fujian Univ Technol, Fujian Prov Key Lab Big Data Min & Applicat, Fuzhou 350108, Peoples R China.
EM yulifang@bigc.edu.cn; yulifang@bigc.edu.cn; wswweiwei@126.com;
   hwtian@live.cn; 414702294@qq.com
FU National NSF of China [62071434, 62262062, 61872095, 61571139, 61872128,
   2020J06043]; Fujian Science Fund for Distinguished Young Scholars
   [KM202110015004]; Beijing municipal education commis-sion project; 
   [61972405]
FX <B>Acknowledgments</B> This work was supported by the National NSF of
   China [grant num-bers 61972405, 62071434, 62262062, 61872095, 61571139,
   61872128] ; Fujian Science Fund for Distinguished Young Scholars [grant
   number 2020J06043] ; and Beijing municipal education commis-sion project
   [grant number KM202110015004] .
CR Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Deng XQ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P230, DOI 10.1145/3335203.3335739
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fu T, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103633
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hinton G., 2015, COMPUT SCI, V2
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kwon K, 2020, INT CONF ACOUST SPEE, P7409, DOI [10.1109/icassp40776.2020.9054698, 10.1109/ICASSP40776.2020.9054698]
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Lin JL, 2021, IEEE ACCESS, V9, P141938, DOI 10.1109/ACCESS.2021.3119664
   Liu S., 2023, ELECTRONICS, V12
   Liu Y, 2020, NEUROCOMPUTING, V415, P106, DOI 10.1016/j.neucom.2020.07.048
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Qian YL, 2016, IEEE IMAGE PROC, P2752, DOI 10.1109/ICIP.2016.7532860
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Ren WX, 2020, NEUROCOMPUTING, V401, P78, DOI 10.1016/j.neucom.2020.02.105
   Romero A., 2015, INT C LEARNING REPRE
   Ruder S., 2017, INT C LEARNING REPRE
   Tan SQ, 2014, ASIAPAC SIGN INFO PR
   Tan Xu, 2019, INT C LEARNING REPRE
   Vongkulbhisal J, 2019, PROC CVPR IEEE, P3170, DOI 10.1109/CVPR.2019.00329
   Wu ST, 2020, IEEE T MULTIMEDIA, V22, P256, DOI 10.1109/TMM.2019.2920605
   Wu XF, 2023, IEEE T NEUR NET LEAR, V34, P2896, DOI 10.1109/TNNLS.2021.3110109
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye DP, 2019, J REAL-TIME IMAGE PR, V16, P623, DOI 10.1007/s11554-019-00870-1
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   You S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1285, DOI 10.1145/3097983.3098135
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhongliang Yang, 2020, Digital Forensics and Watermarking. 18th International Workshop, IWDW 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12022), P352, DOI 10.1007/978-3-030-43575-2_29
   Zou Y, 2019, J VIS COMMUN IMAGE R, V60, P266, DOI 10.1016/j.jvcir.2019.02.034
NR 37
TC 2
Z9 2
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103900
DI 10.1016/j.jvcir.2023.103900
EA JUL 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Q4AH3
UT WOS:001056955500001
DA 2024-07-18
ER

PT J
AU Jin, HY
   Wang, QB
   Su, HA
   Xiao, ZL
AF Jin, Haiyan
   Wang, Qiaobin
   Su, Haonan
   Xiao, Zhaolin
TI Event-guided low light image enhancement via a dual branch GAN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low-light enhancement; Feature fusion; Event camera; Gradient
   reconstruction
ID HISTOGRAM EQUALIZATION; FRAMEWORK; RETINEX
AB In the low light conditions, images are corrupted by low contrast and severe noise, but event cameras capture event streams with clear edge structures. Therefore, we propose an Event-Guided Low Light Image Enhancement method using a dual branch generative adversarial networks and recover clear structure with the guide of events. To overcome the lack of paired training datasets, we first synthesize three datasets containing low-light event streams, low-light images, and the ground truth normal-light images. Then, in the generator network, we develop an end-to-end dual branch network consisting of a image enhancement branch and a gradient reconstruction branch. The image enhancement branch is employed to enhance the low light images, and the gradient reconstruction branch is utilized to learn the gradient from events. Moreover, we develops the attention based event-image feature fusion module which selectively fuses the event and low-light image features, and the fused features are concatenated into the image enhancement branch and gradient reconstruction branch, which respectively generate the enhanced images with clear structure and more accurate gradient images. Extensive experiments on synthetic and real datasets demonstrate that the proposed event guided low light image enhancement method produces visually more appealing enhancement images, and achieves a good performance in structure preservation and denoising over state-of-the-arts.
C1 [Jin, Haiyan; Wang, Qiaobin; Su, Haonan; Xiao, Zhaolin] Xian Univ Technol, Dept Comp Sci & Engn, Xian 710048, Peoples R China.
   Shaanxi Key Lab Network Comp & Secur Technol, Xian 710048, Peoples R China.
C3 Xi'an University of Technology
RP Su, HA (corresponding author), Xian Univ Technol, Dept Comp Sci & Engn, Xian 710048, Peoples R China.
EM jinhaiyan@xaut.edu.cn; 2211220009@stu.xaut.edu.cn; suhaonan@xaut.edu.cn;
   xiaozhaolin@xaut.edu.cn
FU National Natural Science Foundation of China [62272383]; Natural Science
   Basic Research Program of ShaanXi [2022JQ-647]; Na-tional Natural
   Science Foundation of China [61871319, 62031023]
FX Acknowledgments This work has been funded in part by the National
   Natural Science Foundation of China (No. 62272383) , Natural Science
   Basic Research Program of ShaanXi (Program No. 2022JQ-647) , in part by
   the Na-tional Natural Science Foundation of China (No. 61871319 and No.
   62031023) .
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Bardow P, 2016, PROC CVPR IEEE, P884, DOI 10.1109/CVPR.2016.102
   Brandli C, 2014, IEEE J SOLID-ST CIRC, V49, P2333, DOI 10.1109/JSSC.2014.2342715
   Cai BL, 2017, IEEE I CONF COMP VIS, P4020, DOI 10.1109/ICCV.2017.431
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chen Jierun, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P12021, DOI 10.1109/CVPR52729.2023.01157
   Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779
   Cook M, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P770, DOI 10.1109/IJCNN.2011.6033299
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hai J, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103712
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Jolicoeur-Martineau A, 2018, Arxiv, DOI arXiv:1807.00734
   Kim JW, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102903
   Kim W, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103364
   Klenk S, 2021, IEEE INT C INT ROBOT, P8601, DOI 10.1109/IROS51168.2021.9636728
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Li CY, 2021, Arxiv, DOI [arXiv:2103.00860, DOI 10.48550/ARXIV.2103.00860, DOI 10.1109/TPAMI.2021.3063604]
   Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337
   Lin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8312, DOI 10.1109/CVPR42600.2020.00834
   Liu RS, 2021, PROC CVPR IEEE, P10556, DOI 10.1109/CVPR46437.2021.01042
   Ma L, 2022, PROC CVPR IEEE, P5627, DOI 10.1109/CVPR52688.2022.00555
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mostafavi ISM, 2020, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR42600.2020.00284
   Mostafavi SA, 2021, INT J ENERGY ENVIR E, V12, P307, DOI 10.1007/s40095-020-00379-5
   Parihar AS, 2021, IET IMAGE PROCESS, V15, P1410, DOI 10.1049/ipr2.12114
   Parihar AS, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P625, DOI 10.1109/ISS1.2017.8389246
   Paszke A, 2019, ADV NEUR IN, V32
   Pizer S. M., 1990, Proceedings of the First Conference on Visualization in Biomedical Computing (Cat. No.90TH0311-1), P337, DOI 10.1109/VBC.1990.109340
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Rebecq H, 2019, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2019.00398
   Rebecq H, 2021, IEEE T PATTERN ANAL, V43, P1964, DOI 10.1109/TPAMI.2019.2963386
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Scaramuzza D., 2018, P MACHINE LEARNING R, P969
   Singh K, 2024, VISUAL COMPUT, V40, P121, DOI 10.1007/s00371-023-02770-9
   Singh K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103241
   Suganya P., 2013, International Journal of Computer Applications Technology and Research, V2, P623, DOI DOI 10.7753/IJCATR0205.1019
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P7657, DOI 10.1109/TPAMI.2021.3113352
   Wang L, 2019, PROC CVPR IEEE, P10073, DOI 10.1109/CVPR.2019.01032
   Wang Q., INT JOINT C NEURAL N
   Wang XC, 2022, NEUROCOMPUTING, V508, P315, DOI 10.1016/j.neucom.2022.08.042
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu XM, 2022, SIGNAL PROCESS, V194, DOI 10.1016/j.sigpro.2021.108447
   Wu YC, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102878
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YH, 2021, INT J COMPUT VISION, V129, P1013, DOI 10.1007/s11263-020-01407-x
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zhu AZ, 2019, PROC CVPR IEEE, P989, DOI 10.1109/CVPR.2019.00108
NR 55
TC 2
Z9 2
U1 9
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103887
DI 10.1016/j.jvcir.2023.103887
EA JUL 2023
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA N6CQ1
UT WOS:001037873000001
DA 2024-07-18
ER

PT J
AU Yu, SD
   Wang, JY
   Gu, JC
   Jin, MX
   Ma, YL
   Yang, LJ
   Li, JG
AF Yu, Shaode
   Wang, Jiayi
   Gu, Jiacheng
   Jin, Mingxue
   Ma, Yunling
   Yang, Lijuan
   Li, Jianguang
TI A hybrid indicator for realistic blurred image quality assessment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Realistic blur; Feature selection; Machine
   learning
ID SHARPNESS ASSESSMENT
AB Blurriness is annoying yet common in digital images. Many sharpness assessment indicators using handcrafted features achieve impressive results on synthesized blurring images, while room exists for improvement on realistic datasets. This study presents a hybrid indicator in which no-reference indicators perform as mid-level feature extractors and their outputs are selected using a consensus-based method for discriminative ones. On realistic image datasets, 15 off-the-shelf indicators are explored, and experimental results reveal that the hybrid indicator obtains considerable improvement (>= 21.5%, BID2011; >= 11.6%, CID2013; >= 7.1%, LIVE Challenge; and >= 11.6%, KonIQ-10k) compared to the baseline indicator. Meanwhile, the indicator requires more features for representation of diverse distortions (CID2013, LIVE Challenge and KonIQ-10k) than different blurriness (BID2011). Four regression models are investigated, and fitting neural network leads to overall better results. Realistic image quality assessment is challenging, fusion of existing indicators improves the performance, while to develop advanced indicators remains desirable.
C1 [Yu, Shaode; Wang, Jiayi; Gu, Jiacheng; Jin, Mingxue; Ma, Yunling; Li, Jianguang] Commun Univ China, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Yu, Shaode] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing, Peoples R China.
   [Yang, Lijuan] Minjiang Univ, Dept Surveying & Mapping Engn, Fuzhou, Peoples R China.
C3 Communication University of China; Communication University of China;
   Minjiang University
RP Yu, SD (corresponding author), Commun Univ China, Sch Informat & Commun Engn, Beijing, Peoples R China.
EM yushaodecuc@cuc.edu.cn
OI Yu, Shaode/0000-0002-3412-2159
CR Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Cai H, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102861
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen J., 2022, NEURAL COMPUT APPL, P1
   Chen J, 2021, IET SIGNAL PROCESS, V15, P597, DOI 10.1049/sil2.12064
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Dai GZ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P683, DOI 10.1109/ICInfA.2017.8078993
   Feng ZP, 2022, Arxiv, DOI arXiv:2209.10451
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hosseini MS, 2019, IEEE T IMAGE PROCESS, V28, P4510, DOI 10.1109/TIP.2019.2906582
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Hu B, 2022, SIGNAL PROCESS, V198, DOI 10.1016/j.sigpro.2022.108595
   Hu B, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115839
   Huang LQ, 2020, NEUROCOMPUTING, V396, P324, DOI 10.1016/j.neucom.2018.12.083
   Huang Y., 2022, IEEE T MULTIMED
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li BH, 2022, Arxiv, DOI arXiv:2209.01760
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li DQ, 2019, IEEE T MULTIMEDIA, V21, P1221, DOI 10.1109/TMM.2018.2875354
   Li DQ, 2019, LECT NOTES ELECTR EN, V506, P45, DOI 10.1007/978-3-319-91659-0_4
   Li LD, 2020, IEEE T CIRC SYST VID, V30, P3859, DOI 10.1109/TCSVT.2019.2947450
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2017, IEEE T MULTIMEDIA, V19, P1030, DOI 10.1109/TMM.2016.2640762
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Li YQ, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P853, DOI 10.1109/ICInfA.2017.8079022
   Liu JZ, 2022, Arxiv, DOI arXiv:2207.08124
   Liu YT, 2019, IEEE T MULTIMEDIA, V21, P135, DOI 10.1109/TMM.2018.2849602
   Liu YT, 2017, J VIS COMMUN IMAGE R, V46, P70, DOI 10.1016/j.jvcir.2017.03.007
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Nogueira S., 2017, J. Mach. Learn Res, V18, P6345, DOI DOI 10.5555/3122009.3242031
   Nuutinen M, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.061111
   Oh T, 2014, IEEE T IMAGE PROCESS, V23, P5428, DOI 10.1109/TIP.2014.2364925
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Sang QB, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103708
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Song T., 2022, IEEE T MULTIMED
   Song TS, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.739138
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Sun CC, 2020, KSII T INTERNET INF, V14, P4060, DOI 10.3837/tiis.2020.10.008
   Sun W., 2022, IEEE INT S BROADBAND, P1
   Sun W, 2023, Arxiv, DOI arXiv:2105.14550
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   Tang LJ, 2017, J VIS COMMUN IMAGE R, V49, P204, DOI 10.1016/j.jvcir.2017.09.010
   Virtanen T, 2015, IEEE T IMAGE PROCESS, V24, P390, DOI 10.1109/TIP.2014.2378061
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang ZJ, 2011, IEEE SIGNAL PROC MAG, V28, P2, DOI 10.1109/MSP.2011.940297
   Yu SD, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176632
   Yu SD, 2017, LECT NOTES COMPUT SC, V10116, P50, DOI 10.1007/978-3-319-54407-6_4
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhan YB, 2018, IEEE T MULTIMEDIA, V20, P1796, DOI 10.1109/TMM.2017.2780770
   Zhang WX, 2023, IEEE T PATTERN ANAL, V45, P2864, DOI 10.1109/TPAMI.2022.3178874
   Zhang WX, 2023, Arxiv, DOI arXiv:2107.13429
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhang YB, 2019, IEEE IMAGE PROC, P2359, DOI [10.1109/icip.2019.8803370, 10.1109/ICIP.2019.8803370]
   Zhang ZC, 2020, BIOINFORMATICS, V36, P4968, DOI 10.1093/bioinformatics/btaa621
   Zhu H., 2020, P IEEE CVF C COMP VI, P14143
   Zou H, 2005, J R STAT SOC B, V67, P768, DOI 10.1111/j.1467-9868.2005.00527.x
NR 67
TC 4
Z9 4
U1 8
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2023
VL 94
AR 103848
DI 10.1016/j.jvcir.2023.103848
EA MAY 2023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA J4LC2
UT WOS:001009334200001
DA 2024-07-18
ER

PT J
AU Wang, Q
   Li, ZY
   Zhu, DJ
   Yang, WK
AF Wang, Qiang
   Li, Ziyu
   Zhu, Dejun
   Yang, Wankou
TI LiDAR-only 3D object detection based on spatial context
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D object detection; Convolutional neural network; LiDAR; Computer
   vision; Deep learning
AB LiDAR-based 3D Object detection is one of the popular topics in recent years, and it is widely used in the fields of autonomous driving and robot controlling. However, due to the scanning pattern of LiDAR, the point clouds of objects at far distance are sparse and more difficult to be detected. To solve this problem, we propose a two-stage network based on spatial context information, named SC-RCNN (Spatial Context RCNN), for object detection in 3D point cloud scenes. SC-RCNN first uses a backbone with sparse convolutions and submanifold sparse convolutions to extract the voxel features of point scenes and generate a series of candidate boxes. For the sparsity of far-distance point clouds, we design the local grid point pooling (LGP Pooling) to extract features and spatial context information around candidate regions for subsequent box refinement. In addition, we propose the pyramid candidate box augmentation (PCB Augmentation) to expand the candidate boxes with a multi-scale style, enriching the feature encoding. The experimental results show that SC-RCNN significantly outperforms previous methods on KITTI dataset and Waymo dataset, and is particularly robust to the sparsity of point clouds.
C1 [Wang, Qiang; Li, Ziyu; Yang, Wankou] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Zhu, Dejun] Tsinghua Univ, Dept Hydraul Engn, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
   [Wang, Qiang] Jiangsu Automat Res Inst, Lianyungang 221116, Peoples R China.
C3 Southeast University - China; Tsinghua University
RP Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.; Zhu, DJ (corresponding author), Tsinghua Univ, Dept Hydraul Engn, State Key Lab Hydrosci & Engn, Beijing 100084, Peoples R China.
EM wkyang@seu.edu.cn
OI Yang, Wankou/0000-0002-6385-6776
FU National Natural Science Founda-tion of China [62276061, 62006041]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Nos. 62276061 and 62006041.
CR An P, 2022, COMPUT VIS IMAGE UND, V214, DOI 10.1016/j.cviu.2021.103295
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Gao Z, 2018, J VIS COMMUN IMAGE R, V56, P305, DOI 10.1016/j.jvcir.2018.10.007
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He QD, 2022, AAAI CONF ARTIF INTE, P870
   Ji CF, 2022, J VIS COMMUN IMAGE R, V88, DOI 10.1016/j.jvcir.2022.103634
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li JL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P553, DOI 10.1145/3474085.3475208
   Li Y., 2021, ARXIV
   Liang ZM, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103667
   Liang ZD, 2021, PROC CVPR IEEE, P7136, DOI 10.1109/CVPR46437.2021.00706
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Shi W., 2020, P IEEE CVF C COMP VI, P1711, DOI DOI 10.1109/CVPR42600.2020.00178
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Tengteng Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P35, DOI 10.1007/978-3-030-58555-6_3
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   Zetong Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11037, DOI 10.1109/CVPR42600.2020.01105
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 29
TC 1
Z9 1
U1 3
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103805
DI 10.1016/j.jvcir.2023.103805
EA MAR 2023
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A6SA8
UT WOS:000956388600001
DA 2024-07-18
ER

PT J
AU Fadl, S
   Hosny, KM
   Hammad, M
AF Fadl, Sondos
   Hosny, Khalid M.
   Hammad, Mohamed
TI Automatic fake document identification and localization using DE-Net and
   color-based features of foreign inks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Handwriting forgery detection; Addition; Alteration; Document
   examination; Forged document; CNN
ID WRITER IDENTIFICATION; FORGERY DETECTION; IMAGES
AB Document examination is a vital mission for revealing illegal modifications that assist in the detection and resolution of criminal acts. Addition and alteration are more frequently used in handwritten documents. However, most of the documents have been modified with similar inks, and it is tough to detect or observe them with human eyes. As a result, there is a need for methods to automatically detect handwriting forgery to reach an accurate detection efficiently. In this paper, a novel and efficient method is proposed for automatically detecting altered handwritten documents and locating the fake part. Therefore, DE-Net is proposed to identify the forged document using a digitally scanned version of the document. Unlike the existing methods, a further localization schema is applied to locate the forged parts in the candidate forged document accurately. Where each forged document is segmented into objects. Color histograms of R, G, and B channels are used to generate a fused feature vector for each object. Then a structural similarity index (SSIM) is applied to detect the lower similarity parts as forged. The experimental results demonstrate that the proposed method can identify and localize foreign ink in handwritten documents with high performance.
C1 [Fadl, Sondos; Hammad, Mohamed] Menoufia Univ, Fac Comp & Informat, Dept Informat Technol, Shibin Al Kawm 32511, Egypt.
   [Hosny, Khalid M.] Zagazig Univ, Fac Comp & Informat, Dept Informat Technol, Zagazig 44519, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Zagazig University
RP Fadl, S (corresponding author), Menoufia Univ, Fac Comp & Informat, Dept Informat Technol, Shibin Al Kawm 32511, Egypt.
EM sondos.magdy@ci.menofia.edu.eg; k_hosny@zu.edu.eg;
   mohammed.adel@ci.menofia.edu.eg
RI Hammad, Mohamed/U-6169-2019; Hosny, Khalid M./B-1404-2008
OI Hammad, Mohamed/0000-0002-6506-3083; Hosny, Khalid
   M./0000-0001-8065-8977
CR BAUER GT, 1966, APPL OPTICS, V5, P1361, DOI 10.1364/AO.5.001361
   Bhagvati C, 2005, PROC INT CONF DOC, P660
   Bradford R.R., 1992, INTRO HANDWRITING EX
   Bulacu M, 2007, IEEE T PATTERN ANAL, V29, P701, DOI 10.1109/TPAMI.2007.1009
   Chin-Shyurng Fahn, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P690, DOI 10.1109/PST.2016.7906952
   Dansena P, 2017, LECT NOTES COMPUT SC, V10597, P655, DOI 10.1007/978-3-319-69900-4_83
   Ekstrom M.P., 2012, Digital Image Processing Techniques, V2
   GODOWN L, 1964, J CRIM LAW CRIM, V55, P280, DOI 10.2307/1140760
   Gorai A, 2016, IEEE IJCNN, P4512, DOI 10.1109/IJCNN.2016.7727790
   Hammond DL, 2007, J FORENSIC SCI, V52, P967, DOI 10.1111/j.1556-4029.2007.00469.x
   HARDCASTLE RA, 1978, J FORENSIC SCI SOC, V18, P53, DOI 10.1016/S0015-7368(78)71182-5
   Hilton O., 1992, SCI EXAMINATION QUES
   Hosny KM, 2022, IEEE ACCESS, V10, P48622, DOI 10.1109/ACCESS.2022.3172273
   Hosny KM, 2019, IET IMAGE PROCESS, V13, P1437, DOI 10.1049/iet-ipr.2018.5356
   Hosny KM, 2018, IMAGING SCI J, V66, P330, DOI 10.1080/13682199.2018.1461345
   Huber R.A., 1999, HANDWRITING IDENTIFI
   Kundu S., 2019, P ACPR, P136, DOI DOI 10.1007/978-3-030-41404-7_10
   Marti UV, 2001, PROC INT CONF DOC, P101, DOI 10.1109/ICDAR.2001.953763
   Megahed A, 2017, INT CONF SOFTW ENG, P141, DOI 10.1109/ICSESS.2017.8342883
   Mushtaq H, 2015, J FORENSIC SCI, V60, P212, DOI 10.1111/1556-4029.12619
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nandanwar L, 2024, IEEE T NEUR NET LEAR, V35, P5407, DOI 10.1109/TNNLS.2022.3204390
   Nandanwar L, 2021, INT J PATTERN RECOGN, V35, DOI 10.1142/S0218001421600107
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   SAMET H, 1988, IEEE T PATTERN ANAL, V10, P579, DOI 10.1109/34.3918
   Schomaker L, 2004, IEEE T PATTERN ANAL, V26, P787, DOI 10.1109/TPAMI.2004.18
   Srihari S.N., 2007, Journal of Forensic Document Examination, V18, P1
NR 27
TC 2
Z9 2
U1 2
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2023
VL 92
AR 103801
DI 10.1016/j.jvcir.2023.103801
EA MAR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A2YL6
UT WOS:000953838400001
DA 2024-07-18
ER

PT J
AU Li, HY
   Song, YQ
   Li, HJ
   Wang, ZY
AF Li, Haiyan
   Song, Yingqing
   Li, Haijiang
   Wang, Zhengyu
TI Semantic prior-driven fused contextual transformation network for image
   inpainting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Semantic prior generator; Fused contextual
   transformation; Aggregated semantic attention-aware; Discriminator
AB Recent advances in image inpainting have achieved impressive performance for generating plausible visual details on small regular image defects or simple backgrounds. However, current solution suffers from the lack of semantic priors for the image and the inability to deduce the image content from distant background, leading to distorted structures and artifacts in the results when inpainting large random irregular complicated images. To address these problems, a semantic prior-driven fused contextual transformation network for image inpainting is proposed as a promise solution. First, the semantic prior generator is put forward to map the semantic features of ground truth images and the low-level features of broken images to semantic priors. Subsequently, an image split-transform-aggregated strategy, named fusion context transformation block, is presented to infer rich multi-scale remote texture features and thus to improve the restored image finesse. Thereafter, an aggregated semantic attention-aware module, consisting of spatially adaptive normalization and enhanced spatial attention is designed to aggregate semantic priors and multi-scale texture features into the decoder to restore reasonable structure. Finally, the mask guided discriminator is developed to effectively discriminate between real and false pixels in the output image to improve the capability of the discriminator and hence to reduce the probability of artifacts containing in the output image. Comprehensive experimental results on CelebA-HQ, Paris Street View, and Places2 datasets demonstrate the superiority of the proposed network over the state-of-the-arts, whose PSNR, SSIM and MAE are improved about 20 %, 12.6 %, and 42 % gains, respectively.
C1 [Li, Haiyan; Song, Yingqing; Wang, Zhengyu] Yunnan Univ, Sch Informat, Kunming 650050, Yunnan, Peoples R China.
   [Li, Haijiang] Yunnan Commun Investment & Construction Grp Co Ltd, Kunming 650050, Yunnan, Peoples R China.
C3 Yunnan University
RP Li, HJ (corresponding author), Yunnan Commun Investment & Construction Grp Co Ltd, Kunming 650050, Yunnan, Peoples R China.
EM li_cannie@163.com
RI LI, HAIJIANG/JJF-9281-2023
FU National Natural Science Foundation of China [62266049, 62066047,
   61861045]
FX The authors declare that they have no known competing financial
   interests or personal relationships that could have appeared to
   influence the work reported in this paper. This work is supported by the
   National Natural Science Foundation of China (No. 62266049, No. 62066047
   and No. 61861045) .
CR Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Ben-Baruch E, 2021, Arxiv, DOI [arXiv:2009.14119, 10.48550/arXiv.2009.14119, DOI 10.48550/ARXIV.2009.14119]
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Cao CJ, 2022, LECT NOTES COMPUT SC, V13675, P306, DOI 10.1007/978-3-031-19784-0_18
   Criminisi A, 2003, PROC CVPR IEEE, P721
   Doersch C, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185597
   Dolhansky B, 2018, PROC CVPR IEEE, P7902, DOI 10.1109/CVPR.2018.00824
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grosse R, 2009, IEEE I CONF COMP VIS, P2335, DOI 10.1109/ICCV.2009.5459428
   Hensel M, 2017, ADV NEUR IN, V30
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jingyuan Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7757, DOI 10.1109/CVPR42600.2020.00778
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Kong FY, 2022, IEEE COMPUT SOC CONF, P765, DOI 10.1109/CVPRW56347.2022.00092
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu HY, 2019, IEEE I CONF COMP VIS, P4169, DOI 10.1109/ICCV.2019.00427
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Miyato T, 2018, Arxiv, DOI arXiv:1802.05957
   Nazeri K, 2019, IEEE INT CONF COMP V, P3265, DOI 10.1109/ICCVW.2019.00408
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Ren YR, 2019, IEEE I CONF COMP VIS, P181, DOI 10.1109/ICCV.2019.00027
   Shetty R, 2018, Arxiv, DOI arXiv:1806.01911
   Song YH, 2018, LECT NOTES COMPUT SC, V11206, P3, DOI [10.1007/978-3-030-01216-8_1, 10.1109/APCAP.2017.8420330]
   Wan ZY, 2020, PROC CVPR IEEE, P2744, DOI 10.1109/CVPR42600.2020.00282
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan ZY, 2018, LECT NOTES COMPUT SC, V11218, P3, DOI 10.1007/978-3-030-01264-9_1
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu T, 2020, AAAI CONF ARTIF INTE, V34, P12733
   Zeng Y., 2022, IEEE T VISUAL COMPUT
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang W., 2021, INT JOINT C ART INT, P1323
   Zhang WD, 2021, Arxiv, DOI arXiv:2112.04107
   Zheng CX, 2019, PROC CVPR IEEE, P1438, DOI 10.1109/CVPR.2019.00153
   Zheng HT, 2022, LECT NOTES COMPUT SC, V13676, P277, DOI 10.1007/978-3-031-19787-1_16
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 46
TC 1
Z9 1
U1 4
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAR
PY 2023
VL 91
AR 103777
DI 10.1016/j.jvcir.2023.103777
EA FEB 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 9W1US
UT WOS:000948866700001
DA 2024-07-18
ER

PT J
AU Jing, PG
   Huang, ZJ
   Liu, J
   Wang, YT
   Yu, JX
AF Jing, Peiguang
   Huang, Zijian
   Liu, Jing
   Wang, Yating
   Yu, Jiexiao
TI Edge-aware object pixel-level representation tracking
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Edge-aware; Segmentation mask; Real-time
AB Recently, there has been a trend in tracking to use more refined segmentation mask instead of coarse bounding box to represent the target object. Some trackers proposed segmentation branches based on the tracking framework and maintain real-time speed. However, those trackers use a simple FCNs structure and lack of the edge information modeling. This makes performance quite unsatisfactory. In this paper, we propose an edge-aware segmentation network, which uses the complementarity between target information and edge information to provide a more refined representation of the target. Firstly, We use the high-level features of the tracking backbone network and the correlation features of the classification branch of the tracking framework to fuse, and use the target edge and target segmentation mask for simultaneous supervision to obtain an optimized high-level feature with rough edge information and target information. Secondly, we use the optimized high-level features to guide the low-level features of the tracking backbone network to generate more refined edge features. Finally, we use the refined edge features to fuse with the target features of each layer to generate the final mask. Our approach has achieved leading performance on recent pixel-wise object tracking benchmark VOT2020 and segmentation datasets DAVIS2016 and DAVIS2017 while running on 47 fps. Code is available at https://github.com/TJUMMG/EATtracker.
C1 [Jing, Peiguang; Liu, Jing; Wang, Yating; Yu, Jiexiao] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Huang, Zijian] Tianjin Univ, Tianjin Int Engn Inst, Tianjin 300072, Peoples R China.
C3 Tianjin University; Tianjin University
RP Liu, J; Yu, JX (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM jliu_tju@tju.edu.cn; yjx@tju.edu.cn
RI Wang, Ya-Ting/AFL-5523-2022; Jing, LIU/JCP-2850-2023; lin,
   lin/KCZ-0185-2024
OI Jing, LIU/0000-0001-5172-4605; 
FU Research Fund of Guangxi Key Lab of Multi-source Information Mining
   Security [MIMS22-15]; National Key Research and Development Program of
   China [2021YFF0901600]
FX Acknowledgments This work was supported in part by Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security
   (MIMS22-15) and in part by the National Key Research and Development
   Program of China (2021YFF0901600) .
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Guan WL, 2019, IEEE SIGNAL PROC LET, V26, P114, DOI 10.1109/LSP.2018.2881835
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Kristan M., 2020, COMPUTER VISION ECCV, P547
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lin LT, 2022, Arxiv, DOI arXiv:2112.00995
   Liu J, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103456
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Ma C, 2018, INT J COMPUT VISION, V126, P771, DOI 10.1007/s11263-018-1076-4
   Nam H., 2016, IEEE C COMP VIS PATT, P4293
   Perazzi F, 2016, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2016.85
   Pont-Tuset J, 2018, Arxiv, DOI arXiv:1704.00675
   Robinson Andreas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7404, DOI 10.1109/CVPR42600.2020.00743
   Shi ZF, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103312
   Tang CF, 2021, PROC CVPR IEEE, P13921, DOI 10.1109/CVPR46437.2021.01371
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang Z., 2003, P 37 AS C SIGN SYST, P1398, DOI [DOI 10.1109/ACSSC.2003.1292216, 10.1109/ACSSC.2003.1292216]
   Wu QQ, 2021, PROC CVPR IEEE, P2992, DOI 10.1109/CVPR46437.2021.00301
   Xi Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9381, DOI 10.1109/CVPR42600.2020.00940
   Xier Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P617, DOI 10.1007/978-3-030-58583-9_37
   Xu N., 2018, P EUROPEAN C COMPUTE
   Yan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10428, DOI 10.1109/ICCV48922.2021.01028
   Zhang J, 2017, Arxiv, DOI arXiv:1708.04366
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang MK, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103082
   Zhang YZ, 2020, PROC CVPR IEEE, P6947, DOI 10.1109/CVPR42600.2020.00698
   Zhang ZP, 2020, Arxiv, DOI arXiv:2008.02745
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zheng JL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13526, DOI 10.1109/ICCV48922.2021.01329
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
   Zhuge YZ, 2018, IEEE SIGNAL PROC LET, V25, P1800, DOI 10.1109/LSP.2018.2875586
   Zimmermann S, 2019, Arxiv, DOI arXiv:1809.07069
NR 48
TC 0
Z9 0
U1 3
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103735
DI 10.1016/j.jvcir.2022.103735
EA DEC 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8E0FJ
UT WOS:000918658600001
DA 2024-07-18
ER

PT J
AU Jaiswal, G
   Sharma, A
   Yadav, SK
AF Jaiswal, Garima
   Sharma, Arun
   Yadav, Sumit Kumar
TI DFD-SS: Document Forgery Detection using Spectral-Spatial Features for
   Hyperspectral Images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Document forgery; Spectral; Spatial; Spectral -spatial; Autoencoders;
   Unsupervised Deep Learning
ID CLASSIFICATION; AUTOENCODER
AB In the present era of machines and edge-cutting technologies, still document frauds persist. They are done intuitively by using almost identical inks, that it becomes challenging to detect them-this demands an approach that efficiently investigates the document and leaves it intact. Hyperspectral imaging is one such a type of approach that captures the images from hundreds to thousands of spectral bands and analyzes the images through their spectral and spatial features, which is not possible by conventional imaging. Deep learning is an edge-cutting technology known for solving critical problems in various domains. Utilizing supervised learning imposes constraints on its usage in real scenarios, as the inks used in forgery are not known prior. Therefore, it is beneficial to use unsupervised learning. An unsupervised feature extraction through a Convolutional Autoen-coder (CAE) followed by Logistic Regression (LR) for classification is proposed (CAE-LR). Feature extraction is evolved around spectral bands, spatial patches, and spectral-spatial patches. We inspected the impact of spectral, spatial, and spectral-spatial features by mixing inks in equal and unequal proportion using CAE-LR on the UWA writing ink hyperspectral images dataset for blue and black inks. Hyperspectral images are captured at multiple correlated spectral bands, resulting in information redundancy handled by restoring certain principal compo-nents. The proposed approach is compared with eight state-of-art approaches used by the researchers. The results depicted that by using the combination of spectral and spatial patches, the classification accuracy enhanced by 4.85% for black inks and 0.13% for blue inks compared to state-of-art results. In the present scenario, the primary area concern is to identify and detect the almost similar inks used in document forgery, are efficiently managed by the proposed approach.
C1 [Jaiswal, Garima] Bennett Univ, Greater Noida, India.
   [Sharma, Arun] Indira Gandhi Delhi Tech Univ Women, Delhi, India.
   [Yadav, Sumit Kumar] Income Tax Dept, New Delhi, India.
C3 Indira Gandhi Delhi Technical University for Women (IGDTUW)
RP Jaiswal, G (corresponding author), Bennett Univ, Greater Noida, India.
EM garima121@gmail.com; arunsharma@igdtuw.ac.in; sumitarya007@gmail.com
RI Sharma, Arun/IXN-0008-2023; Sharma, Arun/F-4798-2014
OI JAISWAL, GARIMA/0000-0002-2676-299X; Sharma, Arun/0000-0002-9404-4519
CR Abbas A, 2017, PROC INT CONF DOC, P1229, DOI 10.1109/ICDAR.2017.203
   [Anonymous], 2009, Scholarpedia
   [Anonymous], 2012, Self-Organizing Maps
   Butt UM, 2016, INT CONF FRONT HAND, P19, DOI [10.1109/ICFHR.2016.0017, 10.1109/ICFHR.2016.14]
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Devassy BM, 2020, FORENSIC SCI INT, V311, DOI 10.1016/j.forsciint.2020.110194
   Devassy BM, 2019, PROC INT CONF DOC, P25, DOI 10.1109/ICDARW.2019.70137
   Devassy BM, 2019, NISK J, P12
   Dong GG, 2018, IEEE GEOSC REM SEN M, V6, P44, DOI 10.1109/MGRS.2018.2853555
   Duma M, 2018, APPL SOFT COMPUT, V71, P183, DOI 10.1016/j.asoc.2018.07.001
   Ghiyamat A, 2010, INT J REMOTE SENS, V31, P1837, DOI 10.1080/01431160902926681
   Islam AU, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P346, DOI 10.1109/dicta47822.2019.8945886
   Jaiswal G, 2021, COMM COM INF SC, V1440, P739, DOI 10.1007/978-3-030-81462-5_65
   Jaiswal G, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107770
   Jaiswal G, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1426
   Jia S, 2021, NEUROCOMPUTING, V448, P179, DOI 10.1016/j.neucom.2021.03.035
   Khan F., 2013, P AFHA, P41
   Khan Muhammad Jaleed, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1097, DOI 10.1109/ICDAR.2019.00178
   Khan MJ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053001
   Khan MJ, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P393, DOI 10.1109/DAS.2018.26
   Khan MJ, 2018, IEEE ACCESS, V6, P14118, DOI 10.1109/ACCESS.2018.2812999
   Khan Z, 2015, PATTERN RECOGN, V48, P3615, DOI 10.1016/j.patcog.2015.04.008
   Khan Z, 2013, PROC INT CONF DOC, P877, DOI 10.1109/ICDAR.2013.179
   Larochelle H, 2012, J MACH LEARN RES, V13, P643
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055
   Lu XG, 2013, INTERSPEECH, P436
   Luo ZP, 2015, PROC INT CONF DOC, P496, DOI 10.1109/ICDAR.2015.7333811
   Devassy BM, 2020, J IMAGING, V6, DOI 10.3390/jimaging6050029
   Rahiche A, 2020, IEEE COMPUT SOC CONF, P2823, DOI 10.1109/CVPRW50498.2020.00339
   Rastogi V., 2022, INT C COMPUTER VISIO, P14
   Reed G, 2014, SCI JUSTICE, V54, P71, DOI 10.1016/j.scijus.2013.09.005
   Shafait F, 2008, PROC SPIE, V6815, DOI 10.1117/12.767755
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Siche R, 2016, FOOD ENG REV, V8, P306, DOI 10.1007/s12393-015-9137-8
   Silva CS, 2014, ANALYST, V139, P5176, DOI 10.1039/c4an00961d
   Swietojanski P, 2015, INT CONF ACOUST SPEE, P4305, DOI 10.1109/ICASSP.2015.7178783
   Tschannen M, 2018, Arxiv, DOI [arXiv:1812.05069, DOI 10.48550/ARXIV.1812.05069]
   Zabalza J, 2016, NEUROCOMPUTING, V185, P1, DOI 10.1016/j.neucom.2015.11.044
   Zhang LP, 2012, GEO-SPAT INF SCI, V15, P143, DOI 10.1080/10095020.2012.719684
NR 40
TC 4
Z9 4
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103690
DI 10.1016/j.jvcir.2022.103690
EA NOV 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7E9ZF
UT WOS:000901516600002
DA 2024-07-18
ER

PT J
AU Presotto, JGC
   dos Santos, SF
   Valem, LP
   Faria, FA
   Papa, JP
   Almeida, J
   Pedronette, DCG
AF Presotto, Joao Gabriel Camacho
   dos Santos, Samuel Felipe
   Valem, Lucas Pascotti
   Faria, Fabio Augusto
   Papa, Joao Paulo
   Almeida, Jurandy
   Pedronette, Daniel Carlos Guimaraes
TI Weakly supervised learning based on hypergraph manifold ranking?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Weakly supervised learning; Manifold learning; Ranking; Hypergraph
AB Significant challenges still remain despite the impressive recent advances in machine learning techniques, particularly in multimedia data understanding. One of the main challenges in real-world scenarios is the nature and relation between training and test datasets. Very often, only small sets of coarse-grained labeled data are available to train models, which are expected to be applied on large datasets and fine-grained tasks. Weakly supervised learning approaches handle such constraints by maximizing useful training information in labeled and unlabeled data. In this research direction, we propose a weakly supervised approach that analyzes the dataset manifold to expand the available labeled set. A hypergraph manifold ranking algorithm is exploited to represent the contextual similarity information encoded in the unlabeled data and identify strong similarity relations, which are taken as a path to label expansion. The expanded labeled set is subsequently exploited for a more comprehensive and accurate training process. The proposed model was evaluated jointly with supervised and semi-supervised classifiers, including Graph Convolutional Networks. The experimental results on image and video datasets demonstrate significant gains and accurate results for different classifiers in diverse scenarios.
C1 [Presotto, Joao Gabriel Camacho; Valem, Lucas Pascotti; Pedronette, Daniel Carlos Guimaraes] State Univ Sao Paulo UNESP, Dept Stat Appl Math & Comp, Ave 24-A, 1515, BR-13506900 Rio Claro, SP, Brazil.
   [dos Santos, Samuel Felipe; Faria, Fabio Augusto] Fed Univ Sao Paulo UNIFESP, Inst Sci & Technol, BR-12247014 Sao Jose Dos Campos, Brazil.
   [Papa, Joao Paulo] State Univ Sao Paulo UNESP, Sch Sci, BR-17033360 Bauru, Brazil.
   [Almeida, Jurandy] Fed Univ Sao Carlos UFSCAR, Dept Comp, BR-18052780 Sorocaba, Brazil.
C3 Universidade Estadual Paulista; Universidade Federal de Sao Paulo
   (UNIFESP); Universidade Estadual Paulista; Universidade Federal de Sao
   Carlos
RP Valem, LP (corresponding author), State Univ Sao Paulo UNESP, Dept Stat Appl Math & Comp, Ave 24-A, 1515, BR-13506900 Rio Claro, SP, Brazil.
EM lucas.valem@unesp.br; daniel.pedronette@unesp.br
RI SANTOS, SAMUEL FELIPE DOS/AAV-8154-2020
OI SANTOS, SAMUEL FELIPE DOS/0000-0001-6061-5582; Pascotti Valem,
   Lucas/0000-0002-3833-9072
FU S?o Paulo Research Foundation-FAPESP; Brazilian National Council for
   Scien-tific and Technological Development-CNPq; Petrobras; Microsoft
   Research;  [2017/25908-6];  [2018/15597-6];  [2018/23908-1]; 
   [2019/04754-6];  [2020/11366-0];  [309439/2020-5];  [314868/2020-8]; 
   [422667/2021-8];  [2017/00285-6]
FX The authors are grateful to S?o Paulo Research Foundation-FAPESP (grants
   #2017/25908-6, #2018/15597-6, #2018/23908-1, #2019/04754-6, and
   #2020/11366-0) , Brazilian National Council for Scien-tific and
   Technological Development-CNPq (grants #309439/2020-5, #314868/2020-8,
   and #422667/2021-8) , Petrobras (grant #2017/00285-6) , and Microsoft
   Research for financial support.
CR Abuduweili A, 2021, PROC CVPR IEEE, P6919, DOI 10.1109/CVPR46437.2021.00685
   [Anonymous], 2019, ICLR
   Berikov V., 2021, INT C MATH OPT THEOR, P447
   Bianchi FM, 2022, IEEE T PATTERN ANAL, V44, P3496, DOI 10.1109/TPAMI.2021.3054830
   Bretto A., 2013, HYPERGRAPH THEORY IN, DOI DOI 10.1007/978-3-319-00080-0
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cubuk E.D., 2020, ADV NEURAL INFORM PR
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Devries T., 2017, COMPUTING RES REPOSI
   dos Santos SF, 2020, SIBGRAPI, P62, DOI 10.1109/SIBGRAPI51738.2020.00017
   Fey M., 2019, COMPUTING RES REPOSI
   Pedronette DCG, 2021, J IMAGING, V7, DOI 10.3390/jimaging7030049
   Pedronette DCG, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107666
   Pedronette DCG, 2019, IEEE T IMAGE PROCESS, V28, P5824, DOI 10.1109/TIP.2019.2920526
   Pedronette DCG, 2019, NEUROCOMPUTING, V340, P19, DOI 10.1016/j.neucom.2019.02.016
   Pedronette DCG, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P197
   Han K., 2020, INT C LEARN REPR ICL
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jing Lei, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P1110, DOI 10.1109/ICOEI51242.2021.9453076
   Kipf T.N., 2017, P INT C LEARN REPR S
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lee D.-H., 2013, P WORKSH CHALL REPR
   Lin W., 2020, COMPUTING RES REPOSI
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Papa JP, 2012, PATTERN RECOGN, V45, P512, DOI 10.1016/j.patcog.2011.07.013
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Presotto J.G.C., 2020, INT C PATTERN RECOGN
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Velickovic Petar, 2018, INT C LEARN REPR
   Wah C., CNSTR2011001 CALTECH
   Wei C, 2021, PROC CVPR IEEE, P10852, DOI 10.1109/CVPR46437.2021.01071
   Wu F, 2019, PR MACH LEARN RES, V97
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhou D., 2006, ADV NEURAL INFORM PR, P1601, DOI DOI 10.7551/MITPRESS/7503.003.0205
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu X., 2002, CMUCALD02107, V3175, P237, DOI DOI 10.1007/978-3-540-28649-3_29
NR 46
TC 0
Z9 0
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103666
DI 10.1016/j.jvcir.2022.103666
EA OCT 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Z4VL
UT WOS:000879972500008
DA 2024-07-18
ER

PT J
AU Chen, J
   Wu, HT
   Lu, L
   Luo, XY
   Hu, JK
AF Chen, Jian
   Wu, Hao-Tian
   Lu, Lu
   Luo, Xiangyang
   Hu, Jiankun
TI Single underwater image haze removal with a learning-based approach to
   blurriness estimation?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Underwater image; Image dehazing; Image restoration; Image enhancement
ID DATA HIDING METHOD; CONTRAST ENHANCEMENT; COEFFICIENT; COLOR
AB Underwater images are usually degraded due to light scattering and absorption. To recover the scene radiance of degraded underwater images, a new haze removal method is presented by incorporating a learning-based approach to blurriness estimation with the image formation model. Firstly, the image blurriness is estimated with a linear model trained on a set of selected grayscale images, the average Gaussian images and blurriness images. With the estimated image blurriness, three intermediate background lights (BLs) are computed to obtain the synthesized BL. Then the scene depth is calculated by using the estimated image blurriness and BL to construct a transmission map and restore the scene radiance. Compared with other haze removal methods, haze in degraded underwater images can be removed more accurately with our proposed method. Moreover, visual inspection, quantitative evaluation and application test demonstrate that our method is superior to the compared methods and beneficial to high-level vision tasks.
C1 [Chen, Jian; Wu, Hao-Tian; Lu, Lu] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Wu, Hao-Tian] Peng Cheng Lab, Shenzhen 518066, Peoples R China.
   [Luo, Xiangyang] State Key Lab Math Engn & Adv Comp, Zhengzhou, Peoples R China.
   [Luo, Xiangyang] Key Lab Cyberspace Situat Awareness Henan Prov, Zhengzhou, Peoples R China.
   [Hu, Jiankun] Univ New South Wales, Australian Def Force Acad, Sch Engn & Informat Technol, Canberra, Australia.
C3 South China University of Technology; Peng Cheng Laboratory; PLA
   Information Engineering University; University of New South Wales
   Sydney; Australian Defense Force Academy
RP Wu, HT (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM wuht@scut.edu.cn
RI Hu, Jiankun/D-9856-2012; Wu, Hao-Tian/S-5360-2019
OI Wu, Hao-Tian/0000-0001-6462-7193
FU Natural Science Foundation of Guangdong, China; National Natural Science
   Foundation of China; Open Foundation of Henan Key Laboratory of
   Cyberspace Situation Awareness, China;  [2021A1515011798];  [61772208]; 
   [HNTS2022017]
FX Acknowledgments This work was partly supported by the Natural Science
   Foundation of Guangdong, China (No. 2021A1515011798) , the National
   Natural Science Foundation of China (No. 61772208) , and Open Foundation
   of Henan Key Laboratory of Cyberspace Situation Awareness, China (No.
   HNTS2022017) . Many thanks to the anonymous reviewers for their
   insightful comments and valuable suggestions!
CR Abu A, 2022, IEEE SENS J, V22, P6027, DOI 10.1109/JSEN.2022.3148530
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Babu GH, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jveir.2020.102912
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Boudhane M, 2016, J VIS COMMUN IMAGE R, V39, P226, DOI 10.1016/j.jvcir.2016.05.017
   Carlevaris-Bianco N., 2010, OCEANS, P1, DOI DOI 10.1109/OCEANS.2010.5664428
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Freitas TBN, 2022, MAR POLLUT BULL, V175, DOI 10.1016/j.marpolbul.2022.113339
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   GORDON HR, 1989, LIMNOL OCEANOGR, V34, P1389, DOI 10.4319/lo.1989.34.8.1389
   Gould RW, 1999, APPL OPTICS, V38, P2377, DOI 10.1364/AO.38.002377
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Han M, 2020, IEEE T SYST MAN CY-S, V50, P1820, DOI 10.1109/TSMC.2017.2788902
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou GJ, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102732
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Kai Y, 2022, Arxiv, DOI arXiv:2203.09414
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2016, INT CONF ACOUST SPEE, P1731, DOI 10.1109/ICASSP.2016.7471973
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu P, 2022, IEEE T INTELL TRANSP, V23, P25396, DOI 10.1109/TITS.2022.3145815
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng LT, 2022, Arxiv, DOI arXiv:2111.11843
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Ren TD, 2022, Arxiv, DOI arXiv:2205.00434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schoefs F, 2021, J MAR SCI ENG, V9, DOI 10.3390/jmse9121344
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Tomasi C., 1998, 6 INT C COMP VIS IEE, P839
   Wang Y, 2019, IEEE ACCESS, V7, P140233, DOI 10.1109/ACCESS.2019.2932130
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2022, IEEE T CIRC SYST VID, V32, P7605, DOI 10.1109/TCSVT.2022.3180007
   Wu HT, 2021, IEEE SIGNAL PROC LET, V28, P160, DOI 10.1109/LSP.2020.3048840
   Wu HT, 2020, IET IMAGE PROCESS, V14, P327, DOI 10.1049/iet-ipr.2019.0423
   Wu HT, 2019, IEEE ACCESS, V7, P83332, DOI 10.1109/ACCESS.2019.2921407
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Wu HT, 2018, SIGNAL PROCESS-IMAGE, V62, P64, DOI 10.1016/j.image.2017.12.006
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xu W, 2011, Arxiv, DOI arXiv:1107.2490
   Yang CF, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9328-2
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao XW, 2015, OCEAN ENG, V94, P163, DOI 10.1016/j.oceaneng.2014.11.036
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 52
TC 2
Z9 2
U1 1
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103656
DI 10.1016/j.jvcir.2022.103656
EA OCT 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V0YU
UT WOS:000876964800002
DA 2024-07-18
ER

PT J
AU Li, X
   Huang, Q
   Wang, ZJ
   Yang, TJ
AF Li, Xing
   Huang, Qian
   Wang, Zhijian
   Yang, Tianjin
TI VirtualActionNet: A strong two-stream point cloud sequence network for
   human action recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Two-stream network; 3D action recognition; Point cloud sequence
AB In this paper, we propose a strong two-stream point cloud sequence network VirtualActionNet for 3D human action recognition. In the data preprocessing stage, we transform the depth sequence into a point cloud sequence as the input of our VirtualActionNet. In order to encode intra-frame appearance structures, static point cloud technologies are first employed as a virtual action generation sequence module to abstract the point cloud sequence into a virtual action sequence. Then, a two-stream network framework is presented to model the virtual action sequence. Specifically, we design an appearance stream module for aggregating all the appearance information preserved in each virtual action frame. Moreover, a motion stream module is introduced to capture dynamic changes along the time dimension. Finally, a joint loss strategy is adopted during data training to improve the action prediction accuracy of the two-stream network. Extensive experiments on three publicly available datasets demonstrate the effectiveness of the proposed VirtualActionNet.
C1 [Li, Xing; Huang, Qian; Wang, Zhijian; Yang, Tianjin] Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, Nanjing, Jiangsu, Peoples R China.
   Hohai Univ, Sch Comp & Informat, Nanjing, Jiangsu, Peoples R China.
C3 Hohai University; Hohai University
RP Huang, Q (corresponding author), Hohai Univ, Key Lab Water Big Data Technol, Minist Water Resources, Nanjing, Jiangsu, Peoples R China.
EM lixing@hhu.edu.cn; huangqian@hhu.edu.cn; zhjwang@hhu.edu.cn;
   yangtianjin@hhu.edu.cn
RI Huang, Qian/GPX-9181-2022; Huang, Qian/GPX-9488-2022
OI Huang, Qian/0000-0001-5625-0402
FU Fundamental Research Funds of China for the Central Universities;
   Jiangsu Water Conservancy Science and Technology Project; National Key
   Research and Development Program of China;  [B200202188];  [2018057]; 
   [2018YFC0407905]
FX Acknowledgments This research is sponsored by the Fundamental Research
   Funds of China for the Central Universities under Grant No. B200202188,
   the Jiangsu Water Conservancy Science and Technology Project under Grant
   No. 2018057, and the National Key Research and Development Program of
   China under Grant No. 2018YFC0407905.
CR Barkoky A, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103371
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bulbul MF, 2019, MULTIMED TOOLS APPL, V78, P21085, DOI 10.1007/s11042-019-7365-2
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Cheng J, 2022, IEEE T CIRC SYST VID, V32, P1498, DOI 10.1109/TCSVT.2021.3076165
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Diba A, 2017, Arxiv, DOI arXiv:1711.08200
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Elmadany NE, 2019, IEEE T MULTIMEDIA, V21, P1317, DOI 10.1109/TMM.2018.2875510
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   Fan H., 2021, INT C LEARNING REPRE
   Fan HH, 2021, PROC CVPR IEEE, P14199, DOI 10.1109/CVPR46437.2021.01398
   Graves A, 2012, STUD COMPUT INTELL, V385, P37
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kim D., 2014, 8 INT C MOBILE UBIQU
   Ko KE, 2018, ENG APPL ARTIF INTEL, V67, P226, DOI 10.1016/j.engappai.2017.10.001
   Kolekar MH, 2016, PROCEEDINGS OF THE 2016 IEEE REGION 10 CONFERENCE (TENCON), P393, DOI 10.1109/TENCON.2016.7848028
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu XY, 2019, IEEE I CONF COMP VIS, P9245, DOI 10.1109/ICCV.2019.00934
   Muhammad K, 2021, FUTURE GENER COMP SY, V125, P820, DOI 10.1016/j.future.2021.06.045
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Peng W, 2020, AAAI CONF ARTIF INTE, V34, P2669
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qi CR, 2017, ADV NEUR IN, V30
   Rodomagoulakis I, 2016, INT CONF ACOUST SPEE, P2702, DOI 10.1109/ICASSP.2016.7472168
   Sanchez-Caballero A, 2020, Arxiv, DOI arXiv:2006.07744
   Sánchez-Caballero A, 2022, MULTIMED TOOLS APPL, V81, P24119, DOI 10.1007/s11042-022-12091-z
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shen XP, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103386
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Singh T, 2019, ARTIF INTELL REV, V52, P1107, DOI 10.1007/s10462-018-9651-1
   Song YF, 2023, IEEE T PATTERN ANAL, V45, P1474, DOI 10.1109/TPAMI.2022.3157033
   Stroud JC, 2020, IEEE WINT CONF APPL, P614, DOI 10.1109/wacv45572.2020.9093274
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang YC, 2020, PROC CVPR IEEE, P508, DOI 10.1109/CVPR42600.2020.00059
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HB, 2022, IEEE T CIRC SYST VID, V32, P1250, DOI [10.1109/TAI.2021.3092698, 10.1109/TCSVT.2021.3077512]
   Wu HB, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881418825093
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Yan CG, 2021, IEEE T PATTERN ANAL, V43, P1445, DOI 10.1109/TPAMI.2020.2975798
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan CG, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3468872
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan CG, 2021, ACM T MULTIM COMPUT, V16, DOI 10.1145/3404374
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang TJ, 2020, IEEE ACCESS, V8, P135118, DOI 10.1109/ACCESS.2020.3006067
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Zhang BC, 2017, IEEE T IMAGE PROCESS, V26, P4648, DOI 10.1109/TIP.2017.2718189
   Zhu X., 2022, ACM T MULTIM COMPUT, V18, P1
NR 58
TC 2
Z9 2
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103641
DI 10.1016/j.jvcir.2022.103641
EA OCT 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5Q4MG
UT WOS:000873807300002
DA 2024-07-18
ER

PT J
AU Lin, SY
   Zhang, YJ
AF Lin, ShaoYue
   Zhang, YanJun
TI ACGAN: Attribute controllable person image synthesis GAN for pose
   transfer
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE GAN; Personimagesynthesis; Artifact
ID COMPRESSION
AB At present, pose transfer and attribute control tasks are still the challenges for image synthesis network. At the same time, there are often artifacts in the images generated by the image synthesis network when the above two tasks are completed. The existence of artifacts causes the loss of the generated image details or introduces some wrong image information, which leads to the decline of the overall performance of the existing work. In this paper, a generative adversarial network (GAN) named ACGAN is proposed to accomplish the above two tasks and effectively eliminate artifacts in generated images. The proposed network was compared quantitatively and qualitatively with previous works on the DeepFashion dataset and better results are obtained. Moreover, the overall network has advantages over the previous works in speed and number of parameters.
C1 [Lin, ShaoYue] Beijing Inst Technol, Sch Integrated Circuits & Elect, Beijing 100081, Peoples R China.
   [Zhang, YanJun] Beijing Inst Technol, Sch Cyberspace Sci & Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology; Beijing Institute of Technology
RP Zhang, YJ (corresponding author), Beijing Inst Technol, Sch Cyberspace Sci & Technol, Beijing 100081, Peoples R China.
EM 3120190678@bit.edu.cn; zhangyj@bit.edu.cn
RI Zhang, Yanjun/KVA-5254-2024; Zhang, Yanjun/H-9057-2019
OI Zhang, Yanjun/0000-0003-3095-625X; Zhang, Yanjun/0000-0002-1036-8568
CR Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Galteri L, 2017, IEEE I CONF COMP VIS, P4836, DOI 10.1109/ICCV.2017.517
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow I., 2014, COMMUN ACM
   Hao Tang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P717, DOI 10.1007/978-3-030-58595-2_43
   Hensel M, 2017, ADV NEUR IN, V30
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Iwai S, 2021, INT C PATT RECOG, P8235, DOI 10.1109/ICPR48806.2021.9412185
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Lv ZY, 2021, PROC CVPR IEEE, P10801, DOI 10.1109/CVPR46437.2021.01066
   Ma LQ, 2017, ADV NEUR IN, V30
   Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018
   Ma T, 2021, IEEE C COMPUT VIS PA
   Mameli F, 2021, INT C PATT RECOG, P9326, DOI 10.1109/ICPR48806.2021.9413095
   Mechrez R, 2018, LECT NOTES COMPUT SC, V11218, P800, DOI 10.1007/978-3-030-01264-9_47
   Men YF, 2020, PROC CVPR IEEE, P5083, DOI 10.1109/CVPR42600.2020.00513
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Ren YR, 2020, IEEE T IMAGE PROCESS, V29, P8622, DOI 10.1109/TIP.2020.3018224
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Sun XX, 2019, PROC CVPR IEEE, P608, DOI 10.1109/CVPR.2019.00070
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Zhang JS, 2021, PROC CVPR IEEE, P7978, DOI 10.1109/CVPR46437.2021.00789
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
NR 29
TC 2
Z9 2
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103572
DI 10.1016/j.jvcir.2022.103572
EA JUL 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 3C7GN
UT WOS:000828788400004
DA 2024-07-18
ER

PT J
AU Mohammadi, A
AF Mohammadi, Ammar
TI A general framework for reversible data hiding in encrypted images by
   reserving room before encryption
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Encrypted image; Local difference; Prediction-errors; Reversible data
   hiding
ID EXPANSION; ALGORITHM
AB In this paper a general framework to adopt different predictors for reversible data hiding in the encrypted image is presented. Employing linear regression, we propose innovative predictors that contribute more significantly to accomplish more payload than conventional ones. Reserving room before encryption (RRBE) is designated in the proposed scheme making possible to attain high embedding capacity. In RRBE procedure, pre-processing is allowed before image encryption. In our scheme, pre-processing comprises of three main steps: computing prediction-errors, blocking and labeling of the errors. By blocking, we obviate the need for lossless compression to when a content owner is not enthusiastic. Lossless compression is employed in recent state of the art schemes to improve payload. We surpass the prior arts exploiting proper predictors, more efficient labeling procedure and blocking of the prediction-errors.
C1 [Mohammadi, Ammar] Yazd Univ, Dept Elect Engn, Yazd 89195741, Iran.
C3 University of Yazd
RP Mohammadi, A (corresponding author), Yazd Univ, Dept Elect Engn, Yazd 89195741, Iran.
EM mohammadi_a@stu.yazd.ac.ir
CR [Anonymous], Miscellaneous Image Transformations - Thresholding
   [Anonymous], 2011, P 13 INF HID C PRAG
   Bas P., 2017, Image database of bows-2, V20
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen YC, 2019, IEEE T INF FOREN SEC, V14, P3332, DOI 10.1109/TIFS.2019.2914557
   Ge HL, 2019, IEEE T CIRC SYST VID, V29, P2285, DOI 10.1109/TCSVT.2018.2863029
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Johnson M, 2004, IEEE T SIGNAL PROCES, V52, P2992, DOI 10.1109/TSP.2004.833860
   Kalker T, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P71, DOI 10.1109/ICDSP.2002.1027818
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liu W, 2010, IEEE T IMAGE PROCESS, V19, P1097, DOI 10.1109/TIP.2009.2038773
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mohammadi A, 2019, ARXIV PREPRINT ARXIV
   Mohammadi A, 2021, MULTIMED TOOLS APPL, V80, P3307, DOI 10.1007/s11042-020-09719-3
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Weber A., 1997, The usc-sipi image database
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Wu YQ, 2020, IEEE T MULTIMEDIA, V22, P1929, DOI 10.1109/TMM.2019.2952979
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Yan X., 2009, LINEAR REGRESSION AN
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Yi S, 2019, IEEE T MULTIMEDIA, V21, P51, DOI 10.1109/TMM.2018.2844679
   Yin ZX, 2022, IEEE T DEPEND SECURE, V19, P992, DOI 10.1109/TDSC.2020.3019490
   Yin ZX, 2020, IEEE T MULTIMEDIA, V22, P874, DOI 10.1109/TMM.2019.2936314
   Yin Zhaoxia, 2014, ScientificWorldJournal, V2014, P604876, DOI 10.1155/2014/604876
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2013, SECUR COMMUN NETW, V6, P1396, DOI 10.1002/sec.742
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 51
TC 3
Z9 4
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103478
DI 10.1016/j.jvcir.2022.103478
EA MAR 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L4DL
UT WOS:000799240600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rashmi, M
   Guddeti, RMR
AF Rashmi, M.
   Guddeti, Ram Mohana Reddy
TI Human identification system using 3D skeleton-based gait features and
   LSTM model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Biometric; Deep learning; Gait recognition; Human identification; Long
   Short Term Memory (LSTM); Smart surveillance
ID RECOGNITION
AB Vision-based gait emerged as the preferred biometric in smart surveillance systems due to its unobtrusive nature. Recent advancements in low-cost depth sensors resulted in numerous 3D skeleton-based gait analysis techniques. For spatial-temporal analysis, existing state-of-the-art algorithms use frame-level information as the timestamp. This paper proposes gait event-level spatial-temporal features and LSTM-based deep learning model that treats each gait event as a timestamp to identify individuals from walking patterns observed in single and multi-view scenarios. On four publicly available datasets, the proposed system stands superior to state-ofthe-art approaches utilizing a variety of conventional benchmark protocols. The proposed system achieved a recognition rate of greater than 99% in low-level ranks during the CMC test, making it suitable for practical applications. The statistical study of gait event-level features demonstrated retrieved features' discriminating capacity in classification. Additionally, the ANOVA test performed on findings from K folds demonstrated the proposed system's significance in human identification.
C1 [Rashmi, M.; Guddeti, Ram Mohana Reddy] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Rashmi, M (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore 575025, Karnataka, India.
EM nm.rashmi@gmail.com; profgrmreddy@nitk.edu.in
OI M, Rashmi/0000-0003-2101-5992
CR AAT Bioquest, QUEST GRAPHTM ANOVA
   Andersson VO, 2015, AAAI CONF ARTIF INTE, P425
   Araujo R.M., 2013, Proceedings of the 28th Annual ACM Symposium on Applied Computing, P21
   Bari ASMH, 2019, IEEE ACCESS, V7, P162708, DOI 10.1109/ACCESS.2019.2952065
   Bobillo F, 2017, LECT NOTES ARTIF INT, V10564, P397, DOI 10.1007/978-3-319-67582-4_29
   Boyd JE, 2005, LECT NOTES COMPUT SC, V3161, P19
   Chen YT, 2021, APPL INTELL, V51, P4367, DOI 10.1007/s10489-020-02116-1
   Chen YT, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02778-2
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P4237, DOI 10.1007/s11042-020-09887-2
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Choi S, 2019, IEEE T INF FOREN SEC, V14, P2577, DOI 10.1109/TIFS.2019.2901823
   Chollet F., 2015, KERAS
   Deng MQ, 2019, IEEE T CIRC SYST VID, V29, P3636, DOI 10.1109/TCSVT.2018.2883449
   Deng MQ, 2017, PATTERN RECOGN, V67, P186, DOI 10.1016/j.patcog.2017.02.014
   Dikovski B, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1304, DOI 10.1109/MIPRO.2014.6859769
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hosni N, 2020, IEEE COMPUT SOC CONF, P3716, DOI 10.1109/CVPRW50498.2020.00434
   Huynh-The T, 2020, NEUROCOMPUTING, V397, P192, DOI 10.1016/j.neucom.2020.02.048
   Ince OF, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P561, DOI 10.1109/ECTICon.2017.8096299
   Jian-De Li, 2017, 2017 IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT), DOI 10.1109/DFT.2017.8244448
   Justus D, 2018, IEEE INT CONF BIG DA, P3873, DOI 10.1109/BigData.2018.8622396
   Kastaniotis D, 2013, INT CONF DIGIT SIG
   Kastaniotis D, 2016, PATTERN RECOGN LETT, V84, P245, DOI 10.1016/j.patrec.2016.10.012
   Kastaniotis D, 2015, PATTERN RECOGN LETT, V68, P327, DOI 10.1016/j.patrec.2015.06.020
   Khamsemanan N, 2018, IEEE T INF FOREN SEC, V13, P119, DOI 10.1109/TIFS.2017.2738611
   King DB, 2015, ACS SYM SER, V1214, P1
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Liao RJ, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107069
   Limcharoen P, 2021, IEEE ACCESS, V9, P112057, DOI 10.1109/ACCESS.2021.3102936
   Limcharoen P, 2020, IEEE T INF FOREN SEC, V15, P3430, DOI 10.1109/TIFS.2020.2985535
   Liu JY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P663
   Liu Y., 2019, 2019 16 IEEE INT C A, P1, DOI [DOI 10.1109/AVSS.2019.8909881, 10.1109/AVSS.2019.8909881]
   Nambiar A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P108, DOI 10.5220/0006165301080119
   Nambiar A, 2017, IEEE INT CONF AUTOMA, P973, DOI 10.1109/FG.2017.121
   Rahman MW, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P423, DOI 10.1109/ICCI-CC.2017.8109783
   Rao H., 2020, ARXIV PREPRINT ARXIV
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Sheikholeslami S, 2021, PROCEEDINGS OF THE 1ST WORKSHOP ON MACHINE LEARNING AND SYSTEMS (EUROMLSYS'21), P55, DOI 10.1145/3437984.3458834
   Tsironi E, 2017, NEUROCOMPUTING, V268, P76, DOI 10.1016/j.neucom.2016.12.088
   Hoang VN, 2019, 2019 INTERNATIONAL CONFERENCE ON MULTIMEDIA ANALYSIS AND PATTERN RECOGNITION (MAPR), DOI 10.1109/mapr.2019.8743545
   Wan CS, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3230633
   Webster JB, 2019, Atlas of orthoses and assistive devices, V5th, DOI [DOI 10.1016/C2014-0-04193-7, 10.1016/C2014-0-04193-7]
   Yang K, 2016, J VIS COMMUN IMAGE R, V39, P209, DOI 10.1016/j.jvcir.2016.05.020
   Zhang BY, 2019, IEEE T CIRCUITS-II, V66, P2052, DOI 10.1109/TCSII.2019.2899829
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao B, 2021, IEEE T IND ELECTRON, V68, P3629, DOI 10.1109/TIE.2020.2979573
   Zhao B, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P863, DOI 10.1145/3123266.3123328
   Zhao Bin, 2021, IEEE T PATTERN ANAL
NR 52
TC 8
Z9 8
U1 2
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103416
DI 10.1016/j.jvcir.2021.103416
EA JAN 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I8FF
UT WOS:000779649200001
DA 2024-07-18
ER

PT J
AU Barkoky, A
   Charkari, NM
AF Barkoky, Alaa
   Charkari, Nasrollah Moghaddam
TI Complex Network-based features extraction in RGB-D human action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human action recognition; Complex network; Meta-path; 3D skeleton joints
ID DEPTH; ENSEMBLE
AB Analysis of human behavior through visual information has been one of the active research areas in computer vision community during the last decade. Vision-based human action recognition (HAR) is a crucial part of human behavior analysis, which is also of great demand in a wide range of applications. HAR was initially performed via images from a conventional camera; however, depth sensors have recently embedded as an additional informative resource to cameras. In this paper, we have proposed a novel approach to largely improve the performance of human action recognition using Complex Network-based feature extraction from RGB-D information. Accordingly, the constructed complex network is employed for single-person action recognition from skeletal data consisting of 3D positions of body joints. The indirect features help the model cope with the majority of challenges in action recognition. In this paper, the meta-path concept in the complex network has been presented to lessen the unusual actions structure challenges. Further, it boosts recognition performance. The extensive experimental results on two widely adopted benchmark datasets, the MSR-Action Pairs, and MSR Daily Activity3D indicate the efficiency and validity of the method.
C1 [Barkoky, Alaa; Charkari, Nasrollah Moghaddam] Tarbiat Modares Univ, Image Proc Lab, Dept Elect Engn & Comp Sci, Tehran, Iran.
C3 Tarbiat Modares University
RP Charkari, NM (corresponding author), Tarbiat Modares Univ, Image Proc Lab, Dept Elect Engn & Comp Sci, Tehran, Iran.
EM barkoky@modares.ac.ir; charkari@modares.ac.ir
OI moghaddam charkari, nasrollah/0000-0003-1871-7977
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Ahad MAR, 2021, PATTERN RECOGN LETT, V145, P216, DOI 10.1016/j.patrec.2021.02.013
   Al-Faris M, 2020, PATTERN ANAL APPL, V23, P1587, DOI 10.1007/s10044-020-00886-5
   Chaaraoui AA, 2014, IEEE T AUTON MENT DE, V6, P139, DOI 10.1109/TAMD.2014.2315676
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], 2012, J Comput Vis Image Process
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bloom V., 2012, 2012 IEEE COMP SOC C
   Celiktutan Oya, 2013, P 1 ACM INT WORKSH M
   Chaaraoui AA, 2014, ENG APPL ARTIF INTEL, V31, P116, DOI 10.1016/j.engappai.2013.10.003
   Chen LL, 2014, PATTERN RECOGN LETT, V50, P159, DOI 10.1016/j.patrec.2013.09.004
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chen WB, 2015, J VIS COMMUN IMAGE R, V26, P182, DOI 10.1016/j.jvcir.2014.11.008
   Cho SS, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.3.033102
   Climent-Perez Pau, 2013, Advances in Computational Intelligence. 11th Mexican International Conference on Artificial Intelligence, MICAI 2012. Revised Selected Papers, P163
   Costa LD, 2007, ADV PHYS, V56, P167, DOI 10.1080/00018730601170527
   De Boissiere AM, 2020, IEEE ACCESS, V8, P168297, DOI 10.1109/ACCESS.2020.3023599
   Dong Wenkai, 2019, P AAAI C ART INT, V33
   Eweiwi Abdalrahman, 2014, EFFICIENT POSE BASED
   Firman M, 2016, IEEE COMPUT SOC CONF, P661, DOI 10.1109/CVPRW.2016.88
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Gu Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.004
   Guan GL, 2013, IEEE T CIRC SYST VID, V23, P729, DOI 10.1109/TCSVT.2012.2214871
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Ji YL, 2018, SIGNAL PROCESS, V143, P364, DOI 10.1016/j.sigpro.2017.06.001
   Kapsouras I, 2019, MULTIMED TOOLS APPL, V78, P1971, DOI 10.1007/s11042-018-6209-9
   Ke Jina, 2017, The Journal of Engineering, DOI 10.1049/joe.2016.0330
   Kerboua A., 2019, INT J INTELL SYST AP, V11, P42, DOI DOI 10.5815/IJISA.2019.03.05
   Kerola Tommi, 2014, ASIAN C COMPUTER VIS
   Kong J, 2019, J VIS COMMUN IMAGE R, V59, P537, DOI 10.1016/j.jvcir.2019.02.013
   Lee S, 2013, EXPERT SYST APPL, V40, P684, DOI 10.1016/j.eswa.2012.08.004
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li W, 2017, IEEE I CONF COMP VIS, P1453, DOI 10.1109/ICCV.2017.161
   Liang Bin, 2018, AUSTR C DAT MIN
   Lin YY, 2014, PROC CVPR IEEE, P2617, DOI 10.1109/CVPR.2014.335
   Liu AA, 2015, SIGNAL PROCESS, V112, P74, DOI 10.1016/j.sigpro.2014.08.038
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Memmesheimer R, 2020, IEEE INT C INT ROBOT, P10394, DOI 10.1109/IROS45743.2020.9341699
   Núñez JC, 2018, PATTERN RECOGN, V76, P80, DOI 10.1016/j.patcog.2017.10.033
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Rajput AS, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113349
   Sempena S., 2011, EL ENG INF ICEEI 201
   Singh T, 2021, NEURAL COMPUT APPL, V33, P469, DOI 10.1007/s00521-020-05018-y
   Sun YZ, 2013, TSINGHUA SCI TECHNOL, V18, P329, DOI 10.1109/TST.2013.6574671
   Sun YZ, 2011, 2011 INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2011), P121, DOI 10.1109/ASONAM.2011.112
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Van Steen Maarten, 2010, INTRODUCTION144
   Wang J, 2014, SPRINGERBRIEF COMPUT, P1, DOI 10.1007/978-3-319-04561-0
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang YX, 2015, J VIS COMMUN IMAGE R, V33, P193, DOI 10.1016/j.jvcir.2015.09.013
   Wei-Chin Hung, 2014, International Journal of Machine Learning and Computing, V4, P405, DOI 10.7763/IJMLC.2014.V4.445
   Yan S., 2018, AAAI, P1
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhao YX, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-15
   Zhou Y, 2016, PATTERN RECOGN LETT, V83, P261, DOI 10.1016/j.patrec.2016.07.025
NR 63
TC 10
Z9 10
U1 2
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103371
DI 10.1016/j.jvcir.2021.103371
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400003
DA 2024-07-18
ER

PT J
AU Hu, JB
   Wang, XJ
   Chai, XL
   Shao, F
   Jiang, QP
AF Hu, Jinbin
   Wang, Xuejin
   Chai, Xiongli
   Shao, Feng
   Jiang, Qiuping
TI Deep network based stereoscopic image quality assessment via binocular
   summing and differencing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic image quality assessment; Deep regression network;
   Binocular summing; Binocular differencing
AB With the development of deep networks in dealing with various visual tasks, the deep network based on binocular vision is expected to tackle the issue of stereoscopic image quality assessment. Here, we present a stereoscopic image quality assessment method using the deep network with four channels together, which takes the left view, right view, binocular summing view, and binocular differencing view as the inputs of the network. The visual features are enhanced through the concatenation in a weighted way, so that the binocular vision can be adequately included in the binocular addition and subtraction information. Compared with the state-of-the-art metrics, the proposed method exhibits relatively high performances on four benchmark databases.
C1 [Hu, Jinbin; Wang, Xuejin; Chai, Xiongli; Shao, Feng; Jiang, Qiuping] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
C3 Ningbo University
RP Shao, F (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Peoples R China.
EM shaofeng@nbu.edu.cn
RI Hu, Jinbin/KIL-1700-2024; Jiang, Qiuping/AAL-8273-2020
OI Hu, Jinbin/0000-0003-1610-8537; 
FU Natural Science Foundation of China [R18F010008]; K.C. Wong Magna Fund
   inNingbo University
FX Acknowledgments This work was supported by the Natural Science
   Foundation of China (grant 62071261) , and Natural Science Foundation of
   China (grant R18F010008) . It was also sponsored by K.C. Wong Magna Fund
   inNingbo University.
CR Appina B, 2016, SIGNAL PROCESS-IMAGE, V43, P1, DOI 10.1016/j.image.2016.02.001
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Chen YL, 2016, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON ADVANCED MATERIALS FOR SCIENCE AND ENGINEERING (IEEE-ICAMSE 2016), P9, DOI 10.1109/ICAMSE.2016.7840217
   Chong ZH, 2016, INT C CONTR AUTOMAT, P377, DOI 10.1109/ICCAS.2016.7832347
   Fang YM, 2019, J VIS COMMUN IMAGE R, V58, P400, DOI 10.1016/j.jvcir.2018.12.006
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Hancheng Zhu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14131, DOI 10.1109/CVPR42600.2020.01415
   Hong SM, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23283
   Hong S, 2016, 23RD ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2016), DOI 10.14722/ndss.2016.23458
   Jiang QP, 2019, IEEE T CIRC SYST VID, V29, P323, DOI 10.1109/TCSVT.2017.2783938
   Jiang XH, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2019.102745
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Kingdom FAA, 2019, J VISION, V19, DOI 10.1167/19.14.18
   Kingdom FAA, 2012, CURR BIOL, V22, pR22, DOI 10.1016/j.cub.2011.11.048
   Kingma D. P., 2014, arXiv
   Ko H, 2017, J VIS COMMUN IMAGE R, V45, P156, DOI 10.1016/j.jvcir.2017.02.014
   Li QH, 2016, IEEE SIGNAL PROC LET, V23, P541, DOI 10.1109/LSP.2016.2537321
   LI ZP, 1994, NETWORK-COMP NEURAL, V5, P157, DOI 10.1088/0954-898X/5/2/003
   Md SK, 2015, IEEE SIGNAL PROC LET, V22, P1985, DOI 10.1109/LSP.2015.2449878
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Oh H, 2017, IEEE T IMAGE PROCESS, V26, P4923, DOI 10.1109/TIP.2017.2725584
   PETTIGREW JD, 1972, SCI AM, V227, P84, DOI 10.1038/scientificamerican0872-84
   Read J.C.A., 2019, J VISUAL-JAPAN, V19, P1
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shao F, 2018, IEEE T MULTIMEDIA, V20, P2605, DOI 10.1109/TMM.2018.2817072
   Shao F, 2017, IEEE T MULTIMEDIA, V19, P1821, DOI 10.1109/TMM.2017.2685240
   Shao F, 2015, IEEE T BROADCAST, V61, P154, DOI 10.1109/TBC.2015.2402491
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Shen LQ, 2019, IEEE TETCI, V3, P59, DOI 10.1109/TETCI.2018.2804885
   Stidwill D, 2010, OPTOMETRY TODAY
   Szabó R, 2016, APPLIED ELECTRONICS, P265, DOI 10.1109/AE.2016.7577287
   Wang X, 2015, NEUROCOMPUTING, V151, P683, DOI 10.1016/j.neucom.2014.05.090
   Wang XJ, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102868
   Xiong YM, 2019, IEEE ACCESS, V7, P106295, DOI 10.1109/ACCESS.2019.2932015
   Jiang XH, 2020, NEUROCOMPUTING, V386, P30, DOI 10.1016/j.neucom.2019.12.027
   Yang JC, 2019, INFORM SCIENCES, V474, P1, DOI 10.1016/j.ins.2018.08.066
   Yang JC, 2019, IEEE T IMAGE PROCESS, V28, P1314, DOI 10.1109/TIP.2018.2878283
   Yang JC, 2015, J VIS COMMUN IMAGE R, V31, P138, DOI 10.1016/j.jvcir.2015.06.002
   Yang Xiaocui, 2020, IEEE Transactions on Multimedia
   Zhai GT, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2757-1
   Zhang WX, 2021, IEEE T IMAGE PROCESS, V30, P3474, DOI 10.1109/TIP.2021.3061932
   Zhou WJ, 2020, IEEE T COMPUT IMAG, V6, P883, DOI 10.1109/TCI.2020.2993640
   Zhou WJ, 2016, IEEE T MULTIMEDIA, V18, P1077, DOI 10.1109/TMM.2016.2542580
NR 49
TC 5
Z9 5
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103420
DI 10.1016/j.jvcir.2021.103420
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7ZE
UT WOS:000779633400002
DA 2024-07-18
ER

PT J
AU Huang, SB
   Yang, K
   Xiao, H
   Han, P
   Qiu, J
   Peng, L
   Liu, DM
   Luo, KQ
AF Huang, Suibin
   Yang, Kun
   Xiao, Hua
   Han, Peng
   Qiu, Jian
   Peng, Li
   Liu, Dongmei
   Luo, Kaiqing
TI A new head pose tracking method based on stereo visual SLAM
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Head pose tracking; Stereo visual SLAM; Bundle adjustment
ID DEPTH
AB Real-time and reliable head pose tracking is the basis of human-computer interaction and face analysis applications. Aiming at the problems of accuracy and real time performance in current tracking method, a new head pose tracking method based on stereo visual SLAM is proposed in this paper. The sparse head map is constructed based on ORB feature points extraction and stereo matching, then the 3D-2D matching relations between 3D mappoints and 2D feature points are obtained by projection matching. Finally, the camera pose solved by the Bundle Adjustment is converted to head pose, which realizes the tracking of head pose. The experimental results show that this method can obtain high precise head pose. The mean errors of three Euler angles are all less than 1(degrees). Therefore, the proposed head pose tracking method can track and estimate precise head pose in real time under smooth background.
C1 [Huang, Suibin; Yang, Kun; Xiao, Hua; Han, Peng; Qiu, Jian; Peng, Li; Liu, Dongmei; Luo, Kaiqing] South China Normal Univ, Sch Phys & Telecommun Engn, Guangdong Prov Key Lab Quantum Engn & Quantum Mat, Guangzhou 510006, Peoples R China.
   [Huang, Suibin; Han, Peng; Qiu, Jian; Peng, Li; Liu, Dongmei; Luo, Kaiqing] South China Normal Univ, Guangdong Hong Kong Joint Lab Quantum Matter, Guangzhou 510006, Peoples R China.
   [Huang, Suibin; Han, Peng; Qiu, Jian; Peng, Li; Liu, Dongmei; Luo, Kaiqing] South China Normal Univ, Guangdong Prov Engn Res Ctr Optoelect Instrument, Guangzhou 510006, Peoples R China.
   [Huang, Suibin; Han, Peng; Qiu, Jian; Peng, Li; Liu, Dongmei; Luo, Kaiqing] SCNU Qingyuan Inst Sci & Technol Innovat, Qingyuan 511517, Peoples R China.
C3 South China Normal University; South China Normal University; South
   China Normal University
RP Luo, KQ (corresponding author), South China Normal Univ, Sch Phys & Telecommun Engn, Guangdong Prov Key Lab Quantum Engn & Quantum Mat, Guangzhou 510006, Peoples R China.
EM suibinh@m.scnu.edu.cn; xiaoh@scnu.edu.cn; hanp@scnu.edu.cn;
   qiuj@scnu.edu.cn; pengli@m.scnu.edu.cn; dmliu@scnu.edu.cn;
   kqluo@scnu.edu.cn
RI Xiao, Hua/E-9914-2013; Luo, Kaiqing/ABD-6166-2020
OI Luo, Kaiqing/0000-0002-6278-0917
FU National Natural Science Foundation of China [61975058]; Natural Science
   Foundation of Guangdong Prov-ince [2019A1515011401]; Science and
   Technology Program of Guangzhou [2019050001]; Science and Technological
   Plan of Guangdong Province [2019B090905005]; National Natural Science
   Foundation of China-Guangdong big data Science Center Project [U1911401]
FX Funding This work was supported by the National Natural Science
   Foundation of China (61975058) ; Natural Science Foundation of Guangdong
   Prov-ince (2019A1515011401) ; Science and Technology Program of
   Guangzhou (2019050001) ; The Science and Technological Plan of Guangdong
   Province (2019B090905005) ; The National Natural Science Foundation of
   China-Guangdong big data Science Center Project (U1911401) .
CR Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Barros JMD, 2018, IEEE WINT CONF APPL, P2028, DOI 10.1109/WACV.2018.00224
   Borghi G, 2020, IEEE T PATTERN ANAL, V42, P596, DOI 10.1109/TPAMI.2018.2885472
   Borghi G, 2017, PROC CVPR IEEE, P5494, DOI 10.1109/CVPR.2017.583
   Breitenstein MD, 2009, LECT NOTES COMPUT SC, V5575, P219, DOI 10.1007/978-3-642-02230-2_23
   Chen Y, 2014, CHIN CONTR CONF, P8277, DOI 10.1109/ChiCC.2014.6896387
   Derkach D, 2017, IEEE INT CONF AUTOMA, P820, DOI 10.1109/FG.2017.104
   Drouard V, 2017, IEEE WINT CONF APPL, P1232, DOI 10.1109/WACV.2017.142
   Drouard V, 2015, IEEE IMAGE PROC, P4624, DOI 10.1109/ICIP.2015.7351683
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Gurbuz S, 2012, PATTERN RECOGN, V45, P33, DOI 10.1016/j.patcog.2011.06.007
   Hamzah RA, 2010, INT CONF COMP SCI, P652, DOI 10.1109/ICCSIT.2010.5565062
   Khan K, 2021, CMC-COMPUT MATER CON, V66, P1757, DOI 10.32604/cmc.2020.013590
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Li XH, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P673, DOI 10.1109/ICACI.2012.6463252
   Liu K, 2017, INT CONF SYST INFORM, P220, DOI 10.1109/ICSAI.2017.8248293
   Luo CW, 2019, IEEE T MULTIMEDIA, V21, P2473, DOI 10.1109/TMM.2019.2903724
   Meyer GP, 2015, IEEE I CONF COMP VIS, P3649, DOI 10.1109/ICCV.2015.416
   Moreno-Noguer F, 2007, IEEE I CONF COMP VIS, P2252
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Pratomo BA, 2018, 2018 INTERNATIONAL CONFERENCE ON CYBER SECURITY AND PROTECTION OF DIGITAL SERVICES (CYBER SECURITY)
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rossi S, 2016, LECT NOTES COMPUT SC, V10037, P89, DOI 10.1007/978-3-319-49130-1_8
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Seemann E, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P626, DOI 10.1109/AFGR.2004.1301603
   Shou-Yi Tseng, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P401, DOI 10.1109/CSIE.2009.662
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Wongphanngam J., 2016, P 2016 13 INT C ELEC, P1
   Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118
   Yin D, 2020, IEEE ACCESS, V8, P127134, DOI 10.1109/ACCESS.2020.3008457
   Yuan H, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107316
   Zhang ZQ, 2007, LECT NOTES COMPUT SC, V4122, P299
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 38
TC 3
Z9 3
U1 3
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2022
VL 82
AR 103402
DI 10.1016/j.jvcir.2021.103402
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0V1MU
UT WOS:000788110200003
DA 2024-07-18
ER

PT J
AU Kumar, A
   Jha, RK
   Nishchal, NK
AF Kumar, Avishek
   Jha, Rajib Kumar
   Nishchal, Naveen K.
TI A multi-exposure fusion framework for contrast enhancement of hazy
   images employing dynamic stochastic resonance*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic stochastic resonance; Image dehazing; Restoration; Weight maps;
   Multi-scale fusion; Modified atmospheric scattering equation
ID SINGLE IMAGE; QUALITY ASSESSMENT; DARK
AB Current imaging devices coupled with advanced hardware and software are smart enough to enhance low light images taken in clear weather. But in hazy or foggy environments, the captured images are of degraded quality. To address this issue, image processing algorithms are employed to enhance the degraded images to make useful for extracting meaningful features. In this study, we propose a haze removal algorithm to improve the color and contrast of images captured in hazy environments. The first step involves generation of images with various exposures using the theory of dynamic stochastic resonance. The images are then fused in a multi-scale fusion framework crafting weight maps viz. haze density, chromaticity, and luminance gradient. The fusion process focuses on uniformly enhancing the dark and bright regions of the image. However, it may overemphasize haze affected regions. Therefore, in the second step, the atmospheric scattering equation is referred and its modified version is applied that accomplishes the haze removal task. Quantitative and qualitative analyses demonstrate the effectiveness of the proposed method.
C1 [Kumar, Avishek; Jha, Rajib Kumar] Indian Inst Technol Patna, Dept Elect Engn, Bihta 801106, Bihar, India.
   [Nishchal, Naveen K.] Indian Inst Technol Patna, Dept Phys, Bihta 801106, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Technology (IIT) - Patna
RP Nishchal, NK (corresponding author), Indian Inst Technol Patna, Dept Phys, Bihta 801106, Bihar, India.
EM avishek.srf16@iitp.ac.in; jharajib@iitp.ac.in; nkn@iitp.ac.in
OI Nishchal, Naveen/0000-0001-7032-3946
FU CSIR [09/1023 (0021) /2018-EMR-I]
FX The authors would like to acknowledge the funding from CSIR, Govt. of
   India, under Grant No. 09/1023 (0021) /2018-EMR-I.
CR Agrawal SC, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103087
   Amer KO, 2019, OPT EXPRESS, V27, P621, DOI 10.1364/OE.27.000621
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Babu GH, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jveir.2020.102912
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chouhan R, 2013, IET IMAGE PROCESS, V7, P174, DOI 10.1049/iet-ipr.2012.0114
   Ngo D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185170
   Fang S, 2014, OPT EXPRESS, V22, P19523, DOI 10.1364/OE.22.019523
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Gao YY, 2019, IEEE T MULTIMEDIA, V21, P351, DOI 10.1109/TMM.2018.2856095
   GUO LJ, 1991, INT J REMOTE SENS, V12, P2133, DOI 10.1080/01431169108955241
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jiao SM, 2019, OPT EXPRESS, V27, P12841, DOI 10.1364/OE.27.012841
   Kumar A, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103122
   Lam EY, 2009, IMAGE PROCESS SER, P267
   Lee SH, 2018, IEEE IMAGE PROC, P1737, DOI 10.1109/ICIP.2018.8451153
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   Liang J, 2015, OPT EXPRESS, V23, P26146, DOI 10.1364/OE.23.026146
   Ling ZG, 2018, IEEE T MULTIMEDIA, V20, P1699, DOI 10.1109/TMM.2017.2778565
   Liu F, 2015, APPL OPTICS, V54, P8116, DOI 10.1364/AO.54.008116
   Mehra I, 2014, OPT EXPRESS, V22, P5474, DOI 10.1364/OE.22.005474
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Nair D, 2018, J VIS COMMUN IMAGE R, V50, P9, DOI 10.1016/j.jvcir.2017.11.005
   Nishchal NK, 2020, IOP SER ADV OPT PHOT, P1, DOI 10.1088/978-0-7503-2220-1
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Riaz I, 2016, J VIS COMMUN IMAGE R, V40, P85, DOI 10.1016/j.jvcir.2016.06.011
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sahu G, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103008
   Salazar-Colores S, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043022
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Sharma G, 2005, COLOR RES APPL, V30, P21, DOI 10.1002/col.20070
   Shiau YH, 2014, J VIS COMMUN IMAGE R, V25, P445, DOI 10.1016/j.jvcir.2013.12.011
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang X, 2021, OPT EXPRESS, V29, P12010, DOI 10.1364/OE.421937
   Yu T, 2019, IEEE ACCESS, V7, P114619, DOI 10.1109/ACCESS.2019.2936049
   Zhang WF, 2017, APPL OPTICS, V56, P942, DOI 10.1364/AO.56.000942
   Zhang YF, 2017, IEEE IMAGE PROC, P3205, DOI 10.1109/ICIP.2017.8296874
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zosso D., 2014, PRIMAL DUAL PROJECTE
NR 53
TC 5
Z9 5
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2021
VL 81
AR 103376
DI 10.1016/j.jvcir.2021.103376
EA NOV 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA XK3OJ
UT WOS:000727378900002
DA 2024-07-18
ER

PT J
AU Qin, CA
   Zhang, WM
   Dong, XY
   Zha, HY
   Yu, NH
AF Qin, Chuan
   Zhang, Weiming
   Dong, Xiaoyi
   Zha, Hongyue
   Yu, Nenghai
TI Adversarial steganography based on sparse cover enhancement
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganography; Adversarial example; Deep neural network
ID STEGANALYSIS; FEATURES
AB CNN (Convolutional Neural Network) steganalyzers achieve enormous improvements in detecting stego images. However, they are easily deceived by adversarial steganography, which combines adversarial attack and steganography. Currently, there are two kinds of adversarial steganography, function separation and cover enhancement. ADV-EMB (ADVersarial EMBedding) is a typical function separation method. It forces the steganographic modifications along side the gradient directions of the target CNN steganalyzer on partial image elements. It results in relatively low deceiving success rate against the target model. ADS (ADversarial Steganography) is the first adversarial steganography, which is based on cover enhancement. It introduces much distortions, so it can be easily detected by non-target steganalyzers. To overcome such defects of the previous works, in this paper, we propose a novel cover enhancement method, denoted as SPS-ENH (SParSe ENHancement). Through sparse +/- 1 adversarial perturbations, we effectively compress the distortions caused in cover enhancement. In addition, a re-trying scheme is introduced to further reduce the distortion scale. Extensive experiments show that the proposed method outperforms the previous works in the average classification error rates under non-target steganalyzers and deceiving success rates against target CNN models. When combining with the min-max strategy, the proposed method converges in less iterations and provides higher security level than ADV-EMB.
C1 [Qin, Chuan; Zhang, Weiming; Dong, Xiaoyi; Zha, Hongyue; Yu, Nenghai] Chinese Acad Sci, Sch Informat Sci & Technol, Key Lab Electromagnet Space Informat, Univ Sci & Technol China, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Chinese Acad Sci, Sch Informat Sci & Technol, Key Lab Electromagnet Space Informat, Univ Sci & Technol China, Beijing, Peoples R China.
EM qc94@mail.ustc.edu.cn; zhangwm@ustc.edu.cn; dlight@mail.ustc.edu.cn;
   zhahongyue@163.com; ynh@ustc.edu.cn
RI qin, chuan/ABG-4508-2020
OI Zha, Hongyue/0000-0002-8392-7850; Dong, Xiaoyi/0000-0002-4654-835X; Qin,
   Chuan/0000-0002-5841-8210
CR [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P., BOWS 2 CONTEST BREAK
   Bernard S, 2021, IEEE T INF FOREN SEC, V16, P812, DOI 10.1109/TIFS.2020.3021913
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cogranne R, 2014, IEEE INT WORKS INFOR, P167, DOI 10.1109/WIFS.2014.7084322
   Deng XQ, 2019, IH&MMSEC '19: PROCEEDINGS OF THE ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P230, DOI 10.1145/3335203.3335739
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J., 2009, STEGANOGRAPHY DIGITA, DOI [10.1017/CBO9781139192903, DOI 10.1017/CBO9781139192903]
   Fridrich J, 2007, PROC SPIE, V6505, DOI 10.1117/12.697471
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, INT C LEARN REPR ICL
   Li B, 2018, IEEE T INF FOREN SEC, V13, P1242, DOI 10.1109/TIFS.2017.2780805
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li PH, 2017, IEEE I CONF COMP VIS, P2089, DOI 10.1109/ICCV.2017.228
   Li WX, 2020, IEEE T COMMUN, V68, P3948, DOI 10.1109/TCOMM.2020.2982624
   Luo Y, 2015, ISPRS INTERNATIONAL WORKSHOP ON SPATIOTEMPORAL COMPUTING, P19, DOI 10.5194/isprsannals-II-4-W2-19-2015
   Ma S, 2021, J VIS COMMUN IMAGE R, V76, DOI 10.1016/j.jvcir.2021.103066
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qi BJ, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102814
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Rony J, 2019, PROC CVPR IEEE, P4317, DOI 10.1109/CVPR.2019.00445
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Sedighi V, 2015, PROC SPIE, V9409, DOI 10.1117/12.2080272
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tang WX, 2021, IEEE T INF FOREN SEC, V16, P952, DOI 10.1109/TIFS.2020.3025438
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Yang JH, 2020, IEEE T INF FOREN SEC, V15, P839, DOI 10.1109/TIFS.2019.2922229
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   You WK, 2021, IEEE T INF FOREN SEC, V16, P291, DOI 10.1109/TIFS.2020.3013204
   Zhang R, 2020, IEEE T INF FOREN SEC, V15, P1138, DOI 10.1109/TIFS.2019.2936913
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
NR 47
TC 13
Z9 13
U1 1
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103325
DI 10.1016/j.jvcir.2021.103325
EA OCT 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WK7DP
UT WOS:000709884500001
DA 2024-07-18
ER

PT J
AU Wen, Y
   Chen, LT
   Deng, Y
   Ning, J
   Zhou, C
AF Wen, Yang
   Chen, Leiting
   Deng, Yu
   Ning, Jin
   Zhou, Chuan
TI Towards better semantic consistency of 2D medical image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Convolutional neural network; Semantics; Deep
   learning
ID CRF; CNN
AB The latest deep neural networks for medical segmentation typically utilize transposed convolutional filters and atrous convolutional filters for spatial restoration and larger receptive fields, leading to dilution and inconsistency of visual semantics. To address such issues, we propose a novel attentional up-concatenation structure to build an auxiliary path for direct access to multi-level features. In addition, we employ a new structural loss to bring better morphological awareness and reduce the segmentation flaws caused by the semantic inconsistencies. Thorough experiments on the challenging optic cup/disc segmentation, cellular segmentation and lung segmentation tasks were performed to evaluate the proposed methods. Further ablation analysis demonstrated the effectiveness of the different components of the model and illustrated its efficiency. The proposed methods achieved the best performance and speed compared to the state-of-the-art models in three tasks on seven public datasets, including DRISHTI-GS, RIM-r3, REFUGE, MESSIDOR, TNBC, GlaS and LUNA.
C1 [Wen, Yang; Ning, Jin; Zhou, Chuan] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Key Lab Digital Media Technol Sichuan Prov, Chengdu 611731, Sichuan, Peoples R China.
   [Chen, Leiting] Univ Elect Sci & Technol China, Inst Elect & Informat Engn Guangdong, Chengdu 611731, Sichuan, Peoples R China.
   [Deng, Yu] Kings Coll London, Dept Biomed Engn, London, England.
C3 University of Electronic Science & Technology of China; University of
   Electronic Science & Technology of China; University of London; King's
   College London
RP Zhou, C (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Key Lab Digital Media Technol Sichuan Prov, Chengdu 611731, Sichuan, Peoples R China.
EM zhouchuan@uestc.edu.cn
RI Wen, Yang/AGZ-0325-2022
OI Wen, Yang/0000-0003-0561-6229; Zhou, Chuan/0000-0001-7700-7188
FU Sichuan Science and Technology Program
   [2019YJ0176/2019YJ0177/2019YFQ0005]
FX This study was supported by Sichuan Science and Technology Program (No.
   2019YJ0176/2019YJ0177/2019YFQ0005).
CR Almazroa A, 2018, PROC SPIE, V10579, DOI 10.1117/12.2293584
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Apostolopoulos Stefanos, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P294, DOI 10.1007/978-3-319-66179-7_34
   Caesar H, 2016, LECT NOTES COMPUT SC, V9905, P381, DOI 10.1007/978-3-319-46448-0_23
   Chen G, 2019, IEEE T MED IMAGING, V38, P1736, DOI 10.1109/TMI.2018.2890510
   Chen H, 2016, PROC CVPR IEEE, P2487, DOI 10.1109/CVPR.2016.273
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Ting., 2000, Image Segmentation Based on the Integration of Markov Random Fields and Deformable Models, P256
   Chen W., 2018, ARXIV PREPRINT ARXIV
   Cheng J, 2013, IEEE T MED IMAGING, V32, P1019, DOI 10.1109/TMI.2013.2247770
   Ciresan D., 2012, ADV NEURAL INFORM PR, V25, P2843
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Feng NQ, 2020, IEEE ACCESS, V8, P60505, DOI 10.1109/ACCESS.2020.2982197
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Fumero F, 2011, COMP MED SY
   Graham S, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101563
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Gu ZW, 2018, LECT NOTES COMPUT SC, V11039, P253, DOI 10.1007/978-3-030-00949-6_30
   Harley AW, 2017, IEEE I CONF COMP VIS, P5048, DOI 10.1109/ICCV.2017.539
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Heimann T., 2007, P MICCAI WORKSH 3 D, P161
   Hu JH, 2019, LANG FAC BEYOND, V15, P1, DOI 10.1075/lfab.15.01hu
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kaushal C, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P261, DOI [10.1109/iccmc.2019.8819659, 10.1109/ICCMC.2019.8819659]
   Kingma D. P., 2014, arXiv
   Kokkinos I., 2015, arXiv preprint arXiv:151107386
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Naylor P, 2019, IEEE T MED IMAGING, V38, P448, DOI 10.1109/TMI.2018.2865709
   Norman B, 2018, RADIOLOGY, V288, P177, DOI 10.1148/radiol.2018172322
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Raghu M, 2019, ADV NEUR IN, V32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy AG, 2017, BIOMED OPT EXPRESS, V8, P3627, DOI 10.1364/BOE.8.003627
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sirinukunwattana K, 2015, IEEE T MED IMAGING, V34, P2366, DOI 10.1109/TMI.2015.2433900
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Skilling J., 2010, LECT NOTES COMPUTER, V14, P83
   Sudre CH, 2017, LECT NOTES COMPUT SC, V10553, P240, DOI 10.1007/978-3-319-67558-9_28
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tong T, 2015, MED IMAGE ANAL, V23, P92, DOI 10.1016/j.media.2015.04.015
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   Wang SJ, 2019, IEEE T MED IMAGING, V38, P2485, DOI 10.1109/TMI.2019.2899910
   Wong KCL, 2018, LECT NOTES COMPUT SC, V11072, P612, DOI 10.1007/978-3-030-00931-1_70
   Xu MJ, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-018-0619-9
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 52
TC 5
Z9 5
U1 1
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103311
DI 10.1016/j.jvcir.2021.103311
EA SEP 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA3DL
UT WOS:000702769700002
DA 2024-07-18
ER

PT J
AU Fernandes, R
   Sanchez, G
   Cataldo, R
   Agostini, L
   Marcon, C
AF Fernandes, Ramon
   Sanchez, Gustavo
   Cataldo, Rodrigo
   Agostini, Luciano
   Marcon, Cesar
TI Using curved angular intra-frame prediction to improve video coding
   efficiency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Intra-frame prediction; High Efficiency Video Coding (HEVC); Video
   coding; Predictive coding
ID MODE DECISION ALGORITHM; HEVC; H.264/AVC
AB This article presents a new curved-based intra-frame prediction method for current and upcoming video coding standards. Our proposal extends conventional straight-line angular modes found on intra-prediction tools to model curved texture characteristics, enhancing the intra-frame prediction process. Our work targets the High Efficiency Video Coding (HEVC) standard for evaluation, although our curved-based method can be used by any other video coding standard. We model curved intra-frame prediction using an offset-based displacement calculation to each predicted sample. The proposal incurs a small bitstream overhead for transmitting the displacement information, which is offset by encoding efficiency gains. Experimental results demonstrate reduced residual energy; consequently, improving BD-Rate for the tested sequences. Evaluations applying eight curve displacement values show an average BD-Rate reduction of 2.69%, 2.49%, and 0.86% for All-Intra-8, AllIntra 10, and Random-Access configurations, respectively. The proposal allows further BD-Rate improvements, albeit at higher encoding complexity.
C1 [Fernandes, Ramon; Marcon, Cesar] Pontificia Univ Catolica Rio Grande do Sul, Ave Ipiranga 6681, BR-90619900 Porto Alegre, RS, Brazil.
   [Sanchez, Gustavo] Inst Fed Farroupilha, RS-377,Km 27, BR-97555000 Alegrete, Brazil.
   [Cataldo, Rodrigo] Lab STICC, Rue St Maude, F-56100 Lorient, France.
   [Agostini, Luciano] Univ Fed Pelotas, Rua Gomes Carneiro 01, BR-96010610 Pelotas, RS, Brazil.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul; Instituto Federal
   Farroupilha; Universidade Federal de Pelotas
RP Fernandes, R (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Ave Ipiranga 6681, BR-90619900 Porto Alegre, RS, Brazil.
EM ramon.fernandes@acad.pucrs.br; gustavo.sanchez@iffarroupilha.edu.br;
   rodrigo.cataldo@acad.pucrs.br; agostini@inf.ufpel.edu.br;
   cesar.marcon@pucrs.br
RI Agostini, Luciano/N-1102-2019; Agostini, Luciano/G-8626-2011
OI Agostini, Luciano/0000-0002-3421-5830; Marcon,
   Cesar/0000-0002-7811-7896; Cadore Cataldo, Rodrigo/0000-0003-4664-2909
FU CoordenacAo de Aperfeicoa-mento de Pessoal de Nivel Superior - Brasil
   (CAPES) [001]
FX This study was financed in part by the CoordenacAo de Aperfeicoa-mento
   de Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR A. for Open Media, 2019, AV1 BITSTREAM DECODI
   Alshina E., 2018, JVETD1001 ALGORITHM
   Azgin H, 2017, IEEE T CONSUM ELECTR, V63, P36, DOI 10.1109/TCE.2017.014728
   Bjontegaard G., 2001, CALCULATION AVERAGE
   Bross B, 2019, Document JVET-N1001
   Chang YJ, 2019, PROC SPIE, V11137, DOI 10.1117/12.2530564
   Chen C, 2017, IEEE T CIRC SYST VID, V27, P1727, DOI 10.1109/TCSVT.2016.2556478
   Feng L, 2016, OPTOELECTRON LETT, V12, P316, DOI 10.1007/s11801-016-6064-8
   Fernandes R, 2018, ELECTRON LETT, V54, P1214, DOI 10.1049/el.2018.6051
   Kalampogia A, 2018, IEEE T MULTIMEDIA, V20, P171, DOI 10.1109/TMM.2017.2713642
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lainema J, 2011, IEEE INT WORKSH MULT
   Li JH, 2017, IEEE DATA COMPR CONF, P221, DOI 10.1109/DCC.2017.59
   Liu XG, 2017, IEEE T CIRC SYST VID, V27, P1737, DOI 10.1109/TCSVT.2016.2556278
   Lucas LFR, 2015, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2015.7350973
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Matsuo S, 2012, ASIAPAC SIGN INFO PR
   Mukherjee D, 2013, PICT COD SYMP, P390, DOI 10.1109/PCS.2013.6737765
   Rhee CE, 2012, IEEE T CONSUM ELECTR, V58, P1375, DOI 10.1109/TCE.2012.6415009
   Said A, 2016, IEEE IMAGE PROC, P534, DOI 10.1109/ICIP.2016.7532414
   Schwarz Heiko, 2016, Foundations and Trends in Signal Processing, V10, P1, DOI 10.1561/2000000078
   Sharman K., 2018, AC1100 JCTVC
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan G.J., 2014, High Efficiency Video Coding (HEVC)"
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Sun HM, 2020, IEEE T MULTIMEDIA, V22, P2764, DOI 10.1109/TMM.2019.2963620
   T.J.C.T. on Video Coding (JCT-VC), 2018, HEVC TEST MODEL HM 1
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Winken M, 2011, IEEE IMAGE PROC
   Yuan H, 2017, IEEE T MULTIMEDIA, V19, P1416, DOI 10.1109/TMM.2017.2669858
   Yuan H, 2010, OPT ENG, V49, DOI 10.1117/1.3377968
   Zhao L, 2019, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2019.00013
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhao LP, 2018, IEEE T MULTIMEDIA, V20, P796, DOI 10.1109/TMM.2017.2758519
   Zhu SY, 2010, IEEE T CIRC SYST VID, V20, P1385, DOI 10.1109/TCSVT.2010.2046051
NR 37
TC 2
Z9 2
U1 1
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103291
DI 10.1016/j.jvcir.2021.103291
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900007
DA 2024-07-18
ER

PT J
AU Li, SM
   Li, YY
   Han, YT
AF Li, Sumei
   Li, Yueyang
   Han, Yongtian
TI Stereoscopic image quality assessment considering visual mechanism and
   multi-loss constraints
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Binocular information; Multi-loss; Proxy label
ID SIMILARITY
AB In this paper, a convolutional neural network (CNN) with multi-loss constraints is designed for stereoscopic image quality assessment (SIQA). A stereoscopic image not only contains monocular information, but also provides binocular information which is as identically crucial as the former. So we take the image patches of left-view images, right-view images and the difference images as the inputs of the network to utilize monocular information and binocular information. Moreover, we propose a method to obtain proxy label of each image patch. It preserves the quality difference between different regions and views. In addition, the multiple loss functions with adaptive loss weights are introduced in the network, which consider both local features and global features and constrain the feature learning from multiple perspectives. And the adaptive loss weights also make the multi-loss CNN more flexible. The experimental results on four public SIQA databases show that the proposed method is superior to other existing SIQA methods with state-of-the-art performance.
C1 [Li, Sumei; Li, Yueyang; Han, Yongtian] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Li, SM (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM lisumei@tju.edu.cn; 15940260132@163.com; han_yt9@163.com
OI Li, Sumei/0000-0002-4793-3161
FU National Natural Science Foundation of China [61971306, 61520106002,
   61471262]
FX This work was supported by the National Natural Science Founda-tion of
   China under Grant 61971306, 61520106002, 61471262.
CR [Anonymous], 2016, PATTERN RECOGN, DOI DOI 10.1016/j.patcog.2016.01.034
   [Anonymous], 2017, 2017 INT SMART CIT C
   [Anonymous], 2016, 2016 22 NAT C COMM N
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Ding Y, 2018, IEEE ACCESS, V6, P37595, DOI 10.1109/ACCESS.2018.2851255
   Fan Y, 2018, IEEE IMAGE PROC, P3538, DOI 10.1109/ICIP.2018.8451490
   Fang YM, 2019, J VIS COMMUN IMAGE R, V58, P400, DOI 10.1016/j.jvcir.2018.12.006
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li KM, 2015, ELECTRON LETT, V51, P1994, DOI 10.1049/el.2015.2049
   Li SM, 2020, SIGNAL IMAGE VIDEO P, V14, P565, DOI 10.1007/s11760-019-01582-6
   Li YF, 2019, IEEE ACCESS, V7, P46706, DOI 10.1109/ACCESS.2019.2909073
   Liu LX, 2018, NEUROCOMPUTING, V275, P1823, DOI 10.1016/j.neucom.2017.10.017
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Niu YZ, 2019, IEEE ACCESS, V7, P101583, DOI 10.1109/ACCESS.2019.2930707
   Oh H, 2017, IEEE T IMAGE PROCESS, V26, P4923, DOI 10.1109/TIP.2017.2725584
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shao F, 2016, IEEE T COMPUT IMAG, V2, P123, DOI 10.1109/TCI.2016.2538720
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xu CY, 2016, IEEE T CIRC SYST VID, V26, P2273, DOI 10.1109/TCSVT.2015.2477937
   Xu XG, 2019, IEEE ACCESS, V7, P85286, DOI 10.1109/ACCESS.2019.2925084
   Yang JC, 2019, IEEE T MULTIMEDIA, V21, P1750, DOI 10.1109/TMM.2018.2889562
   Yang JC, 2019, IEEE T IMAGE PROCESS, V28, P1314, DOI 10.1109/TIP.2018.2878283
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
   Yue GH, 2018, SIGNAL PROCESS, V150, P204, DOI 10.1016/j.sigpro.2018.04.019
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou W, 2019, IEEE T IMAGE PROCESS, V28, P3946, DOI 10.1109/TIP.2019.2902831
   Zhou WJ, 2016, SIGNAL PROCESS, V129, P130, DOI 10.1016/j.sigpro.2016.06.005
NR 37
TC 0
Z9 0
U1 3
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103255
DI 10.1016/j.jvcir.2021.103255
EA AUG 2021
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF0GI
UT WOS:000688258800003
DA 2024-07-18
ER

PT J
AU Wang, Q
   Zhou, LK
   Yao, YC
   Wang, Y
   Li, J
   Yang, WK
AF Wang, Qiang
   Zhou, Lukuan
   Yao, Yuncong
   Wang, Yong
   Li, Jun
   Yang, Wankou
TI An Interconnected Feature Pyramid Networks for object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Attention mechanism; Feature Pyramid Networks; Object detection; Deep
   learning
AB Although deep learning makes major breakthroughs in object detection, object detection still faces several limitations listed as follows: (1) Many works underplay the feature selection, leading to the resulting key features are not prominent enough and prone to noise; (2) Many works pass back features in a layer-by-layer manner to achieve multi-scale features. However, as the distance of layers from each other increases, the semantics are diluted, and the transfer of information between layers becomes difficult. To overcome these problems, we propose a new Interconnected Feature Pyramid Networks (IFPN) for feature enhancement. It can simultaneously select attentive features through the attention mechanism and realize the free flow of information. On the basis of the improvements, we design a new IFPN Detector. Experiments on COCO dataset and Smart UVM dataset show that our method can bring a significant improvement.
C1 [Wang, Qiang; Zhou, Lukuan; Yao, Yuncong; Yang, Wankou] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Zhou, Lukuan; Yao, Yuncong; Yang, Wankou] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Peoples R China.
   [Wang, Qiang; Wang, Yong] Jiangsu Automat Res Inst, Lianyungang 221116, Peoples R China.
   [Li, Jun] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Peoples R China.
C3 Southeast University - China; Southeast University - China; Nanjing
   Normal University
RP Yang, WK (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM wkyang@seu.edu.cn
OI Li, Jun/0000-0002-9781-8954
FU National Natural Science Foun-dation (NSF) of China [61773117, 62006041,
   61473086]; Natural Science Research of the Jiangsu Higher Education
   Institutions of China [18KJB520034]; Primary Re-search & Development
   Plan of Jiangsu Province-Industry Prospects and Common Key Technologies,
   PR China [BE2017157]
FX This work is partly supported by National Natural Science Foun-dation
   (NSF) of China (Grant No. 61773117, No. 62006041 and No. 61473086) ,
   Natural Science Research of the Jiangsu Higher Education Institutions of
   China (Grant No. 18KJB520034) , and the Primary Re-search & Development
   Plan of Jiangsu Province-Industry Prospects and Common Key Technologies,
   PR China under Grant No. BE2017157.
CR [Anonymous], Microsoft coco: Common objects in context
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Choi JY, 2007, 2007 IEEE INTELLIGENT TRANSPORTATION SYSTEMS CONFERENCE, VOLS 1 AND 2, P349
   Corvee E., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P469, DOI 10.1109/AVSS.2010.51
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Fanani N., 2018, P EUR C COMP VIS ECC
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Kong T., 2019, ARXIV190403797
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mnih V, 2014, ADV NEUR IN, V27
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Rätsch G, 2001, MACH LEARN, V42, P287, DOI 10.1023/A:1007618119488
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sun K., 2019, P IEEE C COMPUTER VI, DOI DOI 10.48550/ARXIV.1904.04514
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tao A., 2020, Arxiv
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wu GX, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102985
   Zhang HJ, 2020, IEEE T IND INFORM, V16, P7722, DOI 10.1109/TII.2019.2954956
   Zhang Z, 2018, IEEE T NEUR NET LEAR, V29, P3798, DOI 10.1109/TNNLS.2017.2740224
   Zhang Z, 2017, IEEE T IMAGE PROCESS, V26, P1607, DOI 10.1109/TIP.2017.2654163
   Zhao CR, 2021, IEEE T IMAGE PROCESS, V30, P4212, DOI 10.1109/TIP.2021.3070182
   Zhao CR, 2020, IEEE T MULTIMEDIA, V22, P3180, DOI 10.1109/TMM.2020.2972125
   Zhao CR, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-019-2675-3
   Zhao CR, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107014
   Zhao CR, 2019, PATTERN RECOGN LETT, V117, P161, DOI 10.1016/j.patrec.2018.04.029
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 41
TC 9
Z9 9
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103260
DI 10.1016/j.jvcir.2021.103260
EA AUG 2021
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100011
DA 2024-07-18
ER

PT J
AU Liao, X
   Peng, J
   Cao, Y
AF Liao, Xin
   Peng, Jing
   Cao, Yun
TI GIFMarking: The robust watermarking for animated GIF based deep
   learning*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Animated GIF images; Robust watermarking; 3D convolutional neural
   networks; Adversarial network
AB Animated GIF has become a key communication tool in contemporary social platforms thanks to highly compatible with affective performance, and it is gradually adopted in commercial applications. Therefore, the copyright protection of the animated GIF requires more attention. Digital watermarking is an effective method to embed invisible data into a digital medium that can identify the creator or authorized users. However, few works have been devoted to robust watermarking for the animated GIF. One of the main challenges is that the animated image also contains time frame dimension information compare with still images. This paper proposes a robust blind watermarking framework based 3D convolutional neural networks for the animated GIF image, which achieves watermark image embedding and extraction for the animated GIF. Also, noise simulation is developed in frame-level to ensure robustness for the attack of the temporal dimension in this framework. Furthermore, the invisibility of the watermarked animated image is optimized by adversarial learning. Experimental results provide the effectiveness of the proposed framework and show advantages over existing works.
C1 [Liao, Xin; Peng, Jing] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
   [Liao, Xin; Cao, Yun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
C3 Hunan University; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Liao, X (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Peoples R China.
EM xinliao@hnu.edu.cn
RI Liao, Xin/X-2736-2018; Jing, Peng/JUV-2688-2023; PENG,
   JING/JNT-2157-2023; Liao, Xin/ITT-1021-2023
OI Liao, Xin/0000-0002-9131-0578; Liao, Xin/0000-0002-9131-0578; Peng,
   Jing/0000-0002-3852-9829
FU National Natural Science Foundation of China [61972142, 61872356,
   61772191]; Hunan Provincial Natural Science Foundation of China
   [2020JJ4212]; Key Lab of Forensic Science, Academy of Forensic Science,
   Ministry of Justice, China [KF202118]
FX This work is supported by National Natural Science Foundation of China
   (Grant Nos. 61972142, 61872356, 61772191), Hunan Provincial Natural
   Science Foundation of China (Grant No. 2020JJ4212), Key Lab of Forensic
   Science, Academy of Forensic Science, Ministry of Justice, China (Grant
   No. KF202118).
CR Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Al-Otum HM, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102726
   [Anonymous], 2007, MORGAN KAUFMANN SERI
   [Anonymous], 2018, ICML
   Baluja S, 2017, ADV NEURAL INFORM PR, P2069
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chang CC, 2008, IEICE T INF SYST, VE91D, P54, DOI 10.1093/ietisy/e91-d.1.54
   Chen P., 5 WORKSH DIG ARCH
   Cox I., 2005, P INT WORKSH DIG FOR, P15
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hamamoto I, 2020, IEICE T INF SYST, VE103D, P33, DOI 10.1587/transinf.2019MUP0007
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kingma D. P., 2014, arXiv
   Li YC, 2016, PROC CVPR IEEE, P4641, DOI 10.1109/CVPR.2016.502
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu HQ, 2016, DIGIT SIGNAL PROCESS, V57, P34, DOI 10.1016/j.dsp.2016.06.012
   Liu Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1509, DOI 10.1145/3343031.3351025
   Machado R., 1997, EZSTEGO
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Miyato T., 2018, Proceedings of the 6th International Conference on Learning Representations, P1
   Nikolaidis N, 1996, INT CONF ACOUST SPEE, P2168, DOI 10.1109/ICASSP.1996.545849
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Swanson MD, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P211, DOI 10.1109/ICIP.1996.560421
   Tancik M, 2020, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR42600.2020.00219
   Tompkin J., 2011, 2011 Conference for Visual Media Production, P87, DOI 10.1109/CVMP.2011.16
   Tzeng CH, 2004, IEICE T FUND ELECTR, VE87A, P1612
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Wang J, 2020, AAAI CONF ARTIF INTE, V34, P6194
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiyang Luo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13545, DOI 10.1109/CVPR42600.2020.01356
   Yang C., 2004, J ACTA SCI NAT U SUN, V43, P128
   Yang JX, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102822
   Yang YJ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P533
   Yu C, 2020, AAAI CONF ARTIF INTE, V34, P1120
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhu JR, 2018, LECT NOTES COMPUT SC, V11219, P682, DOI 10.1007/978-3-030-01267-0_40
NR 48
TC 10
Z9 10
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103244
DI 10.1016/j.jvcir.2021.103244
EA AUG 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF1EY
UT WOS:000688325800005
DA 2024-07-18
ER

PT J
AU Ding, L
   Wang, Y
   Laganière, R
   Huang, D
   Fu, S
AF Ding, Lu
   Wang, Yong
   Laganiere, Robert
   Huang, Dan
   Fu, Shan
TI A CNN model for real time hand pose estimation*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hand pose estimation; CNN; Model-based; Fine-tuning
AB Recently convolutional neural networks (CNNs) have been employed to address the problem of hand pose estimation. In this work, we introduce an end-to-end deep architecture that can accurately estimate hand pose through the joint use of model-based and fine-tuning methods. In the model-based stage, we make use of the prior information in hand model geometry to ensure the geometric validity of the estimated poses. Next, we introduce a fine-tuning approach that learns to refine the errors between the model and observed hand. Our approach is validated on three challenging public datasets and achieves state-of-the-art performance.
C1 [Ding, Lu] Guangxi Univ, Sch Elect Engn, Guangxi, Peoples R China.
   [Wang, Yong] Sun Yat Sen Univ, Sch Aeronaut & Astronaut, Shenzhen, Peoples R China.
   [Laganiere, Robert] Univ Ottawa, Sch Elect Engn & Comp Sci, Ottawa, ON, Canada.
   [Fu, Shan] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [Huang, Dan] Shanghai Jiao Tong Univ, Sch Aeronaut & Astronaut, Shanghai, Peoples R China.
C3 Guangxi University; Sun Yat Sen University; University of Ottawa;
   Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Wang, Y (corresponding author), Sun Yat Sen Univ, Sch Aeronaut & Astronaut, Shenzhen, Peoples R China.
EM wangyong5@mail.sysu.edu.cn
RI Laganiere, Robert/H-9138-2013; Nguang, Sing Kiong/B-2292-2016
CR [Anonymous], 2017, ARXIV170102892
   [Anonymous], 2016, ASIAN C COMPUTER VIS
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2015, CVWW
   Bouchacourt D., 2016, Advances in Neural Information Processing Systems, P352
   De Smedt Q., 2016, P IEEE C COMP VIS PA, P1
   Deng X., 2017, CORR
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fourure D, 2017, NEUROCOMPUTING, V251, P68, DOI 10.1016/j.neucom.2017.04.014
   Ge LH, 2018, PROC CVPR IEEE, P8417, DOI 10.1109/CVPR.2018.00878
   Ge LH, 2019, IEEE T PATTERN ANAL, V41, P956, DOI 10.1109/TPAMI.2018.2827052
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Ge L, 2016, PROC CVPR IEEE, P3593, DOI 10.1109/CVPR.2016.391
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo HK, 2017, IEEE IMAGE PROC, P4512, DOI 10.1109/ICIP.2017.8297136
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang D, 2019, MULTIMED TOOLS APPL, V78, P29953, DOI 10.1007/s11042-018-6748-0
   Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61
   Krejov P, 2017, COMPUT VIS IMAGE UND, V155, P124, DOI 10.1016/j.cviu.2016.11.005
   Li PY, 2015, IEEE I CONF COMP VIS, P819, DOI 10.1109/ICCV.2015.100
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Madadi M., 2017, ARXIV170509606
   Makris Alexandros, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P8, DOI 10.1109/CVPRW.2015.7301343
   Neverova N, 2017, COMPUT VIS IMAGE UND, V164, P56, DOI 10.1016/j.cviu.2017.10.006
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379
   Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145
   Saric Marin, 2011, LibHand: A Library for Hand Articulation. Version 0.9
   Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450
   Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Sun Y, 2020, IET IMAGE PROCESS, V14, P3662, DOI 10.1049/iet-ipr.2020.0148
   Sun Y, 2020, ALEX ENG J, V59, P1149, DOI 10.1016/j.aej.2020.01.015
   Supancic III James Steven, 2015, ARXIV150406378
   Tang DH, 2015, IEEE I CONF COMP VIS, P3325, DOI 10.1109/ICCV.2015.380
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400
   Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Wan CD, 2016, LECT NOTES COMPUT SC, V9907, P554, DOI 10.1007/978-3-319-46487-9_34
   Wang Guijin., 2018, J VISUAL COMMUN IMAG
   Xu C, 2017, INT J COMPUT VISION, V123, P454, DOI 10.1007/s11263-017-0998-6
   Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429
   Ye Q, 2016, LECT NOTES COMPUT SC, V9912, P346, DOI 10.1007/978-3-319-46484-8_21
   Zhou X., 2016, IJCAI
NR 46
TC 6
Z9 8
U1 3
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103200
DI 10.1016/j.jvcir.2021.103200
EA JUL 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF3QM
UT WOS:000688491100002
DA 2024-07-18
ER

PT J
AU Li, YW
   Luo, Y
   Zhang, GK
   Lu, JW
AF Li, Yaowei
   Luo, Ye
   Zhang, Guokai
   Lu, Jianwei
TI Single image deblurring with cross-layer feature fusion and consecutive
   attention
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image deblurring; Cross-layer feature fusion; Consecutive attention
AB Single image deblurring aims to restore the single blurry image to its sharp counterpart and remains an active topic of enduring interest. Recently, deep Convolutional Neural Network (CNN) based methods have achieved promising performance. However, two primary limitations mainly exist on those CNNs-based image deblurring methods: most of them simply focus on increasing the complexity of the network, and rarely make full use of features extracted by encoder. Meanwhile, most of the methods perform the deblurred image reconstruction immediately after the decoder, and the roles of the decoded features are always underestimated. To address these issues, we propose a single image deblurring method, in which two modules to fuse multiple features learned in encoder (the Cross-layer Feature Fusion (CFF) module) and manipulate the features after decoder (the Consecutive Attention Module (CAM)) are specially designed, respectively. The CFF module is to concatenate different layers of features from encoder to enhance rich structural information to decoder, and the CAM module is able to generate more important and correlated textures to the reconstructed sharp image. Besides, the ranking content loss is employed to further restore more realistic details in the deblurred images. Comprehensive experiments demonstrate that our proposed method can generate less blur and more textures in deblurred image on both synthetic datasets and real-world image examples.
C1 [Li, Yaowei; Luo, Ye; Lu, Jianwei] Tongji Univ, Shanghai, Peoples R China.
   [Zhang, Guokai] Univ Shanghai Sci & Technol, Shanghai, Peoples R China.
C3 Tongji University; University of Shanghai for Science & Technology
RP Luo, Y; Lu, JW (corresponding author), Tongji Univ, Shanghai, Peoples R China.
EM yeluo@tongji.edu.cn; jwlu33@tongji.edu.cn
RI luo, ye/KQU-4093-2024
OI Luo, Ye/0000-0002-7052-7268; Lu, Jianwei/0000-0002-9071-9443
FU General Program of National Natural Science Foundation of China (NSFC)
   [61806147]; Shanghai Natural Science Foundation of China [18ZR1441200]
FX The authors would like to thank anonymous reviewers for their valuable
   suggestions. This work was supported by the General Program of National
   Natural Science Foundation of China (NSFC) (Grant No. 61806147) . This
   research was also partially supported by Shanghai Natural Science
   Foundation of China (Grant No. 18ZR1441200) .
CR [Anonymous], CoRR abs/1511.07122
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Elfiky NM, 2015, IEEE COMPUT SOC CONF
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu SH, 2019, IEEE I CONF COMP VIS, P2511, DOI 10.1109/ICCV.2019.00260
   Hall P, 2018, ARXIV180404082
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Ji H, 2012, IEEE T IMAGE PROCESS, V21, P1624, DOI 10.1109/TIP.2011.2171699
   Ji H, 2012, APPL COMPUT HARMON A, V32, P295, DOI 10.1016/j.acha.2011.09.006
   Jiao SM, 2017, IEEE T IND INFORM, V13, P2455, DOI 10.1109/TII.2017.2708764
   Jolicoeur-Martineau A., 2018, The relativistic discriminator: A key element missing from standard GAN
   Kang D.U., 2020, ABS201212507 ARXIV
   Kingma D. P., 2014, arXiv
   Krishnan Dilip, 2009, Advances in Neural Information Processing Systems
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Lau CP, 2019, INVERSE PROBL, V35, DOI 10.1088/1361-6420/ab0e4b
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li X., 2013, 2013 IEEE C COMP VIS
   Li Y., 2020, INT C PATTERN RECOGN
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Purohit K, 2020, AAAI CONF ARTIF INTE, V34, P11882
   Ren DW, 2020, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR42600.2020.00340
   Roth S, 2005, PROC CVPR IEEE, P860
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Simonyan K., 2014, 14091556 ARXIV
   Souri Y, 2017, LECT NOTES COMPUT SC, V10115, P118, DOI 10.1007/978-3-319-54193-8_8
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Suin M, 2020, PROC CVPR IEEE, P3603, DOI 10.1109/CVPR42600.2020.00366
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Tsai F. -J., 2021, ABS210107518 ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wen F., 2019, ABS190606642 ARXIV
   Wu H., 2019, FASTFCN RETHINKING D
   Xiang SM, 2015, INT J COMPUT VISION, V114, P248, DOI 10.1007/s11263-014-0755-z
   Yuan Y, 2020, PROC CVPR IEEE, P3552, DOI 10.1109/CVPR42600.2020.00361
   Zamir S.W., ABS210202808 ARXIV
   Zhang HG, 2019, PROC CVPR IEEE, P5971, DOI 10.1109/CVPR.2019.00613
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang WL, 2019, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2019.00319
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 52
TC 5
Z9 5
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103149
DI 10.1016/j.jvcir.2021.103149
EA MAY 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200006
DA 2024-07-18
ER

PT J
AU Jiang, F
   Chen, ZY
   Nazir, A
   Shi, WZ
   Lim, WX
   Liu, SH
   Rho, S
AF Jiang, Feng
   Chen, ZhiYuan
   Nazir, Amril
   Shi, WuZhen
   Lim, WeiXiang
   Liu, ShaoHui
   Rho, SeungMin
TI Combining Fields of Experts (FoE) and K-SVD methods in pursuing natural
   image priors
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE FoE; K-SVD; Adaptive filters; Joint statistical prior; Nature image
   priors
ID SPARSE REPRESENTATION; MODELS; RESTORATION; STATISTICS
AB Natural image prior is one of the most efficient ways to represent images for computer vision tasks. In the literature, filter response statistics prior and synthesis-based sparse representation are two dominant prior models, which have been investigated separately and our knowledge of the relation between these two methods remains limited. In this paper, we examine the inherent relationship between the Fields of Experts (FoE) and K-SVD methods in the pursuit of natural image priors. We theoretically analyze and show that these two prior models have a mutually complementary relationship in the pursuit of the structure of natural images space. Based on these findings, a novel joint statistical prior is proposed, in which adaptive filters are obtained by exploring clues from both priors and utilized to characterize the subtle structure of natural images subspace. Qualitative and quantitative experiments demonstrate that the proposed method achieves a more comprehensive and reliable estimation of natural image prior and is competitive to both alternative and state-of-the-art methods.
C1 [Jiang, Feng; Liu, ShaoHui] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
   [Chen, ZhiYuan; Lim, WeiXiang] Univ Nottingham Malaysia, Sch Comp Sci, Jln Broga 43500, Semenyih, Malaysia.
   [Nazir, Amril] Zayed Univ, Coll Technol Innovat, Dept Informat Syst, Abu Dhabi, U Arab Emirates.
   [Rho, SeungMin] Chung Ang Univ, Dept Ind Secur, Seoul 06974, South Korea.
   [Shi, WuZhen] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen, Peoples R China.
C3 Harbin Institute of Technology; University of Nottingham Malaysia; Zayed
   University; Chung Ang University; Shenzhen University
RP Nazir, A (corresponding author), Zayed Univ, Coll Technol Innovat, Dept Informat Syst, Abu Dhabi, U Arab Emirates.
EM amril@analyticray.com
RI JIANG, Feng/HTP-2862-2023; Rho, Seungmin/HTP-6683-2023; Liu,
   shaohui/HKE-1383-2023
OI chen, zhiyuan/0000-0002-4915-1593
CR Afonso MV, 2010, IEEE T IMAGE PROCESS, V19, P2345, DOI 10.1109/TIP.2010.2047910
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Barbu A, 2009, IEEE T IMAGE PROCESS, V18, P2451, DOI 10.1109/TIP.2009.2028254
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen YJ, 2014, IEEE T IMAGE PROCESS, V23, P1060, DOI 10.1109/TIP.2014.2299065
   Deng Y, 2014, IEEE T CYBERNETICS, V44, P1924, DOI 10.1109/TCYB.2014.2300192
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Elad M, 2005, APPL COMPUT HARMON A, V19, P340, DOI 10.1016/j.acha.2005.03.005
   Elad M, 2007, INVERSE PROBL, V23, P947, DOI 10.1088/0266-5611/23/3/007
   Hawe S, 2013, IEEE T IMAGE PROCESS, V22, P2138, DOI 10.1109/TIP.2013.2246175
   He Zhuonan, 2020, Investigative Magnetic Resonance Imaging, V24, P179
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hong W, 2006, IEEE T IMAGE PROCESS, V15, P3655, DOI 10.1109/TIP.2006.882016
   Huang YM, 2009, IEEE SIGNAL PROC LET, V16, P457, DOI 10.1109/LSP.2009.2016835
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jiang F, 2015, J SUPERCOMPUT
   Kohli P, 2010, PROC CVPR IEEE, P1863, DOI 10.1109/CVPR.2010.5539858
   Li Chengbo., 2009, Tval3: Tv minimization by augmented lagrangian and alternating direction algorithm
   Li X, 2011, IEEE J-STSP, V5, P953, DOI 10.1109/JSTSP.2011.2138676
   Li YR, 2011, IEEE T IMAGE PROCESS, V20, P1822, DOI 10.1109/TIP.2010.2103950
   Li YH, 2015, 2015 INTERNATIONAL WORKSHOP ON PATTERN RECOGNITION IN NEUROIMAGING (PRNI) 2015, P41, DOI 10.1109/PRNI.2015.18
   Liu QG, 2017, IEEE IMAGE PROC, P1940, DOI 10.1109/ICIP.2017.8296620
   Liu YS, 2015, IEEE T CYBERNETICS, V45, P2498, DOI 10.1109/TCYB.2014.2375959
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   McAuley J.J., 2006, PROC IEEE INT C MACH, P617, DOI DOI 10.1145/1143844.1143922
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Roth S, 2005, PROC CVPR IEEE, P860
   Roth S, 2007, INT J COMPUT VISION, V74, P33, DOI 10.1007/s11263-006-0016-x
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Rubinstein R, 2013, IEEE T SIGNAL PROCES, V61, DOI 10.1109/TSP.2012.2226445
   Sahoo SK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P614, DOI 10.1109/ICDSP.2015.7251947
   Sahoo SK, 2013, IEEE SIGNAL PROC LET, V20, P587, DOI 10.1109/LSP.2013.2258912
   Schmidt U, 2010, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2010.5539844
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   vanderSchaaf A, 1996, VISION RES, V36, P2759, DOI 10.1016/0042-6989(96)00002-8
   Woodford OJ, 2009, IEEE I CONF COMP VIS, P2319, DOI 10.1109/ICCV.2009.5459434
   Xiong JJ, 2017, J VIS COMMUN IMAGE R, V48, P268, DOI 10.1016/j.jvcir.2017.07.002
   Yu GS, 2012, IEEE T IMAGE PROCESS, V21, P2481, DOI 10.1109/TIP.2011.2176743
   Yuan Y, 2016, IEEE T CYBERNETICS, V46, P2966, DOI 10.1109/TCYB.2015.2484324
   Zeng W, 2019, I S BIOMED IMAGING, P1678, DOI [10.1109/isbi.2019.8759265, 10.1109/ISBI.2019.8759265]
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang J, STRUCTURAL GROUP SPA
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang XQ, 2010, SIAM J IMAGING SCI, V3, P253, DOI 10.1137/090746379
   Zhou MY, 2012, IEEE T IMAGE PROCESS, V21, P130, DOI 10.1109/TIP.2011.2160072
   Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983
   Zhu SC, 2010, PATTERN RECOGN LETT, V31, P667, DOI 10.1016/j.patrec.2009.07.020
NR 50
TC 3
Z9 3
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103142
DI 10.1016/j.jvcir.2021.103142
EA MAY 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TL1KZ
UT WOS:000674615200009
DA 2024-07-18
ER

PT J
AU Chen, F
   Zhang, J
   Zheng, MK
   Wu, JY
   Ling, N
AF Chen, Feng
   Zhang, Jie
   Zheng, Mingkui
   Wu, Jiyan
   Ling, Nam
TI Long-term rate control for concurrent multipath real-time video
   transmission in heterogeneous wireless networks*
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual communications; Video coding; Lyapunov optimization;
   Heterogeneous wireless networks; Multi-homing; Rate control
ID MULTIUSER BANDWIDTH ALLOCATION; JOINT RATE CONTROL; MOBILE
AB Concurrent multipath transmission provides an effective solution for streaming high-quality mobile videos in heterogeneous wireless networks. Rate control is commonly adopted in multimedia communication systems to fully utilize the available network bandwidth. This paper proposes a novel rate control for concurrent multipath video transmission. The existing rate control algorithms mainly adapt bit rate in the short-term pattern, i.e., without considering the long-term video transmission quality. We propose a long-term rate control scheme that takes into account the status of both the transmission buffer and video frames. First, a mathematical model is developed to formulate the non-convex problem of long-term quality maximization. Second, we develop a dynamic programming solution for online encoding bit rate control based on buffer status. The performance evaluation is conducted in a real test bed over LTE and Wi-Fi networks. Experimental results demonstrate that the proposed long-term rate control scheme achieves appreciable improvements over the short-term rate control schemes in terms of video quality and delay performance.
C1 [Chen, Feng; Zhang, Jie; Zheng, Mingkui; Wu, Jiyan; Ling, Nam] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Fujian, Peoples R China.
   [Ling, Nam] Santa Clara Univ, Dept Comp Sci & Engn, Santa Clara, CA 95053 USA.
C3 Fuzhou University; Santa Clara University
RP Zheng, MK (corresponding author), Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350108, Fujian, Peoples R China.
EM zhengmk@fzu.edu.cn
FU National Natural Science Foundation for Young Scholars of China
   [61801120]; National Natural Science Foundation of China [61561014,
   61671153]; Fujian Natural Science Foundation [2018J05104]
FX This work was supported in part by the National Natural Science
   Foundation for Young Scholars of China under Grant 61801120, in part by
   the National Natural Science Foundation of China under Grant 61671153,
   in part by the National Natural Science Foundation of China under Grant
   61561014, and in part by the Fujian Natural Science Foundation under
   Grant 2018J05104.
CR [Anonymous], 2007, 1449610 ISOIEC
   [Anonymous], 1999, 2647 RFC
   [Anonymous], 2016, 2016 IEEE INT C COMM
   [Anonymous], 2007, STREAM CONTROL TRANS
   Bao W, 2017, IEEE J SEL AREA COMM, V35, P2798, DOI 10.1109/JSAC.2017.2726357
   Cao Y., 2013, Proceedings of the 4th International Conference on Sustainable Animal Agriculture for Developing Countries (SAADC2013), Lanzhou, China, 27-31 July 2013, P1
   Cao YL, 2017, CHINA COMMUN, V14, P90, DOI 10.1109/CC.2017.7868178
   Chen F, 2019, IEEE ACCESS, V7, P27401, DOI 10.1109/ACCESS.2019.2900387
   Chen PP, 2020, IEEE NETWORK, V34, P270, DOI 10.1109/MNET.001.1900289
   Chilamkurti N, 2013, MULTIMED TOOLS APPL, V65, P201, DOI 10.1007/s11042-011-0779-0
   Cisco Visual Networking Index: Forecast and Trends, 2019, CISC VIS NETW IND FO
   Dragan S., 2019, 2019 14 INT C ADV TE, P1
   Georgiadis Leonidas, 2006, Foundations and Trends in Networking, V1, P1, DOI 10.1561/1300000001
   Go Y, 2019, IEEE T VEH TECHNOL, V68, P5114, DOI 10.1109/TVT.2019.2906561
   Gupta A, 2015, IEEE ACCESS, V3, P1206, DOI 10.1109/ACCESS.2015.2461602
   ISOIEC, 1993, INF TECHN GEN COD MO
   Jiang MQ, 2006, IEEE T MULTIMEDIA, V8, P467, DOI 10.1109/TMM.2006.870713
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Kwon E, 2018, I C INF COMM TECH CO, P1500, DOI 10.1109/ICTC.2018.8539531
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu RZ, 2018, IEEE ACCESS, V6, P14591, DOI 10.1109/ACCESS.2018.2810216
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Lu Yang, 2009, Tsinghua Science and Technology, V14, P183, DOI 10.1016/S1007-0214(09)70028-8
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   MAXEMCHUK N, 1975, THESIS U PENNSYLVANI
   Neely M. J., 2010, STOCHASTIC NETWORK O
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P56, DOI 10.1109/JBHI.2016.2633287
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Starke M, 2008, IEEE POW ENER SOC GE, P922
   Tretiak Oleh J., 1974, INFORM COMPUT, V24, P92
   Tsai MF, 2011, COMPUT COMMUN, V34, P1125, DOI 10.1016/j.comcom.2010.02.001
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu J., 2017, IEEE T MOBILE COMPUT, V16
   Wu JY, 2019, IEEE T MULTIMEDIA, V21, P1593, DOI 10.1109/TMM.2018.2879748
   Wu JY, 2019, IEEE T MOBILE COMPUT, V18, P458, DOI 10.1109/TMC.2018.2836914
   Wu JY, 2018, IEEE T MULTIMEDIA, V20, P457, DOI 10.1109/TMM.2017.2741425
   Wu JY, 2016, IEEE T MOBILE COMPUT, V15, P2345, DOI 10.1109/TMC.2015.2497238
   Wu JY, 2016, IEEE T COMMUN, V64, P2477, DOI 10.1109/TCOMM.2016.2553138
   Wu JY, 2016, IEEE T MOBILE COMPUT, V15, P641, DOI 10.1109/TMC.2015.2426710
   Wu JY, 2013, IEEE GLOB COMM CONF, P1723, DOI 10.1109/GLOCOM.2013.6831322
   Wu JY, 2015, IEEE T MOBILE COMPUT, V14, P688, DOI 10.1109/TMC.2014.2334592
   Wu JY, 2013, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2013-283
   Xu CQ, 2015, IEEE T CIRC SYST VID, V25, P1175, DOI 10.1109/TCSVT.2014.2376138
   Yu W, 2004, IEEE T INFORM THEORY, V50, P145, DOI 10.1109/TIT.2003.821988
   Yuan H., 2020, IEEE T BROADCAST
   Yuan H, 2018, IEEE T MOBILE COMPUT, V17, P2334, DOI 10.1109/TMC.2018.2800749
   Yuan H, 2018, IEEE T MULTIMEDIA, V20, P183, DOI 10.1109/TMM.2017.2724850
   Yuan H, 2017, IEEE T BROADCAST, V63, P338, DOI 10.1109/TBC.2016.2630267
   Yuan H, 2014, J REAL-TIME IMAGE PR, V9, P609, DOI 10.1007/s11554-011-0237-2
   Yufeng Geng, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457857
   Zhang ZW, 2017, IEEE ACCESS, V5, P26328, DOI 10.1109/ACCESS.2017.2748138
   Zuo S, 2017, IEEE T WIREL COMMUN, V16, P4562, DOI 10.1109/TWC.2017.2700302
NR 54
TC 1
Z9 1
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2021
VL 77
AR 102999
DI 10.1016/J.JVCIR.2020.102999
EA APR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA SU7VZ
UT WOS:000663341400007
DA 2024-07-18
ER

PT J
AU Chen, SS
   Chang, CC
AF Chen, Sisheng
   Chang, Chin-Chen
TI Reversible data hiding based on three shadow images using rhombus magic
   matrix
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Three shadow images; Rhombus magic matrix;
   Hierarchical data security
AB This paper proposes a multi-image-based reversible data hiding method using a rhombus magic matrix. It takes a pixel pair as a position coordinate of a 256 ? 256 modulus function matrix and extracts a 5-order rhombus matrix. It first embeds a 5-ary secret digit by producing three shadow pixel pairs which satisfies the predefined distance condition. Then it embeds a 6-ary secret digit by permuting the three shadow pixel pairs and assigning them to three ordered shadow images. Third, it embeds another 5-ary secret digit by modifying the pixel pair within a 3-order rhombus magic matrix in a shadow image. The receiver can extract the secret data and recover the original cover image when obtaining all shadow images. It also introduces a new application scenario for hierarchical security data transmission. The experimental results and analysis show that the proposed security scheme provides high embedding capacity with good visual quality of shadow images.
C1 [Chen, Sisheng] Fujian Polytech Normal Univ, Sch Elect & Informat Engn, Fuzhou 350300, Peoples R China.
   [Chen, Sisheng; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chen, Sisheng] Fujian Prov Univ, Fujian Polytech Normal Univ, Engn Res Ctr ICH Digitalizat & Multisource Inform, Fuzhou 350300, Peoples R China.
C3 Fujian Polytechnic Normal University; Feng Chia University; Fujian
   Polytechnic Normal University; Fuzhou University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU Education-Scientific Project for Youth Teacher of Fujian province
   [JT180618]; Engineering Research Center for ICH Digitalization and
   MultiSource Information Fusion of Fujian Province University [FJ-ICH
   201901]
FX This work was supported by the EducationScientific Project for Youth
   Teacher of Fujian province [grant numbers JT180618] ; and the
   Engineering Research Center for ICH Digitalization and MultiSource
   Information Fusion of Fujian Province University [grant numbers FJ-ICH
   201901] .
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2013, P 3 INT C INFORM COM
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2009, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING (MUE 2009), P145, DOI 10.1109/MUE.2009.35
   Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Crandall R., 1998, POSTED STEGANOGRAPHY
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P390, DOI 10.1109/TIFS.2006.879281
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   Jafar IF, 2016, SIGNAL PROCESS, V128, P98, DOI 10.1016/j.sigpro.2016.03.023
   Ker AD, 2004, LECT NOTES COMPUT SC, V3200, P97
   Kim HJ, 2010, COMPUT MATH APPL, V60, P319, DOI 10.1016/j.camwa.2010.01.006
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin JY, 2019, J REAL-TIME IMAGE PR, V16, P673, DOI 10.1007/s11554-019-00863-0
   Lu TC, 2020, IEEE ACCESS, V8, P90824, DOI 10.1109/ACCESS.2020.2994244
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Lu TC, 2015, SIGNAL PROCESS, V108, P77, DOI 10.1016/j.sigpro.2014.08.022
   Mao Q, 2014, DIGIT SIGNAL PROCESS, V25, P248, DOI 10.1016/j.dsp.2013.11.001
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Shastri S, 2019, J VIS COMMUN IMAGE R, V61, P130, DOI 10.1016/j.jvcir.2019.03.022
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Yao H, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107447
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 30
TC 7
Z9 7
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2021
VL 76
AR 103064
DI 10.1016/j.jvcir.2021.103064
EA MAR 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RV1JE
UT WOS:000645594700006
DA 2024-07-18
ER

PT J
AU Asad, M
   Yang, J
   Tu, EM
   Chen, LM
   He, XJ
AF Asad, Mujtaba
   Yang, Jie
   Tu, Enmei
   Chen, Liming
   He, Xiangjian
TI Anomaly3D: Video anomaly detection based on 3D-normality clusters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Spatiotemporal latent features; 3D-CAE; Anomaly detection; Video
   analysis; Autonomous video surveillance
ID EVENTS
AB Abnormal behavior detection in surveillance videos is necessary for public monitoring and safety. In human-based surveillance systems, it requires continuous human attention and observation, which is a difficult task. The autonomous detection of such events is of essential significance. However, due to the scarcity of labeled data and the low occurrence probability of these events, abnormal event detection is a challenging vision problem. In this paper, we introduce a novel two-stage architecture for detecting anomalous behavior in videos. In the first stage, we propose a 3D Convolutional Autoencoder (3D-CAE) architecture to extract spatio-temporal features from normal event training videos. In 3D-CAE, the encoder and decoder architectures are based on 3D convolutions, which can learn both appearance and the motion features effectively in an unsupervised manner. In the second stage, we group the 3D spatio-temporal features into different normality clusters, and then remove the sparse clusters to represent a stronger pattern of normality. From these clusters, one-class SVM classifier is used to distinguish between normal and abnormal events based on the normality scores. Experimental results on four different benchmark datasets show significant performance improvement compared to state-of-the-art approaches while providing results in real-time.
C1 [Asad, Mujtaba; Yang, Jie; Tu, Enmei] Shanghai Jiao Tonng Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Chen, Liming] Ecole Cent Lyon, CNRS, LIRIS, UMR 5205, F-69134 Ecully, France.
   [He, Xiangjian] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW, Australia.
C3 Centre National de la Recherche Scientifique (CNRS); Ecole Centrale de
   Lyon; Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   University of Technology Sydney
RP Yang, J (corresponding author), Shanghai Jiao Tonng Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM asadmujtaba@sjtu.edu.cn; jieyang@sjtu.edu.cn; tuen@sjtu.edu.cn;
   liming.chen@ec-lyon.fr; xiangjian.he@uts.edu.au
RI He, Xiangjian/CAA-1461-2022; Yang, Jie/JCD-9867-2023
OI Asad, Mujtaba/0000-0003-0318-7379; He, Xiangjian/0000-0001-8962-540X
FU NSFC, China [61876107, U1803261]; Shanghai Natural Science Foundation,
   China [19ZR1476300]
FX This research is partly supported by NSFC, China (No: 61876107,
   U1803261) and Shanghai Natural Science Foundation, China (No.
   19ZR1476300).
CR Abedalla L, 2019, COMM COM INF SC, V1062, P45, DOI 10.1007/978-3-030-27684-3_7
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 2015, BRIT MACHINE VISION
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Antonakaki P, 2009, SIGNAL PROCESS, V89, P1723, DOI 10.1016/j.sigpro.2009.03.016
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Auslander B., 2011, INT SOC OPTICS PHOTO, V8019
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Chen DY, 2011, J VIS COMMUN IMAGE R, V22, P178, DOI 10.1016/j.jvcir.2010.12.004
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Del Giorno A, 2016, LECT NOTES COMPUT SC, V9909, P334, DOI 10.1007/978-3-319-46454-1_21
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fu ZY, 2005, IEEE IMAGE PROC, P2029
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gu, 2013, P 16 INT C ART INT S, P307
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Ionescu RT, 2019, IEEE WINT CONF APPL, P1951, DOI 10.1109/WACV.2019.00212
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Kim J, 2009, PROC CVPR IEEE, P2913
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu YQ, 2020, J VIS COMMUN IMAGE R, V68, DOI 10.1016/j.jvcir.2020.102767
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mei SH, 2019, IEEE T GEOSCI REMOTE, V57, P6808, DOI 10.1109/TGRS.2019.2908756
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Ravanbakhsh M, 2018, IEEE WINT CONF APPL, P1689, DOI 10.1109/WACV.2018.00188
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Sabokrou M, 2017, IEEE T IMAGE PROCESS, V26, P1992, DOI 10.1109/TIP.2017.2670780
   Saligrama V, 2012, PROC CVPR IEEE, P2112, DOI 10.1109/CVPR.2012.6247917
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   Simonyan K, 2014, ADV NEUR IN, V27
   Smeureanu S, 2017, LECT NOTES COMPUT SC, V10485, P779, DOI 10.1007/978-3-319-68548-9_70
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang N, 2013, P ADV NEURAL INFORM
   Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Yao YK, 2013, J COMPUT, V8, P2632, DOI 10.4304/jcp.8.10.2632-2639
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Zaharescu A, 2010, LECT NOTES COMPUT SC, V6311, P563, DOI 10.1007/978-3-642-15549-9_41
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   Zhu YY, 2013, PROC CVPR IEEE, P2491, DOI 10.1109/CVPR.2013.322
NR 56
TC 13
Z9 14
U1 4
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103047
DI 10.1016/j.jvcir.2021.103047
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600009
DA 2024-07-18
ER

PT J
AU Fu, BX
   Li, F
   Niu, Y
   Wu, H
   Li, Y
   Shi, GM
AF Fu, Boxun
   Li, Fu
   Niu, Yi
   Wu, Hao
   Li, Yang
   Shi, Guangming
TI Conditional generative adversarial network for EEG-based emotion
   fine-grained estimation and visualization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Affective computing; Electroencephalography; Generative adversarial
   network; Fine-grained
AB In the field of affective computing (AC), coarse-grained AC has been developed and widely applied in many fields. Electroencephalogram (EEG) signals contain abundant emotional information. However, it is difficult to develop fine-grained AC due to the lack of fine-grained labeling data and suitable visualization methods for EEG data with fine labels. To achieve a fine mapping of EEG data directly to facial images, we propose a conditional generative adversarial network (cGAN) to establish the relationship between EEG data associated with emotions, a coarse label, and a facial expression image in this study. In addition, a corresponding training strategy is also proposed to realize the fine-grained estimation and visualization of EEG-based emotion. The experiments prove the reasonableness of the proposed method for the generation of fine-grained facial expressions. The image entropy of the generated image indicates that the proposed method can provide a satisfactory visualization of fine-grained facial expressions.
C1 [Fu, Boxun; Li, Fu; Niu, Yi; Wu, Hao; Li, Yang; Shi, Guangming] Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence, Chinese Minist Educ, 2 South Taibai Rd, Xian 710071, Peoples R China.
C3 Xidian University
RP Li, F (corresponding author), Xidian Univ, Key Lab Intelligent Percept & Image Understanding, Sch Artificial Intelligence, Chinese Minist Educ, 2 South Taibai Rd, Xian 710071, Peoples R China.
EM fuli@mail.xidian.edu.cn
FU National Key Research and Development Project of China [2018YFB2202400];
   NSFC [61672404, 61875157, 61751310, 61836008, 61632019]; National
   Defense Basic Scientific Research Program of China [JCKY2017204B102];
   Science and Technology Plan of Xi'an [20191122015KYPT011JC013];
   Scientific Research Program - Shannxi Provincial Education Department
   [20JY022]; Fundamental Research Funds of the Central Universities of
   China [JC1904, JX18001]
FX This work was supported in part by the National Key Research and
   Development Project of China (2018YFB2202400), NSFC (No. 61672404,
   61875157, 61751310, 61836008 and 61632019), National Defense Basic
   Scientific Research Program of China (JCKY2017204B102), Science and
   Technology Plan of Xi'an (20191122015KYPT011JC013),Scientific Rese arch
   Program Funded by Shannxi Provincial Education Department(NO. 20JY022),
   the Fundamental Research Funds of the Central Universities of China (No.
   JC1904 and JX18001).
CR [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Arjovsky M., 2017, ARXIV170107875
   Bos D. O., 2006, Influ Vis Audit Stimuli, V56, P1
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   D'Mello S, 2009, APPL ARTIF INTELL, V23, P123, DOI 10.1080/08839510802631745
   Devillers L, 2005, NEURAL NETWORKS, V18, P407, DOI 10.1016/j.neunet.2005.03.007
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani Ishaan, 2017, P ADV NEUR INF PROC, P5767
   Kleinginna P.R., 2009, MOTIVATION EMOT, V1981
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Li M, 2009, IEEE ENG MED BIO, P1323
   Liu S, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON ELECTROMAGNETICS: APPLICATIONS AND STUDENT INNOVATION COMPETITION (IWEM)
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo Y, 2018, IEEE ENG MED BIO, P2535, DOI 10.1109/EMBC.2018.8512865
   Matlovic T., 2016, EMOTION DETECTION US
   Mohammadi Z., 2016, Neural Comput- ing and Applications
   Mühl C, 2014, BRAIN-COMPUT INTERFA, V1, P66, DOI 10.1080/2326263X.2014.912881
   Schuller B, 2005, INT CONF ACOUST SPEE, P325
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   Thammasan N., 2016, INT JOINT C NEUR NET
   Vytal K, 2010, J COGNITIVE NEUROSCI, V22, P2864, DOI 10.1162/jocn.2009.21366
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zheng W.L., 2017, IEEE T AFFECT COMPUT
   Zheng WL, 2019, IEEE T CYBERNETICS, V49, P1110, DOI 10.1109/TCYB.2018.2797176
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
NR 27
TC 12
Z9 12
U1 2
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 102982
DI 10.1016/j.jvcir.2020.102982
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OM
UT WOS:000613151000004
DA 2024-07-18
ER

PT J
AU Xie, YR
   Song, TC
   Li, W
AF Xie, Yurui
   Song, Tiecheng
   Li, Wei
TI Semantic-aware visual attributes learning for zero-shot recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Zero-shot learning; Human-designed attributes; Visual attributes;
   Semantic representation
ID OBJECT
AB Zero-shot learning (ZSL) aims to recognize unseen image classes without requiring any training samples of these specific classes. The ZSL problem is typically achieved by building up a semantic embedding space like attributes to bridge the visual features and class labels of images. Currently, most ZSL approaches focus on learning a visual-semantic alignment from seen classes using only the human-designed attributes, and then ZSL problem is solved by transferring semantic knowledge from seen classes to the unseen classes. However, few works indicate if the human-designed attributes are discriminative enough for image class prediction. To address this issue, we propose a semantic-aware dictionary learning (SADL) framework to explore these discriminative visual attributes across seen and unseen classes. Furthermore, the semantic cues are elegantly integrated into the feature representations via learned visual attributes for recognition task. Experiments conducted on two challenging benchmark datasets show that our approach outweighs other state-of-the-art ZSL methods.
C1 [Xie, Yurui] Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
   [Song, Tiecheng] Chongqing Univ Posts & Telecommun, 2 Chongwen Rd, Chongqing, Peoples R China.
   [Li, Wei] Southwest Jiaotong Univ, 999 Xi An Rd, Chengdu, Peoples R China.
C3 Chengdu University of Information Technology; Chongqing University of
   Posts & Telecommunications; Southwest Jiaotong University
RP Xie, YR (corresponding author), Chengdu Univ Informat & Technol, 24 Block 1,Xuefu Rd, Chengdu, Peoples R China.
EM gloriousxyr@163.com; songtc@cqupt.edu.cn; liwei@swjtu.edu.cn
FU National Natural Science Foundation of China [61806028, 61702065];
   Program for Educational Foundation of Sichuan Province, China [18ZB0125]
FX This work was supported by The National Natural Science Foundation of
   China (No. 61806028, No. 61702065), and in part by the Program for
   Educational Foundation of Sichuan Province, China (No. 18ZB0125).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   [Anonymous], 2014, ICLR
   Ashual O, 2019, IEEE I CONF COMP VIS, P4560, DOI 10.1109/ICCV.2019.00466
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Jiang HJ, 2018, LECT NOTES COMPUT SC, V11214, P121, DOI 10.1007/978-3-030-01249-6_8
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li X, 2019, J VIS COMMUN IMAGE R, V58, P701, DOI 10.1016/j.jvcir.2018.12.041
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ren YZ, 2017, J VIS COMMUN IMAGE R, V42, P192, DOI 10.1016/j.jvcir.2016.11.004
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Song J, 2020, PROC CVPR IEEE, P3921, DOI 10.1109/CVPR42600.2020.00398
   Song J, 2019, ADV NEUR IN, V32
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Song J, 2018, LECT NOTES COMPUT SC, V11213, P474, DOI 10.1007/978-3-030-01240-3_29
   Thomas SS, 2016, J VIS COMMUN IMAGE R, V38, P367, DOI 10.1016/j.jvcir.2016.03.015
   Tong B, 2019, PROC CVPR IEEE, P11459, DOI 10.1109/CVPR.2019.01173
   Verma VK, 2017, LECT NOTES ARTIF INT, V10535, P792, DOI 10.1007/978-3-319-71246-8_48
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
   Zheng Y, 2019, J VIS COMMUN IMAGE R, V59, P563, DOI 10.1016/j.jvcir.2019.02.006
   Zighem MEN, 2019, J VIS COMMUN IMAGE R, V61, P236, DOI 10.1016/j.jvcir.2019.03.025
NR 38
TC 0
Z9 0
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500003
DA 2024-07-18
ER

PT J
AU Chen, H
   Guo, AB
   Ni, WL
   Cheng, Y
AF Chen, Hua
   Guo, AiBin
   Ni, Wenlong
   Cheng, Yan
TI Improving the representation of image descriptions for semantic image
   retrieval with RDF
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image representation; RDF; Image retrieval; Cross-lingual retrieval;
   Semantic image retrieval
ID NETWORK
AB The past few years have witnessed a surge of interest in many topics at the intersection of natural language processing and computer vision. In particular, using objects together with their attributes and relations to represent images or interpret languages has been proved useful across a wide variety of applications. The goal of this work is to provide an improved RDF-based model to represent images for enhancing textual based image retrieval. We use natural language processing tools to obtain a set of objects, attributes and relations; and then model them into graphical structures with RDF-based model. We also conduct some preliminary experiments to show how to handle textual based image retrieval for complex queries or multilingual queries. The experimental results show that our approach improves the representation of image descriptions, which is suitable for enhancing image retrieval with high-level semantics.
C1 [Chen, Hua; Guo, AiBin; Ni, Wenlong; Cheng, Yan] Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
C3 Jiangxi Normal University
RP Chen, H (corresponding author), Jiangxi Normal Univ, Sch Comp & Informat Engn, Nanchang 330022, Jiangxi, Peoples R China.
EM hua.chen@kyudai.jp
RI Ni, Wenlong/A-3004-2012
FU Scientific Research Foundation of Jiangxi Normal University
   [0901/12019572, 0901/12019871]
FX This work is financially supported by the Scientific Research Foundation
   of Jiangxi Normal University for the PhD (No. 0901/12019572 and No.
   0901/12019871).
CR Aditya S, 2015, Arxiv, DOI arXiv:1511.03292
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Bard P., 2004, Proc. of 13th World Conf. on Earthquake Engineering, Vancouver, BC, Canada, P1
   Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Dollin C, 2004, INTRO RDF JENA RDF A, P2007
   Erling O., 2009, NETWORKED KNOWLEDGE, V221, P7, DOI [10.1007/978-3-642-02184-8_2, 10.1007/978-3- 642- 02184-8, DOI 10.1007/978-3-642-02184-8]
   Grobe M., 2009, P 37 ANN ACM SIGUCCS, P131
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kipf TN, 2016, ARXIV
   Li XR, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P271, DOI 10.1145/2911996.2912049
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Luo B., 2018, INT C PION COMP SCI, P27
   Manola F., 2004, RESOURCE DESCRIPTION, V10
   Prud'hommeaux Eric., 2007, SPARQL QUERY LANGUAG
   Schuster S., 2015, P 4 WORKSHOP VISION, P70
   Speer R, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3679
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang Z, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102130
   Wang Z, 2019, PATTERN RECOGN LETT, V122, P60, DOI 10.1016/j.patrec.2019.02.007
   Xu J., 2019, IEEE T MULTIMED
   Xu X., 2020, IEEE T PATTERN ANAL, P1, DOI [DOI 10.1109/TPAMI.2020.3045530, 10.1109/LGRS.2020.3039622]
   Xu X, 2020, IEEE T NEUR NET LEAR, V31, P5412, DOI 10.1109/TNNLS.2020.2967597
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang Y, 2016, ADV COGN SYST
   Yoshikawa Y, 2017, arXiv
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
NR 30
TC 3
Z9 4
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102934
DI 10.1016/j.jvcir.2020.102934
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000005
DA 2024-07-18
ER

PT J
AU Yin, HB
   Yang, HY
   Huang, XF
   Wang, HK
   Yan, CG
AF Yin, Haibing
   Yang, Haoyun
   Huang, Xiaofeng
   Wang, Hongkui
   Yan, Chenggang
TI Multi-stage all-zero block detection for HEVC coding using machine
   learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-stage AZB detection; Rate-distortion optimization; Soft-decision
   quantization; Machine learning
ID QUANTIZED DCT COEFFICIENTS; DETECTION ALGORITHM; MOTION ESTIMATION;
   GENERAL-METHOD; PREDICTION; HYBRID
AB Compared with deadzone hard-decision quantization (HDQ), rate-distortion optimized quantization (RDOQ) in HEVC brings non-negligible coding gain, however consumes considerable computations caused by exhaustive search over multiple candidates to determine optimal output level. Benefiting from efficient prediction in HEVC, transform blocks are frequently quantized to all zero, especially in small-size blocks. It is worthwhile to detect all zero block (AZB) for transform blocks to bypass subsequent computation-intensive RDOQ. Traditional thresholding based AZB detection algorithms are well-suited for deadzone quantized blocks, however miss partial optimal results in RDOQ and suffer from more or less accuracy degradation in RDOQ. This paper proposes a novel multi-stage AZB detection algorithm for RDOQ blocks with good tradeoff between complexity and accuracy. At the first stage, genuine all zero blocks (G_AZB) which are quantized to all zero both in HDQ and RDOQ are prejudged by comparison with conservative threshold determined by mathematical derivation for deadzone HDQ. At the second stage, an adaptive threshold model is built using adaptive deadzone offset by simulating the behavior patterns existing in RDOQ, aiming to further detect the pseudo AZB (P_AZB) which are quantized to all zero in RDOQ however not all zero in HDQ. At the final stage, machine learning based detection is proposed to classify the remaining "cunning" all zero blocks using eight distinguished RDO-related features, by which subtle working mechanism in RDOQ is leveraged. The experimental results demonstrate that the proposed algorithm achieves up to 7.471% total coding computation saving with 0.064% BD-RATE increment compared with RDOQ on average. Moreover, the average FNR and FPR detection accuracies are 6.3% and 6.5% respectively.
C1 [Yin, Haibing; Yang, Haoyun; Huang, Xiaofeng; Yan, Chenggang] Hangzhou Dianzi Univ, Sch Commun Engn, 2 St, Hangzhou 310018, Peoples R China.
   [Wang, Hongkui] Huazhong Univ Sci & Technol, Sch Informat Engn, Wuhan 430000, Peoples R China.
C3 Hangzhou Dianzi University; Huazhong University of Science & Technology
RP Yin, HB (corresponding author), Hangzhou Dianzi Univ, Sch Commun Engn, 2 St, Hangzhou 310018, Peoples R China.
EM yhb@hdu.edu.cn
RI Wang, HK W/GQQ-8378-2022
FU NSFC [61972123, 61931008, 61901150, ZJNSF LY19F020043]; Key RD project
   [2018YFC0830106]
FX This work was supported in part by NSFC 61972123, 61931008 and 61901150,
   ZJNSF LY19F020043, as well as Key RD project 2018YFC0830106.
CR Bossen F., 2013, document JCTVC-L1100,, V12
   Cui J, 2018, IEEE T IMAGE PROCESS, V27, P4987, DOI 10.1109/TIP.2018.2837351
   Huang TY, 2013, IEEE INT SYMP CIRC S, P473, DOI 10.1109/ISCAS.2013.6571883
   Huang YW, 2006, IEEE T CIRC SYST VID, V16, P507, DOI 10.1109/TCSVT.2006.872783
   Ji XY, 2009, IEEE T CIRC SYST VID, V19, P1755, DOI 10.1109/TCSVT.2009.2026839
   Jia G. Wen, 2016, IEEE T MULTIMEDIA, V18, P1
   Kingma D. P., 2014, arXiv
   Lee B, 2016, IEEE T MULTIMEDIA, V18, P1257, DOI 10.1109/TMM.2016.2557075
   Lee K, 2013, IEEE J-STSP, V7, P1124, DOI 10.1109/JSTSP.2013.2272772
   Lei Ya-feng, 2008, Computer Engineering and Applications, V44, P71, DOI 10.3778/j.issn.1002-8331.2008.23.022
   Li J, 2012, IEEE T CIRC SYST VID, V22, P249, DOI 10.1109/TCSVT.2011.2160749
   Liu ZY, 2008, IEEE T CIRC SYST VID, V18, P620, DOI 10.1109/TCSVT.2008.918844
   Marpe D., 2002, FINAL CABAC CLEANUP, P5
   Moon YH, 2005, IEEE T CIRC SYST VID, V15, P1053, DOI 10.1109/TCSVT.2005.852411
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   Sousa LA, 2000, ELECTRON LETT, V36, P306, DOI 10.1049/el:20000272
   Sullivan G, 2005, JVTN011 ISOIEC MPEG
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   Wang HL, 2008, IEEE T CIRC SYST VID, V18, P510, DOI 10.1109/TCSVT.2008.918553
   Wang HL, 2007, IEEE T MULTIMEDIA, V9, P728, DOI 10.1109/TMM.2007.893336
   Wang HL, 2014, J VIS COMMUN IMAGE R, V25, P1784, DOI 10.1016/j.jvcir.2014.08.007
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xie ZG, 2007, IEEE T CIRC SYST VID, V17, P237, DOI 10.1109/TCSVT.2006.888812
   Xuan Z., 2002, ELECTRON LETT, V34, p1839 1840
   Yang EH, 2007, IEEE T IMAGE PROCESS, V16, P1774, DOI 10.1109/TIP.2007.896685
   Yang K.H., 2011, US Patent, Patent No. [US7957600B2, 7957600]
   Yin HB, 2015, IEEE T CIRC SYST VID, V25, P1362, DOI 10.1109/TCSVT.2014.2380232
   Yin HB, 2018, SIGNAL PROCESS-IMAGE, V60, P79, DOI 10.1016/j.image.2017.09.004
   Zhang MJ, 2009, IEEE T CIRC SYST VID, V19, P103, DOI 10.1109/TCSVT.2008.2009239
NR 32
TC 2
Z9 3
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102945
DI 10.1016/j.jvcir.2020.102945
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000003
DA 2024-07-18
ER

PT J
AU Zabihi, S
   Mansoori, E
   Yazdi, M
AF Zabihi, Saman
   Mansoori, Eghbal
   Yazdi, Mehran
TI Exploiting object features in deep gaze prediction models
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human visual system; Deep gaze prediction model; Image segmentation;
   Object detection; Prior bias; Convolutional network structure
ID ATTENTION
AB The human visual system analyzes the complex scenes rapidly. It devotes the limited perceptual resources to the most salient subsets and/or objects of scenes while ignoring their less salient parts. Gaze prediction models try to predict the human eye fixations (human gaze) under free-viewing conditions while imitating the attentive mechanism. Previous studies on saliency benchmark datasets have shown that visual attention is affected by the salient objects of the scenes and their features. These features include the identity, the location, and the visual features of objects in the scenes, beside to the context of the input image. Moreover, the human eye fixations often converge to the specific parts of salient objects in the scenes. In this paper, we propose a deep gaze prediction model using object detection via image segmentation. It uses some deep neural modules to find the identity, location, and visual features of the salient objects in the scenes. In addition, we introduce a deep module to capture the prior bias of human eye fixations. To evaluate our model, several challenging saliency benchmark datasets are used in the experiments. We also conduct an ablation study to show the effectiveness of our proposed modules and its architecture. Despite its fewer parameters, our model has comparable, or even better performance on some datasets, to the state-of-the-art saliency models.
C1 [Zabihi, Saman; Mansoori, Eghbal; Yazdi, Mehran] Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
C3 Shiraz University
RP Mansoori, E (corresponding author), Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
EM mansoori@shirazu.ac.ir
RI Zabihi, Saman/JXY-9227-2024; , Mehran/C-2776-2011
OI Zabihi, Saman/0000-0001-7544-0199; , Mehran/0000-0002-8889-7048
CR Anllo-Vento L, 1998, HUM BRAIN MAPP, V6, P216, DOI 10.1002/(SICI)1097-0193(1998)6:4<216::AID-HBM3>3.0.CO;2-6
   [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], MIT Saliency Benchmark
   [Anonymous], 2012, Technical Report
   Aziz MZ, 2008, IEEE T IMAGE PROCESS, V17, P633, DOI 10.1109/TIP.2008.919365
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Borji, 2019, IEEE T ANAL MACH INT
   Borji A, 2013, IEEE I CONF COMP VIS, P921, DOI 10.1109/ICCV.2013.118
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Che Z, 2019, IEEE T LINAGE PROCES, P2287
   Conner CE, 1997, J NEUROSCI, V17, P3201
   Cornia M, 2016, LECT NOTES COMPUT SC, V9914, P302, DOI 10.1007/978-3-319-48881-3_21
   ERIKSEN BA, 1974, PERCEPT PSYCHOPHYS, V16, P143, DOI 10.3758/BF03203267
   Fosco Camilo, 2019, SVRHM WORKSHOP NEURI
   Gao D., 2008, Advances in Neural Information Processing Systems 20, P497
   Gao W., 2011, VISUAL SALIENCY COMP
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang XG, 2015, 2015 IEEE International Conference on Applied Superconductivity and Electromagnetic Devices (ASEMD), P262, DOI 10.1109/ASEMD.2015.7453564
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kienzle W, 2009, J VISION, V9, DOI 10.1167/9.5.7
   Kiimmerer M., 2014, ARXIV01047
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Korner A, 2019, IEEE T MULTIMEDIA
   Kroner A., 2019, ARXIV06634
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2015, P NATL ACAD SCI USA, V112, P16054, DOI 10.1073/pnas.1510393112
   Kummerer M., MIT/Tuebingen saliency benchmark
   Kummerer Matthias, 2016, CoRR
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Lin Y, 2011, EUR C COMP VIS, p710 755
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Nguyen TV, 2019, IEEE T IMAGE PROCESS, V28, P3130, DOI 10.1109/TIP.2019.2894284
   O'Craven KM, 1999, NATURE, V401, P584, DOI 10.1038/44134
   OCraven KM, 1997, NEURON, V18, P591, DOI 10.1016/S0896-6273(00)80300-1
   Pan J., 2020, COMPUT VIS IMAGE UND
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Parks D, 2015, VISION RES, V116, P113, DOI 10.1016/j.visres.2014.10.027
   POTTER MC, 1976, J EXP PSYCHOL-HUM L, V2, P509, DOI 10.1037/0278-7393.2.5.509
   Rajan Y. D., 2005, 2005 1EEE INT C MULT
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tavakoli HR, 2019, IEEE WINT CONF APPL, P273, DOI 10.1109/WACV.2019.00035
   Thorpe S, 1996, NATURE, V381, P520, DOI 10.1038/381520a0
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E., 2011, P IEEE C COMP VIS PA, p2798 2805
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   WANG Q, 2016, IEEE T NEUR NET LEAR, V27, P1279, DOI DOI 10.1109/TNNLS.2015.2477537
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang WH, 2019, MINIM INVASIV THER, DOI 10.1080/13645706.2019.1602544
   Wu Y., 2019, DETECTRON2
   Yan C, 2020, T PATTERN ANAL MACH
   Yin Li, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P246
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 66
TC 2
Z9 2
U1 3
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2020
VL 73
AR 102931
DI 10.1016/j.jvcir.2020.102931
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA PE7QD
UT WOS:000598557000006
DA 2024-07-18
ER

PT J
AU Afonso, LCS
   Pereira, CR
   Weber, SAT
   Hook, C
   Falcao, AX
   Papa, JP
AF Afonso, Luis C. S.
   Pereira, Clayton R.
   Weber, Silke A. T.
   Hook, Christian
   Falcao, Alexandre X.
   Papa, Joao P.
TI Hierarchical learning using deep optimum-path forest
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Parkinson's disease; Optimum-path forest; Handwriting dynamics;
   Hierarchical representation
ID PATTERN-CLASSIFICATION
AB Bag-of-Visual Words (BoVW) and deep learning techniques have been widely used in several domains, which include computer-assisted medical diagnoses. In this work, we are interested in developing tools for the automatic identification of Parkinson's disease using machine learning and the concept of BoVW. The proposed approach concerns a hierarchical-based learning technique to design visual dictionaries through the Deep Optimum-Path Forest classifier. The proposed method was evaluated in six datasets derived from data collected from individuals when performing handwriting exams. Experimental results showed the potential of the technique, with robust achievements. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Afonso, Luis C. S.] UFSCar Fed Univ Sao Carlos, Dept Comp, Sao Carlos, Brazil.
   [Pereira, Clayton R.; Weber, Silke A. T.; Papa, Joao P.] UNESP Sao Paulo State Univ, Sch Sci, Bauru, SP, Brazil.
   [Hook, Christian] Ostbayer TH, Regensburg, Germany.
   [Falcao, Alexandre X.] UNICAMP Univ Campinas, Inst Comp, Campinas, Brazil.
C3 Universidade Federal de Sao Carlos; Universidade Estadual Paulista;
   Universidade Estadual de Campinas
RP Papa, JP (corresponding author), UNESP Sao Paulo State Univ, Sch Sci, Dept Comp, Sao Paulo, Brazil.
EM sugi.luis@ufscar.br; clayton.pereira@unesp.br; silke@fmb.unesp.br;
   christian.hook@hs-regensburg.de; afalcao@ic.unicamp.br;
   joao.papa@unesp.br
RI Weber, Silke Anna Theresa/H-9340-2019; Pereira, Clayton/AAG-2870-2020;
   Falcão, Alexandre X/F-8361-2012; Papa, Joao Paulo/ABC-6283-2020
OI Weber, Silke Anna Theresa/0000-0003-3194-3039; Pereira,
   Clayton/0000-0002-0427-4880; Falcão, Alexandre X/0000-0002-2914-5380;
   Papa, Joao Paulo/0000-0002-6494-7514
FU FAPESP [2013/07375-0, 2014/12236-1, 2019/07665-4]; CNPq [307066/2017-7,
   427968/2018-6]; Coordenacao de Aperfeicoamento de Pessoal de Nivel
   Superior - Brasil (CAPES) [001]
FX The authors are grateful to FAPESP grants #2013/07375-0, #2014/12236-1,
   #2019/07665-4, as well as CNPq grants #307066/2017-7 and #427968/2018-6.
   This study was financed in part by the Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior - Brasil (CAPES) - Finance Code 001.
CR Afonso L, 2012, IEEE IMAGE PROC, P1897, DOI 10.1109/ICIP.2012.6467255
   Afonso L.C.S., 2018, PATTERN RECOGN UNPUB
   Afonso L, 2016, SIBGRAPI, P401, DOI [10.1109/SIBGRAPI.2016.062, 10.1109/SIBGRAPI.2016.59]
   Afonso LCS, 2017, SIBGRAPI, P163, DOI 10.1109/SIBGRAPI.2017.28
   Amorim WP, 2016, PATTERN RECOGN, V60, P72, DOI 10.1016/j.patcog.2016.04.020
   [Anonymous], 2017, PATTERN RECOGNIT LET
   Avni U, 2011, IEEE T MED IMAGING, V30, P733, DOI 10.1109/TMI.2010.2095026
   Bächlin M, 2010, IEEE T INF TECHNOL B, V14, P436, DOI 10.1109/TITB.2009.2036165
   Caicedo JC, 2009, LECT NOTES ARTIF INT, V5651, P126, DOI 10.1007/978-3-642-02976-9_17
   Castelo-Fernández C, 2015, LECT NOTES COMPUT SC, V9423, P760, DOI 10.1007/978-3-319-25751-8_91
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Eckmann J.-P., 1997, EUROPHYS LETT, V9, P973
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Nye M., 2018, P INT C LEARN REPR
   Papa JP, 2009, INT J IMAG SYST TECH, V19, P120, DOI 10.1002/ima.20188
   Papa JP, 2012, PATTERN RECOGN, V45, P512, DOI 10.1016/j.patcog.2011.07.013
   Papa JP, 2017, PATTERN RECOGN LETT, V87, P117, DOI 10.1016/j.patrec.2016.07.026
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pereira CR, 2016, SIBGRAPI, P340, DOI [10.1109/SIBGRAPI.2016.054, 10.1109/SIBGRAPI.2016.51]
   Pereira CR, 2016, COMPUT METH PROG BIO, V136, P79, DOI 10.1016/j.cmpb.2016.08.005
   Rigas G, 2012, IEEE T INF TECHNOL B, V16, P478, DOI 10.1109/TITB.2011.2182616
   Rocha LM, 2009, INT J IMAG SYST TECH, V19, P50, DOI 10.1002/ima.20191
   Rosa GH, 2014, INT C PATT RECOG, P1472, DOI 10.1109/ICPR.2014.262
   Schwenker F, 2014, PATTERN RECOGN LETT, V37, P4, DOI 10.1016/j.patrec.2013.10.017
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Souza LA, 2017, SIBGRAPI, P308, DOI 10.1109/SIBGRAPI.2017.47
   Spadoto AA, 2011, IEEE ENG MED BIO, P7857, DOI 10.1109/IEMBS.2011.6091936
   Spadoto AA, 2010, IEEE ENG MED BIO, P6087, DOI 10.1109/IEMBS.2010.5627634
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
NR 30
TC 3
Z9 3
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102823
DI 10.1016/j.jvcir.2020.102823
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, YD
   He, HM
   Zhang, ZX
AF Li, Yedong
   He, Hongmei
   Zhang, Zhixin
TI Human motion quality assessment toward sophisticated sports scenes based
   on deeply-learned 3D CNN model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Quality assessment; Deep learning; Human activities; Big data; Neural
   networks
ID IMAGE; INFORMATION; SIMILARITY
AB Video may be subject to various distortions during acquisition, processing, compression, storage, transmission, and reproduction, and it results in reduced visual quality. In complex sports scenes under big data environment, the human body's movements are even more so. The quality of human motion can intuitively affect the human visual experience. Therefore, it is necessary to determine an intelligent quality assessment model to evaluate human motion in complex motion scenarios under big data environment. It can be used to dynamically monitor and adjust video quality, and it can be used for algorithms and parameter settings in motion image processing systems. With the popularity of deep learning, convolutional neural networks have become a very important method in the field of computer vision research. Based on the 2D-CNN algorithm, we propose a 3D convolutional neural network model for human motion quality assessment in complex motion scenarios. The model captures the pose characteristics, motion trajectory, video brightness and contrast in time and space. The model feeds back the reference and distorted video pairs into the network, with each output layer acting as a feature map. The local similarity between the feature maps obtained from the reference video and the distorted video is then calculated and combined to obtain a global image quality score. Experiments show that the model can achieve competitive performance in big data environment for video quality assessment. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Li, Yedong; He, Hongmei] Taiyuan Univ, Taiyuan, Peoples R China.
   [Zhang, Zhixin] Tianjin Univ Commerce, Informat Engn Dept, Tianjin, Peoples R China.
C3 Taiyuan University; Tianjin University of Commerce
RP Li, YD (corresponding author), Taiyuan Univ, Taiyuan, Peoples R China.
EM liyedong888@126.com
CR Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Gao F, 2017, NEUROCOMPUTING, V257, P104, DOI 10.1016/j.neucom.2017.01.054
   Girod Bernd, 1993, P207
   Jayaraman D, 2012, CONF REC ASILOMAR C, P1693, DOI 10.1109/ACSSC.2012.6489321
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Liang YD, 2016, LECT NOTES COMPUT SC, V9909, P3, DOI 10.1007/978-3-319-46454-1_1
   Luvizon D. C., 2017, Human pose regression by combining indirect part detection and contextual information
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Na S, 2017, IEEE I CONF COMP VIS, P677, DOI 10.1109/ICCV.2017.80
   Ning F, 2005, IEEE T IMAGE PROCESS, V14, P1360, DOI 10.1109/TIP.2005.852470
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Shahroudy Amir, 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   TEO PC, 1994, P SOC PHOTO-OPT INS, V2179, P127, DOI 10.1117/12.172664
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou X., 2017, ARXIV170102354
NR 28
TC 3
Z9 4
U1 2
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102702
DI 10.1016/j.jvcir.2019.102702
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900013
DA 2024-07-18
ER

PT J
AU Liu, SG
   Wang, YH
   Wu, XS
   Li, J
   Lei, T
AF Liu, Shigang
   Wang, Yuhong
   Wu, Xiaosheng
   Li, Jun
   Lei, Tao
TI Discriminative dictionary learning algorithm based on sample diversity
   and locality of atoms for face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dictionary learning; Face recognition; Locality constrained; Sample
   diversity
ID SPARSE REPRESENTATION; COLLABORATIVE REPRESENTATION; OVERCOMPLETE
   DICTIONARIES; CLASSIFICATION METHOD; LINEAR-REGRESSION; CROWD
   EVACUATION; K-SVD; ROBUST; ILLUMINATION
AB Dictionary learning is one of the most important algorithms for face recognition. However, many dictionary learning algorithms for face recognition have the problems of small sample and weak discriminability. In this paper, a novel discriminative dictionary learning algorithm based on sample diversity and locality of atoms is proposed to solve the problems. The rational sample diversity is implemented by alternative samples and new error model to alleviate the small sample size problem. Moreover, locality can leads to sparsity and strong discriminability. In this paper, to enhance the dictionary discrimination and to reduce the influence of noise, the graph Laplacian matrix of atoms is used to keep the local information of the data. At the same, the relational theory is presented. A large number of experiments prove that the proposed algorithm can achieve more high performance than some state-of-the-art algorithms. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Liu, Shigang; Wu, Xiaosheng] Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454001, Henan, Peoples R China.
   [Liu, Shigang; Wang, Yuhong] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
   [Li, Jun] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210046, Peoples R China.
   [Lei, Tao] Shaanxi Univ Sci & Technol, Coll Elect & Informat Engn, Xian 710021, Peoples R China.
C3 Henan Polytechnic University; Shaanxi Normal University; Nanjing Normal
   University; Shaanxi University of Science & Technology
RP Wu, XS (corresponding author), Henan Polytech Univ, Sch Comp Sci & Technol, Jiaozuo 454001, Henan, Peoples R China.
EM sxwu_hn@163.com
RI Wang, Yu/GZL-9655-2022
OI lei, tao/0000-0001-9639-6043
FU National Natural Science Foundation of China [61672333]; National
   Natural Science Foundation of Shaanxi Province [2018JM6050]; Transfer
   and Promotion Plan of Scientific and Technological Achievements of
   Shaanxi Province [2019CGXNG-019]; Innovation Chain of Key Industries of
   Shaanxi Province [2019ZDLSF07-01]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61672333), the National Natural Science Foundation of Shaanxi
   Province (No.2018JM6050), Transfer and Promotion Plan of Scientific and
   Technological Achievements of Shaanxi Province (No.2019CGXNG-019),
   Innovation Chain of Key Industries of Shaanxi Province
   (No.2019ZDLSF07-01).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2019, IEEE ACCESS
   [Anonymous], 2007, P TENCON IEEE REG 10
   [Anonymous], 2009, P ADV NEUR INF PROC
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chen ScottShaobing., 2001, SIAM Journal on Scientific Computing, V20, P33
   Du B, 2019, IEEE T GEOSCI REMOTE, V57, P6003, DOI 10.1109/TGRS.2019.2903875
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gong C, 2019, IEEE T CYBERNETICS, V49, P388, DOI 10.1109/TCYB.2017.2773562
   Gong C, 2018, IEEE T CYBERNETICS, V48, P967, DOI 10.1109/TCYB.2017.2669639
   Gong C, 2016, IEEE T IMAGE PROCESS, V25, P3249, DOI 10.1109/TIP.2016.2563981
   Gong C, 2015, IEEE T NEUR NET LEAR, V26, P2261, DOI 10.1109/TNNLS.2014.2376936
   Haghiri S, 2014, IEEE IMAGE PROC, P5242, DOI 10.1109/ICIP.2014.7026061
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   Laanaya H, 2011, PATTERN RECOGN LETT, V32, P1511, DOI 10.1016/j.patrec.2011.05.009
   Li LJ, 2018, ARTIF INTELL REV, V50, P1, DOI 10.1007/s10462-016-9537-z
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liu H, 2018, APPL SOFT COMPUT, V68, P360, DOI 10.1016/j.asoc.2018.04.015
   Liu H, 2018, INFORM SCIENCES, V436, P247, DOI 10.1016/j.ins.2018.01.023
   Liu SG, 2016, J MOD OPTIC, V63, P1181, DOI 10.1080/09500340.2015.1133857
   Liu SG, 2016, SIGNAL PROCESS, V124, P141, DOI 10.1016/j.sigpro.2015.09.033
   Liu WF, 2018, INFORM FUSION, V41, P119, DOI 10.1016/j.inffus.2017.09.001
   Liu ZH, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107456
   Liu ZH, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105768
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Martinez A., 1998, AR FACE DATABASE
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Peng Y., 2017, COMPLEXITY, V2017, P1
   Peng YL, 2020, NEUROCOMPUTING, V398, P505, DOI 10.1016/j.neucom.2019.05.103
   Peng YL, 2019, INT J MACH LEARN CYB, V10, P2229, DOI 10.1007/s13042-018-0862-1
   Peng YL, 2020, PATTERN RECOGN LETT, V130, P99, DOI 10.1016/j.patrec.2018.09.008
   Peng YL, 2019, IET COMPUT VIS, V13, P172, DOI 10.1049/iet-cvi.2018.5096
   Peng YL, 2018, PATTERN RECOGN LETT, V116, P170, DOI 10.1016/j.patrec.2018.10.016
   Peng YL, 2018, MACH VISION APPL, V29, P991, DOI 10.1007/s00138-018-0941-z
   Peng YL, 2018, NEURAL PROCESS LETT, V48, P313, DOI 10.1007/s11063-017-9721-4
   Peng YL, 2018, SIGNAL PROCESS, V147, P101, DOI 10.1016/j.sigpro.2018.01.013
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Sadeghi M, 2014, IEEE T SIGNAL PROCES, V62, P883, DOI 10.1109/TSP.2013.2295062
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang YH, 2018, LECT NOTES COMPUT SC, V11165, P538, DOI 10.1007/978-3-030-00767-6_50
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Xu Y, 2017, INFORM SCIENCES, V375, P171, DOI 10.1016/j.ins.2016.09.059
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2013, INFORM SCIENCES, V238, P138, DOI 10.1016/j.ins.2013.02.051
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu Y, 2010, PATTERN RECOGN, V43, P4165, DOI 10.1016/j.patcog.2010.06.016
   Yang JY, 2015, IEEE T CYBERNETICS, V45, P913, DOI 10.1109/TCYB.2014.2340032
   Yang WK, 2020, NEUROCOMPUTING, V373, P109, DOI 10.1016/j.neucom.2019.09.102
   Yang WK, 2019, MULTIMED TOOLS APPL, V78, P24373, DOI 10.1007/s11042-018-6995-0
   Yang WK, 2018, IEEE ACCESS, V6, P7445, DOI 10.1109/ACCESS.2017.2784800
   Yang WK, 2016, NEUROCOMPUTING, V175, P198, DOI 10.1016/j.neucom.2015.10.049
   Zhang J, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P589, DOI 10.1109/ICSESS.2014.6933637
   Zhang LF, 2018, IEEE T CYBERNETICS, V48, P16, DOI 10.1109/TCYB.2016.2605044
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhu X., 2005, P 22 INT C MACH LEAR, P1052, DOI DOI 10.1145/1102351.1102484
NR 66
TC 11
Z9 11
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102763
DI 10.1016/j.jvcir.2020.102763
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900028
DA 2024-07-18
ER

PT J
AU Silva, SM
   Jung, CR
AF Silva, Sergio Montazzolli
   Jung, Claudio Rosito
TI Real-time license plate detection and recognition using deep
   convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural networks; License plate; Deep learning
ID VEHICLE
AB Automatic License Plate Recognition (ALPR) is an important task with many applications in Intelligent Transportation and Surveillance systems. This work presents an end-to-end ALPR method based on a hierarchical Convolutional Neural Network (CNN). The core idea of the proposed method is to identify the vehicle and the license plate region using two passes on the same CNN, and then to recognize the characters using a second CNN. The recognition CNN massively explores the use of synthetic and augmented data to cope with limited training datasets, and our results show that the augmentation process significantly increases the recognition rate. In addition, we present a novel temporal coherence technique to better stabilize the OCR output in videos. Our method was tested with publicly available datasets containing Brazilian and European license plates, achieving accuracy rates better than competitive academic methods and a commercial system. (c) 2020 Elsevier Inc. All rights reserved.
C1 [Silva, Sergio Montazzolli] Univ Estadual Londrina, Rodovia Celso Garcia Cid,PR 445 Km 380, Londrina, Parana, Brazil.
   [Jung, Claudio Rosito] Univ Fed Rio Grande do Sul, Inst Informat, Av Bento Goncalves 9500, Porto Alegre, RS, Brazil.
C3 Universidade Estadual de Londrina; Universidade Federal do Rio Grande do
   Sul
RP Silva, SM (corresponding author), Univ Estadual Londrina, Rodovia Celso Garcia Cid,PR 445 Km 380, Londrina, Parana, Brazil.
EM smsilva@uel.br; crjung@inf.ufrgs.br
FU CAPES; CNPq; NVIDIA Corporation
FX The authors would like to thank the funding agencies CAPES and CNPq, as
   well as NVIDIA Corporation for the donation of the Titan X Pascal GPU
   used for this research.
CR Anagnostopoulos CNE, 2014, IEEE INTEL TRANSP SY, V6, P59, DOI 10.1109/MITS.2013.2292652
   Bulan O, 2017, IEEE T INTELL TRANSP, V18, P2351, DOI 10.1109/TITS.2016.2639020
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Dong M., 2017, 2017 IEEE 3 VR WORKS, P1
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goncalves GR, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.069801
   Gonçalves GR, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2577, DOI 10.1109/ITSC.2016.7795970
   Gou C, 2016, IEEE T INTELL TRANSP, V17, P1096, DOI 10.1109/TITS.2015.2496545
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   HSU GS, 2017, 2017 14 IEEE INT C A, DOI DOI 10.1109/AVSS.2017.8078493
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Huihua Yang, 2013, 2013 Fifth International Conference on Computational and Information Sciences (ICCIS 2013), P1080, DOI 10.1109/ICCIS.2013.287
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Jain V, 2016, TENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2016), DOI 10.1145/3009977.3010052
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Kurpiel FD, 2017, IEEE IMAGE PROC, P3395, DOI 10.1109/ICIP.2017.8296912
   Laroca R., 2018, 2018 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2018.8489629
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Masood S.Z., ARXIV170307330
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Montazzolli S, 2017, SIBGRAPI, P55, DOI 10.1109/SIBGRAPI.2017.14
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Prates R. F., 2013, International Journal of Computer Science & Information Technology, V5, P39, DOI 10.5121/ijcsit.2013.5603
   Psyllos A, 2011, COMPUT STAND INTER, V33, P142, DOI 10.1016/j.csi.2010.06.005
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selmi Z, 2017, PROC INT CONF DOC, P1132, DOI 10.1109/ICDAR.2017.187
   Sung MC, 2015, PROC INT CONF DOC, P426, DOI 10.1109/ICDAR.2015.7333797
   Xie LL, 2018, IEEE T INTELL TRANSP, V19, P507, DOI 10.1109/TITS.2017.2784093
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yosinski J., 2014, Adv Neural Inf Process Syst, V2, P3320, DOI DOI 10.48550/ARXIV.1411.1792
   Yuan YL, 2017, IEEE T IMAGE PROCESS, V26, P1102, DOI 10.1109/TIP.2016.2631901
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 39
TC 62
Z9 63
U1 4
U2 60
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102773
DI 10.1016/j.jvcir.2020.102773
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WP
UT WOS:000571423900014
DA 2024-07-18
ER

PT J
AU Su, C
   Huang, HY
   Shi, SM
   Jian, P
   Shi, XW
AF Su, Chao
   Huang, Heyan
   Shi, Shumin
   Jian, Ping
   Shi, Xuewen
TI Neural machine translation with Gumbel Tree-LSTM based encoder
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Neural machine translation; Tree to sequence; Gumbel Tree-LSTM
ID MODELS; FIELD
AB Neural machine translation has improved the translation accuracy greatly and received great attention of the machine translation community. Tree-based translation models aim to model the syntactic or semantic relation among long-distance words or phrases in a sentence. However, it faces the difficulties of expensive manual annotation cost and poor automatic annotation accuracy. In this paper, we focus on how to encode a source sentence into a vector in a unsupervised-tree way and then decode it into a target sentence. Our model incorporates Gumbel Tree-LSTM, which can learn how to compose tree structures from plain text without any tree annotation. We evaluate the proposed model on both spoken and news corpora, and show that the performance of our proposed model outperforms the attentional seq2seq model and the Transformer base model. (c) 2020 Published by Elsevier Inc.
C1 [Su, Chao; Huang, Heyan; Shi, Shumin; Jian, Ping; Shi, Xuewen] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Huang, Heyan; Shi, Shumin; Jian, Ping] Beijing Engn Res Ctr High Volume Language Informa, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Huang, HY (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
EM hhy63@bit.edu.cn
RI Su, Chao/H-3119-2015; su, chao/JXW-9081-2024; Su, Chao/Q-7200-2016
OI Su, Chao/0000-0001-6771-329X
FU National Natural Science Foundation of China [61732005, 61671064];
   National Key Research and Development Program of China [2017YFB1002103]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61732005 and 61671064) and the National Key Research
   and Development Program of China (Grant No. 2017YFB1002103).
CR Alvarez-Melis D., 2017, 5 INT C LEARN REPR I
   [Anonymous], 2018, TACL, DOI 10.1162/tacl_a_00019
   [Anonymous], 2015, P 2015 C EMP METH NA
   [Anonymous], 2016, ABS160906038 CORR
   [Anonymous], 2019, P 2019 C N AM CHAPT
   [Anonymous], 2011, P 49 ANN M ASS COMP
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/D15-1166, DOI 10.48550/ARXIV.1508.04025]
   Chaplot DS, 2015, AAAI CONF ARTIF INTE, P2217
   Che W., 2010, Proceedings of the 23rd international conference on computational linguistics: Demonstrations, P13
   Chen HD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1936, DOI 10.18653/v1/P17-1177
   Chen Ping., 2009, Proceedings of the The Annual Conference of the North American Chapter of the Association for Computational Linguistics, P28
   Chen Xieling, 2018, Wireless Communications and Mobile Computing, V2018, P1, DOI DOI 10.1109/JI0T.2018.2876279
   Chiang David, 2005, 43rd Annual Meeting on Association for Computational Linguistics, P263
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Choi J, 2018, AAAI CONF ARTIF INTE, P5094
   CHOMSKY N, 1956, IRE T INFORM THEOR, V2, P113
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA, V11
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Drozdov A., 2019, P 2019 C N AM CHAPT, P1129, DOI 10.18653/v1/N19-1116.
   Dyer C., 2016, ARXIV160207776, DOI DOI 10.18653/V1/N16-1024
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Eriguchi A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P823
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Isozaki H., 2010, P 2010 C EMP METH NA, P944
   Jang E., 2017, P INT C LEARN REPR
   King DB, 2015, ACS SYM SER, V1214, P1
   Koehn Philipp, 2004, EMNLP
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li J., 2015, P C EMPIRICAL METHOD, P2304
   Li JH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P688, DOI 10.18653/v1/P17-1064
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Long QX, 2020, NAT MED, V26, P845, DOI 10.1038/s41591-020-0897-1
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Lu WP, 2018, IEICE T INF SYST, VE101D, P225, DOI 10.1587/transinf.2017EDP7090
   Ma X., 2006, P 5 INT C LANG RES A, P489
   Maddison C. J., 2017, 5 INT C LEARN REPR I
   Miyao Y, 2008, COMPUT LINGUIST, V34, P35, DOI 10.1162/coli.2008.34.1.35
   Neubig G., 2011, P 49 ANN M ASS COMP, P529
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Saier MH, 2007, WATER AIR SOIL POLL, V181, P1, DOI 10.1007/s11270-007-9372-6
   Shen Y., 2018, 6 INT C LEARN REPR I
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Song ZY, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1699
   Sutskever I, 2014, ADV NEUR IN, V27
   Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556
   Tran K, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P25
   Vaswani A, 2017, ADV NEUR IN, V30
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Xu XL, 2020, IEEE T IND INFORM, V16, P6172, DOI 10.1109/TII.2019.2959258
   Xu X, 2019, WORLD WIDE WEB, V22, P657, DOI 10.1007/s11280-018-0541-x
   Yamada K, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P523
   Yogatama D., 2017, 5 INT C LEARN REPR I
   Zhang XY, 2016, AER ADV ENG RES, V63, P310
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
   Zhou GB, 2018, AAAI CONF ARTIF INTE, P5722
   Zhu XD, 2015, PR MACH LEARN RES, V37, P1604
NR 59
TC 22
Z9 22
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102811
DI 10.1016/j.jvcir.2020.102811
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR2WK
UT WOS:000571423400007
DA 2024-07-18
ER

PT J
AU Long, TH
   Sun, YF
   Gao, JB
   Hu, YL
   Yin, BC
AF Long, Tianhang
   Sun, Yanfeng
   Gao, Junbin
   Hu, Yongli
   Yin, Baocai
TI Locality preserving projection based on Euler representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Locality preserving projection; Euler representation; Dimensionality
   reduction
ID ROBUST; SALIENCY
AB Locality preserving projection (LPP) is a widely used linear dimensionality reduction method, which preserves the locality structure of the original data. Motivated by the fact that kernel technique can capture nonlinear similarity of features and help to improve separability between nearby data points, this paper proposes locality preserving projection model based on Euler representation (named as ELPP). This model first projects the data into a complex space with Euler representation, then learns the dimensionality reduction projection with preserving locality structure in this complex space. We also extend ELPP to F-ELPP by replacing the squared F-norm with F-norm, which will weaken the exaggerated errors and be more robustness to outliers. The optimization algorithms of the two models are given, and the convergence of F-ELPP is proved. A large number of experiments on several public databases have demonstrated that the two proposed models have good robustness and feature extraction ability. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Long, Tianhang; Sun, Yanfeng; Hu, Yongli] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Gao, Junbin] Univ Sydney, Sch Business, Discipline Business Analyt, Sydney, NSW 2006, Australia.
   [Yin, Baocai] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Beijing University of Technology; University of Sydney; Dalian
   University of Technology
RP Sun, YF (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM longtianhang@emails.bjut.edu.cn; yfsun@bjut.edu.cn;
   junbin.gao@sydney.edu.au; huyongli@bjut.edu.cn; ybc@dlut.edu.cn
RI Gao, Junbin/C-6566-2008; Long, Tianhang/HLX-8827-2023; Gao,
   Junbin/A-1766-2009
OI Long, Tianhang/0000-0001-7186-8657; Gao, Junbin/0000-0001-9803-0256
FU National Natural Science Foundation of China [61772048, 61632006,
   61672071, U1811463, U19B2039]; Beijing Talents Project [2017A24]
FX This research was supported by National Natural Science Foundation of
   China under Grant 61772048, 61632006, 61672071, U1811463, U19B2039.
   Beijing Talents Project (2017A24).
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Benavente R, 1998, 24 COMP VIS CTR
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Fitch AJ, 2005, IEEE T IMAGE PROCESS, V14, P1063, DOI 10.1109/TIP.2005.849767
   Floudas C.C.A., 2009, REFERENCE REV, V584, P31
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Hu XJ, 2018, AAAI CONF ARTIF INTE, P1330
   Huang J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P327
   Huber Peter J, 2011, ROBUST STAT, P1248
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Liu Y, 2018, AAAI CONF ARTIF INTE, P3691
   Liu Y, 2019, NEURAL NETWORKS, V115, P65, DOI 10.1016/j.neunet.2019.03.008
   Liu Y, 2017, IEEE T IMAGE PROCESS, V26, P684, DOI 10.1109/TIP.2016.2621667
   Liwicki S, 2013, INT J COMPUT VISION, V101, P498, DOI 10.1007/s11263-012-0558-z
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Pang Y, 2019, MICRO NANO TECHNOL, P1, DOI 10.1016/B978-0-12-814154-0.00001-3
   Peng L, 2003, BIOMETRIKA, V90, P967, DOI 10.1093/biomet/90.4.967
   Sanderson C, 2009, LECT NOTES COMPUT SC, V5558, P199, DOI 10.1007/978-3-642-01793-3_21
   Yao C, 2017, IEEE T IMAGE PROCESS, V26, P5257, DOI 10.1109/TIP.2017.2733200
   Yao C, 2014, NEUROCOMPUTING, V138, P310, DOI 10.1016/j.neucom.2014.02.004
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yu WZ, 2018, NEUROCOMPUTING, V316, P322, DOI 10.1016/j.neucom.2018.08.008
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhou T, 2017, IEEE T CIRC SYST VID, V27, P2153, DOI 10.1109/TCSVT.2016.2576941
NR 29
TC 6
Z9 8
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102796
DI 10.1016/j.jvcir.2020.102796
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900012
DA 2024-07-18
ER

PT J
AU Park, J
   Lee, BU
AF Park, Junhee
   Lee, Byung-Uk
TI Color image enhancement with high saturation using piecewise linear
   gamut mapping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gamut mapping; Color enhancement; Hue preservation; Color saturation
ID HISTOGRAM; HUE
AB Most of the color image enhancement algorithms are implemented in two stages: gray scale image enhancement, which finds the target intensity, and then gamut mapping of the original color coordinates to the target. Therefore, hue preserving gamut mapping is an essential and crucial step, which influences colorfulness. In conventional color mapping methods, color saturation is reduced after intensity modification, which deteriorates subjective image quality. In this paper, a new color enhancement algorithm resulting in high color saturation is proposed. The proposed method employs multiplicative and additive color mapping to improve color saturation without clipping of a color component for increased target intensity as well as decreased cases. This new scheme is fast and effective, therefore, it can be employed to real time applications such as video signal processing. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Park, Junhee; Lee, Byung-Uk] Ewha Womans Univ, Elect & Elect Engn, Seoul 03760, South Korea.
C3 Ewha Womans University
RP Lee, BU (corresponding author), 429 Asan Hall,52 Ewhayeodae Gil, Seoul 03760, South Korea.
EM bulee@ewha.ac.kr
OI Lee, Byung-Uk/0000-0002-3452-3016
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2019R1I1A1A01040652]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2019R1I1A1A01040652) and JP and BUL thank HT, Inc. for
   evaluation of the proposed algorithm.
CR Azetsu T, 2019, OPT REV, V26, P283, DOI 10.1007/s10043-019-00499-2
   Gonzalez R., 2018, DIGITAL IMAGE PROCES, V4th, P133
   Han JH, 2011, IEEE T IMAGE PROCESS, V20, P506, DOI 10.1109/TIP.2010.2068555
   Inoue K, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030024
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Ku CC, 2005, IEEE T CONSUM ELECTR, V51, P939, DOI 10.1109/TCE.2005.1510507
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Naik SK, 2003, IEEE T IMAGE PROCESS, V12, P1591, DOI 10.1109/TIP.2003.819231
   Nikolova M, 2014, IEEE T IMAGE PROCESS, V23, P4087, DOI 10.1109/TIP.2014.2337755
   Nnolim UA, 2018, OPTIK, V154, P192, DOI 10.1016/j.ijleo.2017.09.102
   Park GH, 2008, IEEE T CONSUM ELECTR, V54, P1981, DOI 10.1109/TCE.2008.4711262
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Song KS, 2016, J OPT SOC AM A, V33, P1076, DOI 10.1364/JOSAA.33.001076
   Tian QC, 2018, SIGNAL PROCESS, V153, P210, DOI 10.1016/j.sigpro.2018.07.022
   Ueda Y, 2018, IEEE IMAGE PROC, P1123, DOI 10.1109/ICIP.2018.8451308
   Yang S, 2013, ELECTRON LETT, V49, P1221, DOI 10.1049/el.2013.0221
NR 16
TC 6
Z9 6
U1 1
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2020
VL 67
AR 102759
DI 10.1016/j.jvcir.2020.102759
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KX1OZ
UT WOS:000521653800005
DA 2024-07-18
ER

PT J
AU Manimaran, A
   Ramanathan, T
   You, SY
   Kuo, CCJ
AF Manimaran, Abinaya
   Ramanathan, Thiyagarajan
   You, Suya
   Kuo, C-C Jay
TI Visualization, Discriminability and Applications of Interpretable Saak
   Features
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saak transform; Interpretable machine learning; Image classification;
   Adversarial attacks
AB In this work, we study the power of Saak features as an effort towards interpretable deep learning. Being inspired by the operations of convolutional layers of convolutional neural networks, multi-stage Saak transform was proposed. Based on this foundation, we provide an in-depth examination on Saak features, which are coefficients of the Saak transform, by analyzing their properties through visualization and demonstrating their applications in image classification. Being similar to CNN features, Saak features at later stages have larger receptive fields, yet they are obtained in a one-pass feedforward manner without backpropagation. The whole feature extraction process is transparent and is of extremely low complexity. The discriminant power of Saak features is demonstrated, and their classification performance in three well-known datasets (namely, MNIST, CIFAR-10 and STL-10) is shown by experimental results. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Manimaran, Abinaya; Ramanathan, Thiyagarajan; Kuo, C-C Jay] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [You, Suya] US Army, Res Lab, Playa Vista, CA USA.
C3 University of Southern California; United States Department of Defense;
   US Army Research, Development & Engineering Command (RDECOM); US Army
   Research Laboratory (ARL)
RP Manimaran, A (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM manimara@usc.edu; tramanat@usc.edu
RI Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU U.S. Army Research Laboratory's External Collaboration Initiative (ECI)
   of the Director's Research Initiative (DRIA) program
FX This research was supported by the U.S. Army Research Laboratory's
   External Collaboration Initiative (ECI) of the Director's Research
   Initiative (DRIA) program. The views and conclusions contained in this
   document are those of the authors and should not be interpreted as
   representing the official policies, either expressed or implied, of the
   U.S. Army Research Laboratory or the U.S. Government. The U.S.
   Governments are authorized to reproduce and distribute reprints for
   Government purposes notwithstanding any copyright notation hereon.
CR [Anonymous], ARXIV160702533V4
   [Anonymous], 2018, IEEE TPAMI
   [Anonymous], 1986, Probability, random processes, and estimation theory for engineers
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Chen YR, 2018, PICT COD SYMP, P174, DOI 10.1109/PCS.2018.8456277
   Goodfellow I.J., 2015, INT C LEARN REPR ICL, P1
   Grosse K., 2017, ARXIV
   Krizhevsky Alex, 2009, CIFAR 10 CANADIAN I
   Kuo CCJ, 2018, J VIS COMMUN IMAGE R, V50, P237, DOI 10.1016/j.jvcir.2017.11.023
   Kuo CCJ, 2017, IEEE SIGNAL PROC MAG, V34, P81, DOI 10.1109/MSP.2017.2671158
   Kuo CCJ, 2016, J VIS COMMUN IMAGE R, V41, P406, DOI 10.1016/j.jvcir.2016.11.003
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song S., 2018, ARXIV180801785
   Szegedy Christian, 2014, INT C LEARN REPR INT
   Tramer F., 2018, ICLR 18
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 24
TC 3
Z9 3
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102699
DI 10.1016/j.jvcir.2019.102699
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tahir, M
   Taj, IA
   Assuncao, PA
   Asif, M
AF Tahir, Muhammad
   Taj, Imtiaz A.
   Assuncao, Pedro A.
   Asif, Muhammad
TI Low complexity high efficiency coding of light fields using ensemble
   classifiers
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Light fields; HEVC; Fast encoding; Machine learning; Random forests
ID DECISION; REPRESENTATION
AB Light field images can be efficiently compressed using standard video codecs, such as the High Efficiency Video Coding (HEVC). However, the huge amount of data combined with the high computational complexity of HEVC, poses limitations on high-speed light field capturing and storage. This paper presents a contribution for low complexity encoding of light fields, in different formats using HEVC, based on a Random Forests ensemble classifier. Optimal features for training the classifier are found through a score fusion based approach. Using the HEVC still image profile, the proposed method gives speed-up of 56.23% for sub-aperture images. For pseudo video format, the proposed method outperforms others available in the literature, yielding an average speed-up of 62.18%, 56.54% and 44.73% for Random Access, Low-delay Main and All-Intra profiles respectively, with negligible decrease in RD performance. These are novel results in fast coding of light fields, which are useful for further research and benchmarking. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Tahir, Muhammad; Taj, Imtiaz A.] Capital Univ Sci & Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Assuncao, Pedro A.] Polytech Inst Leiria, P-2411901 Leiria, Portugal.
   [Assuncao, Pedro A.] Inst Telecomunicacoes, P-2411901 Leiria, Portugal.
   [Asif, Muhammad] Lahore Garrison Univ, Dept Comp Sci, Lahore, Pakistan.
C3 Capital University of Science & Technology
RP Tahir, M (corresponding author), Capital Univ Sci & Technol, Dept Elect Engn, Islamabad, Pakistan.
EM mtahir.awan@yahoo.com
RI Asif, Muhammad/JAC-2128-2023; Assuncao, Pedro A. Amado/A-4827-2017;
   tahir, muhammad/KAM-3327-2024
OI Asif, Muhammad/0000-0001-6811-0044; Assuncao, Pedro A.
   Amado/0000-0001-9539-8311; Taj, Imtiaz Ahmad/0000-0003-1813-5563
CR [Anonymous], 24 TELECOMMUNICATION
   [Anonymous], 8 INT WORKSH QUAL MU
   [Anonymous], P ISO IEC JTC 1 SC29
   [Anonymous], MOBILE NETWORKS APPL
   [Anonymous], IEEE J SELECTED TOPI
   [Anonymous], 2006, DIGITAL LIGHT FIELD
   [Anonymous], 2016, HIGH EFFICIENCY VIDE
   [Anonymous], 18 MED EL C MELECON
   Bjontegaard g, 2001, ITU-T SG16/Q6, VCEG-M33
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Chen ZY, 2017, J VIS COMMUN IMAGE R, V43, P77, DOI 10.1016/j.jvcir.2016.12.007
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Dessi N., 2009, J ARTIFICIAL EVOLUTI, P1
   Du BC, 2015, ASIAPAC SIGN INFO PR, P1085, DOI 10.1109/APSIPA.2015.7415439
   Ebrahimi T, 2016, IEEE MULTIMEDIA, V23, P14, DOI 10.1109/MMUL.2016.64
   Feng ZQ, 2018, IEEE ACCESS, V6, P45262, DOI 10.1109/ACCESS.2018.2864881
   Fernández DG, 2018, DIGIT SIGNAL PROCESS, V73, P24, DOI 10.1016/j.dsp.2017.11.001
   Gershun Andrei, 1939, J MATH PHYS, V18, P51, DOI [10.1002/sapm193918151, DOI 10.1002/SAPM193918151]
   Goswami K, 2018, IEEE T IND ELECTRON, V65, P8861, DOI 10.1109/TIE.2018.2815941
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Hou JH, 2019, IEEE T CIRC SYST VID, V29, P517, DOI 10.1109/TCSVT.2018.2802943
   Huang XP, 2017, SIGNAL IMAGE VIDEO P, V11, P33, DOI 10.1007/s11760-016-0887-4
   Lelescu D, 2004, GRAPH MODELS, V66, P203, DOI 10.1016/j.gmod.2004.05.003
   Leo Breiman, 2001, Machine learning, V45, P5
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Li YJ, 2009, PROC INT C TOOLS ART, P508, DOI 10.1109/ICTAI.2009.129
   Li Y, 2016, IEEE T CIRC SYST VID, V26, P1308, DOI 10.1109/TCSVT.2015.2450333
   Liu D., 2016, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1109/ICMEW.2016.7574674
   Perra C, 2016, IEEE INT CONF MULTI
   Rerabek M., 2016, JPEG Pleno Database: EPFL Light-field data set
   Santos JM, 2018, J VIS COMMUN IMAGE R, V54, P21, DOI 10.1016/j.jvcir.2018.03.003
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Tariq J, 2017, J VIS COMMUN IMAGE R, V44, P198, DOI 10.1016/j.jvcir.2017.01.029
   Vieira A, 2015, INT CONF IMAG PROC, P494, DOI 10.1109/IPTA.2015.7367195
   Wu GC, 2017, IEEE J-STSP, V11, P926, DOI 10.1109/JSTSP.2017.2747126
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhu LW, 2016, J VIS COMMUN IMAGE R, V38, P824, DOI 10.1016/j.jvcir.2016.04.020
NR 38
TC 1
Z9 1
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2020
VL 66
AR 102742
DI 10.1016/j.jvcir.2019.102742
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA KU4BZ
UT WOS:000519656200014
DA 2024-07-18
ER

PT J
AU Li, H
   Qi, F
   Shi, GM
   Lin, CH
AF Li, Hao
   Qi, Fei
   Shi, Guangming
   Lin, Chunhuan
TI A multiscale dilated dense convolutional network for saliency prediction
   with instance-level attention competition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency; Attention competition; Convolutional neural networks; Dense
   connections; Dilated convolution; Multiscale features
ID VISUAL-ATTENTION
AB Data-driven saliency estimation attracts increasing interests in recent years because of the establishment of large-scale annotated datasets and the evolution of deep convolutional neural networks (CNN). Although CNN-based models perform much better than traditional ones in saliency prediction, there is still a gap between computational models and human behavior. One reason is that existing approaches fail assigning correct saliency to different objects in scenes with multiple objects. In this paper, we propose a multiscale dilated dense convolutional network to handle instance-level attention competition for better saliency prediction. In the proposed architecture, dense connections encode inter- and intra-class features for instance-level attention competition, dilated convolution collects contextual information to enrich feature representations of instances, and shortcut connections provide multiscale features for attention competition across scales. According to evaluations on three challenging datasets, CAT2000, SALICON, and MIT1003, the proposed model achieves the state-of-the-art performance. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Li, Hao; Qi, Fei; Shi, Guangming; Lin, Chunhuan] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Qi, F (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Shaanxi, Peoples R China.
EM hao.li@ieee.org; fred.qi@ieee.org; gmshi@xidian.edu.cn
RI Qi, Fei/G-3978-2013
OI Qi, Fei/0000-0002-2161-1551
FU National Natural Science Foundation of China [61572387, 61632019,
   61836008, 61672404]; Foundation for Innovative Research Groups of the
   National Natural Science Foundation of China [61621005]
FX The work is supported in part by the National Natural Science Foundation
   of China under Grant Nos. 61572387, 61632019, 61836008, 61672404, and in
   part by the Foundation for Innovative Research Groups of the National
   Natural Science Foundation of China under Grant No. 61621005.
CR [Anonymous], 2016, P ICLR
   [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, NIPS 15 P 28 INT C N
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2017, ARXIV170101081
   [Anonymous], 2017, NEUROCOMPUTING, DOI DOI 10.1016/j.neucom.2017.03.018
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, ARXIV181003716
   Borji A., 2015, P CVPR WORKSH FUT DA
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Gao F, 2007, PR IEEE COMP DESIGN, P3
   Gorji S, 2017, PROC CVPR IEEE, P3472, DOI 10.1109/CVPR.2017.370
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houghton George, 1994, P53
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang LQ, 2007, PSYCHON B REV, V14, P148, DOI 10.3758/BF03194042
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jia S., 2018, ARXIV180501047
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   MORAN J, 1985, SCIENCE, V229, P782, DOI 10.1126/science.4023713
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Shen CY, 2014, NEUROCOMPUTING, V138, P61, DOI 10.1016/j.neucom.2013.09.053
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wu JJ, 2012, J VIS COMMUN IMAGE R, V23, P1158, DOI 10.1016/j.jvcir.2012.07.010
   Xia C, 2016, IEEE T NEUR NET LEAR, V27, P1227, DOI 10.1109/TNNLS.2015.2512898
   Xia C, 2015, PATTERN RECOGN, V48, P1337, DOI 10.1016/j.patcog.2014.10.007
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 66
TC 13
Z9 13
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102611
DI 10.1016/j.jvcir.2019.102611
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600014
DA 2024-07-18
ER

PT J
AU Wang, YH
   Li, QQ
   Chen, B
AF Wang, Yanhai
   Li, Qingquan
   Chen, Bo
TI Image classification towards transmission line fault detection via
   learning deep quality-aware fine-grained categorization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fine-grained categorization; Fault recognition; Quality model; Fast
   R-CNN; SVM
ID OBJECT DETECTION; SIMILARITY; TRANSFORM
AB Object detection and image classification are basic tasks in computer vision. In this paper, we introduce fault detection towards transmission line. Traditional fault detection methods in the transmission line are prone to be affected by the noise and transient magnitude. To overcome these limitations, we propose a novel fault zone detection method, where quality-aware fine-grained categorization model is well encoded for category cues discovery. The goal of our approach is to recognize the most discriminative image patches for classification. The key techniques of our method include quality-based discriminative feature extraction and wavelet-support vector machine. We extract the features of the line currents by leveraging Fast R-CNN based image samples decomposition, where quality module is utilized to choose the most discriminative regions. Afterwards, the extracted features are fed into a SVM to recognize the fault. We conduct comprehensive experiment on transmission line fault identification to verify the availability and superiority of our proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Yanhai] China Three Gorges Univ, Key Lab Geol Hazards Three Gorges Reservoir Area, Minist Educ, Yichang, Peoples R China.
   [Wang, Yanhai; Li, Qingquan; Chen, Bo] China Three Gorges Univ, Hubei Prov Engn Technol Res Ctr Power Transmiss L, Yichang, Peoples R China.
C3 China Three Gorges University; China Three Gorges University
RP Wang, YH (corresponding author), China Three Gorges Univ, Key Lab Geol Hazards Three Gorges Reservoir Area, Minist Educ, Yichang, Peoples R China.
EM yanhaiwang@ctgu.edu.cn
RI Chen, Bo/B-3447-2018; zhang, wb/JGM-5316-2023
FU Research Fund for Excellent Dissertation of China Three Gorges
   University [2018BSPY008]
FX This work was supported by the Research Fund for Excellent Dissertation
   of China Three Gorges University (no. 2018BSPY008).
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2013, P 31 INT C MACHINE L
   [Anonymous], 2014, Part-based R-CNNs for fine-grained category detection. Paper presented at: European Conference on Computer Vision, Zurich
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   [Anonymous], 2010, 2010 IEEE COMP SOC C
   Branson S., 2014, BIRD SPECIES CATEGOR, V1, P7
   Chen GH, 2006, INT CONF ACOUST SPEE, P2181
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ekici S, 2009, APPL SOFT COMPUT, V9, P341, DOI 10.1016/j.asoc.2008.04.011
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han JW, 2013, IEEE T IMAGE PROCESS, V22, P2723, DOI 10.1109/TIP.2013.2256919
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He Z., 2010, IEEE T POWER DELIV, V25
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Parikh UB, 2008, IEEE T POWER DELIVER, V23, P1789, DOI 10.1109/TPWRD.2008.919395
   Parikh UB, 2010, INT J ELEC POWER, V32, P629, DOI 10.1016/j.ijepes.2009.11.020
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Reddy MJ, 2008, IET GENER TRANSM DIS, V2, P235, DOI 10.1049/iet-gtd:20070079
   SACHDEV MS, 1988, IEEE T POWER DELIVER, V3, P121, DOI 10.1109/61.4237
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shi YY, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P329, DOI 10.1109/ICECT.2009.116
   Silva KM, 2006, IEEE T POWER DELIVER, V21, P2058, DOI 10.1109/TPWRD.2006.876659
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   [谢云云 Xie Yunyun], 2013, [电力系统自动化, Automation of Electric Power Systems], V37, P32
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu ML, 2015, COMPUT GRAPH FORUM, V34, P60, DOI 10.1111/cgf.12459
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang M., 2018, J VIS COMMUN IMAGE R, P53
NR 43
TC 14
Z9 15
U1 1
U2 32
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102647
DI 10.1016/j.jvcir.2019.102647
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600026
DA 2024-07-18
ER

PT J
AU Zou, C
   He, BW
   Zhu, MZ
   Zhang, LW
   Zhang, JW
AF Zou, Cheng
   He, Bingwei
   Zhu, Mingzhu
   Zhang, Liwei
   Zhang, Jianwei
TI Scene flow estimation by depth map upsampling and layer assignment for
   camera-LiDAR system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D scene flow; Sensor fusion; Depth map upsampling
AB This paper presents a scene flow estimation method which functions by depth map upsampling and layer assignment for the camera-LiDAR (Light Detection And Ranging) system. The 3D geometry and motion of the observed scene are estimated simultaneously based on two consecutive frames from a camera and a LiDAR. The proposed technique begins with dense depth map upsamling guided by a corresponding RGB image. The scene is then classified to various moving layers by a hybrid method. Finally, the motion of each layer is constrained by the RGB image and depth image which provide a coarse 3D rigid motion. Experimental results on both public datasets and a real-word platform demonstrate the effectiveness of this technique. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zou, Cheng; He, Bingwei; Zhu, Mingzhu; Zhang, Liwei] Fuzhou Univ, Sch Mech Engn & Automat, Fuzhou, Fujian, Peoples R China.
   [Zhang, Jianwei] Univ Hamburg, Dept Informat, TAMS, Hamburg, Germany.
C3 Fuzhou University; University of Hamburg
RP He, BW (corresponding author), Fuzhou Univ, Sch Mech Engn & Automat, Fuzhou, Fujian, Peoples R China.
EM mebwhe@fzu.edu.cn
RI Zhang, Jianwei/HJA-0011-2022
OI Zhang, Jianwei/0000-0002-5491-1745
FU National Natural Science Foundation of China [61473090, 61673115];
   Fujian Provincial Collaborative Innovation Center for High-end Equipment
   Manufacturing [50006103]
FX This work was supported by the National Natural Science Foundation of
   China (Project No. 61473090, 61673115) and Fujian Provincial
   Collaborative Innovation Center for High-end Equipment Manufacturing
   (Project No. 50006103).
CR Behl A, 2017, IEEE I CONF COMP VIS, P2593, DOI 10.1109/ICCV.2017.281
   Bouguet J. Y., 1999, OPENCV DOCUMENTS, V22, P363
   Chavez-Garcia RO, 2016, IEEE T INTELL TRANSP, V17, P525, DOI 10.1109/TITS.2015.2479925
   Cheng XD, 2017, IEEE T AUTOMAT CONTR, V62, P5026, DOI 10.1109/TAC.2017.2679479
   De Alvis C, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2147, DOI 10.1109/IROS.2016.7759337
   Dewan A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1765, DOI 10.1109/IROS.2016.7759282
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   Herbst E, 2013, IEEE INT CONF ROBOT, P2276, DOI 10.1109/ICRA.2013.6630885
   Huang WQ, 2015, IEEE SIGNAL PROC LET, V22, P192, DOI 10.1109/LSP.2014.2352715
   KNUTH DE, 1977, INFORM PROCESS LETT, V6, P1, DOI 10.1016/0020-0190(77)90002-3
   Kochanov D, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1785, DOI 10.1109/IROS.2016.7759285
   Kothapa R., 2011, MASTERS PROJECT REPO
   Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141
   Quiroga J, 2014, LECT NOTES COMPUT SC, V8695, P567, DOI 10.1007/978-3-319-10584-0_37
   Ren ZL, 2017, INT CONF 3D VISION, P225, DOI 10.1109/3DV.2017.00034
   Sun D, 2015, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2015.7298653
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Ushani Arash K., 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5666, DOI 10.1109/ICRA.2017.7989666
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Vogel C, 2015, INT J COMPUT VISION, V115, P1, DOI 10.1007/s11263-015-0806-0
   Vogel C, 2013, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2013.174
   Wulff J, 2015, PROC CVPR IEEE, P120, DOI 10.1109/CVPR.2015.7298607
   Xiao L, 2018, INFORM SCIENCES, V432, P543, DOI 10.1016/j.ins.2017.04.048
   Zhang J, 2015, IEEE INT CONF ROBOT, P2174, DOI 10.1109/ICRA.2015.7139486
   Zhang Z, 2012, INT C PAR DISTRIB SY, P284, DOI 10.1109/ICPADS.2012.47
   Zou C, 2018, IET IMAGE PROCESS, V12, P612, DOI 10.1049/iet-ipr.2017.0876
NR 32
TC 3
Z9 3
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102616
DI 10.1016/j.jvcir.2019.102616
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600017
DA 2024-07-18
ER

PT J
AU Melgar, MEV
   Farias, MCQ
AF Vizcarra Melgar, Max E.
   Farias, Mylene C. Q.
TI A (2,2) XOR-based visual cryptography scheme without pixel expansion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Visual secret sharing; Color interference
ID SECRET SHARING SCHEMES; CONTRAST; IMAGE
AB Visual cryptography (VC) is a technique that encodes the content of a secret image into two or more images, which are called shares. These shares are printed on transparencies and superimposed to reveal the original secret image. Frequently, VC techniques require a pixel expansion and a good alignment, which reduces the final spatial resolution. In this paper, we propose a physical VC scheme that only requires two shares and do not demand a pixel expansion. The first share is a colored transparency printed on a Polyvinyl Chloride (PVC) surface of 3 mm, while the second share is a colored image displayed on a smartphone screen. The decoded pixels of the proposed scheme have defined colors and a good resolution. We perform a physical evaluation of the color interference properties of the two shares, to find the most adequate color space, and test the proposed method with practical examples. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Vizcarra Melgar, Max E.; Farias, Mylene C. Q.] Univ Brasilia, Dept Elect Engn, Campus Darcy Ribeiro, Brasilia, DF, Brazil.
C3 Universidade de Brasilia
RP Melgar, MEV (corresponding author), Univ Brasilia, Dept Elect Engn, Campus Darcy Ribeiro, Brasilia, DF, Brazil.
EM maxvizcarra@ieee.org; mylene@ieee.org
RI Farias, Mylene/C-4900-2015
OI Farias, Mylene/0000-0002-1957-9943; Vizcarra Melgar, Max
   Eduardo/0000-0003-0608-8237
FU Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES);
   University of Brasilia
FX This work was supported in part by Coordenacao de Aperfeicoamento de
   Pessoal de Nivel Superior (CAPES) and in part by the University of
   Brasilia.
CR [Anonymous], J CRYPTOL
   [Anonymous], IMPLEMENTIERUNG CARD
   [Anonymous], P 34 ANN HAW INT C S
   [Anonymous], ULLMANNS ENCY IND CH
   [Anonymous], PATTERN RECOGN
   [Anonymous], 2014, VISUAL CRYPTOGRAPHY
   [Anonymous], 2016, J REAL TIME IMAGE PR
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], IET IMAGE P
   [Anonymous], 2010, GARTN TOP END US PRE, P1
   [Anonymous], PHYS SCI ENG MODERN
   [Anonymous], GARTN REP MARK SHAR
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2001, DESIGN CODE CRYPTOGR, V24, P255, DOI 10.1023/A:1011271120274
   Bose M, 2010, DESIGN CODE CRYPTOGR, V55, P19, DOI 10.1007/s10623-009-9327-6
   Chen TH, 2011, IEEE T CIRC SYST VID, V21, P1693, DOI 10.1109/TCSVT.2011.2133470
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Hou YC, 2014, IEEE T CIRC SYST VID, V24, P733, DOI 10.1109/TCSVT.2013.2280097
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Lee KH, 2014, IEEE T INF FOREN SEC, V9, P88, DOI 10.1109/TIFS.2013.2292509
   Li P, 2016, J REAL TIME IMAGE PR, P1
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Papadopoulos NA, 2018, J REAL-TIME IMAGE PR, V14, P75, DOI 10.1007/s11554-016-0630-y
   Sugawara S, 2015, OPT REV, V22, P544, DOI 10.1007/s10043-015-0095-4
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wang XL, 2016, J ANAL METHODS CHEM, V2016, DOI 10.1155/2016/1435106
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yang CN, 2006, LECT NOTES COMPUT SC, V4141, P468
   Yang CN, 2016, J REAL-TIME IMAGE PR, V12, P483, DOI 10.1007/s11554-015-0511-9
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zheng GL, 2017, IEEE J BIOMED HEALTH, V21, P655, DOI 10.1109/JBHI.2016.2546300
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 35
TC 4
Z9 4
U1 0
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102592
DI 10.1016/j.jvcir.2019.102592
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200026
DA 2024-07-18
ER

PT J
AU Wu, HT
   Cheung, YM
   Yang, ZY
   Tang, SH
AF Wu, Hao-Tian
   Cheung, Yiu-ming
   Yang, Zhiyuan
   Tang, Shaohua
TI A high-capacity reversible data hiding method for homomorphic encrypted
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Homomorphic encryption; Privacy protection; Paillier cryptosystem; Image
   quality; Reversible data hiding
ID WATERMARKING; DIFFERENCE; EXPANSION; DOMAIN
AB Recently, reversible data hiding in encrypted images has been developed to transmit useful data while the original images can be perfectly recovered when needed. In this paper, a new method is proposed for homomorphic encrypted images so that part of the hidden data can be extracted in encrypted domain and the rest are extractable after image decryption. Specifically, a plain-text image is preprocessed by reversibly embedding the bit values of some pixels into the image. The preprocessed image is encrypted in Paillier cryptosystem and two embedding algorithms are applied on the encrypted image in succession. Compared with the state-of-the-art schemes, higher embedding capacity can be achieved by applying the proposed method, respectively for data extraction before and after image decryption. Compared with the schemes with similar properties, better performances are achieved with the proposed method in terms of quality of directly decrypted image with respect to data hiding rate. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wu, Hao-Tian; Yang, Zhiyuan; Tang, Shaohua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, GD, Peoples R China.
   [Cheung, Yiu-ming] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China.
C3 South China University of Technology; Hong Kong Baptist University
RP Wu, HT (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, GD, Peoples R China.
EM wuht@scut.edu.cn
RI Cheung, Yiu-ming/E-2050-2015; Wu, Hao-Tian/S-5360-2019; yang,
   zhiyuan/GSD-5815-2022
OI Cheung, Yiu-ming/0000-0001-7629-4648; Wu, Hao-Tian/0000-0001-6462-7193;
   yang, zhiyuan/0000-0003-3488-3131
FU Natural Science Foundation of China [61772208, 61632013]; Guangdong
   Province Key Area Research and Development Program [2019B010137004];
   Guangdong Provincial Project of Science and Technology [201613090920081]
FX This work was supported by Natural Science Foundation of China (Nos.
   61772208, 61632013), Guangdong Province Key Area Research and
   Development Program (No. 2019B010137004) of China, and Guangdong
   Provincial Project of Science and Technology (No. 201613090920081). Many
   thanks to the anonymous reviewers for their insightful comments and
   valuable suggestions!
CR [Anonymous], 1978, FDN SEC COMPUT
   Barni M, 2013, IEEE SIGNAL PROC MAG, V30, P16, DOI 10.1109/MSP.2012.2229069
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Brakerski Z, 2014, SIAM J COMPUT, V43, P831, DOI 10.1137/120868669
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2015, IEEE T IMAGE PROCESS, V24, P1244, DOI 10.1109/TIP.2015.2395724
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Huang FJ, 2016, IEEE T INF FOREN SEC, V11, P2777, DOI 10.1109/TIFS.2016.2598528
   Ke Y, 2018, J VIS COMMUN IMAGE R, V54, P133, DOI 10.1016/j.jvcir.2018.05.002
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li M, 2017, SIGNAL PROCESS, V130, P190, DOI 10.1016/j.sigpro.2016.07.002
   Li M, 2015, SIGNAL PROCESS-IMAGE, V39, P234, DOI 10.1016/j.image.2015.10.001
   Li R., 2018, J INFORM HID MULTIME, V9, P615
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ma B, 2016, IEEE T INF FOREN SEC, V11, P1914, DOI 10.1109/TIFS.2016.2566261
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Shiu CW, 2015, SIGNAL PROCESS-IMAGE, V39, P226, DOI 10.1016/j.image.2015.09.014
   Wu HT, 2016, J VIS COMMUN IMAGE R, V40, P765, DOI 10.1016/j.jvcir.2016.08.021
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu HT, 2010, IEEE T INSTRUM MEAS, V59, P221, DOI 10.1109/TIM.2009.2022453
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiang SJ, 2018, IEEE T CIRC SYST VID, V28, P3099, DOI 10.1109/TCSVT.2017.2742023
   Xu DW, 2016, SIGNAL PROCESS, V123, P9, DOI 10.1016/j.sigpro.2015.12.012
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2016, IEEE T CIRC SYST VID, V26, P1622, DOI 10.1109/TCSVT.2015.2433194
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zheng PJ, 2013, IEEE T IMAGE PROCESS, V22, P2455, DOI 10.1109/TIP.2013.2253474
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 47
TC 34
Z9 36
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 87
EP 96
DI 10.1016/j.jvcir.2019.04.015
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600008
DA 2024-07-18
ER

PT J
AU Virrey, RA
   Liyanage, CD
   Petra, MIBH
   Abas, PE
AF Virrey, Reneiro Andal
   Liyanage, Chandratilak De Silva
   Petra, Mohammad Iskandar bin Pg Hj
   Abas, Pg Emeroylariffion
TI Visual data of facial expressions for automatic pain detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Facial expression recognition; Emotion database; Human pain detection;
   Feature learning
AB Facial expressions are complex, progress over time, and are challenging to interpret. The research subject of automated emotion recognition associated with the facial expressions has been a mainstream topic in computer vision focused on image processing and pattern recognition. Numerous databases of facial expressions are available to the research community, and are used as fundamental tools for the evaluation of a wide range of algorithms for face expression recognition. In this paper, we assessed the existing collections of facial expression datasets as a basis for building and evaluating the largely unmapped facet of pain expressions. To accentuate this topic, the study provides the summary of different characteristics of expressions that are relevant and justifiable indicators of pain. A preliminary platform is tested with accuracy rate of 85.66% using the collected FER datasets as testing inputs. Common challenges in face recognition were discussed, as well as the different methods used to address them. Different variants of feature learning techniques were also compared, and why some methods outperforms other existing methods. (C) 2019 Published by Elsevier Inc.
C1 [Virrey, Reneiro Andal; Liyanage, Chandratilak De Silva; Petra, Mohammad Iskandar bin Pg Hj; Abas, Pg Emeroylariffion] Univ Brunei Darussalam, FIT, Bandar Seri Begawan, Brunei.
C3 University Brunei Darussalam
RP Virrey, RA (corresponding author), Univ Brunei Darussalam, FIT, Bandar Seri Begawan, Brunei.
EM 16H0312@ubd.edu.bn; liyanage.silva@ubd.edu.bn;
   iskandar.petra@ubd.edu.bn; emeroylariffion.abas@ubd.edu.bn
RI Abas, Pg Emeroylariffion/V-2967-2019
OI Abas, Pg Emeroylariffion/0000-0002-7006-3838
FU Universiti Brunei Darussalam
FX We like to thank the Universiti Brunei Darussalam for the support for
   this research under University Bursary Award Scholarship.
CR [Anonymous], SUPPORT VECTOR MACHI
   [Anonymous], MED INFORM SCI REFER
   [Anonymous], DYNEMO DATABASE DYNA
   [Anonymous], FACIAL EXPRESSION IN
   [Anonymous], P 14 ACM INT C MULT
   [Anonymous], PAINFUL FACE PAIN EX
   [Anonymous], SIMPLE PAIN RATING S
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2749576
   [Anonymous], PATTERN RECOGN
   [Anonymous], CLASSIFYING STILL FA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2017, IEEE SIG NAL PROCESS, DOI DOI 10.1109/MSP.2017.2732900
   [Anonymous], 2013, AFFECTIVA FACIAL EXP
   [Anonymous], PAIN RES MANAGE
   [Anonymous], OBSERVER JUDGMENTS A
   [Anonymous], IEEE WINT C APPL COM
   [Anonymous], NONVERBAL BEHAV
   [Anonymous], IEEE T IMAGE PROCESS
   Breivik H, 2008, BRIT J ANAESTH, V101, P17, DOI 10.1093/bja/aen103
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P1666, DOI 10.1109/TIP.2017.2657118
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4042, DOI 10.1109/TIP.2017.2713940
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Pantic M., 2005, WEB BASED DATABASE F
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   Tcherkassof A., 2013, International Journal of Multimedia Its Applications, V5, P61, DOI DOI 10.5121/IJMA.2013.5505
   Walter Steffen, 2013, 2013 IEEE International Conference on Cybernetics (CYBCO), P128, DOI 10.1109/CYBConf.2013.6617456
   Yan HB, 2018, PATTERN RECOGN, V75, P15, DOI 10.1016/j.patcog.2017.03.001
   Yan HB, 2016, NEUROCOMPUTING, V208, P202, DOI 10.1016/j.neucom.2015.11.115
   Yan HB, 2016, NEUROCOMPUTING, V208, P165, DOI 10.1016/j.neucom.2015.11.113
NR 36
TC 23
Z9 23
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 209
EP 217
DI 10.1016/j.jvcir.2019.03.023
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100022
DA 2024-07-18
ER

PT J
AU dos Santos, FP
   Ribeiro, LSF
   Ponti, MA
AF dos Santos, Fernando P.
   Ribeiro, Leonardo S. F.
   Ponti, Moacir A.
TI Generalization of feature embeddings transferred from different video
   anomaly detection domains
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video; Transfer learning; Feature generalization; Anomaly detection
ID DEEP TRANSFER; NETWORK; MODELS
AB Detecting anomalous activity in video surveillance often suffers from limited availability of training data. Transfer learning may close this gap, allowing to use existing annotated data from some source domain. However, analyzing the source feature space in terms of its potential for transfer of learning to another context is still to be investigated. This paper reports a study on video anomaly detection, focusing on the analysis of feature embeddings of pre-trained CNNs with the use of novel cross-domain generalization measures that allow to study how source features generalize for different target video domains. This generalization analysis represents not only a theoretical approach, can be useful in practice as a path to understand which datasets allow better transfer of knowledge. Our results confirm this, achieving better anomaly detectors for video frames and allowing analysis of transfer learning's positive and negative aspects. (C) 2019 Elsevier Inc. All rights reserved.
C1 [dos Santos, Fernando P.; Ribeiro, Leonardo S. F.; Ponti, Moacir A.] Univ Sao Paulo, Inst Math & Comp Sci ICMC, BR-13566590 Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP dos Santos, FP (corresponding author), Univ Sao Paulo, Inst Math & Comp Sci ICMC, BR-13566590 Sao Carlos, SP, Brazil.
EM fernando_persan@usp.br; leonardo.sampaio.ribeiro@usp.br; ponti@usp.br
RI Ponti, Moacir A/E-1642-2011
OI Ponti, Moacir A/0000-0003-2059-9463; Pereira dos Santos,
   Fernando/0000-0002-8213-9799
FU FAPESP [2018/22482-0, 2017/22366-8]; CNPq [307973/2017-4]; Coordenacao
   de Aperfeicoamento de Pessoal de Nivel Superior - Brasil (CAPES) [001];
   CEPID-CeMEAI (FAPESP) [2013/07375-0]; Fundacao de Amparo a Pesquisa do
   Estado de Sao Paulo (FAPESP) [17/22366-8, 18/22482-0] Funding Source:
   FAPESP
FX The authors would like to thank FAPESP for the grants #2018/22482-0 and
   #2017/22366-8, and CNPq (307973/2017-4). This study was financed in part
   by the Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior -
   Brasil (CAPES) - Finance Code 001 and the CEPID-CeMEAI (FAPESP grant
   #2013/07375-0).
CR [Anonymous], 31 SIBGRAPI C GRAPH
   [Anonymous], ECCV
   [Anonymous], COMPUT ELECT ENG
   [Anonymous], 2014, P ADV NEUR INF PROC
   [Anonymous], ARXIV171110292
   [Anonymous], ARXIV150202791
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Chaker R, 2017, PATTERN RECOGN, V61, P266, DOI 10.1016/j.patcog.2016.06.016
   Chandola V, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1541880.1541882
   Chen Y, 2017, IEEE C ELEC DEVICES
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Cheng B, 2019, BRAIN IMAGING BEHAV, V13, P138, DOI 10.1007/s11682-018-9846-8
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Epaillard E, 2016, PATTERN RECOGN, V55, P125, DOI 10.1016/j.patcog.2016.02.004
   Guo HW, 2016, NEUROCOMPUTING, V204, P106, DOI 10.1016/j.neucom.2015.07.153
   Hao T, 2017, J VIS COMMUN IMAGE R, V48, P453, DOI 10.1016/j.jvcir.2017.01.019
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hu JL, 2015, PROC CVPR IEEE, P325, DOI 10.1109/CVPR.2015.7298629
   Hu YC, 2016, J VIS COMMUN IMAGE R, V38, P530, DOI 10.1016/j.jvcir.2016.03.021
   Jiang F, 2009, IEEE IMAGE PROC, P1117, DOI 10.1109/ICIP.2009.5414535
   Jodoin P.-M., 2008, DISTRIBUTED SMART CA, P1
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Li X, 2015, J VIS COMMUN IMAGE R, V33, P265, DOI 10.1016/j.jvcir.2015.09.018
   Liang M, 2015, PROC CVPR IEEE, P3367, DOI 10.1109/CVPR.2015.7298958
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mello R. F., 2018, Machine learning: a practical approach on the statistical learning theory
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ponti M, 2017, INT CONF ACOUST SPEE, P1403, DOI 10.1109/ICASSP.2017.7952387
   Ponti MA, 2017, SIBGRAPI, P17, DOI 10.1109/SIBGRAPI-T.2017.12
   Ravishankar H, 2016, LECT NOTES COMPUT SC, V10008, P188, DOI 10.1007/978-3-319-46976-8_20
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarraf S, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P816, DOI 10.1109/FTC.2016.7821697
   Sun MJ, 2017, J VIS COMMUN IMAGE R, V49, P412, DOI 10.1016/j.jvcir.2017.10.002
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Torrey L., 2010, IGI Global, P242, DOI 10.4018/978-1-60566-766-9.CH011
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   von Luxburg U, 2011, HBK HIST LOGIC, V10, P651
   Wang M, 2012, PROC CVPR IEEE, P3274, DOI 10.1109/CVPR.2012.6248064
   Xian Y, 2017, IEEE T CIRC SYST VID, V27, P624, DOI 10.1109/TCSVT.2016.2589838
   Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451
   Zhou T, 2017, PROC SPIE, V10133, DOI 10.1117/12.2253963
   Zhuang N, 2018, PATTERN RECOGN, V80, P225, DOI 10.1016/j.patcog.2018.03.018
NR 49
TC 25
Z9 25
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 407
EP 416
DI 10.1016/j.jvcir.2019.02.035
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000044
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sui, K
   Lee, WH
AF Sui, Kun
   Lee, Won-Hyung
TI Image processing analysis and research based on game animation design
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Game animation; Visual expression; Human-machine
   interface
AB With the development of the game industry, and the new electronic consumption chain to promote the development of the game industry model continues to strengthen. Therefore, it is more necessary to make good use of good technology to do a good job of games. From the momentum of the development of mobile terminal games in recent years, the game industry has become a new economic growth point in China's economic transformation. With the development of computer and Internet, graphics and image processing technology has entered another unprecedented stage. In recent years, different image processing techniques have been used to process and analyze the game interface. Appropriate image processing methods include image enhancement, image binarization, image edge detection and image feature extraction. In this paper, by changing the mapping function from priority to probability and comparing the single mapping function of the previous algorithm, the mapping function of playback learning with higher probability of the important priority playback unit is found. In the experiment, the intuitive model strategy analysis of the improved algorithm is carried out firstly. Then the choice of CNN network layer structure, cost function analysis, efficiency analysis and game score comparison of each algorithm are carried out. Finally, the test results show that the new algorithm in this paper can make more effective decisions in video games and achieve the goal of winning higher scores and spending less time. (C) 2018 Published by Elsevier Inc.
C1 [Sui, Kun; Lee, Won-Hyung] Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Seoul, South Korea.
C3 Chung Ang University
RP Lee, WH (corresponding author), Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Seoul, South Korea.
EM whlee@cau.ac.kr
CR Abdollahi F, 2014, NEUROREHAB NEURAL RE, V28, P120, DOI 10.1177/1545968313498649
   Babazadeh Masiar, 2014, 2014 IEEE/IFIP Conference on Software Architecture (WICSA), P1, DOI 10.1109/WICSA.2014.42
   Bai J., 2016, AERONAUT COMPUT TECH
   Baker CourtneyR., 2015, Humane Insight: Looking at Images of African American Suffering and Death
   CalvoFerrer J. R., 2017, BRIT J ED TECHNOLOGY, V48, P401
   Cao X. L., 2015, RES EXPLORATION LAB
   Chai Y., 2014, VALUE ORIENTATION AR
   Chatterjee A, 2017, BUILDING APPS UNIVER
   de Waal E, 2015, HUM MOL GENET, V24, P6975, DOI 10.1093/hmg/ddv400
   Dickson PE, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P70, DOI 10.1145/3059009.3059013
   Dong T. Y., 2016, COMPUT SCI
   Eriksson O., 2016, MODELING MODEL SIMPL
   Feng CY, 2014, BRIT J EDUC TECHNOL, V45, P285, DOI 10.1111/bjet.12022
   Hipp JF, 2015, CURR BIOL, V25, P1368, DOI 10.1016/j.cub.2015.03.049
   Jones K., 2015, GAME METHOD PLAYING
   Kleffner R., 2017, BIOINFORMATICS
   Lenovo Pte L., 2015, METHOD WHICH CAMERA
   Oldemeyer S, 2016, J BIOL CHEM, V291, P14062, DOI 10.1074/jbc.M116.726976
   Pellas N, 2014, IEEE INT CONF ADV LE, P699, DOI 10.1109/ICALT.2014.203
   Rajanna V. D., 2016, GAZE FOOT INPUT RICH, P126
   Schouten A. W., 2015, DEFINING RISK RISK H
   Shen S., 2016, MICROCOMPUT APPL
   Sun X., 2017, TRAINING SIMPLIFICAT
   Tran M. K. P., 2016, ASSISTANCE OLDER ADU, V9599
   Upreti S. R., 2017, 6 MODEL SIMPLIFICATI
   Wang Y., 2018, CHINA MECH ENG
   Wang Z., 2018, TIANJIN U TECHNOL
   Yang Q., 2016, REAL TIME OPTICAL DI
   Yue-Hong Wang, 2014, Advanced Materials Research, V998-999, P851, DOI 10.4028/www.scientific.net/AMR.998-999.851
   Zhang QL, 2017, AUTOM CONTROL COMPUT, V51, P263, DOI 10.3103/S0146411617040113
NR 30
TC 3
Z9 3
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 94
EP 100
DI 10.1016/j.jvcir.2018.12.011
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000012
DA 2024-07-18
ER

PT J
AU Wang, YD
   Zhang, T
   Wang, YC
   Ma, JW
   Li, YH
   Han, JZ
AF Wang, Yandong
   Zhang, Tao
   Wang, Yuanchao
   Ma, Jingwei
   Li, Yanhui
   Han, Jingzhuang
TI Compass aided visual-inertial odometry
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual-inertial odometry (VIO); Compass; Sliding window estimator;
   Inconsistency; Pre-integration; Minimum cost function
ID MODEL; SLAM
AB With the development of vision and optimization techniques, visual-inertial odometry (VIO) has shown the capability of motion estimating in the GNSS-denied condition. The VIO can provide absolute pitch and roll angles estimating value, but no the absolute azimuth. In the paper, we proposed a VIO aided by compass, which can obtain the azimuth with respect to the north direction in the geographic frame. Moreover, aided by compass, the yaw angle estimating error was reduced to a greater degree, due to the measurement of azimuth. Furthermore, the consistency of the VIO backend estimator is improved as well, while the accuracy of the estimated pose states was also wholly improved. The aiding approach is a tightly-couple information fusion system of camera, IMU and magnetoresistive sensors. The optimization method is based on the pre-integration and bundle adjustment. In the paper, we derived the compass residual model based on the pre-integration model, and then its Jacobian and covariance formation were deduced to solve the nonlinear equations. The compass aided VIO software was implemented based on the Nvidia Jetson Tx2. The system was fully tested based on hardware-in-the-loop simulation and vehicle test in the real physical environment. The pose errors of VIOs with and without compass aiding were compared in the above tests. The simulation results showed that the position was and yaw errors were improved obviously; the compass aided VIO was still consistent, but the pure VIO was consistent not. The consistency character is evaluated by average NEES by Monte-Carlo in simulation. The vehicle test showed that the position error was reduced by 23%; the yaw error was reduced by 21%. As a result, the compass aided VIO not only improved the pose estimated accuracy, especially position and yaw, but also improved the consistency of VIO system. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Wang, Yandong; Zhang, Tao; Wang, Yuanchao; Ma, Jingwei; Li, Yanhui; Han, Jingzhuang] Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Changchun 130033, Jilin, Peoples R China.
   [Wang, Yandong; Wang, Yuanchao] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Changchun Institute of Optics, Fine
   Mechanics & Physics, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Wang, YD (corresponding author), Chinese Acad Sci, Changchun Inst Opt Fine Mech & Phys, Changchun 130033, Jilin, Peoples R China.; Wang, YD (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RI MA, JINGWEI/H-8829-2013
OI MA, JINGWEI/0000-0002-8854-9756
CR [Anonymous], 2015, ABS151202363 CORR
   [Anonymous], 2013, Experimental Robotics
   Bar-Shalom Yaakov, 2001, APPL NEUROPSYCHOL, V34, P727
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bradski G., 2012, LEARNING OPENCV COMP
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Chiang CY, 2015, J APPL PHYS, V117, DOI 10.1063/1.4916036
   Cui Liu-zheng, 2014, Optics and Precision Engineering, V22, P1304, DOI 10.3788/OPE.20142205.1304
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Feng GH, 2014, OPTIK, V125, P1346, DOI 10.1016/j.ijleo.2013.08.004
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fraundorfer F, 2012, IEEE ROBOT AUTOM MAG, V19, P78, DOI 10.1109/MRA.2012.2182810
   Gebre-Egziabher D., 2000, IEEE 2000. Position Location and Navigation Symposium (Cat. No.00CH37062), P185, DOI 10.1109/PLANS.2000.838301
   HARRIS CG, 1988, IMAGE VISION COMPUT, V6, P87, DOI 10.1016/0262-8856(88)90003-0
   Hartley R., 2000, MULTIPLE VIEW GEOMET, P1865
   Huang GPQ, 2009, SPRINGER TRAC ADV RO, V54, P373
   Kaess M, 2012, INT J ROBOT RES, V31, P216, DOI 10.1177/0278364911430419
   Kummerle Rainer, 2011, IEEE International Conference on Robotics and Automation, P3607
   Leutenegger S, 2013, ROBOTICS SCI SYSTEMS, V34, P789
   Leutenegger S, 2015, INT J ROBOT RES, V34, P314, DOI 10.1177/0278364914554813
   Liu TP, 2016, INT SYM CODE GENER, P1, DOI 10.1145/2854038.2854039
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Macmillan S, 2005, EARTH PLANETS SPACE, V57, P1135, DOI 10.1186/BF03351896
   Mahony R, 2008, IEEE T AUTOMAT CONTR, V53, P1203, DOI 10.1109/TAC.2008.923738
   Maus S, 2010, US UK WORLD MAGNETIC
   Meier L., 2011, 2011 IEEE International Conference on Robotics and Automation (ICRA 2011), P2992, DOI 10.1109/ICRA.2011.5980229
   Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877
   Mourikis AI, 2007, IEEE INT CONF ROBOT, P3565, DOI 10.1109/ROBOT.2007.364024
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nistér D, 2004, PROC CVPR IEEE, P652
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Savage P. G., 1998, J DYN SYST MEAS CONT, V21, P384
   Scaramuzza D., 2011, IEEE ROB AUTOM MAG
   Song T, 2016, SIGNAL PROCESS, V129, P150, DOI 10.1016/j.sigpro.2016.05.012
   Song YL, 2015, OPTIK, V126, P3877, DOI 10.1016/j.ijleo.2015.07.058
   Strasdat H, 2010, IEEE INT CONF ROBOT, P2657, DOI 10.1109/ROBOT.2010.5509636
   Titterton D., 2005, Aerospace and Electronic Systems Magazine, IEEE, V20, P33, DOI [10.1109/MAES.2005.1499250, DOI 10.1109/MAES.2005.1499250]
   Usenko V, 2016, IEEE INT CONF ROBOT, P1885, DOI 10.1109/ICRA.2016.7487335
   Yuan Dongli, 2007, 2007 IEEE International Conference on Control and Automation, ICCA 2007, P2839, DOI 10.1109/ICCA.2007.4376880
   Zhang LM, 2016, IEEE T NEUR NET LEAR, V27, P674, DOI 10.1109/TNNLS.2015.2444417
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1301, DOI 10.1109/TIE.2014.2336602
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2013, PROC CVPR IEEE, P1908, DOI 10.1109/CVPR.2013.249
   Zhu H, 2016, OPTIK, V127, P3572, DOI 10.1016/j.ijleo.2015.12.149
NR 48
TC 3
Z9 3
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 101
EP 115
DI 10.1016/j.jvcir.2018.12.029
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000013
DA 2024-07-18
ER

PT J
AU Tu, B
   He, DB
   Shang, YH
   Zhou, CL
   Li, WJ
AF Tu, Bing
   He, Danbing
   Shang, Yongheng
   Zhou, Chengle
   Li, Wujing
TI Deep feature representation for anti-fraud system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Convolutional neural network; Anti-fraud; Distance metric
AB Online payment is becoming popular due to the development of e-commerce. So payment safety is more important. Since there is a fraudulent situation, an anti-fraud system is indispensable. GMM was lever-aged in many anti-fraud applications, but it only takes positive sample into account. Convolutional neural network is a strong strategy for learning deep representation of samples. So in this paper, we propose a CNNs architecture to deal with this problem. And the distance metric method can effectively identify whether candidates are the same person. Experimental results show the effectiveness of our method. (C) 2019 Published by Elsevier Inc.
C1 [Tu, Bing; He, Danbing; Zhou, Chengle; Li, Wujing] Hunan Inst Sci & Technol, Coll Informat & Commun Engn, Yueyang 414006, Peoples R China.
   [Shang, Yongheng] Zhejiang Univ, Sch Aeronaut & Astronaut, Hangzhou, Zhejiang, Peoples R China.
C3 Hunan Institute of Science & Technology; Zhejiang University
RP Tu, B (corresponding author), Hunan Inst Sci & Technol, Coll Informat & Commun Engn, Yueyang 414006, Peoples R China.
EM tubing@hnist.edu.cn
RI Li, Wujing/GZL-9066-2022; Zhou, Chengle/ABF-2066-2021
OI Zhou, Chengle/0000-0003-3107-5446; Li, Wujing/0000-0002-7825-7805
FU National Natural Science Foundation of China [51704115]; Key Laboratory
   Open Fund Project of Hunan Province University [17K040]; Science and
   Technology Program of Hunan Province [2016TP1021]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 51704115, by the Key Laboratory Open Fund Project of
   Hunan Province University under Grant 17K040, by the Science and
   Technology Program of Hunan Province under Grant 2016TP1021.
CR [Anonymous], 2016, ARXIV161001708
   [Anonymous], 2016, IEEE T INFORM FORENS
   [Anonymous], ARXIV15120056
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long Y, 2017, INF SCI
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Wang Z. L., 2017, Mater. Today, V20, P74, DOI DOI 10.1016/J.MATTOD.2016.12.001
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang LZ, 2018, J VIS COMMUN IMAGE R, V55, P263, DOI 10.1016/j.jvcir.2018.06.016
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
NR 19
TC 5
Z9 5
U1 4
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2019
VL 59
BP 253
EP 256
DI 10.1016/j.jvcir.2019.01.031
PG 4
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HR9ES
UT WOS:000463462600026
DA 2024-07-18
ER

PT J
AU Oszust, M
AF Oszust, Mariusz
TI No-reference image quality assessment with local features and high-order
   derivatives
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; No-reference; Local features; Support vector
   regression
ID INFORMATION; STATISTICS; SHARPNESS
AB The perceptual quality of images is often affected by applied image processing techniques. Their evaluation requires tests which involve human subjects. However, in most cases, image quality assessment (IQA) should be automatic and reproducible. Therefore, in this paper, a novel no-reference IQA method is proposed. The method uses high-order derivatives to extract detailed structure deformation present in distorted images. Furthermore, it employs local features, considering that only some regions of an image carry interesting information. Then, statistics of local features are used by a support vector regression technique to provide an objective quality score. To improve the quality prediction, luminance and chrominance channels of the image are processed. Experimental results on six large-scale public IQA image datasets show that the proposed method outperforms the state-of-the-art hand-crafted and deep-learning techniques in terms of the visual quality prediction accuracy. Furthermore, the method is better than popular full-reference approaches (i.e., SSIM and PSNR). (C) 2018 Elsevier Inc. All rights reserved.
C1 [Oszust, Mariusz] Rzeszow Univ Technol, Dept Comp & Control Engn, Wincentego Pola 2, PL-35959 Rzeszow, Poland.
C3 Rzeszow University of Technology
RP Oszust, M (corresponding author), Rzeszow Univ Technol, Dept Comp & Control Engn, Wincentego Pola 2, PL-35959 Rzeszow, Poland.
EM marosz@kia.prz.edu.pl
RI Oszust, Mariusz/AAC-3224-2022
OI Oszust, Mariusz/0000-0002-5482-6313
CR [Anonymous], INT C COMP VIS ICCV
   [Anonymous], IEEE T MULTIMED
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   [Anonymous], PROBABILISTIC QUALIT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Du SL, 2016, DIGIT SIGNAL PROCESS, V55, P1, DOI 10.1016/j.dsp.2016.04.006
   Fan CL, 2018, IEEE ACCESS, V6, P8934, DOI 10.1109/ACCESS.2018.2802498
   Gabarda S, 2018, J VIS COMMUN IMAGE R, V52, P101, DOI 10.1016/j.jvcir.2018.02.008
   Gerhard HE, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1002873
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Ghosh K, 2007, IMAGE VISION COMPUT, V25, P1228, DOI 10.1016/j.imavis.2006.07.022
   Jayaraman Dinesh, 2012, SIGNALS SYSTEMS COMP, DOI DOI 10.1109/ACSSC.2012.6489321
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Leszczuk M, 2015, SIGNAL PROCESS-IMAGE, V39, P457, DOI 10.1016/j.image.2015.05.003
   Li QH, 2017, NEUROCOMPUTING, V236, P93, DOI 10.1016/j.neucom.2016.09.105
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Lu QB, 2016, INFORM SCIENCES, V369, P334, DOI 10.1016/j.ins.2016.06.042
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Min XK, 2017, IEEE T IMAGE PROCESS, V26, P5462, DOI 10.1109/TIP.2017.2735192
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Okarma K, 2014, ELEKTRON ELEKTROTECH, V20, P128, DOI 10.5755/j01.eee.20.6.7284
   Ospina-Borras JE, 2016, J VIS COMMUN IMAGE R, V39, P142, DOI 10.1016/j.jvcir.2016.05.015
   Oszust M, 2017, IEEE SIGNAL PROC LET, V24, P1656, DOI 10.1109/LSP.2017.2754539
   Oszust M, 2016, IEEE SIGNAL PROC LET, V23, P65, DOI 10.1109/LSP.2015.2500819
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Quan L, 2016, 2016 INTERNATIONAL CONFERENCE ON IDENTIFICATION, INFORMATION AND KNOWLEDGE IN THE INTERNET OF THINGS (IIKI), P1, DOI 10.1109/IIKI.2016.63
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Shang XB, 2018, J ENG-NY, V2018, DOI 10.1155/2018/1214697
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Tang LJ, 2017, J VIS COMMUN IMAGE R, V49, P204, DOI 10.1016/j.jvcir.2017.09.010
   van de Sande KEA, 2014, PROC CVPR IEEE, P2377, DOI 10.1109/CVPR.2014.304
   Video Qual. Experts Group Toronto ON USA, FIN REP VID QUAL EXP
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen Y, 2017, J VIS COMMUN IMAGE R, V43, P119, DOI 10.1016/j.jvcir.2016.12.005
   Xie GF, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661275
   Xu JT, 2016, IEEE T IMAGE PROCESS, V25, P4444, DOI 10.1109/TIP.2016.2585880
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang X, 2015, 2015 PICTURE CODING SYMPOSIUM (PCS) WITH 2015 PACKET VIDEO WORKSHOP (PV), P307, DOI 10.1109/PCS.2015.7170096
   Zhang Z, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040478
   Zhou WJ, 2017, IEEE T BROADCAST, V63, P404, DOI 10.1109/TBC.2016.2638620
   Zhou Y, 2018, IEEE T MULTIMEDIA, V20, P3019, DOI 10.1109/TMM.2018.2829607
NR 56
TC 12
Z9 12
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2018
VL 56
BP 15
EP 26
DI 10.1016/j.jvcir.2018.08.019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GZ6TF
UT WOS:000449578500002
DA 2024-07-18
ER

PT J
AU Ji, ZJ
   Wang, WQ
AF Ji, Zhangjian
   Wang, Weiqiang
TI Correlation filter tracker based on sparse regularization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Correlation filter; Adaptive l(1) regularization;
   Occlusion handling
ID VISUAL TRACKING; OBJECT TRACKING; ROBUST; APPEARANCE
AB Recently, correlation filter-based trackers have achieved the competitive performance both on accuracy and robustness. To learn a classifier effectively, these methods exploit a periodic assumption of the training samples to model the processing of dense sampling in Fourier domain. However, the periodic assumption introduces unwanted boundary effects, which severely degrades the performance of tracking model.
   To lower the boundary effects, we propose a multi-scale l(1) regularized correlation filter tracker (MSL1CFT), which leverages the different regularization parameters to penalize each correlation filter coefficient in the learning process. Our method can learn the correlation filter model on a significantly larger set of negative training samples, without worsening the positive samples. We further present a fast solver to our model utilizing the Alternating Direction Method of Multipliers (ADMM) technique. The extensive empirical evaluations on two benchmark datasets: OTB2013 and VOT2015 demonstrate that our method outperforms the state-of-the-art approaches in tracking accuracy and robustness.
C1 [Ji, Zhangjian] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Shanxi, Peoples R China.
   [Wang, Weiqiang] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
C3 Shanxi University; Chinese Academy of Sciences; University of Chinese
   Academy of Sciences, CAS
RP Ji, ZJ (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan, Shanxi, Peoples R China.
EM jizhangjian08@mails.ucas.ac.cn
RI Ji, Zhangjian/C-7757-2015
OI Ji, Zhangjian/0000-0002-8022-0518
FU National Natural Science Foundation of China [61602288]; Shanxi
   Provincial Natural Science Foundation of China [201701D221102]
FX This work is supported by the National Natural Science Foundation of
   China Under Grant No. 61602288 and Shanxi Provincial Natural Science
   Foundation of China Under Grant No. 201701D221102. The authors also
   would like to thank the anonymous reviewers for their valuable
   suggestions.
CR [Anonymous], 2014, P BMVC
   Balan A.O., 2006, COMPUTER VISION PATT, V1, P758
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chockalingam P, 2009, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2009.5459276
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Ji Z, 2014, IEEE INT C MULT EXP, P1
   Ji ZJ, 2014, IEEE IMAGE PROC, P393, DOI 10.1109/ICIP.2014.7025078
   Ji ZJ, 2015, J VIS COMMUN IMAGE R, V28, P44, DOI 10.1016/j.jvcir.2015.01.008
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kadkhodaie M, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P497, DOI 10.1145/2783258.2783400
   Kim KY, 2017, INT CONF ADV COMMUN, P761
   Kristan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P564, DOI 10.1109/ICCVW.2015.79
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu BY, 2010, LECT NOTES COMPUT SC, V6314, P624
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Montero AS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P587, DOI 10.1109/ICCVW.2015.80
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu YW, 2015, IEEE T IMAGE PROCESS, V24, P1510, DOI 10.1109/TIP.2015.2405479
   Yang J., 2006, IEEE T PATTERN ANAL, V31, P210
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang TZ, 2016, PROC CVPR IEEE, P3880, DOI 10.1109/CVPR.2016.421
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
NR 40
TC 8
Z9 9
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 354
EP 362
DI 10.1016/j.jvcir.2018.06.017
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100029
DA 2024-07-18
ER

PT J
AU Turan, C
   Lam, KM
AF Turan, Cigdem
   Lam, Kin-Man
TI Histogram-based local descriptors for facial expression recognition
   (FER): A comprehensive study
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature extraction; Local descriptors; Facial expression recognition
ID TEXTURE CLASSIFICATION; FEATURE-EXTRACTION; BINARY PATTERNS; FACE; MODEL
AB This paper aims to present histogram-based local descriptors applied to Facial Expression Recognition (FER) from static images and provide a systematic review and analysis of them. First, we describe the main steps in encoding binary patterns in a local patch, which are required in every histogram-based local descriptor. Then, we list the existing local descriptors, while analysing their strengths and weaknesses. Finally, we present the experimental results of all these descriptors on commonly used facial expression databases, with varying resolution, noise, occlusion, and number of sub-regions, as well as comparing them with the results obtained by the state-of-the-art deep learning methods. This paper aims to bring together different studies of the visual features for FER by evaluating their performances under the same experimental setup, and critically reviewing various classifiers making use of the local descriptors.
C1 [Turan, Cigdem; Lam, Kin-Man] Hong Kong Polytech Univ, Ctr Signal Proc, Dept Elect & Informat Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Turan, C (corresponding author), Hong Kong Polytech Univ, DE503,11 Yuk Choi Rd, Hong Kong, Hong Kong, Peoples R China.
EM cigdem.turan@connect.polyu.hk; enkmlam@polyu.edu.hk
RI Turan, Cemal/Q-7638-2019
OI Turan, Cemal/0000-0001-9584-0261; Turan-Schwiewager,
   Cigdem/0000-0002-4836-6023
FU Hong Kong Polytechnic University [G-YBKF]
FX The work described in this paper was supported by a research grant from
   The Hong Kong Polytechnic University (project code: G-YBKF).
CR Ahmed F, 2012, ELECTRON LETT, V48, P1203, DOI 10.1049/el.2012.1841
   Ahmed F., 2013, CHIN J ENG, V2013
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahsan T, 2013, IETE TECH REV, V30, P47, DOI 10.4103/0256-4602.107339
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 2017, ARXIV170803985
   [Anonymous], 2018, arXiv
   Balntas V, 2018, IEEE T PATTERN ANAL, V40, P555, DOI 10.1109/TPAMI.2017.2679193
   Bashar F., 2014, INT C EL INF COMM TE, P1, DOI DOI 10.1109/EICT.2014.6777846
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benitez-Garcia G., 2017, J SIGNAL INFORM PROC, V08, P132, DOI [10.4236/jsip.2017.83009, DOI 10.4236/JSIP.2017.83009]
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chakraborty S, 2016, IEEE T CIRCUITS SYST
   Chen L. F., 2007, Taiwanese Facial Expression Image Database
   Choi WP, 2008, PATTERN RECOGN, V41, P1186, DOI 10.1016/j.patcog.2007.07.025
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Doshi NP, 2012, INT C PATT RECOG, P2760
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Du SL, 2016, OPTIK, V127, P6583, DOI 10.1016/j.ijleo.2016.04.002
   Duan Y., 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Erdem CE, 2015, MULTIMED TOOLS APPL, V74, P7429, DOI 10.1007/s11042-014-1986-2
   Fadaei S, 2017, SIGNAL PROCESS, V137, P274, DOI 10.1016/j.sigpro.2017.02.013
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Ishraque SMZ, 2012, INT CONF COMPUT INFO, P164, DOI 10.1109/ICCITechn.2012.6509762
   Islam M. S., 2013, SCI INT, V25
   Islam M.S., 2014, TRENDS APPL SCI RES, V9, P113, DOI [10.3923/tasr.2014.113.120, DOI 10.3923/tasr.2014.113.120]
   Islam M.S., 2014, J. AI Data Min, V2, P33
   Jabid T., 2010, 2010 7th IEEE International Conference of Advanced Video and Signal Based Surveillance, P482
   Jabid T., 2011, P INT C COMPUTER CON, P333
   Jabid T, 2012, INFORMATION-TOKYO, V15, P2007
   Jaiswal M., 2016, APPL COMP VIS WACV 2, P1, DOI DOI 10.1109/WACV.2016.7477625
   Jaiswal S, 2017, IEEE INT CONF AUTOMA, P762, DOI 10.1109/FG.2017.95
   Jung H., 2015, ARXIV PREPRINT ARXIV
   Kabir Md Hasanul, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P526, DOI 10.1109/AVSS.2010.9
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Kirsh SJ, 2007, AGGRESSIVE BEHAV, V33, P353, DOI 10.1002/ab.20191
   Kristensen RL, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1131, DOI 10.1109/MIPRO.2015.7160445
   Li J, 2016, DIGIT SIGNAL PROCESS, V51, P196, DOI 10.1016/j.dsp.2016.02.003
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu SS, 2014, CHIN CONTR CONF, P4664, DOI 10.1109/ChiCC.2014.6895725
   Lu J., 2017, IEEE transactions on pattern analysis and machine intelligence
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lubing Z., 2012, IM PROC ICIP 2012 19, P2601
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Martinez Brais, 2019, IEEE Transactions on Affective Computing, V10, P325, DOI 10.1109/TAFFC.2017.2731763
   McDuff D, 2015, INT CONF AFFECT, P512, DOI 10.1109/ACII.2015.7344618
   Mohammad T., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P572, DOI 10.1109/ICCITechn.2011.6164854
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Oh YH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1237, DOI 10.1109/ICDSP.2015.7252078
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Peng XL, 2016, IEEE COMPUT SOC CONF, P1544, DOI 10.1109/CVPRW.2016.192
   Pong KH, 2014, PATTERN RECOGN, V47, P556, DOI 10.1016/j.patcog.2013.08.023
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shojaeilangari S, 2012, I C CONT AUTOMAT ROB, P166, DOI 10.1109/ICARCV.2012.6485152
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song T., 2017, IEEE T CIRCUITS SYST, VPP
   Takala V, 2005, IMAGE ANAL, P13
   Tosér Z, 2016, LECT NOTES COMPUT SC, V9915, P359, DOI 10.1007/978-3-319-49409-8_29
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Turan C, 2015, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2015.7415453
   Turan C, 2014, IEEE IMAGE PROC, P5966, DOI 10.1109/ICIP.2014.7026204
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Vurall E, 2007, LECT NOTES COMPUT SC, V4796, P6
   Walecki R, 2017, PROC CVPR IEEE, P5709, DOI 10.1109/CVPR.2017.605
   Wenjin Chu, 2013, 2013 IEEE International Conference on Green Computing and Communications (GreenCom) and IEEE Internet of Things (iThings) and IEEE Cyber, Physical and Social Computing (CPSCom), P1458, DOI 10.1109/GreenCom-iThings-CPSCom.2013.257
   Xia X. X., 2014, T TECH PUBL, P437
   Yang BQ, 2016, MULTIMED TOOLS APPL, V75, P6979, DOI 10.1007/s11042-015-2623-4
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yang Meng., 2010, INT C PATTERN RECOGN, P2680, DOI DOI 10.1109/ICPR.2010.657
   Zeng ZY, 2015, J VIS COMMUN IMAGE R, V33, P85, DOI 10.1016/j.jvcir.2015.08.014
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhen Lei, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P161, DOI 10.1109/FG.2011.5771391
NR 102
TC 54
Z9 55
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 331
EP 341
DI 10.1016/j.jvcir.2018.05.024
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100026
DA 2024-07-18
ER

PT J
AU Sanchez, G
   Agostini, L
   Marcon, C
AF Sanchez, Gustavo
   Agostini, Luciano
   Marcon, Cesar
TI A reduced computational effort mode-level scheme for 3D-HEVC depth maps
   intra-frame prediction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; Intra-frame prediction; Depth maps; 3D video coding
ID VIDEO; MULTIVIEW
AB To encode the depth maps efficiently, 3D-HEVC introduced three intra-frame prediction tools: (i) Depth Intra Skip (DIS), (ii) Depth Modeling Modes (DMMs), and (iii) Segment-wise DC Coding (SDC) that raise the encoding effort. Therefore, we analyzed the most time-consuming steps at the intra-frame prediction and proposed a model-level scheme for reducing the encoding time. The most time-consuming encoding steps were the DMM-1 wedgelet search and the Rate-Distortion (RD) list evaluation in Transform-Quantization and SDC flows. Consequently, we proposed a scheme composed of two solutions for speeding up the DMM-1 and one solution for reducing the RD-list size, accelerating the RD-list evaluation. The DMM-1 speeding up solutions use the information of neighbor-encoded blocks and the data contained in the border of the encoding block to accelerate the wedgelet search. The proposed scheme reduces 31.9% the encoding time with an impact of 0.272% in the Bjontegaard Delta-rate (BD-rate), surpassing the related works.
C1 [Sanchez, Gustavo] Pontificia Univ Catolica Rio Grande do Sul, Comp Sci, Porto Alegre, RS, Brazil.
   [Marcon, Cesar] Pontificia Univ Catolica Rio Grande do Sul, Sch Comp Sci, Porto Alegre, RS, Brazil.
   [Sanchez, Gustavo] Inst Fed Farroupilha, Alegrete, Brazil.
   [Agostini, Luciano] Univ Fed Pelotas, Video Technol Res Grp ViTech, Pelotas, Brazil.
   [Agostini, Luciano] Univ Fed Pelotas, Grp Architectures & Integrated Circuits GACI, Pelotas, Brazil.
C3 Pontificia Universidade Catolica Do Rio Grande Do Sul; Pontificia
   Universidade Catolica Do Rio Grande Do Sul; Instituto Federal
   Farroupilha; Universidade Federal de Pelotas; Universidade Federal de
   Pelotas
RP Sanchez, G (corresponding author), Pontificia Univ Catolica Rio Grande do Sul, Porto Alegre, RS, Brazil.
EM gustavo.sanchez@acad.pucrs.br; agostini@inf.ufpel.edu.br;
   cesar.marcon@pucrs.br
RI Marcon, César/J-4394-2015; Agostini, Luciano/N-1102-2019
OI Marcon, Cesar/0000-0002-7811-7896; Sanchez, Gustavo/0000-0002-8399-3014
FU CAPES [88881135737/2016-01, 88881119481/2016-01]; CNPq [309707/2015-3,
   486136/2013-2]; FAPERGS [16/2551-0000241-0]
FX This paper was achieved in cooperation with Hewlett-Packard Brazil Ltda.
   using incentives of Brazilian Informatics Law (Law no 8.248 of 1991).
   Authors also would like to thank CAPES (processes 88881135737/2016-01
   and 88881119481/2016-01), CNPq (processes 309707/2015-3 and
   486136/2013-2) and FAPERGS (process 16/2551-0000241-0) Brazilian
   research agencies to support the development of this work.
CR [Anonymous], [No title captured]
   Bjontegaard G., 2001, VCEGM33 ITUT SC16SG1
   Budagavi M., 2014, HIGH EFFICIENCY VIDE
   Chen Y., 2014, JTC1SC29WG11 ISOIEC
   Fu CH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P477, DOI 10.1109/ICDSP.2015.7251918
   Gu Z., 2013, FAST IRAN PREDICTION
   Gu Z., 2014, FAST INTRA SDC CODIN, P3
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lee JY, 2015, ANN TRANSL MED, V3, DOI 10.3978/j.issn.2305-5839.2014.11.03
   Liu H., 2012, P IEEE INT C IM PROC, P3219
   Marpe D, 2010, IEEE T CIRC SYST VID, V20, P1676, DOI 10.1109/TCSVT.2010.2092615
   Merkle P, 2016, IEEE T CIRC SYST VID, V26, P570, DOI 10.1109/TCSVT.2015.2407791
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Peng KK, 2016, IEEE IMAGE PROC, P1126, DOI 10.1109/ICIP.2016.7532533
   Sanchez G., 2017, INT S CIRC SYST ISCA
   Sanchez G, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.063011
   Sanchez G, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P137, DOI 10.1109/VCIP.2014.7051523
   Sancho GilJ., 2016, PROFESSORES INCERTEZ, P1
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Zhang HB, 2015, ASIAPAC SIGN INFO PR, P374, DOI 10.1109/APSIPA.2015.7415297
   Zhang HB, 2015, IEEE IMAGE PROC, P961, DOI 10.1109/ICIP.2015.7350942
   Zhao L., 2011, INT C INT MULT COMP, P300
   Zhao X., 2013, JOINT COLL TEAM 3D V
NR 25
TC 12
Z9 12
U1 2
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 193
EP 203
DI 10.1016/j.jvcir.2018.05.003
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800017
DA 2024-07-18
ER

PT J
AU Wang, CC
   Tang, CW
AF Wang, Che-Chien
   Tang, Chih-Wei
TI Region-based rate control for 3D-HEVC based texture video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; Rate control; Bit allocation; Bit starvation; Retained bit
   earnings; R-lambda model
ID LEVEL RATE CONTROL; BIT ALLOCATION; QUALITY; OPTIMIZATION; ALGORITHM
AB Bit starvation resulted from inefficient rate control of 3D video coding deteriorates visual quality of synthesized views. Most region based rate control schemes allocate higher bitrate to regions of interest (ROIs), but bits may be still consumed by early coded units. This paper avoids reducing coding bits in high-cost regions of 3D-HEVC. Instead of ROIs that are determined by humans, high-cost regions sensitive to bit starvation are detected. Region level bit allocation is achieved by curve fitting of coding statistics, and recursive Taylor expansion (RTE) based bit allocation is adopted to optimally estimates the target bitrate and the QP related lambda of LCUs in each region. Based on retained earnings in economics, bits are reserved for LCUs that are sensitive to distortions. Experimental results show that the proposed scheme outperforms both the R-lambda model and RTE model in bitrate accuracy with similar R-D performance.
C1 [Wang, Che-Chien; Tang, Chih-Wei] Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Tang, CW (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
EM cwtang@ce.ncu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST-103-2221-E-008-061,
   MOST-104-2221-E-008-059, MOST-106-2221-E-008-050]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the Grants MOST-103-2221-E-008-061,
   MOST-104-2221-E-008-059, and MOST-106-2221-E-008-050.
CR [Anonymous], 2012, JCTVCH0213
   [Anonymous], 1997, COD MOV PICT ASS AUD
   [Anonymous], 1993, N0400 ISOIEC JTC1SC2
   [Anonymous], 1997, VID COD TEST MOD NEA
   Berman K., FINANCIAL INTELLIGEN
   Cover T. M., 1991, ELEMENTS INFORM THEO
   Dai M, 2004, IEEE IMAGE PROC, P1093
   Ding W, 1996, IEEE T CIRC SYST VID, V6, P12, DOI 10.1109/76.486416
   Draper NormanRichard., 1966, APPL REGRESSION ANAL, V3
   Fan S., 1989, NAT SCI J HAINAN TEA, V2, P91
   Guanghui Ren, 2010, Information Technology Journal, V9, P1390, DOI 10.3923/itj.2010.1390.1396
   He R. L., 2008, P IEEE INT C COMM TE, P665
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Hu S., 2013, IEEE T IMAGE PROCESS, V22
   ISO, 2014, JCT3VC1100 ISOIEC JT
   ISO, 2013, JCT3VD0005 ISOIEC JT
   ISO/IEC JTC1/SC29/WG11, 2013, JCT3VD0111 ISOIEC JT
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li SX, 2017, IEEE T CIRC SYST VID, V27, P2409, DOI 10.1109/TCSVT.2016.2589878
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Lie WN, 2014, IEEE IMAGE PROC, P140, DOI 10.1109/ICIP.2014.7025027
   Lim W, 2013, INT CONF ACOUST SPEE, P2045, DOI 10.1109/ICASSP.2013.6638013
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   Liu YW, 2011, IEEE T BROADCAST, V57, P562, DOI 10.1109/TBC.2011.2105652
   Liu YW, 2009, SIGNAL PROCESS-IMAGE, V24, P666, DOI 10.1016/j.image.2009.06.002
   Mallat S, 1998, IEEE T SIGNAL PROCES, V46, P1027, DOI 10.1109/78.668554
   Meddeb M, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.15
   Morvan Y., 2007, P PICT COD S
   Pham N.T., 2016, VNU Journal of Computer Science and Communication Engineering, V32, P1
   Sethuraman S, 2002, PROCEEDINGS OF WORKSHOP AND EXHIBITION ON MPEG-4, P59, DOI 10.1109/MPEG.2001.996448
   Shiyang Li, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7286597
   Song Y., 2016, P IEEE VIS COMM IM P, DOI [10.1109/VCIP.2016.7805478, DOI 10.1109/VCIP.2016.7805478]
   Sullivan GJ, 1998, IEEE SIGNAL PROC MAG, V15, P74, DOI 10.1109/79.733497
   Tan SC, 2017, IEEE T CIRC SYST VID, V27, P337, DOI 10.1109/TCSVT.2015.2511878
   Tan SC, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P382, DOI 10.1109/VCIP.2014.7051586
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu GL, 2013, IEEE T IMAGE PROCESS, V22, P2247, DOI 10.1109/TIP.2013.2247409
   Xiao JM, 2015, IEEE T CIRC SYST VID, V25, P139, DOI 10.1109/TCSVT.2014.2334011
   Xu L, 2013, IEEE T CIRC SYST VID, V23, P975, DOI 10.1109/TCSVT.2013.2243657
   Xu L, 2013, IEEE T IND ELECTRON, V60, P1850, DOI 10.1109/TIE.2012.2190960
   Xu L, 2011, IEEE T IMAGE PROCESS, V20, P723, DOI 10.1109/TIP.2010.2063708
   Yuan H, 2014, IEEE T BROADCAST, V60, P614, DOI 10.1109/TBC.2014.2361964
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
NR 46
TC 6
Z9 7
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 108
EP 122
DI 10.1016/j.jvcir.2018.05.001
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800010
DA 2024-07-18
ER

PT J
AU Gabarda, S
   Cristóbal, G
   Goel, N
AF Gabarda, Salvador
   Cristobal, Gabriel
   Goel, Navdeep
TI Anisotropic blind image quality assessment: Survey and analysis with
   current methods
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Pseudo-Wigner distribution; Renyi entropy;
   Anisotropy; Correlation; Mean opinion scores
AB The Anisotropic Quality Index (AQI) was previously introduced by the authors as a non-distortion-specific, no reference image quality measure. AQI is based on measuring the variance of the expected entropy of a given image over a predefined set of orientations. In this paper, a statistical evaluation of AQI is provided using standard benchmarking parameters showing good match with observer's response. Some AQI extensions are proposed for tackling ill-posed noise types that provide fair or poor performance. A comparison with other no reference methods has been included showing good competitiveness with many of them.
C1 [Gabarda, Salvador; Cristobal, Gabriel] CSIC, Inst Opt Daza de Valdes, Serrano 121, Madrid 28006, Spain.
   [Goel, Navdeep] Yadavindra Coll Engn, ECE Sect, Talwandi Sabo 151302, Punjab, India.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto
   de Optica (Daza de Valdes); Punjabi University
RP Cristóbal, G (corresponding author), CSIC, Inst Opt Daza de Valdes, Serrano 121, Madrid 28006, Spain.
EM gabriel@optica.csic.es
RI Cristobal, Gabriel/B-7216-2012
OI Cristobal, Gabriel/0000-0001-6408-2269
FU Spanish Ministry of Economy and Competitivity [CTM-2014-51907]
FX This work has been partially supported by the grant CTM-2014-51907 from
   the Spanish Ministry of Economy and Competitivity. The authors would
   like to thank the anonymous reviewers for their constructive comments
   and suggestions. The images included in this paper have been released by
   the Eastman Kodak Company for unrestricted usage.
CR Anantrasirichai N, 2013, IEEE T IMAGE PROCESS, V22, P2398, DOI 10.1109/TIP.2013.2249078
   Bos JP, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.10.107003
   Brenner K.-H., 1983, Signal Processing II: Theories and Applications. Proceedings of EUSIPCO-83 Second European Signal Processing Conference, P307
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P217
   de Oliveira H. C., 2016, SPIE MED IMAGING
   El-Abed M, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0055-8
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Maddheshiya A., 2014, THESIS
   Mahmoudpour S., 2017, QOMEX, P1
   Manap RA, 2015, INFORM SCIENCES, V301, P141, DOI 10.1016/j.ins.2014.12.055
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Samani Arash, 2015, 2015 IEEE International Symposium on Technologies for Homeland Security (HST), P1, DOI 10.1109/THS.2015.7225335
   Sidiropoulos P., 2015, P EUR PLAN SCI C, V10
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749
NR 25
TC 12
Z9 13
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 101
EP 105
DI 10.1016/j.jvcir.2018.02.008
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, GY
   Liu, J
   Liu, Y
   Zhao, JW
   Tian, LC
   Chen, YQ
AF Zhang, Guyue
   Liu, Jun
   Liu, Ye
   Zhao, Jingwen
   Tian, Luchao
   Chen, Yan Qiu
TI Physical blob detector and Multi-Channel Color Shape Descriptor for
   human detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human detection; RGB-D camera; Physical blob detector; Multi-Channel
   Color Shape Descriptor
ID TIME HUMAN DETECTION; REAL-TIME; DEPTH; TRACKING; PEOPLE; IMAGES
AB Human detection is a very important research problem due to its relevance to a wide range of applications. This paper proposes a new method for human detection in RGB-D images. Based on the observation that human head often forms a distinguishable blob-like region in depth image and its physical size and height are in well-known ranges, we propose a physical blob detector to efficiently locate candidate human regions. Since color information and 3D physical structure information are both important cues for characterizing human upper body, we propose to incorporate these two sources of information and construct a novel Multi-Channel Color Shape Descriptor (MCSD) to further verify the candidate regions. The experimental results on four publicly available datasets consistently show that the proposed method can reliably detect humans in RGB-D video in real time.
C1 [Zhang, Guyue; Liu, Jun; Zhao, Jingwen; Tian, Luchao; Chen, Yan Qiu] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 201203, Peoples R China.
   [Liu, Ye] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Jiangsu, Peoples R China.
C3 Fudan University; Nanjing University of Posts & Telecommunications
RP Chen, YQ (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Intelligent Informat Proc, Shanghai 201203, Peoples R China.
EM guyuezhang13@fudan.edu.cn; ljun@fudan.edu.cn; yeliu@njupt.edu.cn;
   jingwenzhao13@fudan.edu.cn; lctian14@fudan.edu.cn; chenyq@fudan.edu.cn
RI Liu, Jun/D-6532-2015; Zhang, Guyue/D-7621-2019
OI Zhang, Guyue/0000-0001-9061-1750; Liu, Jun/0000-0002-4365-4165; Zhao,
   Jingwen/0000-0001-9704-4066
FU Science and Technology Commission of Shanghai Municipality
   [17ZR1402300]; National Natural Science Foundation of China [61602255];
   Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China [16KJB520032]
FX This research work is supported by Science and Technology Commission of
   Shanghai Municipality (Grant No. 17ZR1402300), National Natural Science
   Foundation of China (Grant No. 61602255), and Natural Science Foundation
   of the Jiangsu Higher Education Institutions of China (Grant No.
   16KJB520032).
CR [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.248
   [Anonymous], COMP VIS ACCV 2012
   [Anonymous], 2014, 2014 IEEEIAPR INT
   [Anonymous], 2 INT C INN COMP INF
   [Anonymous], 2017, IEEE SIGNAL PROC LET, DOI DOI 10.1109/LSP.2017.2731952
   [Anonymous], 2009, P BRIT MACH VIS C
   [Anonymous], INT C IM PROC IEEE
   [Anonymous], 22 EUR C ART INT ECA
   [Anonymous], WORKSH PEOPL DET TRA
   Bagautdinov T, 2015, PROC CVPR IEEE, P2829, DOI 10.1109/CVPR.2015.7298900
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Benezeth Y, 2008, LECT NOTES COMPUT SC, V5099, P76, DOI 10.1007/978-3-540-69905-7_9
   Bo LF, 2011, IEEE INT C INT ROBOT, P821, DOI 10.1109/IROS.2011.6048717
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Davis JW, 2004, INT C PATT RECOG, P713, DOI 10.1109/ICPR.2004.1333872
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Fernández-Caballero A, 2011, EXPERT SYST APPL, V38, P2577, DOI 10.1016/j.eswa.2010.08.047
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Gade R, 2013, PROC CVPR IEEE, P3698, DOI 10.1109/CVPR.2013.474
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Ikemura S, 2011, LECT NOTES COMPUT SC, V6495, P25, DOI 10.1007/978-3-642-19282-1_3
   Jafari OH, 2014, IEEE INT CONF ROBOT, P5636, DOI 10.1109/ICRA.2014.6907688
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Lin Z, 2007, IEEE I CONF COMP VIS, P2301
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Linder T, 2016, STUD COMPUT INTELL, V625, P187, DOI 10.1007/978-3-319-26054-9_8
   Liu J, 2015, J VIS COMMUN IMAGE R, V31, P177, DOI 10.1016/j.jvcir.2015.06.014
   Liu J, 2013, IEEE IMAGE PROC, P3088, DOI 10.1109/ICIP.2013.6738636
   Liu J, 2015, PATTERN RECOGN LETT, V53, P16, DOI 10.1016/j.patrec.2014.09.013
   Liu YF, 2016, J VIS COMMUN IMAGE R, V36, P80, DOI 10.1016/j.jvcir.2016.01.010
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mattheij R, 2016, J VIS COMMUN IMAGE R, V38, P82, DOI 10.1016/j.jvcir.2016.02.008
   Mu Y, 2008, C COMPUTER VISION PA, P1
   Munaro M, 2016, ADV INTELL SYST COMP, V302, P1655, DOI 10.1007/978-3-319-08338-4_119
   Ouyang WL, 2013, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2013.257
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Wang WH, 2010, IEEE IMAGE PROC, P2313, DOI 10.1109/ICIP.2010.5649946
   Xue HY, 2016, NEUROCOMPUTING, V204, P70, DOI 10.1016/j.neucom.2015.06.112
   Zhang G, 2016, INT CONF ACOUST SPEE, P2004, DOI 10.1109/ICASSP.2016.7472028
NR 51
TC 9
Z9 10
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 13
EP 23
DI 10.1016/j.jvcir.2018.01.013
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300002
DA 2024-07-18
ER

PT J
AU Saha, S
   Fletcher, A
   Xiao, D
   Kanagasingam, Y
AF Saha, Sajib
   Fletcher, Alexander
   Xiao, Di
   Kanagasingam, Yogesan
TI A novel method for automated correction of non-uniform/poor illumination
   of retinal images without creating false artifacts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Color fundus image; Color correction; Illumination correction; Automated
   analysis of retinal image
ID BLOOD-VESSEL SEGMENTATION; COLOR SPACE; CONTRAST
AB Retinal images are frequently corrupted by unwanted variations in the brightness that occur due to over-all imperfections in the image acquisition process. This inhomogeneous illumination across the retina can limit the pathological information that can be gained from the image; and can lead to serious difficulties when performing image processing tasks that requires qualitative as well as quantitative analysis of feature presence on the image. On that perspective we have proposed a novel two-step approach for non-uniform and/or poor illumination correction in the context of retinal imaging. A subjective experiment was conducted to ensure that the proposed method did not create visually noticeable false color or artifacts on the images, especially on the areas that did not suffer non-uniform/poor illumination prior to correction. An objective experiment on 25,872 retinal images was performed to justify the significance of the proposed method for automated pathology detection/classification.
C1 [Saha, Sajib; Xiao, Di; Kanagasingam, Yogesan] CSIRO, Australian E Hlth Res Ctr, Canberra, ACT, Australia.
   [Fletcher, Alexander] Univ Western, Elect Comp & Math, Perth, WA, Australia.
C3 Commonwealth Scientific & Industrial Research Organisation (CSIRO);
   University of Western Australia
RP Saha, S (corresponding author), CSIRO, Australian E Hlth Res Ctr, Canberra, ACT, Australia.
EM to_sajib_cse@yahoo.com
CR [Anonymous], 2015, J BIOMEDICAL ENG MED
   [Anonymous], 2004, Technical Report
   Barbu T., 2012, P 13 WSEAS INT C AUT, P13
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529
   Büring H, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P459
   Cantrell K, 2010, ANAL CHEM, V82, P531, DOI 10.1021/ac901753c
   Cheung N, 2010, LANCET, V376, P124, DOI 10.1016/S0140-6736(09)62124-3
   Cunha-Vaz J., 2012, COMPUTER AIDED DETEC, P59
   Di Xiao, 2012, AUSTRALAS MED J, V5, P507, DOI [10.4066/AMJ.2012.1364, 10.4066/AMJ.2012.1364.]
   Fairchild M.D., 2005, Color Appearance Models, V2nd
   Finlayson G, 2000, IEEE T IMAGE PROCESS, V9, P1774, DOI 10.1109/83.869188
   Fleming AD, 2006, INVEST OPHTH VIS SCI, V47, P1120, DOI 10.1167/iovs.05-1155
   Foracchia M, 2005, MED IMAGE ANAL, V9, P179, DOI 10.1016/j.media.2004.07.001
   Ford A., 1998, COLOUR SPACE CONVERS, V1-31, P1998
   Galer M., 2003, DIGITAL IMAGING ESSE, P74
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Grisan E, 2006, I S BIOMED IMAGING, P984
   Guillemaud R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P872, DOI 10.1109/ICIP.1998.723695
   Jager RD, 2008, NEW ENGL J MED, V358, P2606, DOI 10.1056/NEJMra0801537
   Joblove G.H., 1978, ACM SIGGRAPH COMPUTE, V12
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kolar R, 2011, EUR SIGNAL PR CONF, P298
   Leahy C, 2012, APPL OPTICS, V51, P8383, DOI 10.1364/AO.51.008383
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Marios Dimitrios V., 2012, J. Biomed. Graph. Comput., V3, P6
   Moreno A, 2011, LECT NOTES COMPUT SC, V6626, P165, DOI 10.1007/978-3-642-20404-3_13
   Naim MJNM, 2012, APPL SOFT COMPUT, V12, P2948, DOI 10.1016/j.asoc.2012.04.028
   Narasimha-Iyer H, 2006, IEEE T BIO-MED ENG, V53, P1084, DOI 10.1109/TBME.2005.863971
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   Ni L, 2011, INT C PAR DISTRIB SY, P534, DOI 10.1109/ICPADS.2011.89
   Niemeijer M, 2005, IEEE T MED IMAGING, V24, P584, DOI 10.1109/TMI.2005.843738
   Panwar N, 2016, TELEMED E-HEALTH, V22, P198, DOI 10.1089/tmj.2015.0068
   Russ J.C., 1995, The Image Processing Handbook, Vsecond
   Sadek I., 2015, SPIE MED IMAGING
   Siisstrunk S., 1999, COL IM C
   Simone G, 2012, J VIS COMMUN IMAGE R, V23, P491, DOI 10.1016/j.jvcir.2012.01.008
   SKIFSTAD K, 1989, COMPUT VISION GRAPH, V46, P387, DOI 10.1016/0734-189X(89)90039-X
   Smith A.R., 1978, ACM SIGGRAPH COMPUT, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Tsai SH, 2012, COMPUT MATH APPL, V64, P1291, DOI 10.1016/j.camwa.2012.03.073
   Varnousfaderani E.S., 2016, SPIE MED IMAGING
   Youssif AAA, 2007, P 5 INT C INF SYST I, P2430
   Zhang B, 2010, PATTERN RECOGN, V43, P2237, DOI 10.1016/j.patcog.2009.12.017
   Zheng YJ, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P972, DOI 10.1109/ISBI.2012.6235719
   Zhu XL, 2008, IEEE ENG MED BIO, P3546, DOI 10.1109/IEMBS.2008.4649971
NR 46
TC 5
Z9 5
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 95
EP 103
DI 10.1016/j.jvcir.2018.01.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500009
DA 2024-07-18
ER

PT J
AU He, G
   Hu, J
   Li, YS
   Yu, WX
   Yang, Z
   Liu, PK
   Guo, RX
AF He, Gang
   Hu, Jing
   Li, Yunsong
   Yu, Wenxin
   Yang, Zhuo
   Liu, Peikun
   Guo, Ruixue
TI Fast mode decision and PU size decision algorithm for intra depth coding
   in 3D-HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D-HEVC; Mode decision; PU size decision; Fast algorithm
ID MULTIVIEW VIDEO; 3-D VIDEO
AB In 3D video extension of High-Efficiency-Video-Coding (3D-HEVC), intra depth coding involves huge computational complexity for the added depth modeling modes (DMMs) and the new complex processing flow. This paper proposes an algorithm including the fast mode and prediction unit (PU) size decisions to accelerate the intra depth coding. For the mode decision, after a modification of the processing flow, three strategies are adopted: (1) evaluation results for intra conventional modes (ICMs) are utilized to determine whether DMMs are skipped; (2) with a predicted direction from ICMs, a golden ratio method is adopted to simplify the DMMs searching; and (3) fast Planar mode decision is made by analyzing the relationship of DMMs and Planar mode. For the fast PU size decision, evaluation costs of ICMs and DMMs, with combination of some trained thresholds, are used to make decisions. Experimental results show the overall algorithm reduces 63.00% computational complexity, with 1.04% BD-rate increasing.
C1 [He, Gang; Hu, Jing; Li, Yunsong; Liu, Peikun; Guo, Ruixue] Xidian Univ, Joint Lab High Speed Multisource Image Coding & P, Xian 710071, Shaanxi, Peoples R China.
   [Yu, Wenxin] Southwest Univ Sci & Technol, Mianyang 621010, Peoples R China.
   [Yang, Zhuo] GuangDong Univ Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Xidian University; Southwest University of Science & Technology - China;
   Guangdong University of Technology
RP Hu, J (corresponding author), Xidian Univ, Joint Lab High Speed Multisource Image Coding & P, Xian 710071, Shaanxi, Peoples R China.
EM jinghu@stu.xidian.edu.cn
RI Yu, wx/KRQ-8572-2024
FU National Natural Science Foundation of China [61502367]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016JQ6018];
   Scientific Research Fund of Sichuan Provincial Education Department
   [16ZA0131]; Science and Technology Program of Guangzhou [201604016034];
   China Postdoctoral Science Foundation [61222101]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61502367, Natural Science Basic Research Plan in
   Shaanxi Province of China (Program No. 2016JQ6018), Scientific Research
   Fund of Sichuan Provincial Education Department (No. 16ZA0131), Science
   and Technology Program of Guangzhou under Grants 201604016034, China
   Postdoctoral Science Foundation funded project 61222101.
CR Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   da Silva TL, 2014, 2014 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING CONFERENCE, P229, DOI 10.1109/VCIP.2014.7051546
   Fu CH, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P477, DOI 10.1109/ICDSP.2015.7251918
   Gu Z., FAST INTRA PREDICTIO
   Gu Zhongyi., 2014, Multimedia and Expo, 2014 IEEE International Conference on, P1
   Jiménez-Moreno A, 2016, IEEE T MULTIMEDIA, V18, P563, DOI 10.1109/TMM.2016.2524995
   Kang MK, 2012, IEEE T MULTIMEDIA, V14, P121, DOI 10.1109/TMM.2011.2169238
   Lee J, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1131, DOI 10.1109/ICME.2004.1394416
   Lin WY, 2011, IEEE T CIRC SYST VID, V21, P237, DOI 10.1109/TCSVT.2011.2106290
   Mao Y., 2016, IEEE T MULTIMEDIA, V18, P1
   Merkle P, 2013, IEEE INT CON MULTI, P1
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Merkle P, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P149, DOI 10.1109/PCS.2012.6213308
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Muller K., JCT3VG1100 ITUT SG 1
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Park M, 2013, IEEE T MULTIMEDIA, V15, P1569, DOI 10.1109/TMM.2013.2264926
   Sanchez G, 2014, IEEE IMAGE PROC, P3209, DOI 10.1109/ICIP.2014.7025649
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tech G., 2015, IEEE T CIRC SYST VID, V26, P1
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
   Zhang MM, 2013, IEEE INT SYMP CIRC S, P2852, DOI 10.1109/ISCAS.2013.6572473
   Zhu C, 2016, IEEE T BROADCAST, V62, P82, DOI 10.1109/TBC.2015.2475697
NR 31
TC 6
Z9 6
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 303
EP 314
DI 10.1016/j.jvcir.2017.09.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800025
DA 2024-07-18
ER

PT J
AU Hou, XD
   Zhang, T
   Ji, L
   Wu, YD
AF Hou, Xiaodan
   Zhang, Tao
   Ji, Lei
   Wu, Yunda
TI Combating highly imbalanced steganalysis with small training samples
   using feature selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Steganalysis; Class imbalance; Feature selection; Sampling; Learning
   algorithms
ID CLASSIFICATION; FRAMEWORK; DETECTOR; CANCER; AREA
AB We consider a particular paradigm of steganalysis, namely, highly imbalanced steganalysis with small training samples, in which the cover images always significantly outnumber the stego ones. Researchers have rigorously studied sampling and learning algorithms as well as feature selection approaches to the class imbalance problem, but the research in the steganalysis domain is rare. This study provides a systematic comparison of eight feature selection metrics and of three types of methods developed for the imbalanced data classification problem in the steganalysis domain. Each metric is compared across three different classifiers and four steganalytic features. The efficiency of the metrics is evaluated to determine which performs best with minimal features selected. The performance of the three types of methods and their combinations is examined. Moreover, we also investigate the effect of feature dimensionality, sample number and imbalance degree on the performance of feature selection inresolving imbalanced image steganalysis.
C1 [Hou, Xiaodan; Zhang, Tao; Ji, Lei; Wu, Yunda] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Zhang, T (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.; Zhang, T (corresponding author), POB 109,62,Sci Ave, Zhengzhou, Henan, Peoples R China.
EM zhangtao_brunda@l63.com
FU National Natural Science Foundation of China [61572518, U1636202]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61572518 and U1636202). The authors would like to thank the
   reviewers for their insightful comments and helpful suggestions.
CR Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   Al-Shahib Ali, 2005, Appl Bioinformatics, V4, P195, DOI 10.2165/00822942-200594030-00004
   Amirkhani H, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3554413
   [Anonymous], P WORKSH MACH LEARN
   [Anonymous], 2012, P MULTIMEDIA SECURIT
   [Anonymous], P SPIE
   [Anonymous], IMAGE DATABASE STEGA
   [Anonymous], 2012, PROC SPIE MEDIA WATE
   Barni M, 2010, INT CONF ACOUST SPEE, P1690, DOI 10.1109/ICASSP.2010.5495494
   Bin Li, 2008, Proceedings of the SPIE - The International Society for Optical Engineering, V6819, P681912, DOI 10.1117/12.765817
   Cao LJ, 2003, PATTERN RECOGN LETT, V24, P2479, DOI 10.1016/S0167-8655(03)00093-X
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Chen GJ, 2015, KNOWL-BASED SYST, V90, P129, DOI 10.1016/j.knosys.2015.09.025
   Chen X., 2007, P 24 INT C MACH LEAR, P153, DOI DOI 10.1145/1273496.1273516
   Chen X. wen, 2008, P 14 ACM SIGKDD INT, P124, DOI [DOI 10.1145/1401890.1401910, 10.1145/1401890.1401910]
   Chen XW, 2005, IEEE IJCNN, P1883
   Cui YJ, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3444
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Estabrooks A, 2004, COMPUT INTELL-US, V20, P18, DOI 10.1111/j.0824-7935.2004.t01-1-00228.x
   Filler T., 2010, BOSS (Break Our Steganography System)
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   FORMAN G, 2004, PROC 8 EUR CONF, V3202, P161
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich Jessica., 2007, STATISTICALLY UNDETE, P3
   Fridrich Jessica, 2010, Steganography in digital media: Principles, algorithms and applications
   Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hand DJ, 2001, MACH LEARN, V45, P171, DOI 10.1023/A:1010920819831
   Hashemipour S. M., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P150, DOI 10.1109/IIH-MSP.2012.42
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Hou XD, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.063016
   Hou XD, 2016, SIGNAL PROCESS-IMAGE, V47, P72, DOI 10.1016/j.image.2016.05.011
   Hou XD, 2014, SIGNAL PROCESS-IMAGE, V29, P385, DOI 10.1016/j.image.2014.01.006
   Hou XD, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013037
   Hou XD, 2012, KSII T INTERNET INF, V6, P1926, DOI 10.3837/tiis.2012.08.003
   Huang K., 2004, P IEEE COMP SOC C CO, V2
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Ker AD, 2014, IEEE T INF FOREN SEC, V9, P1424, DOI 10.1109/TIFS.2014.2336380
   Ker AD, 2011, PROC SPIE, V7880, DOI 10.1117/12.872888
   Kira K., 2009, P 10 NAT C ART INT S, P49
   Knoll U., 1994, Machine Learning: ECML-94. European Conference on Machine Learning. Proceedings, P383
   Kodovsky J, 2014, PROC SPIE, V9028, DOI 10.1117/12.2039693
   Kodovsky J, 2012, PROC SPIE, V8303, DOI 10.1117/12.907495
   Kolcz A., 2004, ACM SIGKDD EXPLORATI, V6, P1, DOI [10.2973/odp.proc.ir.207.2004, DOI 10.1145/1007730.1007733]
   Kubat M., 1997, ICML, P179
   KUBAT M, 1997, P 9 EUR CONF MACH, V1224, P146
   Lehmann Erich Leo, 1975, Nonparametrics: statistical methods based on ranks
   Li FY, 2016, IEEE T INF FOREN SEC, V11, P344, DOI 10.1109/TIFS.2015.2496910
   Li XF, 2013, IEEE IMAGE PROC, P4432, DOI 10.1109/ICIP.2013.6738913
   Lin Y, 2002, MACH LEARN, V46, P191, DOI 10.1023/A:1012406528296
   Loughrey J, 2005, BCS CONFERENCE S, P33, DOI 10.1007/1-84628-102-4_3
   Lubenko I, 2012, PROC SPIE, V8303, DOI 10.1117/12.910214
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Lyu S., 2004, P SPIE, V5306
   Lyu SW, 2006, IEEE T INF FOREN SEC, V1, P111, DOI 10.1109/TIFS.2005.863485
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mladenic D, 1999, MACHINE LEARNING, PROCEEDINGS, P258
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P635, DOI 10.1109/TIFS.2008.2002936
   Pevny T, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P167, DOI 10.1145/1411328.1411357
   Sharp Toby, 2001, Information Hiding, V2137, P13, DOI 10.1007/3-540-45496-9_2
   Sun YM, 2006, IEEE DATA MINING, P592, DOI 10.1109/icdm.2006.29
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Ting K.M., 1994, PROCEEDINGS OF THE BIENNIAL CONFERENCE-CANADIAN SOCIETY FOR COMPUTATIONAL STUDIES OF INTELLIGENCE, P91
   Van der Putten P, 2004, MACH LEARN, V57, P177, DOI 10.1023/B:MACH.0000035476.95130.99
   Wang R, 2009, INT CONF DAT MIN WOR, P400, DOI 10.1109/ICDMW.2009.25
   Wang Y, 2007, IEEE T INF FOREN SEC, V2, P31, DOI 10.1109/TIFS.2006.890517
   Wasikowski M, 2010, IEEE T KNOWL DATA EN, V22, P1388, DOI 10.1109/TKDE.2009.187
   Wu G., 2003, P WORKSH LEARN IMB D, VII
   Yu L, 2004, J MACH LEARN RES, V5, P1205
   Zeng LK, 2015, PROC SPIE, V9409, DOI 10.1117/12.2078188
   Zhao XF, 2016, INT J DIGIT CRIME FO, V8, P1, DOI 10.4018/IJDCF.2016040101
   Zheng EG, 2011, KSII T INTERNET INF, V5, P840, DOI 10.3837/tiis.2011.04.012
   Zheng Z., 2004, ACM Sigkdd Explorations Newsletter, V6, P80, DOI DOI 10.1145/1007730.1007741
NR 77
TC 11
Z9 14
U1 0
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2017
VL 49
BP 243
EP 256
DI 10.1016/j.jvcir.2017.09.016
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FO2MQ
UT WOS:000416613800020
DA 2024-07-18
ER

PT J
AU He, PS
   Jiang, XH
   Sun, TF
   Wang, SL
   Li, B
   Dong, Y
AF He, Peisong
   Jiang, Xinghao
   Sun, Tanfeng
   Wang, Shilin
   Li, Bin
   Dong, Yi
TI Frame-wise detection of relocated I-frames in double compressed H.264
   videos based on convolutional neural network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Double compression detection; Data-driven methodology; Convolutional
   neural network; Video forensics
ID FORENSICS
AB Relocated I-frames are a key type of abnormal inter-coded frame in double compressed videos with shifted GOP structures. In this work, a frame-wise detection method of relocated I-frame is proposed based on convolutional neural network (CNN). The proposed detection framework contains a novel network architecture, which initializes with a preprocessing layer and is followed by a well-designed CNN. In the preprocessing layer, the high-frequency component extraction operation is applied to eliminate the influence of diverse video contents. To mitigate overfitting, several advanced structures, such as 1 x 1 convolutional filter and the global average-pooling layer, are carefully introduced in the design of the CNN architecture. Public available YUV sequences are collected to construct a dataset of double compressed videos with different coding parameters. According to the experiments, the proposed framework can achieve a more promising performance of relocated I-frame detection than a well-known CNN structure (AlexNet) and the method based on average prediction residual. (C) 2017 Elsevier Inc. All rights reserved.
C1 [He, Peisong; Jiang, Xinghao; Sun, Tanfeng; Wang, Shilin; Li, Bin; Dong, Yi] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
   [He, Peisong; Jiang, Xinghao; Sun, Tanfeng; Wang, Shilin; Li, Bin; Dong, Yi] Natl Engn Lab Informat Content Anal Tech, GT036001, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Jiang, XH (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM gokeyhps@sjtu.edu.cn; xhjiang@sjtu.edu.cn; tfsun@sjtu.edu.cn;
   wsl@sjtu.edu.cn; libin@szu.edu.cn; aa44@sjtu.edu.cn
RI Tanfeng, Sun/J-7469-2015; Wang, Shilin/ACN-3143-2022; He,
   Peisong/AAE-2082-2022
FU National Natural Science Foundation of China [61572320, 61572321]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61572320 and 61572321).
CR [Anonymous], 2015, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2015.123
   [Anonymous], 2015, STATE DIGITAL VIDEO
   [Anonymous], 2010, 2010 Asia-Pacific Power and Energy Engineering Conference, DOI DOI 10.1109/APPEEC.2010.5448448
   [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   Bondi L, 2017, IEEE SIGNAL PROC LET, V24, P259, DOI 10.1109/LSP.2016.2641006
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen W, 2009, LECT NOTES COMPUT SC, V5450, P16, DOI 10.1007/978-3-642-04438-0_2
   He PS, 2017, NEUROCOMPUTING, V228, P84, DOI 10.1016/j.neucom.2016.09.084
   He PS, 2016, J VIS COMMUN IMAGE R, V35, P55, DOI 10.1016/j.jvcir.2015.11.014
   He PS, 2015, LECT NOTES ARTIF INT, V9227, P787, DOI 10.1007/978-3-319-22053-6_84
   Huang ZS, 2014, 2014 IEEE CHINA SUMMIT & INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (CHINASIP), P306, DOI 10.1109/ChinaSIP.2014.6889253
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liao D., 2011, IS T SPIE ELECT IMAG
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Luo W., 2008, ELECT IMAGING 2008
   Ravi H, 2014, IEEE IMAGE PROC, P5352, DOI 10.1109/ICIP.2014.7026083
   Sahu N, 2017, J VIS COMMUN IMAGE R, V45, P77, DOI 10.1016/j.jvcir.2017.02.013
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Su PC, 2015, J VIS COMMUN IMAGE R, V29, P103, DOI 10.1016/j.jvcir.2015.02.006
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Vazquez-Padin D., 2012, IEEE INT WORKSH INF
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Xu JY, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413540013
   Zatt B, 2010, IEEE IMAGE PROC, P3053, DOI 10.1109/ICIP.2010.5651700
NR 28
TC 33
Z9 35
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 149
EP 158
DI 10.1016/j.jvcir.2017.06.010
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700012
DA 2024-07-18
ER

PT J
AU Meng, ZJ
   Wang, Y
   Wu, XY
   Yin, YT
   Li, T
AF Meng, Zhijun
   Wang, Yan
   Wu, Xinyu
   Yin, Yating
   Li, Teng
TI Contextual aerial image categorization using codebook
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Aerial image; Contextual modeling; Efficient algorithm; Codebook
ID DISCOVERING OBJECTS; FRAMEWORK; MODEL
AB Effective categorization of the millions of aerial images from unmanned planes is a useful technique with several important applications. Previous methods on this task usually encountered such problems: (1) it is hard to represent the aerial images' topologies efficiently, which are the key feature to distinguish the arial images rather than conventional appearance, and (2) the computational load is usually too high to build a realtime image categorization system. Addressing these problems, this paper proposes an efficient and effective aerial image categorization method based on a contextual topological codebook. The code book of aerial images is learned with a multitask learning framework. The topology of each aerial image is represented with the region adjacency graph (RAG). Furthermore, a codebook containing topologies is learned by jointly modeling the contextual information, based on the extracted discriminative graphlets. These graphlets are integrated into a Bag-of-Words (BoW) representation for predicting aerial image categories. Contextual relation among local patches are taken into account in categorization to yield high categorization performance. Experimental results show that our approach is both effective and efficient. (C) 2017 Published by Elsevier Inc.
C1 [Meng, Zhijun] Beihang Univ, Beijing, Peoples R China.
   [Wang, Yan; Yin, Yating; Li, Teng] Anhui Univ, Hefei 230601, Anhui, Peoples R China.
   [Wu, Xinyu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
C3 Beihang University; Anhui University; Chinese Academy of Sciences;
   Shenzhen Institute of Advanced Technology, CAS
RP Wu, XY (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
EM xy.wu@siat.ac.cn
RI wu, xinyu/KRQ-4615-2024
FU China Postdoctoral Science Foundation [156613, 2016T90148]; Science and
   Technology Project of Anhui Province [1604d0802019]
FX This work is partially supported by China Postdoctoral Science
   Foundation Funded Project (No. 156613) and a Special Financial Grant
   from the China Postdoctoral Science Foundation (No. 2016T90148), and
   partially supported by Science and Technology Project of Anhui Province
   (No. 1604d0802019).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, P 20 ANN C NEUR INF
   [Anonymous], 2010, P NIPS
   [Anonymous], 2007, MIR
   [Anonymous], 2016, Learning From Multiple Social Networks
   [Anonymous], 1976, GRAPH THEORY APPL
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chen L, 2014, IEEE T CYBERNETICS, V44, P1180, DOI 10.1109/TCYB.2013.2281366
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Demirci MF, 2006, INT J COMPUT VISION, V69, P203, DOI 10.1007/s11263-006-6993-y
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Harchaoui Z., 2007, IEEE C COMP VIS PATT, P1, DOI DOI 10.1109/CVPR.2007.383049
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Li T, 2011, IEEE T CIRC SYST VID, V21, P381, DOI 10.1109/TCSVT.2010.2041828
   Lin L, 2012, PATTERN RECOGN, V45, P3648, DOI 10.1016/j.patcog.2012.03.017
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu D, 2008, IEEE T MULTIMEDIA, V10, P200, DOI 10.1109/TMM.2007.911781
   Liu L, 2013, IEEE T CYBERNETICS, V43, P1860, DOI 10.1109/TSMCB.2012.2231959
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Nister David, 2006, CVPR
   Porway J, 2008, PROC CVPR IEEE, P141
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shervashidze Nino, 2009, P INT C ART INT STAT, P488
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wang QC, 2011, IEEE GEOSCI REMOTE S, V8, P177, DOI 10.1109/LGRS.2010.2055536
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Yao B, 2007, LECT NOTES COMPUT SC, V4679, P169
   Zhang LM, 2016, IEEE T CYBERNETICS, V46, P535, DOI 10.1109/TCYB.2015.2408592
   Zhang LM, 2012, INT C PATT RECOG, P2813
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
NR 39
TC 0
Z9 0
U1 0
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 404
EP 410
DI 10.1016/j.jvcir.2017.02.003
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700034
DA 2024-07-18
ER

PT J
AU Zhan, K
   Shi, JH
   Wang, J
   Tian, F
AF Zhan, Kun
   Shi, Jinhui
   Wang, Jing
   Tian, Feng
TI Graph-regularized concept factorization for multi-view document
   clustering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view learning; Concept factorization; Document clustering;
   Manifold learning
ID CONSTRAINED CONCEPT FACTORIZATION
AB We propose a novel multi-view document clustering method with the graph-regularized concept factorization (MVCF). MVCF makes full use of multi-view features for more comprehensive understanding of the data and learns weights for each view adaptively. It also preserves the local geometrical structure of the manifolds for multi-view clustering. We have derived an efficient optimization algorithm to solve the objective function of MVCF and proven its convergence by utilizing the auxiliary function method. Experiments carried out on three benchmark datasets have demonstrated the effectiveness of MVCF in comparison to several state-of-the-art approaches in terms of accuracy, normalized mutual information and purity. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Zhan, Kun; Shi, Jinhui] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
   [Wang, Jing; Tian, Feng] Bournemouth Univ, Fac Sci & Technol, Poole, Dorset, England.
C3 Lanzhou University; Bournemouth University
RP Wang, J (corresponding author), Bournemouth Univ, Fac Sci & Technol, Poole, Dorset, England.
EM jwang@bournemouth.ac.uk
RI Zhan, Kun/D-1741-2017
OI Zhan, Kun/0000-0002-8000-5682
FU National Science Foundation of China [61201422]; Specialized Research
   Fund for the Doctoral Program of Higher Education [20120211120013];
   Fundamental Research Funds for the Central Universities
   [lzujbky-2016-239]
FX This work has been supported by the National Science Foundation of China
   under the Grant No. 61201422, the Specialized Research Fund for the
   Doctoral Program of Higher Education under the Grant No. 20120211120013,
   and the Fundamental Research Funds for the Central Universities under
   the Grant No. lzujbky-2016-239.
CR [Anonymous], 2011, INT C MACHINE LEARNI
   [Anonymous], 2011, INT C NEURAL INF PRO
   [Anonymous], 2009, Proceedings of the 26th Annual International Conference on Machine Learning, DOI DOI 10.1145/1553374.1553388
   [Anonymous], 2013, P AAAI
   [Anonymous], 2009, MATCHING THEORY
   [Anonymous], 2013, P 2013 SIAM INT C DA
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bickel S, 2004, FOURTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P19, DOI 10.1109/ICDM.2004.10095
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Boyd S., 2004, CONVEX OPTIMIZATION
   Cai D, 2011, IEEE T KNOWL DATA EN, V23, P902, DOI 10.1109/TKDE.2010.165
   Chung F. R. K., 1997, Spectral graph theory
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ding C, 2005, SIAM PROC S, P606
   He XF, 2004, ADV NEUR IN, V16, P153
   He YC, 2014, NEURAL NETWORKS, V52, P1, DOI 10.1016/j.neunet.2013.12.007
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Liu HF, 2014, IEEE T CYBERNETICS, V44, P1214, DOI 10.1109/TCYB.2013.2287103
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Redko I, 2014, IEEE IJCNN, P3901, DOI 10.1109/IJCNN.2014.6889379
   Sha Fei., 2002, Advances in Neural Information Processing Systems, V15, P1041
   Shahnaz F, 2006, INFORM PROCESS MANAG, V42, P373, DOI 10.1016/j.ipm.2004.11.005
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Wang ZF, 2015, IEEE IMAGE PROC, P3500, DOI 10.1109/ICIP.2015.7351455
   Wei Xu, 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P202
   Wu Z., 2011, IJCAI Proceedings-International Joint Conference on Artificial Intelli- gence, P1378
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yang Y., IEEE T IMAGE PROCESS, V19
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zhang XC, 2014, IEEE DATA MINING, P1103, DOI 10.1109/ICDM.2014.19
NR 33
TC 21
Z9 23
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 411
EP 418
DI 10.1016/j.jvcir.2017.02.019
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700035
OA Green Accepted, Bronze
DA 2024-07-18
ER

PT J
AU Feiz, R
   Rezghi, M
AF Feiz, Raheleh
   Rezghi, Mansoor
TI A splitting method for total least squares color image restoration
   problem
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Structured total least squares (STLS); Color image restoration; Wavelet;
   Splitting
AB Color image restoration is an important problem in image processing. Using the structured total least squares (STLS) for fidelity term of the restoration process gives better results in comparison with the least squares (LS) approach. The main drawback of the STLS approach is its complexity. To overcome this issue, in this paper by an appropriate transformation the color image restoration is substituted with two smaller subproblems corresponding to smooth and oscillatory parts of the image. The first and second subproblems are modeled via STLS and LS approaches, respectively. We show that the proposed method is faster than STLS and gives competitive solutions with it. Also, we demonstrate that Haar wavelet perseveres the structure of the blurring operator, which causes a considerable reduction in computational and storage complexity of the proposed method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Feiz, Raheleh; Rezghi, Mansoor] Tarbiat Modares Univ, Dept Comp Sci, Tehran, Iran.
C3 Tarbiat Modares University
RP Rezghi, M (corresponding author), Tarbiat Modares Univ, Dept Comp Sci, Tehran, Iran.
EM Rezghi@modares.ac.ir
OI Rezghi, Mansoor/0000-0003-4214-5008
CR [Anonymous], DEBLURRING IMAGES MA
   Baglama J, 2007, J COMPUT APPL MATH, V198, P332, DOI 10.1016/j.cam.2005.09.025
   BenRosen J, 1996, SIAM J MATRIX ANAL A, V17, P110
   Donatelli M, 2015, APPL MATH COMPUT, V253, P135, DOI 10.1016/j.amc.2014.12.058
   Espaliol M. I., 2014, SIAM J SCI COMPUT, V36, P1432
   Español MI, 2010, SIAM J SCI COMPUT, V32, P299, DOI 10.1137/080715780
   Fu HY, 2006, SIAM J SCI COMPUT, V28, P1100, DOI 10.1137/040605436
   Jia TT, 2016, J VIS COMMUN IMAGE R, V38, P461, DOI 10.1016/j.jvcir.2016.03.022
   Klann E, 2011, BIT, V51, P669, DOI 10.1007/s10543-011-0320-x
   Liu J, 2015, COMPUT MATH APPL, V70, P1255, DOI 10.1016/j.camwa.2015.06.029
   Lukac R, 2007, IMAGE PROCESS SER, P1
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   MESAROVIC VZ, 1995, IEEE T IMAGE PROCESS, V4, P1096, DOI 10.1109/83.403444
   Ng MK, 1999, SIAM J SCI COMPUT, V21, P851, DOI 10.1137/S1064827598341384
   Pruessner A, 2003, SIAM J MATRIX ANAL A, V24, P1018, DOI 10.1137/S0895479801395446
   Rezghi M, 2014, SIAM J MATRIX ANAL A, V35, P1086, DOI 10.1137/130917260
   Shen Y, 2016, APPL COMPUT HARMON A, V41, P54, DOI 10.1016/j.acha.2015.04.001
   Shi MZ, 2016, SIGNAL PROCESS, V126, P65, DOI 10.1016/j.sigpro.2015.11.022
   Shi YY, 2008, APPL NUMER MATH, V58, P602, DOI 10.1016/j.apnum.2007.01.007
   Wong CY, 2016, J VIS COMMUN IMAGE R, V38, P802, DOI 10.1016/j.jvcir.2016.04.019
   Zhao XL, 2013, SIAM J SCI COMPUT, V35, pB1304, DOI 10.1137/130915406
NR 21
TC 5
Z9 5
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 48
EP 57
DI 10.1016/j.jvcir.2017.03.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500005
DA 2024-07-18
ER

PT J
AU Ko, H
   Song, R
   Kuo, CCJ
AF Ko, Hyunsuk
   Song, Rui
   Kuo, C. -C. Jay
TI A ParaBoost stereoscopic image quality assessment (PBSIQA) system
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereoscopic images; Objective quality assessment; Machine learning;
   Decision fusion; Feature extraction; Image quality database
ID INFORMATION
AB The problem of stereoscopic image quality assessment, which finds applications in 3D visual content delivery such as 3DTV, is investigated in this work. Specifically, we propose a new ParaBoost (parallel boosting) stereoscopic image quality assessment (PBSIQA) system. The system consists of two stages. In the first stage, various distortions are classified into a few types, and individual quality scorers targeting at a specific distortion type are developed. These scorers offer complementary performance in face of a database consisting of heterogeneous distortion types. In the second stage, scores from multiple quality scorers are fused to achieve the best overall performance, where the fuser is designed based on the parallel boosting idea borrowed from machine learning. Extensive experimental results are conducted to compare the performance of the proposed PBSIQA system with those of existing stereo image quality assessment (SIQA) metrics. The developed quality metric can serve as an objective function to optimize the performance of a 3D content delivery system. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Ko, Hyunsuk] Elect & Telecommun Res Inst, Daejeon 34129, South Korea.
   [Song, Rui] Xidian Univ, State Key Lab ISN, Xian 710071, Peoples R China.
   [Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Kuo, C. -C. Jay] Univ Southern Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Xidian University; University of Southern California; University of
   Southern California
RP Song, R (corresponding author), Xidian Univ, State Key Lab ISN, Xian 710071, Peoples R China.
EM rsong.xidian@gmail.com
RI Ko, Hyunsuk/ABC-9258-2020; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU Institute for Information & communications Technology Promotion (IITP)
   grant - Korea government (MSIP) [2016-0-00572]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP)
   (2016-0-00572, Development and Standardization of 5th Generation
   Video/Audio Coding Technology for Ultra High Quality Media Services)
CR [Anonymous], ACM T APPL PERCEPT T
   [Anonymous], INT SOC OPTICS PHOTO
   [Anonymous], P 15 EUR SIGN PROC C
   [Anonymous], J SIG PROCESS IMAGE
   [Anonymous], 2012, TECH REP
   [Anonymous], COM980E VQEG
   [Anonymous], 2006, PATTERN RECOGN
   [Anonymous], TECH REP
   [Anonymous], 2012, ADV MULTIMEDIA
   [Anonymous], 2008M15913 ISOIEC JT
   [Anonymous], 2013, P IVMSP JUN
   [Anonymous], IEEE SIG PROCESS LET
   [Anonymous], 2005, Digital Video Quality: Vision Models and Metrics
   [Anonymous], TECH REP
   [Anonymous], TECH REP
   [Anonymous], 2013, P 7 INT WORKSH VID P
   [Anonymous], SPIE VISUAL INFORM P
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   Benoit A, 2008, IEEE IMAGE PROC, P389, DOI 10.1109/ICIP.2008.4711773
   Carnec M, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P185
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Cheng JC, 2012, INT CONF COMP SCI ED, P154, DOI 10.1109/ICCSE.2012.6295048
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Falk TH, 2007, CONFERENCE RECORD OF THE FORTY-FIRST ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1-5, P503
   Hsu C.-W., 2003, TECH REP, DOI [DOI 10.1177/02632760022050997, 10 . 1177 / 02632760022050997]
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kim T, 2014, IEEE T MULTIMEDIA, V16, P387, DOI 10.1109/TMM.2013.2292592
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu TL, 2016, IEEE T NEUR NET LEAR, V27, P1851, DOI 10.1109/TNNLS.2015.2458986
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Maalouf A, 2011, INT CONF ACOUST SPEE, P1161
   Meegan DV, 2001, J EXP PSYCHOL-APPL, V7, P143, DOI 10.1037//1076-898X.7.2.143
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   Park M, 2012, IEEE J-STSP, V6, P460, DOI 10.1109/JSTSP.2012.2205132
   Ponomarenko N., 2007, INT WORKSH VID PROC
   Ryu S, 2014, IEEE T CIRC SYST VID, V24, P591, DOI 10.1109/TCSVT.2013.2279971
   Ryu S, 2012, IEEE IMAGE PROC, P609, DOI 10.1109/ICIP.2012.6466933
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Song R, 2015, J INF SCI ENG, V31, P1593
   Stelmach LB, 2000, IEEE IMAGE PROC, P5, DOI 10.1109/ICIP.2000.900878
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Yang JC, 2015, J VIS COMMUN IMAGE R, V31, P138, DOI 10.1016/j.jvcir.2015.06.002
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhao Y, 2011, IEEE T IMAGE PROCESS, V20, P2221, DOI 10.1109/TIP.2011.2118218
NR 54
TC 8
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 156
EP 169
DI 10.1016/j.jvcir.2017.02.014
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Weng, SW
   Liu, YJ
   Pan, JS
   Cai, NA
AF Weng, Shaowei
   Liu, Yijun
   Pan, Jeng-Shyang
   Cai, Nian
TI Reversible data hiding based on flexible block-partition and adaptive
   block-modification strategy
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Flexible block-partition; Adaptive
   pixel-modification strategy; Two-layer embedding
ID HISTOGRAM-MODIFICATION; IMAGE WATERMARKING; SCHEME; EXPANSION;
   SEGMENTATION; ALGORITHM
AB A novel reversible data hiding (RDH) method based on flexible block-partition and adaptive pixel-modification strategy is proposed in this paper, which is implemented from the following two aspects. One aims at partitioning flexibly a smooth block into non-overlapped sub-blocks of arbitrary size according to a local complexity measurement. After partition, since each resulting sub-block can be treated as an independent embedding unit, this block can be embedded with more data bits. The other is that the different pixel modification method is utilized for blocks (or sub-blocks) of different levels. Specifically, for a block, if it is not suitable for further division, only the maximum and minimum are modified at the same time so as to keep the distortion as low as possible. If it is divided into smaller sub-blocks, two pixel-modification schemes are designed for sub-blocks of size 1 x 3 and other sizes, respectively. One is that a 1 x 3 block can be embedded with 2 data bits by only modifying the maximum of this block. In this way, the embedding distortion is further decreased. The other is that in order to exploit better redundancy, two largest and two smallest pixels are modified simultaneously so that at most 4 data bits are embedded into a sub-block. Extensive experiments verify that the proposed method outperforms Peng et al.'s, Wang et al.'s, Li et al.'s, Sachnev et al.'s and Hong et al.'s works. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Weng, Shaowei; Liu, Yijun; Cai, Nian] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Fujian Univ Technol, Fujian Prov Key Lab Data Min & Applicat, Fujian, Peoples R China.
C3 Guangdong University of Technology; Fujian University of Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com; jspan@cc.kuas.edu.tw; cainian@gdut.edu.cn
RI Liu, Yijun/I-2480-2019; Pan, Jeng-Shyang/AEO-3450-2022
OI Liu, Yijun/0000-0001-6680-6590; Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61201393, 61571139]; New Star of Pearl River on
   Science and Technology of Guangzhou [2014J2200085]; Project of
   Collaborative Innovation and Platform Environment Construction in
   Guangdong Province [20158090903017]; Department of Science and
   Technology at Guangdong Province and Guangzhou City [2014B090901061,
   2015B090901060, 20158090908001, 2014Y2-00211]
FX This work was supported in part by National NSF of China (Nos. 61201393,
   61571139), New Star of Pearl River on Science and Technology of
   Guangzhou (No. 2014J2200085), the Project of Collaborative Innovation
   and Platform Environment Construction in Guangdong Province (No.
   20158090903017), funds from Department of Science and Technology at
   Guangdong Province and Guangzhou City (Nos. 2014B090901061,
   2015B090901060, 20158090908001, 2014Y2-00211).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W., 2010, EURASIP J ADV SIGNAL
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Huang HC, 2016, OPTIK, V127, P5950, DOI 10.1016/j.ijleo.2016.04.011
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shi YQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 2, PROCEEDINGS, P33
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang C, 2010, IEEE IMAGE PROC, P217, DOI 10.1109/ICIP.2010.5652066
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Weng S. W., 2015, MULTIMED TOOLS APPL
   Weng SW, 2014, MULTIMED TOOLS APPL, V72, P3063, DOI 10.1007/s11042-013-1585-7
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xu Y, 2015, IEEE INT CONF RFID, P1, DOI 10.1109/RFID.2015.7113066
   Xuan GR, 2004, P IWDW, V5, P23
   Zhang ZW., 2016, J INFORM HIDING MULT, V7, P530
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zhou Z. L., IEEE T INF FORENSIC
NR 55
TC 34
Z9 35
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2016
VL 41
BP 185
EP 199
DI 10.1016/j.jvcir.2016.09.016
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA ED9CY
UT WOS:000389169000017
DA 2024-07-18
ER

PT J
AU Jeyabharathi, D
   Dejey, D
AF Jeyabharathi, D.
   Dejey, D.
TI Vehicle Tracking and Speed Measurement system (VTSM) based on novel
   feature descriptor: Diagonal Hexadecimal Pattern (DHP)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local Tetra Pattern; Diagonal Hexadecimal Pattern; Background
   subtraction; Foreground detection
ID BACKGROUND SUBTRACTION; OBJECTS
AB Object detection and tracking is an important and active research area in computer vision community. The proposed Vehicle Tracking and Speed Measurement (VTSM) system can find out speed parameters of the vehicles. Speed parameters are used to take judgment on accidents at a low cost. The main objective of this paper is to develop an algorithm that can detect foreground, track specified object and calculate speed parameter of the object. Identifying stationary background from moving objects in a video is a critical task. To achieve superior foreground detection quality across unconstrained scenarios, a novel dynamic background subtraction and object tracking algorithm using a novel Diagonal Hexadecimal Pattern (DHP) is proposed. Metric F-score and MOTA are used to measure the performance of the proposed system. From the results, it is observed that the proposed system gives good results for the background subtraction and tracking. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Jeyabharathi, D.; Dejey, D.] Anna Univ Reg Campus Tirunelveli, Dept Comp Sci & Engn, Tirunelveli, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Jeyabharathi, D (corresponding author), Anna Univ Reg Campus Tirunelveli, Dept Comp Sci & Engn, Tirunelveli, India.
EM bharathi.durai@gmail.com
RI bharathi, Jeya/T-6437-2019
OI Dharma, Dejey/0000-0002-5173-4878
CR [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], IMAGE VISION COMPUTI
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   BASCLE B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P302, DOI 10.1109/ICCV.1995.466925
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Bouwmans T., 2014, BACKGROUND MODELS CH
   Bouwmans T., 2011, RECENT PATENTS COMPU, V4, P176
   Bouwmans T., 2012, HDB SOFT COMPUTING V, V5
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cheung SCS, 2004, PROC SPIE, V5308, P881, DOI 10.1117/12.526886
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fazli S, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON MACHINE VISION, PROCEEDINGS, ( ICMV 2009), P89, DOI 10.1109/ICMV.2009.47
   Ferone A, 2014, IEEE T SYST MAN CY-S, V44, P571, DOI 10.1109/TSMC.2013.2280121
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Guo JM, 2013, IEEE T CIRC SYST VID, V23, P1809, DOI 10.1109/TCSVT.2013.2269011
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Haque M, 2013, IEEE T CIRC SYST VID, V23, P2127, DOI 10.1109/TCSVT.2013.2273622
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Henriques J, 2012, LNCS, P702, DOI DOI 10.1007/978-3-642-33765-9_50
   Henriques Joao F, 2014, PAMI
   Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400
   KANHERE NK, 2005, IEEE C COMP VIS PATT
   Kim W, 2012, IEEE SIGNAL PROC LET, V19, P127, DOI 10.1109/LSP.2011.2182648
   Li L., 2003, MULTIMEDIA 03 P 11 A, P2, DOI DOI 10.1145/957013.957017
   Li L., 2014, PREPRINT
   Li M, 2008, PATTERN RECOGN LETT, V29, P664, DOI 10.1016/j.patrec.2007.12.001
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Liu SC, 1998, IEEE T IMAGE PROCESS, V7, P1258, DOI 10.1109/83.709658
   Lu Y., 2014, CVPR
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Manzanera A, 2007, LECT NOTES COMPUT SC, V4756, P42
   Marcel Sebastien, INT J IMAGE VIDEO PR
   Ning Li, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1432, DOI 10.1109/ICOSP.2008.4697401
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Pilet J, 2008, LECT NOTES COMPUT SC, V5305, P567, DOI 10.1007/978-3-540-88693-8_42
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Seki M, 2003, PROC CVPR IEEE, P65
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   SKIFSTAD K, 1989, COMPUT VISION GRAPH, V46, P387, DOI 10.1016/0734-189X(89)90039-X
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Subrahmanyam R., 2012, IEEE T IMAGE PROCESS, V21
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Unay D, 2010, IEEE T INF TECHNOL B, V14, P897, DOI 10.1109/TITB.2009.2038152
   Vosters L. P. J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P384, DOI 10.1109/AVSS.2010.72
   Wei FT, 2008, IEEE INT SYMP CIRC S, P2753, DOI 10.1109/ISCAS.2008.4542027
   Wren C.R., 1997, IEEE T PATTERN ANAL
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xue C, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P217, DOI 10.1109/KAMW.2008.4810464
   Xue GJ, 2010, IEEE INT CON MULTI, P1050, DOI 10.1109/ICME.2010.5582601
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhao Tao., 2004, P 2004 IEEE COMPUTER, P406
   Zhong Wei, 2012, IEEE INT C COMP VIS
NR 64
TC 16
Z9 17
U1 1
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 816
EP 830
DI 10.1016/j.jvcir.2016.08.011
PN B
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600035
DA 2024-07-18
ER

PT J
AU Garrido-Jurado, S
   Muñoz-Salinas, R
   Madrid-Cuevas, FJ
   Marín-Jiménez, MJ
AF Garrido-Jurado, S.
   Munoz-Salinas, R.
   Madrid-Cuevas, F. J.
   Marin-Jimenez, M. J.
TI Simultaneous reconstruction and calibration for multi-view structured
   light scanning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Structured light; Calibration; Multi-view; 3D reconstruction
ID SOFTWARE; TRACKING; SYSTEM
AB Structured light 3D scanning from a single viewpoint requires multiple scans and a registration process for a complete description of the scanned object. Instead, using multiple cameras and projectors simultaneously can reduce the scanning time and increase the visibility. However, a precise estimation of the extrinsic parameters of all the components is a time consuming process prone to errors. This paper proposes a method to automatically reconstruct and self-calibrate multi-view structured light systems with an arbitrary number of devices. The experimentation shows that the proposed method is precise and robust, surpassing other current state of the art approaches. The achieved calibration accuracy is similar to that obtained by a traditional chessboard pattern calibration, but being able to adapt to a wider range of situations. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Munoz-Salinas, R.] Univ Cordoba, Comp & Numer Anal Dept, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
   Univ Cordoba, Maimonides Inst Biomed Res IMIBIC, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba; Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Comp & Numer Anal Dept, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
EM i52gajus@uco.es; rmsalinas@uco.es; fjmadrid@uco.es; mjmarin@uco.es
RI Cuevas, Francisco José Madrid/H-1396-2015; Marin-Jimenez, Manuel
   J./AAS-9152-2020; Munoz-Salinas, Rafael/K-5999-2014
OI Marin-Jimenez, Manuel J./0000-0001-9294-6714; Munoz-Salinas,
   Rafael/0000-0002-8773-8571; Garrido-Jurado, Sergio/0000-0001-6872-7458
FU XXI Program for Research Support (University of Cordoba) [TIC-1692,
   TIC-0161]
FX This work has been developed with the support of the Research Projects
   TIC-1692 (Junta de Andalucia) and TIC-0161 of the XXI Program for
   Research Support (University of Cordoba).
CR Aliaga DG, 2010, IEEE T PATTERN ANAL, V32, P747, DOI 10.1109/TPAMI.2009.202
   Aliaga DanielG., 2008, COMPUTER VISION PATT, P1
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Barone S, 2013, OPT LASER ENG, V51, P116, DOI 10.1016/j.optlaseng.2012.09.003
   Barone S, 2012, OPT LASER ENG, V50, P380, DOI 10.1016/j.optlaseng.2011.10.019
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bi ZM, 2010, ROBOT CIM-INT MANUF, V26, P403, DOI 10.1016/j.rcim.2010.03.003
   Braganca S., 2015, OCCUPATIONAL SAFETY, P149
   CHIEN HJ, 2008, 23 INT C IM VIS COMP, P1
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furuakwa Ryo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P69, DOI 10.1109/CVPR.2009.5204318
   Furukawa R, 2005, FIFTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P302, DOI 10.1109/3DIM.2005.80
   Garcia RR, 2013, IEEE WORK APP COMP, P467, DOI 10.1109/WACV.2013.6475056
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Geng J, 2011, ADV OPT PHOTONICS, V3, P128, DOI 10.1364/AOP.3.000128
   Griesser A., 2006, 2006 C COMP VIS PATT, P56
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Horijon JL, 1996, P SOC PHOTO-OPT INS, V2599, P162, DOI 10.1117/12.230375
   Inokuchi S., 1984, Seventh International Conference on Pattern Recognition (Cat. No. 84CH2046-1), P806
   Jang W, 2013, OPT LASER ENG, V51, P1255, DOI 10.1016/j.optlaseng.2013.05.001
   Je C, 2013, SIGNAL PROCESS-IMAGE, V28, P1046, DOI 10.1016/j.image.2013.05.005
   Jones PRM, 1997, OPT LASER ENG, V28, P89, DOI 10.1016/S0143-8166(97)00006-7
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Lanman D, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P107
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   Li Y, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P328
   Li Y.F., 2003, IEEE T ROBOT AUTOM, V19
   Liu Z, 2015, OPT LASER ENG, V69, P20, DOI 10.1016/j.optlaseng.2015.01.008
   Lougee-Heimer R, 2003, IBM J RES DEV, V47, P57, DOI 10.1147/rd.471.0057
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Luo HF, 2014, OPT LASER ENG, V57, P6, DOI 10.1016/j.optlaseng.2014.01.010
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Moreno D, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P464, DOI 10.1109/3DIMPVT.2012.77
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Paoli A, 2012, ROBOT CIM-INT MANUF, V28, P592, DOI 10.1016/j.rcim.2012.02.010
   Pavlidis G, 2007, J CULT HERIT, V8, P93, DOI 10.1016/j.culher.2006.10.007
   Ribo M, 2005, INT WORKSH ROB SENS, P2
   Sadlo F., 2005, Point-Based Graphics 2005 (IEEE Cat. No. 05EX1159), P89, DOI 10.1109/PBG.2005.194069
   Schrijver A., 1998, THEORY LINEAR INTEGE
   Schueremans L, 2009, OPT LASER ENG, V47, P329, DOI 10.1016/j.optlaseng.2008.06.009
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Valkenburg RJ, 1998, IMAGE VISION COMPUT, V16, P99, DOI 10.1016/S0262-8856(97)00053-X
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   Xie ZX, 2014, OPT LASER ENG, V58, P9, DOI 10.1016/j.optlaseng.2014.01.001
   Yan ZQ, 2014, APPL OPTICS, V53, P3621, DOI 10.1364/AO.53.003621
   Yuan C., 2010, 2010 CHIN C PATT REC, P1, DOI [10.1109/CCPR.2010.5659143, DOI 10.1109/CCPR.2010.5659143]
   Yuan J., 2014, MATH PROBL ENG, V2014
   Zhang B, 2007, PATTERN RECOGN, V40, P1368, DOI 10.1016/j.patcog.2006.04.001
NR 51
TC 19
Z9 23
U1 1
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 120
EP 131
DI 10.1016/j.jvcir.2016.05.014
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900012
DA 2024-07-18
ER

PT J
AU Akin, O
   Erdem, E
   Erdem, A
   Mikolajczyk, K
AF Akin, Osman
   Erdem, Erkut
   Erdem, Aykut
   Mikolajczyk, Krystian
TI Deformable part-based tracking by coupled global and local correlation
   filters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual tracking; Correlation filter tracking; Collaborative model;
   Deformable part-based model
ID ONLINE OBJECT TRACKING; VISUAL TRACKING
AB Correlation filters have recently attracted attention in visual tracking due to their efficiency and high performance. However, their application to long-term tracking is somewhat limited since these trackers are not equipped with mechanisms to cope with challenging cases like partial occlusion, deformation or scale changes. In this paper, we propose a deformable part-based correlation filter tracking approach which depends on coupled interactions between a global filter and several part filters. Specifically, local filters provide an initial estimate, which is then used by the global filter as a reference to determine the final result. Then, the global filter provides a feedback to the part filters regarding their updates and the related deformation parameters. In this way, our proposed collaborative model handles not only partial occlusion but also scale changes. Experiments on two large public benchmark datasets demonstrate that our approach gives significantly better results compared with the state-of-the-art trackers. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Akin, Osman; Erdem, Erkut; Erdem, Aykut] Hacettepe Univ, Ankara, Turkey.
   [Mikolajczyk, Krystian] Univ London Imperial Coll Sci Technol & Med, London, England.
C3 Hacettepe University; Imperial College London
RP Erdem, E (corresponding author), Hacettepe Univ, Ankara, Turkey.
EM erkut@cs.hacettepe.edu.tr
RI Erdem, Erkut/A-2291-2012; AKIN, Osman/AAR-7976-2020; Erdem,
   Aykut/A-2290-2012
OI Erdem, Erkut/0000-0002-6744-8614; Erdem, Aykut/0000-0002-6280-8422
CR Akin O, 2014, INT C PATT RECOG, P4229, DOI 10.1109/ICPR.2014.725
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], BMVC
   [Anonymous], BMVC
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Cehovin L, 2011, IEEE I CONF COMP VIS, P1363, DOI 10.1109/ICCV.2011.6126390
   Chen Z., ARXIV150905520
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gao J, 2014, LECT NOTES COMPUT SC, V8691, P188, DOI 10.1007/978-3-319-10578-9_13
   Grabner H., 2006, BMVC, P47
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M., 2014, ECCV WORKSH, V191217
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lu Y, 2014, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2014.443
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Nejhum S.M. Shahed., 2008, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, P1
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 35
TC 66
Z9 77
U1 0
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 763
EP 774
DI 10.1016/j.jvcir.2016.04.018
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100064
DA 2024-07-18
ER

PT J
AU Shukla, D
   Jha, RK
AF Shukla, Deepika
   Jha, Rajib Kumar
TI Robust motion estimation for night-shooting videos using
   dual-accumulated constraint warping
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dynamic time warping; Sakoe-Chiba band; Motion estimation; Image
   alignment; Video stabilization; Night shooting; Low light shooting
ID IMAGE STABILIZER
AB This paper introduces a novel concept of dual-accumulated constraint projection warping, as a robust and efficient motion estimation solution for night video stabilization. Small imaging-sensors used in compact hand-held cameras become very prone to noise and blur under low illumination condition. Restricted lighting results in dark boundaries and degrades textural information of the frame. Presence of these combined textural artifacts makes night-shooting a hard problem for accurate motion estimation. At poor lighting, local intensity variations result in failure of inter-frame feature or block matching correspondence. In the proposed technique, use of projection ensures accuracy under local perturbations, noise and blur conditions, while dual-accumulation eliminates the effect of dark-regions adding robustness to night-shooting condition. Efficiency of the proposed algorithm over the existing motion estimation techniques is tested and verified over different categories of night shooting videos. In addition to night video stabilization the proposed scheme also performs well under normal illumination. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Shukla, Deepika] PDPM Indian Inst Informat Technol, Design & Mfg Jabalpur, Jabalpur 482005, Madhya Pradesh, India.
   [Jha, Rajib Kumar] Indian Inst Technol Patna, Patna 801103, Bihar, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Indian Institute of Technology (IIT) - Patna; Indian Institute
   of Technology System (IIT System)
RP Shukla, D (corresponding author), PDPM Indian Inst Informat Technol, Design & Mfg Jabalpur, Jabalpur 482005, Madhya Pradesh, India.
EM deepika.shukla0914@gmail.com; jharajib@gmail.com
CR Albu Felix, 2008, 2008 Digest of Technical Papers - International Conference on Consumer Electronics (ICCE '08), P1
   [Anonymous], 2007, INFORM RETRIEVAL MUS
   Bosco A, 2008, IEEE T CONSUM ELECTR, V54, P220, DOI 10.1109/TCE.2008.4560078
   Chang JY, 2002, IEEE T CONSUM ELECTR, V48, P108, DOI 10.1109/TCE.2002.1010098
   Hu R, 2007, IEEE INT CONF INF VI, P871
   Hua G., 2012, BREAKTHROUGHS LOW LI
   Jia C, 2014, IEEE T IMAGE PROCESS, V23, P5070, DOI 10.1109/TIP.2014.2360120
   Karpenko A., 2011, DIGITAL VIDEO STABIL
   Keogh E.J., 2001, P 2001 SIAM INT C DA, P1, DOI [DOI 10.1137/1.9781611972719.1, 10.1137/1.9781611972719.1]
   KINUGASA T, 1990, IEEE T CONSUM ELECTR, V36, P520, DOI 10.1109/30.103168
   Ko SJ, 1998, IEEE T CONSUM ELECTR, V44, P617, DOI 10.1109/30.713172
   Ko SJ, 1999, IEEE T CONSUM ELECTR, V45, P598, DOI 10.1109/30.793546
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Mohammadi B. B., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P1, DOI 10.1109/IranianCEE.2012.6292311
   Okade M, 2014, MULTIMED TOOLS APPL, V68, P947, DOI 10.1007/s11042-012-1095-z
   OSHIMA M, 1989, IEEE T CONSUM ELECTR, V35, P749, DOI 10.1109/30.106892
   Pinto Binoy, 2011, 2011 International Conference on Communications and Signal Processing (ICCSP), P527, DOI 10.1109/ICCSP.2011.5739378
   Piva S, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P299, DOI 10.1109/AVSS.2003.1217935
   Ratakonda K., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P69, DOI 10.1109/ISCAS.1998.698760
   SATO K, 1993, IEEE T CONSUM ELECTR, V39, P461, DOI 10.1109/30.234621
   Shukla Deepika, 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P343, DOI 10.1007/978-3-642-45062-4_46
   Shukla D., 2013, Empirical Study of the Multiaxial, Thermomechanical Behavior of NiTiHf Shape Memory Alloys, P1
   Shukla D, 2015, SIGNAL IMAGE VIDEO P, V9, P1287, DOI 10.1007/s11760-013-0584-5
   UOMORI K, 1990, IEEE T CONSUM ELECTR, V36, P510, DOI 10.1109/30.103167
   Veldandi M, 2013, IEEE IMAGE PROC, P785, DOI 10.1109/ICIP.2013.6738162
   Vella F, 2002, IEEE T CONSUM ELECTR, V48, P796, DOI 10.1109/TCE.2002.1037077
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang YX, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P641, DOI 10.1109/ICECT.2009.27
NR 28
TC 3
Z9 4
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 217
EP 229
DI 10.1016/j.jvcir.2016.03.002
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100019
DA 2024-07-18
ER

PT J
AU Su, SZ
   Ge, HW
   Yuan, YH
AF Su, Shuzhi
   Ge, Hongwei
   Yuan, Yun-Hao
TI Kernel propagation strategy: A novel out-of-sample propagation
   projection for subspace learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Kernel matrix optimization; Propagation; Out-of-sample projection;
   Semi-supervised learning; Canonical correlation analysis; Dimensionality
   reduction; Subspace feature extraction; Multi-view learning
ID CANONICAL CORRELATION-ANALYSIS; EIGENFACES
AB Kernel matrix optimization (KMO) aims at learning appropriate kernel matrices by solving a certain optimization problem rather than using empirical kernel functions. Since KMO is difficult to compute out-of sample projections for kernel subspace learning, we propose a kernel propagation strategy (KPS) based on data distribution similar principle to effectively extract out-of-sample low-dimensional features for subspace learning with KMO. With KPS, we further present an example algorithm, i.e., kernel propagation canonical correlation analysis (KPCCA), which naturally fuses semi-supervised kernel matrix learning and canonical correlation analysis by means of kernel propagation projections. In KPCCA, the extracted correlation features of out-of-sample data not only incorporate integral data distribution information but also supervised information. Extensive experimental results have demonstrated the superior performance of our proposed method. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Su, Shuzhi; Ge, Hongwei; Yuan, Yun-Hao] Jiangnan Univ, Sch Internet Things Engn, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Ge, HW; Yuan, YH (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Peoples R China.
EM ghw8601@163.com; yyhzbh@163.com
FU National Science Foundation of China [61402203, 61273251]; Graduate
   Innovation Foundation of Jiangsu Province [KYLX15_1169]; Fundamental
   Research Funds for the Central Universities [JUSRP11458]; 111 Project
   [B12018]; PAPD of Jiangsu Higher Education Institutions
FX This work is supported by the National Science Foundation of China under
   Grant Nos. 61402203 and 61273251. Meanwhile, it is also supported by the
   Graduate Innovation Foundation of Jiangsu Province under Grant No.
   KYLX15_1169, the Fundamental Research Funds for the Central Universities
   under Grant No. JUSRP11458, the 111 Project under Grant No. B12018, and
   PAPD of Jiangsu Higher Education Institutions.
CR [Anonymous], 2011, International Journal of Computer Applications, DOI DOI 10.5120/1748-2382
   [Anonymous], 2012, MATRIX COMPUTATIONS
   [Anonymous], 2008, Proceedings of the 25th international conference on Machine learning
   Ashad M.A., 2015, INT J PATTERN RECOGN, V29, P374
   Baghshah MS, 2014, PATTERN RECOGN LETT, V45, P161, DOI 10.1016/j.patrec.2014.02.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Borchers B, 1999, OPTIM METHOD SOFTW, V11-2, P613, DOI 10.1080/10556789908805765
   Chapelle O., 2002, P 15 INT C NEURAL IN, P601
   Chen HT, 2005, PROC CVPR IEEE, P846
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jian M, 2015, NEURAL PROCESS LETT, V41, P107, DOI 10.1007/s11063-013-9337-2
   Jing XY, 2014, AAAI CONF ARTIF INTE, P1882
   Larson NB, 2014, EUR J HUM GENET, V22, P126, DOI 10.1038/ejhg.2013.69
   Li JB, 2008, INFORM SCIENCES, V178, P1825, DOI 10.1016/j.ins.2007.12.001
   Liu HD, 2014, PATTERN RECOGN, V47, P1835, DOI 10.1016/j.patcog.2013.11.007
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Min HK, 2016, PATTERN RECOGN, V50, P45, DOI 10.1016/j.patcog.2015.08.021
   Peng Y, 2010, NEURAL PROCESS LETT, V31, P1, DOI 10.1007/s11063-009-9123-3
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shen XB, 2015, NEUROCOMPUTING, V148, P397, DOI 10.1016/j.neucom.2014.06.015
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Sun TK, 2007, INT C WAVEL ANAL PAT, P1283
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Tenenhaus A, 2015, COMPUT STAT DATA AN, V90, P114, DOI 10.1016/j.csda.2015.04.004
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VanVaerenbergh S, 2013, IEEE T SIGNAL PROCES, V61, P2219, DOI 10.1109/TSP.2013.2248004
   Wang YQ, 2014, SIGNAL PROCESS, V105, P258, DOI 10.1016/j.sigpro.2014.05.032
   Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106
   Widjaja D, 2012, IEEE T BIO-MED ENG, V59, P1169, DOI 10.1109/TBME.2012.2186448
   Wilks DS, 2014, INT J CLIMATOL, V34, P1405, DOI 10.1002/joc.3771
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yuan YH, 2014, PATTERN RECOGN, V47, P1411, DOI 10.1016/j.patcog.2013.09.009
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhu XF, 2012, PATTERN RECOGN, V45, P3003, DOI 10.1016/j.patcog.2012.02.007
NR 37
TC 6
Z9 6
U1 0
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2016
VL 36
BP 69
EP 79
DI 10.1016/j.jvcir.2016.01.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DF3WX
UT WOS:000371280200006
OA Bronze
DA 2024-07-18
ER

PT J
AU Chang, K
   Li, BX
AF Chang, Kan
   Li, Baoxin
TI Joint modeling and reconstruction of a compressively-sensed set of
   correlated images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressive sensing; Correlated images; Intra-image correlation;
   Inter-image correlation; Inter-channel correlation; Total variation;
   Non-local means; Group sparsity
ID QUALITY ASSESSMENT; INFORMATION; RECOVERY; REGULARIZATION; ALGORITHMS;
   SPARSITY
AB Employing correlation among images for improved reconstruction in compressive sensing is a conceptually attractive idea, although developing efficient modeling strategies and reconstruction algorithms are often the key to achieve any potential benefit. This paper presents a novel modeling strategy and an efficient reconstruction algorithm for processing a set of correlated images, jointly taking into consideration inter-image correlation, intra-image correlation and inter-channel correlation. The approach starts with joint modeling of the entire image set in the gradient domain, which supports simultaneous representation of local smoothness, nonlocal self-similarity of every single image, and inter-image correlation. Then an efficient algorithm is proposed to solve the joint formulation, using a Split-Bregman-based technique. Furthermore, to support color image reconstruction, the proposed algorithm is extended by using the concept of group sparsity to explore inter-channel correlation. The effectiveness of the proposed approach is demonstrated with extensive experiments on both grayscale and color image sets. Results are also compared with recently proposed compressive sensing recovery algorithms. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Chang, Kan] Guangxi Univ, Sch Comp & Elect Informat, Nanning 530004, Peoples R China.
   [Li, Baoxin] Arizona State Univ, Dept Comp Sci & Engn, Tempe, AZ 85287 USA.
C3 Guangxi University; Arizona State University; Arizona State
   University-Tempe
RP Chang, K (corresponding author), Guangxi Univ, Sch Comp & Elect Informat, Nanning 530004, Peoples R China.
EM changkan0@gmail.com; baoxin.li@asu.edu
RI Li, Zilong/JEZ-8642-2023; 常, 侃/AGP-4123-2022; Wang,
   Xuezhen/IUN-6267-2023
OI 常, 侃/0000-0002-6587-0360; 
FU Natural Science Foundation of China [61401108, 61261023]; Natural
   Science Foundation of Guangxi Zhuang Autonomous Region
   [2013GXNSFBA019272]; China Scholarship Council [1402170001]; Natural
   Science Foundation [1135616, 0845469]
FX The authors would like to thank anonymous reviewers for giving valuable
   suggestions to improve the quality of this manuscript. This work was
   partially supported by the Natural Science Foundation of China via
   Grants 61401108 and 61261023, the Natural Science Foundation of Guangxi
   Zhuang Autonomous Region via Grant 2013GXNSFBA019272. The support
   provided by China Scholarship Council (No. 1402170001) during a visit of
   K. Chang to Arizona State University is also acknowledged. B. Li was
   partially supported by the Natural Science Foundation via Grants 1135616
   and 0845469.
CR Asif MS, 2013, MAGN RESON MED, V70, P800, DOI 10.1002/mrm.24524
   Barrett R, 1994, TEMPLATES SOLUTION L, DOI DOI 10.1137/1.9781611971538
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Cai JF, 2012, J AM MATH SOC, V25, P1033, DOI 10.1090/S0894-0347-2012-00740-1
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chan T., 2005, MATH MODELS COMPUT V, V5, P1
   Chang K, 2014, MULTIMEDIA SYST, V20, P363, DOI 10.1007/s00530-014-0354-4
   Deng W., 2011, Tech. Rep. TR11-06
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Dong W, 2013, ELECTRON LETT, V49, P184, DOI 10.1049/el.2012.2536
   Dong WS, 2012, SIGNAL PROCESS-IMAGE, V27, P1109, DOI 10.1016/j.image.2012.09.003
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duarte MF, 2008, IEEE SIGNAL PROC MAG, V25, P83, DOI 10.1109/MSP.2007.914730
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Hitomi Y, 2011, IEEE I CONF COMP VIS, P287, DOI 10.1109/ICCV.2011.6126254
   Hosseini MS, 2014, IEEE T IMAGE PROCESS, V23, P3869, DOI 10.1109/TIP.2014.2332755
   Hung-Wei Chen, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P210, DOI 10.1109/PCS.2010.5702466
   Li CB, 2013, COMPUT OPTIM APPL, V56, P507, DOI 10.1007/s10589-013-9576-1
   Li CB, 2013, IEEE T BROADCAST, V59, P197, DOI 10.1109/TBC.2012.2226509
   Liu Ce, 2009, THESIS
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Liu Y, 2013, IEEE T CIRC SYST VID, V23, P438, DOI 10.1109/TCSVT.2012.2207269
   Ma JW, 2012, IEEE T CIRC SYST VID, V22, P1354, DOI 10.1109/TCSVT.2012.2201673
   Majumdar A, 2012, IEEE J EM SEL TOP C, V2, P362, DOI 10.1109/JETCAS.2012.2212774
   Majumdar A, 2010, SIGNAL PROCESS, V90, P3122, DOI 10.1016/j.sigpro.2010.05.016
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mun S, 2011, IEEE DATA COMPR CONF, P183, DOI 10.1109/DCC.2011.25
   Nagesh P, 2009, INT CONF ACOUST SPEE, P1261, DOI 10.1109/ICASSP.2009.4959820
   Park JY, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-37
   Puy G, 2014, SIAM J IMAGING SCI, V7, P128, DOI 10.1137/120902586
   Romberg J, 2008, IEEE SIGNAL PROC MAG, V25, P14, DOI 10.1109/MSP.2007.914729
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   SONNEVELD P, 1989, SIAM J SCI STAT COMP, V10, P36, DOI 10.1137/0910004
   Thirumalai V, 2013, J VIS COMMUN IMAGE R, V24, P649, DOI 10.1016/j.jvcir.2011.12.004
   Tramel EW, 2011, IEEE DATA COMPR CONF, P193, DOI 10.1109/DCC.2011.26
   Trocan M, 2014, MULTIMED TOOLS APPL, V72, P95, DOI 10.1007/s11042-012-1330-7
   Wagadarikar A, 2008, APPL OPTICS, V47, pB44, DOI 10.1364/AO.47.000B44
   Wu X., IEEE T IMAGE PROCESS, V21
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Zhang J, 2013, IEEE INT SYMP CIRC S, P2836
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 48
TC 16
Z9 17
U1 2
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 286
EP 300
DI 10.1016/j.jvcir.2015.09.020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700026
DA 2024-07-18
ER

PT J
AU Peng, ZJ
   Chen, F
   Jiang, GY
   Yu, M
   Shao, F
   Ho, YS
AF Peng, Zongju
   Chen, Fen
   Jiang, Gangyi
   Yu, Mei
   Shao, Feng
   Ho, Yo-Song
TI Depth video spatial and temporal correlation enhancement algorithm based
   on just noticeable rendering distortion model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three dimensional video system; Depth video; Just noticeable rendering
   distortion; Virtual view rendering; Spatial and temporal enhancement;
   Human visual perception; Depth video segmentation; Bit rate saving
ID MAPS; OPTIMIZATION; ACQUISITION; PREDICTION
AB Spatial and temporal inconsistency of depth video deteriorates encoding efficiency in three dimensional video systems. A depth video processing algorithm based on human perception is presented. Firstly, a just noticeable rendering distortion (JNRD) model is formulated by combining the analyses of the influence of depth distortion on virtual view rendering with human visual perception characteristics. Then, depth video is processed based on the JNRD model from two aspects, spatial and temporal correlation enhancement. During the process of spatial correlation enhancement, depth video is segmented into edge, foreground, and background regions, and smoothened by Gaussian and mean filters. The operations of the temporal correlation enhancement include temporal-spatial transpose (TST), temporal smoothing filter and inverse TST. Finally, encoding and virtual view rendering experiments are conducted to evaluate the proposed algorithm. Experimental results show that the proposed algorithm can greatly reduce the bit rate while it maintains the quality of virtual view. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Peng, Zongju; Chen, Fen; Jiang, Gangyi; Yu, Mei; Shao, Feng] Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Ho, Yo-Song] Gwangju Inst Sci & Technol GIST, Sch Informat & Mechatron, Gwangju 500712, South Korea.
C3 Ningbo University; Gwangju Institute of Science & Technology (GIST)
RP Peng, ZJ (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM pengzongju@nbu.edu.cn
RI Peng, Zongju/AAA-2914-2020; jiang, gang/KII-8233-2024; Chen,
   Fen/ABG-7013-2021
OI Peng, Zongju/0000-0001-8286-538X; 
FU National Natural Science Foundation of China [61171163, 61271270,
   61111140392, U1301257]; National Key Technology Research and Development
   Program of the Ministry of Science and Technology of China
   [2012BAH67F01]; Natural Science Foundation of Zhejiang Province
   [Y16F010010]; Natural Science Foundation of Ningbo [2015A610124,
   2015A610127]; K.C. Wong Magna Fund in Ningbo University
FX This work was supported by the National Natural Science Foundation of
   China under Grant nos. 61171163, 61271270, 61111140392 and U1301257,
   National Key Technology Research and Development Program of the Ministry
   of Science and Technology of China Grant no. 2012BAH67F01, Natural
   Science Foundation of Zhejiang Province under Grant no. Y16F010010,
   Natural Science Foundation of Ningbo under Grant nos. 2015A610124 and
   2015A610127. It is also sponsored by K.C. Wong Magna Fund in Ningbo
   University.
CR [Anonymous], 2008, JVTAC207 ISOIEC JTC1
   [Anonymous], 2013, JCT3VF1100 ITUT SG16
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 2010, M18356 ISOIEC JTC1SC
   [Anonymous], P IEEE ICIP
   BAKER HH, 1989, INT J COMPUT VISION, V3, P33, DOI 10.1007/BF00054837
   BJONTEGAARD G., 2001, AUST 13 VID COD EXP
   Bosc E, 2013, ANN TELECOMMUN, V68, P615, DOI 10.1007/s12243-013-0363-x
   De Silva DVSX, 2011, IEEE J-STSP, V5, P335, DOI 10.1109/JSTSP.2011.2108113
   De Silva DVSX, 2010, IEEE IMAGE PROC, P4013, DOI 10.1109/ICIP.2010.5653353
   De Silva DVSX, 2009, IEEE T CONSUM ELECTR, V55, P1699, DOI 10.1109/TCE.2009.5278045
   Ekmekcioglu E, 2011, IEEE J-STSP, V5, P352, DOI 10.1109/JSTSP.2010.2052783
   Ekmekcioglu E, 2009, IEEE T CIRC SYST VID, V19, P1209, DOI 10.1109/TCSVT.2009.2020336
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Fu D., 2010, PICT COD S PCS2010 N
   Hanhart P, 2014, IEEE INT WORKSH MULT
   Heo J, 2010, IEEE SIGNAL PROC LET, V17, P835, DOI 10.1109/LSP.2010.2059014
   Johnson GS, 2005, ACM T GRAPHIC, V24, P1462, DOI 10.1145/1095878.1095889
   Jung SW, 2013, IEEE T IMAGE PROCESS, V22, P3892, DOI 10.1109/TIP.2013.2263150
   Kang MK, 2012, IEEE T MULTIMEDIA, V14, P121, DOI 10.1109/TMM.2011.2169238
   Karim HA, 2010, IEEE T CONSUM ELECTR, V56, P1705, DOI 10.1109/TCE.2010.5606316
   Kim SY, 2010, IEEE T CONSUM ELECTR, V56, P1730, DOI 10.1109/TCE.2010.5606319
   Kim W.-S., 2010, P SPIE
   Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62
   Lai P., 2009, P VIS COMM IM PROC V
   Lee C, 2011, IEEE T CONSUM ELECTR, V57, P1370, DOI 10.1109/TCE.2011.6018896
   Liu SJ, 2011, IEEE T BROADCAST, V57, P551, DOI 10.1109/TBC.2011.2120750
   Merkle P., 2007, IEEE 3DTV C KOS GREE
   Merkle P, 2007, IEEE T CIRC SYST VID, V17, P1461, DOI 10.1109/TCSVT.2007.903665
   Merkle P, 2010, IEEE T CONSUM ELECTR, V56, P946, DOI 10.1109/TCE.2010.5506024
   Milani S, 2010, IEEE SIGNAL PROC LET, V17, P51, DOI 10.1109/LSP.2010.2051619
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Mori Y, 2009, SIGNAL PROCESS-IMAGE, V24, P65, DOI 10.1016/j.image.2008.10.013
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Mueller M., 2011, 3DTV C TRUE VIS CAPT
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park YK, 2009, SIGNAL PROCESS-IMAGE, V24, P122, DOI 10.1016/j.image.2008.10.008
   Peng ZJ, 2011, IEEE T CONSUM ELECTR, V57, P1815, DOI 10.1109/TCE.2011.6131158
   Shao F, 2014, IEEE J EM SEL TOP C, V4, P106, DOI 10.1109/JETCAS.2014.2298314
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Nguyen VA, 2013, IEEE T CIRC SYST VID, V23, P189, DOI 10.1109/TCSVT.2012.2203212
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Zhang XH, 2008, J VIS COMMUN IMAGE R, V19, P30, DOI 10.1016/j.jvcir.2007.06.001
   Zhang Y, 2014, IEEE T IMAGE PROCESS, V23, P4879, DOI 10.1109/TIP.2014.2355715
   Zhang Y, 2013, IEEE T IMAGE PROCESS, V22, P3497, DOI 10.1109/TIP.2013.2265883
   Zhao Y, 2011, IEEE T IMAGE PROCESS, V20, P2221, DOI 10.1109/TIP.2011.2118218
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
NR 49
TC 6
Z9 8
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 309
EP 322
DI 10.1016/j.jvcir.2015.10.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700028
DA 2024-07-18
ER

PT J
AU Hsu, LY
   Hu, HT
AF Hsu, Ling-Yuan
   Hu, Hwai-Tsu
TI Blind image watermarking via exploitation of inter-block prediction and
   visibility threshold in DCT domain
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Blind image watermarking; Inter-block prediction; Discrete cosine
   transform; Backward-propagation neural network; Just-noticeable
   difference; Relative modulation; Robustness; Imperceptibility
ID WAVELET-BASED WATERMARKING; DIGITAL WATERMARKING; ROBUST
AB In this paper, the backward-propagation neural network (BPNN) technique and just-noticeable difference OD) model are incorporated into a block-wise discrete cosine transform (DCT)-based scheme to achieve effective blind image watermarking. To form a block structure in the DCf domain, we partition a host image into non-overlapped blocks of size 8 x 8 and then apply DCT to each block separately. By referring to certain DCT coefficients over a 3 x 3 grid of blocks, the BPNN can offer adequate predictions of designated coefficients inside the central block. The watermarking turns out to be a process of adjusting the relationship between the intended coefficients and their BPNN predictions subject to the JND. Experimental results show that the proposed scheme is able to withstand a variety of image processing attacks. Compared with two other schemes that also utilize inter-block correlations, the proposed one apparently exhibits superior robustness and imperceptibility under the same payload capacity. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hsu, Ling-Yuan] Jr Coll Med Nursing & Management, Dept Informat Management, Ilan, Taiwan.
   [Hu, Hwai-Tsu] Natl Ilan Univ, Dept Elect Engn, Ilan, Taiwan.
C3 National Ilan University
RP Hu, HT (corresponding author), Natl Ilan Univ, Dept Elect Engn, Ilan, Taiwan.
EM hthu@mail.niu.edu.tw
OI Hsu, Ling-Yuan/0000-0002-9543-6872
FU Ministry of Science and Technology, Taiwan, ROC [MOST
   103-2221-E-197-020, MOST 104-2221-562-002]
FX This research work was supported by the Ministry of Science and
   Technology, Taiwan, ROC under Grants MOST 103-2221-E-197-020 & MOST
   104-2221-562-002.
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   [Anonymous], 2003, Techniques and Applications of Digital Watermarking and Content Protection
   [Anonymous], 2014, INT J COMPUT VISION
   [Anonymous], J MULTIMEDIA
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CC, 2007, LECT NOTES COMPUT SC, V4614, P82
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Hagan MT, 1997, NEURAL NETWORK DESIG
   Hasler M, 1997, IEEE T CIRCUITS-I, V44, P856, DOI 10.1109/81.633874
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Hu HT, 2015, COMPUT ELECTR ENG, V41, P52, DOI 10.1016/j.compeleceng.2014.08.001
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kuo-Ming Hung, 2008, WSEAS Transactions on Computers, V7, P16
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Li LD, 2011, AEU-INT J ELECTRON C, V65, P435, DOI 10.1016/j.aeue.2010.06.001
   Lin SD, 2000, IEEE T CONSUM ELECTR, V46, P415, DOI 10.1109/30.883387
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lu C., 2005, MULTIMEDIA SECURITY
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Tao P., 2006, J Multimed, V1, P36, DOI 10.4304/jmm.1.6.36-45
   Tong HHY, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P428, DOI 10.1109/ICIP.1998.999032
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang XY, 2008, IMAGE VISION COMPUT, V26, P980, DOI 10.1016/j.imavis.2007.10.014
   Wang YL, 2004, PATTERN RECOGN LETT, V25, P1681, DOI 10.1016/j.patrec.2004.06.012
   Wang YW, 2002, IEEE T IMAGE PROCESS, V11, P77, DOI 10.1109/83.982816
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Zhang GN, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2294
   Zhang XH, 2005, SIGNAL PROCESS, V85, P795, DOI 10.1016/j.sigpro.2004.12.002
   Zhang XH, 2008, J VIS COMMUN IMAGE R, V19, P30, DOI 10.1016/j.jvcir.2007.06.001
NR 45
TC 57
Z9 60
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 130
EP 143
DI 10.1016/j.jvcir.2015.07.017
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300011
DA 2024-07-18
ER

PT J
AU Lemus, E
   Bribiesca, E
   Garduño, E
AF Lemus, Eduardo
   Bribiesca, Ernesto
   Garduno, Edgar
TI Surface trees - Representation of boundary surfaces using a tree
   descriptor
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Surface trees; Surface representation; Boundary surface; Discrete
   surfaces; 3D representation; 3D descriptor; Chain code; Compression
   methods
ID OBJECTS
AB Many applications in fields as diverse as computer graphics, medical imaging or pattern recognition require the usage of the boundary of digital objects, or discrete surface. A discrete surface is a set of orthogonal quadrilaterals connected to each other that is typically represented either as a face adjacency graph or as a polygon mesh. In this work we propose a new method, named surface trees, to represent discrete surfaces. Surface trees allow the representation of any discrete surface by coding a tree structure contained in the face adjacency graph. This method uses an alphabet of nine symbols, in addition to the parenthesis notation, to codify trees of maximum degree four. Surface trees are a compact way of representing any discrete surface at the same time they preserve geometrical information and provide invariance under translation and rotation. We demonstrate our method on synthetic surfaces as well as others obtained from real data. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Lemus, Eduardo] Univ Nacl Autonoma Mexico, Grad Program Comp Sci & Engn, Mexico City 04510, DF, Mexico.
   [Bribiesca, Ernesto; Garduno, Edgar] Univ Nacl Autonoma Mexico, Dept Comp Sci, Inst Invest Matemat Aplicadas & Sistemas, Mexico City 04510, DF, Mexico.
C3 Universidad Nacional Autonoma de Mexico; Universidad Nacional Autonoma
   de Mexico
RP Lemus, E (corresponding author), Univ Nacl Autonoma Mexico, Grad Program Comp Sci & Engn, Mexico City 04510, DF, Mexico.
EM eduardo@turing.iimas.unam.mx; bribiesca@iimas.unam.mx; edgargar@ieee.org
RI Bribiesca, Ernesto/AAH-6842-2021; Garduño, Edgar/R-9988-2016
OI Bribiesca, Ernesto/0000-0001-6663-9438; Garduno,
   Edgar/0000-0001-7262-4443
FU CONACYT grant [CVU 205573]
FX This work was partially supported by CONACYT grant (CVU 205573).
CR Ansaldi S., 1985, Computer Graphics, V19, P131, DOI 10.1145/325165.325218
   Artzy E., 1981, Computer Graphics, V15, P92, DOI 10.1145/988460.988465
   Bondy A., 2010, GRADUATE TEXTS MATH, V244
   BRIBIESCA E, 1980, PATTERN RECOGN, V12, P101, DOI 10.1016/0031-3203(80)90009-6
   Bribiesca E, 2012, PATTERN ANAL APPL, V15, P1, DOI 10.1007/s10044-011-0240-z
   Cayley A., 1889, A theorem of trees, V23, P376
   CHIBA N, 1989, J ALGORITHM, V10, P187, DOI 10.1016/0196-6774(89)90012-6
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   de la Luz Gasca Soto M., 2009, THESIS U NACL AUTONO
   Diestel R., 2017, Grad. Texts in Math., V173, DOI DOI 10.1007/978-3-662-53622-3
   GALVEZ JM, 1993, PATTERN RECOGN, V26, P667, DOI 10.1016/0031-3203(93)90120-L
   Lemus E, 2014, PATTERN RECOGN, V47, P1721, DOI 10.1016/j.patcog.2013.11.002
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   NIELSON GM, 1991, VISUALIZATION 91, P83
   Rottger S., 2006, THE VOLUME LIB
   Sagols F., 1999, COMPUT SIST, V4, P213
   Samet H, 1988, NATO ASI SERIES F, V40, P51, DOI DOI 10.1007/978-3-642-83539-1_2
   THOMASSEN C, 1983, J GRAPH THEOR, V7, P169, DOI 10.1002/jgt.3190070205
   Tutte William T, 1956, Transactions of the American Mathematical Society, V82, P99, DOI DOI 10.1090/S0002-9947-1956-0081471-8
NR 19
TC 3
Z9 3
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 101
EP 111
DI 10.1016/j.jvcir.2015.06.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600009
DA 2024-07-18
ER

PT J
AU Al-Jobouri, L
   Fleury, M
   Ghanbari, M
AF Al-Jobouri, Laith
   Fleury, Martin
   Ghanbari, Mohammed
TI Engineering wireless broadband access to IPTV
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; IPTV; Video codec; Video streaming; WiMAX; Application-layer
   FEC; Data-partitioning; Error resilience
ID H.264/AVC VIDEO; SYSTEM; PROTECTION
AB IPTV is now extending to wireless broadband access. If broadband video streaming is to achieve competitive quality the video stream itself must be carefully engineered to cope with challenging wireless channel conditions. This paper presents a scheme for doing this for H.264/AVC codec streaming across a WiMAX link. Packetization is an effective tool to govern error rates and, in the paper, source-coded data-partitioning serves to allocate smaller packets to more important data. A packetization strategy is insufficient in itself, as temporal error propagation should also be addressed by insertion of intra-coded data. It may be necessary to include redundant packets when channel conditions worsen. The whole should be protected by application-layer rateless coding. Therefore, the contribution of the paper is a complete scheme comprised of various protection measures aimed at robust IPTV streaming. Due to computational overheads, the scheme is aimed at the new generation of smartphones with GHz CPUs. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Al-Jobouri, Laith; Fleury, Martin; Ghanbari, Mohammed] Univ Essex, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Fleury, M (corresponding author), Univ Essex, Wivenhoe Pk, Colchester CO4 3SQ, Essex, England.
EM fleum@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Al-Jobouri,
   Laith/0000-0003-4600-9513
FU Ministry of Science and Technology, Baghdad, Iraq
FX Laith Al-Jobouri, who has recently completed his doctorate at the
   University of Essex, UK, would like to thank his financial sponsors at
   the Ministry of Science and Technology, Baghdad, Iraq.
CR Agboma F, 2007, MOB INF SYST, V3, P153, DOI 10.1155/2007/719840
   Al-Jobouri L., 2012, ADV MULTIMEDIA ONLIN, P11
   Al-Jobouri L., 2013, CONSUMER ELECT TIMES, V2, P137
   Al-Jobouri L, 2012, CONSUM COMM NETWORK, P737, DOI 10.1109/CCNC.2012.6181155
   Ali IA, 2013, J VIS COMMUN IMAGE R, V24, P486, DOI 10.1016/j.jvcir.2013.03.005
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], 2007, 26346 3GPP TS
   [Anonymous], 2007, Fundamentals of WiMAX: understanding broadband wireless networking
   [Anonymous], WIMAX APPL
   Asghar M, 2012, IEEE IMAGE PROC, P2645, DOI 10.1109/ICIP.2012.6467442
   Barmada B, 2006, SIGNAL PROCESS-IMAGE, V21, P390, DOI 10.1016/j.image.2006.01.001
   Bing B, 2010, ARTECH HSE TELECOM S, P1
   Casampere J., 2009, P IEEE INT S BROADB, P1
   Chan SHG, 2006, IEEE T MULTIMEDIA, V8, P370, DOI 10.1109/TMM.2005.864340
   Chatterjee M, 2007, IEEE WIREL COMMUN, V14, P64, DOI 10.1109/MWC.2007.314552
   Dahlman E., 2008, 3G EVOLUTION, V2nd
   De Vleeschauwer D, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P161
   Dhondt Y, 2007, LECT NOTES COMPUT SC, V4678, P720
   Digital Video Broadcasting (DVB), 2006, IP DAT DVB H CONT DE
   Ebert J.P., 1999, TKN TECHNICAL REPORT
   Ferré P, 2008, IEEE T VEH TECHNOL, V57, P2596, DOI 10.1109/TVT.2007.909258
   Ferré P, 2010, SIGNAL PROCESS-IMAGE, V25, P163, DOI 10.1016/j.image.2009.12.005
   Fleury M., 2009, WIMAX, New Developments, P213
   Gasiba T, 2006, IEEE ICC, P5444
   Halinger Gerhard, 2008, Proc. 14th GI/ITG Conf. Meas. Modelling Evaluation Comput. Commun. Syst, P1
   Hillestad O.I., 2006, Proc. Proceedings of the 2nd ACM international workshop on Wireless multimedia networking and performance modeling, P43
   Hillested O., 2007, P PACK VID NOV, P26
   Hwang JN, 2009, MULTIMEDIA NETWORKING: FROM THEORY TO PRACTICE, P1, DOI 10.1017/CBO9780511626654
   Issariwakul T., 2012, INTRO NS 2 SIMULATOR
   Jenkac H., 2005, P IST MOB SUMM
   Juan H.-H., 2008, WIREL NETW, V16, P113
   Kalva H., 2012, P IEEE INT C CONS EL, P160
   Lederer S., 2012, P ACM UT C
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   Luby M, 2002, ANN IEEE SYMP FOUND, P271, DOI 10.1109/SFCS.2002.1181950
   Luby M, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4511656
   Luby M, 2007, IEEE T BROADCAST, V53, P235, DOI 10.1109/TBC.2007.891703
   MacKay DJC, 2005, IEE P-COMMUN, V152, P1062, DOI 10.1049/ip-com:20050237
   Martin J, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P230, DOI 10.1109/CCNC.2013.6488451
   Mladenov T, 2011, IEEE T COMPUT, V60, P1678, DOI 10.1109/TC.2010.210
   Moiron S., 2011, RECENT PATENTS SIGNA, V1, P1, DOI DOI 10.2174/2210686311101020124
   Muntean GM, 2004, IEEE T BROADCAST, V50, P1, DOI 10.1109/TBC.2004.824745
   Mys S, 2006, LECT NOTES COMPUT SC, V4261, P329
   Niyato D., 2007, IEEE COMMUN MAG, V45, P14
   Park S, 2009, IEEE INTERNET COMPUT, V13, P23, DOI 10.1109/MIC.2009.65
   Pecheron S., 2013, COMMS ENG DESIGN CED, V39, P22
   Peyic M, 2012, MICROPROCESS MICROSY, V36, P159, DOI 10.1016/j.micpro.2011.12.006
   Radulovic I, 2010, IEEE T CIRC SYST VID, V20, P144, DOI 10.1109/TCSVT.2009.2026815
   Razavi R, 2008, ELECTRON LETT, V44, P867, DOI 10.1049/el:20080403
   Ryu M., 2012, P ACM WORKSH NETW OP
   Schierl T, 2012, IEEE T CIRC SYST VID, V22, P1871, DOI 10.1109/TCSVT.2012.2223054
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Simpson W., 2008, VIDEO OVER IP
   So-In C., 2010, J COMPUT SYST NETWOR
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Srinivasan K, 2008, SENSYS'08: PROCEEDINGS OF THE 6TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P29
   Stockhammer T, 2004, IEEE IMAGE PROC, P545
   Stockhammer T, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P193
   Stockhammer T., 2007, MULTIMEDIA IP WIRELE, P13, DOI DOI 10.1016/B978-012088480-3/50003-5
   Tourapis A. M., 2009, P 31 M JOINT VID TEA
   Tsai F. C. D., 2006, P WORKSH NS2 IP NETW
   Varsa V., 2001, P 14 M ITU T VCEG
   Verhoeyen M, 2009, BELL LABS TECH J, V14, P39, DOI 10.1002/bltj.20372
   Waggoner B., 2010, Compression for Great Video and Audio: Master Tips and Common Sense, VSecond
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 66
TC 6
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1493
EP 1506
DI 10.1016/j.jvcir.2014.06.013
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100001
DA 2024-07-18
ER

PT J
AU Wang, JX
   Ni, JQ
   Hu, YJ
AF Wang, Junxiang
   Ni, Jiangqun
   Hu, Yongjian
TI An efficient reversible data hiding scheme using prediction and optimal
   side information selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Histogram shifting; Prediction errors; Optimal
   peak and zero bins selection; Multi-layer embedding; Location map
   compression; Improved rhombus prediction; Control parameter
AB In this paper, we present an efficient histogram shifting (HS) based reversible data hiding scheme for copyright protection of multimedia. Firstly, an improved HS based multi-layer embedding process for rhombus prediction is employed by introducing a control parameter to explore the correlation of prediction errors. A rate-distortion model for HS embedding is then developed for optimal side information selection, which is especially suitable for low payload reversible data hiding when only a single layer embedding is required. Finally, a modified location map is constructed to facilitate the compression of location map and further increase the embedding capacity. Compared with similar schemes, experimental results demonstrate the superior performance of the proposed scheme in the terms of embedding capacity and stego-image quality. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Wang, Junxiang] Jingdezhen Ceram Inst, Sch Mech & Elect Engn, Jingdezhen 333403, Jiangxi, Peoples R China.
   [Ni, Jiangqun] Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
   [Hu, Yongjian] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 Jingdezhen Ceramic Institute; Sun Yat Sen University; South China
   University of Technology
RP Ni, JQ (corresponding author), Sun Yat Sen Univ, Sch Informat Sci & Technol, Guangzhou 510275, Guangdong, Peoples R China.
EM wjx851113851113@gmail.com; issjqni@mail.sysu.edu.cn; eeyjhu@scut.edu.cn
FU National Natural Science Foundation of China [61379156, 61164014,
   61100170]; National Research Foundation for the Doctoral Program of
   Higher Education of China [20120171110037]; key Program of Natural
   Science Foundation of Guangdong [S2012020011114]; Natural Science
   Foundation for Youths of Jiangxi Province [20132BAB211019]
FX This work is supported by the National Natural Science Foundation of
   China (61379156, 61164014 and 61100170), the National Research
   Foundation for the Doctoral Program of Higher Education of China
   (20120171110037), the key Program of Natural Science Foundation of
   Guangdong (S2012020011114) and Natural Science Foundation for Youths of
   Jiangxi Province (20132BAB211019).
CR Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Hwang J, 2006, LECT NOTES COMPUT SC, V4283, P348
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang C., 2010, P IEEE INT C IM PROC
   Wang J. X., 2011, P INT WORKSH DIG WAT
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yeo DG, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3532833
NR 17
TC 12
Z9 13
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1425
EP 1431
DI 10.1016/j.jvcir.2014.04.005
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100012
DA 2024-07-18
ER

PT J
AU Pakniat, N
   Noroozi, M
   Eslami, Z
AF Pakniat, Nasrollah
   Noroozi, Mahnaz
   Eslami, Ziba
TI Secret image sharing scheme with hierarchical threshold access structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cryptography; Secret image sharing; Hierarchical threshold access
   structure; Cellular automata; Birkhoff interpolation; Information
   hiding; Reversibility; Tamper detection
ID CELLULAR-AUTOMATA; STEGANOGRAPHY; SUBSTITUTION
AB A hierarchical threshold secret image sharing (HTSIS) scheme is a method to share a secret image among a set of participants with different levels of authority. Recently, Guo et al. (2012) [22] proposed a HTSIS scheme based on steganography and Birkhoff interpolation. However, their scheme does not provide the required secrecy needed for HTSIS schemes so that some non-authorized subsets of participants are able to recover parts of the secret image. In this paper, we employ cellular automata and Birkhoff interpolation to propose a secure HTSIS scheme. In the new scheme, each authorized subset of participants is able to recover both the secret and cover images losslessly whereas non-authorized subsets obtain no information about the secret image. Moreover, participants are able to detect tampering of the recovered secret image. Experimental results show that the proposed scheme outperforms Guo et al.'s approach in terms of visual quality as well. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Pakniat, Nasrollah; Noroozi, Mahnaz; Eslami, Ziba] Shahid Beheshti Univ, Dept Comp Sci, GC, Tehran, Iran.
C3 Shahid Beheshti University
RP Eslami, Z (corresponding author), Shahid Beheshti Univ, Dept Comp Sci, GC, Tehran, Iran.
EM n_pakniat@sbu.ac.ir; m.noroozi@mail.sbu.ac.ir; z_eslami@sbu.ac.ir
RI Noroozi, Mahnaz/AAT-7645-2021; Pakniat, Nasrollah/AAT-7623-2021
OI Noroozi, Mahnaz/0000-0002-3021-438X; Pakniat,
   Nasrollah/0000-0003-3925-1141; Eslami, Ziba/0000-0002-9818-3911
CR Alonso-Sanz R, 2003, PHYSICA D, V175, P1, DOI 10.1016/S0167-2789(02)00693-0
   Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Eslami Z, 2010, INFORM SCIENCES, V180, P2889, DOI 10.1016/j.ins.2010.04.015
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Thien C.-C., PATTERN RECOGN, V36
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   TOFFOLI T, 1990, PHYSICA D, V45, P229, DOI 10.1016/0167-2789(90)90185-R
   Ulutas M, 2013, J SYST SOFTWARE, V86, P485, DOI 10.1016/j.jss.2012.09.027
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wu XT, 2013, J SYST SOFTWARE, V86, P1068, DOI 10.1016/j.jss.2012.11.021
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Wu YS, 2004, PATTERN RECOGN, V37, P1377, DOI 10.1016/j.patcog.2004.01.002
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
NR 25
TC 35
Z9 35
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1093
EP 1101
DI 10.1016/j.jvcir.2014.03.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200035
DA 2024-07-18
ER

PT J
AU Alvarez-Santos, V
   Iglesias, R
   Pardo, XM
   Regueiro, CV
   Canedo-Rodriguez, A
AF Alvarez-Santos, V.
   Iglesias, R.
   Pardo, X. M.
   Regueiro, C. V.
   Canedo-Rodriguez, A.
TI Gesture-based interaction with voice feedback for a tour-guide robot
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tour-guide robot; Gesture interface; Human-robot interaction; Gesture
   recognition; Human following; Human detection; Human identification;
   Human tracking
ID PEOPLE TRACKING; INTERFACE; RECOGNITION
AB Any service robot should possess some kind of human-robot interaction to communicate with users. In this paper we present a tour-guide robot able to recognize hand gestures and provide voice feedback. A user can communicate with the robot using hand movements, but also through virtual buttons which are shown in a augmented reality environment in the robot's screen. Moreover, the user continuously receives feedback from the robot's screen or by means of voice messages. The result is a robot that understands the users' needs and which keeps them informed about what it senses, which increases the usefulness of our robot. Finally, to measure the quality in use, we have conducted two user studies, which we have used to reveal and correct the weakness of the robot. The guide robot was successfully tested in several real world environments. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Alvarez-Santos, V.; Iglesias, R.; Pardo, X. M.; Canedo-Rodriguez, A.] Univ Santiago de Compostela, CITIUS, E-15782 Santiago De Compostela, Spain.
   [Regueiro, C. V.] Univ A Coruna, Dept Elect & Syst, E-15071 La Coruna, Spain.
C3 Universidade de Santiago de Compostela; Universidade da Coruna
RP Alvarez-Santos, V (corresponding author), Univ Santiago de Compostela, CITIUS, E-15782 Santiago De Compostela, Spain.
EM victor.alvarez@usc.es; roberto.iglesias@usc.es; xose.pardo@usc.es;
   cvazquez@udc.es; adrian.canedo@usc.es
RI Regueiro, Carlos V./L-2230-2014; Rodriguez, Roberto
   Iglesias/B-6171-2012; Pardo, Xose M./L-8567-2014
OI Regueiro, Carlos V./0000-0003-3672-1726; Rodriguez, Roberto
   Iglesias/0000-0002-6279-5190; Pardo, Xose M./0000-0002-3997-5150
FU FPI-MICINN [BES-2010-040813]; Galician Government;  [TIN2009-07737]; 
   [TIN2012-32262]
FX This work was funded by the research projects TIN2009-07737 and
   TIN2012-32262, the Grant BES-2010-040813 FPI-MICINN and by the Galician
   Government (Consolidation of Competitive Research Groups, Xunta de
   Galicia ref. 2010/6)
CR Alvarez-Santos V, 2012, ROBOT AUTON SYST, V60, P1021, DOI 10.1016/j.robot.2012.05.014
   [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], 2008, J INF ACQUISITION
   Avilés H, 2010, LECT NOTES ARTIF INT, V6433, P512
   BUHMANN J, 1995, AI MAG, V16, P31
   Burgard W, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P11
   Chen S, 2010, ARTIF LIFE ROBOT, V15, P439, DOI 10.1007/s10015-010-0838-z
   Choset H., 2005, Principles of robot motion: Theory, algorithms and implementation, P77
   Cielniak G, 2010, ROBOT AUTON SYST, V58, P435, DOI 10.1016/j.robot.2010.02.004
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elmezain M, 2008, INT C PATT RECOG, P424
   Fritsch J., 2004, P INT C INTELLIGENT, P898
   Gast Jurgen, 2009, 2009 2nd Conference on Human System Interactions (HSI 2009), P276, DOI 10.1109/HSI.2009.5090992
   Gockley R., 2007, P ACM IEEE INT C HUM, P17, DOI DOI 10.1145/1228716.1228720
   GRANATA C, 2010, P 19 IEEE HUM ROB IN, P785
   Gross HM, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2005, DOI 10.1109/IROS.2009.5354497
   Hüttenrauch H, 2004, IEEE T SYST MAN CY C, V34, P113, DOI 10.1109/TSMCC.2004.826281
   Ishii K, 2009, LECT NOTES COMPUT SC, V5727, P479, DOI 10.1007/978-3-642-03658-3_52
   Just A, 2009, COMPUT VIS IMAGE UND, V113, P532, DOI 10.1016/j.cviu.2008.12.001
   Kanda T., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P173
   Lang S., 2003, P 5 INT C MULTIMODAL, P28, DOI DOI 10.1145/958432.958441
   Liu X, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P529
   Moni MA, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 4, P433, DOI 10.1109/ICCSIT.2009.5234536
   Mucientes M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P692, DOI 10.1109/IROS.2006.282614
   Muñoz-Salinas R, 2008, J VIS COMMUN IMAGE R, V19, P75, DOI 10.1016/j.jvcir.2007.07.004
   Muñoz-Salinas R, 2009, J VIS COMMUN IMAGE R, V20, P339, DOI 10.1016/j.jvcir.2009.03.005
   Okuno Y., 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P53
   Pacchierotti E, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4965, DOI 10.1109/IROS.2006.282519
   Pengyu Hong, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P410, DOI 10.1109/AFGR.2000.840667
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Rodriguez-Losada D., 2008, Advances in Service Robotics, P229
   Rogalla O, 2002, IEEE ROMAN 2002, PROCEEDINGS, P454, DOI 10.1109/ROMAN.2002.1045664
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Stricker R., 2012, 2012 RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication, P695, DOI 10.1109/ROMAN.2012.6343832
   Thomaz A. L., 2006, P 5 INT C DEV LEARN
   Thrun Sebastian, 1999, P IEEE INT C ROB AUT, V3
   Treptow A, 2006, ROBOT AUTON SYST, V54, P729, DOI 10.1016/j.robot.2006.04.013
   van Breemen A., 2005, P 4 INT JOINT C AUTO, P143
   Waldherr S, 2000, AUTON ROBOT, V9, P151, DOI 10.1023/A:1008918401478
   Xu FL, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P115, DOI 10.1109/AVSS.2003.1217910
   Yelamarthi K, 2012, MIDWEST SYMP CIRCUIT, P562, DOI 10.1109/MWSCAS.2012.6292082
   Yoon K, 2006, J VIS COMMUN IMAGE R, V17, P605, DOI 10.1016/j.jvcir.2005.09.003
   Zhou HY, 2008, IEEE J-STSP, V2, P503, DOI 10.1109/JSTSP.2008.2001429
   Zhu C, 2011, IEEE T SYST MAN CY A, V41, P569, DOI 10.1109/TSMCA.2010.2093883
NR 44
TC 32
Z9 36
U1 2
U2 40
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 499
EP 509
DI 10.1016/j.jvcir.2013.03.017
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300025
DA 2024-07-18
ER

PT J
AU Asghar, MN
   Ghanbari, M
   Fleury, M
   Reed, MJ
AF Asghar, Mamoona N.
   Ghanbari, Mohammed
   Fleury, Martin
   Reed, Martin J.
TI Confidentiality of a selectively encrypted H.264 coded video bit-stream
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Confidentiality; Cryptanalysis; Entropy coding; Guessing attacks;
   Perceptual attacks; Probability analysis; Selective encryption; Syntax
   elements
ID MULTIMEDIA
AB It is an assumption that selective encryption does not strongly protect confidentiality owing to the partial visibility of some video data. This is because, though encryption keys may be difficult to derive, an enhanced version of selectively encrypted video sequence might be found from knowledge of the unencrypted parts of the sequence. An efficient selective encryption method for syntax elements of H.264 encoded video was recently proposed at the entropy coding stage of an H.264 encoder. Using this recent scheme as an example, the purpose of this paper is a comprehensive cryptanalysis of selectively encrypted H.264 bit-streams to contradict the previous assumption that selective encryption is vulnerable. The novel cryptanalysis methods presented in this paper analyze the ability of an attacker to improve the quality of the encrypted video stream to make it watchable. The conclusion is drawn that if the syntax elements for selective encryption are chosen using statistical and structural characteristics of the video, then the selective encryption method is secure. The cryptanalysis is performed by taking into account the probability distribution of syntax elements within the video sequence, the relationship of syntax elements with linear regression analysis and the probability of successfully attacking them in order to enhance the visual quality. The results demonstrate the preservation of distorted video quality even after considering many possible attacks on: the whole video sequence; each video frame; and on small video segments known as slices. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Asghar, Mamoona N.; Ghanbari, Mohammed; Fleury, Martin; Reed, Martin J.] Univ Essex, Sch CSEE, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Asghar, MN (corresponding author), Univ Essex, Sch CSEE, Colchester CO4 3SQ, Essex, England.
EM masghaa@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Asghar,
   Mamoona/0000-0001-7460-266X
CR Algin GB, 2011, J VIS COMMUN IMAGE R, V22, P353, DOI 10.1016/j.jvcir.2011.02.005
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], P ACM MULT SEC WORKS
   Asghar M. N., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P443, DOI 10.1109/TrustCom.2012.268
   Asghar M.N., 2012, INT C IM PROC
   Bhargava B, 2004, MULTIMED TOOLS APPL, V24, P57, DOI 10.1023/B:MTAP.0000033983.62130.00
   Chen TC, 2006, IEEE T CIRCUITS-II, V53, P832, DOI 10.1109/TCSII.2006.880014
   Esslinger B., 2010, CRYPTOOL SCRIPT CRYP
   Furht B, 2005, INTERNET COMMUN SER, P95
   Furht B., 2006, Multimedia encryption and authentication techniques and applications
   Harte L, 2007, INTRO DIGITAL RIGHTS, V2
   HHI, 2008, JM REF SOFTW
   Jakimoski G, 2008, IEEE T MULTIMEDIA, V10, P330, DOI 10.1109/TMM.2008.917355
   Kahn D., 1997, The Codebreakers: The Comprehensive History of Secret Communication From Ancient Times to the Internet
   Lambert P, 2006, J VIS COMMUN IMAGE R, V17, P358, DOI 10.1016/j.jvcir.2005.05.008
   Lookabaugh T, 2004, IEEE COMMUN MAG, V42, P124, DOI 10.1109/MCOM.2004.1299355
   Lookabaugh T., 2003, SPIE P, V5241, P1
   Magli E, 2011, SIGNAL PROCESS, V91, P1103, DOI 10.1016/j.sigpro.2010.10.012
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Muharemagic E, 2005, INTERNET COMMUN SER, P221
   Ostermann J., 2004, IEEE Circuits and Systems Magazine, V4, P7, DOI 10.1109/MCAS.2004.1286980
   Park S. W., 2008, 4 INT C NETW COMP AD, P371
   Quan HT, 2012, TELECOMMUN SYST, V49, P35, DOI 10.1007/s11235-010-9351-x
   Said A., 2005, IEEE INT C IMAGE PRO, V2, P1126
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seidel T. E., 2004, Tatra Mountains Mathematical Publications, V29, P79
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   Shahid Z, 2009, IEEE IMAGE PROC, P1273, DOI 10.1109/ICIP.2009.5413605
   Shi C., 1998, INT C MULT, P55
   Stütz T, 2012, IEEE T CIRC SYST VID, V22, P325, DOI 10.1109/TCSVT.2011.2162290
   Stütz T, 2008, IEEE INT SYM MULTIM, P446, DOI 10.1109/ISM.2008.52
   Uhl A., 2005, Image and Video Encryption: From Digital Rights Management to Secured Personal Communication
   Wang YS, 2013, IEEE T CIRC SYST VID, V23, P1476, DOI 10.1109/TCSVT.2013.2248588
   Wang Z., 2004, IEEE T IMAGE PROCESS, V13
   Yu H, 2005, INTERNET COMMUN SER, P197
   Zhu BB, 2004, PROC SPIE, V5601, P157, DOI 10.1117/12.571869
NR 38
TC 18
Z9 19
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 487
EP 498
DI 10.1016/j.jvcir.2013.12.015
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300024
DA 2024-07-18
ER

PT J
AU Chen, HS
   Tsai, WJ
AF Chen, Hsuan-Sheng
   Tsai, Wen-Jiin
TI A framework for video event classification by modeling temporal context
   of multimodal features using HMM
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multimedia system; Video semantic analysis; Baseball event
   classification; Co-occurrence symbol; Interval-based multimodal feature;
   HMM; Probabilistic temporal modeling; Multivariate temporal data
   classification
ID HIDDEN MARKOV-MODELS; KNOWLEDGE
AB Semantic high-level event recognition of videos is one of most interesting issues for multimedia searching and indexing. Since low-level features are semantically distinct from high-level events, a hierarchical video analysis framework is needed, i.e., using mid-level features to provide clear linkages between low-level audio-visual features and high-level semantics. Therefore, this paper presents a framework for video event classification using temporal context of mid-level interval-based multimodal features. In the framework, a co-occurrence symbol transformation method is proposed to explore full temporal relations among multiple modalities in probabilistic HMM event classification. The results of our experiments on baseball video event classification demonstrate the superiority of the proposed approach. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Chen, Hsuan-Sheng; Tsai, Wen-Jiin] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, HS (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Taiwan 1001 Univ Rd, Hsinchu 300, Taiwan.
EM xschen@cs.nctu.edu.tw; wjtsai@cs.nctu.edu.tw
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Babaguchi N, 2002, IEEE T MULTIMEDIA, V4, P68, DOI 10.1109/6046.985555
   BALDI P, 1994, P NATL ACAD SCI USA, V91, P1059, DOI 10.1073/pnas.91.3.1059
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   Brand M., 1996, P IEEE COMP VIS PATT
   Chang P, 2002, IEEE IMAGE PROC, P609
   Chen M, 2006, IEEE SIGNAL PROC MAG, V23, P38, DOI 10.1109/MSP.2006.1621447
   Chen M, 2007, I C DATA ENGIN WORKS, P137, DOI 10.1109/ICDEW.2007.4400983
   Dao MS, 2010, MULTIMED TOOLS APPL, V50, P227, DOI 10.1007/s11042-009-0379-4
   Ding Y., P 1 ACM INT WORKSH E
   Duan L.-Y., P 11 ACM INT C MULT
   Duan LY, 2005, IEEE T MULTIMEDIA, V7, P1066, DOI 10.1109/TMM.2005.858395
   Fleischman M., P INT WORKSH WORKSH
   Fleischman M., P 8 ACM INT WORKSH M
   Fleischman Michael, 2008, ACL, P121
   Huang J., 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P53, DOI 10.1109/MMSP.1999.793797
   Li BX, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P132, DOI 10.1109/IVL.2001.990867
   Nefian AV, 2002, INT CONF ACOUST SPEE, P2013
   Poppe C., P 3 INT WORKSH AUT I
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Snoek C. G. M., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P21, DOI 10.1109/ICME.2002.1035364
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Tardini G, 2005, LECT NOTES COMPUT SC, V3617, P653, DOI 10.1007/11553595_80
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   Weng M.-F., P 16 ACM INT C MULT
   Wu SY, 2007, IEEE T KNOWL DATA EN, V19, P742, DOI [10.1109/TKDE.2007.190613, 10.1109/TKDE.2007.1032.]
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Xu G, 2002, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2002.1048431
   Xu H., P 6 ACM SIGMM INT WO
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Zhang T., P INT C MULT FIR IT
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
NR 34
TC 9
Z9 9
U1 2
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 285
EP 295
DI 10.1016/j.jvcir.2013.12.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300005
DA 2024-07-18
ER

PT J
AU Bereta, M
   Pedrycz, W
   Reformat, M
AF Bereta, Michal
   Pedrycz, Witold
   Reformat, Marek
TI Local descriptors and similarity measures for frontal face recognition:
   A comparative analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Face identification; Face verification; Local
   descriptors; Local binary patterns; Gabor filters; FERET database; Local
   descriptors' taxonomy
ID PHASE PATTERNS HGPP; BINARY PATTERNS; GENDER CLASSIFICATION; GABOR
   WAVELETS; REPRESENTATION; HISTOGRAM; COMPONENT; EIGENFACES; DESIGN;
   MODEL
AB Face recognition based on local descriptors has been recently recognized as the state-of-the-art design framework for problems of facial identification and verification. Given the diversity of the existing approaches, the main objective of this paper is to present a comprehensive, in-depth comparative analysis of the recent face recognition methodologies based on local descriptors. We carefully review and contrast a suite of commonly encountered local descriptors. In particular, we highlight their main features in the setting of problems of facial recognition. The main advantages and limitations of the discussed methods are identified. Furthermore a carefully structured taxonomy of the existing approaches is presented We show that the presented techniques are particularly suitable for large scale facial authentication systems in which the training stage with the use of the overall face database might be computationally prohibited. A variety of approaches being used to realize a fusion of the local descriptions into the global ones are discussed along with their pros and cons. Furthermore different similarity measures and possible extensions and hybridizations with statistical learning techniques are elaborated on as well. Experimental results obtained for the FERET database are carefully assessed and compared. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Bereta, Michal; Pedrycz, Witold; Reformat, Marek] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6R 2V4, Canada.
   [Bereta, Michal] Cracow Univ Technol, Inst Comp Sci, PL-31155 Krakow, Poland.
   [Pedrycz, Witold] King Abdulaziz Univ, Fac Engn, Dept Elect & Comp Engn, Jeddah 21589, Saudi Arabia.
   [Pedrycz, Witold] Polish Acad Sci, Syst Res Inst, PL-01447 Warsaw, Poland.
C3 University of Alberta; Cracow University of Technology; King Abdulaziz
   University; Polish Academy of Sciences; Systems Research Institute of
   the Polish Academy of Sciences
RP Bereta, M (corresponding author), Univ Alberta, Dept Elect & Comp Engn, 9107-116 St, Edmonton, AB T6R 2V4, Canada.
EM bereta@ualberta.ca; wpedrycz@ualberta.ca; marek.reformat@ualberta.ca
OI Bereta, Michal/0000-0002-7153-980X; Reformat, Marek
   Z./0000-0003-4783-0717
FU Natural Sciences and Engineering Research Council (NSERC); Canada
   Research Chair (CRC) program
FX This work was supported in part by a Strategic Grant from the Natural
   Sciences and Engineering Research Council (NSERC) and the Canada
   Research Chair (CRC) program.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Albiol A, 2008, PATTERN RECOGN LETT, V29, P1537, DOI 10.1016/j.patrec.2008.03.017
   [Anonymous], 2008, FAC REAL LIF IM WORK
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bendada Abdelhakim, 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P101, DOI 10.1109/CRV.2010.20
   Beveridge JR, 2001, PROC CVPR IEEE, P535
   Bian W., 2011, HDB FACE RECOGNITION, P51
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   Boom BJ, 2007, P 28 S INF THEOR BEN, P189
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Chan CH, 2007, LECT NOTES COMPUT SC, V4642, P809
   Chen JF, 2008, LECT NOTES COMPUT SC, V5226, P430, DOI 10.1007/978-3-540-87442-3_54
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Daugman J, 2002, IEEE IMAGE PROC, P33
   Dongil Han, 2010, Proceedings of the 2010 International Symposium on Ubiquitous Virtual Reality (ISUVR 2010), P48, DOI 10.1109/ISUVR.2010.25
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Guo Yanlin., 2008, IEEE CVPR, P1, DOI DOI 10.1109/WICOM.2008.2663
   Guo YM, 2009, LECT NOTES COMPUT SC, V5575, P229
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Heusch G, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P9
   Ho T.K., IEEE T PATTERN ANAL, P16
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Huang CR, 2008, PATTERN RECOGN, V41, P3071, DOI 10.1016/j.patcog.2008.03.013
   Jabid T, 2010, IEEE IMAGE PROC, P1605, DOI 10.1109/ICIP.2010.5652374
   Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44
   Jun B, 2009, IEEE INT SYMP SIGNAL, P392, DOI 10.1109/ISSPIT.2009.5407525
   Kannala J, 2012, INT C PATT RECOG, P1363
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu GC, 2009, IEEE T IMAGE PROCESS, V18, P921, DOI 10.1109/TIP.2009.2013072
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marcel S., 2006, INT J IMAGE VIDEO PR
   Meir R., 2003, Advanced Lectures on Machine Learning. Machine Learning Summer School 2002. Revised Lectures. (Lecture Notes in Artificial Intelligence Vol.2600), P118
   Meng X, 2006, INT C PATT RECOG, P536
   Meng Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2680, DOI 10.1109/ICPR.2010.657
   Mohamed AA, 2012, 2012 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2012), VOL 1, P57, DOI 10.1109/ICMLA.2012.19
   Mu Y, 2009, COGN COMPUT, V1, P327, DOI 10.1007/s12559-009-9028-5
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1999, ADV NEUR IN, V11, P803
   Qing LY, 2006, INT C PATT RECOG, P1139
   Rodriguez Y, 2006, LECT NOTES COMPUT SC, V3954, P321
   Sapkota A., 2010, 2010 IEEE COMP SOC C, P82
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Serrano A, 2010, PATTERN RECOGN LETT, V31, P372, DOI 10.1016/j.patrec.2009.11.002
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   Störmer A, 2009, IEEE IMAGE PROC, P61, DOI 10.1109/ICIP.2009.5413952
   Sun N, 2006, LECT NOTES COMPUT SC, V3972, P194
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Verschae R, 2006, LECT NOTES COMPUT SC, V4225, P68
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XY, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, VOLS 1-4, P590, DOI 10.1109/ICINFA.2008.4608068
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Xie S., 2008, P 19 INT C PATT REC, P1, DOI DOI 10.1109/WICOM.2008.1011008
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016
   Yan SC, 2007, INT CONF ACOUST SPEE, P629
   Yanbin H., 2008, INT S COMP SCI COMP, P719
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yun WH, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, VOLS 1-3, P749, DOI 10.1109/ISCIT.2007.4392116
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhang TH, 2008, LECT NOTES COMPUT SC, V5302, P725, DOI 10.1007/978-3-540-88682-2_55
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang WC, 2005, LECT NOTES COMPUT SC, V3546, P937
   Zhang WC, 2007, IEEE SIGNAL PROC LET, V14, P875, DOI 10.1109/LSP.2007.903260
   Zhang WC, 2009, PATTERN ANAL APPL, V12, P301, DOI 10.1007/s10044-008-0123-0
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhen Cui, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P149, DOI 10.1109/FG.2011.5771389
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 80
TC 40
Z9 42
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1213
EP 1231
DI 10.1016/j.jvcir.2013.08.004
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700001
DA 2024-07-18
ER

PT J
AU Zhu, SH
   Hu, JJ
   Wang, BY
   Shen, SH
AF Zhu, Songhao
   Hu, Juanjuan
   Wang, Baoyun
   Shen, Shuhan
TI Image annotation using high order statistics in non-Euclidean spaces
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dissimilarity diffusion distribution; High-order statistics; Maximum a
   posteriori; Gaussian Mixture Model; Non-Euclidean space; Image
   annotation; Corel database; Experimentation
ID RECOGNITION
AB Automatic image annotation is a promising way to achieve more effective image retrieval and image analysis by using keywords associated to the image content. Due to the semantic gap between low-level visual features and high-level semantic concepts of an image, however, the performances of many existing algorithms are not so satisfactory. In this paper, a novel image classification scheme, named high order statistics based maximum a posterior (HOS-MAP), is proposed to deal with the issue of image annotation. To bridge the gap between human judgment and machine intelligence, the proposed scheme first constructs a dissimilarity representation for each image in a non-Euclidean space; then, the information of dissimilarity diffusion distribution for each image is achieved with respect to the high-order statistics of a triplet of nearest neighbor images; finally, a maximum a posteriori algorithm with the information of Gaussian Mixture Model and dissimilarity diffusion distribution is adopted to estimate the relevance between each annotation and an input un-annotated image. Experimental results on a general-purpose image database demonstrate the effectiveness and efficiency of the proposed automatic image annotation scheme. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhu, Songhao; Hu, Juanjuan; Wang, Baoyun] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Jiangsu, Peoples R China.
   [Shen, Shuhan] Chinese Acad Sci, Inst Automat, Beijing 110093, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Chinese Academy of
   Sciences; Institute of Automation, CAS
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Jiangsu, Peoples R China.
EM zhush@njupt.edu.cn
RI Shen, Shuhan/B-2439-2015
OI Shen, Shuhan/0000-0002-8704-7914
FU Research Fund for the Doctoral Program of Higher Education of China
   [20103223120003]; Natural Science Fund of Jiangsu Province [BK2011758,
   BK2012832]; National Natural Science Foundation of China [61073113,
   61104216, 61271232]
FX This work is supported by Research Fund for the Doctoral Program of
   Higher Education of China under No. 20103223120003, Natural Science Fund
   of Jiangsu Province under No. BK2011758 and BK2012832, National Natural
   Science Foundation of China under Nos. 61073113, 61104216 and 61271232.
CR Aidos H, 2012, PATTERN RECOGN, V45, P3061, DOI 10.1016/j.patcog.2011.12.009
   Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], 2008, Proceedings of the 16th ACM international conference on Multimedia
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Chen ZH, 2012, IEEE T SYST MAN CY C, V42, P1120, DOI 10.1109/TSMCC.2011.2178831
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Edelman Shimon., 1999, REPRESENTATION RECOG
   Fan JP, 2005, PATTERN RECOGN, V38, P865, DOI 10.1016/j.patcog.2004.07.011
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Fred ALN, 2003, IEEE T PATTERN ANAL, V25, P944, DOI 10.1109/TPAMI.2003.1217600
   Fu H, 2010, PATTERN RECOGN, V43, P3539, DOI 10.1016/j.patcog.2010.04.009
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Kokare M, 2003, TENCON IEEE REGION, P571, DOI 10.1109/TENCON.2003.1273228
   Lavrenko V., 2003, IEEE INT C NEUR INF, P1
   Liu J, 2009, PATTERN RECOGN, V42, P218, DOI 10.1016/j.patcog.2008.04.012
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Tang J., 2010, P ACM C MULT, P1019
   Ulges A, 2011, IEEE T MULTIMEDIA, V13, P330, DOI 10.1109/TMM.2010.2101051
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Wang C., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383221
   Wang Y, 2009, PATTERN RECOGN, V42, P259, DOI 10.1016/j.patcog.2008.05.010
   WANG ZW, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P152
   Xu HX, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P573, DOI 10.1109/GCIS.2009.320
   ZHU SH, 2012, 2012 IEEE INT C AC, P1041
   Zhu SH, 2008, OPT ENG, V47, DOI 10.1117/1.3027481
NR 26
TC 2
Z9 3
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2013
VL 24
IS 8
BP 1342
EP 1348
DI 10.1016/j.jvcir.2013.09.004
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 274EZ
UT WOS:000328590700011
DA 2024-07-18
ER

PT J
AU Yang, KF
   Wan, S
   Gong, YC
   Feng, Y
AF Yang, Kaifang
   Wan, Shuai
   Gong, Yanchao
   Feng, Yan
TI A fast algorithm of bitstream extraction using distortion prediction
   based on simulated annealing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Scalable Video Coding (SVC); Bitstream extraction; Simulated annealing;
   Medium-grain Quality Scalability (MGS); Inter layer dependency;
   Optimization; Decoding times; Fast algorithm
ID SCALABLE EXTENSION; VIDEO
AB Scalable video streams can be extracted to meet the bandwidth limitation of different networks and end-users. Bitstream extraction is usually performed at the network proxy or gateway during transmission, where a low computational complexity is always preferred. How to quickly and accurately select the best resolution combination for a video to meet different bandwidth requirements by each user is crucial in bitstream extraction. In this paper a fast algorithm of bitstream extraction for scalable video is proposed. The interlayer dependency between the base quality layer and the first quality layer was used to predict the distortion of higher quality layers. When quality of every layer is available, the proposed method searches for the optimized combination of quality layers based on simulated annealing. Experimental results show that the proposed method provides an optimized performance, which is significantly higher than that can be achieved by the basic extraction method. Compared to the quality layer based extraction method in the reference software model of H.264/SVC (i.e., JSVM), the proposed algorithm can greatly decrease the decoding times from 2NT to only 2 without losing rate-distortion performance. Furthermore, the proposed method obtains a more smoothed video quality which is always favorable to the observer. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Yang, Kaifang; Wan, Shuai; Gong, Yanchao; Feng, Yan] Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Yang, KF (corresponding author), Northwestern Polytech Univ, Sch Elect & Informat, Xian 710072, Peoples R China.
EM yangkaifang5@hotmail.com
RI Wan, Shuai/AAA-8777-2022
OI Wan, Shuai/0000-0001-8617-149X
FU National Science Foundation of China [60902052, 60902081]; Northwestern
   Polytechnical University [z2012093]
FX This work was supported by the National Science Foundation of China
   (60902052, 60902081) and the graduate starting seed fund of Northwestern
   Polytechnical University (z2012093).
CR Amonou I, 2007, IEEE T CIRC SYST VID, V17, P1186, DOI 10.1109/TCSVT.2007.906870
   Görkemli B, 2010, IEEE IMAGE PROC, P4201, DOI 10.1109/ICIP.2010.5650771
   Gupta R, 2012, IEEE T BROADCAST, V58, P428, DOI 10.1109/TBC.2012.2191702
   JVT, 2011, H 264 SVC REF SOFTW
   Lee D, 2008, CONF REC ASILOMAR C, P2233, DOI 10.1109/ACSSC.2008.5074833
   Li XA, 2011, IEEE T BROADCAST, V57, P66, DOI 10.1109/TBC.2010.2082370
   Liu JY, 2009, IEEE IMAGE PROC, P3737, DOI 10.1109/ICIP.2009.5414439
   Maani E, 2009, IEEE T IMAGE PROCESS, V18, P2022, DOI 10.1109/TIP.2009.2023152
   Mansour H, 2011, IEEE T MULTIMEDIA, V13, P165, DOI 10.1109/TMM.2010.2099648
   Peng WH, 2008, J VIS COMMUN IMAGE R, V19, P543, DOI 10.1016/j.jvcir.2008.08.002
   Ponec M, 2009, IEEE INT CON MULTI, P1406, DOI 10.1109/ICME.2009.5202767
   Pulipaka A., 2010, CONSUMER COMMUNICATI, P1
   Schwarz H., 2004, 1SC29WG11M11043 ISOI
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Wan S., 2012, INT J CONCUR COMPUT, V24, P1123
   Ying-Hong Wang, 2009, 2009 Symposia and Workshops on Ubiquitous, Autonomic and Trusted Computing in conjunction with the UIC 2009 and ATC 2009 Conferences, P1, DOI [10.1109/ICBBE.2009.5163482, 10.1109/UIC-ATC.2009.19]
   Wiegand T, 2009, IEEE T BROADCAST, V55, P527, DOI 10.1109/TBC.2009.2020954
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
NR 18
TC 2
Z9 2
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 752
EP 759
DI 10.1016/j.jvcir.2013.04.013
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700002
DA 2024-07-18
ER

PT J
AU Zhang, LL
   Koch, R
AF Zhang, Lilian
   Koch, Reinhard
TI An efficient and robust line segment matching approach based on LBD
   descriptor and pairwise geometric consistency
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Line segment matching; Multi-scale line detection; Line band descriptor;
   Unary geometric attribute; Pairwise geometric consistency; Relational
   graph; Graph matching; Spectral method
ID VIEWS
AB We present a line matching algorithm which utilizes both the local appearance of lines and their geometric attributes. To overcome the problem of segment fragmentation and geometric variation, we extract lines in the scale space. To depict the local appearance of lines, we design a novel line descriptor called Line Band Descriptor (LBD). To evaluate the pairwise geometric consistency, we define the pairwise geometric attributes between line pairs. Then we built a relational graph for candidate line matches and employ a spectral technique to solve this matching problem efficiently. The advantages of the proposed algorithm are as follows: (1) it is robust to image transformations because of the multi-scale line detection strategy; (2) it is efficient because the designed LBD descriptor is fast to compute and the appearance similarities reduce the dimension of the graph matching problem; (3) it is accurate even for low-texture images because of the pairwise geometric consistency evaluation. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhang, Lilian; Koch, Reinhard] Univ Kiel, Inst Comp Sci, D-24098 Kiel, Germany.
C3 University of Kiel
RP Zhang, LL (corresponding author), Univ Kiel, Inst Comp Sci, D-24098 Kiel, Germany.
EM lz@mip.informatik.uni-kiel.de; rk@mip.informati-k.uni-kiel.de
OI Koch, Reinhard/0000-0003-4398-1569
FU China Scholarship Council [2009611008]
FX This work was supported by China Scholarship Council (No. 2009611008).
   The authors thank the anonymous reviewers for their valuable comments
   that helped to improve the paper.
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Amaury Negre J.L.C., 2008, ISER
   [Anonymous], IJCV
   [Anonymous], BMVC
   [Anonymous], 2010, ECCV
   AYACHE N, 1987, INT J COMPUT VISION, V1, P107, DOI 10.1007/BF00123161
   Bay H, 2005, PROC CVPR IEEE, P329
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chandraker M, 2009, IEEE I CONF COMP VIS, P1741, DOI 10.1109/ICCV.2009.5459390
   Chmielewski LJ, 2005, ADV SOFT COMP, P363
   CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565
   David P, 2005, IEEE I CONF COMP VIS, P1581
   DERICHE R, 1990, IMAGE VISION COMPUT, V8, P261, DOI 10.1016/0262-8856(90)80002-B
   Ethan Rublee K.K., 2011, ICCV
   Fan B, 2010, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2010.5540186
   HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855
   Hyunwoo Kim, 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P1157, DOI 10.1109/IROS.2010.5650309
   Lehoucq R., 2011, ARPACK SOFTWARE
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Lilian Zhang, 2012, Pattern Recognition. Proceedings Joint 34th DAGM and 36th OAGM Symposium, P236, DOI 10.1007/978-3-642-32717-9_24
   Lourakis MIA, 2000, IMAGE VISION COMPUT, V18, P673, DOI 10.1016/S0262-8856(99)00071-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MELTZER J., 2008, IEEE C COMP VISION P, P1
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Neubert P, 2008, IEEE INT C EMERG, P353, DOI 10.1109/ETFA.2008.4638418
   Schmid C, 1997, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1997.609397
   Stefan Leutenegger M.C., 2011, ICCV
   Taylor C.J., 1992, PAMI, V17, P1021
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Wang L, 2009, IEEE I CONF COMP VIS, P1311, DOI 10.1109/ICCV.2009.5459316
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251
   Woo DM, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL III, PROCEEDINGS, P99, DOI 10.1109/AICI.2009.287
NR 33
TC 324
Z9 393
U1 13
U2 124
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2013
VL 24
IS 7
BP 794
EP 805
DI 10.1016/j.jvcir.2013.05.006
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 223YP
UT WOS:000324848700006
DA 2024-07-18
ER

PT J
AU Ali, IA
   Moiron, S
   Fleury, M
   Ghanbari, M
AF Ali, I. A.
   Moiron, S.
   Fleury, M.
   Ghanbari, M.
TI Packet prioritization for H.264/AVC video with cyclic intra-refresh line
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data prioritization; Error propagation; Error resilience; H.264/AVC; HD
   video; IEEE 802.11e; Intra-refresh; Mobile network; Video streaming
ID TRANSMISSION
AB Insertion of a cyclic intra-refresh line is a lightweight way of mitigating spatio-temporal error propagation in a video stream transmitted over a mobile network. This paper presents low-complexity yet effective prioritization based on slice position within a video frame relative to the cyclic refresh line. Two prioritization schemes are compared. The first is a region-based method, while the second, which is packet-based, improves packet classification. Experimental results indicate that, the packet-based scheme can achieve video quality gains of up to 4 dB, compared to when the scheme is not used. The proposed schemes require no decoder modifications and do not introduce an increase in bitrate or in computational complexity. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Ali, I. A.; Moiron, S.; Fleury, M.; Ghanbari, M.] Univ Essex, Sch CSEE, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Fleury, M (corresponding author), Univ Essex, Sch CSEE, Colchester CO4 3SQ, Essex, England.
EM fleum@essex.ac.uk
RI Ghanbari, Mohammad/L-4053-2019; Ali, Ismail/AAH-9593-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378; Ali, Ismail/0000-0001-6684-2399
CR Ali IA, 2010, IEEE IMAGE PROC, P2901, DOI 10.1109/ICIP.2010.5652683
   ALJOBOURI L, 2012, ADV MULTIMEDIA, P11
   Altaf M., 2011, INT J MOBILE MULTIME, V7, P216
   [Anonymous], 2005, 3984 RFC IETF
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   BACCICHET P, 2006, J ZHEJIANG UNIV-SC A, V7, P900
   Bononi L, 2009, IEEE ICC, P148
   Chiou HJ, 2005, J VIS COMMUN IMAGE R, V16, P563, DOI 10.1016/j.jvcir.2004.11.009
   Côté G, 1999, SIGNAL PROCESS-IMAGE, V15, P25, DOI 10.1016/S0923-5965(99)00022-3
   Hannuksela MM, 2004, IEEE T MULTIMEDIA, V6, P259, DOI 10.1109/TMM.2003.822784
   Haskell P., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P545, DOI 10.1109/ICASSP.1992.226155
   Im SK, 2007, IET IMAGE PROCESS, V1, P197, DOI 10.1049/iet-ipr:20060262
   Jiang J, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS, P242, DOI 10.1109/ISDA.2008.119
   Krause E., 1991, U.S. Patent, Patent No. [5,057,916, 5057916]
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Lambert P, 2006, J VIS COMMUN IMAGE R, V17, P358, DOI 10.1016/j.jvcir.2005.05.008
   LIU L, 2006, J JHEJIANG U SCI S, V6, P41
   Liu YP, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P207, DOI 10.1109/IASP.2009.5054635
   Ma HJ, 2009, J ZHEJIANG UNIV-SC A, V10, P1169, DOI 10.1631/jzus.A0820660
   Moiron S., 2010, INT C WIR ADV, P1, DOI DOI 10.1109/WIAD.2010.5544868
   Nunes P, 2009, IEEE IMAGE PROC, P3073, DOI 10.1109/ICIP.2009.5414493
   Rao AV, 2010, 23RD INTERNATIONAL CONFERENCE ON VLSI DESIGN, P458, DOI 10.1109/VLSI.Design.2010.72
   Rappaport T.S., 2003, WIRELESS COMMUNICATI, V2nd
   Schreier RM, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2053, DOI 10.1109/ICME.2006.262618
   Schreier RM, 2006, IEEE T CONSUM ELECTR, V52, P249
   Stockhammer T., 2007, MULTIMEDIA IP WIRELE, P13, DOI DOI 10.1016/B978-012088480-3/50003-5
   Su JL, 2006, I C CONT AUTOMAT ROB, P1
   Varsa V., 2001, 14 M ITU T VCEG
   Wang JT, 1999, IEEE T CIRC SYST VID, V9, P513, DOI 10.1109/76.754780
   Wang QJ, 2010, IEEE INT CON MULTI, P452, DOI 10.1109/ICME.2010.5583074
   WANG X, 2005, 6 IET INT C 3G, P1
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xu J, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P693, DOI 10.1109/ICME.2006.262540
NR 34
TC 5
Z9 5
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 486
EP 498
DI 10.1016/j.jvcir.2013.03.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400006
DA 2024-07-18
ER

PT J
AU Nguyen, TNA
   Cai, JF
   Zheng, JM
   Li, JG
AF Thi Nhat Anh Nguyen
   Cai, Jianfei
   Zheng, Jianmin
   Li, Jianguo
TI Interactive object segmentation from multi-view images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive image segmentation; Multi-view image segmentation; Image
   co-segmentation; Image segmentation; 3D graph-cut; Active contour;
   Object cutout; Joint 3D and 2D segmentation
AB Despite the great progress on interactive image segmentation, image co-segmentation, 2D and 3D segmentation, there is still no workable solution to the problem: given a set of calibrated or un-calibrated multi-view images (say, more than 40 images), by interactively cutting 3 similar to 4 images, can the foreground object of the rest images be quickly cutout automatically and accurately? In this paper, we propose a non-trivial engineering solution to this problem. Our basic idea is to integrate 3D segmentation with 2D segmentation so as to combine their advantages. Our proposed system iteratively performs 2D and 3D segmentation, where the 3D segmentation results are used to initialize 2D segmentation and ensure the silhouette consistency among different views and the 2D segmentation results are used to provide more accurate cues for the 3D segmentation. The experimental results show that the proposed system is able to generate highly accurate segmentation results, even for some challenging real-world multi-view image sequences, with a small amount of user input. (c) 2013 Elsevier Inc. All rights reserved.
C1 [Thi Nhat Anh Nguyen] Danang Univ Technol, Da Nang City, Vietnam.
   [Cai, Jianfei; Zheng, Jianmin] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 University of Danang; Nanyang Technological University
RP Cai, JF (corresponding author), Danang Univ Technol, Da Nang City, Vietnam.
EM ngt.nhatanh@gmail.com; asjfcai@ntu.edu.sg; asjmzheng@ntu.edu.sg;
   jianguo.li@intel.com
RI Zheng, Jianmin/A-3717-2011; Cai, Jianfei/A-3691-2011
OI Zheng, Jianmin/0000-0002-5062-6226; Nguyen, Thi Nhat
   Anh/0000-0003-1117-4770; Cai, Jianfei/0000-0002-9444-3763
CR [Anonymous], 2011, CVPR
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Campbell NDF, 2010, IMAGE VISION COMPUT, V28, P14, DOI 10.1016/j.imavis.2008.09.005
   Cui J., 2008, CVPR
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Li JG, 2010, PROC CVPR IEEE, P2769, DOI 10.1109/CVPR.2010.5540004
   Lu J. B., 2011, ACM MULTIMEDIA, P1309
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Nguyen TNA, 2012, IEEE T IMAGE PROCESS, V21, P3734, DOI 10.1109/TIP.2012.2191566
   Xiao J., 2007, ICCV, P43
   Yang WX, 2010, IEEE T IMAGE PROCESS, V19, P2470, DOI 10.1109/TIP.2010.2048611
NR 19
TC 2
Z9 4
U1 3
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2013
VL 24
IS 4
BP 477
EP 485
DI 10.1016/j.jvcir.2013.02.012
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 137VN
UT WOS:000318466400005
DA 2024-07-18
ER

PT J
AU Chen, F
   Hu, R
   Yu, HM
   Wang, SY
AF Chen, Fei
   Hu, Roland
   Yu, Huimin
   Wang, Shiyan
TI Reduced set density estimator for object segmentation based on shape
   probabilistic representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Principal components analysis; Shape priors; Probabilistic method;
   Segmentation; Reduced set density estimator; Variational methods; Level
   sets; Shape representation
ID ACTIVE CONTOURS; VARIATIONAL SEGMENTATION; IMAGE SEGMENTATION; KERNEL
   SPACE; PRIORS; MODEL; MINIMIZATION
AB In this paper, a nonparametric statistical shape model based on shape probabilistic representation is proposed for object segmentation. Given a set of training shapes, Cremers et al.'s probabilistic method is adopted to represent the shape, and then principal components analysis (PCA) on shape probabilistic representation is computed to capture the variation of the training shapes. To encode complex shape variation in training set, reduced set density estimator is used to model nonlinear shape distributions in a finite-dimensional subspace. This statistical shape prior is integrated to convex segmentation functional to guide the evolving contour to the object of interest. In addition, in contrast to the commonly used signed distance functions. PCA on shape probabilistic representation needs less number of eigenmodes to capture certain details of the training shapes. Numerical experiments show promising results and the potential of the model for object segmentation. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Yu, Huimin] Zhejiang Univ, Dept Informat Sci & Elect Engn, Inst Informat & Commun Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Yu, Huimin] State Key Lab CAD & CG, Hangzhou 310027, Zhejiang, Peoples R China.
   [Chen, Fei] Jimei Univ, Sch Sci, Xiamen 367021, Peoples R China.
C3 Zhejiang University; Jimei University
RP Yu, HM (corresponding author), Zhejiang Univ, Dept Informat Sci & Elect Engn, Inst Informat & Commun Engn, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM chenfei314@zju.edu.cn; haoji_hu@zju.edu.cn; yhm2005@zju.edu.cn;
   wangshiyan@zju.edu.cn
OI Chen, Fei/0000-0002-3676-6011
FU National Key Basic Research Project of China (973 Program)
   [2012CB316400]; NSFC [60872069]
FX This work was supported by a National Key Basic Research Project of
   China (973 Program No. 2012CB316400) and NSFC (No. 60872069).
CR [Anonymous], 2002, SURFACES
   [Anonymous], IEEE INT C COMP VIS
   Ben-Ari R, 2008, LECT NOTES COMPUT SC, V5259, P494, DOI 10.1007/978-3-540-88458-3_45
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan T, 2005, PROC CVPR IEEE, P1164
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2006, INT J COMPUT VISION, V66, P67, DOI 10.1007/s11263-005-3676-z
   Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388
   Cremers D, 2003, PATTERN RECOGN, V36, P1929, DOI 10.1016/S0031-3203(03)00056-6
   Cremers D., 2008, IEEE INT C COMP VIS
   Cremers D, 2008, J SCI COMPUT, V35, P132, DOI 10.1007/s10915-008-9220-x
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161
   Dambreville S, 2008, IEEE T PATTERN ANAL, V30, P1385, DOI 10.1109/TPAMI.2007.70774
   Fundana K, 2008, INT J COMPUT VISION, V80, P289, DOI 10.1007/s11263-008-0160-6
   Girolami M, 2003, IEEE T PATTERN ANAL, V25, P1253, DOI 10.1109/TPAMI.2003.1233899
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kim J, 2010, IEEE T PATTERN ANAL, V32, P1822, DOI 10.1109/TPAMI.2009.188
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni K, 2009, INT J COMPUT VISION, V84, P97, DOI 10.1007/s11263-009-0234-0
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Popovic A, 2007, INT J COMPUT ASS RAD, V2, P169, DOI 10.1007/s11548-007-0125-1
   Rousson M, 2005, LECT NOTES COMPUT SC, V3750, P757, DOI 10.1007/11566489_93
   Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209
   Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Tsai A, 2001, PROC CVPR IEEE, P463
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
NR 35
TC 6
Z9 7
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1085
EP 1094
DI 10.1016/j.jvcir.2012.07.006
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900012
DA 2024-07-18
ER

PT J
AU Ejaz, N
   Bin Tariq, T
   Baik, SW
AF Ejaz, Naveed
   Bin Tariq, Tayyab
   Baik, Sung Wook
TI Adaptive key frame extraction for video summarization using an
   aggregation mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Key frame extraction; Video summarization; Video abstraction; Static
   video summary; Storyboard; Video analysis; Evaluation of video summary;
   Feature aggregation
AB Video summarization is a method to reduce redundancy and generate succinct representation of the video data. One of the mechanisms to generate video summaries is to extract key frames which represent the most important content of the video. In this paper, a new technique for key frame extraction is presented. The scheme uses an aggregation mechanism to combine the visual features extracted from the correlation of RGB color channels, color histogram, and moments of inertia to extract key frames from the video. An adaptive formula is then used to combine the results of the current iteration with those from the previous. The use of the adaptive formula generates a smooth output function and also reduces redundancy. The results are compared to some of the other techniques based on objective criteria. The experimental results show that the proposed technique generates summaries that are closer to the summaries created by humans. (C) 2012 Elsevier Inc. All rights reserved.
C1 [Ejaz, Naveed; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
   [Bin Tariq, Tayyab] Natl Univ Comp & Emerging Sci, Islamabad, Pakistan.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM naveed@sju.ac.kr; tayyab.tariq@nu.edu.pk; sbaik@sejong.ac.kr
RI Ejaz, Naveed/I-2891-2012; Baik, Sung Wook/AAR-8236-2020; Ejaz,
   Naveed/HZJ-6101-2023; Ejaz, Naveed/HZL-7415-2023
OI Ejaz, Naveed/0000-0003-1295-4787; Ejaz, Naveed/0000-0003-1295-4787;
   Baik, Sung Wook/0000-0002-6678-7788
FU Industrial Strategic Technology Development Program [10041772]; Ministry
   of Knowledge Economy (MKE, Korea)
FX This work was supported by the Industrial Strategic Technology
   Development Program (10041772, the Development of an Adaptive
   Mixed-Reality Space based on Interactive Architecture) funded by the
   Ministry of Knowledge Economy (MKE, Korea).
CR Calic J, 2004, P WORKSH IM AN MULT
   Chen F, 2011, IEEE T MULTIMEDIA, V13, P1381, DOI 10.1109/TMM.2011.2166379
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   Doulamis ND, 2000, IEEE T CIRC SYST VID, V10, P501, DOI 10.1109/76.844996
   Ejaz N., 2012, INT J INNOVATIVE COM, V8
   Ejaz N., 2011, Int J Phys Sci, V6, P3377
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   de Avila SEF, 2011, PATTERN RECOGN LETT, V32, P56, DOI 10.1016/j.patrec.2010.08.004
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gianluigi C, 2006, J REAL-TIME IMAGE PR, V1, P69, DOI 10.1007/s11554-006-0001-1
   Guironnet M, 2007, EURASIP J IMAGE VIDE, DOI 10.1155/2007/60245
   HANJALIC A, 1998, IMAGE DATABASES MULT
   Hanjalic R, 1996, 1 INT WORKSH IM DAT, P67
   Hoon SH, 2000, 12 WORKSH IM PROC IM, P217
   Jiang RM, 2009, STUD COMPUT INTELL, V231, P27
   Kim HH, 2010, J AM SOC INF SCI TEC, V61, P927, DOI 10.1002/asi.21317
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Y., 2001, HP2001191
   Liu TY, 2004, PATTERN RECOGN LETT, V25, P1451, DOI 10.1016/j.patrec.2004.05.020
   Luo JB, 2009, IEEE T CIRC SYST VID, V19, P289, DOI 10.1109/TCSVT.2008.2009241
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   PAL SK, 1995, J INTELL FUZZY SYST, V3, P247
   Smeaton AF, 2007, INFORM SYST, V32, P545, DOI 10.1016/j.is.2006.09.001
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vattani A, 2009, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY (SCG'09), P324, DOI 10.1145/1542362.1542419
   Venetianer PL, 2010, COMPUT VIS IMAGE UND, V114, P1292, DOI 10.1016/j.cviu.2010.07.010
   Yeung MM, 1997, IEEE T CIRC SYST VID, V7, P771, DOI 10.1109/76.633496
   Zhang XD, 2003, PATTERN RECOGN LETT, V24, P1523, DOI 10.1016/S0167-8655(02)00391-4
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 31
TC 113
Z9 124
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2012
VL 23
IS 7
BP 1031
EP 1040
DI 10.1016/j.jvcir.2012.06.013
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 012PB
UT WOS:000309247900007
DA 2024-07-18
ER

PT J
AU Herman, GT
   Kong, TY
   Oliveira, LM
AF Herman, Gabor T.
   Kong, T. Yung
   Oliveira, Lucas M.
TI Tree representation of digital picture embeddings
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Tree representation; Digital picture; Embedding; Component tree image
   representation; Digital picture embeddings; Tree embeddings; Structural
   biology; Digital space; Connectedly embedded
ID MAPS
AB It is often the case that the same object is imaged in different ways, resulting in digital pictures of (some parts of) it at different resolutions. This leads to the combinatorial problem of "embedding" one of these pictures into the other in a way that corresponds to physical truth. In this paper we present a mathematical formulation of this intuitive concept of embedding. We also show, using a tree representation of digital pictures, how picture embedding relates to tree embedding, which has been a subject of much study in combinatorial computer science (mostly for reasons other than application to digital pictures). (C) 2012 Elsevier Inc. All rights reserved.
C1 [Herman, Gabor T.; Oliveira, Lucas M.] CUNY, Grad Ctr, Comp Sci PhD Program, New York, NY 10016 USA.
   [Kong, T. Yung] CUNY Queens Coll, Dept Comp Sci, Flushing, NY 11367 USA.
C3 City University of New York (CUNY) System; City University of New York
   (CUNY) System; Queens College NY (CUNY)
RP Herman, GT (corresponding author), CUNY, Grad Ctr, Comp Sci PhD Program, 365 5th Ave, New York, NY 10016 USA.
EM gabortherman@yahoo.com; ykong@cs.qc.cu-ny.edu; lmoliveira@gmail.com
FU National Science Foundation [DMS-1114901]; Direct For Mathematical &
   Physical Scien; Division Of Mathematical Sciences [1114901] Funding
   Source: National Science Foundation
FX This research is supported by award DMS-1114901 from the National
   Science Foundation.
CR Belnap DM, 1999, J STRUCT BIOL, V125, P166, DOI 10.1006/jsbi.1999.4093
   Carr H, 2003, COMP GEOM-THEOR APPL, V24, P75, DOI 10.1016/S0925-7721(02)00093-7
   Chi Y, 2005, FUND INFORM, V66, P161
   Edelsbrunner H., 2010, AM MATH SOC, DOI DOI 10.1007/978-3-540-33259-6_7
   GUPTA A, 1995, J ALGORITHM, V18, P176, DOI 10.1006/jagm.1995.1006
   Herman G.T., 2012, DIGITAL GEOMETRY ALG
   Herman GT., 1998, Geometry of digital spaces
   Jolley CC, 2008, BIOPHYS J, V94, P1613, DOI 10.1529/biophysj.107.115949
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Najman L, 2006, IEEE T IMAGE PROCESS, V15, P3531, DOI 10.1109/TIP.2006.877518
   Sarioz D, 2006, LECT NOTES COMPUT SC, V4291, P263
   Wriggers W, 1999, J STRUCT BIOL, V125, P185, DOI 10.1006/jsbi.1998.4080
   Zaki M.J., 2005, Fundamenta Informaticae, V65, P1
NR 13
TC 3
Z9 4
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 883
EP 891
DI 10.1016/j.jvcir.2012.05.007
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900006
DA 2024-07-18
ER

PT J
AU Wu, JJ
   Qi, F
   Shi, GM
AF Wu, Jinjian
   Qi, Fei
   Shi, Guangming
TI Self-similarity based structural regularity for just noticeable
   difference estimation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Just noticeable difference (JND); Spatial masking; Self-similarity;
   Non-local; Structural regularity; Entropy; Human visual system (HVS);
   Visual perception
ID IMAGE QUALITY ASSESSMENT; VISIBILITY; QUANTIZATION
AB In this paper, we introduce a novel just noticeable difference (JND) threshold estimation model based on a spatial masking function taking both luminance difference and structural regularity into account. Existing spatial masking functions underestimate the JND threshold for irregular textural regions, because they mainly consider the amplitude of luminance change for simplicity. As regular areas show weak masking effect due to their self-similar structures while irregular regions present strong masking effect, the spatial structure directly determines spatial masking. To effectively measure structural regularity in images under different contents, we propose an adaptive non-local self-similarity analysis based procedure. Then we weight luminance differences with similarity coefficients and deduce a new spatial masking function. Finally, an accurate JND estimation model is introduced. Experimental results demonstrate that the proposed JND model has a better visual effect than other models: it injects much noise into the insensitive regions, whereas little into the sensitive regions. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Wu, Jinjian; Qi, Fei; Shi, Guangming] Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Shi, GM (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Shaanxi, Peoples R China.
EM jinjian.wu@mail.xidian.edu.cn; fred.qi@ieee.org; gmshi@xidian.edu.cn
RI Wu, Jinjian/GQH-0222-2022; Qi, Fei/G-3978-2013
OI Qi, Fei/0000-0002-2161-1551
FU National Natural Science Foundation of China [60805012, 61033004,
   61070138]; RFDP [20090203110003]
FX This work is supported by National Natural Science Foundation of China
   under Grant Nos. 60805012, 61033004, and 61070138, and by RFDP under
   Grant No. 20090203110003.
CR Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Chiu YJ, 1999, IEEE T CIRC SYST VID, V9, P438, DOI 10.1109/76.754773
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Colleu T, 2010, J VIS COMMUN IMAGE R, V21, P561, DOI 10.1016/j.jvcir.2010.01.003
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Doré V, 2009, IEEE T SIGNAL PROCES, V57, P1703, DOI 10.1109/TSP.2008.2011832
   Eckert MP, 1998, SIGNAL PROCESS, V70, P177, DOI 10.1016/S0165-1684(98)00124-8
   Höntsch I, 2002, IEEE T IMAGE PROCESS, V11, P213, DOI 10.1109/83.988955
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2010, IEEE IMAGE PROC, P317, DOI 10.1109/ICIP.2010.5653355
   Macknik SL, 1998, NAT NEUROSCI, V1, P144, DOI 10.1038/393
   NETRAVALI AN, 1977, P IEEE, V65, P536, DOI 10.1109/PROC.1977.10515
   Niu YQ, 2010, IEEE INT CON MULTI, P1679, DOI 10.1109/ICME.2010.5583164
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu JJ, 2010, INT CONF ACOUST SPEE, P2454, DOI 10.1109/ICASSP.2010.5496302
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
   Zhang XH, 2008, J VIS COMMUN IMAGE R, V19, P30, DOI 10.1016/j.jvcir.2007.06.001
NR 24
TC 20
Z9 26
U1 0
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2012
VL 23
IS 6
BP 845
EP 852
DI 10.1016/j.jvcir.2012.04.010
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 983QX
UT WOS:000307134900002
DA 2024-07-18
ER

PT J
AU Hu, WC
   Jhu, JJ
   Lin, CP
AF Hu, Wu-Chih
   Jhu, Jia-Jie
   Lin, Cheng-Pin
TI Unsupervised and reliable image matting based on modified spectral
   matting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image matting; Spectral matting; Alpha Matte; Matting Laplacian;
   Component classification; Component palette; Image composition;
   Consistency of color temperature
AB Spectral matting is the state-of-the-art image matting and also a milestone in theoretic matting research. For spectral matting without user intervention, the accuracy of alpha matte is low and the computational cost is high. Therefore, this paper presents a modified version of spectral matting to greatly increase the accuracy of alpha matte and effectively reduce the computational cost. In the proposed modified spectral matting, palette-based component classification is used to obtain reliable foreground and background components. Next, the corresponding matting components are obtained via a linear transformation of the smallest eigenvectors of the matting Laplacian matrix. Finally, the matting components of the foreground and the unknown regions are combined to from the complete alpha matte based on minimizing the matte cost. Moreover, image composition with consistency of color temperature is used to obtain the realistic image composition. Experimental results show that the proposed method outperforms the state-of-the-art methods based on spectral matting. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Hu, Wu-Chih; Jhu, Jia-Jie; Lin, Cheng-Pin] Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, Makung 880, Penghu, Taiwan.
C3 National Penghu University of Science & Technology
RP Hu, WC (corresponding author), Natl Penghu Univ Sci & Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd, Makung 880, Penghu, Taiwan.
EM wchu@npu.edu.tw; d1095405044@npu.edu.tw; d1095405020@npu.edu.tw
FU National Science Council, Taiwan [NSC99-2221-E-346-007]
FX This paper was supported by the National Science Council, Taiwan, under
   Grant No. NSC99-2221-E-346-007. The authors also gratefully acknowledge
   the helpful comments and suggestions of the reviewers, which have
   improved the presentation.
CR [Anonymous], J INFORM HIDING MULT
   Chen Y.-H., 2008, P 21 C COMP VIS GRAP
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Dennis JE., 1996, NUMERICAL METHODS UN
   Guan Y, 2006, COMPUT GRAPH FORUM, V25, P567, DOI 10.1111/j.1467-8659.2006.00976.x
   Gupta A, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P336, DOI 10.1109/ICCSIT.2009.5234624
   Hsieh C.-J., 2005, THESIS NATL DONG HWA
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jou FD, 2004, PATTERN RECOGN LETT, V25, P277, DOI 10.1016/j.patrec.2003.10.005
   Lam H.-K., 2004, P IEEE INT C AC SPEE, V3, P493
   Lee SY, 2010, GRAPH MODELS, V72, P25, DOI 10.1016/j.gmod.2010.03.001
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li Zhengjun, 2008, Microcomputer Information, P246
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Porter T., 1984, Proceedings of the 11th annual conference on Computer graphics and interactive techniques, P253, DOI 10.1145/800031.808606
   Reinhard E., 2005, Proceedings of Applied Perception in Graphics and Visualization (APGV 2005), P95
   SAYOUD H, 2010, J INFORM HIDING MULT, V1, P344
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954
   Sural S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P589
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Wang J.-Z., 2010, ADV WIRELESS NETWORK, V72, P119
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
NR 28
TC 7
Z9 9
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 665
EP 676
DI 10.1016/j.jvcir.2012.03.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500008
DA 2024-07-18
ER

PT J
AU Samet, R
   Hancer, E
AF Samet, Refik
   Hancer, Emrah
TI A new approach to the reconstruction of contour lines extracted from
   topographic maps
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Topographic maps; Contour lines; Gaps and end points; Reconstruction;
   Geometric properties; Feature extraction; Geophysical image processing;
   Cartography
AB It is known that after segmentation and morphological operations on topographic maps, gaps occur in contour lines. It is also well known that filling these gaps and reconstruction of contour lines with high accuracy is not an easy problem. In this paper, a nontrivial semi-automatic approach to solve this problem is proposed. The main idea of the proposed approach is based on local and geometric properties such as (1) parabolic and opposite directions, (2) the differences of y-ordinate of end points, (3) changing the directions of x-axis and y-ordinate to the nearest clockwise direction and (4) avoiding the use of the second end point of a small piece of any contour line in the same mask if its other end point is used. The proposed approach was implemented on the base of many topographic maps with different resolutions and complexity. The obtained results show that the proposed approach increases accuracy and performance. (c) 2012 Elsevier Inc. All rights reserved.
C1 [Samet, Refik] Ankara Univ, Dept Comp Engn, TR-06501 Ankara, Turkey.
   [Hancer, Emrah] Erciyes Univ, Dept Comp Engn, TR-38039 Kayseri, Turkey.
C3 Ankara University; Erciyes University
RP Samet, R (corresponding author), Ankara Univ, Dept Comp Engn, TR-06501 Ankara, Turkey.
EM samet@eng.ankara.edu.tr; emrahhancer@erciyes.edu.tr
RI HANCER, Emrah/JWP-8724-2024; Samet, Refik/AAG-4597-2019
OI HANCER, Emrah/0000-0002-3213-5191; Samet, Refik/0000-0001-8720-6834
CR Amenta N, 1998, GRAPH MODEL IM PROC, V60, P125, DOI 10.1006/gmip.1998.0465
   [Anonymous], 1997, ALGORITHMS IMAGE PRO
   ARRIGHI P, 1999, P GEOV 99
   Ghircoias T., 2011, UBIQUITOUS COMPUT CO, V6
   Giesen D.P.J., 2000, THESIS SWISS FEDERAL
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Heath Michael T, 2018, Scientific Computing: An Introductory Survey
   Ismail N. Isrozaidi Nik, 2006, THESIS U TEKNOLOGI M
   Khotanzad A, 2003, IEEE T PATTERN ANAL, V25, P18, DOI 10.1109/TPAMI.2003.1159943
   Pouderoux J., P 9 INT C DOC AN REC, V2, P779
   Samet R, 2010, APPL COMPUT MATH-BAK, V9, P116
   Samet R, 2008, APPL COMPUT MATH-BAK, V7, P242
   San L. Mun, INT C CGIV 2004
   Soille P., 1991, Journal of Visual Communication and Image Representation, V2, P138, DOI 10.1016/1047-3203(91)90004-Y
   Spinello S, 2004, J WSCG, V12, P1
   Wu R.-Q., 2009, JCS T, V9
   Xin D., 2006, J INFORM COMPUTING S, V1, P275
NR 17
TC 25
Z9 30
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2012
VL 23
IS 4
BP 642
EP 647
DI 10.1016/j.jvcir.2012.02.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 940NO
UT WOS:000303900500006
DA 2024-07-18
ER

PT J
AU Li, WH
   Li, QL
   Gong, WG
   Tang, S
AF Li, Weihong
   Li, Quanli
   Gong, Weiguo
   Tang, Shu
TI Total variation blind deconvolution employing split Bregman iteration
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image processing; Blind deconvolution; Split Bregman; Total variation;
   Deblurring; Euler-Lagrange equation; Iteration scheme; Point spread
   function
ID IMAGE-RESTORATION; REGULARIZATION
AB Blind image deconvolution is one of the most challenging problems in image processing. The total variation (TV) regularization approach can effectively recover edges of image. In this paper, we propose a new TV blind deconvolution algorithm by employing split Bregman iteration (called as TV-BDSB). Considering the operator splitting and penalty techniques, we present also a new splitting objective function. Then, we propose an extended split Bregman iteration to address the minimizing problems, the latent image and the blur kernel are estimated alternately. The TV-BDSB algorithm can greatly reduce the computational cost and improve remarkably the image quality. Experiments are conducted on both synthetic and real-life degradations. Comparisons are also made with some existing blind deconvolution methods. Experimental results indicate the advantages of the proposed algorithm. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Li, Weihong; Li, Quanli; Gong, Weiguo; Tang, Shu] Chongqing Univ, Educ Minist, Key Lab Optoelect Technol & Syst, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Li, WH (corresponding author), Chongqing Univ, Educ Minist, Key Lab Optoelect Technol & Syst, Chongqing 400044, Peoples R China.
EM weihongli@cqu.edu.cn; quanli2009@cqu.edu.cn
FU Ministry of Public Security of the People's Republic of China
   [2010YYCXCQSJ074]; Natural Science Foundation of Chongqing Municipality
   of China [CSTC2009AB0175, CSTC2010BB2230]; Fundamental Research Funds
   for the Central Universities [CDJXS11122221, CDJXS11122216]
FX The authors would like to thank all reviewers for their valuable
   comments. This research was supported by the Application Innovation
   Project of the Ministry of Public Security of the People's Republic of
   China (2010YYCXCQSJ074), the Key Research Project of the Natural Science
   Foundation of Chongqing Municipality of China (CSTC2009AB0175,
   CSTC2010BB2230), and the Fundamental Research Funds for the Central
   Universities (CDJXS11122221, CDJXS11122216).
CR [Anonymous], TR0918 NANJ U
   AYERS GR, 1988, OPT LETT, V13, P547, DOI 10.1364/OL.13.000547
   Babacan S.D., 2008, 16 EUR SIGN PROC C E, P25
   Bioucas-Dias J.M., 2009, 16 IEEE INT C IM PRO, P3717
   Cai JF, 2009, MULTISCALE MODEL SIM, V8, P337, DOI 10.1137/090753504
   Chan TF, 1999, SIAM J SCI COMPUT, V20, P1964, DOI 10.1137/S1064827596299767
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Darbon J., 2007, FAST DISCRETE OPTIMI
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hall P, 2007, STAT SINICA, V17, P1483
   He L, 2005, INT J IMAG SYST TECH, V15, P74, DOI 10.1002/ima.20040
   Joshi MV, 2005, J OPT SOC AM A, V22, P1066, DOI 10.1364/JOSAA.22.001066
   Kundur D, 1998, IEEE T SIGNAL PROCES, V46, P375, DOI 10.1109/78.655423
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Miskin J.W., 2000, Advances in Independent Component Analysis
   Molina R, 2006, IEEE T IMAGE PROCESS, V15, P3715, DOI 10.1109/TIP.2006.881972
   Money JH, 2008, IMAGE VISION COMPUT, V26, P302, DOI 10.1016/j.imavis.2007.06.005
   Oliveira JP, 2009, SIGNAL PROCESS, V89, P1683, DOI 10.1016/j.sigpro.2009.03.018
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Rudin L. I., 1994, Proceedings ICIP-94 (Cat. No.94CH35708), P31, DOI 10.1109/ICIP.1994.413269
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Setzer S., 2010, J VISUAL COMMUNICATI, V3, P193
   Shan Q., 2008, ACM T GRAPHICS, V27
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Wang Y., 2007, FAST ALGORITHM IMAGE
   You Y., 1996, IEEE INT C IM PROC L, V2, P461
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P416, DOI 10.1109/83.491316
NR 28
TC 68
Z9 79
U1 0
U2 46
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2012
VL 23
IS 3
BP 409
EP 417
DI 10.1016/j.jvcir.2011.12.003
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 917WH
UT WOS:000302208800001
DA 2024-07-18
ER

PT J
AU Singh, M
   Lu, C
   Basu, A
   Mandal, M
AF Singh, Meghna
   Lu, Cheng
   Basu, Anup
   Mandal, Mrinal
TI Choice of low resolution sample sets for efficient super-resolution
   signal reconstruction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Temporal registration; Recurrent non-uniform sampling; Confidence
   measure; Event dynamics; Super-resolution; Signal reconstruction;
   Iterative ranking; MR imaging
ID MRI
AB In applications such as super-resolution imaging and mosaicking, multiple video sequences are registered to reconstruct video with enhanced resolution. However, not all computed registration is reliable. In addition, not all sequences contribute useful information towards reconstruction from multiple non-uniformly distributed sample sets. In this paper we present two algorithms that can help determine which low resolution sample sets should be combined in order to maximize reconstruction accuracy while minimizing the number of sample sets. The first algorithm computes a confidence measure which is derived as a combination of two objective functions. The second algorithm is an iterative ranked-based method for reconstruction which uses confidence measures to assign priority to sample sets that maximize information gain while minimizing reconstruction error. Experimental results with real and synthetic sequences validate the effectiveness of the proposed algorithms. Application of our work in medical visualization and super-resolution reconstruction of MRI data are also presented. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Singh, Meghna; Lu, Cheng; Mandal, Mrinal] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
   [Basu, Anup] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2V4, Canada.
C3 University of Alberta; University of Alberta
RP Mandal, M (corresponding author), Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB T6G 2V4, Canada.
EM meghna@ualberta.ca; lcheng4@ualberta.ca; basu@ualberta.ca;
   mandal@ualberta.ca
RI Lu, Cheng/AAH-1606-2021
OI Lu, Cheng/0000-0002-7651-3924
CR Capel D, 2003, IEEE SIGNAL PROC MAG, V20, P75, DOI 10.1109/MSP.2003.1203211
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   Dietrich O, 2007, J MAGN RESON IMAGING, V26, P375, DOI 10.1002/jmri.20969
   Feichtinger HG, 2000, INT CONF ACOUST SPEE, P3834, DOI 10.1109/ICASSP.2000.860239
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Grammalidis N, 2000, IEEE T CIRC SYST VID, V10, P302, DOI 10.1109/76.825729
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hemmendorff M, 1999, INT CONF ACOUST SPEE, P3345, DOI 10.1109/ICASSP.1999.757558
   Hess R, 2007, PROC CVPR IEEE, P154
   IRANI M, 1992, IEEE             MAR, P216, DOI DOI 10.1109/CVPR.1992.223272
   Izquierdo E, 1997, IEEE T CIRC SYST VID, V7, P629, DOI 10.1109/76.611174
   JACKSON JI, 1991, IEEE T MED IMAGING, V10, P473, DOI 10.1109/42.97598
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346
   Listgarten J., 2005, Advances in Neural Information Processing Systems, V17, P817
   Lucas B. D., 1981, P IJCAI, P674
   Magarey J, 1996, INT CONF ACOUST SPEE, P2371, DOI 10.1109/ICASSP.1996.547759
   MARSAGLIA G, 1991, ANN APPL PROBAB, V3, P462
   Marvasti F., 2001, Nonuniform Sampling theory and Practice
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   MOREAU N, 1999, 6 EUR C SPEECH COMM
   MORTENSEN EN, 2001, IEEE COMP SOC C COMP, V1, P477, DOI DOI 10.1109/CVPR.2001.990513
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Singh M, 2008, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2008.4517853
   Singh M, 2007, LECT NOTES COMPUT SC, V4815, P608
   Singh M, 2007, IEEE T MULTIMEDIA, V9, P1004, DOI 10.1109/TMM.2007.898937
   Singh M, 2006, IEEE IMAGE PROC, P1169, DOI 10.1109/ICIP.2006.312765
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Strohmer T, 2007, INT CONF ACOUST SPEE, P881
   Thompson RB, 2002, MAGNET RESON MED, V47, P499, DOI 10.1002/mrm.10079
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   WANG R, 2000, IEEE INT S CIRC SYST, V5, P21, DOI DOI 10.1109/ISCAS.2000.857353
   Welch Greg., 2004, INTRO KALMAN FILTER
NR 35
TC 4
Z9 4
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2012
VL 23
IS 1
BP 194
EP 207
DI 10.1016/j.jvcir.2011.09.009
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 874QB
UT WOS:000298972100019
DA 2024-07-18
ER

PT J
AU Hu, HM
   Li, B
   Lin, WY
   Sun, MT
AF Hu, Hai-Miao
   Li, Bo
   Lin, Weiyao
   Sun, Ming-Ting
TI A rate-control algorithm using inter-layer information for H.264/SVC for
   low-delay applications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/SVC; Rate control; MAD prediction; Bit allocation; Initial QP
   selection; Low-delay applications; Inter-layer information; Smooth
   buffer fullness
AB This paper proposes a novel frame-level rate-control scheme for H.264/SVC for low-delay applications. The trend of the Mean Absolute Difference (MAD) (after motion compensation) of the reference layer is used as the inter-layer information for Inter-layer MAD prediction, which is combined with Intra-layer MAD prediction to predict the MAD of the enhancement layers (EL) more accurately. By considering the influence from both the texture and nontexture information, the varying picture complexity and feedback information from the actual encoding results are combined to achieve an accurate bit-allocation. A coarse-to-fine initial quantization parameter (QP) selection method is proposed to refine the initial QP of the EL according to the channel condition and the video sequence characteristics. Experimental results demonstrate that the proposed scheme can obtain high and smooth PSNR, and the output bit-rate is close to the target bit-rate. Also, the proposed scheme can avoid serious buffer fullness fluctuation and reduce skipped frames in the video coding. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hu, Hai-Miao; Li, Bo] Beihang Univ, Sch Engn & Comp Sci, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Lin, Weiyao] Shanghai Jiao Tong Univ, Dept Elect Engn, Shanghai 200240, Peoples R China.
   [Sun, Ming-Ting] Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
   [Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Shanghai Jiao Tong University; University of
   Washington; University of Washington Seattle; Beihang University
RP Li, B (corresponding author), Beihang Univ, Sch Engn & Comp Sci, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
EM bhboli@vip.sina.com
RI lin, yuxi/HKF-6212-2023; Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888; Lin, Weiyao/0000-0001-8307-7107
FU 973 Program [2010CB327900]; National 863 Program [2009AA01Z316]
FX This work was partially supported by the 973 Program (Project No.
   2010CB327900), and the National 863 Program (2009AA01Z316).
CR [Anonymous], 2004, N6505 REQ GROUP
   He ZH, 2001, IEEE T CIRC SYST VID, V11, P928, DOI 10.1109/76.937431
   Jiang MQ, 2006, IEEE T MULTIMEDIA, V8, P467, DOI 10.1109/TMM.2006.870713
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Li Z.G., 2003, 7 JVT M PATT THAIL M
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P116, DOI 10.1109/TCSVT.2007.903325
   Liu Y, 2007, IEEE T CIRC SYST VID, V17, P68, DOI 10.1109/TCSVT.2006.887081
   Ma S.W., 2003, IEEE INT C IM PROC B, P892
   REICHEL J, 2007, JVTW202
   Ribas-Corbera J, 1999, IEEE T CIRC SYST VID, V9, P172, DOI 10.1109/76.744284
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Segall CA, 2007, IEEE T CIRC SYST VID, V17, P1121, DOI 10.1109/TCSVT.2007.906824
   Vieron J., 2008, JVTW203
   Wang CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P436, DOI 10.1109/CISP.2008.689
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1227, DOI 10.1109/TCSVT.2007.905519
   Xu L, 2005, PROC SPIE, V5960, P525, DOI 10.1117/12.631424
   Xu L, 2007, IEEE INT SYMP CIRC S, P49, DOI 10.1109/ISCAS.2007.378179
NR 17
TC 2
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 504
EP 515
DI 10.1016/j.jvcir.2011.05.002
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000005
OA Bronze
DA 2024-07-18
ER

PT J
AU Hung, TY
   Chen, ZZ
   Tan, YP
AF Hung, Tzu-Yi
   Chen, Zhenzhong
   Tan, Yap-Peng
TI Packet scheduling with playout adaptation for scalable video delivery
   over wireless networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE H.264/AVC; Scalable Video Coding; Playout adaptation; Packet scheduling;
   Wireless video; Packet priority; Playout-deadline; Packet dependency
ID ADAPTIVE MEDIA PLAYOUT; RESOURCE-ALLOCATION; TRANSMISSION
AB In this paper, we propose a playout deadline-aware packet scheduling for scalable video delivery over wireless networks. We develop a novel playout adaptation algorithm to reduce playback interruptions by jointly considering the active playout buffer status and adaptive playout rate. We also propose a packet priority analysis method based on the layer information of Scalable Video Coding (SVC). Based on the priority of the video packet and the adaptive playout-deadline, an optimal packet scheduling algorithm is proposed. Packets are selected for transmission to minimize the quality degradation caused as well as to reduce the playout latency. We also adopt a benchmark for the packet priority analysis by calculating the distortion impact of each packet with the consideration of the packet dependency in SVC. When compared with the state-of-the-art algorithms as well as the benchmark, our proposed scheduling algorithm shows a good trade-off between the video quality and the playout latency. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Hung, Tzu-Yi; Chen, Zhenzhong; Tan, Yap-Peng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chen, ZZ (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM E090043@e.ntu.edu.sg; zzchen@ieee.org; eyptan@ntu.edu.sg
RI Tan, Yap-Peng/A-5158-2011; Chen, Zhenzhong/B-3110-2011; 陈,
   震中/C-6857-2014; Chen, Zhenzhong/C-2529-2015
FU Agency for Science, Technology and Research (A*STAR), Singapore; Science
   and Engineering Research Council
FX This research is partially supported by a research grant awarded by The
   Agency for Science, Technology and Research (A*STAR), Singapore, under
   the Mobile Media Thematic Strategic Research Programme of the Science
   and Engineering Research Council.
CR Chen H.-L., 2008, 4 INT C WIR MOB COMM
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Chuang HC, 2007, IEEE T MULTIMEDIA, V9, P1273, DOI 10.1109/TMM.2007.902884
   Conklin GJ, 2001, IEEE T CIRC SYST VID, V11, P269, DOI 10.1109/76.911155
   Fiandrotti A., 2008, P 17 ICCCN VIRG ISL
   Hsu CY, 1997, IEEE J SEL AREA COMM, V15, P1016, DOI 10.1109/49.611156
   Kalman M, 2004, IEEE T CIRC SYST VID, V14, P841, DOI 10.1109/TCSVT.2004.828335
   Katsaggelos AK, 2005, P IEEE, V93, P135, DOI 10.1109/JPROC.2004.839621
   Li MD, 2011, J VIS COMMUN IMAGE R, V22, P284, DOI 10.1016/j.jvcir.2011.01.002
   Li WP, 2001, IEEE T CIRC SYST VID, V11, P301, DOI 10.1109/76.911157
   Li Y, 2008, IEEE T MULTIMEDIA, V10, P885, DOI 10.1109/TMM.2008.922860
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Pahalawatta P, 2007, IEEE J SEL AREA COMM, V25, P749, DOI 10.1109/JSAC.2007.070511
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Su YF, 2009, IEEE T MULTIMEDIA, V11, P1331, DOI 10.1109/TMM.2009.2030543
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Van Dyck RE, 1999, P IEEE, V87, P1734, DOI 10.1109/5.790634
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang Y, 2002, IEEE T CIRC SYST VID, V12, P438, DOI 10.1109/TCSVT.2002.800320
   WIEGAND T, 2007, JVTX201
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Yang XG, 2007, MUE: 2007 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND UBIQUITOUS ENGINEERING, PROCEEDINGS, P585
NR 22
TC 3
Z9 4
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 491
EP 503
DI 10.1016/j.jvcir.2011.06.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000004
DA 2024-07-18
ER

PT J
AU Li, F
   Bao, Z
   Liu, RH
   Zhang, GX
AF Li, Fang
   Bao, Zheng
   Liu, Ruihua
   Zhang, Guixu
TI Fast image inpainting and colorization by Chambolle's dual method
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Inpainting; Colorization; Total variation; Chambolle's dual method
ID MINIMIZATION; ALGORITHM; MODELS
AB In this paper, we propose to use Chambolle's dual methods to solve Total Variation (TV) inpainting model and (weighted) TV colorization model. The fidelity coefficients in these two models are functions which taking zero in the inpainting region and a positive constant in the other region. Then Chambolle's dual method can not be directly used to solve these models since the fidelity coefficient will be denominator in the algorithm. In order to overcome this drawback, we propose to approximate these models by adding new variables. Then the approximated problems can be solved by alternating minimization method with Chambolle's dual method and closed form solutions which is fast and easy to implement. Mathematical results of existence of minimizers are proved for both the original and the approximated problems. Numerical results and comparison with other closely related methods demonstrate that our algorithms are quite efficient. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Zhang, Guixu] E China Normal Univ, Dept Comp Sci, Shanghai 200062, Peoples R China.
   [Li, Fang] E China Normal Univ, Dept Math, Shanghai 200062, Peoples R China.
   [Bao, Zheng] Huaya Microelect Inc, Shanghai, Peoples R China.
   [Liu, Ruihua] Chongqing Univ Technol, Sch Math & Stat, Chongqing, Peoples R China.
C3 East China Normal University; East China Normal University; Chongqing
   University of Technology
RP Zhang, GX (corresponding author), E China Normal Univ, Dept Comp Sci, Shanghai 200062, Peoples R China.
EM gxzhang@cs.ecnu.edu.cn
RI Liu, Ruihua/GSE-4956-2022
FU 973 Program [2011CB707104]; National Science Foundation of Shanghai
   [10ZR1410200]; National Science Foundation of China [11001082];
   Chongqing CMEC foundation of China [KJ100818]; CQUT foundation of China
   [2010ZQ13]
FX The authors would like to thank the anonymous reviewers for their useful
   comments. This work is supported by the 973 Program (2011CB707104), the
   National Science Foundation of Shanghai (10ZR1410200), the National
   Science Foundation of China (11001082), the Chongqing CMEC foundation of
   China (KJ100818), and the CQUT foundation of China (2010ZQ13).
CR Andreu-Vaillo F., 2004, PARABOLIC QUASI LINE
   [Anonymous], 2006, IMAGE PROCESSING BAS
   [Anonymous], 0931 UCLA COMP APPL
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M., 2000, SIGGRAPH NEW ORL LA
   Bresson X., 0725 UCLA CAM, P07
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Cai JF, 2008, APPL COMPUT HARMON A, V24, P131, DOI 10.1016/j.acha.2007.10.002
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan RH, 2008, SIAM J IMAGING SCI, V1, P273, DOI 10.1137/070711499
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P422, DOI 10.1006/jvci.2001.0491
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chan TF, 2006, J MATH IMAGING VIS, V26, P85, DOI 10.1007/s10851-006-6865-7
   Criminisi A., 2003, OBJECT REMOVAL EXEMP
   Evans L. C., 1992, MEASURE THEORY FINE
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Grossauer H, 2003, LECT NOTES COMPUT SC, V2695, P225
   Grossauer H., 2004, LNCS, P3022
   Imo M. Berta, 2001, IEEE CVPR 2001 HAW U
   Kang SH, 2007, IEEE T IMAGE PROCESS, V16, P2251, DOI 10.1109/TIP.2007.903257
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   Nesterov Y, 2005, MATH PROGRAM, V103, P127, DOI 10.1007/s10107-004-0552-5
   Patwardhan K.A., 2005, P INT C IM PROC ICIP
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro Guillermo., 2005, IEEE INT C IMAGE PRO, P698
   Setzer S, 2011, INT J COMPUT VISION, V92, P265, DOI 10.1007/s11263-010-0357-3
   Vese LA, 2003, SIAM J NUMER ANAL, V40, P2085
   Yatziv L, 2006, IEEE T IMAGE PROCESS, V15, P1120, DOI 10.1109/TIP.2005.864231
NR 34
TC 14
Z9 19
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2011
VL 22
IS 6
BP 529
EP 542
DI 10.1016/j.jvcir.2011.06.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 813TV
UT WOS:000294394000008
DA 2024-07-18
ER

PT J
AU Wang, DL
   Lim, KB
AF Wang Daolei
   Lim, Kah Bin
TI Obtaining depth map from segment-based stereo matching using graph cuts
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Color segmentation; Graph cuts; Disparity plane
   fitting; Clustering; Optimization; Occlusion; Similarity measure
ID ALGORITHM
AB In the paper, the algorithm of segment-based stereo matching using graph cuts is developed for extracting depth information from the stereo image pairs. The first step of the algorithm employs the mean-shift algorithm to segment the reference image, which ensures our method to correctly estimate in large untextured regions and precisely localize depth boundaries, followed by the use of Adaptive Support Weighted Self-Adaptation dissimilarity algorithm (ASW-SelfAd) for the estimation of initial disparity. This is followed by application of Singular Value Decomposition (SVD) in solving the robust disparity plane fitting. In order to ensure reliable pixel sets for the segment, we filter out outliers which contain occlusion region through three main rules, namely; cross-checking, judging reliable area and disparity distance measurement. Lastly, we apply improved clustering algorithm to merge the neighboring segments. The geometrical relationship of adjacent planes such as parallelism and intersection is employed for determination of whether two planes shall be merged. A new energy function is subsequently formulated with the use of graph cuts for the refinement of the disparity map. Finally, the depth information is extracted from the final disparity map. Experimental results on the Middlebury dataset demonstrate that our approach is effective in improving the state of the art. (C) 2011 Elsevier Inc. All rights reserved.
C1 [Wang Daolei; Lim, Kah Bin] Natl Univ Singapore, Dept Mech Engn, Control & Mechatron Lab, EA 04-06,10 Kent Ridge Crescent, Singapore 119260, Singapore.
C3 National University of Singapore
RP Wang, DL (corresponding author), Natl Univ Singapore, Dept Mech Engn, Control & Mechatron Lab, EA 04-06,10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM g0800337@nus.edu.sg
OI Lim, Kah Bin/0000-0002-2118-0966
CR [Anonymous], 2008, CVPRO8
   [Anonymous], 2008, CVPR
   [Anonymous], 2001, P INT C COMP VIS
   [Anonymous], 1999, THESIS CORNELL U
   Bleyer M, 2005, ISPRS J PHOTOGRAMM, V59, P128, DOI 10.1016/j.isprsjprs.2005.02.008
   BLEYER M, 2006, SPIE, V5665, P288
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 1998, IEEE T PATTERN ANAL, V20, P1283, DOI 10.1109/34.735802
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Deng Y, 2005, IEEE I CONF COMP VIS, P1316
   FELZENSZWALB PF, 2006, INT J COMPUT VIS, V70
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Hong L, 2004, PROC CVPR IEEE, P74
   HUANG XF, 2007, COOP OPT EN MIN CAS
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Ke QF, 2001, PROC CVPR IEEE, P255
   Klaus A, 2006, INT C PATT RECOG, P15
   KOLMOGOROV V, 2002, P EUR C COMP VIS
   KRISHNAMACHARI S, 1999, IS T SPIE C STOR RET, P427
   Li G, 2005, LECT NOTES COMPUT SC, V3757, P617
   Li G., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V2, P2355
   LIU ZH, 2009, IEEE INT C MECH AUT
   Nalpantidis L, 2008, LECT NOTES ARTIF INT, V5138, P365, DOI 10.1007/978-3-540-87881-0_34
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562
   WANG DL, 2010, 3 IEEE INT C COMP SC, V5, P410
   YOOK KJ, 2006, IEEE T PATTERN ANAL, V28, P650
   Zhang Y, 2002, LECT NOTES COMPUT SC, V2351, P556
   ZINTNICK C, 2002, T PATTERN ANAL MACH, V22, P675
NR 31
TC 29
Z9 40
U1 1
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2011
VL 22
IS 4
BP 325
EP 331
DI 10.1016/j.jvcir.2011.02.001
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 751AG
UT WOS:000289589100003
DA 2024-07-18
ER

PT J
AU Lin, SJ
   Chen, SK
   Lin, JC
AF Lin, Sian-Jheng
   Chen, Shang-Kuan
   Lin, Ja-Chen
TI Flip visual cryptography (FVC) with perfect security,
   conditionally-optimal contrast, and no expansion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Flipping; Conditionally optimal contrast; Secret
   image sharing; Visual secret sharing; Non-expansible; Perfect security;
   Random grids
ID SECRET SHARING SCHEMES
AB This paper proposes a flip visual cryptography (FVC) scheme with perfect security, conditionally optimal contrast, and no expansion of size. The proposed FVC scheme encodes two secret images into two dual-purpose transparencies. Stacking the two transparencies can reveal one secret image. Flipping one of the two transparencies and then stacking with the other transparency can reveal the second secret image. The proposed scheme is proved to have conditionally optimal contrast: its contrast is optimal if the double-secrets non-expanded FVC scheme is required to have perfect security. The perfect security is also proved. (c) 2010 Elsevier Inc. All rights reserved.
C1 [Chen, Shang-Kuan] Yuanpei Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
   [Lin, Sian-Jheng; Lin, Ja-Chen] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, SK (corresponding author), Yuanpei Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
EM skchen@mail.ypu.edu.tw
FU National Science Council of Republic of China [NSC97-2221-E-009-120-MY3]
FX The work is supported by National Science Council of Republic of China,
   under Grant NSC97-2221-E-009-120-MY3. The authors thank the reviewers
   for valuable suggestions to improve the paper.
CR CHEN SK, 2009, 5 INT C INT INF HID
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Chen YF, 2007, INFORM SCIENCES, V177, P4696, DOI 10.1016/j.ins.2007.05.011
   De Bonis A, 2004, THEOR COMPUT SCI, V314, P351, DOI 10.1016/j.tcs.2003.12.018
   Fang WP, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2193912
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu F, 2010, INFORM PROCESS LETT, V110, P241, DOI 10.1016/j.ipl.2010.01.003
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wu HC, 2005, COMPUT STAND INTER, V28, P123, DOI 10.1016/j.csi.2004.12.006
   Yang CN, 2005, PATTERN RECOGN LETT, V26, P193, DOI 10.1016/j.patrec.2004.08.025
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 16
TC 29
Z9 32
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2010
VL 21
IS 8
BP 900
EP 916
DI 10.1016/j.jvcir.2010.08.006
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 675JV
UT WOS:000283827500014
DA 2024-07-18
ER

PT J
AU Zhang, QA
   Ngan, KN
AF Zhang, Qian
   Ngan, King Ngi
TI Multi-view video based multiple objects segmentation using graph cut and
   spatiotemporal projections
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-view pre-processing; Depth reconstruction; Saliency model; Object
   extraction; Graph cut; Spatiotemporal protections; Multi-view
   segmentation; Multi-view video
ID VISUAL-ATTENTION; COLOR; IMAGE; EXTRACTION; STEREO
AB In this paper, we present an automatic algorithm to segment multiple objects from multi-view video. The Initial Interested Objects (IIOs) are automatically extracted in the key view of the initial frame based on the saliency model. Multiple objects segmentation is decomposed into several sub-segmentation problems, and solved by minimizing the energy function using binary label graph cut. In the proposed novel energy function, the color and depth cues are integrated with the data term, which is then modified with background penalty with occlusion reasoning. In the smoothness term, foreground contrast enhancement is developed to strengthen the moving objects boundary, and at the same time attenuates the background contrast. To segment the multi-view video, the coarse predictions of the other views and the successive frame are projected by pixel-based disparity and motion compensation, respectively, which exploits the inherent spatiotemporal consistency. Uncertain band along the object boundary is shaped based on activity measure and refined with graph cut, resulting in a more accurate Interested Objects (IOs) layer across all views of the frames. The experiments are implemented on a couple of multi-view videos with real and complex scenes. Excellent subjective results have shown the robustness and efficiency of the proposed algorithm. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Zhang, Qian; Ngan, King Ngi] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Zhang, QA (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
EM qzhang@ee.cuhk.edu.hk; knngan@ee.cuhk.edu.hk
RI Ngan, N/E-8240-2014
OI Ngan, N/0000-0003-1946-3235
CR [Anonymous], 2008, P IEEE C COMP VIS PA
   Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cui CH, 2007, LECT NOTES COMPUT SC, V4872, P497
   DOULAMIS AD, 1999, P INT C INF INT SYST
   Goldlücke B, 2003, PROC CVPR IEEE, P683
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Huang Y., 2009, P IEEE C COMP VIS PA
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Kolmogorov V, 2005, PROC CVPR IEEE, P407
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193
   Kubota A, 2007, IEEE SIGNAL PROC MAG, V24, P10, DOI 10.1109/MSP.2007.905873
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lempitsky V, 2007, IEEE I CONF COMP VIS, P620
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Liu Tie, 2007, P IEEE C COMP VIS PA
   Min D, 2009, SIGNAL PROCESS-IMAGE, V24, P31, DOI 10.1016/j.image.2008.10.009
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paschos G, 2001, IEEE T IMAGE PROCESS, V10, P932, DOI 10.1109/83.923289
   Quan L, 2007, INT J COMPUT VISION, V75, P135, DOI 10.1007/s11263-007-0044-1
   Quan L, 2006, ACM T GRAPHIC, V25, P599, DOI 10.1145/1141911.1141929
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   SFIKAS G, 2008, P IEEE C CVPR JUN, P1
   Shapiro L. G., 2001, COMPUTER VISION
   SUN J, 2006, BACKGROUND CUT ECCV
   Tai YW, 2007, IEEE T PATTERN ANAL, V29, P1520, DOI 10.1109/TPAMI.2007.1168
   Tsai YP, 2007, IEEE T IMAGE PROCESS, V16, P2607, DOI 10.1109/TIP.2007.904465
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yang WX, 2007, LECT NOTES COMPUT SC, V4678, P178
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 37
TC 14
Z9 19
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL-AUG
PY 2010
VL 21
IS 5-6
SI SI
BP 453
EP 461
DI 10.1016/j.jvcir.2009.09.005
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 613HS
UT WOS:000278970600008
DA 2024-07-18
ER

PT J
AU Joo, H
   Song, H
AF Joo, Hyunchul
   Song, Hwangjun
TI Wireless link state-aware H.264 MGS coding-based mobile IPTV system over
   WiMAX network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Mobile IPTV; WiMAX; H.264 medium-grain scalability coding; Media
   broadcasting; IP multicast; Modulation and coding scheme; Multicast and
   broadcast service; Resource allocation
ID MULTIUSER OFDM; VIDEO; BROADCAST; ALGORITHM
AB This paper presents a simple but effective architecture for the transmission of H.264 MGS coding-based IPTV stream over WiMAX network. The proposed system is implemented to provide more subscribers with an enhanced mobile IPTV service considering their wireless link states. In the proposed system, the base layer of the IPTV stream is transmitted with the sparsest modulation scheme and the lowest coding rate to provide IPTV service of minimum quality to as many subscribers as possible. And some parts of the enhancement layer are transmitted with the modulation scheme and the coding rate adaptive to wireless link states of subscribers. Basically, we pursue an efficient tradeoff between the number of subscribers that receive the enhancement layer stream and their IPTV service quality. Finally, experimental results are provided to show the performance of the proposed system. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Joo, Hyunchul; Song, Hwangjun] Pohang Univ Sci & Technol, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Song, H (corresponding author), Pohang Univ Sci & Technol, Pohang 790784, South Korea.
EM hwangjun@postech.ac.kr
FU Ministry of Education, Science and Technology [R31-2008-000-10100-0]
FX This research was supported by WCU (World Class University) program
   through the Korea Science and Engineering Foundation funded by the
   Ministry of Education, Science and Technology (Project No.
   R31-2008-000-10100-0).
CR *3GPP, 2006, 25346 TS 3GPP
   [Anonymous], 2004, 302304 ETSI EN
   [Anonymous], 2004, IEEE Standard for Local and Metropolitan Area Networks Part 16: Air Interface for Fixed Broadband Wireless Access Systems, P1
   *CABL TEL LAB INC, 2003, SPCMCI109030730 DOCS
   Erceg V, 1999, IEEE J SEL AREA COMM, V17, P1205, DOI 10.1109/49.778178
   GERSHO A, 1979, IEEE T INFORM THEORY, V23
   HARRIS A, 2005, ENABLING IPTV WHAT C
   HOU F, 2008, P IEEE INT C COMM MA
   Hsu CH, 2008, IEEE T MULTIMEDIA, V10, P457, DOI 10.1109/TMM.2008.917365
   *IEEE, 2004, 80216 IEEE TGE
   Jang JH, 2003, IEEE J SEL AREA COMM, V21, P171, DOI 10.1109/JSAC.2002.807348
   Jiang T, 2007, IEEE COMMUN MAG, V45, P78, DOI 10.1109/MCOM.2007.4290318
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   *JVT ISO IEC MPEG, 2007, N8751 JVT ISO IEC MP
   Kim HS, 2008, IEEE T CONSUM ELECTR, V54, P171, DOI 10.1109/TCE.2008.4470040
   KIM J, 2006, INT C ADV COMM TECHN, V1, P465
   Mohanram C, 2005, IEEE COMMUN LETT, V9, P685, DOI 10.1109/LCOMM.2005.08006
   OPNET modeler, OPNET MOD
   *QUALCOMM, QUALCOMM MEDIAFLO
   Rong B, 2007, IEEE WIREL COMMUN, V14, P14, DOI 10.1109/MWC.2007.314546
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   She J, 2007, IEEE COMMUN MAG, V45, P87, DOI 10.1109/MCOM.2007.4290319
   Wang JF, 2007, IEEE J SEL AREA COMM, V25, P712, DOI 10.1109/JSAC.2007.070508
   WIEGAND T, 2006, JVTT201 KLAG
NR 24
TC 7
Z9 7
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 89
EP 97
DI 10.1016/j.jvcir.2009.04.004
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800003
DA 2024-07-18
ER

PT J
AU Tang, L
   Chen, Z
   Yin, H
   Li, J
   Li, YD
AF Tang, Li
   Chen, Zhen
   Yin, Hao
   Li, Jun
   Li, Yanda
TI CORS: A cooperative overlay routing service to enhance interactive
   multimedia communications
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interactive multimedia communications; Overlay routing; Multi-path
   transmission service
ID INTERNET; VIDEO
AB As interactive multimedia communications are developing rapidly on the Internet, they present stringent challenges on end-to-end (E2E) performance. On the other hand, however, the Internet's architecture (IPv4) remains almost the same as it was originally designed for only data transmission purpose, and has experienced big hurdle to actualize QoS universally. This paper designs a cooperatively overlay routing service (CORS) aiming to overcome the performance limit inherent in the Internet's IP-layer routing service. The key idea of CORS is to efficiently compose a number of eligible application-layer paths with suitable relays in the overlay network. Besides the direct IP path, CORS can transfer data simultaneously through one or more application-layer paths to adaptively satisfy the data's application-specific requirements on E2E performance. Simulation results indicate the proposed schemes are scalable and effective. Practical experiments based on a prototype implemented on PlanetLab show that CORS is feasible to enhance the transmission reliability and the quality of multimedia communications. (C) 2009 Elsevier Inc. All rights reserved.
C1 [Tang, Li; Li, Yanda] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Yin, Hao] Tsinghua Univ, Dept Comp Sci, Beijing 100084, Peoples R China.
   [Tang, Li; Chen, Zhen; Yin, Hao; Li, Jun] Tsinghua Univ, Res Inst Informat Technol, Beijing 100084, Peoples R China.
   [Chen, Zhen; Li, Jun; Li, Yanda] Tsinghua Natl Lab Informat Sci & Technol, Beijing, Peoples R China.
C3 Tsinghua University; Tsinghua University; Tsinghua University; Tsinghua
   University
RP Tang, L (corresponding author), Tsinghua Univ, Dept Automat, Room 3-421,FIT Bldg, Beijing 100084, Peoples R China.
EM tangli03@mails.tsinghua.edu.cn
RI Li, Yanda/A-9495-2012; chen, zhen/C-5865-2009
OI chen, zhen/0000-0001-5503-2630
FU NEC Laboratories, China
FX The authors thank the colleagues in Network Security Lab, RIIT, Tsinghua
   University for their cooperation on developing CORS, and are very
   grateful to Dr. Yong Xia at NEC and anonymous reviewers for their
   insightful comments and suggestions on improving this paper. This work
   is sponsored by NEC Laboratories, China.
CR AMIR Y, 2005, P 10 INT WORKSH NETW
   Amir Y, 2006, IEEE T MULTIMEDIA, V8, P1250, DOI 10.1109/TMM.2006.884609
   Andersen D., 2001, Operating Systems Review, V35, P131, DOI 10.1145/502059.502048
   [Anonymous], 1998, An Architecture for Differentiated Services, RFC 2475 Informational
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   BOLOSKY W, 2000, P ACM INT C MEAS MOD
   Braden R., 1994, INTEGRATED SERVICES
   Dahlin M, 2003, IEEE ACM T NETWORK, V11, P300, DOI 10.1109/TNET.2003.810312
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P74, DOI 10.1109/79.952806
   GUMMADI KP, 2004, P 6 USENIX S OP SYST
   *ITU T, 2005, G114 ITUT
   JIANG W, 2000, P 10 INT WORKSH NETW
   Labovitz C, 2001, IEEE ACM T NETWORK, V9, P293, DOI 10.1109/90.929852
   MEDINA A, 2001, P 9 INT S MOD AN SIM
   Mitzenmacher M, 2001, IEEE T PARALL DISTR, V12, P1094, DOI 10.1109/71.963420
   Paxson V, 1997, IEEE ACM T NETWORK, V5, P601, DOI 10.1109/90.649563
   RAHUL H, 2006, P PASS ACT MEAS PAM
   REN S, 2006, P 26 IEEE INT C DIST
   Salomon D., 2005, CODING DATA COMPUTER, V1
   Savage S, 1999, COMP COMM R, V29, P289, DOI 10.1145/316194.316233
   Song HJ, 2001, IEEE T CIRC SYST VID, V11, P512, DOI 10.1109/76.915357
   SUBRAMANIAN V, 2007, P WIR SYST ADV RES D
   Thomas A., 2003, P ACM SIGCOMM C KARL
   WANG C, AEROSPACE CORPORATIO, V3
   WU D, 2000, P IEEE NETWORLD INT
   Yang W, 2006, IEEE T CIRC SYST VID, V16, P286, DOI 10.1109/TCSVT.2005.862496
   ZHANG H, 2006, P 15 INT C COMP COMM
NR 27
TC 1
Z9 2
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2010
VL 21
IS 2
BP 107
EP 119
DI 10.1016/j.jvcir.2009.06.005
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 567LR
UT WOS:000275448800005
DA 2024-07-18
ER

PT J
AU Awrangjeb, M
   Lu, GJ
AF Awrangjeb, Mohammad
   Lu, Guojun
TI Techniques for efficient and effective transformed image identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Feature detection; Feature representation; Feature matching; Transformed
   image identification
ID POINT DISTANCE ACCUMULATION; CORNER DETECTION; CURVATURE; SCALE
AB In many applications, one common problem is to identify images which may have undergone unknown transformations. We define this problem as transformed image identification (TII), where the goal is to identify geometrically transformed and signal processed images for a given test image. The TII consists of three main stages - feature detection, feature representation, and feature matching. The TII approach by Lowe [D.G. Lowe, Distinctive image features from scale-invariant keypoints, Int. J. Comput. Vision 60 (2) (2004) 91-110] is one of the most promising techniques. However, both of its feature detection and matching stages are expensive, because a large number of feature-points are detected in the image scale-space and each feature-point is described using a high dimensional vector. In this paper, we explore the use of different techniques in each of the three TII stages and propose a number of promising TII approaches by combining different techniques of the three stages. Our experimental results reveal that the proposed approaches not only improve the computational efficiency and decrease the storage requirement significantly, but also increase the transformed image identification accuracy (robustness). (C) 2009 Elsevier Inc. All rights reserved.
C1 [Awrangjeb, Mohammad] Univ Melbourne, Cooperat Res Ctr Spatial Informat, Carlton, Vic 3053, Australia.
   [Lu, Guojun] Monash Univ, Gippsland Sch IT, Churchill, Vic 3842, Australia.
C3 University of Melbourne; Federation University Australia; Monash
   University
RP Awrangjeb, M (corresponding author), Univ Melbourne, Cooperat Res Ctr Spatial Informat, 723 Swanston St, Carlton, Vic 3053, Australia.
EM mawr@unimelb.edu.au; Guojun.Lu@infotech.monash.edu.au
RI cai, bo/G-1491-2010; Awrangjeb, Mohammad/N-3387-2016
OI Awrangjeb, Mohammad/0000-0002-2711-4329; Lu, Guojun/0000-0003-2523-7576
CR [Anonymous], P IEEE COMP SOC C CO
   Awrangieb M, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1483
   Awrangieb M, 2007, INT CONF ACOUST SPEE, P1233
   AWRANGJEB M, THESIS
   Awrangjeb M, 2008, IEEE T IMAGE PROCESS, V17, P2425, DOI 10.1109/TIP.2008.2006441
   Awrangjeb M, 2008, IEEE T MULTIMEDIA, V10, P1059, DOI 10.1109/TMM.2008.2001384
   Awrangjeb M, 2006, IEEE IMAGE PROC, P1961, DOI 10.1109/ICIP.2006.313109
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao GZ, 2004, P AMER CONTR CONF, P2196
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Han JH, 2001, PATTERN RECOGN LETT, V22, P1133, DOI 10.1016/S0167-8655(01)00063-0
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377
   Huttenlocher D. P., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P263, DOI 10.1109/CVPR.1991.139699
   Ke Y, 2004, PROC CVPR IEEE, P506
   KE Y, 2004, P ACM MULT NEW YORK
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu CJ, 2004, IEEE T SYST MAN CY B, V34, P1117, DOI 10.1109/TSMCB.2003.821449
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu G., 1999, MULTIMEDIA DATABASE
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Schmid C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P230, DOI 10.1109/ICCV.1998.710723
   Sinzinger ED, 2008, PATTERN RECOGN, V41, P494, DOI 10.1016/j.patcog.2007.06.032
   TAO D, 2005, P IEEE INT C DAT MIN
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P3, DOI 10.1109/TCSVT.2007.906936
   Xu D., 2008, P IEEE C COMP VIS PA, P1
   Xu D, 2006, IEEE T CIRC SYST VID, V16, P896, DOI 10.1109/TCSVT.2006.877418
   ZHANG D, 2004, P ACM MULT NEW YORK
   Zhang XH, 2007, PATTERN RECOGN LETT, V28, P545, DOI 10.1016/j.patrec.2006.10.006
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
   ZHOU D, 2004, P INT C ROB AUT, V3, P2730
NR 35
TC 8
Z9 9
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2009
VL 20
IS 8
BP 511
EP 520
DI 10.1016/j.jvcir.2009.07.004
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 530FC
UT WOS:000272573400002
OA Green Published
DA 2024-07-18
ER

PT J
AU Yang, KC
   Huang, CM
   Wang, JS
AF Yang, Kai-Chao
   Huang, Chun-Ming
   Wang, Jia-Shung
TI Error resilient GOP structures on video streaming
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE GOP; streaming; video coding; error resilience
ID H.264/AVC
AB In this paper, we describe novel coding dependencies among video frames supporting efficient error resilience in a video streaming system. Our approach is based upon reorganizing the regular linear GOP encoding structure to prevent the error propagation phenomenon and recover lost frames by interpolation. For errors taking place in a single frame, we guarantee that errors will not propagate to the neighboring frames. Therefore, both the past and future temporal information can be used to reconstruct the damaged frame. Furthermore, the proposed coding structures can also recover successive lost frames. In low power and low bandwidth circumstances such as some mobile devices, the proposed structures can also dynamically adjust the video quality level to adapt to a fluctuant network environment. (C) 2006 Elsevier Inc. All rights reserved.
C1 Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Tsing Hua University
RP Yang, KC (corresponding author), Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM kcyang@vc.cs.nthu.edu.tw; cmhuang@cic.org.tw; jswang@cs.nthu.edu.tw
CR Apostolopoulos J, 2002, IEEE INFOCOM SER, P1736, DOI 10.1109/INFCOM.2002.1019427
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Derryberry RT, 2002, IEEE COMMUN MAG, V40, P68, DOI 10.1109/35.995853
   FUKUNAGA S, 1996, GLOBECOM96
   KUMAR S, 2005, IN PRESS ELSEVIER J
   Liang J., 1999, P SOC PHOTO-OPT INS, V3653, P40
   Lim CP, 1999, INT J IMAG SYST TECH, V10, P54, DOI 10.1002/(SICI)1098-1098(1999)10:1<54::AID-IMA6>3.0.CO;2-H
   Shanableh T, 2001, IEEE T CIRC SYST VID, V11, P402, DOI 10.1109/76.911164
   Stockhammer T, 2003, IEEE T CIRC SYST VID, V13, P657, DOI 10.1109/TCSVT.2003.815167
   Talluri R, 1998, IEEE COMMUN MAG, V36, P112, DOI 10.1109/35.685373
   TOMITA Y, 1997, P INT PICT COD S PCS, P743
   Wang Y., 2002, VIDEO PROCESSING COM
   Wenger S, 1998, IEEE T CIRC SYST VID, V8, P867, DOI 10.1109/76.735382
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
   WENGER S, 1997, P AVSPN, V97
   Yang KC, 2003, 2003 INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING, PROCEEDINGS, P107
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
NR 17
TC 2
Z9 2
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2007
VL 18
IS 2
BP 151
EP 161
DI 10.1016/j.jvcir.2006.12.001
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 163AB
UT WOS:000246129700006
DA 2024-07-18
ER

PT J
AU Selivanov, VV
   Lepage, MD
   Lecomte, R
AF Selivanov, Vitali V.
   Lepage, Martin D.
   Lecomte, Roger
TI List-mode image reconstruction for real-time PET imaging
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE positron emission tomography; tomographic reconstruction; list mode;
   iterative algorithms; regularized pseudo-inverse matrix; truncated
   singular value decomposition
ID EM ALGORITHM; 3-DIMENSIONAL RECONSTRUCTION; TOMOGRAPHY; LIKELIHOOD;
   DECOMPOSITION; QUALITY; SYSTEM
AB The problem of tomographic image reconstruction from measured projection data can be reduced to solving a set of linear equations represented in matrix form. In this paper, we show how image reconstruction in positron emission tomography (PET) can be achieved potentially in real-time using a regularized pseudo-inverse of the system matrix. An update of the current image estimate accounting for the next registered event can be obtained using a single column of the regularized pseudo-inverse matrix, thus allowing for instant visualization of the radioactivity distribution while the subject is still being scanned. The computed image estimate is the minimum-norm least-squares solution of the regularized inverse problem. The speed and performance of the algorithm were characterized and compared to those of a well-known statistical iterative algorithm. The proposed algorithm was validated with experimental list-mode PET data. (C) 2006 Published by Elsevier Inc.
C1 Univ Sherbrooke, Etienne LeBel Clin Res Ctr, Sherbrooke Mol Imaging Ctr, Sherbrooke, PQ J1H 5N4, Canada.
   Adv Mol Imaging Inc, Sherbrooke, PQ J1J 2E8, Canada.
C3 University of Sherbrooke
RP Lecomte, R (corresponding author), Univ Sherbrooke, Etienne LeBel Clin Res Ctr, Sherbrooke Mol Imaging Ctr, Sherbrooke, PQ J1H 5N4, Canada.
EM Roger.Lecomte@USherbrooke.ca
RI LECOMTE, Roger/F-2582-2011
OI LECOMTE, Roger/0000-0002-8541-0783
CR Anderson E., 1999, LAPACK USERSGUIDE, Vthird
   BAKER JR, 1992, CRIT REV BIOMED ENG, V20, P47
   BEVINGTON PR, 1992, DATA REDUCTION ERROR, P63
   Browne J, 1996, IEEE T MED IMAGING, V15, P687, DOI 10.1109/42.538946
   BUDINGER TF, 1974, IEEE T NUCL SCI, VNS21, P2, DOI 10.1109/TNS.1974.6499234
   BUONOCORE MH, 1981, IEEE T BIO-MED ENG, V28, P69, DOI 10.1109/TBME.1981.324781
   CAHILL P, 1970, J NUCL MED, V11, P613
   CLACK R, 1989, IEEE T MED IMAGING, V8, P32, DOI 10.1109/42.20359
   DESJARDINS B, 1997, 1997 IEEE NUCL SCI S, V2, P1551
   Di Sciascio E, 1998, REAL-TIME IMAGING, V4, P255, DOI 10.1006/rtim.1997.0088
   DISCIASCIO E, 1992, 1992 IEEE NUCL SCI S, V2, P921
   DISCIASCIO E, 1994, 1994 IEEE NUCL SCI S, V3, P1192
   FESSLER JA, 1994, IEEE T MED IMAGING, V13, P290, DOI 10.1109/42.293921
   Gullberg GT, 1996, IEEE T NUCL SCI, V43, P295, DOI 10.1109/23.485969
   HANSEN PC, 1992, INVERSE PROBL, V8, P849, DOI 10.1088/0266-5611/8/6/005
   HARTZ R, 1985, IEEE T NUCL SCI, V32, P839, DOI 10.1109/TNS.1985.4336952
   HARTZ R, 1982 WORKSH TIM OF F, P153
   HUDSON HM, 1994, IEEE T MED IMAGING, V13, P601, DOI 10.1109/42.363108
   Huesman RH, 2000, IEEE T MED IMAGING, V19, P532, DOI 10.1109/42.870263
   Leahy RM, 2000, STAT COMPUT, V10, P147, DOI 10.1023/A:1008946426658
   Lecomte R, 1996, IEEE T NUCL SCI, V43, P1952, DOI 10.1109/23.507252
   Lepage MD, 2002, IEEE NUCL SCI CONF R, P1771, DOI 10.1109/NSSMIC.2001.1008685
   LEPAGE MD, 2002, THESIS U SHERBROOKE
   LEPAGE MD, 2000, 2000 IEEE NUCL SCI S
   MANDELKERN MA, 1995, ANNU REV NUCL PART S, V45, P205
   MCINTYRE JA, 1981, IEEE T NUCL SCI, V28, P171, DOI 10.1109/TNS.1981.4331161
   Nuyts J, 2001, IEEE T MED IMAGING, V20, P365, DOI 10.1109/42.925290
   Parra L, 1998, IEEE T MED IMAGING, V17, P228, DOI 10.1109/42.700734
   PESS WH, 1992, NUMERICAL RECIPES C, P683
   PHILIPPE EA, 1982, IEEE T NUCL SCI, V29, P524, DOI 10.1109/TNS.1982.4335900
   Pomper MG, 2001, ACAD RADIOL, V8, P1141, DOI 10.1016/S1076-6332(03)80728-6
   Raichle ME, 1998, SEMIN NUCL MED, V28, P278, DOI 10.1016/S0001-2998(98)80033-0
   Reader AJ, 2002, IEEE T NUCL SCI, V49, P693, DOI 10.1109/TNS.2002.1039550
   ROCKMORE AJ, 1976, IEEE T NUCL SCI, V23, P1428, DOI 10.1109/TNS.1976.4328496
   Selivanov V, 2001, J NUCL MED, V42, p138P
   Selivanov VV, 2002, IEEE NUCL SCI CONF R, P1737, DOI 10.1109/NSSMIC.2001.1008678
   Selivanov VV, 2001, IEEE T NUCL SCI, V48, P883, DOI 10.1109/23.940180
   Selivanov VV, 2001, IEEE T NUCL SCI, V48, P761, DOI 10.1109/23.940160
   Selivanov VV, 2000, IEEE T NUCL SCI, V47, P1168, DOI 10.1109/23.856565
   SELIVANOV VV, 2002, THESIS U SHERBROOKE
   Shepp L A, 1982, IEEE Trans Med Imaging, V1, P113, DOI 10.1109/TMI.1982.4307558
   SHIM YS, 1981, IEEE T ACOUST SPEECH, V29, P904, DOI 10.1109/TASSP.1981.1163632
   SMITH MF, 1992, IEEE T MED IMAGING, V11, P165, DOI 10.1109/42.141640
   Smith MF, 1996, IEEE T NUCL SCI, V43, P2008, DOI 10.1109/23.507261
   SNYDER DL, 1983, IEEE T NUCL SCI, V30, P1843, DOI 10.1109/TNS.1983.4332660
   STRANG G, 1980, LINEAR ALGEBRA ITS A, P137
   VOGEL CR, 1994, SIAM J SCI COMPUT, V15, P736, DOI 10.1137/0915047
NR 47
TC 3
Z9 6
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUN
PY 2006
VL 17
IS 3
BP 630
EP 646
DI 10.1016/j.jvcir.2006.02.004
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JX
UT WOS:000242027300009
DA 2024-07-18
ER

PT J
AU Yin, PY
AF Yin, Peng-Yeng
TI Particle swarm optimization for point pattern matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE point pattern matching; particle swarm optimization; genetic algorithm;
   simulated annealing; local optimal solution; global optimal solution
ID ALGORITHM; CONVERGENCE; IMAGES
AB The technique for point pattern matching (PPM) is essential to many image analysis and computer vision tasks. Given two point patterns, the PPM technique finds an optimal transformation for one point pattern such that a distance measure from the transformed point pattern to the other is minimized. This paper presents a new PPM algorithm based on particle swarm optimization (PSO). The set of transformation parameters is encoded as a real-valued vector called particle. A swarm of particles are initiated at random and fly through the transformation space for targeting the optimal transformation. The proposed algorithm is validated through both synthetic datasets and real fingerprint images. The experimental results manifest that the PSO-based method is robust against practical scenarios such as positional perturbations, contaminations, and drop-outs from the point sets. The PSO algorithm is also shown to be superior to a genetic algorithm and a simulated annealing algorithm on both effectiveness and efficiency. (c) 2005 Elsevier Inc. All rights reserved.
C1 Natl Chi Nan Univ, Dept Informat Management, Puli 545, Nantou, Taiwan.
C3 National Chi Nan University
RP Yin, PY (corresponding author), Natl Chi Nan Univ, Dept Informat Management, 303 Univ Rd, Puli 545, Nantou, Taiwan.
EM pyyin@ncnu.edu.tw
CR AGRAWAL A, 1994, 1994 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOL 1-7, P1777, DOI 10.1109/ICNN.1994.374425
   ANSARI N, 1990, P 16 ANN C IEEE IND, V2, P1233
   ANSARI N, 1993, P IEEE REG C CONTR, P215
   Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7
   Chang SH, 1997, PATTERN RECOGN, V30, P311, DOI 10.1016/S0031-3203(96)00076-3
   Clerc M, 2004, STUD FUZZ SOFT COMP, V141, P219
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Eberhart R., 1998, PROC 1998 INT C NEUR, P5
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   GOSHTASBY A, 1985, IEEE T SYST MAN CYB, V15, P631, DOI 10.1109/TSMC.1985.6313439
   GRIFFIN PM, 1989, IEEE T SYST MAN CYB, V19, P1274, DOI 10.1109/21.44047
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Mount DM, 1999, PATTERN RECOGN, V32, P17, DOI 10.1016/S0031-3203(98)00086-7
   Naka S, 2003, IEEE T POWER SYST, V18, P60, DOI 10.1109/TPWRS.2002.807051
   OGAWA H, 1984, PATTERN RECOGN, V17, P569, DOI 10.1016/0031-3203(84)90055-4
   Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100
   Parsopoulos K. E., 2002, Natural Computing, V1, P235, DOI 10.1023/A:1016568309421
   RANADE S, 1980, PATTERN RECOGN, V12, P269, DOI 10.1016/0031-3203(80)90067-9
   STARINK JPP, 1995, PATTERN RECOGN, V28, P231, DOI 10.1016/0031-3203(94)00087-3
   Tandon V., 2000, THESIS INDIANA U PUR
   TON JC, 1989, IEEE T GEOSCI REMOTE, V27, P642, DOI 10.1109/TGRS.1989.35948
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Wang WH, 1997, ELECTRON LETT, V33, P478, DOI 10.1049/el:19970337
   Yin PY, 2004, J VIS COMMUN IMAGE R, V15, P241, DOI 10.1016/j.jvcir.2003.12.001
   YOSHIDA H, 1999, P INT C INT SYST APP, P117
   YUEN PC, 1993, ELECTRON LETT, V29, P2023, DOI 10.1049/el:19931350
   Zhang LH, 2003, PATTERN RECOGN LETT, V24, P9, DOI 10.1016/S0167-8655(02)00160-5
NR 30
TC 40
Z9 47
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2006
VL 17
IS 1
BP 143
EP 162
DI 10.1016/j.jvcir.2005.02.002
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 105JT
UT WOS:000242026900009
DA 2024-07-18
ER

PT J
AU Tseng, BL
   Lin, CY
   Smith, JR
AF Tseng, BL
   Lin, CY
   Smith, JR
TI Video personalization and summarization system for usage environment
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE video personalization; summarization; adaptation; usage environment;
   MPEG-7; MPEG-21; annotation; rich media description; digital item
   adaptation; rights expression
AB A video personalization and summarization system is designed and implemented incorporating usage environment to dynamically generate a personalized video summary. The personalization system adopts the three-tier server-middleware-client architecture in order to select, adapt, and deliver rich media content to the user. The server stores the content sources along with their corresponding MPEG-7 metadata descriptions. Our semantic metadata is provided through the use of the VideoAnnEx MPEG-7 Video Annotation Tool. When the user initiates a request for content, the client communicates the MPEG-21 usage environment description along with the user query to the middleware. The middleware is powered by the personalization engine and the content adaptation engine. Our personalization engine includes the Video-Sue Summarization on Usage Environment engine that selects the optimal set of desired contents according to user preferences. Afterwards, the adaptation engine performs the required transformations and compositions of the selected contents for the specific usage environment using our VideoEd Editing and Composition Tool. Finally, two personalization and summarization systems are demonstrated for the IBM Websphere Portal Server and for pervasive PDA devices. (C) 2004 Elsevier Inc. All rights reserved.
C1 IBM Corp, TJ Watson Res Ctr, Hawthorne, NY 10532 USA.
C3 International Business Machines (IBM)
RP IBM Corp, TJ Watson Res Ctr, 19 Skyline Dr, Hawthorne, NY 10532 USA.
EM Belle@ieee.org; chingyung@us.ibm.com; jsmith@us.ibm.com
RI Smith, John/Y-2316-2019; Smith, John/GYJ-1302-2022; Smith,
   John/HJB-2300-2022
OI Smith, John/0000-0001-6885-1117; 
CR AIZAWA K, 2001, SUMMARIZING WEARABLE
   AMIR A, 2000, HAW INT C SYST SCI H
   [Anonymous], 2002, JTC1SC29WG11M8321 IS
   BUTLER MH, 2001, HPL2001190
   GONG Y, 2001, SUMM VID MIN VISU CO
   HAN R, 2001, ACM MULT
   *ISO IEC, 2002, JTCISC29WG11N5354 IS
   *ISO IEC, 2001, JTC1SC29WG11N4242 IS
   Lin C.-Y., 2003, IEEE INT C IM PROC B
   Lin CY, 2015, IEEE INT CONF MULTI
   LIN CY, 2002, IEEE INT C MULT EXP
   MA YF, 2002, INT C IM PROC ROCH
   MANJUNATH BS, 2002, INTRO MPEG 7 MULT CN
   MERIALDO B, 1999, ACM MULTIMEDIA 1999
   SUNDARAM H, 2000, ACM MULTIMEDIA 2000
   Tseng B.L., 2002, SPIE ELECT IMAGING 2
   Tseng B.L., 2002, IEEE MULTIMEDIA SIGN
   TSENG BL, 2003, INT S ITCOM 2003
   YEUNG M, 1995, P SPIE MULTIMEDIA CO, V2417
NR 19
TC 13
Z9 13
U1 0
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2004
VL 15
IS 3
BP 370
EP 392
DI 10.1016/j.jvcir.2004.04.011
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 863WC
UT WOS:000224593100007
DA 2024-07-18
ER

PT J
AU Fan, JY
   Li, JJ
   Ren, L
   Chen, Z
AF Fan, Junyu
   Li, Jinjiang
   Ren, Lu
   Chen, Zheng
TI Multi-scale dynamic fusion for correcting uneven illumination images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Uneven illumination image correction; Multi-scale dynamic fusion;
   Balance factor
ID ADAPTIVE HISTOGRAM EQUALIZATION; REAL-TIME IMAGE; CONTRAST ENHANCEMENT;
   QUALITY ASSESSMENT; NETWORK
AB Images taken under non-ideal lighting conditions often suffer from uneven illumination, resulting in image distortion and unclear details. To address these issues, researchers have developed various methods for image enhancement. However, most of these methods are only applicable to specific types of images, especially those with underexposed exposures. Therefore, to achieve this goal, in this article, we propose a multi -scale dynamic fusion method for correcting uneven illumination images. This method can balance the overall illumination of unevenly illuminated images captured under non-ideal lighting conditions, while maintaining the original brightness contrast and enhancing the image details. We constructed a multi-branch multi-scale fully convolutional neural network, which uses attention mechanisms to focus on the bright and dark areas that need to be processed in the main branch, while the side branch is used to maintain the image's color and naturalness. Extracting features at different scales is beneficial for detail recovery, while a larger receptive field results in better brightness contrast and a more realistic visual experience. Finally, the attention fusion method is used to fuse the features of different branches to obtain the corrected results.
C1 [Fan, Junyu] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang; Ren, Lu; Chen, Zheng] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Chen, Z (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
EM chenzheng@sdtbu.edu.cn
FU National Natural Science Foun-dation of China [61772319, 62002200,
   62202268, 62272281]; Shan-dong Natural Science Foundation of China
   [ZR2023MF026, ZR2021MF107]; Yantai science and technology innovation
   develop-ment plan of China [2022JCYJ031]
FX <B>Acknowledgments</B> This research was supported by the National
   Natural Science Foun-dation of China (61772319, 62002200, 62202268,
   62272281) , Shan-dong Natural Science Foundation of China (ZR2023MF026,
   ZR2021MF107) , Yantai science and technology innovation develop-ment
   plan of China (2022JCYJ031) .
CR Celik T, 2011, IEEE T IMAGE PROCESS, V20, P3431, DOI 10.1109/TIP.2011.2157513
   Cheng J., 2023, IEEE Trans. Circuits Syst. Video Technol., P1
   Dai Q, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11040574
   Dong X., 2010, ACM SIGGRAPH 2010 PO, P1
   Fan GD, 2022, IEEE T CIRC SYST VID, V32, P7403, DOI 10.1109/TCSVT.2022.3186880
   Fan GD, 2024, IEEE T NEUR NET LEAR, V35, P1598, DOI 10.1109/TNNLS.2022.3184164
   Feng RC, 2021, PROC CVPR IEEE, P662, DOI 10.1109/CVPR46437.2021.00072
   Feng XM, 2021, APPL INTELL, V51, P5111, DOI 10.1007/s10489-020-02119-y
   Feng XM, 2020, CAAI T INTELL TECHNO, V5, P128, DOI 10.1049/trit.2019.0065
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo CL, 2019, IEEE T IMAGE PROCESS, V28, P2545, DOI 10.1109/TIP.2018.2887029
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YQ, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103769
   Hou GJ, 2024, IEEE T CIRC SYST VID, V34, P799, DOI 10.1109/TCSVT.2023.3290363
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jiang QP, 2022, IEEE T INTELL TRANSP, V23, P19440, DOI 10.1109/TITS.2022.3165176
   Jiang QP, 2022, IEEE T IMAGE PROCESS, V31, P2279, DOI 10.1109/TIP.2022.3154588
   Jiang Su, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P16, DOI 10.1007/978-3-319-78890-6_2
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Kang YZ, 2023, IEEE T CIRC SYST VID, V33, P988, DOI 10.1109/TCSVT.2022.3208100
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee C, 2012, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2012.6467022
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P9396, DOI 10.1109/TPAMI.2021.3126387
   Li CY, 2021, IEEE T CYBERNETICS, V51, P88, DOI 10.1109/TCYB.2020.2969255
   Li CY, 2019, IEEE T GEOSCI REMOTE, V57, P9156, DOI 10.1109/TGRS.2019.2925070
   Li CY, 2018, IEEE SIGNAL PROC LET, V25, P323, DOI 10.1109/LSP.2018.2792050
   Li CY, 2017, PATTERN RECOGN LETT, V94, P62, DOI 10.1016/j.patrec.2017.05.023
   Li JJ, 2021, IEEE T CIRC SYST VID, V31, P4227, DOI 10.1109/TCSVT.2021.3049940
   Li K., 2022, IEEE Trans. Circuits Syst. Video Technol., P1
   Li Z., 2023, IEEE Trans Geosci Remote Sensing
   Liu JY, 2023, INFORM FUSION, V95, P237, DOI 10.1016/j.inffus.2023.02.027
   Liu RS, 2022, IEEE T IMAGE PROCESS, V31, P4922, DOI 10.1109/TIP.2022.3190209
   Lv F., 2018, P BMVC, V220, P4
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Ma L, 2023, Arxiv, DOI arXiv:2306.01343
   Ma L, 2022, Arxiv, DOI arXiv:2212.14245
   NARENDRA PM, 1981, IEEE T PATTERN ANAL, V3, P655, DOI 10.1109/TPAMI.1981.4767166
   Park J, 2023, J VIS COMMUN IMAGE R, V95, DOI 10.1016/j.jvcir.2023.103863
   Peng W.-Y., 2021, 2021 IEEE INT C CONS, P1
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ren YR, 2019, IEEE T CIRC SYST VID, V29, P968, DOI 10.1109/TCSVT.2018.2828141
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Song X, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103773
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tao L, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Tong K, 2023, J VIS COMMUN IMAGE R, V93, DOI 10.1016/j.jvcir.2023.103830
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei C, 2018, Arxiv, DOI arXiv:1808.04560
   Xiaobin Hu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P763, DOI 10.1007/978-3-030-58548-8_44
   Yan ZC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2790296
   Ying ZQ, 2017, IEEE INT CONF COMP V, P3015, DOI 10.1109/ICCVW.2017.356
   Zhang D., 2023, Expert Systems with Applications
   Zhang TL, 2022, COMPUT VIS MEDIA, V8, P495, DOI 10.1007/s41095-021-0246-4
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhang Z., 2023, J. Vis. Commun. Image Represent.
   Zhou J., 2023, IEEE J. Ocean. Eng.
   Zhou JC, 2023, INT J COMPUT VISION, DOI 10.1007/s11263-023-01853-3
   Zhou JC, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3293912
   Zhou JC, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.105946
   Zhou JC, 2023, ENG APPL ARTIF INTEL, V121, DOI 10.1016/j.engappai.2023.105952
   Zhou JC, 2022, ENG APPL ARTIF INTEL, V111, DOI 10.1016/j.engappai.2022.104785
   Zhou JC, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3170702
   Zhuang PX, 2022, IEEE T IMAGE PROCESS, V31, P5442, DOI 10.1109/TIP.2022.3196546
NR 71
TC 1
Z9 1
U1 7
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103978
DI 10.1016/j.jvcir.2023.103978
EA NOV 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Z4DP6
UT WOS:001111601300001
DA 2024-07-18
ER

PT J
AU Alshami, A
   Boult, T
   Kalita, J
AF Alshami, Ali
   Boult, Terrance
   Kalita, Jugal
TI Pose2Trajectory: Using transformers on body pose to predict tennis
   player's trajectory
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Body joints; Object detection; Human pose estimation
AB Tracking the trajectory of tennis players can help camera operators in production. Predicting future movement enables cameras to automatically track and predict a player's future trajectory without human intervention. It is also intellectually satisfying to predict future human movement in the context of complex physical tasks. Swift advancements in sports analytics and the wide availability of videos for tennis have inspired us to propose a novel method called Pose2Trajectory, which predicts a tennis player's future trajectory as a sequence derived from their body joints' data and ball position. Demonstrating impressive accuracy, our approach capitalizes on body joint information to provide a comprehensive understanding of the human body's geometry and motion, thereby enhancing the prediction of the player's trajectory. We use encoder-decoder Transformer architecture trained on the joints and trajectory information of the players with ball positions. The predicted sequence can provide information to help close-up cameras to keep tracking the tennis player, following centroid coordinates. We generate a high-quality dataset from multiple videos to assist tennis player movement prediction using object detection and human pose estimation methods. It contains bounding boxes and joint information for tennis players and ball positions in singles tennis games. Our method shows promising results in predicting the tennis player's movement trajectory with different sequence prediction lengths using the joints and trajectory information with the ball position.
C1 [Alshami, Ali; Boult, Terrance; Kalita, Jugal] Univ Colorado, 1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918 USA.
C3 University of Colorado System; University of Colorado at Colorado
   Springs
RP Alshami, A (corresponding author), Univ Colorado, 1420 Austin Bluffs Pkwy, Colorado Springs, CO 80918 USA.
EM aalshami@uccs.com; tboult@uccs.edu; jkalita@uccs.edu
OI AlShami, Ali/0000-0002-3705-2651
CR Achaji L, 2022, IEEE INT C INTELL TR, P2457, DOI 10.1109/ITSC55140.2022.9922451
   Aharon N, 2022, Arxiv, DOI [arXiv:2206.14651, DOI 10.48550/ARXIV.2206.14651]
   Alahi A, 2014, PROC CVPR IEEE, P2211, DOI 10.1109/CVPR.2014.283
   Alhami A.K., 2022, Generating Tennis Player by the Predicting Movement Using 2D Pose Estimation
   Amirian J, 2019, IEEE COMPUT SOC CONF, P2964, DOI 10.1109/CVPRW.2019.00359
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bergeron MF, 2006, BRIT J SPORT MED, V40, P406, DOI 10.1136/bjsm.2005.023333
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bracewell Ronald Newbold, 1986, The Fourier transform and its applications, V31999
   Chen W, 2021, ASIAN C MACHINE LEAR, P454
   Cunjun Yu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P507, DOI 10.1007/978-3-030-58610-2_30
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Derpanis Konstantinos G., 2004, York University, V2, P1
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dinc I., 2015, Emerging Trends in Image Processing, Computer Vision and Pattern Recognition, P183, DOI [DOI 10.1016/C2014-0-01692-9, DOI 10.1016/B978-0-12-802045-6.00012-0, 10.1016/C2014-0-01692-9]
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fernando T, 2020, IEEE T KNOWL DATA EN, V32, P1785, DOI 10.1109/TKDE.2019.2911507
   Giles B, 2020, J SPORT SCI, V38, P106, DOI 10.1080/02640414.2019.1684132
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Giuliari F, 2021, INT C PATT RECOG, P10335, DOI 10.1109/ICPR48806.2021.9412190
   Hauri S., 2021, P IEEE CVF WINT C AP, P1640
   Huang YC, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909871
   Kalman R.E., 1960, J BASIC ENG-T ASME, V82, P35, DOI [DOI 10.1115/1.3662552, 10.1115/1.3662552]
   Kazemi S. M., 2019, arXiv, DOI 10.48550/ARXIV.1907.05321
   Kingma D. P., 2014, arXiv
   Kosaraju V, 2019, ADV NEUR IN, V32
   Li C, 2023, arXiv, DOI 10.48550/arXiv.2301.05586
   Li LH, 2022, PROC CVPR IEEE, P2221, DOI 10.1109/CVPR52688.2022.00227
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lindstrom P., 2020, Machine Learning and Data Mining for Sports Analytics, V7, P62
   Liu P, 2022, IEEE COMPUT SOC CONF, P3512, DOI 10.1109/CVPRW56347.2022.00395
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma K, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), P21, DOI 10.1109/SAMI50585.2021.9378695
   Mahdavian M, 2022, Arxiv, DOI arXiv:2209.07600
   McEwen B., Predictive Animal Tracking for Invasive Species Identification and Elimination
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Mora SV, 2017, IEEE COMPUT SOC CONF, P170, DOI 10.1109/CVPRW.2017.27
   Nien-En Sun, 2020, 2020 International Conference on Pervasive Artificial Intelligence (ICPAI), P86, DOI 10.1109/ICPAI51961.2020.00023
   Ning B, 2021, FUTURE GENER COMP SY, V125, P188, DOI 10.1016/j.future.2021.06.022
   Owens N., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P182, DOI 10.1049/cp:20030517
   Pingali G, 2001, IEEE VISUAL, P75, DOI 10.1109/VISUAL.2001.964496
   Polk T, 2020, IEEE T VIS COMPUT GR, V26, P397, DOI 10.1109/TVCG.2019.2934243
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rocha NMS, 2023, SIGNAL IMAGE VIDEO P, V17, P1133, DOI 10.1007/s11760-022-02320-1
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Sheets AL, 2011, ANN BIOMED ENG, V39, P3011, DOI 10.1007/s10439-011-0418-y
   Shrivastava A., 2023, A Unifying Framework for Formal Theories of Novelty: Discussions, Guidelines, and Examples for Artificial Intelligence, P37
   Siciliano B., 2008, SPRINGER HDB ROBOTIC, V200
   Vaswani A, 2017, ADV NEUR IN, V30
   Wei XY, 2016, IEEE T KNOWL DATA EN, V28, P2988, DOI 10.1109/TKDE.2016.2594787
   Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu N, 2020, Arxiv, DOI [arXiv:2001.08317, 10.48550/ARXIV.2001.08317, DOI 10.48550/ARXIV.2001.08317]
   Xu YF, 2022, Arxiv, DOI arXiv:2204.12484
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Zhang HT, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592408
   Zhang YF, 2022, LECT NOTES COMPUT SC, V13682, P1, DOI 10.1007/978-3-031-20047-2_1
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhou L, 2022, IEEE ROBOT AUTOM LET, V7, P7660, DOI 10.1109/LRA.2022.3176064
   Zhu GY, 2007, IEEE T MULTIMEDIA, V9, P1167, DOI 10.1109/TMM.2007.902847
NR 62
TC 1
Z9 1
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2023
VL 97
AR 103954
DI 10.1016/j.jvcir.2023.103954
EA OCT 2023
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA Y3AD1
UT WOS:001104017300001
DA 2024-07-18
ER

PT J
AU Hwang, S
   Han, D
   Jeon, M
AF Hwang, Seongmin
   Han, Daeyoung
   Jeon, Moongu
TI Making depthwise convolution SR-friendly via kernel attention injection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Single image super-resolution (SISR); Linear depthwise convolution;
   Kernel attention; Intra-kernel correlation; Determinant pooling
ID IMAGE SUPERRESOLUTION
AB Despite the remarkable results achieved by deep convolutional neural networks (CNNs) in single image super-resolution (SISR), their computational cost increase exponentially as CNN models get deeper and wider. Consequently, depthwise separable convolutions (DSConvs) have emerged as the fundamental building basis for various contemporary lightweight network architectures. However, depthwise convolution is sub-optimal for restoring missing high-frequency details. In this paper, we commence with the vanilla depthwise convolution and progressively develop it to alleviate the above problem. Specifically, we introduce an effective method, kernel attention injection, to integrate intra-kernel correlation into the depthwise convolution layer by incorporating the learned kernel attention into the depthwise kernel. We find that the determinant is capable of capturing the correlation between diagonal elements of the depthwise kernel by summing the products of the diagonals. Therefore, we utilize the determinant as the kernel pooling method. Furthermore, we propose to remove the non-linear activation function behind the depthwise convolution (i.e., linear depthwise convolution) to preserve informative features for reconstructing faithful high-resolution (HR) images. Built on this recipe, we introduce kernel-attentive linear depthwise separable convolutions (KDSConvs), which exhibits promising super-resolution performance. Our experimental results underline the potential of depthwise convolution in super-resolution tasks by demonstrating that the proposed KDSConvs significantly outperforms DSConvs in terms of both quantitative measurements and visual quality. The code will be released at https: //github.com/AwesomeHwang/KALDN.
C1 [Hwang, Seongmin] Gwangju Inst Sci & Technol GIST, Artificial Intelligence Grad Sch, Gwangju, South Korea.
   [Han, Daeyoung; Jeon, Moongu] Gwangju Inst Sci & Technol GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
C3 Gwangju Institute of Science & Technology (GIST); Gwangju Institute of
   Science & Technology (GIST)
RP Jeon, M (corresponding author), Gwangju Inst Sci & Technol GIST, Sch Elect Engn & Comp Sci, Gwangju, South Korea.
EM sm.hwang@gm.gist.ac.kr; xesta120@gist.ac.kr; mgjeon@gist.ac.kr
OI Jeon, Moongu/0000-0002-2775-7789
FU Institute of Information & communications Technology Planning &
   Evaluation (IITP) of Ministry of Science and ICT (MSIT) [2014-3-00077];
   Korea Creative Content Agency (KOCCA) of Ministry of Culture, Sports,
   and Tourism (MCST) in 2023 [R2022060001]
FX This work was supported by the Institute of Information & communications
   Technology Planning & Evaluation (IITP) of Ministry of Science and ICT
   (MSIT) (No. 2014-3-00077) , and by the Korea Creative Content Agency
   (KOCCA) of Ministry of Culture, Sports, and Tourism (MCST) in 2023 (No.
   R2022060001) .
CR Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chen XY, 2022, Arxiv, DOI arXiv:2205.04437
   Dai T, 2019, PROC CVPR IEEE, P11057, DOI 10.1109/CVPR.2019.01132
   Ding X., 2021, arXiv
   Ding XH, 2022, PROC CVPR IEEE, P11953, DOI 10.1109/CVPR52688.2022.01166
   Ding XH, 2021, PROC CVPR IEEE, P10881, DOI 10.1109/CVPR46437.2021.01074
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Goodfellow I., 2014, arXiv, DOI 10.48550/arXiv.1406.2661
   Haase Daniel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14588, DOI 10.1109/CVPR42600.2020.01461
   Han Qi, 2021, INT C LEARN REPR
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jie Liu, 2020, Proceedings of the 16th European Conference on Computer Vision - ECCV 2020 Workshops. Lecture Notes in Computer Science (LNCS 12537), P41, DOI 10.1007/978-3-030-67070-2_2
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kingma D. P., 2014, arXiv
   Kong FY, 2022, IEEE COMPUT SOC CONF, P765, DOI 10.1109/CVPRW56347.2022.00092
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu J, 2020, PROC CVPR IEEE, P2356, DOI 10.1109/CVPR42600.2020.00243
   Liu SW, 2022, Arxiv, DOI arXiv:2207.03620
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Michelini PN, 2022, IEEE WINT CONF APPL, P4019, DOI 10.1109/WACV51458.2022.00407
   Paszke A., 2017, NIPS W
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Seongmin Hwang, 2020, SMA 2020: The 9th International Conference on Smart Media and Applications, P72, DOI 10.1145/3426020.3426037
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Sifre L., 2014, THESIS, V1, P3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun L., 2022, arXiv
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang Y, 2022, IEEE COMPUT SOC CONF, P776, DOI 10.1109/CVPRW56347.2022.00093
   Zamir SW, 2022, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR52688.2022.00564
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XD, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4034, DOI 10.1145/3474085.3475291
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao H, 2020, COMPUTER VISION ECCV, P56, DOI DOI 10.1007/978-3-030-67070-23
NR 52
TC 1
Z9 1
U1 10
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2023
VL 96
AR 103930
DI 10.1016/j.jvcir.2023.103930
EA SEP 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA T2XS0
UT WOS:001076670700001
DA 2024-07-18
ER

PT J
AU Zhang, ZA
   Guo, JC
   Yue, HH
   Wang, YD
AF Zhang, Zenan
   Guo, Jichang
   Yue, Huihui
   Wang, Yudong
TI Global guidance-based integration network for salient object detection
   in low-light images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low-light images; Salient object detection; Global information flow;
   Multi-level features cross integration; U-shaped attention refinement
ID MULTISCALE
AB Most of current salient object detection (SOD) methods focus on well-lit scenes, and their performance drops when generalized into low-light scenes due to limitations such as blurred boundaries and low contrast. To solve this problem, we propose a global guidance-based integration network (G2INet) customized for low -light SOD. First, we propose a Global Information Flow (GIF) to extract comprehensive global information, for guiding the fusion of multi-level features. To facilitate information integration, we design a Multi-level features Cross Integration (MCI) module, which progressively fuses low-level details, high-level semantics, and global information by interweaving. Furthermore, a U-shaped Attention Refinement (UAR) module is proposed to further refine edges and details for accurate saliency predictions. In terms of five metrics, extensive experimental results demonstrate that our method outperforms the existing twelve state-of-the-art models.
C1 [Zhang, Zenan; Guo, Jichang; Yue, Huihui; Wang, Yudong] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Guo, JC (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM znzhang@tju.edu.cn; jcguo@tju.edu.cn; yuehuihui@tju.edu.cn;
   yudongwang@tju.edu.cn
RI Chen, Bowen/KFB-3986-2024; Guo, Jichang/GQY-5798-2022; Wang,
   Yudong/GQY-6481-2022
OI Guo, Jichang/0000-0003-3130-1685; 
FU National Natural Science Foundation of China [62171315]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 62171315.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen T, 2022, IEEE Trans. Multimed.
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cong RM, 2019, IEEE T IMAGE PROCESS, V28, P4819, DOI 10.1109/TIP.2019.2910377
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fang X, 2022, KNOWL-BASED SYST, V242, DOI 10.1016/j.knosys.2022.108372
   Guo TD, 2021, VISUAL COMPUT, V37, P2069, DOI 10.1007/s00371-020-01964-9
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li HC, 2018, Arxiv, DOI [arXiv:1805.10180, DOI 10.48550/ARXIV.1805.10180]
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P1415, DOI 10.1109/TPAMI.2020.3023152
   Liu Y, 2021, IEEE T IMAGE PROCESS, V30, P3804, DOI 10.1109/TIP.2021.3065239
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo WJ, 2016, ADV NEUR IN, V29
   Ma MC, 2021, AAAI CONF ARTIF INTE, V35, P2311
   Mu N., 2017, P 9 INT C MACHINE LE, P314
   Mu N, 2019, IEEE COMPUT SOC CONF, P743, DOI 10.1109/CVPRW.2019.00102
   Mu N, 2018, LECT NOTES COMPUT SC, V11166, P35, DOI 10.1007/978-3-030-00764-5_4
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Song MK, 2022, IEEE T IMAGE PROCESS, V31, P6124, DOI 10.1109/TIP.2022.3205747
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang Y, 2020, VISUAL COMPUT, V36, P683, DOI 10.1007/s00371-019-01646-1
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu YH, 2022, IEEE T IMAGE PROCESS, V31, P3125, DOI 10.1109/TIP.2022.3164550
   Wu ZY, 2022, IEEE T IMAGE PROCESS, V31, P6649, DOI 10.1109/TIP.2022.3214332
   Xu X., 2018, EUR C COMP VIS
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang SY, 2015, KNOWL-BASED SYST, V82, P128, DOI 10.1016/j.knosys.2015.02.028
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yue HH, 2022, KNOWL-BASED SYST, V257, DOI 10.1016/j.knosys.2022.109938
   Zhang PP, 2021, IEEE T IMAGE PROCESS, V30, P3204, DOI 10.1109/TIP.2020.3045624
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhu L, 2020, IEEE T CIRC SYST VID, V30, P3358, DOI 10.1109/TCSVT.2019.2941017
NR 47
TC 2
Z9 2
U1 3
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD SEP
PY 2023
VL 95
AR 103862
DI 10.1016/j.jvcir.2023.103862
EA JUN 2023
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY5V0
UT WOS:001163093400001
DA 2024-07-18
ER

PT J
AU Brai, R
   Bekhouch, A
   Doghmane, N
   Harize, S
   Kouadria, N
AF Brai, Radhia.
   Bekhouch, Amara
   Doghmane, Noureddine
   Harize, Saliha
   Kouadria, Nasreddine
TI Low calculation cost of HEVC coding unit size based on spatial
   homogeneity detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CU size decision; Complexity reduction; Spatial homogeneity
ID DECISION ALGORITHM; EFFICIENCY; DEPTH; MODE
AB For the same video quality, HEVC gives 25% to 50% bitrate savings, compared to its predecessor the Advanced Video Coding H.264 and thus supports resolutions up to 8 K UHD. However, the reduction in bitrates provided by the HEVC leads to an increase in the computational cost of the encoding operation. This complexity can become a true handicap especially for real-time video streaming and also for VANET (Vehicular Ad-Hoc Network) appli-cations such as traffic safety and Video surveillance. The improvement in the bitrates and also the increase in the calculation cost are due to the use of large and multi-sized coding, prediction and transform blocks. Indeed, the H264 coder is based on structure macroblocks with sizes 4 x 4, 8 x 8 and 16 x 16, while H.265 depends on Coding Tree Units (CTUs), CTUs select sizes 4 x 4, 8 x 8, 16 x 16, 32 x 32 and 64 x 64 blocks. This paper proposes a fast CU (Coding Unit) size decision method to reduce the HEVC calculation cost based on spatial homogeneity. Compared with the HM16.13 benchmark test model, the average coding time is reduced by around 40% for CIF / QCIF video sequences, 35% to 43% for class A, B and C test sequences. These important reductions in coding time are obtained with negligible loss of quality and an average increase in bitrates which does not exceed 0.89% for the three configuration modes (All intra, Random Access and Low Delay).
C1 [Brai, Radhia.] Univ Souk Ahras, Dept Elect Engn, Souk Ahras 41000, Algeria.
   [Bekhouch, Amara] Univ Souk Ahras, Dept Comp Sci, Souk Ahras 41000, Algeria.
   [Doghmane, Noureddine; Harize, Saliha; Kouadria, Nasreddine] Badji Mokhtar Annaba Univ, Fac Engn Sci, Dept Elect, Annaba 23000, Algeria.
C3 Universite de Souk Ahras Mohammed Cherif Messaadia; Universite de Souk
   Ahras Mohammed Cherif Messaadia; Universite Badji Mokhtar - Annaba
RP Brai, R (corresponding author), Univ Souk Ahras, Dept Elect Engn, Souk Ahras 41000, Algeria.
EM radia.berai@univ-soukahras.dz; a.bekhouch@univ-soukahras.dz;
   ndoghmane@univ-annaba.org; shrz.dj@gmail.com;
   nasreddine.kouadria@univ-annaba.org
RI Bekhouch, Amara/KCK-6721-2024
CR Abdellah S, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.6.063015
   Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Ahn YJ, 2016, J REAL-TIME IMAGE PR, V12, P419, DOI 10.1007/s11554-015-0487-5
   [Anonymous], 2018, HM HEVC TEST MODEL
   [Anonymous], 2015, High Efficiency Video Coding: coding tools and specifications
   Bossen F., 2012, JCTVCJ1100, P1
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Ding HQ, 2016, OPTIK, V127, P7155, DOI 10.1016/j.ijleo.2016.05.061
   Elyousfi A., 2017, TEXTURE COMPLEXITY B, DOI [10.1109/ISACV.2017.8054912, DOI 10.1109/ISACV.2017.8054912]
   Elyousfi A, 2013, SIGNAL IMAGE VIDEO P, V7, P53, DOI 10.1007/s11760-011-0232-x
   Fernandez D.G., 2018, FAST EFFECTIVE CU SI, DOI [10.1007/s11042-017-4503-6, DOI 10.1007/S11042-017-4503-6]
   Fernando DAIP, 2016, STUD COMPUT INTELL, V656, P1, DOI 10.1007/978-3-319-40171-3_1
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2321, DOI 10.1109/TMM.2016.2598481
   Goswami K., 2014, ENTROPY DIFFERENCE B, DOI [10.1007/s11554-014-0476-0, DOI 10.1007/S11554-014-0476-0]
   Hamout H, 2020, IEEE T CIRC SYST VID, V30, P1933, DOI 10.1109/TCSVT.2019.2918770
   Hamout H, 2020, SIGNAL IMAGE VIDEO P, V14, P1301, DOI 10.1007/s11760-020-01669-5
   ITU-T, 1999, RECOMMENDATION ITU R
   Jha M.K., 2017, RESTRICTED AFFINE MO
   Kim I., 2013, JCTVCM1002
   Kuang W, 2020, IEEE T IMAGE PROCESS, V29, P170, DOI 10.1109/TIP.2019.2924810
   Lee D, 2018, SIGNAL PROCESS-IMAGE, V62, P33, DOI 10.1016/j.image.2017.12.005
   Liao WH, 2018, SIGNAL PROCESS-IMAGE, V67, P140, DOI 10.1016/j.image.2018.06.003
   Liu Z., 2017, HEVC CODING UNIT DEC, DOI [10.1007/s11042-016-3530-z, DOI 10.1007/S11042-016-3530-Z]
   Liu ZY, 2016, J VIS COMMUN IMAGE R, V38, P474, DOI 10.1016/j.jvcir.2016.03.025
   Maazouz M, 2019, ENG SCI TECHNOL, V22, P706, DOI 10.1016/j.jestch.2018.12.016
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan ZQ, 2014, IEEE IMAGE PROC, P3214, DOI 10.1109/ICIP.2014.7025650
   Saurty K, 2014, INT CONF DIGIT INFO, P247, DOI 10.1109/DICTAP.2014.6821690
   Shang XW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.2.023006
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sun HM, 2017, IEEE T MULTIMEDIA, V19, P2375, DOI 10.1109/TMM.2017.2700629
   Sze V., 2014, HIGH EFFICIENCY VIDE, DOI [10.1007/978-3-319-06895-4, DOI 10.1007/978-3-319-06895-4]
   Westland N, 2019, IEEE IMAGE PROC, P2666, DOI [10.1109/ICIP.2019.8803302, 10.1109/icip.2019.8803302]
   xiph.Org, 2017, DERFS TEST MED COLL
   Yang Z., 2017, FAST INTERFRAME ENCO, DOI [10.1007/s11042-016-4165-9, DOI 10.1007/S11042-016-4165-9]
   Zhang YF, 2013, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2013.13
NR 37
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103819
DI 10.1016/j.jvcir.2023.103819
EA APR 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA G0HH0
UT WOS:000986061300001
DA 2024-07-18
ER

PT J
AU Ou, YJ
   Chen, ZZ
AF Ou, Yangjun
   Chen, Zhenzhong
TI 3D Deformable Convolution Temporal Reasoning network for action
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Action recognition; 3D deformable convolutional network; Reasoning
AB Modeling and reasoning of the interactions between multiple entities (actors and objects) are beneficial for the action recognition task. In this paper, we propose a 3D Deformable Convolution Temporal Reasoning (DCTR) network to model and reason about the latent relationship dependencies between different entities in videos. The proposed DCTR network consists of a spatial modeling module and a temporal reasoning module. The spatial modeling module uses 3D deformable convolution to capture relationship dependencies between different entities in the same frame, while the temporal reasoning module uses Conv-LSTM to reason about the changes of multiple entity relationship dependencies in the temporal dimension. Experiments on the Moments-in-Time dataset, UCF101 dataset and HMDB51 dataset demonstrate that the proposed method outperforms several state-of-the-art methods.
C1 [Ou, Yangjun; Chen, Zhenzhong] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Ou, Yangjun] Wuhan Text Univ, Sch Comp Sci & Artificial Intelligence, Wuhan 430200, Peoples R China.
   [Chen, Zhenzhong] Wuhan Univ, Hubei Luojia Lab, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan Textile University; Wuhan University
RP Chen, ZZ (corresponding author), Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
EM zzchen@whu.edu.cn
RI Chen, Zhenzhong/C-2529-2015
FU National Natural Science Foun-dation of China [62036005]; Special Fund
   of Hubei Luojia Laboratory
FX Acknowledgments This work was supported in part by National Natural
   Science Foun-dation of China (Grant No. 62036005) and the Special Fund
   of Hubei Luojia Laboratory.
CR Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Baradel F, 2018, LECT NOTES COMPUT SC, V11217, P106, DOI 10.1007/978-3-030-01261-8_7
   Boxiao Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10867, DOI 10.1109/CVPR42600.2020.01088
   Bulat A, 2021, ADV NEUR IN
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Diba A, 2018, LECT NOTES COMPUT SC, V11208, P299, DOI 10.1007/978-3-030-01225-0_18
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou JY, 2020, AAAI CONF ARTIF INTE, V34, P10973
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji R., 2020, P IEEE CVF C COMP VI, P10236
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jiang B, 2021, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP42928.2021.9506453
   Jiang P, 2020, AAAI CONF ARTIF INTE, V34, P11109
   Jing LL, 2018, J VIS COMMUN IMAGE R, V52, P58, DOI 10.1016/j.jvcir.2018.01.016
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lee HC, 2019, INT CONF ACOUST SPEE, P3956, DOI 10.1109/ICASSP.2019.8682513
   Leng CJ, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103344
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Materzynska J, 2020, PROC CVPR IEEE, P1046, DOI 10.1109/CVPR42600.2020.00113
   Ming Y, 2021, NEUROCOMPUTING, V450, P362, DOI 10.1016/j.neucom.2021.03.120
   Monfort M, 2020, IEEE T PATTERN ANAL, V42, P502, DOI 10.1109/TPAMI.2019.2901464
   Ou L. Mi, 2022, P IEEECVF C COMPUTER, P20133
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Santoro A, 2017, ADV NEUR IN, V30
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan A. Zisserman, 2014, P ADV NEURAL INFORM
   Song XM, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P239, DOI 10.1145/3240508.3240563
   Soomro K., 2012, CoRR, V2
   Sun C, 2018, LECT NOTES COMPUT SC, V11215, P335, DOI 10.1007/978-3-030-01252-6_20
   Tang J., 2020, COMPUTER VISION ECCV, P71
   Tsai YHH, 2019, PROC CVPR IEEE, P10416, DOI 10.1109/CVPR.2019.01067
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu CY, 2019, PROC CVPR IEEE, P284, DOI 10.1109/CVPR.2019.00037
   Wu JC, 2019, PROC CVPR IEEE, P9956, DOI 10.1109/CVPR.2019.01020
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu H, 2019, PROC CVPR IEEE, P9290, DOI 10.1109/CVPR.2019.00952
   Yang CY, 2020, PROC CVPR IEEE, P588, DOI 10.1109/CVPR42600.2020.00067
   Yifei Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14021, DOI 10.1109/CVPR42600.2020.01404
   Yudistira N, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115731
   Zhang CH, 2021, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR46437.2021.00446
   Zhang JR, 2020, IEEE T IMAGE PROCESS, V29, P5491, DOI 10.1109/TIP.2020.2985219
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou SR, 2019, J VIS COMMUN IMAGE R, V59, P393, DOI 10.1016/j.jvcir.2019.01.029
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zhuo T, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P521, DOI 10.1145/3343031.3351040
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 66
TC 4
Z9 4
U1 4
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2023
VL 93
AR 103804
DI 10.1016/j.jvcir.2023.103804
EA MAR 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA A6TA1
UT WOS:000956414200001
DA 2024-07-18
ER

PT J
AU Wang, YT
   Ke, YZ
   Wang, K
   Guo, J
   Yang, S
AF Wang, Yaoting
   Ke, Yongzhen
   Wang, Kai
   Guo, Jing
   Yang, Shuai
TI Spatial-invariant convolutional neural network for photographic
   composition prediction and automatic correction
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image composition classification; Aesthetic optimization; Space
   invariance; Deep learning
AB "Composition"determines the vividness of the image and its narrative power. Current research on image aesthetics implicitly considers simple composition rules, but no reliable composition classification and image optimization method explicitly considers composition rules. The existing composition classification models are not suitable for snapshots. We propose a composition classification model based on spatial-invariant convolutional neural networks (RSTN) with translation invariance and rotation invariance. It enhances the generalization of the model for snapshots or skewed images. Ultimately, the accuracy of the RSTN model improved by 3% over the Baseline to 90.8762%, and the rotation consistency improved by 16.015%. Furthermore, we classify images into three categories based on their sensitivity to editing: skew-sensitive, translation-sensitive, and non-space-sensitive. We design a set of composition optimization strategies for each composition that can effectively adjust the composition to beautify the image.
C1 [Wang, Yaoting; Ke, Yongzhen; Wang, Kai; Guo, Jing; Yang, Shuai] Tiangong Univ, Sch Comp Sci & technol, Tianjin 300387, Peoples R China.
   [Wang, Yaoting; Ke, Yongzhen; Wang, Kai; Guo, Jing; Yang, Shuai] Tianjin Key Lab Autonomous Intelligence Technol &, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Ke, YZ (corresponding author), Tiangong Univ, Sch Comp Sci & technol, Tianjin 300387, Peoples R China.
EM 1831125497@tiangong.edu.cn; keyongzhen@tiangong.edu.cn;
   wangkai@tiangong.edu.cn; guojing@tiangong.edu.cn;
   yangshuai@tiangong.edu.cn
OI ke, yongzhen/0000-0002-2792-8728; Yang, Shuai/0000-0002-8279-2499
FU National Natural Sci-ence Foundation of China [61771340]; Natural
   Science Foundation of Tianjin, China [18JCYBJC15300]
FX This research was partially supported by National Natural Sci-ence
   Foundation of China [Grant No. 61771340] and Natural Science Foundation
   of Tianjin, China [Grant No. 18JCYBJC15300] .
CR Banerjee S, 2007, IEEE T IMAGE PROCESS, V16, P1807, DOI 10.1109/TIP.2007.898992
   Chang YY, 2009, IEEE I CONF COMP VIS, P2225, DOI 10.1109/ICCV.2009.5459470
   Chen YL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P37, DOI 10.1145/3123266.3123274
   Chian-Li Wen, 2012, 2012 International Conference on Machine Learning and Cybernetics (ICMLC 2012), P1447, DOI 10.1109/ICMLC.2012.6359578
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Fang C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1105, DOI 10.1145/2647868.2654979
   Freeman M., 2017, PHOTOGRAPHERS EYE CO
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2013, IEEE I CONF COMP VIS, P553, DOI 10.1109/ICCV.2013.74
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He SQ, 2018, IEEE T MULTIMEDIA, V20, P496, DOI 10.1109/TMM.2017.2740026
   Hong CY, 2021, PROC CVPR IEEE, P7053, DOI 10.1109/CVPR46437.2021.00698
   Jaderberg M, 2015, ADV NEUR IN, V28
   Kim M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300625
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee JT, 2019, IEEE I CONF COMP VIS, P1191, DOI 10.1109/ICCV.2019.00128
   Lee JT, 2018, J VIS COMMUN IMAGE R, V55, P91, DOI 10.1016/j.jvcir.2018.05.018
   Lee JT, 2017, IEEE I CONF COMP VIS, P3249, DOI 10.1109/ICCV.2017.350
   Li DB, 2018, PROC CVPR IEEE, P8193, DOI 10.1109/CVPR.2018.00855
   Liang Y, 2018, IEEE T VIS COMPUT GR, V24, P2728, DOI 10.1109/TVCG.2017.2764895
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Lu P, 2019, Arxiv, DOI arXiv:1907.01432
   Luo W, 2011, IEEE I CONF COMP VIS, P2206, DOI 10.1109/ICCV.2011.6126498
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mai L, 2016, PROC CVPR IEEE, P497, DOI 10.1109/CVPR.2016.60
   Rawat YS, 2018, IEEE T MULTIMEDIA, V20, P754, DOI 10.1109/TMM.2017.2750420
   Schwarz K, 2018, IEEE WINT CONF APPL, P2048, DOI 10.1109/WACV.2018.00226
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su HH, 2012, IEEE T MULTIMEDIA, V14, P833, DOI 10.1109/TMM.2012.2186123
   Tu Y, 2020, AAAI CONF ARTIF INTE, V34, P12104
   Wang WG, 2017, IEEE I CONF COMP VIS, P2205, DOI 10.1109/ICCV.2017.240
   Wei ZJ, 2018, PROC CVPR IEEE, P5437, DOI 10.1109/CVPR.2018.00570
   Zeng H, 2019, PROC CVPR IEEE, P5942, DOI 10.1109/CVPR.2019.00610
   Zhang J., 2019, P 2019 CHI C HUM FAC, P1
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 36
TC 2
Z9 2
U1 4
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103751
DI 10.1016/j.jvcir.2023.103751
EA JAN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA C5UW0
UT WOS:000962573100001
DA 2024-07-18
ER

PT J
AU Wang, ZY
   Chen, Y
AF Wang, Zhongyue
   Chen, Ying
TI Anomaly detection with dual-stream memory network
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Anomaly detection; Memory network; Optical flow; Memory sharing
ID PREDICTION
AB Anomaly detection is an essential but challenging task. Existing DNN-based approaches tend to ignore the impact of network history state on extracting spatio-temporal correlations between video events. To address this problem, a Dual-Stream Memory Network (DSM-Net) has been proposed. It leverages historical information from the network to create a dual-stream memory module serving as complementary knowledge for the anomaly detection network. The memory module performs writing and reading in the form of a queue of data features. The writing records the historic information of video events through a moving average encoder, and the reading uses optical flow to uncover behavioral patterns in RGB images. Using a memory sharing strategy, the semantic information of the appearance branch and the motion branch can be integrated to reinforce the network. Results demonstrate that the proposed method on various standard datasets performs favorably when compared to existing methods.
C1 [Wang, Zhongyue; Chen, Ying] Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Peoples R China.
C3 Jiangnan University
RP Chen, Y (corresponding author), Jiangnan Univ, Key Lab Adv Proc Control Light Ind, Minist Educ, Wuxi 214122, Peoples R China.
EM chenying@jiangnan.edu.cn
RI Wang, Zhongyue/KPA-3781-2024; Wang, Zhongyue/KPA-3182-2024
OI Wang, Zhongyue/0000-0003-4395-0439; 
CR Cai RC, 2021, AAAI CONF ARTIF INTE, V35, P938
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chang YP, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108213
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Deepak K, 2021, SIGNAL IMAGE VIDEO P, V15, P215, DOI 10.1007/s11760-020-01740-1
   Georgescu M.I., 2021, IEEE T PATTERN ANAL
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Guo AB, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104391
   Hao Y, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108232
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Kaltsa V, 2015, IEEE T IMAGE PROCESS, V24, P2153, DOI 10.1109/TIP.2015.2409559
   Kiran BR, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020036
   Li DH, 2022, PATTERN RECOGN LETT, V156, P183, DOI 10.1016/j.patrec.2022.03.004
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu W, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3023
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu YW, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909850
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Morais R, 2019, PROC CVPR IEEE, P11988, DOI 10.1109/CVPR.2019.01227
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Paszke A, 2019, ADV NEUR IN, V32
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2587, DOI 10.1109/WACV45572.2020.9093417
   Ravanbakhsh M, 2017, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2017.8296547
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabokrou Mohammad, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P56, DOI 10.1109/CVPRW.2015.7301284
   Shin W, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500343
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Sun C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P184, DOI 10.1145/3394171.3413887
   Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197
   Wang XZ, 2022, IEEE T NEUR NET LEAR, V33, P2301, DOI 10.1109/TNNLS.2021.3083152
   Xiankai Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P661, DOI 10.1007/978-3-030-58580-8_39
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu M., 2021, P ADV NEUR INF PROC
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yan SY, 2020, IEEE T COGN DEV SYST, V12, P30, DOI 10.1109/TCDS.2018.2883368
   Ye MC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1805, DOI 10.1145/3343031.3350899
   Yu G, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P583, DOI 10.1145/3394171.3413973
   Zhai SF, 2016, PR MACH LEARN RES, V48
   Zhang Q, 2022, MULTIMED TOOLS APPL, P1
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhou JT, 2020, IEEE T CIRC SYST VID, V30, P4639, DOI 10.1109/TCSVT.2019.2962229
   Zhou JT, 2019, IEEE T INF FOREN SEC, V14, P2537, DOI 10.1109/TIFS.2019.2900907
NR 52
TC 3
Z9 3
U1 7
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103739
DI 10.1016/j.jvcir.2022.103739
EA JAN 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 8H1ZM
UT WOS:000920835300001
DA 2024-07-18
ER

PT J
AU Li, XF
   Wang, WW
   Feng, XC
   Qi, TT
AF Li, Xiaofang
   Wang, Weiwei
   Feng, Xiangchu
   Qi, Tingting
TI Cartoon-Texture decomposition with patch-wise decorrelation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Cartoon-Texture decomposition; Patch-wise cosine similarity; Total
   variation
ID TOTAL VARIATION MINIMIZATION; IMAGE DECOMPOSITION; VARIATIONAL MODEL
AB Cartoon-Texture decomposition (CTD) is a fundamental task and has wide applications in image processing and computer vision. To enhance separation of the cartoon and texture, existing models explicitly introduce correlation terms to decorrelate the two components. However, existing correlations usually ignore the local geometric structure information, thus insufficient to decorrelate cartoon and texture. In this work, we propose the patch-wise cosine similarity to decorrelate the cartoon and texture. The proposed decorrelation term takes the local geometric information into account and is more effective in separating cartoon and texture. Combining our decorrelation term with the regularities for cartoon (Relative Total Variation (RTV)) and texture (div(L1)-norm), we propose a new CTD model. Extended experiments show that the proposed model outperforms existing methods in CTD, especially in preserving edges of the cartoon.
C1 [Li, Xiaofang; Wang, Weiwei; Feng, Xiangchu; Qi, Tingting] Xidian Univ, Sch Math & Stat, Xian 710071, Peoples R China.
C3 Xidian University
RP Wang, WW (corresponding author), Xidian Univ, Sch Math & Stat, Xian 710071, Peoples R China.
EM xfli_96@stu.xidian.edu.cn; wwwang@mail.xidian.edu.cn;
   xcfeng@mail.xidian.edu.cn; ttqi@stu.xidian.edu.cn
RI wang, weiwei/AAI-2245-2020
OI Li, Xiaofang/0000-0001-8382-9487
FU National Natural Science Foundation of China; Natural Science Foundation
   of Guangdong Province; Natural Science Foundation of Shenzhen; 
   [61972264];  [62072312];  [61971005];  [2019A1515010894]; 
   [20200807165235002]
FX Acknowledgments The authors would like to thank the editors and the
   anonymous re-viewers for their constructive comments and suggestions.
   This paper is supported by the National Natural Science Foundation of
   China (Grant Nos. 61972264, 62072312, 61971005) , Natural Science
   Foundation of Guangdong Province (Grant No. 2019A1515010894) and Natural
   Science Foundation of Shenzhen (20200807165235002) .
CR Aujol JF, 2005, LECT NOTES COMPUT SC, V3752, P85
   Aujol JF, 2003, LECT NOTES COMPUT SC, V2695, P297
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chen PY, 2014, SIGNAL PROCESS, V94, P476, DOI 10.1016/j.sigpro.2013.06.011
   Duan JM, 2016, DIGIT SIGNAL PROCESS, V49, P162, DOI 10.1016/j.dsp.2015.10.010
   Kim Y, 2019, IEEE T IMAGE PROCESS, V28, P2692, DOI 10.1109/TIP.2018.2889531
   Li M, 2021, NEUROCOMPUTING, V458, P639, DOI 10.1016/j.neucom.2019.11.123
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Liu QG, 2013, IEEE I CONF COMP VIS, P1081, DOI 10.1109/ICCV.2013.138
   Liu XW, 2020, SIGNAL IMAGE VIDEO P, V14, P305, DOI 10.1007/s11760-019-01558-6
   Liu XW, 2018, IEEE SIGNAL PROC LET, V25, P1221, DOI 10.1109/LSP.2018.2850218
   Liu YP, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108037
   Ma TH, 2016, INFORM SCIENCES, V328, P510, DOI 10.1016/j.ins.2015.08.039
   Meyer Y., 2001, Memoirs of the American Mathematical Society
   Ng MK, 2013, IEEE T IMAGE PROCESS, V22, P2233, DOI 10.1109/TIP.2013.2246520
   Ono S, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2299067
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Patel V., 2016, BRIT MACHINE VISION, P1
   Peyré G, 2010, SIAM J IMAGING SCI, V3, P646, DOI 10.1137/090770783
   Riya, 2022, DIGIT SIGNAL PROCESS, V123, DOI 10.1016/j.dsp.2022.103386
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schaeffer H, 2013, SIAM J IMAGING SCI, V6, P226, DOI 10.1137/110854989
   Shahidi R, 2009, IEEE T IMAGE PROCESS, V18, P299, DOI 10.1109/TIP.2008.2008046
   Starck J. L., 2005, P SPIE, V5914
   Starck JL, 2005, IEEE T IMAGE PROCESS, V14, P1570, DOI 10.1109/TIP.2005.852206
   Starck JL, 2004, ADV IMAG ELECT PHYS, V132, P287, DOI 10.1016/S1076-5670(04)32006-9
   Sur F, 2019, IEEE T IMAGE PROCESS, V28, P1882, DOI 10.1109/TIP.2018.2881906
   Valkealahti K, 1998, IEEE T PATTERN ANAL, V20, P90, DOI 10.1109/34.655653
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JL, 2020, IEEE ACCESS, V8, P46574, DOI 10.1109/ACCESS.2020.2978011
   Xu L, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366158
   Xu RT, 2021, IEEE T IMAGE PROCESS, V30, P1542, DOI 10.1109/TIP.2020.3043665
   Xu RT, 2020, SIAM J IMAGING SCI, V13, P1179, DOI 10.1137/19M128898X
   Yin WT, 2005, LECT NOTES COMPUT SC, V3752, P73
   Zhang Z, 2021, Image Commun., V96
   Zhou F, 2020, IEEE T IMAGE PROCESS, V29, P3458, DOI 10.1109/TIP.2019.2961232
NR 38
TC 0
Z9 0
U1 1
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103726
DI 10.1016/j.jvcir.2022.103726
EA DEC 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7S7KZ
UT WOS:000910932100001
DA 2024-07-18
ER

PT J
AU Parihar, AS
   Java, A
AF Parihar, Anil Singh
   Java, Abhinav
TI Densely connected convolutional transformer for single image dehazing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image Dehazing; Transformers; Attention
ID VISIBILITY
AB Image Dehazing is an important low-level vision task that aims to remove the haze from an image. In this paper, we proposed Densely Connected Convolutional Transformer (DCCT) for single image dehazing. DCCT is an efficient architecture that combines the multi-head Performer with the local dependencies. To prevent loss of information between features at different levels, we propose a learnable connection layer that is used to fuse features at different levels across the entire architecture. We guide the training of DCCT through a joint loss considering a supervised metric learning approach that allows us to consider both negative and positive features for a multi-image perceptual loss. We validate the design choices and the effectiveness of the proposed DCCT through ablation studies. Through comparison with the representative techniques, we establish that the proposed DCCT is highly competitive with the state of the art.
C1 [Parihar, Anil Singh; Java, Abhinav] Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
C3 Delhi Technological University
RP Parihar, AS (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Machine Learning Res Lab, Delhi, India.
EM parihar.anil@gmail.com
RI Parihar, Anil Singh/Z-4992-2019
OI Parihar, Anil Singh/0000-0001-5339-8671
CR Ancuti C.O., 2019, IEEE INT C IMAGE PRO
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P2029, DOI 10.1109/CVPRW50498.2020.00253
   Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Baffour AA, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103368
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Choromanski K., 2021, INT C LEARN REPR ICL
   Das SD, 2020, IEEE COMPUT SOC CONF, P1994, DOI 10.1109/CVPRW50498.2020.00249
   Dauphin YN, 2017, PR MACH LEARN RES, V70
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P2453, DOI 10.1109/ICCV.2019.00254
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dong Y, 2020, AAAI CONF ARTIF INTE, V34, P10729
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Elharrouss O, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103116
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fourure D., 2017, RESIDUAL CONV DECONV, DOI [10.5244/C.31.181, DOI 10.5244/C.31.181]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gulati A, 2020, INTERSPEECH, P5036, DOI 10.21437/Interspeech.2020-3015
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Huang GL, 2017, IEEE ICC
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876
   Khosla P., 2020, ADV NEURAL INF PROCE, V33, P18661
   Kim W, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103364
   Kingma D. P., 2014, arXiv
   Lan Z., 2019, ARXIV190911942, DOI DOI 10.48550/ARXIV.1909.11942
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu XJ, 2019, IEEE I CONF COMP VIS, P2611, DOI 10.1109/ICCV.2019.00270
   Liu Y, 2022, J VIS COMMUN IMAGE R, V83, DOI 10.1016/j.jvcir.2021.103434
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Malav R, 2019, LECT NOTES COMPUT SC, V11365, P593, DOI 10.1007/978-3-030-20873-8_38
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Mehra A, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103137
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   NOSOFSKY RM, 1986, J EXP PSYCHOL GEN, V115, P39, DOI 10.1037/0096-3445.115.1.39
   Paszke A, 2019, ADV NEUR IN, V32
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Ren WQ, 2018, PROC CVPR IEEE, P3253, DOI 10.1109/CVPR.2018.00343
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Rohilla H., 2020, LOW LIGHT IMAGE ENHA, V29, P4481
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sanh V, 2020, Arxiv, DOI arXiv:1910.01108
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103241
   Steiner A, 2022, Arxiv, DOI arXiv:2106.10270
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Taghanaki SA, 2019, LECT NOTES COMPUT SC, V11861, P417, DOI 10.1007/978-3-030-32692-0_48
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CQ, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103414
   Wang Q, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103260
   Wang SN, 2020, Arxiv, DOI arXiv:2006.04768
   Wang Y, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102953
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Wu Z., 2020, ICLR
   Xiao DG, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103373
   Xie SR, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102770
   Yang HH, 2020, INT CONF ACOUST SPEE, P2628, DOI [10.1109/ICASSP40776.2020.9053920, 10.1109/icassp40776.2020.9053920]
   Yang Z, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103245
   Ye Liu, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P50, DOI 10.1145/3474085.3475331
   Yuan FN, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108076
   Zhan Y, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103253
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103170
   Zhang Q, 2021, J VIS COMMUN IMAGE R, V81, DOI 10.1016/j.jvcir.2021.103350
   Zhou HC, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102655
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu X., 2021, INT C LEARNING REPRE
NR 77
TC 7
Z9 8
U1 2
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103722
DI 10.1016/j.jvcir.2022.103722
EA DEC 2022
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 7M8UE
UT WOS:000906925600001
DA 2024-07-18
ER

PT J
AU Latorre-Carmona, P
   Huertas, R
   Pedersen, M
   Morillas, S
AF Latorre-Carmona, Pedro
   Huertas, Rafael
   Pedersen, Marius
   Morillas, Samuel
TI Proposal of a new fidelity measure between computed image quality and
   observers quality scores accounting for scores variability?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE STRESS; Psycophysics; Image quality metric; Evaluation
ID SIMILARITY
AB Assessment of the visual quality of colour images is usually a difficult process, validated through hard-to -carry-out psychophysical experiments, used to record observer quality scores. Visual image quality metrics aim to maximise the agreement between computed indexes and observer scores, or opinions. Therefore, in this area, it is of critical importance to have appropriate measures of this agreement (i.e. performance) between the computed image quality metric values and observer's quality scores, both for the development, as well as for the use of image quality metrics. Among the measures of agreement, the most used one nowadays is the well-known Pearson correlation coefficient, while Spearman rank correlation coefficient is also commonly used. The aim of this paper is two-fold. First, to introduce the Standardised Residual Sum of Squares (STRESS) as an alternative metric for the agreement between computed image quality and observers quality scores and analyse its properties and advantages in front of Pearson, Spearman and Kendall correlation coefficients; Second, to introduce a new version of STRESS (called UST RESS) that takes observers' scores variability into account. The results on synthetic and real datasets support that STRESS has a series of benefits in front of the classical approaches and that the inclusion of uncertainty in STRESS has an important effect on the results, quantified by statistical significance tests. A free to download MATLAB code version of UST RESS is available at https://viplab.webs.upv.es/resources/
C1 [Latorre-Carmona, Pedro] Univ Burgos, Dept Ingn Informat, Burgos, Spain.
   [Huertas, Rafael] Univ Granada, Dept Opt, Granada, Spain.
   [Pedersen, Marius] Norwegian Univ Sci & Technol, Dept Comp Sci, Colourlab, Trondheim, Norway.
   [Morillas, Samuel] Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Valencia, Spain.
C3 Universidad de Burgos; University of Granada; Norwegian University of
   Science & Technology (NTNU); Universitat Politecnica de Valencia
RP Latorre-Carmona, P (corresponding author), Univ Burgos, Dept Ingn Informat, Burgos, Spain.
EM plcarmona@ubu.es; rhuertas@ugr.es; marius.pedersen@ntnu.no;
   smorillas@mat.upv.es
OI Latorre Carmona, Pedro/0000-0001-6984-5173
FU Generalitat Valenciana [AICO-2020-136, FIS2017-89258-P]; Ministerio de
   Economia, Industria y Competitividad; European Union FEDER (European
   Regional Development Funds); Research Council of Norway [324663]
FX S. Morillas and R. Huertas acknowledge the support of Generalitat
   Valenciana under grant AICO-2020-136. R. Huertas acknowledges the
   support under the research project FIS2017-89258-P ("Ministerio de
   Economia, Industria y Competitividad", "Agencia Estatal de
   Investigacion", Spain) along with the European Union FEDER (European
   Regional Development Funds) support. M. Pedersen acknowledges the
   support of the Research Council of Norway through the project "Quality
   and Content: understanding the influence of content on subjective and
   objective image quality assessment" (project number 324663) .
CR [Anonymous], 2004, OBJ PERC ASS VID QUA
   Brereton RG, 2015, J CHEMOMETR, V29, P143, DOI 10.1002/cem.2692
   Brereton RG, 2015, J CHEMOMETR, V29, P9, DOI 10.1002/cem.2680
   Coxon A.P. M., 1982, USERS GUIDE MULTIDIM
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   De Maesschalck R, 2000, CHEMOMETR INTELL LAB, V50, P1, DOI 10.1016/S0169-7439(99)00047-7
   Fairchild MD, 2004, J ELECTRON IMAGING, V13, P126, DOI 10.1117/1.1635368
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Fisher R. A., 1922, PHILOS T R SOC A, V222, P309, DOI 10.1098/rsta.1922.0009
   García PA, 2007, J OPT SOC AM A, V24, P1823, DOI 10.1364/JOSAA.24.001823
   Ghadiyaram D, 2017, J VISION, V17, DOI 10.1167/17.1.32
   Grecova S, 2016, J VIS COMMUN IMAGE R, V34, P230, DOI 10.1016/j.jvcir.2015.04.003
   Hassan M., 2012, International Journal of Computer Applications, V43, P7
   Hosu V, 2020, IEEE T IMAGE PROCESS, V29, P4041, DOI 10.1109/TIP.2020.2967829
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Li CJ, 2017, COLOR RES APPL, V42, P703, DOI 10.1002/col.22131
   Liu XW, 2014, LECT NOTES COMPUT SC, V8509, P193, DOI 10.1007/978-3-319-07998-1_22
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   Mclachlan G.J., 1999, Mahalanobis Distance
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Pedersen M, 2011, FOUND TRENDS COMPUT, V7, P1, DOI 10.1561/0600000037
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Safdar M, 2017, OPT EXPRESS, V25, P15131, DOI 10.1364/OE.25.015131
   Scopus, ABOUT US
   Seely JF, 1997, AM STAT, V51, P55, DOI 10.2307/2684696
   Sheikh H.R., Live Image Quality Assessment Database
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Venkatanath N, 2015, NATL CONF COMMUN
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu QB, 2018, IEEE T IMAGE PROCESS, V27, P2499, DOI 10.1109/TIP.2018.2799331
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 39
TC 0
Z9 0
U1 0
U2 0
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2023
VL 90
AR 103704
DI 10.1016/j.jvcir.2022.103704
EA DEC 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA E5HS0
UT WOS:000975855200001
DA 2024-07-18
ER

PT J
AU Zhu, HC
   Zhou, Y
   Li, QY
   Shao, ZW
AF Zhu, Hancheng
   Zhou, Yong
   Li, Qiaoyue
   Shao, Zhiwen
TI Personality modeling from image aesthetic attribute-aware graph
   representation learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Social media; Personality modeling; Image aesthetics; Attribute-aware
   graph; Convolutional neural network
ID DEPRESSION; TRAITS
AB Recently, inferring users' personality traits on social media has attracted extensive attention. Existing studies have shown that users' personality traits can be inferred from their preferences for images. However, since users' preferences on images are often affected by multiple factors, some liked images cannot effectively reflect their personality traits. To handle this issue, this paper proposes a personality modeling approach based on image aesthetic attribute-aware graph representation learning, which can leverage aesthetic attributes to refine the liked images that are consistent with users' personality traits. Specifically, we first utilize a Convolutional Neural Network (CNN) to train an aesthetic attribute prediction module. Then, attribute-aware graph representation learning is introduced to refine the images with similar aesthetic attributes from users' liked images. Finally, the aesthetic attributes of all refined images are combined to predict personality traits through a Multi-Layer Perceptron (MLP). Experimental results and visual analysis have shown that the proposed method is superior to state-of-the-art personality modeling methods.
C1 [Zhu, Hancheng; Zhou, Yong; Shao, Zhiwen] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
   [Zhu, Hancheng; Zhou, Yong; Shao, Zhiwen] Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Peoples R China.
   [Li, Qiaoyue] Suzhou City Univ, Dept Optoelect & Energy Engn, Suzhou 215104, Peoples R China.
C3 China University of Mining & Technology; Suzhou City University
RP Zhou, Y (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Peoples R China.
EM yzhou@cumt.edu.cn
RI Shao, Zhiwen/N-8985-2018
FU National Natural Science Founda-tion of China; Natural Science
   Foundation of Jiangsu Province; China Postdoctoral Science Foundation;
   Fundamental Research Funds for the Central Universities; National
   Natural Sci-ence Foundation of China; High-Level Talent Program for
   Innovation and Entrepreneurship (ShuangChuang Doc-tor) of Jiangsu
   Province; Six Talent Peaks High-level Talents in Jiangsu Province; 
   [62101555];  [BK20201346];  [2022M713379];  [2021QN1071];  [62272461]; 
   [62106268];  [JSSCBS20211220];  [2015-DZXX-010]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China (62101555) , the Natural Science Foundation of
   Jiangsu Province (BK20210488) , the Project funded by China Postdoctoral
   Science Foundation (2022M713379) , the Fundamental Research Funds for
   the Central Universities (2021QN1071) , the National Natural Sci-ence
   Foundation of China (62272461, 62106268) , the Natural Science
   Foundation of Jiangsu Province (BK20201346) , the High-Level Talent
   Program for Innovation and Entrepreneurship (ShuangChuang Doc-tor) of
   Jiangsu Province (JSSCBS20211220) , and the Six Talent Peaks High-level
   Talents in Jiangsu Province (2015-DZXX-010) .
CR Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Cristani M., 2013, P 21 ACM INT C MULT, P213
   Gelli F, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2263, DOI 10.1145/3343031.3350574
   Guntuku Sharath Chandra, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P171, DOI 10.1007/978-3-319-14442-9_15
   Guntuku SC, 2018, IEEE T AFFECT COMPUT, V9, P130, DOI 10.1109/TAFFC.2016.2581168
   Guntuku SC, 2017, CURR OPIN BEHAV SCI, V18, P43, DOI 10.1016/j.cobeha.2017.07.005
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kao YY, 2017, IEEE T IMAGE PROCESS, V26, P1482, DOI 10.1109/TIP.2017.2651399
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li LD, 2020, IEEE T IMAGE PROCESS, V29, P3898, DOI 10.1109/TIP.2020.2968285
   Liu X, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102833
   Ma S, 2017, PROC CVPR IEEE, P722, DOI 10.1109/CVPR.2017.84
   Moreno-Armendáriz MA, 2020, IEEE ACCESS, V8, P201649, DOI 10.1109/ACCESS.2020.3034639
   Oshio A, 2018, PERS INDIV DIFFER, V127, P54, DOI 10.1016/j.paid.2018.01.048
   Qayyum H, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102672
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Ren J, 2017, IEEE I CONF COMP VIS, P638, DOI 10.1109/ICCV.2017.76
   Segalin C, 2017, IEEE T AFFECT COMPUT, V8, P268, DOI 10.1109/TAFFC.2016.2516994
   Segalin C, 2017, COMPUT VIS IMAGE UND, V156, P34, DOI 10.1016/j.cviu.2016.10.013
   She DY, 2021, PROC CVPR IEEE, P8471, DOI 10.1109/CVPR46437.2021.00837
   Shi-Xue Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9696, DOI 10.1109/CVPR42600.2020.00972
   Shu YY, 2020, NEUROCOMPUTING, V404, P304, DOI 10.1016/j.neucom.2020.04.142
   Shuster K, 2019, PROC CVPR IEEE, P12508, DOI 10.1109/CVPR.2019.01280
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Srinivas U, 2013, IEEE GEOSCI REMOTE S, V10, P505, DOI 10.1109/LGRS.2012.2211858
   Taib R, 2020, ACM T INTERACT INTEL, V10, DOI 10.1145/3357459
   Vinciarelli A, 2014, IEEE T AFFECT COMPUT, V5, P273, DOI 10.1109/TAFFC.2014.2330816
   Wang K, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2019.102735
   Wang QX, 2018, J VIS COMMUN IMAGE R, V57, P228, DOI 10.1016/j.jvcir.2018.11.003
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Zhang ZM, 2021, IEEE T IMAGE PROCESS, V30, P8265, DOI 10.1109/TIP.2021.3113791
   Zhu HC, 2023, IEEE T MULTIMEDIA, V25, P179, DOI 10.1109/TMM.2021.3123468
   Zhu HC, 2022, PATTERN RECOGN LETT, V155, P84, DOI 10.1016/j.patrec.2022.02.008
   Zhu HC, 2020, NEURAL PROCESS LETT, V51, P2105, DOI 10.1007/s11063-019-09987-7
   Zhu HC, 2018, PATTERN RECOGN LETT, V116, P121, DOI 10.1016/j.patrec.2018.09.027
NR 40
TC 2
Z9 2
U1 3
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103675
DI 10.1016/j.jvcir.2022.103675
EA NOV 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 6E0HJ
UT WOS:000883066600007
DA 2024-07-18
ER

PT J
AU Li, ZH
   Cui, GM
   Zhao, JF
   Xiang, QL
   He, BT
AF Li, Zihan
   Cui, Guangmang
   Zhao, Jufeng
   Xiang, Qinlei
   He, Bintao
TI Joint strong edge and multi-stream adaptive fusion network for
   non-uniform image deblurring
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Non-uniform motion deblurring; Attention mechanisms; Edge extraction
   algorithm; Generative adversarial network
AB Non-uniform motion deblurring has been a challenging problem in the field of computer vision. Currently, deep learning-based deblurring methods have made promising achievements. In this paper, we propose a new joint strong edge and multi-stream adaptive fusion network to achieve non-uniform motion deblurring. The edge map and the blurred map are jointly used as network inputs and Edge Extraction Network (EEN) guides the Deblurring Network (DN) for image recovery and to complement the important edge information. The Multi -stream Adaptive Fusion Module (MAFM) adaptively fuses the edge information and features from the encoder and decoder to reduce feature redundancy to avoid image artifacts. Furthermore, the Dense Attention Feature Extraction Module (DAFEM) is designed to focus on the severely blurred regions of blurry images to obtain important recovery information. In addition, an edge loss function is added to measure the difference of edge features between the generated and clear images to further recover the edges of the deblurred images. Experi-ments show that our method outperforms currently public methods in terms of PSNR, SSIM and VIF, and gen-erates images with less blur and sharper edges.
C1 [Li, Zihan; Cui, Guangmang; Zhao, Jufeng; Xiang, Qinlei; He, Bintao] Hangzhou Dianzi Univ, Inst Carbon Neutral & New Energy, Sch Elect & Informat, Hangzhou 310018, Peoples R China.
   [Cui, Guangmang; Zhao, Jufeng] Hangzhou Dianzi Univ, Zhejiang Prov Key Lab Equipment Elect, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University
RP Cui, GM (corresponding author), Hangzhou Dianzi Univ, Inst Carbon Neutral & New Energy, Sch Elect & Informat, Hangzhou 310018, Peoples R China.
EM cuigm@hdu.edu.cn
OI Cui, Guangmang/0000-0001-9821-8179
FU Zhejiang Provincial Natural Science Foundation of China [LGF20F050003,
   LY22F050002]; National Natural Science Foundation of China [61805063];
   Zhejiang association for science and technology YuCai project
   [SKX201901]; Graduate Scientific Research Foundation of Hangzhou Dianzi
   University and Research Project of Zhejiang Province Department of
   Education [Y202249843]
FX This work was supported by Zhejiang Provincial Natural Science
   Foundation of China under Grant Nos. LGF20F050003 and LY22F050002 and
   the National Natural Science Foundation of China under Grant No.
   61805063. This work was partly supported by Zhejiang association for
   science and technology YuCai project (Grant No. SKX201901). This work
   was also supported by the Graduate Scientific Research Foundation of
   Hangzhou Dianzi University and Research Project of Zhejiang Province
   Department of Education under Grant No. Y202249843.
CR [Anonymous], 2020, IEEE ACCESS, DOI DOI 10.1016/J.IMAGE.2020.115952
   Arevalo J, 2020, NEURAL COMPUT APPL, V32, P10209, DOI 10.1007/s00521-019-04559-1
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chakrabarti A, 2016, LECT NOTES COMPUT SC, V9907, P221, DOI 10.1007/978-3-319-46487-9_14
   Chen L, 2021, INFORM SCIENCES, V546, P368, DOI 10.1016/j.ins.2020.08.105
   Chen Y, 2021, IEEE ACCESS, V9, P65638, DOI 10.1109/ACCESS.2021.3076241
   Chen ZM, 2019, INT CONF ACOUST SPEE, P1463, DOI [10.1109/icassp.2019.8683728, 10.1109/ICASSP.2019.8683728]
   Cho S, 2011, IEEE I CONF COMP VIS, P495, DOI 10.1109/ICCV.2011.6126280
   Cui JK, 2020, NEUROCOMPUTING, V383, P39, DOI 10.1016/j.neucom.2019.11.063
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta A, 2010, LECT NOTES COMPUT SC, V6311, P171, DOI 10.1007/978-3-642-15549-9_13
   Hosseinpour H, 2022, ISPRS J PHOTOGRAMM, V184, P96, DOI 10.1016/j.isprsjprs.2021.12.007
   Hu D., 2021, VISUAL COMPUT, P1, DOI DOI 10.1007/S00371-021-02329-6
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim TH, 2013, IEEE I CONF COMP VIS, P3160, DOI 10.1109/ICCV.2013.392
   Kumar J., 2021, ARXIV211115438
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Levin A, 2009, PROC CVPR IEEE, P1964, DOI 10.1109/CVPRW.2009.5206815
   Li J, 2018, PROC EUR C COMPUT VI, V11212, P517, DOI 10.1007/978-3-030-01237-3_32
   Li LRH, 2018, PROC CVPR IEEE, P6616, DOI 10.1109/CVPR.2018.00692
   Li YW, 2021, J VIS COMMUN IMAGE R, V78, DOI 10.1016/j.jvcir.2021.103149
   Liu J, 2019, IEEE ACCESS, V7, P6186, DOI 10.1109/ACCESS.2018.2888885
   Nah S, 2019, IEEE COMPUT SOC CONF, P1996, DOI 10.1109/CVPRW.2019.00251
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372
   Quan T.M., 2016, FRONTIERS COMPUTER S
   Rares A, 2005, IEEE T IMAGE PROCESS, V14, P1454, DOI 10.1109/TIP.2005.854466
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu CD, 2020, IET IMAGE PROCESS, V14, P2588, DOI 10.1049/iet-ipr.2018.5716
   Xu L., 2010, LECT NOTES COMPUT SC, DOI 10.1007/ 978-3-642-15549-9_12
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Xu M., 2021, ARXIV210706536
   Zhang JW, 2018, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2018.00267
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao HT, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102921
   Zheng S, 2019, IEEE SIGNAL PROC LET, V26, P1546, DOI 10.1109/LSP.2019.2939752
NR 52
TC 1
Z9 1
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2022
VL 89
AR 103663
DI 10.1016/j.jvcir.2022.103663
EA OCT 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 5V0YU
UT WOS:000876964800001
DA 2024-07-18
ER

PT J
AU Fu, ZX
   Fang, LG
   Huang, HY
   Yu, B
AF Fu, Zhengxin
   Fang, Liguo
   Huang, Hangying
   Yu, Bin
TI Distributed three-level QR codes based on visual cryptography scheme
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Three -level QR code; Visual cryptography scheme; Multiple formats
AB Owing to the large storage and fast machine recognition, QR codes have been widely utilized in many fields such as mobile payment, website navigation and user identity authentication. However, any QR code reader can access to the message contained in the QR code, the security becomes a major challenge to QR codes for privacy usage scenarios. Moreover, the management of QR codes for users are also inconvenient, since the human vision is hard to distinguish a QR code from the others. To solve the security and management problems, we propose the three-level QR codes for a group of participants. The first-level management information and the second-level public information are recognizable for the human vision and QR code reader device, respectively. The thirdlevel privacy information is protected using visual cryptography scheme, and can be decoded using simple and non-cryptography computations. Furthermore, the shares can be stored or transferred in not only e-format but also print-format and photo-format, leading to the broad applicability. Experimental results and analysis demonstrate that the proposed scheme can encode three-level information into several distributed QR codes, and has more advantages compared with the previous schemes.
C1 [Fu, Zhengxin; Fang, Liguo; Huang, Hangying; Yu, Bin] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
C3 PLA Information Engineering University
RP Fu, ZX (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Peoples R China.
EM fzx2515@163.com
RI Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942; Huang, Hangying/0000-0001-8475-3146
FU National Natural Science Foundation of China [61602513]
FX The authors thank the anonymous reviewers for their valuable comments.
   This work was supported by the National Natural Science Foundation of
   China under Grant No.61602513.
CR [Anonymous], 2000, 18004 ISO IEC
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chou GJ, 2020, IEEE SIGNAL PROC LET, V27, P1230, DOI 10.1109/LSP.2020.3006375
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Fu ZX, 2019, MEASUREMENT, V141, P267, DOI 10.1016/j.measurement.2019.03.080
   Fu ZX, 2014, MULTIMED TOOLS APPL, V73, P1177, DOI 10.1007/s11042-013-1625-3
   Lin PY, 2016, IEEE T IND INFORM, V12, P384, DOI 10.1109/TII.2015.2514097
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Tan LD, 2020, MULTIMED TOOLS APPL, V79, P5719, DOI 10.1007/s11042-019-08351-0
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wan S, 2018, J REAL-TIME IMAGE PR, V14, P25, DOI 10.1007/s11554-017-0678-3
   Wang GY, 2016, MULTIMED TOOLS APPL, V75, P1223, DOI 10.1007/s11042-014-2365-8
   Weir Jonathan, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P196, DOI 10.1007/978-3-642-32205-1_17
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Yan XH, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115721
   Yang CN, 2017, COMPUT STAND INTER, V51, P118, DOI 10.1016/j.csi.2016.11.015
   Yang CN, 2014, INFORM SCIENCES, V278, P141, DOI 10.1016/j.ins.2014.03.033
NR 21
TC 6
Z9 6
U1 1
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2022
VL 87
AR 103567
DI 10.1016/j.jvcir.2022.103567
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2Z1FR
UT WOS:000826332100008
DA 2024-07-18
ER

PT J
AU Wang, ZJ
   Liu, L
   Zhang, HX
AF Wang, Zhongjie
   Liu, Li
   Zhang, Huaxiang
TI Dual-path image pair joint discrimination for visible-infrared person
   re-identification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Person re-identification; visible-infrared; Image pair generation;
   Dual-path discrimination
ID REPRESENTATION; ATTENTION
AB Because the imaging spectra of infrared images and visible light images are different, there is a huge modal difference between visible light images and infrared ones. Existing methods use image conversion to solve the problem of modal difference between two images, but these methods usually fail to focus on the complete information of images, which lead to the results of cross modal person re-identification are unstable. To solve this problem, we propose a new visible-infrared person re-identification method, called dual-path image pair joint discriminant model (DPJD), which simultaneously optimizes the distance within and between classes, and supervises the network learning to identify feature representations. We generate images with different modalities for the samples, and separately compose the same modality image pair and different modality image pair so as to overcome the inconsistent alignment issues. In addition, we also propose a discriminant module based on dual-path (DMDP) to improve the generation quality and discrimination accuracy of image pairs. Experiments on two benchmark datasets SYSU-MM01 and RegDB demonstrate its effectiveness.
C1 [Wang, Zhongjie; Liu, Li; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Jiaotong University
RP Liu, L; Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Zhang, HX (corresponding author), Shandong Jiaotong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
EM liuli_790209@163.com; huaxzhang@hotmail.com
FU National Natural Science Foundation of China [U1836216, 62176144,
   62076153]; major fundamental research project of Shandong, China
   [ZR2019Z D03]; Taishan Scholar Project of Shandong Province, China
   [ts20190924]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. U1836216, 62176144, 62076153) , the major
   fundamental research project of Shandong, China (No. ZR2019Z D03) , and
   the Taishan Scholar Project of Shandong Province, China (No. ts20190924)
   .
CR An JF, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102743
   Chen DP, 2018, LECT NOTES COMPUT SC, V11220, P56, DOI 10.1007/978-3-030-01270-0_4
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen GY, 2020, IEEE T IMAGE PROCESS, V29, P6963, DOI 10.1109/TIP.2020.2995272
   Chen GY, 2019, IEEE T IMAGE PROCESS, V28, P4192, DOI 10.1109/TIP.2019.2908062
   Cheng D, 2020, IEEE ACCESS, V8, P12824, DOI 10.1109/ACCESS.2020.2966002
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dong HS, 2018, NEUROCOMPUTING, V307, P25, DOI 10.1016/j.neucom.2018.04.013
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Hu Y., ARXIV210108467, V2021
   Huang SS, 2011, LECT NOTES COMPUT SC, V6524, P208
   Jiang M, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102775
   Kavakli-Thorne M., 2019, ARXIV190405992
   Li B, 2019, IEEE ACCESS, V7, P171485, DOI 10.1109/ACCESS.2019.2955930
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Lin J, 2017, PROC CVPR IEEE, P3396, DOI 10.1109/CVPR.2017.362
   Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386
   Liu HJ, 2021, IEEE SIGNAL PROC LET, V28, P653, DOI 10.1109/LSP.2021.3065903
   Liu HJ, 2023, IEEE T NEUR NET LEAR, V34, P1958, DOI 10.1109/TNNLS.2021.3105702
   Liu JC, 2022, APPL INTELL, V52, P2423, DOI 10.1007/s10489-021-02548-3
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Ma A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102367
   Martinet J, 2011, INFORM PROCESS MANAG, V47, P391, DOI 10.1016/j.ipm.2010.10.003
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Prates R, 2019, J VIS COMMUN IMAGE R, V58, P304, DOI 10.1016/j.jvcir.2018.12.003
   Pu N, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2149, DOI 10.1145/3394171.3413673
   Qi K., 2021, P INT JOINT C NEUR N, P1
   Qi MB, 2021, MULTIMED TOOLS APPL, V80, P17645, DOI 10.1007/s11042-020-10431-5
   Rao YM, 2019, INT J COMPUT VISION, V127, P701, DOI 10.1007/s11263-018-1135-x
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Shao H., ARXIV210314210
   Shen Z, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2213, DOI 10.1145/3340531.3412132
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tian XD, 2021, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR46437.2021.00157
   Wang T, 2020, NEUROCOMPUTING, V386, P84, DOI 10.1016/j.neucom.2019.12.058
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu Q, 2021, PROC CVPR IEEE, P4328, DOI 10.1109/CVPR46437.2021.00431
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Yamaguchi M, 2017, IEEE I CONF COMP VIS, P1462, DOI 10.1109/ICCV.2017.162
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Zhang C, 2021, INT C PATT RECOG, P8679, DOI 10.1109/ICPR48806.2021.9412576
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
NR 63
TC 1
Z9 1
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103512
DI 10.1016/j.jvcir.2022.103512
EA APR 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L9NQ
UT WOS:000799607600006
DA 2024-07-18
ER

PT J
AU Zheng, YP
   Zeng, G
   Li, HS
   Cai, Q
   Du, JP
AF Zheng, Yanping
   Zeng, Guang
   Li, Haisheng
   Cai, Qiang
   Du, Junping
TI Colorful 3D reconstruction at high resolution using multi-view
   representation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Review
DE 3D reconstruction; Colorful volumes; Super resolution; Multi-view
   representation
AB High-quality 3D models should contain accurate shapes, as well as other correct attributes, such as realistic surface color. However, current researches were mostly focused on the reconstruction of shapes. We present a method to reconstruct high-resolution colorful 3D models from single images. Shapes and colors are learned separately, using a coarse-to-fine strategy in which the 3D color is expressed as 3-channel volumes. Colorful volumes share the same spatial dimension with generated shape volumes. We propose orthographic colorful maps to retain and recover projected coordinates and corresponding color for 3D surface points. To achieve a fine granularity increase in the quality of maps from low-resolution to high-resolution, we introduce 2D super resolution during reconstructing 3D shapes and color volumes. Models are carved by utilizing predicted high resolution silhouette, depth and color details. Experimental results in a subset of the ShapeNet dataset and the Colorful Human dataset show the effectiveness of our method.
C1 [Zheng, Yanping; Zeng, Guang; Li, Haisheng; Cai, Qiang] Beijing Technol & Business Univ, Sch Comp & Informat Engn, Beijing, Peoples R China.
   [Zheng, Yanping; Zeng, Guang; Li, Haisheng; Cai, Qiang] Natl Engn Lab Agriprod Qual Traceabil, Beijing, Peoples R China.
   [Zheng, Yanping; Zeng, Guang; Li, Haisheng; Cai, Qiang] Beijing Key Lab Big Data Technol Food Safety, Beijing, Peoples R China.
   [Du, Junping] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing, Peoples R China.
C3 Beijing Technology & Business University; Beijing University of Posts &
   Telecommunications
RP Li, HS (corresponding author), 33 Fucheng Rd, Beijing 100048, Peoples R China.
EM lihsh@btbu.edu.cn
RI yang, zheng/HGC-7753-2022; LI, Haisheng/AAM-5232-2020; zheng,
   yan/GQY-6668-2022
OI LI, Haisheng/0000-0003-4861-0513; 
FU National Natural Science Foundation of China [61877002]; Beijing Natural
   Science Foundation-Fengtai Rail Transit Frontier Research Joint Fund
   [L191009]; Beijing Munic-ipal Commission of Education
   [PXM2019_014213_000007]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61877002) , Beijing Natural Science Foundation-Fengtai Rail
   Transit Frontier Research Joint Fund L191009 and Beijing Munic-ipal
   Commission of Education PXM2019_014213_000007.
CR Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Chang A, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P53
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23
   Kato H, 2019, PROC CVPR IEEE, P9770, DOI 10.1109/CVPR.2019.01001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li HS, 2019, INT J COMPUT INT SYS, V12, P697, DOI 10.2991/ijcis.d.190617.001
   Li HS, 2018, IEEE ACCESS, V6, P31854, DOI 10.1109/ACCESS.2018.2845362
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   MakeHuman, About us
   Oechsle M, 2019, IEEE I CONF COMP VIS, P4530, DOI 10.1109/ICCV.2019.00463
   Smith E, 2018, ADV NEUR IN, V31
   Smith Edward J., 2017, P MACH LEARN RES, V78, P87
   Sun Y, 2018, IEEE INT WORK SIGN P, P925
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Wang XT, 2019, LECT NOTES COMPUT SC, V11133, P63, DOI 10.1007/978-3-030-11021-5_5
   Wu J., 2017, PROC ADVNEURAL INF P, V30, P153
   Wu JJ, 2016, ADV NEUR IN, V29
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Zhu XB, 2018, COMPUT GRAPH FORUM, V37, P289, DOI 10.1111/cgf.13568
NR 28
TC 11
Z9 12
U1 4
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2022
VL 85
AR 103486
DI 10.1016/j.jvcir.2022.103486
EA MAR 2022
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 1L9NQ
UT WOS:000799607600002
DA 2024-07-18
ER

PT J
AU Guo, DQ
   Zhang, GX
   Neri, F
   Peng, S
   Yang, Q
   Liu, P
AF Guo, Dequan
   Zhang, Gexiang
   Neri, Ferrante
   Peng, Sheng
   Yang, Qiang
   Liu, Paul
TI An adaptive kernelized correlation filters with multiple features in the
   tracking application
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual properties; Target tracking; Multiple features; Kernelized
   correlation filter
ID ROBUST VISUAL TRACKING; OBJECT TRACKING
AB Automatic target detection and tracking systems are used extensively in complex scenes. In long-term tracking, some visual attributes of objects are changing, such as illumination, size, profile, and so on. To address the issue, it is particularly important to describe the essential properties of the objects in tracking. An enhanced kernelized correlation filter tracking strategy fused multiple features with location prediction is proposed. To make the object appearance models more accuracy and robustness, based on the original histogram of oriented gradient features, we integrate the hue, saturation, value, and grayscale information to construct a new descriptor to represent the target appearance. Moreover, location prediction and bi-linear interpolation are employed to obtain the more accurate target position. Experiments show that the proposed strategy can obtain superior or competitive performance in challenging benchmark data sets. In practice, the algorithm is applied to track shuttle bus targets in the airport apron.
C1 [Guo, Dequan; Zhang, Gexiang; Yang, Qiang] Chengdu Univ Informat Technol, Sch Control Engn, Chengdu, Peoples R China.
   [Neri, Ferrante] Univ Nottingham, Sch Comp Sci, Nottingham, England.
   [Peng, Sheng] Southwest Reg Adm, Chengdu, Peoples R China.
   [Liu, Paul] Stork Healthcare, Chengdu, Peoples R China.
C3 Chengdu University of Information Technology; University of Nottingham
RP Yang, Q (corresponding author), Chengdu Univ Informat Technol, Sch Control Engn, Chengdu, Peoples R China.
EM qiangychd@126.com
RI Neri, Ferrante/U-7036-2019; yang, qiang/GYJ-0971-2022
OI Neri, Ferrante/0000-0002-6100-6532; 
FU National Natural Science Foundation of China [61806028, 61672437,
   62103064, 61702428]; Sichuan Science and Technology Program [21ZDYF2484,
   2021YFN0104, 21GJHZ0061, 21ZDYF3629, 21ZDYF0418, 21YYJC1827, 2021YJ0086,
   2021YFG0295, 21ZDYF3537, 21ZDYF3598, 2020YFG0177]; Chinese Scholarship
   Council [202008510036]; Opening Project of International Joint Research
   Center for Robotics and Intelligence System of Sichuan Province
   [JQZN2021-003]; Department of Science and Technology of Sichuan Province
   [2019YFSY0043]; AECC Sichuan Gas Turbine Establishment, Key Laboratory
   on Aero-engine Altitude Simulation Technology, and Intelligent Control
   Education Reform Project of Chengdu University of Information Technology
   [JYJG2021044]
FX The authors would like to thank the editor and anonymous reviewers for
   their insight and suggestions. We also thank Prof. DongC. Liu and Prof.
   Shiqi Jiang for value suggestions. This work was supported in part by
   the National Natural Science Foundation of China under Grant 61806028,
   Grant 61672437, Grant 62103064 and Grant 61702428, Sichuan Science and
   Technology Program under Grant 21ZDYF2484, Grant 2021YFN0104, Grant
   21GJHZ0061, Grant 21ZDYF3629, Grant 21ZDYF0418, Grant 21YYJC1827, Grant
   2021YJ0086, Grant 2021YFG0295, Grant 21ZDYF3537, Grant 21ZDYF3598, Grant
   2020YFG0177, Chinese Scholarship Council under Grant 202008510036,
   Opening Project of International Joint Research Center for Robotics and
   Intelligence System of Sichuan Province under Grant JQZN2021-003,
   Department of Science and Technology of Sichuan Province under Grant
   2019YFSY0043, AECC Sichuan Gas Turbine Establishment, Key Laboratory on
   Aero-engine Altitude Simulation Technology, and Intelligent Control
   Education Reform Project of Chengdu University of Information Technology
   under Grant JYJG2021044.
CR Accadia C, 2003, WEATHER FORECAST, V18, P918, DOI 10.1175/1520-0434(2003)018<0918:SOPFSS>2.0.CO;2
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2017, REAL LIFE APPL MEMBR
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Díaz-Pernil D, 2019, J MEMBRANE COMPUT, V1, P58, DOI 10.1007/s41965-018-00002-x
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Guo DQ, 2021, CMES-COMP MODEL ENG, V129, P191, DOI 10.32604/cmes.2021.016347
   Guo DQ, 2021, CMES-COMP MODEL ENG, V127, P599, DOI 10.32604/cmes.2021.014119
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Karim S.A., 2015, FAR E J MATH SCI, V96, P211
   Karim SAA, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/7459218
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei Y, 2008, IEEE T SYST MAN CY B, V38, P1578, DOI 10.1109/TSMCB.2008.928226
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu FH, 2016, PATTERN RECOGN LETT, V84, P163, DOI 10.1016/j.patrec.2016.09.009
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   MAHALANOBIS A, 1994, APPL OPTICS, V33, P3751, DOI 10.1364/AO.33.003751
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Shin J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020713
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Wang Q., 2017, ARXIV170404057V1, P13
   Wang SH, 2021, INFORM FUSION, V67, P208, DOI 10.1016/j.inffus.2020.10.004
   Wang SH, 2019, INTEGR COMPUT-AID E, V26, P411, DOI 10.3233/ICA-190605
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yahya R., 2016, INT C BIOINSPIRED CO, P314
   Yang B, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00505-7
   Yuan JY, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540338
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang L, 2017, PATTERN RECOGN, V69, P82, DOI 10.1016/j.patcog.2017.04.004
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang YD, 2020, INFORM FUSION, V64, P149, DOI 10.1016/j.inffus.2020.07.006
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
NR 45
TC 5
Z9 5
U1 3
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103484
DI 10.1016/j.jvcir.2022.103484
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0P0PF
UT WOS:000783924700002
DA 2024-07-18
ER

PT J
AU Liu, J
   Wang, YT
   Huang, XD
   Su, YT
AF Liu, Jing
   Wang, Yating
   Huang, Xiangdong
   Su, Yuting
TI Tracking by dynamic template: Dual update mechanism
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual object tracking; Siamese trackers; Template update mechanism;
   Real-time tracking
AB Recently, Siamese trackers have received widespread attention for visual object tracking owing to their good balance between speed and performance. Those Siamese trackers heavily depend on target template while conventional practice fixes the template to initial frame. This strategy makes it unable to cope with variation of target appearance, which often leads to tracking failures and causes the gap in performance from other tracking methods. Despite the performance gain achieved by few template update methods with target templates generated by the tracked results, these tracked templates are easy to accumulate errors and cause tracking drift. In this paper, we propose two template update mechanisms to effectively adapt the target template during the tracking process which is dubbed as DTDU (Dynamic Template with Dual Update). Unlike predecessors that directly use the tracked template, we use initial template to perform similar transformation to the tracked template. Then the similar transformed template and the tracked template are combined linearly to capture the variation of target appearance. These updated templates are stored in a memory bank and retrieved to generate the final target template. In order to enhance quick update of memory bank to accommodate the target appearance, we use the retrieved template to further update the templates in memory bank for subsequent tracking. Extensive experiments on OTB-2015, VOT2016, VOT2018 and GOT-10k datasets have proved the effectiveness of these two update mechanisms and the proposed tracker achieves a real-time speed of 44 fps.
C1 [Liu, Jing; Wang, Yating; Huang, Xiangdong; Su, Yuting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, J (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM jliu_tju@tju.edu.cn
RI Jing, LIU/JCP-2850-2023; Wang, Ya-Ting/AFL-5523-2022
OI Jing, LIU/0000-0001-5172-4605; 
FU Tianjin Science Foundation of China [20JCQNJC01150]
FX Acknowledgments This work was supported by the Tianjin Science
   Foundation of China (Grant No. 20JCQNJC01150) .
CR Ahmed EK, 2022, J INTELL TRANSPORT S, V26, P269, DOI 10.1080/15472450.2020.1852082
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Chen BY, 2018, LECT NOTES COMPUT SC, V11211, P328, DOI 10.1007/978-3-030-01234-2_20
   Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Dai KH, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102800
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Fleuret, 2016, ARXIV161200604
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristan M, 2015, LECT NOTES COMPUT SC, V8926, P191, DOI 10.1007/978-3-319-16181-5_14
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li DQ, 2020, IEEE ACCESS, V8, P55905, DOI 10.1109/ACCESS.2020.2982261
   Li PX, 2019, IEEE I CONF COMP VIS, P6161, DOI 10.1109/ICCV.2019.00626
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li ZY, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103107
   Lukezic A, 2020, PROC CVPR IEEE, P7131, DOI 10.1109/CVPR42600.2020.00716
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Nam H., 2016, CORR
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Park E, 2018, LECT NOTES COMPUT SC, V11207, P587, DOI 10.1007/978-3-030-01219-9_35
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wang XC, 2017, IEEE T IMAGE PROCESS, V26, P4765, DOI 10.1109/TIP.2017.2723239
   Wang XC, 2016, IEEE T PATTERN ANAL, V38, P2312, DOI 10.1109/TPAMI.2015.2513406
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang M, J VIS COMMUN IMAGE R, V77
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
NR 45
TC 3
Z9 3
U1 1
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2022
VL 84
AR 103456
DI 10.1016/j.jvcir.2022.103456
EA FEB 2022
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 0I7YP
UT WOS:000779631900001
DA 2024-07-18
ER

PT J
AU Gao, XS
   Zhou, Y
   Huo, SW
   Li, ZZ
   Li, KQ
AF Gao, Xuesong
   Zhou, Yuan
   Huo, Shuwei
   Li, Zizi
   Li, Keqiu
TI Robust object tracking via deformation samples generator
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object tracking; Convolutional neural network; Deformation samples
   generator; Alternating strategy
ID CORRELATION FILTER; VISUAL TRACKING; CHANNEL
AB In object tracking applications, it is common for trackers to experience drift problems when the object of interest becomes deformed, which compromises the ability of the tracker to track the object. It is therefore desirable to develop a learning tracker classifier that is robust to deformations. The performance of existing trackers that employ deep classification networks degrades when the amount of training data is limited and does not cover all possible scenarios. While these limitations can be mitigated in part by using larger training datasets, these datasets may still not cover all situations and the positive samples are still monotonous. To overcome this problem, we propose a novel deformation samples generator that generates samples that would normally be difficult for the tracker to classify. In the proposed framework, both the classifier and deformation samples generator learn in a joint manner. Our experiments show that the proposed approach outperforms state-of-the-art methods in both quantitative and qualitative evaluations for the visual object tracking task.
C1 [Gao, Xuesong; Zhou, Yuan; Huo, Shuwei; Li, Zizi; Li, Keqiu] Tianjin Univ, Tianjin, Peoples R China.
   [Gao, Xuesong] Hisense Co Ltd, State Key Lab Digital Multimedia Technol, Qingdao, Peoples R China.
C3 Tianjin University; Hisense
RP Zhou, Y; Huo, SW (corresponding author), Tianjin Univ, Tianjin, Peoples R China.
EM zhouyuan@tju.edu.cn; huosw@tju.edu.cn
RI Huo, Shuwei/JAO-1073-2023
FU National Key Research and Development Program of China [2020YFC1523200,
   2019YFB2102400]; National Natural Science Foundation of China [62171320,
   U2006211]
FX This work was supported by the National Key Research and Development
   Program of China (2020YFC1523200, 2019YFB2102400) and National Natural
   Science Foundation of China (62171320 and U2006211).
CR Abdelpakey MH, 2020, IEEE T IMAGE PROCESS, V29, P1479, DOI 10.1109/TIP.2019.2942506
   Alajel KM, 2012, IEEE T CONSUM ELECTR, V58, P731, DOI 10.1109/TCE.2012.6311311
   [Anonymous], 2017, P IEEE INT C COMP VI
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Cehovin L, 2016, IEEE WINT CONF APPL
   Chatfield K., 2014, P BRIT MACHINE VISIO, P1834
   Chen BY, 2018, LECT NOTES COMPUT SC, V11211, P328, DOI 10.1007/978-3-030-01234-2_20
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen Y, 2021, IEEE ACCESS, V9, P15004, DOI 10.1109/ACCESS.2021.3052511
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Emami A, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P349, DOI 10.1109/AVSS.2012.64
   Fan H, 2017, IEEE I CONF COMP VIS, P5487, DOI 10.1109/ICCV.2017.585
   Fan H, 2017, IEEE T CIRC SYST VID, V27, P1018, DOI 10.1109/TCSVT.2016.2515738
   Gao P, 2014, IEEE T MULTIMEDIA, V16, P1797, DOI 10.1109/TMM.2014.2331013
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han ZJ, 2020, IEEE T CIRC SYST VID, V30, P155, DOI 10.1109/TCSVT.2018.2888492
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SF, 2017, IEEE T CIRC SYST VID, V27, P1006, DOI 10.1109/TCSVT.2016.2527300
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Huo SW, 2018, IEEE T MULTIMEDIA, V20, P1350, DOI 10.1109/TMM.2017.2769801
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang B, 2021, IEEE T MULTIMEDIA, V23, P2162, DOI 10.1109/TMM.2020.3008035
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   King DB, 2015, ACS SYM SER, V1214, P1
   Kristan M., IEEE INT C COMPUTER, P1949
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li CH, 2017, IEEE IMAGE PROC, P3660, DOI 10.1109/ICIP.2017.8296965
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Li ZZ, 2019, IEEE INT CONF MULTI, P114, DOI 10.1109/ICMEW.2019.00027
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu C, 2018, IEEE T MULTIMEDIA, V20, P889, DOI 10.1109/TMM.2017.2760633
   Liu GG, 2018, IEEE T MULTIMEDIA, V20, P2949, DOI 10.1109/TMM.2018.2844685
   Liu LW, 2012, INT C PATT RECOG, P565
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lukezic A, 2018, INT J COMPUT VISION, V126, P671, DOI 10.1007/s11263-017-1061-3
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2017, IEEE T MULTIMEDIA, V19, P2415, DOI 10.1109/TMM.2017.2694219
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Salimans Tim, 2017, ICLR
   Sui Y, 2020, IEEE T CIRC SYST VID, V30, P167, DOI 10.1109/TCSVT.2018.2888573
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Vu A, 2012, IEEE T INTELL TRANSP, V13, P899, DOI 10.1109/TITS.2012.2187641
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiang W, 2009, IEEE T CIRC SYST VID, V19, P1730, DOI 10.1109/TCSVT.2009.2022787
   Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804
   Yan B, 2021, PROC CVPR IEEE, P5285, DOI 10.1109/CVPR46437.2021.00525
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yao R, 2019, IEEE T CIRC SYST VID, V29, P1687, DOI 10.1109/TCSVT.2018.2848358
   Yao R, 2017, IEEE T MULTIMEDIA, V19, P772, DOI 10.1109/TMM.2016.2631727
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang SQ, 2021, IEEE T MULTIMEDIA, V23, P859, DOI 10.1109/TMM.2020.2990089
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhao F, 2019, IEEE T CIRC SYST VID, V29, P1998, DOI 10.1109/TCSVT.2018.2856540
   Zhou WZ, 2021, IEEE T IMAGE PROCESS, V30, P3597, DOI 10.1109/TIP.2021.3060905
   Zhou Y, 2021, IEEE T CYBERNETICS, V51, P5423, DOI 10.1109/TCYB.2019.2956091
   Zhou Y, 2022, IEEE J OCEANIC ENG, V47, P76, DOI 10.1109/JOE.2021.3104055
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 79
TC 4
Z9 4
U1 2
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103446
DI 10.1016/j.jvcir.2022.103446
EA FEB 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6OC
UT WOS:000819856800001
DA 2024-07-18
ER

PT J
AU Hassanin, M
   Radwan, I
   Khan, S
   Tahtali, M
AF Hassanin, Mohammed
   Radwan, Ibrahim
   Khan, Salman
   Tahtali, Murat
TI Learning discriminative representations for multi-label image
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-label recognition; Multi-label-contrastive learning; Contrastive
   representation; Deep learning
AB Multi-label recognition is a fundamental, and yet is a challenging task in computer vision. Recently, deep learning models have achieved great progress towards learning discriminative features from input images. However, conventional approaches are unable to model the inter-class discrepancies among features in multi-label images, since they are designed to work for image-level feature discrimination. In this paper, we propose a unified deep network to learn discriminative features for the multi-label task. Given a multi-label image, the proposed method first disentangles features corresponding to different classes. Then, it discriminates between these classes via increasing the inter-class distance while decreasing the intra-class differences in the output space. By regularizing the whole network with the proposed loss, the performance of applying the well-known ResNet-101 is improved significantly. Extensive experiments have been performed on COCO-2014, VOC2007 and VOC2012 datasets, which demonstrate that the proposed method outperforms state-of-the-art approaches by a significant margin of 3.5% on large-scale COCO dataset. Moreover, analysis of the discriminative feature learning approach shows that it can be plugged into various types of multi-label methods as a general module.
C1 [Hassanin, Mohammed; Tahtali, Murat] UNSW Canberra, Canberra, ACT, Australia.
   [Radwan, Ibrahim] Univ Canberra, Canberra, ACT, Australia.
   [Khan, Salman] IIAT, Dubai, U Arab Emirates.
C3 University of New South Wales Sydney; University of Canberra
RP Hassanin, M (corresponding author), UNSW Canberra, Canberra, ACT, Australia.
EM m.hassanin@unsw.edu.au; ibrahim.radwan@canberra.edu.au;
   salman.khan@inceptionai.org; murat.tahtali@adfa.edu.au
RI Tahtali, Murat/KGK-9532-2024; Khan, Salman Hameed/M-4834-2016
OI Radwan, Ibrahim/0000-0002-8170-5058; Khan, Salman
   Hameed/0000-0002-9502-1749; Tahtali, Murat/0000-0003-4702-4002
CR Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Chen SF, 2018, AAAI CONF ARTIF INTE, P6714
   Chen TS, 2019, IEEE I CONF COMP VIS, P522, DOI 10.1109/ICCV.2019.00061
   Chen TS, 2018, AAAI CONF ARTIF INTE, P6730
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Ge WF, 2018, PROC CVPR IEEE, P1277, DOI 10.1109/CVPR.2018.00139
   Ge Z, 2018, ARXIV PREPRINT ARXIV
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   Guo H, 2019, PROC CVPR IEEE, P729, DOI 10.1109/CVPR.2019.00082
   Guo H, 2017, PATTERN RECOGN LETT, V94, P38, DOI 10.1016/j.patrec.2017.05.012
   Hadid A, 2004, PROC CVPR IEEE, P797
   Hassanin M, 2020, IEEE ACCESS, V8, P28123, DOI 10.1109/ACCESS.2019.2958608
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S., 2018, 32 AAAI C ARTIFICIAL
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang K, 2016, ARXIV160307054
   Huang S.-J., 2012, 26 AAAI C ARTIFICIAL
   Lee CW, 2018, PROC CVPR IEEE, P1576, DOI 10.1109/CVPR.2018.00170
   Li Q, 2016, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2016.325
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Y, 2016, NEUROCOMPUTING, V217, P19, DOI 10.1016/j.neucom.2016.04.060
   Liu J., 2015, ARXIV150607310
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen XB, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2675
   Shen XB, 2018, IEEE T NEUR NET LEAR, V29, P4324, DOI 10.1109/TNNLS.2017.2763967
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang M, 2016, IEEE T IMAGE PROCESS, V26, P5678, DOI 10.1109/TIP.2016.2612829
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xue XY, 2011, IEEE I CONF COMP VIS, P651, DOI 10.1109/ICCV.2011.6126300
   Yang H, 2016, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2016.37
   Yang Yi, 2011, 22 INT JOINT C ARTIF
   Yazici Vacit Oguz, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13437, DOI 10.1109/CVPR42600.2020.01345
   Zhang JJ, 2018, IEEE T MULTIMEDIA, V20, P2801, DOI 10.1109/TMM.2018.2812605
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zheng Liang, 2016, arXiv preprint arXiv
   Zhu F, 2017, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR.2017.219
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 56
TC 15
Z9 15
U1 5
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2022
VL 83
AR 103448
DI 10.1016/j.jvcir.2022.103448
EA FEB 2022
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA 2P6OC
UT WOS:000819856800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bao, YQ
   Song, KC
   Wang, J
   Huang, LM
   Dong, HW
   Yan, YH
AF Bao, Yanqi
   Song, Kechen
   Wang, Jie
   Huang, Liming
   Dong, Hongwen
   Yan, Yunhui
TI Visible and thermal images fusion architecture for few-shot semantic
   segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE V-T semantic segmentation; Thermal images; Few-shot semantic
   segmentation
ID DEEP NEURAL-NETWORKS; FRAMEWORK; MODEL; RGB
AB Few-shot semantic segmentation (FSS) has drawn great attention in the community of computer vision, due to its remarkable potential for segmenting novel objects with few pixel-annotated samples. However, some interference factors, such as insufficient illumination and complex background, can impose more challenge to the segmentation performance than fully-supervised when the number of samples is insufficient. Therefore, we propose the visible and thermal (V-T) few-shot semantic segmentation task, which utilize the complementary and similar information of visible and thermal images to boost few-shot segmentation performance. As the first step, we build a novel outdoor city dataset Tokyo Multi-Spectral-4i for the V-T few-shot semantic segmentation task. In addition, a fusion architecture is proposed, which consists of an Edge Similarity fusion module (ES) and a Texture Edge Prototype module (TEP). The ES module fuses the bi-modal information by exploiting the edge similarity in the visible and thermal images. The TEP module extracts the prototype from two models by collaborating the representativeness and complementarity of the visible and thermal feature. Finally, extensive experiments conducted on the proposed datasets demonstrate that our architecture can achieve state-of-the-arts results.
C1 [Song, Kechen; Yan, Yunhui] Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
   Energy Saving Met Equipment & Intelligent Detect, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Song, KC; Yan, YH (corresponding author), Northeastern Univ, Sch Mech Engn & Automat, Shenyang, Liaoning, Peoples R China.
EM songke@me.neu.edu.cn; yanyh@mail.neu.edu.cn
RI Song, Kechen/T-1896-2019; Yan, Yunhui/HDL-7343-2022; Huang,
   Liming/AAE-8323-2022
OI Song, Kechen/0000-0002-7636-3460; Yan, Yunhui/0000-0001-7121-2367;
   Huang, Liming/0000-0003-4992-387X; Bao, Yanqi/0000-0001-5298-7087; Wang,
   Jie/0000-0002-7266-8179
FU National Natural Science Foundation of China [51805078]; Fundamental
   Research Funds for the Central Universities [N2103011, N2003021]
FX This work is supported by the National Natural Science Foundation of
   China (51805078) , the Fundamental Research Funds for the Central
   Universities (N2103011, N2003021) .
CR [Anonymous], CoRR abs/1511.07122
   Bao YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3083561
   Cao YP, 2019, ISPRS J PHOTOGRAMM, V150, P70, DOI 10.1016/j.isprsjprs.2019.02.005
   Cao YP, 2019, INFORM FUSION, V46, P206, DOI 10.1016/j.inffus.2018.06.005
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen T, 2022, IEEE T MULTIMEDIA, V24, P968, DOI 10.1109/TMM.2021.3061816
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Choy SK, 2019, SIGNAL PROCESS, V154, P30, DOI 10.1016/j.sigpro.2018.08.010
   Choy SK, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107483
   Couprie C., 2013, ARXIV13013572, P1
   Deng L., 2019, ARXIV PREPRINT ARXIV
   Dong HW, 2022, IEEE T IND INFORM, V18, P1801, DOI 10.1109/TII.2021.3090036
   Feng MZ, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102881
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   Guo-Sen Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P562, DOI 10.1007/978-3-030-58548-8_33
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang LM, 2022, IEEE T CIRC SYST VID, V32, P1366, DOI 10.1109/TCSVT.2021.3069812
   Huang LM, 2020, IEEE SIGNAL PROC LET, V27, P1585, DOI 10.1109/LSP.2020.3020735
   Jiang, 2018, ARXIV PREPRINT ARXIV, DOI DOI 10.5194/ACP-2018-920
   Kornblith S, 2019, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2019.00277
   Li X, 2020, PROC CVPR IEEE, P2866, DOI 10.1109/CVPR42600.2020.00294
   Li YB, 2017, IEEE IMAGE PROC, P1262, DOI 10.1109/ICIP.2017.8296484
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lyu Y, 2020, ELECTRON LETT, V56, P920, DOI 10.1049/el.2020.1635
   Meriaudeau, 2020, INT C PATTERN RECOGN
   Shaban A, 2017, ARXIV PREPRINT ARXIV, DOI 10.5244/C.31.167
   Shivakumar SS, 2020, IEEE INT CONF ROBOT, P9441, DOI [10.1109/icra40945.2020.9196831, 10.1109/ICRA40945.2020.9196831]
   Sun YX, 2021, IEEE T AUTOM SCI ENG, V18, P1000, DOI 10.1109/TASE.2020.2993143
   Sun YX, 2019, IEEE ROBOT AUTOM LET, V4, P2576, DOI 10.1109/LRA.2019.2904733
   Tian ZH, 2020, IEEE INTERNET THINGS, V7, P3901, DOI [10.1109/TPAMI.2020.3013717, 10.1109/JIOT.2019.2951620]
   Vertens J, 2020, IEEE INT C INT ROBOT, P8461, DOI 10.1109/IROS45743.2020.9341192
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang LL, 2015, J VIS COMMUN IMAGE R, V28, P83, DOI 10.1016/j.jvcir.2015.01.014
   Xie GS, 2022, IEEE T NEUR NET LEAR, V33, P2903, DOI 10.1109/TNNLS.2020.3046924
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Xu HB, 2019, J VIS COMMUN IMAGE R, V59, P186, DOI 10.1016/j.jvcir.2019.01.016
   Zhang C, 2019, IEEE I CONF COMP VIS, P9586, DOI 10.1109/ICCV.2019.00968
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
   Zhu XB, 2019, J VIS COMMUN IMAGE R, V58, P532, DOI 10.1016/j.jvcir.2018.11.020
   Zou C, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102616
NR 47
TC 15
Z9 16
U1 4
U2 37
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103306
DI 10.1016/j.jvcir.2021.103306
EA SEP 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WA4TS
UT WOS:000702879900013
DA 2024-07-18
ER

PT J
AU Liu, RR
   Ruichek, Y
   El Bagdouri, M
AF Liu, Rongrong
   Ruichek, Yassine
   El Bagdouri, Mohammed
TI Multispectral background subtraction with deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Background subtraction; Multispectral images; Deep learning;
   Convolutional neural networks
ID FEATURE-SELECTION; DATASETS
AB In this paper, we follow the trend of deep learning and make an attempt to investigate the potential benefit of using multispectral images via convolutional neural networks for background subtraction task. The major contributions of this work lie in two aspects, based on the impressive algorithm FgSegNet_v2. Firstly, we extract three channels out of the seven of the FluxData FD-1665 multispectral dataset to match the number of input channels of the VGG16 deep model. Some combinations of three-channel based multispectral images perform better than RGB images. Secondly, a new convolutional encoder is designed to use all the multispectral channels available to further explore the information of multispectral images. The results outperform the RGB images and also other approaches using the same multispectral dataset.
C1 [Liu, Rongrong; Ruichek, Yassine; El Bagdouri, Mohammed] Univ Bourgogne Franche Comte, UTBM, Connaissance & Intelligence Artificielle Distribu, 12 Rue Thierry Mieg, F-90000 Belfort, France.
C3 Universite de Franche-Comte; Universite de Bourgogne; Universite de
   Technologie de Belfort-Montbeliard (UTBM)
RP Liu, RR (corresponding author), Univ Bourgogne Franche Comte, UTBM, Connaissance & Intelligence Artificielle Distribu, 12 Rue Thierry Mieg, F-90000 Belfort, France.
EM rongrong.liu@utbm.fr; yassine.ruichek@utbm.fr;
   mohammed.el-bagdouri@utbm.fr
RI Ruichek, Yassine/GRX-3627-2022
OI LIU, Rongrong/0000-0001-7804-1337; RUICHEK, Yassine/0000-0003-4795-8569
FU China Scholarship Council (CSC)
FX The authors gratefully acknowledge the financial support of the China
   Scholarship Council (CSC) for granting a PhD scholarship to the first
   author. Many thanks to Mohamed Kas, Assistant Professor in CIAD Lab.,
   for his help in CPU and GPU implementation for computation time
   evaluation.
CR [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2006, Remote Sensing: Models and Methods for Image Processing
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 2018, ACTA AUTOMATICASINIC
   [Anonymous], 2019, Dive into deep learning
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bakkay MC, 2018, IEEE IMAGE PROC, P4018, DOI 10.1109/ICIP.2018.8451603
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Benezeth Y., 2014, IEEE INT C ROBOT AUT, P6
   Bolón-Canedo V, 2014, INFORM SCIENCES, V282, P111, DOI 10.1016/j.ins.2014.05.042
   Bouwmans T., 2019, Background Subtraction in Real Applications: Challenges, Current Models and Future Directions
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Chang CI, 2000, IEEE T INFORM THEORY, V46, P1927, DOI 10.1109/18.857802
   Cireundefinedan D.C., 2011, IJCAI INT JOINT C AR, VTwo, P1237, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-210
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Davenport MA, 2016, IEEE J-STSP, V10, P608, DOI 10.1109/JSTSP.2016.2539100
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Feng Jiashi, 2013, Advances in Neural Information Processing Systems, P404
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goes J, 2014, JMLR WORKSH CONF PRO, V33, P266
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jacobson NP, 2005, IEEE T GEOSCI REMOTE, V43, P2684, DOI 10.1109/TGRS.2005.857623
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Kalsotra R, 2019, IEEE ACCESS, V7, P59143, DOI 10.1109/ACCESS.2019.2914961
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krungkaew R., 2016, 2016 13 INT C ELECT, P1
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li CL, 2017, IEEE T CIRC SYST VID, V27, P725, DOI 10.1109/TCSVT.2016.2556586
   Lim Kyungsun., 2017, Advanced Video and Signal Based Surveillance (AVSS), 2017 14th IEEE International Conference on, P1
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Lin M., 2013, ARXIV13124400
   Lin Z., 2016, BIG DATA INF ANAL, V1, P139, DOI [DOI 10.3934/BDIA.2016001, 10.3934/bdia.2016001]
   Liu RR, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030703
   Liu RR, 2018, LECT NOTES COMPUT SC, V11182, P225, DOI 10.1007/978-3-030-01449-0_19
   Liu RR, 2017, LECT NOTES COMPUT SC, V10617, P581, DOI 10.1007/978-3-319-70353-4_49
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Pitts Walter, 1947, BULL MATH BIOPHYS, V9, P127, DOI 10.1007/BF02478291
   Ranzato MA., 2007, CVPR, DOI [10.1109/cvpr.2007.383157, 10.1109/CVPR.2007.383157]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rongrong Liu, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P35, DOI 10.1007/978-3-030-51935-3_4
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Silva C, 2017, PATTERN RECOGN LETT, V100, P144, DOI 10.1016/j.patrec.2017.10.034
   Silva C, 2016, INT C PATT RECOG, P2216, DOI 10.1109/ICPR.2016.7899965
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sobral A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P946, DOI 10.1109/ICCVW.2015.125
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2019, INT J COMPUT VISION, V127, P1044, DOI 10.1007/s11263-018-01141-5
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang Y., 2014, P IEEE C COMP VIS PA, P387, DOI 10.1109/ICIP40778.2020.9190887
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Xu Y, 2016, CAAI T INTELL TECHNO, V1, P43, DOI 10.1016/j.trit.2020.03.005
   Yu TM, 2019, ALGORITHMS, V12, DOI 10.3390/a12070128
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zheng A., 2019, NEUROCOMPUTING
   Zheng W., 2019, Neurocomputing
NR 74
TC 5
Z9 5
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103267
DI 10.1016/j.jvcir.2021.103267
EA AUG 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600007
OA Bronze
DA 2024-07-18
ER

PT J
AU Long, YQ
   Yu, HM
   Liu, BY
AF Long, Yangqi
   Yu, Huimin
   Liu, Biyang
TI Depth completion towards different sensor configurations via relative
   depth map estimation and scale recovery
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Depth estimation; Depth completion; Relative depth; Scale recovery;
   Geometry structure
AB Depth completion, which combines additional sparse depth information from the range sensors, substantially improves the accuracy of monocular depth estimation, especially using the deep-learning-based methods. However, these methods can hardly produce satisfactory depth results when the sensor configuration changes at test time, which is important for real-world applications. In this paper, the problem is tackled by our proposed novel two-stage mechanism, which decomposes depth completion into two subtasks, namely relative depth map estimation and scale recovery. The relative depth map is first estimated from a single color image with our designed scale-invariant loss function. Then the scale map is recovered with the additional sparse depth. Experiments on different densities and patterns of the sparse depth input show that our model always produces satisfactory depth results. Besides, our approach achieves state-of-the-art performance on the indoor NYUv2 dataset and performs competitively on the outdoor KITTI dataset, demonstrating the effectiveness of our method.
C1 [Long, Yangqi; Yu, Huimin; Liu, Biyang] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Yu, HM (corresponding author), Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou, Peoples R China.
EM yhm2005@zju.edu.cn
RI Long, Yangqi/CAG-0974-2022
OI Long, Yangqi/0000-0001-6549-5700
FU H-Z long-term cooperation framework [FA2018101021]
FX This work was supported by H-Z long-term cooperation framework
   (FA2018101021) .
CR [Anonymous], 2018, IJCAI
   Bhat S.F., 2020, ARXIV PREPRINT ARXIV
   Chen Y, 2019, IEEE I CONF COMP VIS, P10022, DOI [10.1109/iccv.2019.01012, 10.1109/ICCV.2019.01012]
   Cheng XJ, 2018, LECT NOTES COMPUT SC, V11220, P108, DOI 10.1007/978-3-030-01270-0_7
   Cheng XJ, 2020, AAAI CONF ARTIF INTE, V34, P10615
   Ding Y, 2019, J VIS COMMUN IMAGE R, V61, P1, DOI 10.1016/j.jvcir.2019.03.019
   Eigen D, 2014, ADV NEUR IN, V27
   Eldesokey A., 2020, P IEEECVF C COMPUTER, P12014
   Eldesokey A, 2020, IEEE T PATTERN ANAL, V42, P2423, DOI 10.1109/TPAMI.2019.2929170
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Huang ZX, 2020, IEEE T IMAGE PROCESS, V29, P3429, DOI 10.1109/TIP.2019.2960589
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaritz M, 2018, INT CONF 3D VISION, P52, DOI 10.1109/3DV.2018.00017
   Jinsun Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P120, DOI 10.1007/978-3-030-58601-0_8
   King DB, 2015, ACS SYM SER, V1214, P1
   Knutsson H., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P515, DOI 10.1109/CVPR.1993.341081
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Lee Jin Han, 2019, ARXIV190710326
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li A, 2020, IEEE WINT CONF APPL, P32, DOI 10.1109/WACV45572.2020.9093407
   Ma F., 2018, IEEE INT C ROB AUT I
   Ma FC, 2019, IEEE INT CONF ROBOT, P3288, DOI [10.1109/ICRA.2019.8793637, 10.1109/icra.2019.8793637]
   Marín-Jiménez MJ, 2018, J VIS COMMUN IMAGE R, V55, P627, DOI 10.1016/j.jvcir.2018.07.010
   Qiu JX, 2019, PROC CVPR IEEE, P3308, DOI 10.1109/CVPR.2019.00343
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SY, 2016, IEEE T PATTERN ANAL, V38, P730, DOI 10.1109/TPAMI.2015.2469274
   Strasdat H., 2010, Robotics: Science and Systems, V2, P5, DOI [10.1.1. 165.7975, DOI 10.15607/RSS.2010.VI.010]
   Tang J, 2021, IEEE T IMAGE PROCESS, V30, P1116, DOI 10.1109/TIP.2020.3040528
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012
   Van Gansbeke W, 2019, PROCEEDINGS OF MVA 2019 16TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), DOI 10.23919/mva.2019.8757939
   Wang TH, 2019, IEEE INT CONF ROBOT, P5880, DOI [10.1109/ICRA.2019.8794404, 10.1109/icra.2019.8794404]
   Wang XW, 2018, IEEE INT CONF ROBOT, P988
   Xia ZH, 2020, PROC CVPR IEEE, P62, DOI 10.1109/CVPR42600.2020.00014
   Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040
   Xu Y, 2019, IEEE I CONF COMP VIS, P2811, DOI 10.1109/ICCV.2019.00290
   Xu ZY, 2020, IEEE IMAGE PROC, P913, DOI [10.1109/ICIP40778.2020.9191138, 10.1109/icip40778.2020.9191138]
   Xue F, 2020, IEEE INT C INT ROBOT, P2330, DOI 10.1109/IROS45743.2020.9340802
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Zhang YD, 2018, PROC CVPR IEEE, P175, DOI 10.1109/CVPR.2018.00026
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 46
TC 4
Z9 4
U1 1
U2 4
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2021
VL 80
AR 103272
DI 10.1016/j.jvcir.2021.103272
EA AUG 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA WB2TI
UT WOS:000703429600002
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Zhang, L
   Chen, WH
   Wu, XM
   Li, ZG
AF Liu, Ziyang
   Zhang, Lei
   Chen, Weihai
   Wu, Xingming
   Li, Zhengguo
TI S&CNet: A lightweight network for fast and accurate depth completion*,**
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Dense depth completion; Lightweight network; Coarse-to-fine; Attention
   module
AB Dense depth completion is essential for autonomous driving and robotic navigation. Existing methods focused on attaining higher accuracy of the estimated depth, which comes at the price of increasing complexity and cannot be well applied in a real-time system. In this paper, a coarse-to-fine and lightweight network (S&CNet) is proposed for dense depth completion to reduce the computational complexity with negligible sacrifice on accuracy. A dual-stream attention module (S&C enhancer) is proposed according to a new finding of deep neural network-based depth completion, which can capture both the spatial-wise and channel-wise global range information of extracted features efficiently. Then it is plugged between the encoder and decoder of the coarse estimation network so as to improve the performance. The experiments on KITTI dataset demonstrate that the proposed approach achieves competitive result with respect to state-of-the-art works but via an almost four times faster speed. The S&C enhancer can also be easily plugged into other existing works to boost their performances significantly with negligible additional computations.
C1 [Liu, Ziyang; Zhang, Lei; Wu, Xingming] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
   [Liu, Ziyang; Zhang, Lei; Wu, Xingming] Beihang Univ, Hangzhou Innovat Inst, Hangzhou 310051, Peoples R China.
   [Chen, Weihai] Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
   [Wu, Xingming; Li, Zhengguo] Inst Infocomm Res, SRO Dept, Singapore 138632, Singapore.
C3 Beihang University; Beihang University; Shandong University of Science &
   Technology; Agency for Science Technology & Research (A*STAR); A*STAR -
   Institute for Infocomm Research (I2R)
RP Wu, XM (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.; Wu, XM (corresponding author), Beihang Univ, Hangzhou Innovat Inst, Hangzhou 310051, Peoples R China.; Chen, WH (corresponding author), Shandong Univ Sci & Technol, Coll Elect Engn & Automat, Qingdao 266590, Peoples R China.
EM whchen@buaa.edu.cn; wxmbuaa@163.com
RI Chen, Wei/GZK-7348-2022
OI Li, Zhengguo/0000-0002-4525-1204; /0009-0006-1337-808X; Liu,
   Ziyang/0000-0003-1864-9951
FU National Natural Science Foundation of China [61573048]; Beijing Natural
   Science Foun-dation [4202042]; Key Research and Development Program of
   Zhejiang Province [2020C01109]; Special Funding for Top Talents of
   Shandong Province
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 61620106012, Beijing Natural Science Foun-dation under
   Grant No. 4202042, the Key Research and Development Program of Zhejiang
   Province under Grant No. 2020C01109, National Natural Science Foundation
   of China under Grant No. 61573048, and the Special Funding for Top
   Talents of Shandong Province.
CR Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Lin-Zhuo, 2019, ARXIV PREPRINT ARXIV
   Chen Y, 2019, IEEE I CONF COMP VIS, P10022, DOI [10.1109/iccv.2019.01012, 10.1109/ICCV.2019.01012]
   Cheng XJ, 2018, LECT NOTES COMPUT SC, V11220, P108, DOI 10.1007/978-3-030-01270-0_7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eldesokey A, 2020, IEEE T PATTERN ANAL, V42, P2423, DOI 10.1109/TPAMI.2019.2929170
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   HLUCHYJ MG, 1991, J LIGHTWAVE TECHNOL, V9, P1386, DOI 10.1109/50.90937
   Howard A. G., 2017, PREPRINT
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jinsun Park, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P120, DOI 10.1007/978-3-030-58601-0_8
   Kim J.-H., 2018, arXiv, V2, P1
   Kingma D. P., 2014, arXiv
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Li A, 2020, IEEE WINT CONF APPL, P32, DOI 10.1109/WACV45572.2020.9093407
   Li B., 2021, Towards precise and efficient image guided depth completion
   Li ZG, 2018, IEEE T IMAGE PROCESS, V27, P442, DOI 10.1109/TIP.2017.2750418
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma FC, 2019, IEEE INT CONF ROBOT, P3288, DOI [10.1109/ICRA.2019.8793637, 10.1109/icra.2019.8793637]
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Park J, 2014, IEEE T IMAGE PROCESS, V23, P5559, DOI 10.1109/TIP.2014.2361034
   Paszke A, 2019, ADV NEUR IN, V32
   Qiu JX, 2019, PROC CVPR IEEE, P3308, DOI 10.1109/CVPR.2019.00343
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richardt C, 2012, COMPUT GRAPH FORUM, V31, P247, DOI 10.1111/j.1467-8659.2012.03003.x
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang J, 2021, IEEE T IMAGE PROCESS, V30, P1116, DOI 10.1109/TIP.2020.3040528
   Treml M., 2016, SPEEDING SEMANTIC SE, V2, P1
   Uhrig J, 2017, INT CONF 3D VISION, P11, DOI 10.1109/3DV.2017.00012
   Van Gansbeke W, 2019, PROCEEDINGS OF MVA 2019 16TH INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), DOI 10.23919/mva.2019.8757939
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Yang YC, 2019, PROC CVPR IEEE, P3348, DOI 10.1109/CVPR.2019.00347
   Yu F., 2015, ARXIV
   Zhang Yang, 2019, INT C LEARN REPR
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 45
TC 1
Z9 1
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2021
VL 79
AR 103220
DI 10.1016/j.jvcir.2021.103220
EA AUG 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA UF2LR
UT WOS:000688410900009
DA 2024-07-18
ER

PT J
AU Meng, XD
   Ma, W
   Li, CH
   Mi, Q
AF Meng, Xiangdong
   Ma, Wei
   Li, Chunhu
   Mi, Qing
TI Siamese CNN-based rank learning for quality assessment of inpainted
   images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image inpainting; Rank learning; Image quality assessment; Siamese
   network
AB Existing NR-IIQA (no reference-based inpainted image quality assessment) algorithms assess the quality of an inpainted image via artificially designed unnaturalness expression, which often fail to capture inpainted artifacts. This paper presents a new deep rank learning-based method for NR-IIQA. The model adopts a siamese deep architecture, which takes a pair of inpainted images as input and outputs their rank order. Each branch utilizes a CNN structure to capture the global structure coherence and a patch-wise coherence assessment module (PCAM) to depict the local color and texture consistency in an inpainted image. To train the deep model, we construct a new dataset, which contains thousands of pairs of inpainted images with ground-truth quality ranking labels. Rich ablation studies are conducted to verify the key modules of the proposed architecture. Comparative experimental results demonstrate that our method outperforms existing NR-IIQA metrics in evaluating both inpainted images and inpainting algorithms.
C1 [Meng, Xiangdong; Ma, Wei; Li, Chunhu; Mi, Qing] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Ma, W (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
EM reborn0502@emails.bjut.edu.cn; mawei@bjut.edu.cn;
   lich@emails.bjut.edu.cn; miqing@bjut.edu.cn
RI Mi, Qing/GQI-1620-2022
OI Mi, Qing/0000-0001-5063-3189; Ma, Wei/0000-0001-9652-4260
FU National Natural Science Foundation of China [61771026]; Key Project of
   Beijing Municipal Education Commission, China [KZ201910005008]
FX This research is supported by National Natural Science Foundation of
   China (No. 61771026) . It is also supported by the Key Project of
   Beijing Municipal Education Commission, China (No. KZ201910005008) .
CR Ardis P.A., 2009, VISUAL COMMUN-US, V7257
   Blau Y, 2018, PROC CVPR IEEE, P6228, DOI 10.1109/CVPR.2018.00652
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Bosse S, 2016, IEEE IMAGE PROC, P3773, DOI 10.1109/ICIP.2016.7533065
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P147, DOI 10.5201/ipol.2012.g-tvi
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   Herling J, 2012, INT SYM MIX AUGMENT, P141, DOI 10.1109/ISMAR.2012.6402551
   Hong X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2033, DOI 10.1145/3343031.3351002
   Hu B, 2019, IEEE T MULTIMEDIA, V21, P2042, DOI 10.1109/TMM.2019.2894958
   Isogawa M, 2019, INT J COMPUT VISION, V127, P1751, DOI 10.1007/s11263-018-1132-0
   Isogawa M, 2019, MULTIMED TOOLS APPL, V78, P1399, DOI 10.1007/s11042-018-6186-z
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kingma D. P., 2014, arXiv
   Kong S, 2016, LECT NOTES COMPUT SC, V9905, P662, DOI 10.1007/978-3-319-46448-0_40
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liang S, 2019, IEICE T INF SYST, VE102D, P1430, DOI 10.1587/transinf.2018EDL8206
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu XL, 2017, IEEE I CONF COMP VIS, P1040, DOI 10.1109/ICCV.2017.118
   Ma W, 2020, IET COMPUT VIS, V14, P482, DOI 10.1049/iet-cvi.2019.0775
   Nazeri K., 2019, ARXIV COMPUTER VISIO
   Oncu AI, 2012, LECT NOTES COMPUT SC, V7583, P561, DOI 10.1007/978-3-642-33863-2_58
   Qureshi MA, 2017, J VIS COMMUN IMAGE R, V49, P177, DOI 10.1016/j.jvcir.2017.09.006
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Snelgrove X, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149449
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   Dang TT, 2013, 2013 COLOUR AND VISUAL COMPUTING SYMPOSIUM (CVCS)
   Tiefenbacher P, 2015, IEEE IMAGE PROC, P447, DOI 10.1109/ICIP.2015.7350838
   Venkatesh MV, 2010, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2010.5653640
   Viacheslav V, 2014, INT CONF SIGN PROCES, P643, DOI 10.1109/ICOSP.2014.7015082
   Voronin V., 2015, WSCG 2015 Conference on Computer Graphics, Visualization and Computer Vision, P167
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Yu L., 2017, ARXIV PREPRINT ARXIV
   Yu W, 2015, LECT NOTES COMPUT SC, V9358, P356, DOI 10.1007/978-3-319-24947-6_29
   Zhang WL, 2019, IEEE I CONF COMP VIS, P3096, DOI 10.1109/ICCV.2019.00319
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 44
TC 1
Z9 1
U1 0
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2021
VL 78
AR 103176
DI 10.1016/j.jvcir.2021.103176
EA JUN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA TH4RC
UT WOS:000672077500009
DA 2024-07-18
ER

PT J
AU Hait-Fraenkel, E
   Gilboa, G
AF Hait-Fraenkel, Ester
   Gilboa, Guy
TI Revealing stable and unstable modes of denoisers through nonlinear
   eigenvalue analysis?
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Eigenfunctions; Nonlinear operators; Denoising; Power iteration;
   Total-variation; EPLL
AB In this paper, we propose to analyze stable and unstable modes of black-box image denoisers through nonlinear eigenvalue analysis. We aim to find input images for which the denoiser output is proportional to the input. We treat this as a generalized nonlinear eigenproblem. Potential implications are wide, as most image processing algorithms can be viewed as black-box operators. We introduce a generalized nonlinear power-method to solve eigenproblems for such operators. This allows us to reveal stable modes of the denoiser: optimal inputs, achieving superior PSNR in noise removal. Analogously to the linear case, such stable modes show coarse structures and correspond to large eigenvalues. We also provide a method to generate unstable modes, which the denoiser suppresses strongly, which are textural with small eigenvalues. We validate the method using total-variation (TV) and demonstrate it on the EPLL (Zoran?Weiss) and the Non-local means denoisers. Finally, we suggest an encryption?decryption application.
C1 [Hait-Fraenkel, Ester; Gilboa, Guy] Technion Israel Inst Technol, Dept Elect Engn, Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Hait-Fraenkel, E (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, Haifa, Israel.
EM etyhait@campus.technion.ac.il
FU Israel Science Foundation [534/19]; Technion Ollendorff Minerva Center
FX We acknowledge support by Israel Science Foundation (grant No. 534/19)
   and the Technion Ollendorff Minerva Center.
CR ARNOLDI WE, 1951, Q APPL MATH, V9, P17, DOI 10.1090/qam/42792
   Arrigo F, 2020, P ROY SOC A-MATH PHY, V476, DOI 10.1098/rspa.2019.0724
   Aujol JF, 2018, SIAM J IMAGING SCI, V11, P1416, DOI 10.1137/17M1139126
   Aviles-Rivero A. I, 2019, ARXIV PREPRINT ARXIV
   Benning M, 2013, METHODS APPL ANAL, V20, P295, DOI 10.4310/MAA.2013.v20.n4.a1
   Bresson X., 2013, ARXIV13022717
   BROWDER FE, 1966, B AM MATH SOC, V72, P571, DOI 10.1090/S0002-9904-1966-11544-6
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Bungert L., 2019, NONLINEAR SPECTRAL D
   Bungert L., 2019, J EVOL EQU, P1
   Bungert L, 2019, INVERSE PROBL, V35, DOI 10.1088/1361-6420/ab1d71
   Burger M, 2016, SIAM J IMAGING SCI, V9, P1374, DOI 10.1137/15M1054687
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chu M. T., 2014, 2 DOMINANT EIGENVALU
   Cohen I, 2018, J COMPUT PHYS, V375, P1138, DOI 10.1016/j.jcp.2018.09.012
   Daskalakis C, 2018, ACM S THEORY COMPUT, P44, DOI 10.1145/3188745.3188968
   Feld T, 2019, INVERSE PROBL, V35, DOI 10.1088/1361-6420/ab0cb2
   Gautier A., 2020, ARXIV PREPRINT ARXIV
   Gautier A, 2019, SIAM J MATRIX ANAL A, V40, P1179, DOI 10.1137/18M1165037
   Gilboa G., 2018, Nonlinear Eigenproblems in Image Processing and Computer Vision
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hein M., 2010, Adv. Neural Inf. Process., P847
   Johnson, 2012, MATRIX ANAL
   Katzir O., 2017, THESIS  ISRAEL I TEC
   Kolda TG, 2011, SIAM J MATRIX ANAL A, V32, P1095, DOI 10.1137/100801482
   Lv XG, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aaa4a7
   Ma LY, 2016, J SCI COMPUT, V67, P1, DOI 10.1007/s10915-015-0067-7
   Meyer Y., 2001, OSCILLATING PATTERNS, V22
   Mises R., 1929, Z ANGEW MATH MECH, V9, P152, DOI DOI 10.1002/ZAMM.19290090206
   Nossek RZ, 2018, J SCI COMPUT, V75, P859, DOI 10.1007/s10915-017-0577-6
   Pohlhausen E, 1921, Z ANGEW MATH MECH, V1, P28, DOI 10.1002/zamm.19210010104
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schmidt MF, 2018, INVERSE PROBL, V34, DOI 10.1088/1361-6420/aab0ae
   Shaham TR, 2016, LECT NOTES COMPUT SC, V9910, P136, DOI 10.1007/978-3-319-46466-4_9
   Trefethen L.N., 1997, NUMERICAL LINEAR ALG
   Wang ZS, 2021, IEEE T CYBERNETICS, V51, P1454, DOI [10.1007/s00170-020-06291-w, 10.1109/TCYB.2019.2960605]
   Wilkinson J.H., 1988, ALGEBRAIC EIGENVALUE
   Wu SJ, 2017, APPL MATH COMPUT, V303, P226, DOI 10.1016/j.amc.2017.01.030
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 39
TC 2
Z9 2
U1 1
U2 3
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103041
DI 10.1016/j.jvcir.2021.103041
EA FEB 2021
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600008
DA 2024-07-18
ER

PT J
AU Wu, YH
   Jia, T
   Pang, Y
   Sun, JD
   Xue, DY
AF Wu, Yunhe
   Jia, Tong
   Pang, Yu
   Sun, Jiaduo
   Xue, Dingyu
TI Salient object detection via a boundary-guided graph structure
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient object detection; Coarse saliency map; Weighting integration
   framework; Boundary-guided graph structure; Adaptive strategy; Iterative
   propagation mechanism
ID NETWORK
AB Graph-based salient object detection methods have gained more and more attention recently. However, existing works fail to separate effectively salient object and background in some challenging scenes. Inspired by this observation, we propose an effective salient object detection method based on a novel boundary-guided graph structure. More specifically, the input image is firstly segmented into a series of superpixels. Then we integrate two prior cues to generate the coarse saliency map, a novel weighting mechanism is proposed to balance the proportion of two prior cues according to their performance. Secondly, we propose a novel boundary-guided graph structure to explore deeply the intrinsic relevance between superpixels. Based on the proposed graph structure, an iterative propagation mechanism is constructed to refine the coarse saliency map. Experimental results on four datasets show adequately the superiority of the proposed method than other state-of-the-art methods.
C1 [Wu, Yunhe; Jia, Tong; Sun, Jiaduo; Xue, Dingyu] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Pang, Yu] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Jia, T (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.; Pang, Y (corresponding author), Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110169, Peoples R China.
EM jiatong@ise.neu.edu.cn; pangyu@stumail.neu.edu.cn
RI Wu, Yunhe/JWA-3597-2024
OI Wu, Yunhe/0000-0001-7049-7161
FU National Key Research and Development Project of China [2018YFB1404101]
FX This work was supported in part by the National Key Research and
   Development Project of China under Grant 2018YFB1404101
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alpert S, 2007, PROC CVPR IEEE, P359
   Chen SH, 2016, PATTERN RECOGN, V60, P2, DOI 10.1016/j.patcog.2016.05.016
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Gao ZF, 2020, IEEE INTERNET THINGS, V7, P4092, DOI 10.1109/JIOT.2019.2963701
   Gao ZF, 2020, IEEE NETWORK, V34, P216, DOI 10.1109/MNET.001.1900260
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hwang I, 2017, MULTIMED TOOLS APPL, V76, P2111, DOI 10.1007/s11042-015-3171-7
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Kong YQ, 2016, LECT NOTES COMPUT SC, V9910, P583, DOI 10.1007/978-3-319-46466-4_35
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Movahedi V., 2010, P 2010 IEEE C COMP V, P4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pang Y, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.1.013011
   Pang Y, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102676
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Pearson K., 1895, PHILOS T R SOC LON A, V186
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Qian MY, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.06.021
   Qin Y, 2018, INT J COMPUT VISION, V126, P751, DOI 10.1007/s11263-017-1062-2
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Simonyan K, 2015, IEEE INT C ICLR
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623
   Zeng Y, 2018, IEEE T IMAGE PROCESS, V27, P4545, DOI 10.1109/TIP.2018.2838761
   Zhan JM, 2021, IEEE T FUZZY SYST, V29, P2844, DOI 10.1109/TFUZZ.2020.3007423
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang M, 2018, J VIS COMMUN IMAGE R, V52, P131, DOI 10.1016/j.jvcir.2018.01.004
   Zhou XL, 2014, IEEE T IND INFORM, V10, P1064, DOI 10.1109/TII.2013.2294156
NR 48
TC 4
Z9 4
U1 2
U2 29
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2021
VL 75
AR 103048
DI 10.1016/j.jvcir.2021.103048
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA RD5BZ
UT WOS:000633494600006
DA 2024-07-18
ER

PT J
AU Chaitanya, BSNV
   Mukherjee, S
AF Chaitanya, B. S. N., V
   Mukherjee, Snehasis
TI Single image dehazing using improved cycleGAN
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE CycleGAN; Cyclic consistency loss; AOD-NET; Single image dehazing; SSIM
   loss
AB Haze is an aggregation of very fine, widely dispersed, solid and/or liquid particles suspended in the atmosphere. In this paper, we propose an end-to-end network for single image dehazing, which enhances the CycleGAN model by introducing a transformer architecture within the generator, which is specific for haze removal. The proposed model is trained in an unpaired fashion with clear and hazy images altogether and does not require pairs of hazy and corresponding ground-truth clear images. Furthermore, the proposed model does not depend on estimating the parameters of the atmospheric scattering model. Rather, it uses a K-estimation module as the generator's transformer for complete end-to-end modeling. The feature transformer introduced in the proposed generator model transforms the encoded features into desired feature space and then feeds them into the CycleGAN decoder to create a clear image. In the proposed model we further modified the cycle consistency loss to include the SSIM loss along with pixel-wise mean loss to produce a new loss function specific for the reconstruction task, which enhances the performance of the proposed model. The model performs well even on the high-resolution images provided in the NTIRE 2019 challenge dataset for single image dehazing. Further, we perform experiments on NYU-Depth and reside beta datasets. Results of our experiments show the efficacy of the proposed approach compared to the state-of-the-art in removing the haze from the input image.
C1 [Chaitanya, B. S. N., V] Indian Inst Informat Technol, Sri City, India.
   [Mukherjee, Snehasis] Shiv Nadar Univ, Greater Noida, India.
C3 Shiv Nadar University
RP Mukherjee, S (corresponding author), Shiv Nadar Univ, Greater Noida, India.
EM viswachaitanya.b16@iiits.in; snehasis.mukherjee@snu.edu.in
RI Mukherjee, Snehasis/Q-1000-2019
OI Basava, Sai Naga Viswa Chaitanya/0000-0003-2296-6722; Mukherjee,
   Snehasis/0000-0002-2196-8980
FU NVIDIA company, United States
FX The authors wish to thank the NVIDIA company, United States for
   providing a TITAN X GPU card as a research grant, which is used for
   conducting the experiments reported in this paper.
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti Codruta Orniana, 2010, INT C IM PROC IEEE
   [Anonymous], 2018, P IEEE C COMP VIS PA
   Borkar K, 2020, NEUROCOMPUTING, V400, P294, DOI 10.1016/j.neucom.2020.03.027
   Borkar Kushal, 2018, ARXIVE180808610
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Cai Zixing, 2010, 2010 INT C INT SYST, V1
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen YY, 2019, J VIS COMMUN IMAGE R, V61, P284, DOI 10.1016/j.jvcir.2019.04.008
   Dudhane A, 2018, IEEE WINT CONF APPL, P1397, DOI 10.1109/WACV.2018.00157
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Gao Y, 2018, J VIS COMMUN IMAGE R, V55, P586, DOI 10.1016/j.jvcir.2018.07.004
   Golts A, 2020, IEEE T IMAGE PROCESS, V29, P2692, DOI 10.1109/TIP.2019.2952032
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hore A., 2010, 2010 20 INT C PATT R
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang Zhiying, 2018, IEEE T POWER SYST, V99, P1
   Kumar H, 2019, IET IMAGE PROCESS, V13, P1931, DOI 10.1049/iet-ipr.2018.5240
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li Boyi, 2017, IEEE I CONF COMP VIS
   Li RD, 2018, PROC CVPR IEEE, P8202, DOI 10.1109/CVPR.2018.00856
   Liu Q, 2018, IEEE T IMAGE PROCESS, V27, P5178, DOI 10.1109/TIP.2018.2849928
   Liu Z., 2018, INT C LEARN REPR
   Mei Kangfu, 2018, AS C COMP VIS
   Morales Peter, 2019, P IEEE C COMP VIS PA
   Mukhopadhyay Sudipta, 2019, ARXIV PREPRINT ARXIV
   Qu Yanyun., 2019, COMPUTER VISION PATT
   Salazar Colores S, 2019, IET IMAGE PROCESS, V13, P2877, DOI 10.1049/iet-ipr.2018.6403
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song YF, 2018, IEEE T MULTIMEDIA, V20, P1548, DOI 10.1109/TMM.2017.2771472
   Swami K., 2018, ARXIV PREPRINT ARXIV
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Timofte Radu, 2019, ARXIV PREPRINT ARXIV
   Wang AN, 2019, IEEE T IMAGE PROCESS, V28, P381, DOI 10.1109/TIP.2018.2868567
   Xiao J, 2020, NEUROCOMPUTING
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Zhang H., 2017, ARXIV PREPRINT ARXIV
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 44
TC 20
Z9 20
U1 5
U2 28
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103014
DI 10.1016/j.jvcir.2020.103014
EA JAN 2021
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500001
DA 2024-07-18
ER

PT J
AU Zamiri, M
   Yazdi, HS
AF Zamiri, Mona
   Yazdi, Hadi Sadoghi
TI Image annotation based on multi-view robust spectral clustering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image annotation; Geo-tagged photos; Recommender systems; Maximum
   correntropy criterion; Multi-view spectral clustering; Geographical
   information
ID GRAPH; CORRENTROPY; INFORMATION; PHOTOS
AB Nowadays, image annotation has been a hot topic in the semantic retrieval field due to the abundant growth of digital images. The purpose of these methods is to realize the content of images and assign appropriate keywords to them. Extensive efforts have been conducted in this field, which effectiveness is limited between low-level image features and high-level semantic concepts. In this paper, we propose a Multi-View Robust Spectral Clustering (MVRSC) method, which tries to model the relationship between semantic and multi-features of training images based on the Maximum Correntropy Criterion. A Half-Quadratic optimization framework is used to solve the objective function. According to the constructed model, a few tags are suggested based on a novel decision-level fusion distance. The stability condition and bound calculation of MVRSC are analyzed, as well. Experimental results on real-world Flickr and 500PX datasets, and Corel5K confirm the superiority of the proposed method over other competing models.
C1 [Zamiri, Mona; Yazdi, Hadi Sadoghi] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
   [Zamiri, Mona; Yazdi, Hadi Sadoghi] Ferdowsi Univ Mashhad, Ctr Excellence Soft Comp & Intelligent Informat P, Mashhad, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad; Ferdowsi University Mashhad
RP Yazdi, HS (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Razavi Khorasan, Iran.
EM zamiri.mona@mail.um.ac.ir; h-sadoghi@um.ac.ir
RI Zamiri, Mona/HIR-4439-2022
OI Zamiri, Mona/0000-0001-8315-7027
CR Abbasi R, 2009, LECT NOTES COMPUT SC, V5887, P65, DOI 10.1007/978-3-642-10543-2_8
   [Anonymous], 2019, KNOWL-BASED SYST
   [Anonymous], 2017, IEEE T IMAGE PROCESS
   [Anonymous], 2013, INFORM FUSION
   [Anonymous], 2001, LECT NOTES COMPUT SC
   [Anonymous], 2011, ESAIM-PROBAB STAT
   Ashkezari-Toussi S, 2019, CITIES, V86, P113, DOI 10.1016/j.cities.2018.09.009
   Belém FM, 2017, J ASSOC INF SCI TECH, V68, P830, DOI 10.1002/asi.23736
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cai GC, 2018, EXPERT SYST APPL, V94, P32, DOI 10.1016/j.eswa.2017.10.049
   Cai X., 2011, COMPUTER VISION PATT
   Chen BD, 2016, IEEE T SIGNAL PROCES, V64, P3376, DOI 10.1109/TSP.2016.2539127
   Chen BD, 2014, IEEE SIGNAL PROC LET, V21, P880, DOI 10.1109/LSP.2014.2319308
   Chen WY, 2011, IEEE T PATTERN ANAL, V33, P568, DOI 10.1109/TPAMI.2010.88
   Cheng QM, 2018, PATTERN RECOGN, V79, P242, DOI 10.1016/j.patcog.2018.02.017
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   far E.E., 2011, NEURAL INF PROCESS S
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hays J, 2008, PROC CVPR IEEE, P3436
   He L, 2019, IEEE T CYBERNETICS, V49, P1058, DOI 10.1109/TCYB.2018.2794998
   He R, 2014, IEEE T PATTERN ANAL, V36, P261, DOI 10.1109/TPAMI.2013.102
   He R, 2011, IEEE T PATTERN ANAL, V33, P1561, DOI 10.1109/TPAMI.2010.220
   Hu HX, 2016, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2016.323
   Hu ZX, 2020, NEUROCOMPUTING, V384, P1, DOI 10.1016/j.neucom.2019.12.004
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jiang K, 2013, NEUROCOMPUTING, V119, P17, DOI 10.1016/j.neucom.2012.02.049
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kang Z, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105102
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei CY, 2016, IEEE T MULTIMEDIA, V18, P687, DOI 10.1109/TMM.2015.2477277
   Li XC, 2015, IEEE T MULTIMEDIA, V17, P674, DOI 10.1109/TMM.2015.2413351
   Liu W, 2018, FUTURE GENER COMP SY, V83, P183, DOI 10.1016/j.future.2017.12.014
   Liu WF, 2007, IEEE T SIGNAL PROCES, V55, P5286, DOI 10.1109/TSP.2007.896065
   Liu XW, 2021, IEEE T PATTERN ANAL, V43, P2634, DOI 10.1109/TPAMI.2020.2974828
   Liu XW, 2019, IEEE T PATTERN ANAL, V41, P2410, DOI 10.1109/TPAMI.2018.2879108
   Liu Z, 2018, EXPERT SYST APPL, V104, P168, DOI 10.1016/j.eswa.2018.03.014
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu Y, 2016, GEOINFORMATICA, V20, P829, DOI 10.1007/s10707-016-0250-5
   Luo JB, 2011, MULTIMED TOOLS APPL, V51, P187, DOI 10.1007/s11042-010-0623-y
   Ma H, 2014, GEOINFORMATICA, V18, P671, DOI 10.1007/s10707-013-0199-6
   Maier M, 2013, ESAIM-PROBAB STAT, V17, P370, DOI 10.1051/ps/2012001
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   McLeod, 2008, P ACM WORKSH SEARCH
   Miliou Ioanna, 2014, Database and Expert Systems Applications 25th International Conference (DEXA 2014). Proceedings. LNCS 8644, P97, DOI 10.1007/978-3-319-10073-9_9
   Murthy V.N., 2014, P INT C MULT RETR
   Nie F., 2016, IJCAI, P1881
   Nie FP, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2022, DOI 10.1145/3219819.3220049
   Peng X, 2019, PR MACH LEARN RES, V97
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Putthividhya D, 2010, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2010.5540000
   Qian XM, 2013, NEUROCOMPUTING, V111, P144, DOI 10.1016/j.neucom.2012.12.021
   Rad R, 2017, J VIS COMMUN IMAGE R, V46, P1, DOI 10.1016/j.jvcir.2017.03.005
   Rad R, 2015, IET COMPUT VIS, V9, P806, DOI 10.1049/iet-cvi.2014.0413
   Ren XY, 2017, NEUROCOMPUTING, V241, P38, DOI 10.1016/j.neucom.2017.02.005
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sangeetha M., 2016, INT RES J ENG TECHNO
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sinhal A., 2013, INT J ENG RES TECHNO, P35
   Spyrou E, 2016, NEUROCOMPUTING, V172, P114, DOI 10.1016/j.neucom.2014.12.104
   Sumuya C., 2009, CHIN C PATT REC CCPR
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   Verma Y., 2012, EUR C COMP VIS ECCV
   Verma Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.25
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang H, 2020, IEEE T KNOWL DATA EN, V32, P1116, DOI 10.1109/TKDE.2019.2903810
   Wen J, 2021, IEEE T CYBERNETICS, V51, P101, DOI 10.1109/TCYB.2020.2987164
   Xue Z., 2018, INFORM SCI, P190
   Yang Y, 2015, J VIS COMMUN IMAGE R, V33, P368, DOI 10.1016/j.jvcir.2015.10.006
   Zhang, 2005, IEEE INT C COMP VIS
   Zhao MB, 2015, KNOWL-BASED SYST, V76, P148, DOI 10.1016/j.knosys.2014.12.014
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
   Zhou N, 2019, IEEE T CIRC SYST VID, V29, P1946, DOI 10.1109/TCSVT.2018.2856827
   Zhou N, 2019, IEEE T CIRC SYST VID, V29, P404, DOI 10.1109/TCSVT.2017.2783364
NR 77
TC 15
Z9 16
U1 0
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103003
DI 10.1016/j.jvcir.2020.103003
EA JAN 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QK3QR
UT WOS:000620295500006
DA 2024-07-18
ER

PT J
AU Zhu, LW
   Zhang, Y
   Li, N
   Pi, JY
   Wang, SQ
AF Zhu, Linwei
   Zhang, Yun
   Li, Na
   Pi, Jinyong
   Wang, Shiqi
TI Circular intra prediction for 360 degree video coding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Circular intra prediction; Projection deformation; 360 degree video;
   Versatile video coding
AB Different from traditional 2D video, the contents of 360 degree video are deformed due to the projection from 3D sphere to 2D plane. As a result, the traditional Angular Intra Prediction (AIP) with a linear pattern may not be always efficient. To further improve the coding performance of 360 degree video, a novel intra prediction method is presented in this paper, i.e., Circular Intra Prediction (CIP), which takes consideration of the spherical characteristics of 360 degree video. In specific, the proposed CIP is performed in a circular pattern, where the center of circle is located around the to-be-predicted block, and different centers of circle are able to produce different CIP modes. The distance between center of this circle and center of the to-be-predicted block is adaptively determined according to the degree of projection deformation, where stronger projection deformation needs shorter distance, and vice versa. As the increase of the distance, the CIP is more and more close to the traditional AIP. In addition, one additional binary flag is utilized to achieve better coding performance from the competition between AIP and CIP with the rate-distortion optimization. The proposed algorithm is implemented on the platform of Versatile video coding Test Model (VTM) 5.0 + 360Lib 9.1. Extensive experiments show that the proposed method can achieve bit rate reduction on this platform for 360 degree video coding.
C1 [Zhu, Linwei; Zhang, Yun; Li, Na; Pi, Jinyong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Wang, Shiqi] City Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; City University of Hong Kong
RP Zhang, Y (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM yun.zhang@siat.ac.cn
RI Zhang, Yun/V-7261-2019
OI Zhang, Yun/0000-0001-9457-7801; , linwei/0000-0002-9385-9054; ,
   Na/0000-0003-3888-7893
FU Shenzhen Science and Technology Program [JCYJ20180507183823045]; Natural
   Science Foundation of China [61901459, 61902389]; China Postdoctoral
   Science Foundation [2019M653127]; Guangdong International Science and
   Technology Cooperative Research Project [2018A050506063]; Free
   Application Fund of Natural Science Foundation of Guangdong Province
   [2018A0303130126]; Membership of Youth Innovation Promotion Association,
   Chinese Academy of Sciences [2018392]; Hong Kong RGC Early Career Scheme
   [9048122, CityU 21211018]
FX This work was supported in part by Shenzhen Science and Technology
   Program under Grant JCYJ20180507183823045, in part by the Natural
   Science Foundation of China under Grant 61901459 and Grant 61902389, in
   part by China Postdoctoral Science Foundation under Grant 2019M653127,
   in part by Guangdong International Science and Technology Cooperative
   Research Project under Grant 2018A050506063, in part by Free Application
   Fund of Natural Science Foundation of Guangdong Province under Grant
   2018A0303130126, in part by Membership of Youth Innovation Promotion
   Association, Chinese Academy of Sciences under Grant 2018392, and in
   part by Hong Kong RGC Early Career Scheme under Grant 9048122 (CityU
   21211018).
CR [Anonymous], 2018, JVETK1001V7
   Bjotegaard G., 2001, VCEGM33
   Bross B., 2018, 12 M MAC CN OCT 3 12
   Bross B, 2020, IEEE T CIRC SYST VID, V30, P1226, DOI 10.1109/TCSVT.2019.2949619
   Chen HM, 2016, IEEE T IMAGE PROCESS, V25, P3671, DOI 10.1109/TIP.2016.2573585
   D-L-Henrandez S., 2019, 13 M MARR MA JAN 9 1
   Duanmu F., 2018, 2018 DAT COMPR C SNO
   François E, 2016, IEEE T CIRC SYST VID, V26, P63, DOI 10.1109/TCSVT.2015.2461911
   Hanhart P., 2018, 12 M MAC CN OCT 3 12
   Hanhart P, 2019, IEEE J EM SEL TOP C, V9, P71, DOI 10.1109/JETCAS.2018.2888960
   He Y., 2017, 2017 DAT COMPR C DCC
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li JH, 2018, IEEE T CIRC SYST VID, V28, P947, DOI 10.1109/TCSVT.2016.2633377
   Li L, 2020, IEEE J-STSP, V14, P130, DOI 10.1109/JSTSP.2019.2963154
   Li L, 2019, IEEE T IMAGE PROCESS, V28, P2342, DOI 10.1109/TIP.2018.2885482
   Li L, 2017, IEEE IMAGE PROC, P1427, DOI 10.1109/ICIP.2017.8296517
   Li YM, 2019, IEEE T CIRC SYST VID, V29, P1767, DOI 10.1109/TCSVT.2018.2846042
   Lin JL, 2019, IEEE J EM SEL TOP C, V9, P84, DOI 10.1109/JETCAS.2019.2899660
   Racape F., 2018, 11 M LJUBLJ SI JUL 1
   Said A., 2015, COM16C1016
   Salehifar M., 2019, M GOTH SE JUL 3 12
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiu XY, 2020, IEEE T CIRC SYST VID, V30, P1296, DOI 10.1109/TCSVT.2019.2945698
   Ye Y., 2019, 13 M MARR MA JAN
   Ye Y, 2020, IEEE T CIRC SYST VID, V30, P1241, DOI 10.1109/TCSVT.2019.2953827
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P3983, DOI 10.1109/TIP.2018.2830640
   Zhang T, 2018, IEEE T MULTIMEDIA, V20, P1622, DOI 10.1109/TMM.2017.2775223
   Zhou YM, 2020, IEEE J-STSP, V14, P118, DOI 10.1109/JSTSP.2019.2957952
   Zhu LW, 2020, IEEE T MULTIMEDIA, V22, P45, DOI 10.1109/TMM.2019.2924591
NR 31
TC 2
Z9 2
U1 1
U2 10
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2021
VL 74
AR 103000
DI 10.1016/j.jvcir.2020.103000
EA JAN 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA QA0OL
UT WOS:000613150900001
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Lee, FF
   Wang, YG
   Miao, R
   Chen, L
   Chen, Q
AF Zhang, Qian
   Lee, Feifei
   Wang, Ya-gang
   Miao, Ran
   Chen, Lei
   Chen, Qiu
TI An improved noise loss correction algorithm for learning from noisy
   labels
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Noisy labels; KL entropy; Mix-up loss; DNN
AB Despite excellent performance in image classification researches, the training of the deep neural networks (DNN) needs a large set of clean data with accurate annotations. The collection of a dataset is easy, but annotating the collected data is difficult on the contrary. There are many image data on the websites, which contain inaccurate annotations, but trainings on these datasets may make networks easier to over-fit noisy data and cause performance degradation. In this work, we propose an improved joint optimization framework for noise correction, which uses the Combination of Mix-up entropy and Kullback-Leibler entropy (CMKL) as the loss function. The new loss function can achieve better fine-tuning results after updating all label annotations. The experimental results on publicly available CIFAR-10 dataset and ClothinglM dataset show superior performance of our approach compared with other state-of-the-art methods.
C1 [Zhang, Qian; Lee, Feifei; Wang, Ya-gang; Miao, Ran; Chen, Lei] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Zhang, Qian; Wang, Ya-gang] Univ Shanghai Sci & Technol, Shanghai Engn Res Ctr Assist Devices, Sch Med Instrument & Food Engn, Shanghai 200093, Peoples R China.
   [Chen, Qiu] Kogakuin Univ, Grad Sch Engn, Major Elect Engn & Elect, Tokyo, Japan.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Kogakuin University
RP Wang, YG; Chen, Q (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM ygwang@usst.edu.cn; q.chen@ieee.org
RI zhang, qian/ITT-5156-2023; CHEN, QIU/G-7959-2012
OI zhang, qian/0000-0003-1749-8653; 
FU National Natural Science Foundation [11502145, 61074087, 61703277]; JSPS
   KAKENHI [15K00159]
FX This work is partially support by National Natural Science Foundation:
   11502145; 61074087; 61703277, and also partially supported by JSPS
   KAKENHI Grant Number 15K00159.
CR Angluin D., 1988, Machine Learning, V2, P343, DOI 10.1007/BF00116829
   [Anonymous], 2017, PROC INT CONF RECON
   Arazo E, 2019, PR MACH LEARN RES, V97
   Arpit, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P34, DOI 10.1145/3154979.3155004
   Dong XW, 2018, IEEE CONF COMPUT
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goldberger J., 2017, INT C LEARNING REPRE
   Goodfellow I.J., 2015, INT C LEARN REPR ICL, P1
   Hardt M., 2016, IEEE C COMP VIS PATT
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2018, ADV NEUR IN, V31
   Jiang Lu, 2018, INT C MACH LEARN ICM
   Jindal I, 2016, IEEE DATA MINING, P967, DOI [10.1109/ICDM.2016.124, 10.1109/ICDM.2016.0121]
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larsen J, 1998, INT CONF ACOUST SPEE, P1205, DOI 10.1109/ICASSP.1998.675487
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Ma XJ, 2018, PR MACH LEARN RES, V80
   Malach E, 2017, ADV NEUR IN, V30
   Neyshabur B., 2014, COMPUTER RES REPOSIT
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Pereyra G., 2017, ICLR WORKSHOP, P1
   Reed S.E., 2015, INT C LEARNING REPRE
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sankaranarayanan S., 2019, IEEE C COMP VIS PATT
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tanaka D, 2018, PROC CVPR IEEE, P5552, DOI 10.1109/CVPR.2018.00582
   Tang MF, 2017, J VIS COMMUN IMAGE R, V48, P310, DOI 10.1016/j.jvcir.2017.07.005
   Tokui S., 2015, C WORKSH NEUR INF PR
   Vandat A, 2017, ADV NEUR IN, V30
   Veit A, 2017, PROC CVPR IEEE, P6575, DOI 10.1109/CVPR.2017.696
   Wang X.F., 2017, J VIS COMMUN IMAGE R, V44, P229
   Wang YR, 2019, IEEE I CONF COMP VIS, P5016, DOI 10.1109/ICCV.2019.00512
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Xu YL, 2019, ADV NEUR IN, V32
   Yi K, 2019, PROC CVPR IEEE, P7010, DOI 10.1109/CVPR.2019.00718
   Yu XR, 2019, PR MACH LEARN RES, V97
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhang WX, 2019, PROC CVPR IEEE, P12428, DOI 10.1109/CVPR.2019.01272
   Zhang Z., 2018, C WORKSHOP NEURAL IN
   Zhao HY, 2020, INT J MACH LEARN CYB, V11, P1483, DOI 10.1007/s13042-019-01052-y
   Zhu SH, 2017, J VIS COMMUN IMAGE R, V44, P229, DOI 10.1016/j.jvcir.2016.08.013
NR 45
TC 8
Z9 8
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2020
VL 72
AR 102930
DI 10.1016/j.jvcir.2020.102930
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA OD3DV
UT WOS:000579732400024
DA 2024-07-18
ER

PT J
AU Cheng, HY
   Yu, CC
AF Cheng, Hsu-Yung
   Yu, Chih-Chang
TI Low-resource automatic cartoon image creation from limited samples
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image creation; Clustering; Convolutional neural networks
AB In this work, a framework that can automatically create cartoon images with low computation resources and small training datasets is proposed. The proposed system performs region segmentation and learns a region relationship tree from each learning image. The segmented regions are clustered automatically with an enhanced clustering mechanism with no prior knowledge of number of clusters. According to the topology represented by region relationship tree and clustering results, the regions are reassembled to create new images. A swarm intelligence optimization procedure is designed to coordinate the regions to the optimized sizes and positions in the created image. Rigid deformation using moving least squares is performed on the regions to generate more variety for created images. Compared with methods based on Generative Adversarial Networks, the proposed framework can create better images with limited computation resources and a very small amount of training samples.
C1 [Cheng, Hsu-Yung] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 32001, Taiwan.
   [Yu, Chih-Chang] Chung Yuan Christian Univ, Dept Informat & Comp Engn, Taoyuan 32023, Taiwan.
C3 National Central University; Chung Yuan Christian University
RP Cheng, HY (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan 32001, Taiwan.
EM chengsy@csie.ncu.edu.tw; ccyu@cycu.edu.tw
OI Cheng, Hsu-Yung/0000-0002-8342-7450
FU Ministry of Science and Technology, Taiwan [109-2221-E-008-071]
FX This work is supported in part by the Ministry of Science and
   Technology, Taiwan under grant number 109-2221-E-008-071.
CR [Anonymous], 2016, C NEUR INF PROC SYST
   [Anonymous], 2012, ICML
   [Anonymous], 2016, ARXIV161200404
   [Anonymous], 2016, NIPS
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Cabanes G, 2007, ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P316, DOI 10.1109/ICMLA.2007.71
   Chen X, 2016, ADV NEUR IN, V29
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   de Amorim RC, 2012, PATTERN RECOGN, V45, P1061, DOI 10.1016/j.patcog.2011.08.012
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everitt B. S., 2011, CLUSTER ANAL, V5, P71
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Y, 2019, IEEE T MULTIMEDIA, V21, P2726, DOI 10.1109/TMM.2019.2908352
   Gurumurthy S, 2017, PROC CVPR IEEE, P4941, DOI 10.1109/CVPR.2017.525
   Hayashi T, 2015, INT J NETW DISTRIB C, V3, P185, DOI 10.2991/ijndc.2015.3.3.6
   Jin Y, 2017, LECT NOTES ARTIF INT, V10357, P1, DOI 10.1007/978-3-319-62701-4_1
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Jing YC, 2020, AAAI CONF ARTIF INTE, V34, P4369
   Jing YC, 2018, LECT NOTES COMPUT SC, V11217, P244, DOI 10.1007/978-3-030-01261-8_15
   Karras T, 2018, P INT C LEARN REPR I
   Kohonen T., 2001, INFORM SCIENCES
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Liu LQ, 2016, IEEE T MULTIMEDIA, V18, P64, DOI 10.1109/TMM.2015.2500730
   Martino L, 2013, COMPUTATION STAT, V28, P2797, DOI 10.1007/s00180-013-0429-2
   Ndjiki-Nya P, 2011, IEEE T MULTIMEDIA, V13, P453, DOI 10.1109/TMM.2011.2128862
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Radford A., 2015, COMPUTER SCI
   Thomas JCR, 2016, P INT C CHIL COMPUT, P49, DOI 10.1109/SCCC.2013.29
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   Simonyan K., 2014, 14091556 ARXIV
   Song ML, 2012, INFORM SCIENCES, V193, P233, DOI 10.1016/j.ins.2012.01.004
   van den Oord A, 2016, ADV NEUR IN, V29
   Xu R, 2012, IEEE T SYST MAN CY B, V42, P1243, DOI 10.1109/TSMCB.2012.2188509
   Xu WJ, 2019, IEEE T MULTIMEDIA, V21, P2387, DOI 10.1109/TMM.2019.2898777
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
NR 39
TC 0
Z9 0
U1 0
U2 2
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2020
VL 71
AR 102863
DI 10.1016/j.jvcir.2020.102863
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA NR7QJ
UT WOS:000571755000005
DA 2024-07-18
ER

PT J
AU Wu, XT
   Yang, CN
AF Wu, Xiaotian
   Yang, Ching-Nung
TI Probabilistic color visual cryptography schemes for black and white
   secret images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual cryptography; Probabilistic; Color; Black and white; Pixel
   expansion; Secret image sharing
ID SHARING SCHEMES; PROGRESSIVE K; CONTRAST; QUALITY
AB Color-black-and-white visual cryptography scheme (CBW-VCS) is a methodology that utilizes colors to alleviate the pixel expansion problem. In a general (k, n) CBW-VCS, when k and n become larger, the pixel expansion increases dramatically. In this paper, two constructions for constituting a (k, n) threshold probabilistic CBW-VCS (PCBW-VCS) are introduced, where the generated color shares are non-expansible. The two proposed constructions are proven to be valid constructions which satisfy the security and contrast conditions. Theoretical analysis and sufficient experiments are demonstrated to shown the effectiveness and advantages of the proposed PCBW-VCSs. (C) 2020 Elsevier Inc. All rights reserved.
C1 [Wu, Xiaotian] Jinan Univ, Dept Comp Sci, Guangzhou, Peoples R China.
   [Yang, Ching-Nung] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 Jinan University; National Dong Hwa University
RP Yang, CN (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
EM wxiaotian@jnu.edu.cn; cnyang@gms.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
FU National Natural Science Foundation of China [61972179, 61602211];
   Science and Technology Program of Guangzhou, China [201707010259];
   Fundamental Research Funds for the Central Universities; Ministry of
   Science and Technology [108-2221-E-259-009-MY2]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos. 61972179 and 61602211), Science and Technology
   Program of Guangzhou, China (Grant No. 201707010259), Fundamental
   Research Funds for the Central Universities, and Ministry of Science and
   Technology, under Grant 108-2221-E-259-009-MY2.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 1998, COMPUT GRAPH, V22, P449, DOI 10.1016/S0097-8493(98)00034-X
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Blundo C, 2006, THEOR COMPUT SCI, V369, P169, DOI 10.1016/j.tcs.2006.08.008
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   De Prisco R, 2013, THEOR COMPUT SCI, V510, P62, DOI 10.1016/j.tcs.2013.09.005
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Jia XX, 2019, MULTIMED TOOLS APPL, V78, P8207, DOI 10.1007/s11042-018-6779-6
   Jia XX, 2018, IEEE T CIRC SYST VID, V28, P1056, DOI 10.1109/TCSVT.2016.2631404
   Liu YX, 2018, J VIS COMMUN IMAGE R, V55, P766, DOI 10.1016/j.jvcir.2018.08.003
   Liu YX, 2018, SIGNAL PROCESS-IMAGE, V66, P77, DOI 10.1016/j.image.2018.05.004
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ren YW, 2017, IET INFORM SECUR, V11, P211, DOI 10.1049/iet-ifs.2016.0126
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shyu SJ, 2011, IEEE T INF FOREN SEC, V6, P960, DOI 10.1109/TIFS.2011.2158096
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wang DS, 2013, IEEE T INF FOREN SEC, V8, P2059, DOI 10.1109/TIFS.2013.2281108
   Wu XT, 2019, J VIS COMMUN IMAGE R, V61, P74, DOI 10.1016/j.jvcir.2019.03.020
   Wu XT, 2014, IEEE T INF FOREN SEC, V9, P1592, DOI 10.1109/TIFS.2014.2346014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P552, DOI 10.1016/j.jvcir.2013.03.002
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Wu XT, 2012, J SYST SOFTWARE, V85, P1119, DOI 10.1016/j.jss.2011.12.041
   Yan B, 2019, IEEE T IMAGE PROCESS, V28, P896, DOI 10.1109/TIP.2018.2874378
   Yan XH, 2019, J VIS COMMUN IMAGE R, V58, P89, DOI 10.1016/j.jvcir.2018.11.031
   Yan XH, 2019, SIGNAL PROCESS-IMAGE, V71, P66, DOI 10.1016/j.image.2018.11.002
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yang CN, 2008, COMPUT J, V51, P710, DOI 10.1093/comjnl/bxm118
   Yang CN, 2018, J VIS COMMUN IMAGE R, V55, P660, DOI 10.1016/j.jvcir.2018.07.012
   Yang CN, 2016, THEOR COMPUT SCI, V609, P143, DOI 10.1016/j.tcs.2015.09.016
   Yang CN, 2014, IEEE T CIRC SYST VID, V24, P189, DOI 10.1109/TCSVT.2013.2276708
   Yang CN, 2005, PATTERN RECOGN LETT, V26, P193, DOI 10.1016/j.patrec.2004.08.025
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 39
TC 26
Z9 27
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2020
VL 70
AR 102793
DI 10.1016/j.jvcir.2020.102793
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA MO6NU
UT WOS:000551640900011
DA 2024-07-18
ER

PT J
AU Liu, ZK
AF Liu, Zhenkun
TI 3DSportNet: 3D sport reconstruction by quality-aware deep multi-video
   summation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D reconstruction; Quality model; Weakly-supervised learning
ID SCENE CLASSIFICATION; SIMULATION; FEATURES
AB Automatically reconstructing 3D sceneries from video sequences is an indispensable technique in computer 3D games, urban planning, and intelligent navigation. Many previous work relies on complicated and expensive equipment to fulfill 3D reconstruction under constrained environments. Nevertheless, such schemes are not readily to be applied for reconstructing 3D sport sceneries, such as basketball and mountain climbing. In this work, we propose a novel deep architecture: 3DSportNet, which reconstructs 3D sport sceneries by making use of multiple handheld videos captured by smart phones. In particular, given a rich of mobile videos captured by users, we extract multiple deep/shallow visual features from each sport video frame by leveraging the weakly-supervised semantic encoding. Afterward, a geometry-aware quality model is designed to summarize the multiple videos into multiple key frames from each single video, wherein the objective is that the selected key frames can maximally reconstruct the multiple sport videos. Based on this, we employ the key frames to reconstruct sport videos by utilizing the PMVS2 software. Comprehensive experimental comparisons and visualization results have shown that our method can produce very real 3D sport sceneries and athletes. Besides, the 3D reconstruction time consumption is reduced by 95% compared to conventional methods. (C) 2019 Published by Elsevier Inc.
C1 [Liu, Zhenkun] Xuchang Univ, Sch Phys Educ, Xuchang, Henan, Peoples R China.
C3 Xuchang University
RP Liu, ZK (corresponding author), Xuchang Univ, Sch Phys Educ, Xuchang, Henan, Peoples R China.
EM 12005061@xcu.edu.cn
CR [Anonymous], J ELECT INFORM TECHN
   [Anonymous], P CVPR IEEE COMP SOC
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2015, HARVESTING DISCRIMIN
   [Anonymous], P NIPS
   [Anonymous], 2011, 6 INT C IM GRAPH
   [Anonymous], IEEE T SERV COMPUT
   [Anonymous], 2016, P IEEE C COMPUTER VI, DOI DOI 10.1109/CVPR.2016.90
   [Anonymous], IEEE T MULTIMEDIA
   [Anonymous], MULTIVIEW METRIC LEA
   [Anonymous], UNSUPERVISED REPRESE
   [Anonymous], GEOSC REM SENS S
   [Anonymous], 2018, IEEE INT C SOL STAT, DOI DOI 10.1109/ICSICT.2018.8564869
   [Anonymous], INT C NEUR INF PROC
   Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026
   Chaabouni S, 2019, J VIS COMMUN IMAGE R, V60, P79, DOI 10.1016/j.jvcir.2019.02.004
   Cheng HY, 2012, IEEE T IMAGE PROCESS, V21, P2152, DOI 10.1109/TIP.2011.2172798
   Cheriyadat AM, 2014, IEEE T GEOSCI REMOTE, V52, P439, DOI 10.1109/TGRS.2013.2241444
   COSTEA D, 2016, AERIAL IMAGE GEOLOCA
   Dai QQ, 2017, IEEE T IMAGE PROCESS, V26, P765, DOI 10.1109/TIP.2016.2631339
   Di Mauro D, 2019, J VIS COMMUN IMAGE R, V62, P234, DOI 10.1016/j.jvcir.2019.05.015
   Kao D, 2001, IEEE VISUAL, P457, DOI 10.1109/VISUAL.2001.964550
   Kossyk I, 2019, J VIS COMMUN IMAGE R, V61, P121, DOI 10.1016/j.jvcir.2019.03.008
   Mai G., 2018, IEEE T PATTERN ANAL, P1
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Wang Z, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P65, DOI 10.1109/ICIP.2002.1038904
   Wei W, 2016, INFORM SCIENCES, V330, P403, DOI 10.1016/j.ins.2015.10.024
   Xu F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964927
   Xu ML, 2014, J COMPUT SCI TECH-CH, V29, P799, DOI 10.1007/s11390-014-1469-y
   Xu ML, 2015, NEUROCOMPUTING, V168, P529, DOI 10.1016/j.neucom.2015.05.074
   Xu ML, 2013, IEEE MULTIMEDIA, V20, P49, DOI 10.1109/MMUL.2012.54
   Xu ML, 2010, COMPUT GRAPH FORUM, V29, P2187, DOI 10.1111/j.1467-8659.2010.01807.x
   Yu YL, 2018, IEEE GEOSCI REMOTE S, V15, P287, DOI 10.1109/LGRS.2017.2786241
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhou L, 2013, PATTERN RECOGN, V46, P424, DOI 10.1016/j.patcog.2012.07.017
NR 35
TC 3
Z9 4
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD DEC
PY 2019
VL 65
AR 102651
DI 10.1016/j.jvcir.2019.102651
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JU0WA
UT WOS:000501398700002
DA 2024-07-18
ER

PT J
AU Hou, R
   Pan, MM
   Zhao, YH
   Yang, Y
AF Hou Rui
   Pan MingMing
   Zhao YunHao
   Yang Yang
TI Image anomaly detection for IoT equipment based on deep learning
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Operating environment monitoring; Image anomaly detection; Deep learning
ID IDENTIFICATION; DYNAMICS; SYSTEM
AB Intelligent power grid systems is the trend of power development, since traditional methods of manually monitoring power equipment have been unable to meet the requirements of power systems. When an abnormal situation occurs in the operating environment, most monitoring devices cannot be quickly and accurately identified, which may have serious consequences. Aiming at the above problems, in this paper, we propose an anomaly detection algorithm for the monitoring environment of power IoT equipment operating environment based on deep learning from the perspective of personnel identification and fire smoke detection. The multi-stream CNN-based remote monitoring image personnel detection method and the deep convolutional neural network-based fire smoke detection method have achieved good results in personnel identification and fire smoke detection in the power equipment operating environment monitoring image, respectively. This provides a reference for monitoring image anomaly detection. (C) 2019 Published by Elsevier Inc.
C1 [Hou Rui; Zhao YunHao] North China Elect Power Univ, Sch Econ & Management, Beijing 102206, Peoples R China.
   [Hou Rui; Zhao YunHao] North China Elect Power Univ, Res Ctr Energy Network, Beijing 102206, Peoples R China.
   [Pan MingMing] China Elect Power Res Inst, Beijing 100192, Peoples R China.
   [Yang Yang] State Grid Hebei Econ Res Inst, Shijiazhuang 050021, Hebei, Peoples R China.
C3 North China Electric Power University; North China Electric Power
   University
RP Pan, MM (corresponding author), China Elect Power Res Inst, Beijing 100192, Peoples R China.
EM hankrui@aliyun.com; panmingmingl@epri.sgcc.com
FU National Key RD Plan [2018YFB0605504]; Fundamental Research Funds for
   the Central Universities
FX Supported by "National Key R&D Plan": 2018YFB0605504.; Supported by "the
   Fundamental Research Funds for the Central Universities".
CR Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   [Anonymous], 2017, J VIS COMMUN IMAGE R
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Bai C, 2018, J VIS COMMUN IMAGE R, V50, P199, DOI 10.1016/j.jvcir.2017.11.021
   Chang J., 2018, J VISUAL COMMUN IMAG
   Chen Qi, 2017, J CHINA JILIANG U, V4, P106
   Cheng Weihua, 2016, ELECT TECHNOL SOFTWA, V7, P30
   Cheng Xianyi, 2018, J NANJING NORMAL U E, V18, P39
   Cosar S., 2016, IEEE T CIRCUITS SYST, V27, P1
   Cui YJ, 2016, APPL MATH LETT, V51, P48, DOI 10.1016/j.aml.2015.07.002
   Fu HL, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10072488
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE T CIRC SYST VID, V28, P2473, DOI 10.1109/TCSVT.2017.2706264
   Hao Peng, 2017, GLOBAL MARKET, V14, P150
   Huang Hongbing, 2017, ELECT POWER INFORM C, V3, P106
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Jing Wang, 2017, MODERN BUS IND, V5, P192
   Kang L, 2018, COMPLEXITY, DOI 10.1155/2018/6703908
   Kumar N, 2015, IEEE T INTELL TRANSP, V16, P1148, DOI 10.1109/TITS.2014.2354372
   Lai Huanhuan, 2016, ELECTRON ENG, V7, P46
   [雷亚国 Lei Yaguo], 2015, [机械工程学报, Journal of Mechanical Engineering], V51, P49
   Lu DJ, 2018, IEEE T VEH TECHNOL, V67, P11219, DOI 10.1109/TVT.2018.2870872
   Luo Lijuan, 2017, SCI TECHNOL INFORM, V15, P59
   Meng XZ, 2016, J MATH ANAL APPL, V433, P227, DOI 10.1016/j.jmaa.2015.07.056
   MIN ZY, 2018, INFRARED TECHNOL, V9, DOI DOI 10.1186/S13287-018-0950-X
   Motlagh NH, 2017, IEEE COMMUN MAG, V55, P128, DOI 10.1109/MCOM.2017.1600587CM
   Peng Yang, 2017, ELECT ENG, V8
   Pramanik R, 2018, J VIS COMMUN IMAGE R, V50, P123, DOI 10.1016/j.jvcir.2017.11.016
   Qi Kaiyuan, 2017, DIGITAL COMMUN WORLD, V9, P174
   Shan PF, 2018, TRANSPORT POROUS MED, V124, P1061, DOI 10.1007/s11242-018-1110-6
   [宋焕生 Song Huansheng], 2018, [计算机应用研究, Application Research of Computers], V35, P1270
   Wang Hongbin, 2017, HIGH VOLTAGE APPARAT, V8, P204
   Wang SK, 2016, MULTIMED TOOLS APPL, V75, P11603, DOI 10.1007/s11042-015-2698-y
   Wei W, 2016, J EARTH SCI-CHINA, V27, P233, DOI 10.1007/s12583-015-0657-1
   Wu Yuqian, 2017, J COMPUT MEASUR CONT, V7
   Xie Guanghui, 2017, HELIYON, V3
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu ML, 2021, IEEE T AFFECT COMPUT, V12, P227, DOI 10.1109/TAFFC.2018.2868651
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu ML, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982425
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Ying L, 2015, IEEE T MULTIMEDIA, V18, P351
   Yong Yu, 2017, CHINA HIGH TECH ZONE, V22, P153
   Yu Wang, 2016, SCI TECHNOL COMMUN, V8
   Zhang Hui, 2017, ACTA AUTOMAT SIN, V8
   Zhang M., 2018, J VIS COMMUN IMAGE R, P53
   Zhao QL, 2016, ANAL MATH PHYS, V6, P237, DOI 10.1007/s13324-015-0116-2
   Zhou XP, 2018, IEEE T KNOWL DATA EN, V30, P1178, DOI 10.1109/TKDE.2017.2784430
NR 49
TC 13
Z9 13
U1 4
U2 42
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102599
DI 10.1016/j.jvcir.2019.102599
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600004
DA 2024-07-18
ER

PT J
AU Zhang, YJ
   Gong, S
   Luo, MJ
AF Zhang, Yanjun
   Gong, Shuai
   Luo, Mingjiu
TI Image quality guided biology application for genetic analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Low-level features; Deep learning; BP neural
   network
ID TIMED ARTIFICIAL-INSEMINATION; REPRODUCTIVE-PERFORMANCE; FERTILITY;
   PROGESTERONE; STATE
AB Image quality assessment (IQA) is widely applied in image processing, such as image retrieval, image aesthetic evaluation and image classification. To expand application of IQA, we propose a novel method toward biology application using IQA for genetic research. The proposed approach breaks through limitations of traditional biology research, which integrates image processing algorithms with biology applications. Specifically, we first conduct the dataset acquisition including frozen semen images and their according biology scores that reflect genetic attributes. Then, each obtained image will be assigned a quality score according to its grayscale features and texture features. Afterward, we leverage BP neural network for deep feature extraction with fusing quality score and biology score as tags. Finally, given a test image, we can predict its genetic attribute according to deep-learned model. Comprehensive experiments conducted on goat genetic research demonstrate satisfied performance of proposed method. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Zhang, Yanjun; Gong, Shuai; Luo, Mingjiu] Shandong Agr Univ, Coll Anim Sci & Vet, Tai An, Shandong, Peoples R China.
   [Zhang, Yanjun] Jiaxiang Cty Anim Husb & Vet Bur, Jining, Shandong, Peoples R China.
C3 Shandong Agricultural University
RP Luo, MJ (corresponding author), Shandong Agr Univ, Coll Anim Sci & Vet, Tai An, Shandong, Peoples R China.
EM zhangyanjun1995@163.com; gongshuai5@163.com; luomj@sdau.edu.cn
RI yan, wang/JRW-9981-2023; Luo, Mingjiu/AAU-8570-2021; zhang,
   yu/HNS-5948-2023; Zhang, Y J/HLG-1022-2023
OI Luo, Ming Jiu/0000-0003-0460-8358
FU National Key R&D Program of China [2017YFD0501904]; Funds of Shandong
   Double Tops Program [SYL2017YSTD12]
FX This work was supported by National Key R&D Program of China (Grant No.
   2017YFD0501904), and the Funds of Shandong Double Tops Program (No.
   SYL2017YSTD12).
CR Abecia JA, 2016, INT J BIOMETEOROL, V60, P1603, DOI 10.1007/s00484-016-1150-y
   Anagun Y, 2019, J VIS COMMUN IMAGE R, V61, P178, DOI 10.1016/j.jvcir.2019.03.027
   Benmoula A., 2018, ANIMAL REPROD SCI, V192
   Bisinotto RS, 2015, J DAIRY SCI, V98, P2472, DOI 10.3168/jds.2014-8954
   Borzan M.M., 2015, B U AGR SCI VET MED, V72, P33
   Chang J., 2018, J VISUAL COMMUN IMAG
   Chen L, 2014, OPT LASER TECHNOL, V57, P265, DOI 10.1016/j.optlastec.2013.10.005
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   David I, 2015, ANIM REPROD SCI, V161, P75, DOI 10.1016/j.anireprosci.2015.08.006
   Ding SF, 2015, ARTIF INTELL REV, V43, P593, DOI 10.1007/s10462-013-9398-7
   Duan H, 2009, J SYST SOFTWARE, V82, P400, DOI 10.1016/j.jss.2008.07.007
   Esses S.J., 2017, J MAGNETIC RESON IMA, V47
   Fontana DL, 2014, ANIM REPROD SCI, V144, P109, DOI 10.1016/j.anireprosci.2013.12.003
   Fricke PM, 2014, J DAIRY SCI, V97, P2771, DOI 10.3168/jds.2013-7366
   Furstoss V, 2015, ANIMAL, V9, P1935, DOI 10.1017/S1751731115001500
   Geenty KG, 2014, ANIM PROD SCI, V54, P715, DOI 10.1071/AN11323
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Han Junwei, SYSTEMS MAN CYBERN A
   Howard J.G., 2015, ZOO BIOL, V15, P55
   Huang X, 2016, NEUROCOMPUTING, V218, P296, DOI 10.1016/j.neucom.2016.08.078
   Ibn Afjal M, 2019, J VIS COMMUN IMAGE R, V59, P514, DOI 10.1016/j.jvcir.2019.01.042
   Kalloo F.A., 2014, IND J ANIMAL SCI, V73, P63
   Liu L, 2015, COMPUT GEOSCI-UK, V83, P27, DOI 10.1016/j.cageo.2015.06.017
   Maia M.D.S., 2015, ACTA VET BRASILICA, V8, P389
   Masoudi R., 2014, PROG CLIN BIOL RES, V55, P123
   Monteiro PLJ, 2014, J DAIRY SCI, V97, P4907, DOI 10.3168/jds.2013-7802
   Olsen MA, 2016, IET BIOMETRICS, V5, P47, DOI 10.1049/iet-bmt.2014.0055
   Palacios C, 2014, BIOL RHYTHM RES, V45, P869, DOI 10.1080/09291016.2014.923621
   Santolaria P, 2015, ANIM REPROD SCI, V163, P82, DOI 10.1016/j.anireprosci.2015.10.001
   Sheng L, 2017, IEEE T NEUR NET LEAR, V28, P2382, DOI 10.1109/TNNLS.2016.2580601
   Shokrollahi A, 2017, AEU-INT J ELECTRON C, V77, P61, DOI 10.1016/j.aeue.2017.04.026
   Song BY, 2017, COGN COMPUT, V9, P5, DOI 10.1007/s12559-016-9442-4
   Sun HM, 2016, COMPUT GEOSCI-UK, V91, P98, DOI 10.1016/j.cageo.2016.03.012
   Tian ZW, 2016, COMPUT GEOSCI-UK, V86, P15, DOI 10.1016/j.cageo.2015.10.002
   Tsuma V.T., 2015, J MAULANA AZAD COLL, V30, P137
   Wang H, 2013, INFORM SCIENCES, V223, P221, DOI 10.1016/j.ins.2012.08.027
   Wang JJ, 2014, J ZHEJIANG U-SCI C, V15, P383, DOI 10.1631/jzus.C1300289
   Xie Z, 2019, J VIS COMMUN IMAGE R, V59, P62, DOI 10.1016/j.jvcir.2019.01.006
   Xu ML, 2018, IEEE T CIRC SYST VID, V28, P2814, DOI 10.1109/TCSVT.2017.2731866
   Xu ML, 2017, IEEE T IMAGE PROCESS, V26, P5811, DOI 10.1109/TIP.2017.2737321
   Xu Mingliang, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/298017910.1145/2980179.2982425
   Yan B, 2013, MULTIMED TOOLS APPL, V67, P383, DOI 10.1007/s11042-011-0861-7
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yang M, 2014, IEEE SIGNAL PROC LET, V21, P1215, DOI 10.1109/LSP.2014.2330848
   Zhang M, 2018, J VIS COMMUN IMAGE R, V53, P215, DOI 10.1016/j.jvcir.2018.03.019
   Zhang Y., 2014, ACTA PHOTONICA SINIC, V43
NR 46
TC 0
Z9 0
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2019
VL 64
AR 102606
DI 10.1016/j.jvcir.2019.102606
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA JH5HB
UT WOS:000492798600002
DA 2024-07-18
ER

PT J
AU Ge, LW
   Zhang, J
   Xia, Y
   Chen, P
   Wang, B
   Zheng, CH
AF Ge, Lin-Wei
   Zhang, Jun
   Xia, Yi
   Chen, Peng
   Wang, Bing
   Zheng, Chun-Hou
TI Deep spatial attention hashing network for image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Hash function; Deep learning; Image retrieval; Convolutional neural
   network (CNN); Deep hashing
AB Hashing is one of the most popular image retrieval technique since its fast-computational speed and low storage cost. Recently, deep hashing methods have greatly improved the image retrieval performance in contrast to traditional hashing method. However, the binary hashing representation is only generated from the global image region, which may result in sub-optimal hashing code. Inspired by the latest advance in spatial attention mechanism, we propose an novel end-to-end deep hashing framework which composes of two sub-networks. One sub-network uses spatial attention model to determine the local features from more specific region of interest, another sub-network extracts the global features from original image. By combining the local and global features with learnable hash functions, the proposed deep hashing framework can optimize the deep hash function and high-quality binary code jointly. Numerous experiments on two large scale image benchmarks datasets have shown that the proposed method is superior to other existing methods for image retrieval. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ge, Lin-Wei; Zhang, Jun; Xia, Yi] Anhui Univ, Coll Elect Engn & Automat, Hefei 230601, Anhui, Peoples R China.
   [Chen, Peng; Zheng, Chun-Hou] Anhui Univ, Coll Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.
   [Wang, Bing] Anhui Univ Technol, Sch Elect & Informat Engn, Maanshan 243032, Peoples R China.
C3 Anhui University; Anhui University; Anhui University of Technology
RP Zhang, J (corresponding author), Anhui Univ, Coll Elect Engn & Automat, Hefei 230601, Anhui, Peoples R China.; Chen, P (corresponding author), Anhui Univ, Coll Comp Sci & Technol, Hefei 230601, Anhui, Peoples R China.; Wang, B (corresponding author), Anhui Univ Technol, Sch Elect & Informat Engn, Maanshan 243032, Peoples R China.
EM 00568@ahu.edu.cn
RI Ge, Linwei/AAP-4914-2020; Chen, Peng/E-4507-2011
OI WANG, BING/0000-0003-4945-7725; Chen, Peng/0000-0002-5810-8159; Zhang,
   Jun/0000-0002-5985-8023
FU National Natural Science Foundation of China [61872004, 61672035]; Anhui
   Scientific Research Foundation for Returned Scholars
FX This work is supported by National Natural Science Foundation of China
   (grant numbers 61872004 and 61672035) and Anhui Scientific Research
   Foundation for Returned Scholars.
CR Andoni A., 2006, FDN COMPUTER SCI
   [Anonymous], 28 BRIT MACH VIS C B
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], P IEEE C COMPU VIS P
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], COLUMN SAMPLING BASE
   [Anonymous], INT C INT C MACH LEA
   [Anonymous], P INT C MACH LEARN
   [Anonymous], INT JOINT C ART INT
   [Anonymous], 2014, AAAI C ART INT
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], DATA COMPRESSION C
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C ART INT
   [Anonymous], INT C NEUR INF PROC
   [Anonymous], 2016, Deep Supervised Hashing With Triplet Labels
   [Anonymous], 2017, P ADV NEUR INF PROC
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2467315
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], COMPUT SCI
   [Anonymous], INT C INT C MACH LEA
   [Anonymous], SIGGRAPH ASIA
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], TIP
   [Anonymous], INT JOINT C ART INT
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2015, PROC 28 INT C NEURAL
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Lai HJ, 2015, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2015.7298947
   Li C, 2018, MULTIMED TOOLS APPL, V77, P21371, DOI 10.1007/s11042-017-5542-8
   Li Q, 2017, ADV NEUR IN, V30
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Song DJ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2229, DOI 10.1145/3219819.3220108
   Zhan K, 2016, J VIS COMMUN IMAGE R, V40, P847, DOI 10.1016/j.jvcir.2016.08.016
   Zhang ZM, 2016, PROC CVPR IEEE, P1487, DOI 10.1109/CVPR.2016.165
   Zhou X., 2018, IEEE Trans. Cybern., P1
NR 42
TC 10
Z9 10
U1 1
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2019
VL 63
AR 102577
DI 10.1016/j.jvcir.2019.102577
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IU3AD
UT WOS:000483450200013
DA 2024-07-18
ER

PT J
AU Fan, CL
   Zhang, Y
   Zhang, H
   Hamzaoui, R
   Jiang, QS
AF Fan, Chunling
   Zhang, Yun
   Zhang, Huan
   Hamzaoui, Raouf
   Jiang, Qingshan
TI Picture-level just noticeable difference for symmetrically and
   asymmetrically compressed stereoscopic images: Subjective quality
   assessment study and datasets
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Picture-level JND; Subjective quality assessment test; Stereoscopic
   image
ID SIMILARITY; MODEL; EDGE
AB The Picture-level Just Noticeable Difference (PJND) for a given image and compression scheme reflects the smallest distortion level that can be perceived by an observer with respect to a reference image. Previous work has focused on the PJND of images and videos. In this paper, we study the PJND of symmetrically and asymmetrically compressed stereoscopic images for JPEG2000 and H.265 intra coding. We conduct interactive subjective quality assessment tests to determine the PJND point using both a pristine image and a distorted image as a reference. We find that the PJND points are highly dependent on the image content. In asymmetric compression, there exists a perceptual threshold in the quality difference between the left and right views due to the binocular masking effect. We generate two PJND-based stereo image datasets (one for symmetric compression and one for asymmetric compression) and make them accessible to the public. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Fan, Chunling; Zhang, Yun; Zhang, Huan; Jiang, Qingshan] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
   [Fan, Chunling; Zhang, Huan] Univ Chinese Acad Sci, Shenzhen Coll Adv Technol, Beijing, Peoples R China.
   [Hamzaoui, Raouf] De Montfort Univ, Sch Engn & Sustainable Dev, Leicester, Leics, England.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS; De Montfort University
RP Zhang, Y (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China.
EM yun.zhang@siat.ac.cn
RI Zhang, Yun/V-7261-2019; Zhang, Huan/JMB-8621-2023; Zhang,
   Huan/AFB-3705-2022
OI Zhang, Yun/0000-0001-9457-7801; Zhang, Huan/0000-0002-5507-4985
FU NSFC [61871372]; Guangdong NSF for Distinguished Young Scholar
   [2016A030306022]; Guangdong Provincial Science and Technology
   Development [2017B010110014]; Shenzhen International Collaborative
   Research Project [GJHZ20170314155404913]; Shenzhen Science and
   Technology Program [JCYJ20170811160212033]; Guangdong International
   Science and Technology Cooperative Research Project [2018A050506063];
   Membership of Youth Innovation Promotion Association, CAS [2018392];
   Shenzhen Key Technologies Program [JSGG20160229123657040]
FX This work was supported in part by the NSFC under Grant 61871372,
   Guangdong NSF for Distinguished Young Scholar under Grant
   2016A030306022, Guangdong Provincial Science and Technology Development
   under Grant 2017B010110014, Shenzhen International Collaborative
   Research Project under Grant GJHZ20170314155404913, Shenzhen Science and
   Technology Program under Grant JCYJ20170811160212033, Guangdong
   International Science and Technology Cooperative Research Project under
   Grant 2018A050506063, Membership of Youth Innovation Promotion
   Association, CAS under Grant 2018392, in part by the Shenzhen Key
   Technologies Program under Grant JSGG20160229123657040.
CR [Anonymous], IEEE T CONSUM ELECT
   [Anonymous], 1999, Subjective Video Quality Assessment Methods for Multimedia Applications
   [Anonymous], 2012, GEN VIEW COND SUBJ A
   [Anonymous], 2002, RIRBT50011
   [Anonymous], IEEE INT C AC SPEECH
   Blake R, 2002, NAT REV NEUROSCI, V3, P13, DOI 10.1038/nrn701
   Bossen F., 2013, JCTVCM1010
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   De Silva DVSX, 2010, IEEE INT CON MULTI, P1219, DOI 10.1109/ICME.2010.5582582
   Eli Brenner J.B.S., 2018, STEVENS HDB EXP PSYC, V2, P1
   Fan C., 2019, 11 INT C QUAL MULT E
   Fan Y, 2017, IEEE IMAGE PROC, P760, DOI 10.1109/ICIP.2017.8296383
   Gorley P., 2008, STEREOSCOPIC DISPLAY, V6803
   GRUBBS FE, 1950, ANN MATH STAT, V21, P27, DOI 10.1214/aoms/1177729885
   Jiang GY, 2018, IET IMAGE PROCESS, V12, P810, DOI 10.1049/iet-ipr.2017.0650
   Jiang QP, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043002
   Jin L., 2016, Electronic Imaging, V2016, P1
   Lin JY, 2015, PROC SPIE, V9599, DOI 10.1117/12.2188389
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu AM, 2010, IEEE T CIRC SYST VID, V20, P1648, DOI 10.1109/TCSVT.2010.2087432
   Liu XK, 2015, IEEE T IMAGE PROCESS, V24, P4847, DOI 10.1109/TIP.2015.2469140
   Ni ZK, 2017, IEEE T IMAGE PROCESS, V26, P4818, DOI 10.1109/TIP.2017.2718185
   Oh H, 2017, IEEE T IMAGE PROCESS, V26, P3789, DOI 10.1109/TIP.2017.2702383
   Qi F, 2016, SIGNAL IMAGE VIDEO P, V10, P737, DOI 10.1007/s11760-015-0802-4
   Shao F, 2016, IEEE T IMAGE PROCESS, V25, P2059, DOI 10.1109/TIP.2016.2538462
   Siahaan E, 2016, IEEE T MULTIMEDIA, V18, P1338, DOI 10.1109/TMM.2016.2559942
   Urvoy M, 2012, INT WORK QUAL MULTIM, P109, DOI 10.1109/QoMEX.2012.6263847
   Wang H., 2018, MULTIMEDIA
   Wang HG, 2016, IEEE IMAGE PROC, P1509, DOI 10.1109/ICIP.2016.7532610
   Wang HQ, 2017, J VIS COMMUN IMAGE R, V46, P292, DOI 10.1016/j.jvcir.2017.04.009
   Wang SQ, 2016, IEEE T IMAGE PROCESS, V25, P3838, DOI 10.1109/TIP.2016.2573597
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Winkler S, 2012, IEEE J-STSP, V6, P616, DOI 10.1109/JSTSP.2012.2215007
   Wu JJ, 2017, IEEE T IMAGE PROCESS, V26, P2682, DOI 10.1109/TIP.2017.2685682
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1705, DOI 10.1109/TMM.2013.2268053
   Xu L, 2016, DISPLAYS, V44, P21, DOI 10.1016/j.displa.2016.06.002
   Xu L, 2016, IEEE T MULTIMEDIA, V18, P590, DOI 10.1109/TMM.2016.2525004
   You Q, 2010, INFORM VISUAL, V9, P1, DOI 10.1057/ivs.2008.3
   Zhao Y, 2011, IEEE SIGNAL PROC LET, V18, P19, DOI 10.1109/LSP.2010.2090041
   Zhou WJ, 2017, NEUROCOMPUTING, V224, P128, DOI 10.1016/j.neucom.2016.10.046
NR 40
TC 13
Z9 13
U1 0
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 140
EP 151
DI 10.1016/j.jvcir.2019.04.016
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600013
DA 2024-07-18
ER

PT J
AU Sadeghi, H
   Raie, AA
AF Sadeghi, Hamid
   Raie, Abolghasem-A.
TI Histogram distance metric learning for facial expression recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Metric learning; Local metric learning; Chi-squared distance; Histogram
   classification; Facial expression recognition in the wild
ID EMOTION RECOGNITION; GAIT RECOGNITION; FACE RECOGNITION; CLASSIFICATION;
   DESCRIPTORS; MANIFOLD
AB Facial expression recognition is an interesting and challenging problem in computer vision. So far, much research has been performed in this area: however, facial expression recognition in uncontrolled conditions has remained an unresolved problem. The widely-used feature descriptors in computer vision are often histogram data. In this paper, a new metric learning method is presented for histogram data classification. In this method, chi-squared distance is appropriately modified for metric learning. Then, a convex cost function is proposed to use in metric learning optimization. Moreover, the proposed algorithm is redefined as Local Metric Learning for facial expression recognition problem. In this definition, the proposed metric learning method is applied locally on facial sub-regions. Experimental results on four histogram datasets (dslr, webcam, amazon, and caltech) as well as controlled and uncontrolled facial expression recognition datasets (CK+, SFEW, and RAF-DB) show that the proposed method has superior performance compared to the state-of-art methods. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Sadeghi, Hamid; Raie, Abolghasem-A.] Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
C3 Amirkabir University of Technology
RP Raie, AA (corresponding author), Amirkabir Univ Technol, Elect Engn Dept, Tehran, Iran.
EM raie@aut.ac.ir
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2014, J INF SYST TELECOMMU
   [Anonymous], 2018, ARXIV180206664
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], 2018, arXiv:1805.02397
   [Anonymous], P 15 ACM INT C MULT
   [Anonymous], 2011, NIPS
   [Anonymous], 2005, HDB FACE RECOGNITION
   Nguyen B, 2017, PATTERN RECOGN, V64, P215, DOI 10.1016/j.patcog.2016.11.010
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Bellet A., 2013, SURVEY METRIC LEARNI
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   Ben XY, 2016, NEURAL COMPUT APPL, V27, P2629, DOI 10.1007/s00521-015-2031-8
   Ben XY, 2013, NEUROCOMPUTING, V120, P577, DOI 10.1016/j.neucom.2013.04.012
   Ben XY, 2012, NEUROCOMPUTING, V97, P44, DOI 10.1016/j.neucom.2012.06.022
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chen J., 2014, P 16 INT C MULT INT, P508, DOI DOI 10.1145/2663204.2666277
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   Davis J. V., 2007, ICML, P209
   Dhall A., 2011, TECHNICAL REPORT
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Ding C, 2005, SIAM PROC S, P32
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Eleftheriadis S, 2015, IEEE T IMAGE PROCESS, V24, P189, DOI 10.1109/TIP.2014.2375634
   Etemadi A, 2013, 2013 IEEE MALAYSIA INTERNATIONAL CONFERENCE ON COMMUNICATIONS (MICC), P110, DOI 10.1109/MICC.2013.6805809
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hinton G. E., 2012, 12070580 ARXIV
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Huang LK, 2014, J VIS COMMUN IMAGE R, V25, P1774, DOI 10.1016/j.jvcir.2014.08.006
   Jain P., 2008, NIPS, P761, DOI 10.5555/2981780.2981875
   Jia XT, 2018, J COMPUT SCI-NETH, V25, P289, DOI 10.1016/j.jocs.2017.03.016
   Jin C, 2016, J VIS COMMUN IMAGE R, V34, P167, DOI 10.1016/j.jvcir.2015.10.017
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kedem D., 2012, Advances in Neural Information Processing Systems, P2573
   KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P387, DOI 10.1109/ROMAN.1992.253856
   KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P381
   Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019
   Kunapuli Gautam, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P859, DOI 10.1007/978-3-642-33460-3_60
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liu MY, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P525, DOI 10.1145/2522848.2531738
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu ZW, 2017, IEEE INT CONF AUTOMA, P967, DOI 10.1109/FG.2017.120
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Maaten L., 2013, P 30 INT C MACH LEAR, P410
   Majumder A, 2014, PATTERN RECOGN, V47, P1282, DOI 10.1016/j.patcog.2013.10.010
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Moeini A, 2016, J VIS COMMUN IMAGE R, V35, P1, DOI 10.1016/j.jvcir.2015.11.006
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pai NS, 2011, COMPUT MATH APPL, V61, P2101, DOI 10.1016/j.camwa.2010.08.082
   Palestra G, 2015, LECT NOTES COMPUT SC, V9280, P518, DOI 10.1007/978-3-319-23234-8_48
   Pele O, 2010, LECT NOTES COMPUT SC, V6312, P749, DOI 10.1007/978-3-642-15552-9_54
   Qian Q, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P323, DOI 10.1145/2623330.2623678
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Qian Q, 2015, MACH LEARN, V99, P353, DOI 10.1007/s10994-014-5456-x
   Rui Zhang, 2016, 2016 International Conference on Machine Learning and Cybernetics (ICMLC). Proceedings, P502, DOI 10.1109/ICMLC.2016.7872938
   Sadeghi H, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013005
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Schultz Matthew, 2003, ADV NEURAL INFORM PR, V16
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shojaeilangari S, 2015, IEEE T IMAGE PROCESS, V24, P2140, DOI 10.1109/TIP.2015.2416634
   Sikka K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P517, DOI 10.1145/2522848.2531741
   Sun Bo., 2014, Proceedings of the 16th International Conference on Multimodal Interaction. ACM, P481
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tom Mitchell, 1997, MACH LEARN
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Wager S., 2013, Advances in Neural Information Processing Systems
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Yang W, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/352849
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhu XN, 2018, MULTIMED TOOLS APPL, V77, P3105, DOI 10.1007/s11042-017-4943-z
   Zong Y, 2016, J MULTIMODAL USER IN, V10, P163, DOI 10.1007/s12193-015-0210-7
NR 91
TC 24
Z9 25
U1 2
U2 17
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 152
EP 165
DI 10.1016/j.jvcir.2019.05.004
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600014
DA 2024-07-18
ER

PT J
AU Yao, W
   Jiang, Y
   Lu, WD
   Chen, J
   Xie, LC
AF Yao, Wei
   Jiang, Ying
   Lu, Wenda
   Chen, Jun
   Xie, Linchao
TI RETRACTED: Deeply fusing multimodal features in hypergraph (Retracted
   article. See vol. 69, 2020)
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article; Retracted Publication
DE Multimodel; Deeply fusing
ID DISCRIMINANT-ANALYSIS; OBJECT
AB Utilizing multimodal features to describe multimedia data is a natural way to improve recognition accuracy. However, how to optimally cluster the raw features into different modalities in order to alleviate curse of dimension and how to exploit relationships between and within the feature modalities are still two tough issues. In this paper, we propose a new deep feature fusion framework: hypergraph feature fusion (HFF), to handle these two issues. First, we extract a collection of deep features from multiple images, then HFF constructs a features' relationships hypergraph (FRH) to reveal relationships among raw features. Then HFF conducts generalized community learning by graph approximation (GCLGA) in FRH to cluster the raw features into k modalities and obtain the inter and intra modalities' structure matrices. These matrices reveal relationships of inter and intra modalities and can help to build graph kernels in order to optimize kernel based classification. Finally, HFF applies a two level classifier to classify the fused feature vectors. Dimension of each level classifier's input feature vector is much lower than raw feature vector. We conduct the kernel based classification on two experiments: (1) Using kernel SVM to classify ETH-80 image dataset by fusing 2 kinds of raw image features. (2) Using features extracted from kernel LDA on speech emotion recognition by fusing 6 kinds of raw speech features. The experimental result shows HFF can effectively solve these two issues and improve class-prediction accuracy over state-of-art feature fusion techniques. (C) 2019 Published by Elsevier Inc.
C1 [Yao, Wei; Jiang, Ying; Lu, Wenda] State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Jun; Xie, Linchao] Zhejiang Huayun Informat Technol Co Ltd, Hangzhou, Zhejiang, Peoples R China.
C3 State Grid Corporation of China
RP Yao, W (corresponding author), State Grid Zhejiang Elect Power Co, Informat & Telecommun Branch, Hangzhou, Zhejiang, Peoples R China.
RI ARSLAN, Okan/AAA-3232-2020
CR Agarwal S, 2005, PROC CVPR IEEE, P838
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2016, ARXIV161001708
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Cai D, 2007, IEEE DATA MINING, P427, DOI 10.1109/ICDM.2007.88
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cheng G, 2018, IEEE T IMAGE PROCESS, V27, P281, DOI 10.1109/TIP.2017.2760512
   Cristianini N, 2002, AI MAG, V23, P31
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Harchaoui Zaid, CVPR07, P1
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   ITAKURA F, 1975, J ACOUST SOC AM, V57, pS35, DOI 10.1121/1.1995189
   Jie L., 2009, P ACCV
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Korn Theresa M., 2001, MATH HDB SCI ENG DEF, P613
   Kwon O.-W., 2003, Interspeech, P125
   Leibe B, 2003, PROC CVPR IEEE, P409
   Li X, 2017, J VET BEHAV, V21, P1, DOI 10.1016/j.jveb.2017.06.002
   Liang YN, 2017, IEEE T WIREL COMMUN, V16, P4817, DOI 10.1109/TWC.2017.2703168
   Liu ZG, 2018, IEEE T CYBERNETICS, V48, P1605, DOI 10.1109/TCYB.2017.2710205
   Long B, 2007, IEEE DATA MINING, P232, DOI 10.1109/ICDM.2007.42
   Long Y., 2017, INFORM SCI
   Nemhauser G., 1988, INTEGER COMBINATORIA, DOI DOI 10.1002/9781118627372
   Pao TL, 2004, 2004 INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, P301
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Schuller B, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P401
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tato R., P INT C SPOK LANG PR, P2029
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wu Yi, OPTIMAL MULTIMODAL F, P572
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Zeng W., 2018, IEEE T VEH TECHNOL
   Zhang DW, 2018, ACM T INTEL SYST TEC, V9, DOI 10.1145/3158674
   Zhang DW, 2017, IEEE T PATTERN ANAL, V39, P865, DOI 10.1109/TPAMI.2016.2567393
   Zhang J., 2018, IEEE COMMUN MAG
   Zhang JY, 2018, IEEE T VEH TECHNOL, V67, P2766, DOI 10.1109/TVT.2017.2766784
   Zhang JY, 2018, IEEE WIREL COMMUN LE, V7, P14, DOI 10.1109/LWC.2017.2750162
   Zhang JY, 2017, IEEE T VEH TECHNOL, V66, P11404, DOI 10.1109/TVT.2017.2727078
   Zhang JY, 2017, IEEE J SEL AREA COMM, V35, P1327, DOI 10.1109/JSAC.2017.2687278
   Zhang JY, 2016, IEEE T VEH TECHNOL, V65, P8800, DOI 10.1109/TVT.2015.2504428
   Zhang JY, 2016, IEEE COMMUN LETT, V20, P842, DOI 10.1109/LCOMM.2016.2535132
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P94, DOI 10.1109/TMM.2013.2286817
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P802, DOI 10.1109/TIP.2012.2223226
   Zhou D, 2007, 2007 IEEE NORTH-EAST WORKSHOP ON CIRCUITS AND SYSTEMS, P167, DOI 10.1109/CADCG.2007.4407875
   Zhou X, 2008, PATTERN RECOGN, V41, P778, DOI 10.1016/j.patcog.2007.06.019
   Zhou Xiaoli, P 2006 C COMP VIS PA, P55
NR 48
TC 1
Z9 1
U1 2
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2019
VL 62
BP 97
EP 104
DI 10.1016/j.jvcir.2019.02.025
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA IL0CB
UT WOS:000476962600009
DA 2024-07-18
ER

PT J
AU Ding, Y
   Liu, Z
   Huang, MK
   Shi, R
   Wang, XY
AF Ding, Yu
   Liu, Zhi
   Huang, Mengke
   Shi, Ran
   Wang, Xiangyang
TI Depth-aware saliency detection using convolutional neural networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Saliency detection; Convolutional neural networks; Depth saliency
   network; Saliency fusion network; RGBD images; Stereoscopic images
ID OBJECT DETECTION; VISUAL-ATTENTION; SEGMENTATION; VIDEO; MODEL
AB This paper proposes a new end-to-end depth-aware saliency model using three convolutional neural networks including color saliency network, depth saliency network and saliency fusion network, for saliency detection in RGBD images and stereoscopic images. Firstly, the color image is fed to the color saliency network to generate the color saliency map. Then, by sharing the weights of some layers in the color saliency network, the depth saliency network exploits the weight initialization and multi-layer pyramid feature fusion to learn effective depth features from the three-channel depth image, which is converted from the original depth map, and generates the depth saliency map. Finally, the saliency fusion network integrates the color saliency map with the depth saliency map into the final saliency map, which can highlight salient object regions and suppress background regions more effectively. Experimental results on five public datasets demonstrate that our model achieves the better performance compared with the state-of-the-art depth-aware saliency models. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Ding, Yu; Liu, Zhi; Huang, Mengke] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Ding, Yu; Liu, Zhi; Huang, Mengke; Wang, Xiangyang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Shi, Ran] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
C3 Shanghai University; Shanghai University; Nanjing University of Science
   & Technology
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61771301, 61801219]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 61771301 and 61801219.
CR Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng Y, 2014, IEEE INT CON MULTI
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Couprie C., 2013, ARXIV13013572, P1
   Fan XX, 2014, INT CONF DIGIT SIG, P454, DOI 10.1109/ICDSP.2014.6900706
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P4684, DOI 10.1109/TIP.2017.2721112
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   Han JW, 2013, IEEE T CIRC SYST VID, V23, P2009, DOI 10.1109/TCSVT.2013.2242594
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Lin T., 2017, P IEEE CVPR, P237
   Liu Z, 2014, IEEE T CIRC SYST VID, V24, P1522, DOI 10.1109/TCSVT.2014.2308642
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song H., 2015, P ICIMCS AUG, P240
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang X, 2018, IEEE T IMAGE PROCESS, V27, P121, DOI 10.1109/TIP.2017.2756825
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yang J, 2016, IEEE INT CONF MULTI
   Zhang JL, 2018, GEOPHYS RES LETT, V45, P8665, DOI 10.1029/2018GL077787
   Zhang P, 2018, TOP CURR CHEM COLLEC, P1, DOI 10.1007/s41061-017-0112-0
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
   Zhu CY, 2018, 2018 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP)
   2015, IEEE T IMAGE PROCESS, V24, P3858, DOI DOI 10.1109/TIP.2015.2456497
NR 43
TC 37
Z9 45
U1 2
U2 25
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2019
VL 61
BP 1
EP 9
DI 10.1016/j.jvcir.2019.03.019
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HY3GK
UT WOS:000468011100001
DA 2024-07-18
ER

PT J
AU Rao, KP
   Rao, MVPCS
   Chowdary, NH
AF Rao, K. Prasada
   Rao, M. V. P. Chandra Sekhara
   Chowdary, N. Hemanth
TI An integrated approach to emotion recognition and gender classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Emotion recognition; MFCC; MSER; Speeded Up Robust Features (SURF); SVM;
   Viola Jones
ID FACE
AB The human-computer communication adds to worldwide access to training, information upgrade and the conveyance of value learning and instructions. Furthermore, the changing paradigm of machine perceiving the human emotions effectively is a technological advancement for the learning community. The automatic recognition of emotions reflected from speech and facial expressions for making the machine to understand the human verbal and non-verbal emotions is coined as "Emotion Recognition". Emotion recognition systems, regardless, are not totally seen as subject independent dynamic features, so they are not sufficiently vigorous for constant acknowledgment assignments with subject assortment (human face), head movement, illumination change, speech, noise and so on when thought about exclusively. Hence, it is proposed to fuse the features of facial expressions and speech. The present framework utilizes the Speech (Mel Frequency Cepstral Coefficients) features and Facial (Maximally Stable Extremal Regions) features to predict the emotions of a person through a systematic and scientific study. Specifically, when combining MSER with MFCC, the recognition rates can be further improved by 2 to 3% on Indian Face Database and Berlin Speech Database. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Rao, K. Prasada] ANU, Guntur, AP, India.
   [Rao, M. V. P. Chandra Sekhara] RVR & JCCE, Guntur, India.
   [Chowdary, N. Hemanth] Northwest Missouri State Univ, CSIS, Maryville, MO 64468 USA.
C3 Acharya Nagarjuna University; RVR & JC College of Engineering
RP Rao, KP (corresponding author), ANU, Guntur, AP, India.
EM prasadrao.karu@gmail.com
RI rao, karu prasada/AAQ-1344-2021; karu, prasada Rao/P-5958-2015; Rao,
   M.V.P. Chandra Sekhara/ABH-6843-2020
OI rao, karu prasada/0000-0001-5379-0964; Rao, M.V.P. Chandra
   Sekhara/0000-0002-6676-0454
CR [Anonymous], FEB
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2749576
   [Anonymous], 2011, P ICML
   [Anonymous], 2001, P IEEE C COMP VIS PA
   [Anonymous], P 4 IEEE INT C IEEE
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], EXAMPLE BASED AUDIO
   Bishop J, 2012, J ACOUST SOC AM, V132, P1100, DOI 10.1121/1.4714351
   BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560
   Chen LS, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P423, DOI 10.1109/ICME.2000.869630
   Chen LS, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P366, DOI 10.1109/AFGR.1998.670976
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dagar D, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION CONTROL AND COMPUTING TECHNOLOGIES (ICACCCT), P77, DOI 10.1109/ICACCCT.2016.7831605
   Davis J. V., 2007, ICML, P209
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Jain V., 2002, The Indian Face Database
   Kahou SE, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P543, DOI 10.1145/2522848.2531745
   Kamaruddin N, 2012, EXPERT SYST APPL, V39, P5115, DOI 10.1016/j.eswa.2011.11.028
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Kumar R, 2017, SIGNAL IMAGE VIDEO P, V11, P1519, DOI 10.1007/s11760-017-1115-6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2017, IEEE SIGNAL PROC MAG, V34, P76, DOI 10.1109/MSP.2017.2732900
   Lu JW, 2017, IEEE T IMAGE PROCESS, V26, P4269, DOI 10.1109/TIP.2017.2717505
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Lugovic S, 2016, 2016 39TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1278, DOI 10.1109/MIPRO.2016.7522336
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   Thampi S.M., 2014, Advances in signal processing and intelligent recognition systems
   Wagner J, 2007, LECT NOTES COMPUT SC, V4738, P114
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Yan HB, 2018, PATTERN RECOGN, V75, P15, DOI 10.1016/j.patcog.2017.03.001
   Yan HB, 2016, NEUROCOMPUTING, V208, P202, DOI 10.1016/j.neucom.2015.11.115
   Yan HB, 2016, NEUROCOMPUTING, V208, P165, DOI 10.1016/j.neucom.2015.11.113
   Yoshitomi Y, 2000, IEEE RO-MAN 2000: 9TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P178, DOI 10.1109/ROMAN.2000.892491
NR 39
TC 13
Z9 13
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2019
VL 60
BP 339
EP 345
DI 10.1016/j.jvcir.2019.03.002
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HS7ZO
UT WOS:000464088000037
DA 2024-07-18
ER

PT J
AU Lu, ZY
   Qiu, YN
   Zhan, TM
AF Lu, Zhenyu
   Qiu, Yunan
   Zhan, Tianming
TI Neutrosophic C-means clustering with local information and noise
   distance-based kernel metric image segmentation
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image segmentation; Noise clustering; Fuzzy clustering; Nutrosophic
   clustering
AB The traditional FCM algorithm is developed on the basis of classical fuzzy theory, though the classical fuzzy theory has its own limitations. The lack of expressive ability of uncertain information makes it hard for FCM algorithm to handle clustered boundary pixels and outliers. This paper proposes a Neutrosophic C-means Clustering with local information and noise distance-based kernel metric for image segmentation (NKWNLICM). At first, noisy distance and fuzzy spatial information are introduced to NCM model to improve the robustness of noise image segmentation. Then, the kernel function is used to measure the distance between pixels. By mapping low-dimensional data into high-dimensional data, the classification performance is further improved. At last, the fuzzy factor is redefined based on the distance between the center pixel and its neighborhood. The new fuzzy factor can excellently reflect the influence of neighborhood pixels on central pixels and improve the classification accuracy much better. The experimental results on Berkeley Segmentation Database demonstrates the excellent performance of the proposed method for noisy image segmentation. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Lu, Zhenyu; Qiu, Yunan] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing, Jiangsu, Peoples R China.
   [Lu, Zhenyu] Jiangsu Collaborat Innovat Ctr Atmospher Environm, Nanjing, Jiangsu, Peoples R China.
   [Zhan, Tianming] Nanjing Audit Univ, Sch Informat & Engn, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing Audit
   University
RP Zhan, TM (corresponding author), Nanjing Audit Univ, Sch Informat & Engn, Nanjing, Jiangsu, Peoples R China.
EM ztm@nau.edu.cn
RI Lu, Zhenyu/AAA-5077-2019
FU National Natural Science Foundation of China [61773220, 61502206];
   Nature Science Foundation of Jiangsu Province [BK20150523]; Open Project
   Program of Key Laboratory of Jiangsu Key Laboratory of Meteorological
   Observation and Information Processing [KDXS1807]
FX This work has been supported in part by the National Natural Science
   Foundation of China (Grant Nos. 61773220, 61502206), the Nature Science
   Foundation of Jiangsu Province under Grant (No. BK20150523) and the Open
   Project Program of Key Laboratory of Jiangsu Key Laboratory of
   Meteorological Observation and Information Processing under grant number
   (KDXS1807).
CR BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296
   Chuang KS, 2006, COMPUT MED IMAG GRAP, V30, P9, DOI 10.1016/j.compmedimag.2005.10.001
   DAVE RN, 1991, PATTERN RECOGN LETT, V12, P657, DOI 10.1016/0167-8655(91)90002-4
   Esch T, 2008, IEEE GEOSCI REMOTE S, V5, P463, DOI 10.1109/LGRS.2008.919622
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Guo YH, 2015, PATTERN RECOGN, V48, P2710, DOI 10.1016/j.patcog.2015.02.018
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hong RC, 2016, IEEE T MULTIMEDIA, V18, P1555, DOI 10.1109/TMM.2016.2567071
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P1124, DOI 10.1109/TIP.2016.2514499
   Hui Zhang, 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5307, P38, DOI 10.1117/12.527167
   James C. B., 1973, J CYBERNETICS, V3, P58
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Miyamoto S, 2008, STUD FUZZ SOFT COMP, V229, P1
   Pedrycz W, 2005, KNOWLEDGE-BASED CLUSTERING: FROM DATA TO INFORMATION GRANULES, P1, DOI 10.1002/0471708607
   Smarandache F., 1998, UNIFYING FIELD LOGIC
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 20
TC 12
Z9 12
U1 0
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 269
EP 276
DI 10.1016/j.jvcir.2018.11.045
PG 8
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100027
OA Green Published
DA 2024-07-18
ER

PT J
AU Mandeljc, R
   Maver, J
AF Mandeljc, Rok
   Maver, Jasna
TI AGs: Local descriptors derived from the dependent effects model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local image descriptor; Dependent effects model; Image matching;
   Keypoint descriptor evaluation
ID IMAGE DESCRIPTORS; COMPACT; PERFORMANCE; SIFT
AB We present a novel local descriptor based on the dependent effects model. Different types of effects are computed in a local region and properly normalized to form a descriptor, which is designed to be robust to rotation, scale changes, and skew. Two specific instances of descriptor are presented and evaluated. The first, named AG, is real-valued, and uses 126 floating-point values to represent 126 effects. The second version, named AGS, is binarized, and uses 60 bytes to represent 240 effects, each with two bits. The first bit represents the sign of an effect value, while the second denotes whether the value is near or far from zero. We experimentally evaluate the proposed descriptors in combination with popular keypoint detectors on standard feature matching datasets. The extensive evaluation shows that AG and AGS achieve high score in several performance measures, and as such, they represent an attractive alternative to popular local descriptors. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Mandeljc, Rok; Maver, Jasna] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, SL-1000 Ljubljana, Slovenia.
C3 University of Ljubljana
RP Maver, J (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, SL-1000 Ljubljana, Slovenia.
EM jasna.maver@ff.uni-lj.si
OI MAVER, JASNA/0000-0002-6579-7239
FU Slovenian Research Agency [L2-6765, P2-0214]
FX This work was supported by the applied project L2-6765 and the research
   programme P2-0214, both by the Slovenian Research Agency.
CR Aanæs H, 2012, INT J COMPUT VISION, V97, P18, DOI 10.1007/s11263-011-0473-8
   Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Araujo A, 2016, IEEE IMAGE PROC, P305, DOI 10.1109/ICIP.2016.7532368
   Balntas V., 2016, Bmvc, DOI DOI 10.5244/C.30.119
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bian J., CORR
   Bianco S, 2015, DIGIT SIGNAL PROCESS, V44, P1, DOI 10.1016/j.dsp.2015.06.001
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Cadena C, 2016, IEEE T ROBOT, V32, P1309, DOI 10.1109/TRO.2016.2624754
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Feng Tang, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2631, DOI 10.1109/CVPRW.2009.5206550
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Ke Y, 2004, PROC CVPR IEEE, P506
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Levieuge G, 2017, APPL ECON, V49, P823, DOI 10.1080/00036846.2016.1208350
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Madeo S, 2017, IEEE T MULTIMEDIA, V19, P221, DOI 10.1109/TMM.2016.2615521
   Mair E, 2010, LECT NOTES COMPUT SC, V6312, P183, DOI 10.1007/978-3-642-15552-9_14
   Mandeljc R., 2017, ALPHAGAMMA DESCRIPTO
   Maresca ME, 2013, LECT NOTES COMPUT SC, V8157, P419, DOI 10.1007/978-3-642-41184-7_43
   Maver J, 2018, ELEKTROTEH VESTN, V85, P197
   Maver J, 2010, IEEE T PATTERN ANAL, V32, P1211, DOI 10.1109/TPAMI.2009.105
   Mele K, 2009, IET COMPUT VIS, V3, P8, DOI 10.1049/iet-cvi:20070001
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schonberger J. L., 2017, C COMP VIS PATT REC
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Simonyan K, 2014, IEEE T PATTERN ANAL, V36, P1573, DOI 10.1109/TPAMI.2014.2301163
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snavely N, 2010, P IEEE, V98, P1370, DOI 10.1109/JPROC.2010.2049330
   Sotiras A, 2013, IEEE T MED IMAGING, V32, P1153, DOI 10.1109/TMI.2013.2265603
   Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Trzcinski T, 2015, IEEE T PATTERN ANAL, V37, P597, DOI 10.1109/TPAMI.2014.2343961
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Winder SAJ, 2007, PROC CVPR IEEE, P17
   Xie LX, 2017, INT J COMPUT VISION, V123, P226, DOI 10.1007/s11263-016-0970-x
   Xie LX, 2014, IEEE IMAGE PROC, P5716, DOI 10.1109/ICIP.2014.7026156
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zhou W., 2010, P 18 ACM INT C MULTI, P511
NR 59
TC 3
Z9 3
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2019
VL 58
BP 503
EP 514
DI 10.1016/j.jvcir.2018.12.008
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA HK1MD
UT WOS:000457668100049
DA 2024-07-18
ER

PT J
AU Fan, C
   Zhang, ZH
   Crandall, DJ
AF Fan, Chenyou
   Zhang, Zehua
   Crandall, David J.
TI Deepdiary: Lifelogging image captioning and summarization
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Lifelogging; First-person; Image captioning; Diary; Privacy
ID SENSECAM
AB Automatic image captioning has been studied extensively over the last few years, driven by breakthroughs in deep learning-based image-to-text translation models. However, most of this work has considered captioning web images from standard data sets like MS-COCO, and has considered single images in isolation. To what extent can automatic captioning models learn finer-grained contextual information specific to a given person's day-today visual experiences? In this paper, we consider captioning image sequences collected from wearable, lifelogging cameras. Automatically-generated captions could help people find and recall photos among their large-scale life-logging photo collections, or even to produce textual "diaries" that summarize their day. But unlike web images, photos from wearable cameras are often blurry and poorly composed, without an obvious single subject. Their content also tends to be highly dependent on the context and characteristics of the particular camera wearer. To address these challenges, we introduce a technique to jointly caption sequences of photos, which allows captions to take advantage of temporal constraints and evidence across time, and we introduce a technique to increase the diversity of generated captions, so that they can describe a photo from multiple perspectives (e.g., first-person versus third-person). To test these techniques, we collect a dataset of about 8000 realistic lifelogging images, a subset of which are annotated with nearly 5000 human-generated reference sentences. We evaluate the quality of image captions both quantitatively and qualitatively using Amazon Mechanical Turk, finding that while these algorithms are not perfect, they could be an important step towards helping to organize and summarize lifelogging photos.
C1 [Fan, Chenyou; Zhang, Zehua; Crandall, David J.] Indiana Univ, Sch Informat Comp & Engn, Bloomington, IN 47405 USA.
C3 Indiana University System; Indiana University Bloomington
RP Fan, C (corresponding author), Indiana Univ, Sch Informat Comp & Engn, Bloomington, IN 47405 USA.
EM fan6@indiana.edu; zehzhang@indiana.edu; djcran@indiana.edu
RI Li, Zexi/KFA-6939-2024
FU National Science Foundation [CAREER IIS-1253549, CNS-1408730]; Google;
   IU Office of the Vice Provost for Research; College of Arts and
   Sciences; School of Informatics, Computing, and Engineering through the
   Emerging Areas of Research Project; Paul Purdom Fellowship; Indiana
   University Pervasive Technology Institute; Indiana METACyt Initiative;
   Romeo FutureSystems facility - Indiana University; NSF RaPyDLI grant
   [1439007]
FX This work was supported in part by the National Science Foundation
   (CAREER IIS-1253549 and CNS-1408730) and Google, and the IU Office of
   the Vice Provost for Research, the College of Arts and Sciences, and the
   School of Informatics, Computing, and Engineering through the Emerging
   Areas of Research Project, "Learning: Brains, Machines, and Children."
   CF was supported by a Paul Purdom Fellowship. This work used compute
   facilities provided by NVidia, the Lilly Endowment through support of
   the Indiana University Pervasive Technology Institute, the Indiana
   METACyt Initiative, and the Romeo FutureSystems facility which is
   partially supported by Indiana University and NSF RaPyDLI grant 1439007.
   We thank Zhenhua Chen, Sally Crandall, and Xuan Dong for helping to
   label our lifelogging photos, and Katherine Spoon for copy-editing
   corrections and suggestions.
CR Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   [Anonymous], ARXIV150500487
   [Anonymous], TECH REP
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], 2015, VISUALIZING UNDERSTA
   [Anonymous], 150706120 ARXIV
   [Anonymous], ACM CHI C HUM FACT C
   [Anonymous], 2013, UBICOMP 2013 ADJUNCT, DOI DOI 10.1145/2494091.2494166
   [Anonymous], 2018, J VIS COMMUN IMAGE R, DOI DOI 10.1016/j.jvcir.2017.11.022
   [Anonymous], 2015, ARXIV150606724
   [Anonymous], IAPR INT C PATT REC
   [Anonymous], 2014, Networks and Distributed Systems Security (NDSS)
   [Anonymous], 2016, ARXIV161002391
   [Anonymous], ARXIV15003044
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, ICLR 2015
   [Anonymous], 2013, P 2013 ACM C PERV UB
   [Anonymous], PROC CVPR IEEE
   [Anonymous], NARR CLIP
   [Anonymous], AUTOGRAPHER WEARABLE
   [Anonymous], INT S WEAR COMP
   [Anonymous], EUR C COMP VIS INT S
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], COMPUTERS HELPING PE
   [Anonymous], AM SOC INF SCI TECHN
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2011, IEEE IC COMP COM NET
   [Anonymous], ICCV WORKSH
   [Anonymous], USENIX S US PRIV SEC
   [Anonymous], INT J COMPUT VISION
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], TECH REP
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], 2004, ROUGE PACKAGE AUTO
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   BROOKS G, 1992, SIGPLAN NOTICES, V27, P1, DOI [10.13334/j.0258-8013.pcsee.213043, 10.1145/143103.143108]
   Cadmus-Bertram LA, 2015, AM J PREV MED, V49, P414, DOI 10.1016/j.amepre.2015.01.020
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Clinch S, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1397, DOI 10.1145/2638728.2641721
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Denning T, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P2377, DOI 10.1145/2556288.2557352
   Doherty AR, 2012, HUM-COMPUT INTERACT, V27, P151, DOI 10.1080/07370024.2012.656050
   Doherty AR, 2011, COMPUT HUM BEHAV, V27, P1948, DOI 10.1016/j.chb.2011.05.002
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Fathi A, 2012, LECT NOTES COMPUT SC, V7572, P314, DOI 10.1007/978-3-642-33718-5_23
   Graves A., 2013, Generating sequences with recurrent neural networks
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Gurrin C, 2008, LECT NOTES COMPUT SC, V4993, P537, DOI 10.1007/978-3-540-68636-1_60
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Hoyle R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P571, DOI 10.1145/2632048.2632079
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kalnikaité V, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2045
   Karpathy A, 2014, ADV NEUR IN, V27
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kerr J, 2013, AM J PREV MED, V44, P290, DOI 10.1016/j.amepre.2012.11.004
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Koller D., 2009, Probabilistic graphical models: principles and techniques
   Kuznetsova Polina, 2012, Association for Computational Linguistics
   Lee S, 2016, ADV NEUR IN, V29
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mann S., 2003, SURVEILL SOC, V1, P331, DOI 10.24908/ss.v1i3.3344
   Mao Junhua., 2014, Explain images with multimodal recurrent neural networks
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Nguyen DH, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P165
   O'Loughlin G, 2013, AM J PREV MED, V44, P297, DOI 10.1016/j.amepre.2012.11.007
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Ryoo MS, 2015, ACMIEEE INT CONF HUM, P295, DOI 10.1145/2696454.2696462
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Singh KK, 2016, IEEE WINT CONF APPL
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Takeuchi T., 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P79, DOI 10.1109/VSMM.2010.5665961
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xie B, 2017, IEEE ICC
   Yang ZL, 2016, ADV NEUR IN, V29
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
NR 95
TC 13
Z9 13
U1 1
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 40
EP 55
DI 10.1016/j.jvcir.2018.05.008
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100005
DA 2024-07-18
ER

PT J
AU Meng, FJ
   Shan, DL
   Shi, RX
   Song, Y
   Guo, BL
   Cai, WD
AF Meng, Fanjie
   Shan, Dalong
   Shi, Ruixia
   Song, Yang
   Guo, Baolong
   Cai, Weidong
TI Merged region based image retrieval
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image retrieval (IR); Regional convolution mapping feature (RCMF);
   Convolution neural networks (CNN); Integrated category matching (ICM)
AB In Region based Image Retrieval (RBIR) methods, region matching mainly focuses on region-to-region and image-to-image methods. The former may cause loss of image information and the latter may lead to similar regions being matched repeatedly. To solve these problems, we propose a new image retrieval method based on merged regions, and feature extraction and matching are processed at the category level. Merged regions in an image belong to the same category to some extent, and are obtained by a statistical region merging and affinity propagation (SRM-AP) algorithm. For feature extraction, regional convolution mapping feature (RCMF) based on the convolutional neural networks (CNN) are extracted. RCMF is further combined with the number and distribution of regions to represent the characteristics of merged regions. Moreover, to match the merged regions according to their significance in images, an integrated category matching (ICM) method is designed. Experimental results on Corel-1000 and Caltech-256 show that the proposed method is more effective than some existing RBIR methods.
C1 [Meng, Fanjie; Shi, Ruixia; Guo, Baolong] Xidian Univ, Sch Aerosp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
   [Shan, Dalong] China Elect Technol Informat Ind Co Ltd, Zhengzhou 450018, Henan, Peoples R China.
   [Song, Yang; Cai, Weidong] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
C3 Xidian University; University of Sydney
RP Meng, FJ (corresponding author), Xidian Univ, Sch Aerosp Sci & Technol, Xian 710071, Shaanxi, Peoples R China.
EM fjmeng@xidian.edu.cn; yang.song@sydney.edu.au; blguo@xidian.edu.au;
   tom.cai@sydney.edu.au
RI Song, Yangyi/JBJ-7119-2023; Cai, Tingwei Bill/AAJ-8822-2020; Song,
   Yangyi/HGU-4953-2022
OI Song, Yangyi/0000-0002-3649-014X; Song, Yangyi/0000-0002-3649-014X; Cai,
   Weidong/0000-0003-3706-8896; Song, Yang/0000-0003-1283-1672
FU National Natural Science Foundation of China [61305040]; Fundamental
   Research Funds for the Central Universities [JB181308]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 61305040 and the Fundamental Research Funds for the
   Central Universities under Grant JB181308.
CR Amit G., 2015, INT J ENG RES TECHNO, V4
   [Anonymous], 2016, ECCV
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Cheng H, 2009, IEEE I CONF COMP VIS, P317, DOI 10.1109/ICCV.2009.5459267
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Gordo A, 2012, PROC CVPR IEEE, P3045, DOI 10.1109/CVPR.2012.6248035
   Griffin G., 2007, Technical Report 7694, P1
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Karamti H., 2014, IEEE ACS 11 INT C CO
   Li J., 2017, IEEE TIP
   Li J, 2017, NEUROCOMPUTING, V257, P47, DOI 10.1016/j.neucom.2016.10.074
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Shokoufandeh A, 2012, IET COMPUT VIS, V6, P500, DOI 10.1049/iet-cvi.2012.0030
   Tan M, 2016, IEEE T INTELL TRANSP, V17, P1415, DOI 10.1109/TITS.2015.2506182
   Velazco-Paredes Y, 2015, 2015 IEEE COLOMBIAN CONFERENCE ON COMMUNICATIONS AND COMPUTING (COLCOM)
   Vimina ER, 2013, IJCSI INT J COMPUTER, V10, P686
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang YC, 2017, PR MACH LEARN RES, V70
   Wang YH, 2016, IEEE T IMAGE PROCESS, V25, P4406, DOI 10.1109/TIP.2016.2590323
   Xia Dingyuan, 2012, Computer Engineering and Applications, V48, P197, DOI 10.3778/j.issn.1002-8331.2012.26.043
   Yang XH, 2014, IET COMPUT VIS, V8, P141, DOI 10.1049/iet-cvi.2012.0157
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu W, 2017, NEUROCOMPUTING, V237, P235, DOI 10.1016/j.neucom.2016.12.002
   Zhang S., 2015, IEEE TPAM
   Zheng L., 2013, CVPR, V9, P1626
NR 30
TC 4
Z9 4
U1 3
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 572
EP 585
DI 10.1016/j.jvcir.2018.07.003
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100050
DA 2024-07-18
ER

PT J
AU Yousif, H
   Yuan, JH
   Kays, R
   He, ZH
AF Yousif, Hayder
   Yuan, Jianhe
   Kays, Roland
   He, Zhihai
TI Object detection from dynamic scene using joint background modeling and
   fast deep learning classification
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Human-animal detection; Camera-trap images; Background subtraction; Deep
   convolutional neural networks; Wildlife monitoring
ID SEGMENTATION
AB In this paper, we couple effective dynamic background modeling with fast deep learning classification to develop an accurate scheme for human-animal detection from camera-trap images with cluttered moving objects. We introduce a new block-wise background model, named as Minimum Feature Difference (MFD), to model the variation of the background of the camera-trap sequences and generate the foreground object proposals. We then develop a region proposals verification to reduce the number of false alarms. Finally, we perform complexity-accuracy analysis of DCNN to construct a fast deep learning classification scheme to classify these region proposals into three categories: human, animals, and background patches. The optimized DCNN is able to maintain high level of accuracy while reducing the computational complexity by 14 times, which allows near real-time implementation of the proposed method on CPU machines. Our experimental results demonstrate that the proposed method outperforms existing methods on our and Alexander von Humboldt Institute camera-trap datasets in both foreground segmentation and object detection. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Yousif, Hayder; Yuan, Jianhe; He, Zhihai] Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
   [Kays, Roland] North Carolina State Univ, Dept Forestry & Environm Resources, Raleigh, NC 27601 USA.
C3 University of Missouri System; University of Missouri Columbia; North
   Carolina State University
RP Yousif, H (corresponding author), Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
EM hyypp5@mail.missouri.edu; yuanjia@missouri.edu; rwkay@ncsu.edu;
   hezhi@missouri.edu
RI Yousif, Hayder/AAG-2259-2020; He, Zhihai/A-5885-2019; Yuan,
   Jianhe/ABG-1712-2020
OI Yousif, Hayder/0000-0002-7638-9505; Yuan, Jianhe/0000-0002-4004-6236;
   Kays, Roland/0000-0002-2947-6665
FU National Science Foundation [CyberSEES-1539389]
FX This work has been supported in part by National Science Foundation
   under grant CyberSEES-1539389.
CR [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Azzam R, 2016, J VIS COMMUN IMAGE R, V36, P90, DOI 10.1016/j.jvcir.2015.11.009
   Balzano L., 2010, 2010 48 ANN ALL C CO, P704
   BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P293, DOI 10.1109/36.377929
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Bubnicki J.W., 2016, METHODS ECOL EVOL
   Bunyak Filiz, 2007, J Multimed, V2, P20
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheung SCS, 2005, EURASIP J APPL SIG P, V2005, P2330, DOI 10.1155/ASP.2005.2330
   Choudhury S. K., 2016, EVALUATION BACKGROUN
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gillis N, 2015, SIAM J MATRIX ANAL A, V36, P1404, DOI 10.1137/140993272
   Giraldo-Zuluaga J.-H., ARXIV170108180
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He J, 2012, PROC CVPR IEEE, P1568, DOI 10.1109/CVPR.2012.6247848
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Kays R, 2009, C LOCAL COMPUT NETW, P811, DOI 10.1109/LCN.2009.5355046
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee K., RESIDUAL FEATURES UN
   Ling Q, 2014, NEUROCOMPUTING, V133, P32, DOI 10.1016/j.neucom.2013.11.034
   Liu LH, 2016, LECT NOTES COMPUT SC, V9914, P676, DOI 10.1007/978-3-319-48881-3_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu CY, 2013, J VIS COMMUN IMAGE R, V24, P111, DOI 10.1016/j.jvcir.2012.05.003
   Lucas TCD, 2015, METHODS ECOL EVOL, V6, P500, DOI 10.1111/2041-210X.12346
   Miller AB, 2017, J OUTDOOR REC TOUR, V17, P44, DOI 10.1016/j.jort.2016.09.007
   Mittal A, 2004, PROC CVPR IEEE, P302
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   O'Connell A, 2011, CAMERA TRAPS IN ANIMAL ECOLOGY: METHODS AND ANALYSES, pV
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Portmann J, 2014, IEEE INT CONF ROBOT, P1794, DOI 10.1109/ICRA.2014.6907094
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren J., 2017, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2017.87
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XB, 2013, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2013.254
   Schick A., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P27, DOI DOI 10.1109/CVPRW.2012.6238923
   Shaoqing Ren R. G. J. S., ARXIV150601497
   Shu XB, 2014, PROC CVPR IEEE, P3874, DOI 10.1109/CVPR.2014.495
   Sobral A, 2016, HANDBOOK OF ROBUST LOW-RANK AND SPARSE MATRIX DECOMPOSITION: APPLICATIONS IN IMAGE AND VIDEO PROCESSING
   Trigeorgis G, 2014, PR MACH LEARN RES, V32, P1692
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vandereycken B, 2013, SIAM J OPTIMIZ, V23, P1214, DOI 10.1137/110845768
   Wang SH, 2014, J VIS COMMUN IMAGE R, V25, P263, DOI 10.1016/j.jvcir.2013.11.005
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Zhang SH, 2017, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2017.8026235
   Zhang Z, 2016, IEEE T MULTIMEDIA, V18, P2079, DOI 10.1109/TMM.2016.2594138
NR 54
TC 7
Z9 9
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 802
EP 815
DI 10.1016/j.jvcir.2018.08.013
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100071
DA 2024-07-18
ER

PT J
AU Zhang, YG
   Zheng, J
   Zhang, C
   Li, B
AF Zhang, Yugui
   Zheng, Jin
   Zhang, Chi
   Li, Bo
TI An effective motion object detection method using optical flow
   estimation under a moving camera
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Optical flow estimation; The moving camera; The horizontal flow; The
   vertical flow; Motion object detection; Motion object boundary
ID PARALLEL FRAMEWORK
AB Optical flow techniques have been applied to motion object detection under a moving camera over the years. In this paper, we propose an effective motion object detection method based on optical flow estimation, characterized in that the complete boundary of the motion object can be extracted from the combination of the optimized horizontal flow with the optimized vertical flow. The optimized horizontal flow and the optimized vertical flow can be obtained as follows: introducing a third frame into the two frames to obtain the horizontal flow and the vertical flow, and then optimizing the horizontal flow and the vertical flow by applying gradient function and threshold method, respectively. The complete boundary of the motion object, after being subjected to region filling, could be optimized by Gaussian filtering technique to obtain the final detection results. Our proposed method is tested on the following datasets consisting of Cdnet2014, KITTI2015, MPI Sintel datasets, natural YouTube sequences and the collected data, respectively. The results show that our proposed method outperforms state-of-the-art significantly.
C1 [Zhang, Yugui; Zheng, Jin; Zhang, Chi] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zheng, Jin; Li, Bo] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Zheng, J (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.; Zheng, J (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM JinZheng@buaa.edu.cn
RI Li, Bo/AAA-8968-2020; Zhang, Cheng/JAD-2236-2023; Li, bo/IWL-9318-2023;
   zhang, chi/GRX-3610-2022; zhang, chao/HTO-2468-2023; zhang,
   chao/IXD-9965-2023
OI Li, Bo/0000-0002-7294-6888; 
FU National Key Research and Development Plan of China [2016YFC0801002];
   National Natural Science Foundation of China [61370124]; Army Equipment
   Research Project of China [301020203]
FX This work was partially supported by the National Key Research and
   Development Plan of China (Grant No. 2016YFC0801002), the National
   Natural Science Foundation of China (No. 61370124) and Army Equipment
   Research Project of China (No. 301020203). The authors would like to
   express their heartfelt gratitude to those people who have helped with
   this manuscript and to the reviewers for their comments on the
   manuscript.
CR [Anonymous], 2016, CVPR
   [Anonymous], CVPR
   [Anonymous], DAGST MOT WORKSH
   [Anonymous], 2016, CVPR
   [Anonymous], IJCV
   Baker Simon., 2007, ICCV
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2359374
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Butler D., 2012, Tech. Rep. MPI-IS-TR-006
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Faktor A., 2014, P BRIT MACHINE VISIO
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hu WC, 2015, J VIS COMMUN IMAGE R, V30, P164, DOI 10.1016/j.jvcir.2015.03.003
   Kang Hyeon, 2016, IEMCON
   Kelson R., 2008, 1PTICAL FLOW USING C, P1607
   Lempitsky VictorS., 2008, CVPR
   Muddamsetty Satya M., 2017, MULTIMED TOOLS APPL, P1
   Narayana M, 2013, IEEE I CONF COMP VIS, P1577, DOI 10.1109/ICCV.2013.199
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sepehr Aslani, 2013, INT J ELECT COMPUTER, V7
   Shivakuamra P, 2014, IEEE IMAGE PROC, P1668, DOI 10.1109/ICIP.2014.7025334
   Sorte B, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P295, DOI 10.1109/ICACDOT.2016.7877597
   Sun DQ, 2008, LECT NOTES COMPUT SC, V5304, P83
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y., 2016, Pattern Recognition Letters
   Wang Y, 2014, PROCEEDINGS OF 2014 INTERNATIONAL SYMPOSIUM ON ELECTRICAL INSULATING MATERIALS (ISEIM 2014), P393, DOI 10.1109/ISEIM.2014.6870802
   WEDEL A., 2009, ICCV
   Wedel A., 2008, IVCNZ
   Wedel A, 2009, LECT NOTES COMPUT SC, V5681, P14, DOI 10.1007/978-3-642-03641-5_2
   Wu YY, 2017, IEEE T CIRC SYST VID, V27, P236, DOI 10.1109/TCSVT.2015.2493499
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yuan C, 2007, IEEE T PATTERN ANAL, V29, P1627, DOI 10.1109/TPAMI.2007.1084
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang CX, 2017, IEEE T IMAGE PROCESS, V26, P4055, DOI 10.1109/TIP.2017.2712279
NR 42
TC 16
Z9 20
U1 3
U2 30
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2018
VL 55
BP 215
EP 228
DI 10.1016/j.jvcir.2018.06.006
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GU5IB
UT WOS:000445318100019
DA 2024-07-18
ER

PT J
AU Bai, C
   Reibman, AR
AF Bai, Chen
   Reibman, Amy R.
TI Image quality assessment in first-person videos
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE First-person videos; Local Visual Information (LVI); Mutual reference;
   Image quality assessment; Pseudo-reference
ID EGOCENTRIC VIDEO; BLUR; FEATURES
AB First-person videos (FPVs) or egocentric videos provide a huge amount of data for visual lifelogs. The quality assessment of frames in FPVs serves as an important tool, feature or evaluation baseline for not only structuring but also analyzing lifelogs. To develop a frame-quality measure for FPVs, we introduce a new strategy for image quality estimation, called mutual reference (MR), which uses one or more pseudo-reference images to evaluate a test image. We then propose a MR quality estimator, called Local Visual Information (LVI), that primarily measures the relative blur between two images. To apply the MR strategy to FPVs, we propose a mutual reference frame quality assessment for FPVs (MRFQAFPV) framework which incorporates LVI. Our results, using both real and synthetic distortions and objective and subjective tests, demonstrate both methods perform better than existing NR QEs at measuring the quality of frames in FPVs.
C1 [Bai, Chen; Reibman, Amy R.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
C3 Purdue University System; Purdue University
RP Bai, C (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM baichen@purdue.edu
OI Reibman, Amy/0000-0003-1859-1091
CR Agarwal A., 2005, SURVEY PLANAR HOMOGR
   [Anonymous], ELECT IMAGING
   Bai C., 2017, HUMAN VISION ELECTRO
   Bai C, 2017, IEEE IMAGE PROC, P290, DOI 10.1109/ICIP.2017.8296289
   Bai C, 2016, IEEE IMAGE PROC, P2440, DOI 10.1109/ICIP.2016.7532797
   Baker S, 2010, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2010.5539932
   Baulida A.L., 2012, THESIS
   Betancourt A, 2015, IEEE T CIRC SYST VID, V25, P744, DOI 10.1109/TCSVT.2015.2409731
   Bolanos M., 2016, IEEE T HUMAN MACH SY
   Chandler D.M., 2013, ISBN SIGNAL PROCESS
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Chandrasekhar V, 2014, IEEE COMPUT SOC CONF, P541, DOI 10.1109/CVPRW.2014.84
   Demirtas AM, 2014, IEEE T IMAGE PROCESS, V23, P2069, DOI 10.1109/TIP.2014.2310991
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Handley J.C., 2001, PICS
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hemami S.S., 2010, SIGNAL PROCESS IMAGE
   Hu H, 2006, IEEE IMAGE PROC, P617, DOI 10.1109/ICIP.2006.312411
   Jin HL, 2005, PROC CVPR IEEE, P18
   Kang HW, 2011, IEEE I CONF COMP VIS, P762, DOI 10.1109/ICCV.2011.6126314
   Kellnhofer P., 2015, ELECT IMAGING
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Lin WS, 2005, IEEE T CIRC SYST VID, V15, P900, DOI 10.1109/TCSVT.2005.848345
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Liu H., 2016, QUALITY MULTIMEDIA E
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Marichal X., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P386, DOI 10.1109/ICIP.1999.822923
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mas J., 2003, TRECVID
   Melo Silva Michel, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P557, DOI 10.1007/978-3-319-46604-0_40
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy A.K., 2010, IEEE SIGNAL PROCESS
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Niu YZ, 2012, IEEE T CIRC SYST VID, V22, P1037, DOI 10.1109/TCSVT.2012.2189689
   Peleg S., 2014, CVPR, P2537, DOI DOI 10.1109/CVPR.2014.325
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Poleg Y, 2015, PROC CVPR IEEE, P4768, DOI 10.1109/CVPR.2015.7299109
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Saad M.A., 2015, Colour and Visual Computing Symposium, P1, DOI DOI 10.1109/CVCS.2015.7274887
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Stathaki T, 2011, Image fusion: algorithms and applications
   Wainwright MJ, 2001, APPL COMPUT HARMON A, V11, P89, DOI 10.1006/acha.2000.0350
   Wang P, 2012, INT J MULTIMED INF R, V1, P87, DOI 10.1007/s13735-012-0010-8
   Wang X, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P467, DOI 10.1109/CISP.2008.371
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wannous H, 2012, LECT NOTES COMPUT SC, V7131, P244, DOI 10.1007/978-3-642-27355-1_24
   Xiong B, 2014, LECT NOTES COMPUT SC, V8693, P282, DOI 10.1007/978-3-319-10602-1_19
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2012, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2012.6467150
   Zhang L, 2012, IEEE IMAGE PROC, P1473, DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 63
TC 4
Z9 5
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2018
VL 54
BP 123
EP 132
DI 10.1016/j.jvcir.2018.05.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GJ3EC
UT WOS:000435167800011
DA 2024-07-18
ER

PT J
AU Thongkor, K
   Amornraksa, T
   Delp, EJ
AF Thongkor, Kharittha
   Amornraksa, Thumrongrat
   Delp, Edward J.
TI Digital watermarking for camera-captured images based on just noticeable
   distortion and Wiener filtering
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Digital image watermarking; Just noticeable distortion; Pixel value
   distortions; Geometric distortions
ID EXTRACTION
AB In this paper, we propose a digital image watermarking method for camera-captured images. In our proposed method, an image component of all image pixels is used for embedding an individual watermark bit in order to provide large amount of the embedded watermark. The watermark strength is adjusted in accordance with the modified just noticeable distortion. After the watermarked image is printed and then captured by a digital camera, the reliable watermark extraction is accomplished based on the techniques of reducing distortions introduced from the printing and camera-capturing processes, and predicting original image component from the watermarked image component. In the experiments, various types of pixel value distortions and geometric distortions are considered and explored. With the proposed method, the results show that the watermark can be invisibly embedded, and reliably extracted. We also demonstrate its robustness against various types of distortions from the printing and camera-capturing processes.
C1 [Thongkor, Kharittha; Amornraksa, Thumrongrat] King Mongkuts Univ Technol Thonburi, Fac Engn, Dept Comp Engn, 126 Pracha Uthit Rd, Bangkok 10140, Thailand.
   [Delp, Edward J.] Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47906 USA.
C3 King Mongkuts University of Technology Thonburi; Purdue University
   System; Purdue University
RP Thongkor, K (corresponding author), King Mongkuts Univ Technol Thonburi, Fac Engn, Dept Comp Engn, 126 Pracha Uthit Rd, Bangkok 10140, Thailand.
EM kharittha@gmail.com
RI Delp, Edward J/C-3616-2013
OI Delp, Edward/0000-0002-2909-7323
FU Thailand Research Fund through the Royal Golden Jubilee Ph.D. Program
   [PHD/0111/2553]; King Mongkut's University of Technology Thonburi
FX This work was financially supported from the Thailand Research Fund
   through the Royal Golden Jubilee Ph.D. Program (Grant No. PHD/0111/2553)
   and King Mongkut's University of Technology Thonburi.
CR Aizenberg I, 2002, LECT NOTES COMPUT SC, V2415, P1231
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Amornraksa T, 2006, IMAGE VISION COMPUT, V24, P111, DOI 10.1016/j.imavis.2005.09.018
   [Anonymous], 1996, Computer graphics: principles and practice
   [Anonymous], 2016, IRTC VIEWING VOTING
   [Anonymous], 2016, TEST STILL IMAGES
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Cattin P., 2014, MIAC U BASEL LECT NO
   Chen David, 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P535, DOI 10.1109/MMSP.2008.4665136
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Cox J., 2007, DIGITAL WATERMARKING
   Delaigle J.F., 2002, P ICME
   Delaigle JF, 1998, SIGNAL PROCESS, V66, P319, DOI 10.1016/S0165-1684(98)00013-9
   Erçelebi E, 2006, IEE P-VIS IMAGE SIGN, V153, P31, DOI 10.1049/ip-vis:20045116
   Geoffrey B., 1996, U.S. patent, Patent No. [5 822436, 5822436]
   Ghazal M, 2008, IEEE T CIRC SYST VID, V18, P1797, DOI 10.1109/TCSVT.2008.2004925
   Goshtasby A., 2005, 2D 3D IMAGE REGISTRA
   Greenbaum A., 2012, Numerical Methods: Design, Analysis, and Computer Implementation of Algorithms
   Horprasert T., 1998, Proc. Perceptual User Interfaces, P87
   HUANG TS, 1965, IEEE SPECTRUM, V2, P57, DOI 10.1109/MSPEC.1965.6501034
   Kim W, 2006, LECT NOTES COMPUT SC, V3981, P106
   Lee MJ, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3134121
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Lin C.Y., 1999, P ISMIP
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Nakamura T., 2004, P 3 INT C MOB UB MUL, P101
   Nguyen L.V., 2012, P ICISCE
   Nuutinen M., 2009, GRAPHIC ARTS FINLAND, V38, P1
   Perry B, 2002, P SOC PHOTO-OPT INS, V4675, P118, DOI 10.1117/12.465267
   Pramila A., 2007, P FINSIG
   Pramila A, 2012, SIGNAL IMAGE VIDEO P, V6, P211, DOI 10.1007/s11760-011-0211-2
   Seitz J., 2005, DIGITAL WATERMARKING
   Setkov A., 2013, P MIRAGE
   Shen RM, 2005, J SYST SOFTWARE, V78, P1, DOI 10.1016/j.jss.2005.02.013
   Shih F.Y., 2007, DIGITAL WATERMARKING
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Takeuchi S, 2005, IEEE ICCE, P411, DOI 10.1109/ICCE.2005.1429892
   Tsai HH, 2014, INFORMATICA-LITHUAN, V25, P113, DOI 10.15388/Informatica.2014.07
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Voloshynovskiy S, 2001, SIGNAL PROCESS, V81, P1177, DOI 10.1016/S0165-1684(01)00039-1
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang XK, 2005, SIGNAL PROCESS-IMAGE, V20, P662, DOI 10.1016/j.image.2005.04.001
NR 47
TC 12
Z9 12
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2018
VL 53
BP 146
EP 160
DI 10.1016/j.jvcir.2018.03.005
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GF8OS
UT WOS:000432232800014
DA 2024-07-18
ER

PT J
AU Kaashki, NN
   Safabakhsh, R
AF Kaashki, Nastaran Nourbakhsh
   Safabakhsh, Reza
TI RGB-D face recognition under various conditions via 3D constrained local
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE 3D face recognition; Depth image; Face model; 3D constrained local
   model; Head pose; Lighting; Facial expression; Kinect; Feature
   descriptor
ID KEYPOINT DETECTION; RECONSTRUCTION; EIGENFACES
AB This research proposes a method for 3D face recognition in various conditions using 3D constrained local model (CLM-Z). In this method, a combination of 2D images (RGBs) and depth images (Ds) captured by Kinect has been used. After detecting the face and smoothing the depth image, CLM-Z model has been used to model and detect the important points of the face. These points are described using Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), and 3D Local Binary Patterns (3DLBP). Finally, each face is recognized by a Support Vector Machine (SVM). The challenging situations are changes of lighting, facial expression and head pose. The results on CurtinFaces and IIIT-D datasets demonstrate that the proposed method outperformed state-of-the-art methods under illumination, expression and pitch pose conditions and comparable results were obtained in other cases. Additionally, our proposed method is robust even when the training data has not been carefully collected.
C1 [Kaashki, Nastaran Nourbakhsh; Safabakhsh, Reza] Amirkabir Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Amirkabir University of Technology
RP Safabakhsh, R (corresponding author), Amirkabir Univ Technol, Dept Comp Engn, Tehran, Iran.
EM nastaran_nourbakhsh@aut.ac.ir; safa@aut.ac.ir
RI Safabakhsh, Reza/K-9687-2018
OI Safabakhsh, Reza/0000-0002-4937-8026; Nourbakhsh Kaashki,
   Nastaran/0000-0001-8317-4994
CR [Anonymous], 2016, Face Recognition Across the Imaging Spectrum, DOI DOI 10.1007/978-3-319-28501-6_12
   Baltrusaitis T., 2012, 2012 IEEE C COMP VIS
   Bartlett M. S., 2002, IEEE T NEURAL NETWOR
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berretti S, 2014, VISUAL COMPUT, V30, P1275, DOI 10.1007/s00371-014-0932-7
   Blanz V., 1999, SIGGRAPH
   Cao Z., 2010, 2010 IEEE C COMP VIS
   Cendrillon R., 2000, VISUAL COMMUNICATION
   Cootes T.F., 1992, BMVC92
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cox I.J., 1996, P IEEE C COMP VIS PA
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dalal N, 2005, P CVPR, P01
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Faro A., 2006, 28 ANN INT C IEEE EN
   González-Jiménez D, 2007, IEEE T INF FOREN SEC, V2, P413, DOI 10.1109/TIFS.2007.903543
   Goswami G, 2013, 2013 IEEE SIXTH INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS)
   Goswami G, 2014, IEEE T INF FOREN SEC, V9, P1629, DOI 10.1109/TIFS.2014.2343913
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Guo Z, 2013, J VIS COMMUN IMAGE R, V24, P117, DOI 10.1016/j.jvcir.2012.08.004
   Hayat M, 2016, NEUROCOMPUTING, V171, P889, DOI 10.1016/j.neucom.2015.07.027
   Hsu GS, 2014, IEEE T INF FOREN SEC, V9, P2110, DOI 10.1109/TIFS.2014.2361028
   Huynh T., 2013, COMP VIS ACCV 2012 W
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Kaashki NN, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P361
   Kanade Takeo, 1973, Picture processing system by computer complex and recognition of human faces
   Li BYL, 2016, NEUROCOMPUTING, V214, P93, DOI 10.1016/j.neucom.2016.06.012
   Li B, 2012, EXP DIABETES RES, DOI 10.1155/2012/216512
   Liao HB, 2012, J VIS COMMUN IMAGE R, V23, P924, DOI 10.1016/j.jvcir.2012.06.005
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Moghaddam B., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P350, DOI 10.1109/ICPR.1996.546848
   Mohammadzade H, 2013, IEEE T PATTERN ANAL, V35, P381, DOI 10.1109/TPAMI.2012.107
   Paysan P., 2009, 6 IEEE INT C AVSS
   Saragih JM, 2009, 2009 IEEE 12 INT C C
   Seshadri K., 2009, IEEE 3 INT C BIOM TH
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Teijeiro-Mosquera L., 2010, 2010 20 INT C PATT R
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Wan KW, 2005, PATTERN RECOGN LETT, V26, P2409, DOI 10.1016/j.patrec.2005.04.015
   Wang W, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P523, DOI 10.1109/ICMI.2002.1167050
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
   Yin L, 2008, 8 IEEE INT C AUT FAC
   Zhang H, 2013, TENCON IEEE REGION
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 48
TC 17
Z9 17
U1 1
U2 14
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 66
EP 85
DI 10.1016/j.jvcir.2018.02.003
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300007
DA 2024-07-18
ER

PT J
AU Qiu, YQ
   He, H
   Qian, ZX
   Li, S
   Zhang, XP
AF Qiu, Yingqiang
   He, Han
   Qian, Zhenxing
   Li, Sheng
   Zhang, Xinpeng
TI Lossless data hiding in JPEG bitstream using alternative embedding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Information hiding; Lossless data hiding; Reversible data hiding
ID GENERALIZED INTEGER TRANSFORM; REVERSIBLE WATERMARKING; DIFFERENCE
   EXPANSION; IMAGES; SCHEME
AB This paper proposes a lossless data hiding method for JPEG images using adaptive embedding. By constructing an optimal mapping between the used and unused Huffman codes in each category, we take full use of the combination of mapping to achieve a high embedding rate. In order to improve the payload, we further use a code reordering based embedding algorithm. Both algorithms are alternatively used during data hiding. After modifying the Huffman Table defined in JPEG header and substituting the codes in entropy-encoded segments, additional messages are embedded into the JPEG bitstream. The proposed method is lossless to the image, Le., the decoded content of a marked JPEG bitstream is identical to the original JPEG image. Meanwhile, the file size can be well preserved after data hiding. Experimental results show that the proposed method has a better performance than state-of-the-art works.
C1 [Qiu, Yingqiang; He, Han] Huaqiao Univ, Coll Informat Sci & Engn, Xiamen 361021, Peoples R China.
   [Qian, Zhenxing; Li, Sheng; Zhang, Xinpeng] Fudan Univ, Sch Comp Sci, Shanghai Inst Intelligent Elect & Syst, Shanghai 200433, Peoples R China.
C3 Huaqiao University; Fudan University
RP Qian, ZX (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Inst Intelligent Elect & Syst, Shanghai 200433, Peoples R China.
EM zxqian@fudan.edu.cn
RI Qiu, Yingqiang/AAR-8483-2020; li, sheng/AAF-2381-2019; Qian,
   Zhenxing/AHC-9176-2022
OI li, sheng/0000-0002-7932-9831; 
FU Natural Science Foundation of China [61572308, U1536108, U1736213,
   U1636206, 61525203, 61472235, 61602294]; Shanghai Dawn Scholar Plan
   [145G36]; Shanghai Excellent Academic Leader Plan [16XD1401200]; young
   and middle-aged teacher education research project of Fujian Province of
   China [JAT160034]; Shanghai Sailing Program [16YF1404100]
FX This work was supported by Natural Science Foundation of China (Grant
   61572308, Grant U1536108, Grant U1736213, Grant U1636206, Grant
   61525203, Grant 61472235, Grant 61602294), the Shanghai Dawn Scholar
   Plan (Grant 145G36), the Shanghai Excellent Academic Leader Plan (Grant
   16XD1401200), the young and middle-aged teacher education research
   project of Fujian Province of China (Grant JAT160034), and the Shanghai
   Sailing Program (Grant 16YF1404100).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Hu YJ, 2013, J SYST SOFTWARE, V86, P2166, DOI 10.1016/j.jss.2013.03.102
   Huang FJ, 2016, IEEE T CIRC SYST VID, V26, P1610, DOI 10.1109/TCSVT.2015.2473235
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Mobasseri BG, 2010, IEEE T IMAGE PROCESS, V19, P958, DOI 10.1109/TIP.2009.2035227
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qian ZX, 2018, IEEE T DEPEND SECURE, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qian ZX, 2012, J SYST SOFTWARE, V85, P309, DOI 10.1016/j.jss.2011.08.015
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Sakai H., 2008, P INT S INF THEOR IT, P1
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang JX, 2017, IEEE T CYBERNETICS, V47, P315, DOI 10.1109/TCYB.2015.2514110
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wu YH, 2011, INT J AUDIOL, V50, P405, DOI 10.3109/14992027.2010.551219
   Xuan GR, 2007, LECT NOTES COMPUT SC, V4633, P715
   Zhang WM, 2015, IEEE T IMAGE PROCESS, V24, P294, DOI 10.1109/TIP.2014.2358881
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
NR 29
TC 29
Z9 35
U1 1
U2 35
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 86
EP 91
DI 10.1016/j.jvcir.2018.02.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300008
DA 2024-07-18
ER

PT J
AU Zhang, TH
   Tang, CW
AF Zhang, Ting-hao
   Tang, Chih-Wei
TI Multiple-target tracking on mixed images with reflections and occlusions
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Multi-target tracking; Reflections; Occlusions; Multi-cue integration;
   Data association
ID PROBABILISTIC DATA ASSOCIATION; VISUAL TRACKING; OBJECTS; MODEL
AB Measurements arose from strong reflections combined with occlusions significantly degrade accuracy of multi target tracking. Few methods have addressed this problem, and thus this paper proposes a robust multi-target tracker for mixed images with occlusions. For multi-cue integration using co-inference tracking, moving object detection significantly enhances motion cue based correction in the presence of reflections. Target templates are represented by sets of color and spatiality histograms. Joint likelihoods referring to both the target motion trajectory and appearance model of the co-inference fused state are computed. Thus each optimized particle weight with the criteria of maximum joint likelihood is more reliable in the face of reflections and inter-object occlusions. State estimation is achieved with the sample-based data association probability and occlusion confidence indicator. Experimental results show that the proposed tracker outperforms the-state-of-the-art multi target trackers on images with strong reflections and inter-object occlusions.
C1 [Zhang, Ting-hao] HTC Corp, 23 Xinghua Rd, Taoyuan 330, Taiwan.
   [Tang, Chih-Wei] Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
C3 National Central University
RP Tang, CW (corresponding author), Natl Cent Univ, Dept Commun Engn, Jhongli 32001, Taiwan.
EM taylor355109@gmail.com; cwtang@ce.ncu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST-103-2221-E-008-061,
   MOST-104-2221-E-008-059]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the Grants MOST-103-2221-E-008-061 and
   MOST-104-2221-E-008-059.
CR Aherne F., 1997, KYBERNETIKA, V32, P1
   [Anonymous], 2006, P INT EVAL WORKSH CL
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Ata-ur-Rehman, 2013, 2013 16TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1730
   Bar-Shalom Y., 2011, Tracking and Data Fusion: A Handbook of Algorithms
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   CHANG KC, 1984, IEEE T AUTOMAT CONTR, V29, P585, DOI 10.1109/TAC.1984.1103597
   Chen HT, 2015, J VIS COMMUN IMAGE R, V30, P208, DOI 10.1016/j.jvcir.2015.04.006
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Elgharib M. A., 2013, P EUR C VIS MED PROD
   Feng X. Y., 2016, 2 INT C ART INT IND, V133
   Ferryman J., 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P143, DOI 10.1109/AVSS.2010.90
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fortmann T. E., 1980, Proceedings of the 19th IEEE Conference on Decision & Control Including the Symposium on Adaptive Processes, P807
   Hong CQ, 2016, MULTIMED TOOLS APPL, V75, P1459, DOI 10.1007/s11042-014-2305-7
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hsiao-Tzu Chen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6548, DOI 10.1109/ICASSP.2014.6854866
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Liu KJ, 2015, IEEE IMAGE PROC, P2979, DOI 10.1109/ICIP.2015.7351349
   Lu JY, 2011, IEEE IMAGE PROC, P489, DOI 10.1109/ICIP.2011.6116558
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mahler RPS, 2004, IEEE AERO EL SYS MAG, V19, P53, DOI 10.1109/MAES.2004.1263231
   McLaughlin N, 2015, IEEE WINT CONF APPL, P71, DOI 10.1109/WACV.2015.17
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Perez-Sala X., 2012, P INT C CAT ASS ART
   Poore A. B., 1994, Computational Optimization and Applications, V3, P27, DOI 10.1007/BF01299390
   Schulz D, 2003, INT J ROBOT RES, V22, P99, DOI 10.1177/0278364903022002002
   Shi XF, 2015, IEEE ICC, P6615, DOI 10.1109/ICC.2015.7249379
   van Gastel JS, 2015, IEEE INT C INTELL TR, P919, DOI 10.1109/ITSC.2015.154
   Wang N, 2013, P ADV NEURAL INFORM
   Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606
   Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd
   Xiao JJ, 2016, IEEE T CIRC SYST VID, V26, P304, DOI 10.1109/TCSVT.2015.2406193
   Yang T, 2005, PROC CVPR IEEE, P970
   Zhang TH, 2015, LECT NOTES COMPUT SC, V9474, P127, DOI 10.1007/978-3-319-27857-5_12
NR 38
TC 3
Z9 4
U1 0
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2018
VL 52
BP 45
EP 57
DI 10.1016/j.jvcir.2018.02.001
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA GC2RM
UT WOS:000429630300005
DA 2024-07-18
ER

PT J
AU Martínez-Díaz, Y
   Hernández, N
   Biscay, RJ
   Chang, L
   Méndez-Vázquez, H
   Sucar, LE
AF Martinez-Diaz, Yoanna
   Hernandez, Noslen
   Biscay, Rolando J.
   Chang, Leonardo
   Mendez-Vazquez, Heydi
   Enrique Sucar, L.
TI On Fisher vector encoding of binary features for video face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Fisher vector; Binary features; Face recognition; Video
AB Several approaches have been proposed for face recognition in videos. Fisher vector (FV) encoding of local Scale Invariant Feature Transforms (SIFT) is among the best performing ones. Aiming at speed up the computation time of this approach, a method based on FV encoding of binary features was recently introduced. By using Binary Robust Independent Elementary Features (BRIEF), this method gained in efficiency but lost in accuracy. FV representation of binary features demands appropriated mathematical tools, which are not as easy available as for continuous features. This paper introduces a new way for obtaining FV encoding of binary features that is still efficient and also accurate. We show that BRIEF combined with FV are discriminative enough, and provide as good performance as the one obtained by using SIFT features for video face recognition. Besides, we discuss several insights and promising lines of future work in regard to FV encoding of binary features.
C1 [Martinez-Diaz, Yoanna; Mendez-Vazquez, Heydi] Adv Technol Applicat Ctr CENATAV, Havana, Cuba.
   [Hernandez, Noslen] Univ Sao Paulo, Sao Paulo, Brazil.
   [Biscay, Rolando J.] Ctr Invest Matemat CIMAT, Guanajuato, Mexico.
   [Enrique Sucar, L.] INAOE, Puebla, Mexico.
   [Chang, Leonardo] Tecnol Monterrey, Campus Estado Mexico, Mexico City, DF, Mexico.
C3 Universidade de Sao Paulo; CIMAT - Centro de Investigacion en
   Matematicas; Instituto Nacional de Astrofisica, Optica y Electronica;
   Tecnologico de Monterrey
RP Hernández, N (corresponding author), Univ Sao Paulo, Sao Paulo, Brazil.
EM noslenh@gmail.com
OI Chang, Leonardo/0000-0002-0703-2131; Mendez-Vazquez,
   Heydi/0000-0002-7834-1791; Hernandez, Noslen/0000-0003-2438-1912
FU FAPERJ/CAPES [E45/2013]; FONCICYT (CONACYT) [272727]; FONCICYT (European
   UNION) [272727]
FX The second author was supported by FAPERJ/CAPES (E45/2013). This work is
   supported in part by FONCICYT (CONACYT and European UNION) Project No.
   272727.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2013, P INT C BIOM ICB
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   Chen JC, 2015, IEEE IMAGE PROC, P2705, DOI 10.1109/ICIP.2015.7351294
   Collins M., 2001, ADV NEURAL INFORM PR, V14, P617
   Cui Z, 2013, PROC CVPR IEEE, P3554, DOI 10.1109/CVPR.2013.456
   de Leeuw J, 2006, COMPUT STAT DATA AN, V50, P21, DOI 10.1016/j.csda.2004.07.010
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Grother P., 2017, 8173 NAT I STAND TEC
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang ZW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493448
   Huang ZW, 2014, PROC CVPR IEEE, P1677, DOI 10.1109/CVPR.2014.217
   Landgraf A., ARXIV151006112
   Landgraf A. J., 2015, THESIS
   Lankinen J, 2012, INT C PATT RECOG, P780
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li H., 2014, Asian Conference on Computer Vision, P17
   Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449
   LI HX, 2015, CVPR, P4055
   Mahmood Z, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17500256
   Martínez-Díaz Y, 2016, INT C PATT RECOG, P1436, DOI 10.1109/ICPR.2016.7899839
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Parkhi OM, 2014, PROC CVPR IEEE, P1693, DOI 10.1109/CVPR.2014.219
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sánchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019
   Schein A.I., 2003, PROCEEDING 9 INT WOR, P14
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wen Y, 2016, DIGIT SIGNAL PROCESS, V50, P103, DOI 10.1016/j.dsp.2015.11.001
   Wolf L, 2013, PROC CVPR IEEE, P3523, DOI 10.1109/CVPR.2013.452
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Yang J., 2017, CVPR IN PRESS
NR 40
TC 17
Z9 17
U1 1
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2018
VL 51
BP 155
EP 161
DI 10.1016/j.jvcir.2018.01.017
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FX8IB
UT WOS:000426334500015
DA 2024-07-18
ER

PT J
AU Edmunds, T
   Caplier, A
AF Edmunds, Taiamiti
   Caplier, Alice
TI Motion-based countermeasure against photo and video spoofing attacks in
   face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Motion cues; Face anti-spoofing; Fisher kernel; Replay attacks
ID LIVENESS DETECTION; IMAGE
AB Facial biometric systems are vulnerable to fraudulent access attempts by presenting photographs or videos of a valid user in front of the sensor also known as "spoofing attacks". Multiple protection measures have been proposed but limited attention has been dedicated to exclusive motion-based countermeasures since the arrival of video and mask attacks. A novel motion-based countermeasure which exploits natural and unnatural motion cues is presented. The proposed method takes advantage of the Conditional Local Neural Fields (CLNF) face tracking algorithm to extract rigid and non-rigid face motions. Similarly to the bag-of-words feature encoding, a vocabulary of motion sequences is constructed to derive discriminant mid-level motion features using the Fisher vector framework. Extensive experiments are conducted on ReplayAttack-DB, CASIA-FASD and MSU-MFSD databases. Complementary experiments on rigid mask attacks from the 3DMAD public database are also conducted and generalization issues are investigated via cross-database evaluation in particular.
C1 [Edmunds, Taiamiti; Caplier, Alice] GIPSA Lab, 11 Rue Math,Grenoble Campus BP46, F-38402 St Martin Dheres, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Edmunds, T (corresponding author), GIPSA Lab, 11 Rue Math,Grenoble Campus BP46, F-38402 St Martin Dheres, France.
EM edmunds.taia@gmail.com
FU  [BIOFENCE ANR-13-INSE-0004]
FX This work has been supported by the project BIOFENCE ANR-13-INSE-0004.
CR Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Anjos Andre, 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], TECH REP
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], ICB2013LBPTOP
   [Anonymous], FACE RECOGNITION MET
   [Anonymous], YOUR FACE IS NOT YOU
   [Anonymous], 2011, 2011 INT JOINT C BIO
   [Anonymous], 2016, P IEEE WINT C APPL C
   [Anonymous], FACE ANTISPOOFING VI
   [Anonymous], 1997, Tech. Rep.
   [Anonymous], INT C BIOM ICB 13 FB
   [Anonymous], FACE LIVENESS DETECT
   [Anonymous], 22 CBSA BORD TECHN D
   [Anonymous], FG 2013
   [Anonymous], 2013 IEEE C COMP VIS
   [Anonymous], FACE ANTISPOOFING BA
   Bai JM, 2010, IEEE INT SYMP CIRC S, P3425, DOI 10.1109/ISCAS.2010.5537866
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chingovska I, 2013, INT CONF BIOMETR
   Chingovska Ivana, 2012, BIOSIG
   da Silva Pinto A., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P221, DOI 10.1109/SIBGRAPI.2012.38
   De Marsico M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P73, DOI 10.1109/ICB.2012.6199761
   Dhamecha TI, 2013, INT CONF BIOMETR
   Ekman P., FACIAL ACTION CODING
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Gahyun Kim, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P67, DOI 10.1109/ICB.2012.6199760
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Kim YS, 2009, J OPT SOC AM A, V26, P760, DOI 10.1364/JOSAA.26.000760
   Kobayashi T, 2012, PATTERN RECOGN LETT, V33, P1188, DOI 10.1016/j.patrec.2012.01.007
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Kollreider K, 2008, IEEE COMPUTER SOC C, P1
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Komulainen Jukka, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P146, DOI 10.1007/978-3-642-37410-4_13
   Kose N, 2013, INT CONF DIGIT SIG
   Lee KC, 2005, COMPUT VIS IMAGE UND, V99, P303, DOI 10.1016/j.cviu.2005.02.002
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Nesli E., 2013, IEEE 6 INT C BIOM TH, P1
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484
   Perronnin F., 2007, P IEEE CVPR, P1
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Schwartz W.R., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117592
   Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Tronci Roberto, 2011, BIOM IJCB 2011 INT J, P1, DOI DOI 10.1109/IJCB.2011.6117522
   Waris M.-A., 2013, 21st European Signal Processing Conference (EUSIPCO 2013), P1
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Yan JJ, 2012, I C CONT AUTOMAT ROB, P188, DOI 10.1109/ICARCV.2012.6485156
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 62
TC 25
Z9 27
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 314
EP 332
DI 10.1016/j.jvcir.2017.12.004
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700031
DA 2024-07-18
ER

PT J
AU Haghighi, BB
   Taherinia, AH
   Harati, A
AF Haghighi, Behrouz Bolourian
   Taherinia, Amir Hossein
   Harati, Ahad
TI TRLH: Fragile and blind dual watermarking for image tamper detection and
   self-recovery based on lifting wavelet transform and halftoning
   technique
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Data hiding; Watermarking; Tamper detection and self-recovery; Image
   authentication; Lifting wavelet transform; Halftoning technique
ID SCHEME; AUTHENTICATION
AB This paper proposes a fragile and blind dual watermarking method for tamper detection and self-recovery. This method generates two image digests from the host image, based on the lifting wavelet and the halftoning technique. Therefore, for each 2 x 2 non-overlapping blocks, two chances for recovering tampered blocks is provided. Then, the authentication bit is obtained by using the image digests. Totally, eight bits are embedded in two LSBs for each block of image. To enhance the quality of the digest, a new LSBRounding technique is proposed. Additionally, to determine the mapping blocks and shuffling LSBs, the Arnold Cat Map is utilized. To improve the recovery rate, a Shift-aside operation is proposed. For preventing copy-move, vector-quantization attacks, and any manipulation in LSBs, the information embedded in each block depends on the key which is assigned to it. Experimental results show the efficiency of TRLH compared to the state of the art methods.
C1 [Haghighi, Behrouz Bolourian; Taherinia, Amir Hossein; Harati, Ahad] Ferdowsi Univ Mashhad, Comp Engn Dept, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Taherinia, AH (corresponding author), Ferdowsi Univ Mashhad, Comp Engn Dept, Mashhad, Iran.
EM b.bolourian@stu.um.ac.ir; taherinia@um.ac.ir; a.harati@um.ac.ir
RI Haghighi, Behrouz Bolourian/W-2895-2019; Taherinia, Amir
   Hossein/AAC-9575-2020; Bolourian Haghighi, Behrouz/ADD-8260-2022;
   Taherinia, Amir Hossein/HTP-1792-2023; Harati, Ahad/P-4468-2015
OI Haghighi, Behrouz Bolourian/0000-0002-2388-5556; Taherinia, Amir
   Hossein/0000-0002-5103-4812; Harati, Ahad/0000-0001-7263-0309
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2015, 2015 12 INT C EL ENG
   [Anonymous], QUALITY MEASURES HAL
   [Anonymous], 2000, Digital Watermarking
   Arnol'd VI, 1968, ERGODIC PROBLEMS CLA, Vix
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Fridrich J., 1999, ISSPA '99. Proceedings of the Fifth International Symposium on Signal Processing and its Applications (IEEE Cat. No.99EX359), P301, DOI 10.1109/ISSPA.1999.818172
   FRIEDMAN GL, 1993, IEEE T CONSUM ELECTR, V39, P905, DOI 10.1109/30.267415
   Hsu CS, 2016, MEASUREMENT, V88, P287, DOI 10.1016/j.measurement.2016.03.053
   Hsu CS, 2010, OPT COMMUN, V283, P1737, DOI 10.1016/j.optcom.2009.12.073
   Jarvis JF, 1976, Comput Graph Image Process, V5, P13, DOI DOI 10.1016/S0146-664X(76)80003-2
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lu CS, 2000, IEEE T MULTIMEDIA, V2, P209, DOI 10.1109/6046.890056
   Manish Mishra Manish Mishra, 2013, International Research Journal of Biological Sciences, V2, P1
   Neelamani R., 2002, IEEE T IMAGE PROCESS, V59, P128
   Parashar P., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P111, DOI DOI 10.14257/IJSIP.2014.7.6.10
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Singh P., 2013, INT J ENG INNOV TECH, V2, P165
   Soleymani S.H., 2016, MULTIMED TOOLS APPL, P1
   Son CH, 2014, IEEE T IMAGE PROCESS, V23, P2542, DOI 10.1109/TIP.2014.2319732
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Taherinia AH, 2011, OPT ENG, V50, DOI 10.1117/1.3581116
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu CM., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P13, DOI [10.14257/ijsip.2014.7.5.02, DOI 10.14257/IJSIP.2014.7.5.02]
   Yu GJ, 2001, OPT ENG, V40, P1396, DOI 10.1117/1.1384885
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
NR 38
TC 38
Z9 39
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 49
EP 64
DI 10.1016/j.jvcir.2017.09.017
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700006
DA 2024-07-18
ER

PT J
AU Hu, HJ
   Froment, J
   Liu, QS
AF Hu, Haijuan
   Froment, Jacques
   Liu, Quansheng
TI A note on patch-based low-rank minimization for fast image denoising
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Patch-based method; Low-rank minimization; Principal
   component analysis; Singular value decomposition; Hard thresholding
ID APPROXIMATION; ALGORITHM; MATRIX; SPARSE; IMPLEMENTATION
AB Patch-based low-rank minimization for image processing attracts much attention in recent years. The minimization of the matrix rank coupled with the Frobenius norm data fidelity can be solved by the hard thresholding filter with principle component analysis (PCA) or singular value decomposition (SVD). Based on this idea, we propose a patch-based low-rank minimization method for image denoising. The main denoising process is stated in three equivalent way: PCA, SVD and low-rank minimization. Compared to recent patch-based sparse representation methods, experiments demonstrate that the proposed method is rather rapid, and it is effective for a variety of natural grayscale images and color images, especially for texture parts in images. Further improvements of this method are also given. In addition, due to the simplicity of this method, we could provide an explanation of the choice of the threshold parameter, estimation of PSNR values, and give other insights into this method.
C1 [Hu, Haijuan] Northeastern Univ Qinhuangdao, Sch Math & Stat, Qinhuangdao 066004, Hebei, Peoples R China.
   [Froment, Jacques; Liu, Quansheng] Univ Bretagne Sud, CNRS, UMR 6205, LMBA, Campus Tohann, F-56000 Vannes, France.
C3 Northeastern University - China; Centre National de la Recherche
   Scientifique (CNRS); CNRS - National Institute for Mathematical Sciences
   (INSMI)
RP Hu, HJ (corresponding author), Northeastern Univ Qinhuangdao, Sch Math & Stat, Qinhuangdao 066004, Hebei, Peoples R China.
EM huhaijuan61@126.com; Jacques.Froment@univ-ubs.fr;
   Quansheng.Liu@univ-ubs.fr
RI Froment, Jacques/AAG-6715-2019
OI Froment, Jacques/0000-0002-9864-8432
FU Scientific Research Foundation for the Returned Overseas Chinese
   Scholars, State Education Ministry [48-2]; Centre Henri Lebesgue (CHL)
   [ANR-11-LABX-0020-01]; National Natural Science Foundation of China
   [11571052, 11401590, 11731012]; Hunan Natural Science Foundation
   [2017JJ2271]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. The work is sponsored by the Scientific Research
   Foundation for the Returned Overseas Chinese Scholars, State Education
   Ministry (48-2) and benefited from the support of the Centre Henri
   Lebesgue (CHL, ANR-11-LABX-0020-01). Q. Liu has been partially supported
   by the National Natural Science Foundation of China (Grant Nos.
   11571052, 11401590 and 11731012), and by Hunan Natural Science
   Foundation (China, Grant No. 2017JJ2271).
CR Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chatterjee P, 2012, IEEE T IMAGE PROCESS, V21, P1635, DOI 10.1109/TIP.2011.2172799
   Coifman R. R., 1995, LECT NOTES STAT, V103, P125, DOI [DOI 10.1007/978-1-4612-2544-7_9, 10.1002/cpa.3160410705, DOI 10.1002/CPA.3160410705]
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Eckart C, 1936, PSYCHOMETRIKA, V1, P211, DOI 10.1007/BF02288367
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   He YM, 2011, IEEE SIGNAL PROC LET, V18, P215, DOI 10.1109/LSP.2011.2109039
   Hiriart-Urruty JB, 2013, RAIRO-OPER RES, V47, P299, DOI 10.1051/ro/2013040
   Horn R.A., 1987, Topics in Matrix Analysis
   Johnstone IM, 1997, J R STAT SOC B, V59, P319, DOI 10.1111/1467-9868.00071
   Knaus C, 2013, IEEE IMAGE PROC, P440, DOI 10.1109/ICIP.2013.6738091
   Lebrun M, 2013, SIAM J IMAGING SCI, V6, P1665, DOI 10.1137/120874989
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P96, DOI 10.5201/ipol.2012.llm-ksvd
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Muresan D., 2003, ICIP 2003 P 2003 INT, V1
   Parekh A, 2016, IEEE SIGNAL PROC LET, V23, P493, DOI 10.1109/LSP.2016.2535227
   Pierazzo N, 2014, IEEE IMAGE PROC, P813, DOI 10.1109/ICIP.2014.7025163
   Schaeffer H, 2013, SIAM J IMAGING SCI, V6, P226, DOI 10.1137/110854989
   Talebi H, 2014, IEEE T IMAGE PROCESS, V23, P755, DOI 10.1109/TIP.2013.2293425
   Wang YH, 2017, IEEE T IMAGE PROCESS, V26, P3360, DOI 10.1109/TIP.2017.2678798
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Zeng K, 2017, IEEE T CYBERNETICS, V47, P27, DOI 10.1109/TCYB.2015.2501373
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
NR 30
TC 12
Z9 14
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JAN
PY 2018
VL 50
BP 100
EP 110
DI 10.1016/j.jvcir.2017.11.013
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FU3WB
UT WOS:000423781700011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dai, T
   Xu, ZY
   Liang, HY
   Gu, K
   Tang, QT
   Wang, YS
   Lu, WZ
   Xia, ST
AF Dai, Tao
   Xu, Zhiya
   Liang, Haoyi
   Gu, Ke
   Tang, Qingtao
   Wang, Yisen
   Lu, Weizhi
   Xia, Shu-Tao
TI A generic denoising framework via guided principal component analysis
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image denoising; Principal component analysis; Back projection
ID EFFICIENT NONLOCAL-MEANS; PARALLEL FRAMEWORK; IMAGE; HEVC; ALGORITHM;
   DECISION; SURE
AB Though existing state-of-the-art denoising algorithms, such as BM3D, LPG-PCA and DDF, obtain remarkable results, these methods are not good at preserving details at high noise levels, sometimes even introducing non-existent artifacts. To improve the performance of these denoising methods at high noise levels, a generic denoising framework is proposed in this paper, which is based on guided principle component analysis (GPCA). The propose framework can be split into two stages. First, we use statistic test to generate an initial denoised image through back projection, where the statistical test can detect the significantly relevant information between the denoised image and the corresponding residual image. Second, similar image patches are collected to form different patch groups, and local basis are learned from each patch group by principle component analysis. Experimental results on natural images, contaminated with Gaussian and non-Gaussian noise, verify the effectiveness of the proposed framework. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Dai, Tao; Xu, Zhiya; Tang, Qingtao; Wang, Yisen; Lu, Weizhi; Xia, Shu-Tao] Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Guangdong, Peoples R China.
   [Liang, Haoyi] Univ Virginia, Dept ECE, Charlottesville, VA 22904 USA.
   [Gu, Ke] Beijing Univ Technol, BJUT Fac Informat Technol, Beijing 100124, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   University of Virginia; Beijing University of Technology
RP Lu, WZ (corresponding author), Tsinghua Univ, Grad Sch Shenzhen, Shenzhen 518055, Guangdong, Peoples R China.
EM wzlusd@sz.tsinghua.edu.cn
RI Gu, Ke/AAJ-9684-2021; Xu, Zhiya/HTM-9742-2023
FU National Natural Science Foundation of China [61371078]; R&D Program of
   Shenzhen [JCYJ20140509172959977, JSGG20150512162853495,
   ZDSYS20140509172959989, JCYJ20160331184440545]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61371078, and the R&D Program of Shenzhen under
   Grant Nos. JCYJ20140509172959977, JSGG20150512162853495,
   ZDSYS20140509172959989, JCYJ20160331184440545.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   [Anonymous], 2017, IEEE T NEUR NET LEAR
   Brox T, 2008, IEEE T IMAGE PROCESS, V17, P1083, DOI 10.1109/TIP.2008.924281
   Brunet D, 2009, LECT NOTES COMPUT SC, V5627, P1, DOI 10.1007/978-3-642-02611-9_1
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Chen F, 2015, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2015.76
   Chen J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618492
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dai SY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1039
   Dai T, 2017, SIGNAL PROCESS, V137, P223, DOI 10.1016/j.sigpro.2017.02.005
   Dai T, 2015, IEEE IMAGE PROC, P4406, DOI 10.1109/ICIP.2015.7351639
   Deledalle C.-A., 2011, BMVC 2011-22nd British Machine Vision Conference, P25
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Dong WS, 2009, IEEE IMAGE PROC, P349, DOI 10.1109/ICIP.2009.5414423
   Eldar YC, 2009, IEEE T SIGNAL PROCES, V57, P471, DOI 10.1109/TSP.2008.2008212
   Guo Q, 2016, IEEE T CIRC SYST VID, V26, P868, DOI 10.1109/TCSVT.2015.2416631
   Han Y, 2015, NEUROCOMPUTING, V168, P575, DOI 10.1016/j.neucom.2015.05.069
   Hung KW, 2012, IET IMAGE PROCESS, V6, P877, DOI 10.1049/iet-ipr.2011.0050
   Hung KW, 2012, IEEE T IMAGE PROCESS, V21, P1061, DOI 10.1109/TIP.2011.2168416
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Knaus C, 2013, IEEE IMAGE PROC, P440, DOI 10.1109/ICIP.2013.6738091
   Liang HY, 2016, IEEE T IMAGE PROCESS, V25, P5118, DOI 10.1109/TIP.2016.2601783
   Luisier F, 2007, IEEE T IMAGE PROCESS, V16, P593, DOI 10.1109/TIP.2007.891064
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Orchard J, 2008, IEEE IMAGE PROC, P1732, DOI 10.1109/ICIP.2008.4712109
   Paris Sylvain, 2009, BILATERAL FILTERING
   Peyre G, 2008, LECT NOTES COMPUT SC, V5304, P57, DOI 10.1007/978-3-540-88690-7_5
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Romano Y, 2013, IEEE IMAGE PROC, P435, DOI 10.1109/ICIP.2013.6738090
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Van de Ville D, 2011, IEEE T IMAGE PROCESS, V20, P2683, DOI 10.1109/TIP.2011.2121083
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2015, J VIS COMMUN IMAGE R, V31, P146, DOI 10.1016/j.jvcir.2015.06.010
   Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2621478
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang YQ, 2014, INFORM SCIENCES, V259, P128, DOI 10.1016/j.ins.2013.08.002
   Zhong H, 2012, IEEE SIGNAL PROC LET, V19, P535, DOI 10.1109/LSP.2012.2205566
NR 49
TC 5
Z9 7
U1 0
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 340
EP 352
DI 10.1016/j.jvcir.2017.05.009
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700027
DA 2024-07-18
ER

PT J
AU Weng, SW
   Zhang, GH
   Pan, JS
   Zhou, ZL
AF Weng, Shaowei
   Zhang, Guohao
   Pan, Jeng-Shyang
   Zhou, Zhili
TI Optimal PPVO-based reversible data hiding
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Adaptive prediction pattern; Adaptive
   pixel-modification strategy; Two-stage embedding; PPVO
ID HISTOGRAM-MODIFICATION; DIFFERENCE EXPANSION; IMAGE WATERMARKING;
   PREDICTION; SCHEME; ALGORITHM
AB The optimal PPVO-based reversible data hiding (RDH) including adaptive prediction pattern and optimal bin selection is proposed in this paper. By reasonably designing the prediction pattern, each to-be embedded pixel can be predicted by the n (n is an element of{4,...,13}) neighbors surrounding it. The larger n, the more accurate the prediction, and the higher embedding performance is achieved at low embedding capacity (EC) and vice versa. Since the neighbors surrounding each to-be-embedded pixel can be used for measuring the local complexity, the smoothness classification is more accurate, and furthermore, the prediction performance is increased. Two-stage embedding is exploited in this paper so as to ensure the implementation of full-enclosed-based prediction. Instead of treating separately two stages like in existing methods, two stages are treated jointly to optimize the selection of embedding bins at a given EC. In this way, the optimal embedding bins which can achieve as high visual quality as possible is obtained. Extensive experiments verify the proposed method is effective. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Weng, Shaowei; Zhang, Guohao] Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
   [Pan, Jeng-Shyang] Funjian Univ Technol, Fujian Prov Key Lab Data Min & Applicat, Fuzhou, Fujian, Peoples R China.
   [Zhou, Zhili] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
C3 Guangdong University of Technology; Nanjing University of Information
   Science & Technology
RP Weng, SW (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM wswweiwei@126.com; jspan@cc.kuas.edu.tw; zhou_zhili@163.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU National NSF of China [61571139, 61201393, 61574049]; New Star of Pearl
   River on Science and Technology of Guangzhou [2014J2200085]
FX This work was supported in part by National NSF of China (Nos. 61571139,
   61201393 and 61574049), New Star of Pearl River on Science and
   Technology of Guangzhou (No. 2014J2200085).
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Celik MU, 2005, IEEE T IMAGE PROCESS, V12, P157
   Chen M, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P19
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Coltuc D, 2012, IEEE T IMAGE PROCESS, V21, P412, DOI 10.1109/TIP.2011.2162424
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Hong W., 2010, EURASIP J ADV SIGNAL
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2013, OPT COMMUN, V291, P87, DOI 10.1016/j.optcom.2012.10.081
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hwang HJ, 2010, KSII T INTERNET INF, V4, P655, DOI 10.3837/tiis.2010.08.0012
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2013, SIGNAL PROCESS, V93, P2748, DOI 10.1016/j.sigpro.2013.01.020
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B., 2014, J VIS COMMUN IMAGE R, V22, P5010
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Weinberger MJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P140, DOI 10.1109/DCC.1996.488319
   Weng SW, 2015, MULTIMED TOOLS APPL, V74, P10657, DOI 10.1007/s11042-014-2197-6
   Weng SW, 2014, MULTIMED TOOLS APPL, V72, P3063, DOI 10.1007/s11042-013-1585-7
   Weng SW, 2009, IET ELECT LETT, V1, P91
   Weng SW, 2008, IEEE SIG PROCESS LET, V45, P1022
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Xuan GR, 2004, P IWDW, V5, P23
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
   Zhou ZL, 2016, IEICE T INF SYST, VE99D, P1531, DOI 10.1587/transinf.2015EDP7341
NR 56
TC 35
Z9 38
U1 1
U2 27
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 317
EP 328
DI 10.1016/j.jvcir.2017.05.005
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700025
DA 2024-07-18
ER

PT J
AU Zeng, ZQ
   Wang, XD
   Chen, YM
AF Zeng, Zhiqiang
   Wang, Xiaodong
   Chen, Yuming
TI Multimedia annotation via semi-supervised shared-subspace feature
   selection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Semi-supervised learning; Feature selection; Multi-label learning; Web
   page annotation; Image annotation
ID IMAGE ANNOTATION; INFORMATION; SPARSITY; WEB
AB With the rapid development of social network and computer technologies, we always confront with high dimensional multimedia data. It is time-consuming and unrealistic to organize such a large amount of data. Most existing methods are not appropriate for large-scale data due to their dependence of Laplacian matrix on training data. Normally, a given multimedia sample is usually associated with multiple labels, which are inherently correlated to each other. Although traditional methods could solve this problem by translating it into several single-label problems, they ignore the correlation among different labels. In this paper, we propose a novel semi-supervised feature selection method and apply it to the multimedia annotation. Both labeled and unlabeled samples are sufficiently utilized without the need of graph construction, and the shared information between multiple labels is simultaneously uncovered. We apply the proposed algorithm to both web page and image annotation. Experimental results demonstrate the effectiveness of our method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Zeng, Zhiqiang; Wang, Xiaodong; Chen, Yuming] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
   [Wang, Xiaodong] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
C3 Xiamen University of Technology; Chaoyang University of Technology
RP Wang, XD (corresponding author), Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
EM xdwangjsj@xmut.edu.cn
RI Li, June/JEF-1173-2023; Chen, Yumin/JDD-4884-2023; wang,
   xiao/HZI-9156-2023
OI Chen, Yumin/0000-0003-1981-5827; 
FU National Natural Science Foundation of China [61103100]; National
   Natural Science Foundation of Fujian Province, China [2016J01324];
   Xiamen University of Technology [E201400400]; Fujian Provincial
   Education Department [JA15385]
FX This paper is supported by National Natural Science Foundation of China
   (Grant No. 61103100), National Natural Science Foundation of Fujian
   Province, China (Grant No. 2016J01324), the International Science and
   Technology Cooperation Program of Xiamen University of Technology (No.
   E201400400), Scientific Research Fund of Fujian Provincial Education
   Department (No. JA15385).
CR Amores J, 2007, IEEE T PATTERN ANAL, V29, P1818, DOI 10.1109/TPAMI.2007.1098
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   [Anonymous], P 7 SIAM INT C DAT M
   [Anonymous], 2007, ICML
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Cheng Zheng-Dong, 2010, Acta Automatica Sinica, V36, P1361, DOI 10.3724/SP.J.1004.2010.01361
   Doquire G., NEUROCOMPUTING, V121
   Fung G., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P64, DOI 10.1145/347090.347105
   Gu Q., 2011, 27 C UNC ART INT UAI, P266
   Ji S., 2010, ACM T KNOWL DISCOV D, V4, P890
   Ji SW, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1754428.1754431
   Li Z., 2012, P AAAI C ART INT, P1026
   Liu Y, 2013, NEUROCOMPUTING, V105, P12, DOI 10.1016/j.neucom.2012.05.031
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2011, IEEE I CONF COMP VIS, P2268
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Ren YZ, 2012, NEUROCOMPUTING, V89, P147, DOI 10.1016/j.neucom.2012.02.021
   Ueda N., 2002, ADV NEURAL INFORMATI, P721
   Wang XD, 2016, J VIS COMMUN IMAGE R, V41, P272, DOI 10.1016/j.jvcir.2016.10.007
   Xiaojun Chang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P74, DOI 10.1007/978-3-319-06605-9_7
   Xu ZL, 2010, IEEE T NEURAL NETWOR, V21, P1033, DOI 10.1109/TNN.2010.2047114
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2012, IEEE T IMAGE PROCESS, V21, P1339, DOI 10.1109/TIP.2011.2169269
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Zeng ZQ, 2016, NEUROCOMPUTING, V173, P102, DOI 10.1016/j.neucom.2015.05.119
   Zhang ML, 2007, PATTERN RECOGN, V40, P2038, DOI 10.1016/j.patcog.2006.12.019
   Zhou Z.-H., 2007, P ADV NEUR INF PROC, P1609, DOI DOI 10.1016/J.PATCOG.2006.12.019
NR 36
TC 6
Z9 7
U1 0
U2 18
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2017
VL 48
BP 386
EP 395
DI 10.1016/j.jvcir.2017.01.030
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA FE4JR
UT WOS:000408180700032
DA 2024-07-18
ER

PT J
AU Bae, JS
   Lee, SH
   Choi, KS
   Kim, JO
AF Bae, Ji-Sang
   Lee, Sang-Ho
   Choi, Kang-Sun
   Kim, Jong-Ok
TI Robust skin-roughness estimation based on co-occurrence matrix
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Skin roughness; Gray-level co-occurrence matrix (GLCM); Texture domain;
   Skin image
ID IMAGE-ANALYSIS; FEATURES; SYSTEM
AB As the interest in one's appearance has recently increased, the demand for diagnosing skin conditions has also increased. However, conventional specialized skin diagnostic devices are generally expensive, and people have to visit a skin-care shop to diagnose their skin condition. This is time consuming and troublesome. In this paper, we propose a skin-roughness estimation method that uses a mobile-phone camera in daily environments. In order to achieve accurate evaluation, the illumination variation is alleviated using texture components of the facial skin image. We also propose a new feature-extraction method based on the gray-level co-occurrence matrix, which effectively measures the skin roughness from the texture components. The performance of the proposed method is compared with the conventional commonly used features, and we verify the superiority of the proposed method. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Bae, Ji-Sang; Lee, Sang-Ho; Kim, Jong-Ok] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Choi, Kang-Sun] Koreatech, Sch Elect Elect & Commun Engn, Cheonan, South Korea.
C3 Korea University; Korea University of Technology & Education
RP Kim, JO (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM qowitkd@korea.ac.kr; franky_@korea.ac.kr; ks.choi@koreatech.ac.kr;
   jokim@korea.ac.kr
RI KIM, MINJI/IXD-7702-2023
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) support program
   [IITP-2016-H8501-16-1017]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2016-H8501-16-1017) supervised by the IITP
   (Institute for Information & communications Technology Promotion).
CR Abbadi N. K., 2008, P INT AR C INF TECHN, P1
   Barata C, 2015, IEEE J BIOMED HEALTH, V19, P1146, DOI 10.1109/JBHI.2014.2336473
   Bargo PR, 2010, BRIT J DERMATOL, V162, P724, DOI 10.1111/j.1365-2133.2010.09639.x
   Cavalcanti P.G., 2010, P 2010 25 INT C IM V, P1
   Cho M, 2016, INT J COSMETIC SCI, V38, P399, DOI 10.1111/ics.12303
   Choi JW, 2014, BRIT J DERMATOL, V171, P252, DOI 10.1111/bjd.12769
   Egawa M, 2002, SKIN RES TECHNOL, V8, P212, DOI 10.1034/j.1600-0846.2002.00351.x
   Eleyan A, 2011, TURK J ELECTR ENG CO, V19, P97, DOI 10.3906/elk-0906-27
   Fadzil MHA, 2013, COMPUT BIOL MED, V43, P1987, DOI 10.1016/j.compbiomed.2013.08.009
   Gallagher P, 2012, IEEE CONSUM ELECTR M, V1, P25, DOI 10.1109/MCE.2011.2172076
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iliev D, 1997, EXP DERMATOL, V6, P157, DOI 10.1111/j.1600-0625.1997.tb00199.x
   Lee E, 2011, SKIN RES TECHNOL, V17, P320, DOI 10.1111/j.1600-0846.2011.00500.x
   Lee J.Y., 2015, PORE EXTRACTION SKIN
   Lu RS, 2006, APPL OPTICS, V45, P8839, DOI 10.1364/AO.45.008839
   Mendonça T, 2007, P ANN INT IEEE EMBS, P6573
   Michael GKO, 2012, J VIS COMMUN IMAGE R, V23, P1068, DOI 10.1016/j.jvcir.2012.07.004
   Ozkaya N, 2014, J VIS COMMUN IMAGE R, V25, P1647, DOI 10.1016/j.jvcir.2014.08.003
   Prats-Montalbán JM, 2009, CHEMOMETR INTELL LAB, V96, P6, DOI 10.1016/j.chemolab.2008.10.012
   이강규, 2015, [Journal of the Institute of Electronics and Information Engineers, 전자공학회논문지], V52, P106
   Setaro M, 2001, SKIN RES TECHNOL, V7, P159, DOI 10.1034/j.1600-0846.2001.70303.x
   Suprigianto, 2009, INT C INSTR COMM INF, P1
   Tchvialeva L, 2010, SKIN ROUGHNESS ASSES, P341
   Valkealahti K, 1998, IEEE T PATTERN ANAL, V20, P90, DOI 10.1109/34.655653
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Wen Q, 2013, INT CONF COMPUTAT, P267, DOI 10.1109/ICCPS.2013.6893488
   Zhang JG, 2002, PATTERN RECOGN, V35, P735, DOI 10.1016/S0031-3203(01)00074-7
   Zhou H, 2010, I S BIOMED IMAGING, P225, DOI 10.1109/ISBI.2010.5490372
NR 29
TC 7
Z9 7
U1 3
U2 8
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 13
EP 22
DI 10.1016/j.jvcir.2017.03.003
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500002
DA 2024-07-18
ER

PT J
AU Liu, YT
   Gu, K
   Zhai, GT
   Liu, XM
   Zhao, DB
   Gao, W
AF Liu, Yutao
   Gu, Ke
   Zhai, Guangtao
   Liu, Xianming
   Zhao, Debin
   Gao, Wen
TI Quality assessment for real out-of-focus blurred images
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual quality assessment; Out-of-focus blur; Blind/no-reference; Phase
   congruency; Visual saliency
ID VISUAL SALIENCY DETECTION; INFORMATION; STATISTICS
AB Images are vulnerable to different kinds of distortions, such as blur, noise, blockiness etc, which all degrade the image quality. Among the distorted images, out-of-focus blurred images are frequently encountered and occupy a large proportion. However, few efforts have been done to quality evaluation for these images. In this paper, we devise a dedicated quality evaluation scheme to automatically infer the quality of out-of-focus blurred images, which is named GPSQ (Gradient magnitude and Phase congruency-based and Saliency-guided Quality model). In GPSQ a pair of low-level features, including gradient magnitude (GM) and phase congruency (PC), are extracted to characterize the image local blurriness. Then saliency detection is performed on the image to generate a corresponding saliency map. Finally, we weight the local structure map with the saliency map to estimate the visual quality of the out-of-focus blurred image. Experimental results demonstrate the proposed GPSQ delivers high consistency with subjective evaluation results. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Liu, Yutao; Liu, Xianming; Zhao, Debin; Gao, Wen] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Gu, Ke] Beijing Univ Technol, BJUT Fac Informat Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing 100124, Peoples R China.
   [Zhai, Guangtao] Shanghai Jiao Tong Univ, Inst Image Commun & Informat Proc, Shanghai 200240, Peoples R China.
   [Gao, Wen] Peking Univ, Sch Elect Engn & Comp Sci, Natl Engn Lab Video Technol, Key Lab Machine Percept, Beijing 100871, Peoples R China.
C3 Harbin Institute of Technology; Beijing University of Technology;
   Shanghai Jiao Tong University; Peking University
RP Zhao, DB (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM dbzhao@hit.edu.cn
RI Zhai, Guangtao/X-5949-2019; Gu, Ke/AAJ-9684-2021; Zhao,
   Debin/JEP-0204-2023
OI Zhai, Guangtao/0000-0001-8165-9322; 
FU Major State Basic Research Development Program of China (973 Program)
   [2015CB351804]; National Science Foundation of China [61672193,
   61422112, 61371146, 61521062, 61527804]
FX This work was supported by the Major State Basic Research Development
   Program of China (973 Program) under Grant 2015CB351804 and the National
   Science Foundation of China under Grants (61672193, 61422112, 61371146,
   61521062, 61527804).
CR Alers H., J ELECT IMAG, P24
   [Anonymous], IEEE SIGNAL PROC LET
   Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Gu K., IEEE T IMAGE PROCESS, P24
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2016, NEUROCOMPUTING, V196, P140, DOI 10.1016/j.neucom.2015.11.101
   Gu K, 2016, IEEE T CYBERNETICS, V46, P284, DOI 10.1109/TCYB.2015.2401732
   Gu K, 2015, IEEE T BROADCAST, V61, P520, DOI 10.1109/TBC.2015.2459851
   Gu K, 2015, IEEE T CIRC SYST VID, V25, P1480, DOI 10.1109/TCSVT.2014.2372392
   Gu K, 2015, IEEE SIGNAL PROC LET, V22, P1552, DOI 10.1109/LSP.2015.2413944
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gu K, 2014, IEEE T BROADCAST, V60, P555, DOI 10.1109/TBC.2014.2344471
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Henriksson L, 2009, J NEUROSCI, V29, P14342, DOI 10.1523/JNEUROSCI.3136-09.2009
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Liu YN, 2016, VADOSE ZONE J, V15, DOI 10.2136/vzj2015.05.0068
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   MORRONE MC, 1986, NATURE, V324, P250, DOI 10.1038/324250a0
   Narvekar N.D., IEEE T IMAGE PROCESS, P20
   Riche N, 2012, IEEE IMAGE PROC, P641, DOI 10.1109/ICIP.2012.6466941
   Rohaly A.M., 2000, ITU T STANDARDS CONT, P9
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Soundararajan R, 2012, IEEE T IMAGE PROCESS, V21, P517, DOI 10.1109/TIP.2011.2166082
   Vikram TN, 2012, PATTERN RECOGN, V45, P3114, DOI 10.1016/j.patcog.2012.02.009
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Wu QB, 2015, IEEE IMAGE PROC, P339, DOI 10.1109/ICIP.2015.7350816
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Zhai G., 2006, P 2006 IEEE INT CIRC
   Zhai GT, 2008, SIGNAL PROCESS-IMAGE, V23, P417, DOI 10.1016/j.image.2008.04.007
   Zhai GT, 2011, IEEE IMAGE PROC, P1857, DOI 10.1109/ICIP.2011.6115828
   Zhai GT, 2012, IEEE T IMAGE PROCESS, V21, P41, DOI 10.1109/TIP.2011.2161092
   Zhai GT, 2008, IEEE T MULTIMEDIA, V10, P1316, DOI 10.1109/TMM.2008.2004910
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang W, 2016, IEEE T NEUR NET LEAR, V27, P1266, DOI 10.1109/TNNLS.2015.2461603
   Zhang Y, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043025
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 53
TC 29
Z9 30
U1 1
U2 24
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2017
VL 46
BP 70
EP 80
DI 10.1016/j.jvcir.2017.03.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EX5SJ
UT WOS:000403302500007
OA hybrid
DA 2024-07-18
ER

PT J
AU Yoo, CH
   Kim, SW
   Jung, JY
   Ko, SJ
AF Yoo, Cheol-Hwan
   Kim, Seung-Wook
   Jung, June -Young
   Ko, Sung-Jea
TI High-dimensional feature extraction using bit-plane decomposition of
   local binary patterns for robust face recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Face recognition; Feature extraction; Local binary pattern;
   High-dimensional feature; Linear discriminant analysis; Bit-plane
   decomposition
ID SPARSE REPRESENTATION; PROJECTION
AB Transforming an original image into a high-dimensional (HD) feature has been proven to be effective in classifying images. This paper presents a novel feature extraction method utilizing the HD feature space to improve the discriminative ability for face recognition. We observed that the local binary pattern can be decomposed into bit-planes, each of which has scale-specific directional information of the face image. Each bit-plane not only has the inherent local-structure of the face image but also has an illumination robust characteristic. By concatenating all the decomposed bit-planes, we generate an HD feature vector with an improved discriminative ability. To reduce the computational complexity while preserving the incorporated local structural information, a supervised dimension reduction method, the orthogonal linear discriminant analysis, is applied to the HD feature vector. Extensive experimental results show that existing classifiers with the proposed feature outperform those with other conventional features under various illumination, pose, and expression variations. (C) 2017 Elsevier Inc. All rights reserved.
C1 [Yoo, Cheol-Hwan; Kim, Seung-Wook; Jung, June -Young; Ko, Sung-Jea] Korea Univ, Dept Elect Engn, Seoul, South Korea.
C3 Korea University
RP Ko, SJ (corresponding author), Korea Univ, Dept Elect Engn, Seoul, South Korea.
EM chyoo@dali.korea.ac.kr; swkim@dali.korea.ac.kr; jyjung@dali.korea.ac.kr;
   sjko@korea.ac.kr
FU Institute for Information & communications Technology Promotion (IITP)
   grant - Korea government (MSIP) [B0101-16-0525]
FX This work was supported by Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP)
   (No. B0101-16-0525, Development of global multi-target tracking and
   event prediction techniques based on real-time large-scale video
   analysis).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bereta M, 2013, J VIS COMMUN IMAGE R, V24, P1213, DOI 10.1016/j.jvcir.2013.08.004
   Cai D, 2007, IEEE DATA MINING, P427, DOI 10.1109/ICDM.2007.88
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Finlayson G., 2005, P IEEE INT C IM PROC
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Hong CQ, 2015, IEEE T IND ELECTRON, V62, P3742, DOI 10.1109/TIE.2014.2378735
   Hong CQ, 2013, NEUROCOMPUTING, V101, P94, DOI 10.1016/j.neucom.2012.09.001
   Lei L, 2014, IEEE T CONSUM ELECTR, V60, P702, DOI 10.1109/TCE.2014.7027346
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Ma CF, 2015, NEUROCOMPUTING, V149, P1232, DOI 10.1016/j.neucom.2014.09.004
   Martinez A., 1998, AR FACE DATABASE
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Seo HJ, 2010, IEEE T PATTERN ANAL, V32, P1688, DOI 10.1109/TPAMI.2009.153
   Seo J, 2014, NEUROCOMPUTING, V129, P41, DOI 10.1016/j.neucom.2012.09.048
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang CP, 2015, J VIS COMMUN IMAGE R, V26, P265, DOI 10.1016/j.jvcir.2014.09.013
   Wolf L, 2010, LECT NOTES COMPUT SC, V5995, P88
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang WK, 2016, NEUROCOMPUTING, V213, P183, DOI 10.1016/j.neucom.2015.11.134
   Ye JP, 2005, J MACH LEARN RES, V6, P483
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 33
TC 16
Z9 18
U1 0
U2 20
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD MAY
PY 2017
VL 45
BP 11
EP 19
DI 10.1016/j.jvcir.2017.02.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA EQ9TC
UT WOS:000398427100002
DA 2024-07-18
ER

PT J
AU Liao, B
   Yan, L
   Mo, W
   Shen, J
   Zhang, WY
AF Liao, Bin
   Yan, Lei
   Mo, Wei
   Shen, Jing
   Zhang, Wenyao
TI Coherence restricted StOMP and its application in image fusion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Sparse representation; Stagewise orthogonal matching pursuit; Image
   fusion; De-correlation
ID SPARSE; SIGNAL; TRANSFORM
AB This paper proposes an image fusion method based on an improved Stagewise OMP algorithm (ApStOMP), which is more efficient than StOMP in finding the sparest solution of large-scale under-determined problem. Multiple atoms can be selected at each stage, and only a fixed number of stages are required. Unlike StOMP, we restrict the mutual coherence of selected atoms to be as low as possible at each stage, and atoms with high coherence are excluded. In this way, we can obtain a more accurate estimated support set than with StOMP. The advantages of the proposed fusion method are demonstrated experimentally with different groups of pre-registered source images, for which we can carry out image denoising and fusion simultaneously. The experimental results show that the performance of the proposed method is competitive with other methods in terms of several objective fusion metrics, as well as in visual quality. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Liao, Bin; Yan, Lei; Mo, Wei; Shen, Jing] North China Elect Power Univ, Sch Elect & Elect Engn, 2 Beinong Rd, Beijing 100226, Peoples R China.
   [Zhang, Wenyao] Beijing Inst Technol, Sch Comp Sci, Beijing 100081, Peoples R China.
C3 North China Electric Power University; Beijing Institute of Technology
RP Liao, B (corresponding author), North China Elect Power Univ, Sch Elect & Elect Engn, 2 Beinong Rd, Beijing 100226, Peoples R China.
EM nathan@ncepu.edu.cn
RI Liao, Bin/J-5661-2015
FU Fundamental Research Funds for the Central Universities [NCEPU2014MS02];
   National Natural Science Foundation of China [11472049]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions. This work was supported by the
   Fundamental Research Funds for the Central Universities (No.
   NCEPU2014MS02) and was partly supported by the National Natural Science
   Foundation of China under contract 11472049.
CR Bai XZ, 2013, OPTIK, V124, P3198, DOI 10.1016/j.ijleo.2012.09.054
   Blumensath T, 2009, APPL COMPUT HARMON A, V27, P265, DOI 10.1016/j.acha.2009.04.002
   Blumensath T, 2008, J FOURIER ANAL APPL, V14, P629, DOI 10.1007/s00041-008-9035-z
   Chen ScottShaobing., 2001, SIAM Journal on Scientific Computing, V20, P33
   Cheng J, 2015, ISPRS J PHOTOGRAMM, V104, P158, DOI 10.1016/j.isprsjprs.2015.02.015
   Dai W, 2009, IEEE T INFORM THEORY, V55, P2230, DOI 10.1109/TIT.2009.2016006
   Dong GG, 2014, IEEE SIGNAL PROC LET, V21, P952, DOI 10.1109/LSP.2014.2321565
   Donoho DL, 2012, IEEE T INFORM THEORY, V58, P1094, DOI 10.1109/TIT.2011.2173241
   Donoho DL, 2001, IEEE T INFORM THEORY, V47, P2845, DOI 10.1109/18.959265
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Giuliani M, 2013, INT J SOC ROBOT, V5, P345, DOI 10.1007/s12369-013-0194-y
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   HongXia B., 2012, SCI CHINA F
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jionghua Teng, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1552, DOI 10.1109/CISP.2010.5646958
   Kumar M., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2437, DOI 10.1109/ICIP.2011.6116136
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li F., 2013, J CHINA U POSTS TELE, V20, P113
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T GEOSCI REMOTE, V51, P4779, DOI 10.1109/TGRS.2012.2230332
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li ST, 2012, IEEE T BIO-MED ENG, V59, P3450, DOI 10.1109/TBME.2012.2217493
   Li X, 2015, J AMB INTEL HUM COMP, V6, P141, DOI 10.1007/s12652-015-0255-1
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2001, PATTERN RECOGN LETT, V22, P929, DOI 10.1016/S0167-8655(01)00047-2
   Liu ZD, 2014, EXPERT SYST APPL, V41, P7425, DOI 10.1016/j.eswa.2014.05.043
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Park H, 2010, ACAD RADIOL, V17, P614, DOI 10.1016/j.acra.2010.01.003
   Petrovic V, 2005, IEEE I CONF COMP VIS, P1866
   Shah P., 2011, 2011 IEEE 10th IVMSP Workshop: Perception and Visual Signal Analysis, P54, DOI 10.1109/IVMSPW.2011.5970354
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1125, DOI 10.1007/s11760-012-0361-x
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Tropp JA, 2004, IEEE T INFORM THEORY, V50, P2231, DOI 10.1109/TIT.2004.834793
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Venkataraman A, 2014, MID EAST CONF BIO, P103, DOI 10.1109/MECBME.2014.6783216
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
NR 45
TC 5
Z9 5
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 559
EP 573
DI 10.1016/j.jvcir.2016.07.022
PN B
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600014
DA 2024-07-18
ER

PT J
AU Rein, S
   Reisslein, M
AF Rein, Stephan
   Reisslein, Martin
TI Scalable line-based wavelet image coding in wireless sensor networks
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Low-memory image coding; Sensor node; Scalable image compression;
   Wavelet image coding
ID LOW-COMPLEXITY; REDUCED MEMORY; SCHEME; CODEC; COMPRESSION; MULTIMEDIA;
   ALGORITHMS; TRANSFORM; DESIGN
AB Existing scalable wavelet image coding approaches, such as set partitioning in hierarchical trees and its derivatives, employ a memory-intensive tree-based coding structure. Existing tree-based wavelet coding approaches are therefore not suitable for memory-constrained sensor nodes. In this paper, we introduce a scalable wavelet image coding approach based on a line structure that requires very little memory. The proposed line-based approach is suitable for scalable wavelet image coding in memory-constrained sensor nodes, requiring only a few kilobytes of memory for a 256 x 256 pixel image. The presented line based wavelet coding algorithm accesses the image data line by line and thus conforms with the data access patterns in current flash memory technology. Our performance evaluations demonstrate that the proposed scalable line-based image wavelet coding approach has no overhead compared to one run (non-scalable) wavelet image coding and has competitive compression performance compared to JPEG 2000 and the recent Google WebP image format. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Rein, Stephan; Reisslein, Martin] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
C3 Arizona State University; Arizona State University-Tempe
RP Reisslein, M (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
EM rein@gmx.net; reisslein@asu.edu
RI Reisslein, Martin/B-3278-2014
OI Reisslein, Martin/0000-0003-1606-233X
CR Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   [Anonymous], INT J ADV RES COMPUT
   [Anonymous], 2004, JPEG2000 IMAGE COMPR
   Arora H, 2005, INT CONF ACOUST SPEE, P385
   Bao YL, 2001, IEEE T CIRC SYST VID, V11, P642, DOI 10.1109/76.920193
   Bhattar RK, 2002, SIGNAL PROCESS-IMAGE, V17, P441, DOI 10.1016/S0923-5965(02)00019-X
   Caulfield A. M., 2009, P 42 ANN IEEE ACM IN, P24
   Chen F, 2009, PERF E R SI, V37, P181
   Chew LW, 2008, IEEE SIGNAL PROC LET, V15, P389, DOI 10.1109/LSP.2008.920515
   Chia WC, 2012, INT J SENS NETW, V11, P22, DOI 10.1504/IJSNET.2012.045037
   Chrysafis C, 2000, IEEE T IMAGE PROCESS, V9, P378, DOI 10.1109/83.826776
   Costa DG, 2013, J SENS ACTUAT NETW, V2, P424, DOI 10.3390/jsan2030424
   Eslami M.H., 2008, P INT MULTICONFERENC, P1
   Guo JL, 2006, J COMPUT, V1, P1, DOI 10.4304/jcp.1.4.1-7
   Guo JL, 2006, 2006 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS, P442
   Guo JL, 2006, IEEE DATA COMPR CONF, P292
   Hu CK, 2004, SIGNAL PROCESS, V84, P1689, DOI 10.1016/j.sigpro.2004.05.014
   Hung CH, 2012, J VIS COMMUN IMAGE R, V23, P1128, DOI 10.1016/j.jvcir.2012.06.008
   Imran M., 2012, P SOC PHOTO-OPT INS, V8437
   Latte MV, 2006, DIGIT SIGNAL PROCESS, V16, P817, DOI 10.1016/j.dsp.2006.06.001
   Loomans MJH, 2011, IEEE T CONSUM ELECTR, V57, P507, DOI 10.1109/TCE.2011.5955186
   Granado OML, 2012, J SIGNAL PROCESS SYS, V68, P203, DOI 10.1007/s11265-011-0598-6
   Lopez O., 2007, P SPIE ELECT IMAGING
   Lu Q, 2008, COMPUT NETW, V52, P2594, DOI 10.1016/j.comnet.2008.05.006
   Ma T, 2013, IEEE COMMUN SURV TUT, V15, P963, DOI 10.1109/SURV.2012.060912.00149
   Ma T, 2011, IEEE IMAGE PROC, P297, DOI 10.1109/ICIP.2011.6116287
   Mammeri Abdelhamid, 2012, ISRN Sensor Networks, DOI 10.5402/2012/760320
   Margi C.B., 2006, Proc. Int. Conf. on Testbeds Research Infrastr. for the DEvelopm. of NeTworks COMmunities (TRIDENTCOM), P1
   Margi CB, 2005, 2005 INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS, COMMUNICATIONS AND MOBILE COMPUTING, VOLS 1 AND 2, P1142
   Mathur G, 2009, ACM T SENSOR NETWORK, V5, DOI 10.1145/1614379.1614385
   Oliver J, 2008, IEEE T CIRC SYST VID, V18, P237, DOI 10.1109/TCSVT.2007.913962
   Phat NH, 2010, IEICE T COMMUN, VE93B, P3438, DOI 10.1587/transcom.E93.B.3438
   Ratnakar V, 1999, INT CONF ACOUST SPEE, P3133, DOI 10.1109/ICASSP.1999.757505
   Rein Stephan, 2009, 2009 Data Compression Conference. DCC 2009, P252, DOI 10.1109/DCC.2009.30
   Rein S, 2011, AD HOC NETW, V9, P482, DOI 10.1016/j.adhoc.2010.08.004
   Rein S, 2011, IEEE COMMUN SURV TUT, V13, P291, DOI 10.1109/SURV.2011.100110.00059
   Rein SA, 2015, SIGNAL PROCESS-IMAGE, V37, P58, DOI 10.1016/j.image.2015.07.010
   Reinhard S.C., 2008, Patient Safety and Quality: An Evidence-Based Handbook for Nurses, P341
   Rinner B, 2009, MULTI-CAMERA NETWORKS: PRINCIPLES AND APPLICATIONS, P483, DOI 10.1016/B978-0-12-374633-7.00020-3
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Sakalli M, 2006, 2006 40TH ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS, VOLS 1-4, P1158, DOI 10.1109/CISS.2006.286640
   Seema A, 2011, IEEE COMMUN SURV TUT, V13, P462, DOI 10.1109/SURV.2011.102910.00098
   Shnayder V., 2004, Proceedings of the 2nd international conference on Embedded Networked Sensor Systems SenSys04, P188, DOI DOI 10.1145/1031495.1031518
   Song B, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940441
   Su CY, 2003, IEEE T IMAGE PROCESS, V12, P271, DOI 10.1109/TIP.2002.807359
   Tausif M, 2015, IEEE SENS J, V15, P6218, DOI 10.1109/JSEN.2015.2456332
   Tavli B, 2012, MULTIMED TOOLS APPL, V60, P689, DOI 10.1007/s11042-011-0840-z
   Yang CH, 2007, IEICE T FUND ELECTR, VE90A, P1062, DOI 10.1093/ietfec/e90-a.5.1062
   Ye LN, 2007, IEEE DATA COMPR CONF, P213
   Ye LN, 2011, OPT ENG, V50, DOI 10.1117/1.3541802
   Zhang XM, 2009, SIGNAL PROCESS-IMAGE, V24, P384, DOI 10.1016/j.image.2009.01.001
NR 51
TC 7
Z9 11
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 418
EP 431
DI 10.1016/j.jvcir.2016.07.006
PN B
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600003
DA 2024-07-18
ER

PT J
AU Tang, LM
   Fang, Z
   Xiang, CC
   Chen, SQ
AF Tang, Liming
   Fang, Zhuang
   Xiang, Changcheng
   Chen, Shiqiang
TI Image selective restoration using multi-scale variational decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Total variation; Variational decomposition; Image restoration; Scale
ID TOTAL VARIATION MINIMIZATION; NOISE REMOVAL; ALGORITHM; REGULARIZATION;
   RECOVERY; MODEL
AB In this paper we propose a multi-scale variational decomposition model for image selective restoration. Firstly, we introduce a single-parameter (BV, G, L-2) variational decomposition functional and theoretically analyze the relationship between the parameter and the scale of image features. And then, by replacing the fixed scale parameter with a varying sequence in the single-parameter decomposition functional, we obtain the multi-scale variational decomposition which can decompose the input image into a series of image slices of different scales. Furthermore, we show some properties and prove the convergence of the multi-scale decomposition. Finally, we introduce an alternating and iterative method based on Chambolle's projection algorithm to numerically solve the multi-scale variational decomposition model. Experiments are conducted on both synthetic and real images to demonstrate the effectiveness of the proposed multi-scale variational decomposition. In addition, we use the multi-scale variational decomposition to achieve image selective restoration, and compare it with several state-of-the-art models in denoising application. The numerical results show that our model has better performance in terms of PSNR and SSIM indexes. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Tang, Liming; Fang, Zhuang; Xiang, Changcheng; Chen, Shiqiang] Hubei Univ Nationalities, Sch Sci, Enshi 445000, Peoples R China.
C3 Hubei Minzu University
RP Tang, LM (corresponding author), Hubei Univ Nationalities, Sch Sci, Enshi 445000, Peoples R China.
EM tlmcs78@foxmail.com
RI , changcheng/HSE-9682-2023; Tang, Liming/AAE-6606-2022
OI Tang, Liming/0000-0001-9140-4745
FU Natural Science Foundation of China [61561019]; Natural Science
   Foundation of Hubei Province [2015CFB262]; Doctoral Scientific Fund
   Project of Hubei University for Nationalities [MY2015B001]
FX This work was supported in part by the Natural Science Foundation of
   China under Grant No. 61561019, Natural Science Foundation of Hubei
   Province under Grant No. 2015CFB262, and the Doctoral Scientific Fund
   Project of Hubei University for Nationalities under Grant No.
   MY2015B001. The authors would like to thank the anonymous reviewers for
   their constructive comments.
CR Aubert G, 2005, APPL MATH OPT, V51, P163, DOI 10.1007/s00245-004-0812-z
   Aubert G., 2006, MATH PROBLEMS IMAGE
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Aujol JF, 2005, INT J COMPUT VISION, V63, P85, DOI 10.1007/s11263-005-4948-3
   Aujol JF, 2003, LECT NOTES COMPUT SC, V2695, P297
   Aujol JF, 2005, J MATH IMAGING VIS, V22, P71, DOI 10.1007/s10851-005-4783-8
   Barbu T, 2009, NONLINEAR ANAL-REAL, V10, P1351, DOI 10.1016/j.nonrwa.2008.01.017
   Bergounioux M, 2013, COMPUT OPTIM APPL, V54, P215, DOI 10.1007/s10589-012-9484-9
   Bildhauer M., 2015, J MATH SCI, V205, P121, DOI 10.1007/s10958-015-2237-4
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Brito-Loeza C, 2010, SIAM J IMAGING SCI, V3, P363, DOI 10.1137/080737903
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chen DQ, 2012, J SCI COMPUT, V51, P505, DOI 10.1007/s10915-011-9519-x
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P700, DOI 10.1109/TIP.2012.2221729
   Gopi V.P., 2013, COMPUT MATH METHOD M, V2013, P343
   Han Y, 2013, PATTERN RECOGN, V46, P989, DOI 10.1016/j.patcog.2012.10.010
   Jun Z, 2011, APPL MATH MODEL, V35, P2516, DOI 10.1016/j.apm.2010.11.049
   Jung M, 2015, J SCI COMPUT, V62, P336, DOI 10.1007/s10915-014-9860-y
   Kindermann S, 2005, MULTISCALE MODEL SIM, V4, P1091, DOI 10.1137/050622249
   Litvinov WG, 2011, SIAM J SCI COMPUT, V33, P1574, DOI 10.1137/080727506
   Lou YF, 2010, J SCI COMPUT, V42, P185, DOI 10.1007/s10915-009-9320-2
   Lv XG, 2015, J COMPUT APPL MATH, V290, P553, DOI 10.1016/j.cam.2015.06.006
   MEYER Y, 2001, U LECT SER, V22
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nikolova M, 2013, SIAM J SCI COMPUT, V35, pA397, DOI 10.1137/10080172X
   Oh S, 2013, J VIS COMMUN IMAGE R, V24, P332, DOI 10.1016/j.jvcir.2013.01.010
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   Rahman T, 2007, LECT NOTES COMPUT SC, V4485, P473
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shao WZ, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.6.067008
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   Tadmor E, 2004, MULTISCALE MODEL SIM, V2, P554, DOI 10.1137/030600448
   Tadmor E, 2008, COMMUN MATH SCI, V6, P281
   Tang LM, 2013, J MATH IMAGING VIS, V45, P148, DOI 10.1007/s10851-012-0351-1
   Vese LA, 2003, J SCI COMPUT, V19, P553, DOI 10.1023/A:1025384832106
   Vese LA, 2004, J MATH IMAGING VIS, V20, P7, DOI 10.1023/B:JMIV.0000011316.54027.6a
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Zhang HY, 2014, IEEE T GEOSCI REMOTE, V52, P4729, DOI 10.1109/TGRS.2013.2284280
   Zhang JP, 2015, J COMPUT PHYS, V293, P442, DOI 10.1016/j.jcp.2015.02.021
   Zhang J, 2012, J MATH IMAGING VIS, V43, P39, DOI 10.1007/s10851-011-0285-z
NR 40
TC 6
Z9 6
U1 2
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2016
VL 40
BP 638
EP 655
DI 10.1016/j.jvcir.2016.08.004
PN B
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DX5CY
UT WOS:000384398600020
DA 2024-07-18
ER

PT J
AU Shaaban, KM
   Omar, NM
AF Shaaban, Khaled M.
   Omar, Nagwa M.
TI Depth extraction of partially occluded objects using deformable net
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Monocular vision navigation; Depth extraction; Partially occluded
   objects; Deformable net; Video segmentation
ID BELIEF PROPAGATION; STEREO; MAPS
AB Estimating depth using a single camera moving along its optical axis has great benefits to autonomous robot navigation. In Shaaban and Omar (2012) we estimated depth information for non-occluded regions using the change of their seen area. The proposed work extends this technique to handle regions with partial occlusion. As the robot moves, the seen area of a partially occluded region is different from the two points of view. Therefore, at least one of the edges is deceptive and is not a real object boundary. We propose a technique to detect deceptive-edges at the boundary of occlusion then use triangulation to detect the structure of occlusion. With this knowledge, we estimate the percentage change in the actual area seen as the camera moves. This percentage is used to correct the results of the original Area-based method. Experimentally the algorithm provides an average depth with good accuracy for both far and near objects. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Shaaban, Khaled M.] Assiut Univ, Fac Engn, Dept Elect Engn, Assiut, Egypt.
   [Omar, Nagwa M.] Assiut Univ, Fac Comp & Informat, Dept Informat Technol, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Assiut University; Egyptian Knowledge
   Bank (EKB); Assiut University
RP Shaaban, KM (corresponding author), Assiut Univ, Fac Engn, Dept Elect Engn, Assiut, Egypt.
EM k_shaaban@hotmail.com
OI Omar, Nagwa/0000-0002-7089-2740
CR Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Criminisi A, 2007, INT J COMPUT VISION, V71, P89, DOI 10.1007/s11263-006-8525-1
   Gargallo P, 2005, PROC CVPR IEEE, P885
   Gupta RK, 2013, IET COMPUT VIS, V7, P123, DOI 10.1049/iet-cvi.2011.0077
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hoiem D, 2011, INT J COMPUT VISION, V91, P328, DOI 10.1007/s11263-010-0400-4
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Huq S, 2013, COMPUT VIS IMAGE UND, V117, P688, DOI 10.1016/j.cviu.2013.01.008
   Kang SB, 2004, INT J COMPUT VISION, V58, P139, DOI 10.1023/B:VISI.0000015917.35451.df
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Klaus A, 2006, INT C PATT RECOG, P15
   Larsen ES, 2007, IEEE I CONF COMP VIS, P1440
   Liao M, 2012, IEEE T VIS COMPUT GR, V18, P1079, DOI 10.1109/TVCG.2011.114
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Min D, 2008, IEEE T IMAGE PROCESS, V17, P1431, DOI 10.1109/TIP.2008.925372
   Oh JD, 2010, J VIS COMMUN IMAGE R, V21, P404, DOI 10.1016/j.jvcir.2010.03.003
   Raza S., 2014, BMVC
   Saxena AK, 2005, ARKIVOC, P1, DOI 10.3998/ark.5550190.0006.201
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shaaban KM, 2012, J VIS COMMUN IMAGE R, V23, P397, DOI 10.1016/j.jvcir.2011.12.001
   Shaaban KM, 2009, IMAGE VISION COMPUT, V27, P1504, DOI 10.1016/j.imavis.2009.02.003
   Stein AN, 2009, INT J COMPUT VISION, V82, P325, DOI 10.1007/s11263-008-0203-z
   Sun J, 2005, PROC CVPR IEEE, P399
   Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364
   Wang OL, 2011, PITUITARY, 3RD EDITION, P47, DOI 10.1016/B978-0-12-380926-1.10003-3
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Zhang GF, 2009, IEEE T PATTERN ANAL, V31, P974, DOI 10.1109/TPAMI.2009.52
   Zhang ZB, 2013, IEEE T CIRC SYST VID, V23, P1795, DOI 10.1109/TCSVT.2013.2269023
   Zhang ZB, 2011, IEEE IMAGE PROC, P909, DOI 10.1109/ICIP.2011.6116707
   Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
NR 33
TC 0
Z9 0
U1 0
U2 7
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 1
EP 11
DI 10.1016/j.jvcir.2016.05.004
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900001
DA 2024-07-18
ER

PT J
AU Zhu, SQ
   Wang, Z
   Zhang, XQ
   Li, YH
AF Zhu, Shiqiang
   Wang, Zhi
   Zhang, Xuequn
   Li, Yuehua
TI Edge-preserving guided filtering based cost aggregation for stereo
   matching
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Stereo matching; Adaptive support window; Cost aggregation; Guided
   filter
ID WINDOW
AB Stereo matching has been widely used in various computer applications and it is still a challenging problem. In stereo matching, the filter-based stereo matching methods have achieved outstanding performance. A local stereo matching method based on adaptive edge-preserving guided filter is presented in this paper, which can achieve proper cost-volume filtering and keep edges well. We introduce a gradient vector of the enhanced image generated by the proposed filter into the cost computation and the Census transform is adopted in the cost measurement. This cost computation method is robust against radiometric variations and textureless areas. The edge-preserving guided filter approach is proposed to aggregate the cost volume, which further proves the effectiveness of edge-preserving filter for stereo matching. The experiments conducted on Middlebury benchmark and KITTI benchmark demonstrate that the proposed algorithm produces better results compared with other edge-aware filter based methods. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Zhu, Shiqiang; Wang, Zhi; Zhang, Xuequn; Li, Yuehua] Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Wang, Z (corresponding author), Zhejiang Univ, State Key Lab Fluid Power & Mechatron Syst, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM 11325067@zju.edu.cn
RI li, yueyue/IVH-9846-2023; li, yue/HSF-7296-2023; li, yue/IXD-9935-2023;
   LI, Yue/GRS-8071-2022
FU Hangzhou Civic Significant Technological Innovation Project of China
   [20131110A04, 20142013A56]
FX The authors would like to thank the Hangzhou Civic Significant
   Technological Innovation Project of China (No: 20131110A04), Hangzhou
   Civic Significant Technological Innovation Project of China (No:
   20142013A56) for supporting this work.
CR [Anonymous], 2013, P INT C SCAL SPAC VA, DOI DOI 10.1007/978-3-642-38267-3_24
   Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245
   Chen DM, 2015, IEEE T CIRC SYST VID, V25, P730, DOI 10.1109/TCSVT.2014.2361422
   Chen ZY, 2015, IEEE I CONF COMP VIS, P972, DOI 10.1109/ICCV.2015.117
   GEIGER A, 2011, REVISED SELECTED P 1, P25
   Gurrieri LE, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.1.011004
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2009, IEEE T PATTERN ANAL, V31, P1582, DOI 10.1109/TPAMI.2008.221
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Klaus A, 2006, INT C PATT RECOG, P15
   Lee S, 2015, IMAGE VISION COMPUT, V37, P1, DOI 10.1016/j.imavis.2015.01.003
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Tombari F., 2008, Computer Vision and Pattern Recognition, P1
   Veksler O, 2003, PROC CVPR IEEE, P556
   Nguyen VD, 2014, IEEE T CIRC SYST VID, V24, P2049, DOI 10.1109/TCSVT.2014.2334053
   Wang Q., 2014, J ELECTRON IMAGING, V23
   Wang Wenchao, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1, DOI 10.1109/ICSAI.2012.6223033
   Wei Zeng, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563053
   Xu YF, 2014, APPL OPTICS, V53, P6885, DOI 10.1364/AO.53.006885
   Yamaguchi K, 2014, LECT NOTES COMPUT SC, V8693, P756, DOI 10.1007/978-3-319-10602-1_49
   Yamaguchi K, 2012, LECT NOTES COMPUT SC, V7576, P45, DOI 10.1007/978-3-642-33715-4_4
   Yang Q., 2006, IEEE COMPUTER SOC C, P2347
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P834, DOI 10.1109/TPAMI.2014.2353642
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang CY, 2013, SIGNAL PROCESS-IMAGE, V28, P1171, DOI 10.1016/j.image.2013.07.004
   Zhang K, 2014, PROC CVPR IEEE, P1590, DOI 10.1109/CVPR.2014.206
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhang SY, 2015, 2015 IEEE WORKSHOP ON ENVIRONMENTAL, ENERGY AND STRUCTURAL MONITORING SYSTEMS (EESMS), P1, DOI [10.1109/INTMAG.2015.7156970, 10.1109/EESMS.2015.7175842]
   Zhu S, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.4.043016
NR 39
TC 23
Z9 28
U1 1
U2 52
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2016
VL 39
BP 107
EP 119
DI 10.1016/j.jvcir.2016.05.012
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DQ8HN
UT WOS:000379450900011
DA 2024-07-18
ER

PT J
AU Huang, C
   Han, TX
   He, ZH
   Cao, WM
AF Huang, Chen
   Han, Tony X.
   He, Zhihai
   Cao, Wenming
TI Constellational contour parsing for deformable object detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Object detection; Shape matching; Optimization; Additive similarity
   measure; Dynamic programming; Constellational contour parsing
ID RECOGNITION; DESCRIPTOR
AB In this paper we propose a novel framework for contour-based object detection from cluttered environments. Given a contour model for a class of object, it is first decomposed into fragments, then in the test image we simultaneously perform selection of relevant contour fragments in edge images, grouping of the selected contour fragments, and finding best geometry-preserving matching to model contours. Finding the best matching is inherently a computationally expensive problem. To address this challenge, we developed local shape descriptors and an additive similarity metric function which can be computed locally while preserving the capability of matching deformable shapes globally. This allows us to establish a constellational shape parsing framework using low-complexity dynamic programming to find optimal configuration of contour segments in test images to match the model contour. To effectively detect objects with large deformation, we augmented the metric function with a local motion search, modeled the relationship between different shape parts using multiple concurrent dynamic programming shape parsers. Our experimental results show that the proposed method outperforms the state-of-the-art contour-based object detection algorithms on two benchmark datasets in terms of average precision. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Huang, Chen; Han, Tony X.; He, Zhihai] Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
   [Cao, Wenming] Shenzhen Univ, Dept Comp Sci, Shenzhen 518060, Guangdong, Peoples R China.
C3 University of Missouri System; University of Missouri Columbia; Shenzhen
   University
RP Cao, WM (corresponding author), Shenzhen Univ, Dept Comp Sci, Shenzhen 518060, Guangdong, Peoples R China.
EM chenhuang@mail.missouri.edu; hantx@missouri.edu; HeZhi@missouri.edu;
   wmcao@szu.edu.cn
RI Huang, Chen/AAY-4934-2020; He, Zhihai/A-5885-2019
CR [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI 10.1109/CVPR.2007.383018
   [Anonymous], P 2004 IEEE COMP SOC
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ICCV 13
   Bagon S, 2010, PROC CVPR IEEE, P33, DOI 10.1109/CVPR.2010.5540233
   Bai XA, 2009, PROC CVPR IEEE, P1335, DOI 10.1109/CVPRW.2009.5206543
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damski JC, 1996, COMPUT AIDED DESIGN, V28, P169, DOI 10.1016/0010-4485(95)00024-0
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2011, IEEE T PATTERN ANAL, V33, P721, DOI 10.1109/TPAMI.2010.135
   Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   FLYNN PJ, 1989, 1989 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, VOLS 1-3, P162, DOI 10.1109/ICSMC.1989.71272
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Huang C, 2014, J VIS COMMUN IMAGE R, V25, P1640, DOI 10.1016/j.jvcir.2014.08.005
   Kovesi P.D., 2000, MATLAB and Octave Functions for Computer Vision and Image Processing
   LEYTON M, 1988, ARTIF INTELL, V34, P213, DOI 10.1016/0004-3702(88)90039-2
   Liu MZ, 2012, IEEE T PATTERN ANAL, V34, P2407, DOI 10.1109/TPAMI.2012.44
   Lu CE, 2009, IEEE I CONF COMP VIS, P2288, DOI 10.1109/ICCV.2009.5459446
   Ma TY, 2011, PROC CVPR IEEE, P1441, DOI 10.1109/CVPR.2011.5995591
   Maji S, 2009, PROC CVPR IEEE, P1038, DOI 10.1109/CVPRW.2009.5206693
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Ommer B, 2009, IEEE I CONF COMP VIS, P484, DOI 10.1109/ICCV.2009.5459200
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Ravishankar S, 2008, LECT NOTES COMPUT SC, V5302, P483, DOI 10.1007/978-3-540-88682-2_37
   Riemenschneider H, 2010, LECT NOTES COMPUT SC, V6315, P29, DOI 10.1007/978-3-642-15555-0_3
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   SHECHTMAN E., 2007, IEEE C COMPUTER VISI
   Shotton J, 2005, IEEE I CONF COMP VIS, P503
   Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8
   Srinivasan P, 2010, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2010.5539834
   Toshev A, 2012, INT J COMPUT VISION, V99, P123, DOI 10.1007/s11263-012-0521-z
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang XG, 2012, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.2012.6247670
   Yarlagadda P, 2010, LECT NOTES COMPUT SC, V6315, P197, DOI 10.1007/978-3-642-15555-0_15
   Zhu QH, 2008, LECT NOTES COMPUT SC, V5303, P774
NR 43
TC 3
Z9 3
U1 0
U2 13
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 540
EP 549
DI 10.1016/j.jvcir.2016.03.028
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100046
DA 2024-07-18
ER

PT J
AU Li, LD
   Xia, WH
   Fang, YM
   Gu, K
   Wu, JJ
   Lin, WS
   Qian, JS
AF Li, Leida
   Xia, Wenhan
   Fang, Yuming
   Gu, Ke
   Wu, Jinjian
   Lin, Weisi
   Qian, Jiansheng
TI Color image quality assessment based on sparse representation and
   reconstruction residual
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image quality assessment; Color distortion; Sparse representation;
   Reconstruction residual
ID STRUCTURAL SIMILARITY; INFORMATION
AB Image quality assessment (IQA) is a fundamental problem in image processing. While in practice almost all images are represented in the color format, most of the current IQA metrics are designed in gray-scale domain. Color influences the perception of image quality, especially in the case where images are subject to color distortions. With this consideration, this paper presents a novel color image quality index based on Sparse Representation and Reconstruction Residual (SRRR). An overcomplete color dictionary is first trained using natural color images. Then both reference and distorted images are represented using the color dictionary, based on which two feature maps are constructed to measure structure and color distortions in a holistic manner. With the consideration that the feature maps are insensitive to image contrast change, the reconstruction residuals are computed and used as a complementary feature. Additionally, luminance similarity is also incorporated to produce the overall quality score for color images. Experiments on public databases demonstrate that the proposed method achieves promising performance in evaluating traditional distortions, and it outperforms the existing metrics when used for quality evaluation of color-distorted images. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Li, Leida; Xia, Wenhan; Qian, Jiansheng] China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Peoples R China.
   [Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Peoples R China.
   [Gu, Ke; Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Wu, Jinjian] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
C3 China University of Mining & Technology; Jiangxi University of Finance &
   Economics; Nanyang Technological University; Xidian University
RP Qian, JS (corresponding author), China Univ Min & Technol, Sch Informat & Elect Engn, Xuzhou 221116, Peoples R China.
EM iqaqian@gmail.com
RI Li, Li/AEM-3636-2022; Gu, Ke/AAJ-9684-2021; li, li/HII-4157-2022; Wu,
   Jinjian/GQH-0222-2022; Lin, Weisi/A-8011-2012; Lin, Weisi/A-3696-2011
OI Lin, Weisi/0000-0001-9866-1947
FU Fundamental Research Funds for the Central Universities [2015XKMS032]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities (2015XKMS032).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2013, International Scholarly Research Notices., DOI DOI 10.1155/2013/905685
   Chang HW, 2013, IEEE T IMAGE PROCESS, V22, P4007, DOI 10.1109/TIP.2013.2266579
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Kolaman A, 2012, IEEE T IMAGE PROCESS, V21, P1526, DOI 10.1109/TIP.2011.2181522
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Li LD, 2015, J VIS COMMUN IMAGE R, V30, P153, DOI 10.1016/j.jvcir.2015.04.001
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu AM, 2012, IEEE T IMAGE PROCESS, V21, P1500, DOI 10.1109/TIP.2011.2175935
   Ma L, 2013, CHINA COMMUN, V10, P62, DOI 10.1109/CC.2013.6520939
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Ponomarenko Nikolay, 2013, 2013 4th European Workshop on Visual Information Processing (EUVIP), P106
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Rehman A, 2012, IEEE T IMAGE PROCESS, V21, P3378, DOI 10.1109/TIP.2012.2197011
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Tang CW, 2014, J VIS COMMUN IMAGE R, V25, P1746, DOI 10.1016/j.jvcir.2014.06.007
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu JJ, 2013, IEEE T MULTIMEDIA, V15, P1700, DOI 10.1109/TMM.2013.2266093
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang X, 2015, IEEE SYS MAN CYBERN, P1561, DOI 10.1109/SMC.2015.276
NR 35
TC 20
Z9 23
U1 0
U2 33
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 550
EP 560
DI 10.1016/j.jvcir.2016.04.006
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100047
DA 2024-07-18
ER

PT J
AU Wu, H
   Li, YL
   Miao, ZJ
   Wang, YQ
   Zhu, RS
   Bie, RF
   Wang, Y
AF Wu, Hao
   Li, Yueli
   Miao, Zhenjiang
   Wang, Yuqi
   Zhu, Runsheng
   Bie, Rongfang
   Wang, Yi
TI Creative and high-quality image composition based on a new criterion
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Image composition; Wavelet pyramid; Multi-scale composition; Semantic
   matching; Image entropy; Joint probability; SIFT; GIST
AB Image compositing techniques are primarily utilized to achieve realistic composite results. Some existing image compositing methods, such as gradient domain and alpha matting, are widely used in the field of computer vision, and can typically achieve realistic results, especially for seamless boundaries. However, when the candidate composite images and the target images have obvious differences, such as color, texture and brightness, the composite results are unrealistic and inconsistent. At the same time, traditional compositing methods focus on basic feature matching, ignoring semantic rationality in composition processing. Quite a few compositing methods thus generate composite results without semantic rationality.
   In this paper, a new multi-scale image composition method has been presented. In the composition process, wavelet pyramid and basic feature handling were used to achieve multi-scale compositions. More importantly, a new criterion was established, based on the semantic rationality. of images, which could ensure that the composite images are semantically valid. A large database was created to facilitate experimentation. The experiments showed that the methodology introduced in this paper produced superior results compared to traditional composition methods; the composite results were not only consistent and seamless, but were also semantically valid. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wu, Hao; Bie, Rongfang] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
   [Wu, Hao] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
   [Li, Yueli] Agr Univ Hebei, Coll Informat Sci & Technol, Baoding, Peoples R China.
   [Wu, Hao; Miao, Zhenjiang; Wang, Yuqi; Zhu, Runsheng; Bie, Rongfang; Wang, Yi] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Wang, Yi] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Beijing Normal University; United States Department of Energy (DOE);
   Lawrence Berkeley National Laboratory; Hebei Agricultural University;
   Beijing Jiaotong University; Carnegie Mellon University
RP Bie, RF (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.; Bie, RF (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
EM rongfangbie@163.com
FU National Natural Science Foundation of China [61371185, 61401029,
   61571049]; Fundamental Research Funds for the Central Universities
   [2014KJJCB32, 2013NT57, 2012LYB46]; SRF for ROCS, SEM; NSFC [61273274,
   61370127, 61201158]; FRFCU [2014JBZ004, Z131110001913143];  [15ZR003]; 
   [NSFB4123104]
FX This research is sponsored by National Natural Science Foundation of
   China (Nos. 61371185, 61401029, 61571049), the Fundamental Research
   Funds for the Central Universities (Nos. 2014KJJCB32, 2013NT57,
   2012LYB46), Research Funds (15ZR003) and by SRF for ROCS, SEM, NSFC
   61273274, 61370127 and 61201158, NSFB4123104, FRFCU 2014JBZ004,
   Z131110001913143. Especially thanks to Research "Small Instance Model
   For Massive Image Retrieval" and "Completion Material Optimized
   Retrieval Based Image Completion".
CR Adrian Ulges, 2008, P 2008 INT C CONT BA
   Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], 2001, Schooling for Tomorrow
   [Anonymous], 2011, IMAGE CLASSIFICATION
   [Anonymous], 2005, Computational Aesthetics in Graphics, Visualization and Imaging, DOI [DOI 10.2312/COMPAESTH/COMPAESTH05/111-122, 10.2312/COMPAESTH/COMPAESTH05/111-122]
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Boyle, 2014, CENGAGE LEARNING
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen J, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618492
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239502, 10.1145/1276377.1276441]
   Georgiev T., 2004, Workshop on Applications of Computer Vision (ECCV 2004), P1, DOI DOI 10.1145/1050330.1050437
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Heeger DJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC648
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lalonde JF, 2007, IEEE I CONF COMP VIS, P2181
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Li YZ, 2005, ACM T GRAPHIC, V24, P836, DOI 10.1145/1073204.1073271
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Maji S, 2009, IEEE I CONF COMP VIS, P40, DOI 10.1109/ICCV.2009.5459203
   Morovic J, 2003, PATTERN RECOGN LETT, V24, P1725, DOI 10.1016/S0167-8655(02)00328-8
   Olshausen BA, 2001, ADV NEUR IN, V13, P887
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pitié F, 2005, IEEE I CONF COMP VIS, P1434
   Porter Thomas, 1984, ACM SIGGRAPH COMPUTE, V18
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Siddiquie B, 2010, PROC CVPR IEEE, P2979, DOI 10.1109/CVPR.2010.5540044
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wang J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239460
   Wu H, 2015, NEUROCOMPUTING, V159, P157, DOI 10.1016/j.neucom.2014.12.088
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yedidia JS, 2005, IEEE T INFORM THEORY, V51, P2282, DOI 10.1109/TIT.2005.850085
   Zeev Farbman, 2008, ACM T GRAPHIC, V27
   Zha ZJ, 2008, PROC CVPR IEEE, P333
   Zhang YM, 2009, PROC CVPR IEEE, P1762, DOI 10.1109/CVPRW.2009.5206791
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
NR 41
TC 15
Z9 15
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 100
EP 114
DI 10.1016/j.jvcir.2016.02.011
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100010
DA 2024-07-18
ER

PT J
AU Wu, H
   Li, YL
   Miao, ZJ
   Wang, YQ
   Zhu, RS
   Bie, RF
   Lie, R
AF Wu, Hao
   Li, Yueli
   Miao, Zhenjiang
   Wang, Yuqi
   Zhu, Runsheng
   Bie, Rongfang
   Lie, Rui
TI A new sampling algorithm for high-quality image matting
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Random sampling; Cost function; WLS filter; Multi-decompositions; SAD;
   MSE
AB Image matting is the extraction of the foreground from an image through the use of provided information. It has been an important technique in the image and video editing field. Current image matting methods estimate the foreground and background, based on information provided regarding the nearby pixels. Color sampling has been an effective means for matting directly, and quite a few methods have achieved high quality matting results based on color sampling. However, there are some drawbacks; for example it is easy to overlook important candidate pixels for matting, and even if the candidate pixels are effectively selected, similar foregrounds and backgrounds will reduce the accuracy of the matting.
   In this paper's work, a Weighted-Least Squares (WLS) filter was utilized to sharpen the boundaries between the foregrounds and backgrounds, which facilitated the matting process; and an innovative sampling criterion based on random searching for the matting was then presented. This innovative method could effectively prevent valid samples being overlooked, and could manage the relationships of the nearby and distant pixels. In this process, a new cost function was utilized to evaluate the candidate samples. Experiments utilizing an image database demonstrated that this method significantly improved the matting results. (C) 2016 Elsevier Inc. All rights reserved.
C1 [Wu, Hao; Bie, Rongfang] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
   [Wu, Hao] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
   [Li, Yueli] Agr Univ Hebei, Coll Informat Sci & Technol, Wuhan, Peoples R China.
   [Wu, Hao; Miao, Zhenjiang; Wang, Yuqi; Zhu, Runsheng; Bie, Rongfang] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Beijing, Peoples R China.
   [Lie, Rui] Beijing Jiaotong Univ, Sch Civil Engn, Beijing, Peoples R China.
C3 Beijing Normal University; United States Department of Energy (DOE);
   Lawrence Berkeley National Laboratory; Hebei Agricultural University;
   Beijing Jiaotong University; Beijing Jiaotong University
RP Bie, RF (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
EM rongfangbie@163.com
FU National Natural Science Foundation of China [61371185, 61401029,
   61571049]; Fundamental Research Funds for the Central Universities
   [2014KJJCB32, 2013NT57, 2012LYB46]; SRF for ROCS, SEM [NSFC 61273274,
   61370127, 61201158, NSFB4123104, FRFCU 2014JBZ004, Z131110001913143]; 
   [15ZR003]
FX This research is sponsored by National Natural Science Foundation of
   China (Nos. 61371185, 61401029, 61571049), the Fundamental Research
   Funds for the Central Universities (Nos. 2014KJJCB32, 2013NT57,
   2012LYB46), Research Funds (15ZR003) and by SRF for ROCS, SEM, NSFC
   61273274, 61370127 and 61201158, NSFB4123104, FRFCU 2014JBZ004,
   Z131110001913143.
CR [Anonymous], ACM T GRAPHICS TOG
   BERMAN A, 2000, Patent No. 6134346
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen Qifeng, 2012, COMP VIS PATT REC CV
   Cheng Jun, 2013, PATT REC ACPR 2013 2
   Chuang Yung-Yu, 2001, COMP VIS PATT REC 20, V2
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gastal Eduardo S.L., 2010, COMPUTER GRAPHICS FO, V292
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   He Kaiming, 2011, COMP VIS PATT REC CV
   LAGENDIJK RL, 1988, IEEE T ACOUST SPEECH, V36, P1874, DOI 10.1109/29.9032
   Leo Grady, 2005, P VIIP, V2005
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li Xiangang., 2015, Neurocomputing
   Mishima Y., 1994, US Patent, Patent No. [5,355,174, 5355174]
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rhemann Christoph, 2008, COMP VIS PATT REC 20
   Ruzon Mark, 2000, COMP VIS PATT REC 20, V1
   SUN J, 2004, ACM T GRAPHICS TOG, V23
   Tomasi C., 1998, P ICCV
   Varnousfaderani ES, 2013, IEEE T IMAGE PROCESS, V22, P4260, DOI 10.1109/TIP.2013.2271549
   WANG J, 2008, IMAGE VIDEO MATTING
   Wang J., 2005, COMP VIS 2005 ICCV 2, V2
   Wang Jue, 2007, COMP VIS PATT REC 20
   Wu H. - m., 2015, MULTIMED TOOLS APPL, P1
   Wu H, 2015, NEUROCOMPUTING, V159, P157, DOI 10.1016/j.neucom.2014.12.088
   Zhang YX, 2014, NEUROCOMPUTING, V140, P299, DOI 10.1016/j.neucom.2014.03.008
   Zheng Yuanjie, 2009, COMP VIS 2009 IEEE 1
   Zhong BN, 2013, NEUROCOMPUTING, V103, P132, DOI 10.1016/j.neucom.2012.10.001
NR 32
TC 12
Z9 13
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2016
VL 38
BP 573
EP 581
DI 10.1016/j.jvcir.2016.04.008
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA DN5ZB
UT WOS:000377149100049
DA 2024-07-18
ER

PT J
AU Hou, YC
   Quan, ZY
   Tsai, CF
AF Hou, Young-Chang
   Quan, Zen-Yu
   Tsai, Chih-Fong
TI A privilege-based visual secret sharing model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Visual secret sharing; Visual cryptography; Privileged share;
   Progressive reconstruction; Image sharing; Image encryption; Unexpanded
   share; Information hiding
ID CRYPTOGRAPHY; SCHEME
AB In traditional visual secret sharing (VSS) schemes, every transparency has the same capability for recovery of the secret image. This means that managers are unable to assign an appropriate privilege to participants according to their importance. One way to solve this problem would be to assign each share a suitable recovery capability. In this study, we propose a novel secret sharing method, the privilege-based visual secret sharing model (PVSSM), which allows participants with different privileges. It is assumed that participants having a higher privilege will have a higher ability to recover the secret image. The proposed PVSSM has the following advantages: (1) Each share has an appropriate capability to reveal the secret information corresponding to the privilege of the share holder. (2) The restored image has a better contrast than the traditional VSS method can achieve. (3) The share has the same size as the secret image. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Hou, Young-Chang] Tamkang Univ, Dept Informat Management, New Taipei 25137, Taiwan.
   [Quan, Zen-Yu; Tsai, Chih-Fong] Natl Cent Univ, Dept Informat Management, Taipei, Taiwan.
C3 Tamkang University; National Central University
RP Hou, YC (corresponding author), Tamkang Univ, Dept Informat Management, New Taipei 25137, Taiwan.
EM ychou@mail.im.tku.edu.tw
FU National Science Council of Republic of China [NSC-99-2221-E-032-051]
FX This research was partly supported by National Science Council of
   Republic of China under contract NSC-99-2221-E-032-051. We express our
   gratitude for the valuable comments provided by Lisa Liu and Shih-Chieh
   Wei on earlier drafts of this paper.
CR Blakley G. R., 1979, P NAT COMP C AM FED, P313, DOI [10.1109/MARK.1979.8817296, DOI 10.1109/AFIPS.1979.98, DOI 10.1109/MARK.1979.8817296]
   Chen SK, 2005, PATTERN RECOGN, V38, P2466, DOI 10.1016/j.patcog.2005.04.002
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chin-Chen Chang, 2011, Journal of Electronic Science and Technology, V9, P325, DOI 10.3969/j.issn.1674-862X.2011.04.008
   Fang Wen-Pinn, 2006, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V16, P632
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Yan XH, 2015, J VIS COMMUN IMAGE R, V26, P94, DOI 10.1016/j.jvcir.2014.11.003
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 17
TC 17
Z9 17
U1 0
U2 9
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 358
EP 367
DI 10.1016/j.jvcir.2015.10.005
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700032
DA 2024-07-18
ER

PT J
AU Ji, YL
   Cheng, H
   Zheng, YL
   Li, HX
AF Ji, Yanli
   Cheng, Hong
   Zheng, Yali
   Li, Haoxin
TI Learning contrastive feature distribution model for interaction
   recognition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Interaction recognition; CFDM; Contrast mining; CR-UESTC database; SBU
   database; Human skeleton; Action recognition; HRI
ID REPRESENTATION
AB In this paper, we learn a Contrastive Feature Distribution Model (CFDM) for interaction recognition. Our contributions are three-folded. First of all, we introduce an intra-inter-frame skeleton feature for interaction description. Secondly, we learn CFDM for a discriminative representation of interactions. In this step, we mine contrastive features to create a dictionary, and learn the probability distribution of dictionary words to construct CFDM in positive and negative training samples. With CFDM, we represent interactions in a discriminative way for recognition. Since there is few skeleton based interaction databases now, we capture a new database, CR-UESTC, which is the third contribution. We evaluate the proposed CFDM approach on CR-UESTC and SBU interaction databases, and compare the result of CFDM with the CM and the BoW approach. The comparison indicates that the recognition accuracy of three approaches is: CFDM > CM > BoW. Compared with Yun et al. (2012), the proposed CFDM also obtain a better result on SBU database. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ji, Yanli; Cheng, Hong; Zheng, Yali; Li, Haoxin] UESTC, Ctr Robot, Sch Automat Engn, Chengdu, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Ji, YL (corresponding author), UESTC, Ctr Robot, Sch Automat Engn, Chengdu, Peoples R China.
FU Natural Science Foundation of China (NSFC) [61305043]
FX This research is supported by the Natural Science Foundation of China
   (NSFC) under Grant No. 61305043.
CR Alazrai R., 2015, PATTERN RECOGN, V48, P2761
   [Anonymous], P BMVC
   [Anonymous], P CVPR
   [Anonymous], P CVPR
   [Anonymous], 2005, P CVPR
   [Anonymous], P ICCV
   Buys K, 2014, J VIS COMMUN IMAGE R, V25, P39, DOI 10.1016/j.jvcir.2013.03.011
   DONG G, 1999, P ACM SIGKDD
   Du YT, 2007, IEEE SIGNAL PROC LET, V14, P952, DOI 10.1109/LSP.2007.908035
   Ji Y., 2014, P ICME WORKSH
   Ji YL, 2013, IEEJ T ELECTR ELECTR, V8, P269, DOI 10.1002/tee.21850
   Kong Y., 2012, P ECCV
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Masood S., 2011, P ICCV WORKSH
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Park S., 2005, P SPIE
   Raptis M., 2013, P CVPR
   Ryoo M., 2009, P ICCV
   Ryoo M.S., 2006, RECOGNITION COMPOSIT, P1709
   Shen H., 2014, P ECCV
   Waltisberg D., 2010, P ICPR
   Wang C., 2013, P BMVC
   Wang C., 2014, P CVPR
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wei P., 2013, P ICCV
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang Y., 2012, P CVPR
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Yun K., 2012, P CVPR WORKSH
NR 30
TC 45
Z9 47
U1 0
U2 12
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 340
EP 349
DI 10.1016/j.jvcir.2015.10.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700030
DA 2024-07-18
ER

PT J
AU Song, YX
   Jia, KB
AF Song, Yu-xin
   Jia, Ke-bin
TI Early merge mode decision for texture coding in 3D-HEVC
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video coding; 3D-HEVC; Multiview plus depth; Dependent view; Texture
   coding; Mode decision; Merge mode; Complexity reduction
ID VIDEO
AB As the upcoming 3D video coding standard, high efficiency video coding (HEVC) based 3D video coding (3D-HEVC) has been drafted. In 3D-HEVC, the computational complexity of mode decision process is significantly high due to exhaustive modes' checks for coding units (CU) derived from recursive quad-tree partitioning. In this paper, we propose an early merge mode decision method for complexity reduction of dependent texture views. First, inter-view correlation and hierarchical depth correlation of coding modes are separately analyzed for B frame and P frame. Then, conditions to early determine merge mode coded CUs are derived based on the correlations. All of the early determined CUs only check merge modes in the mode decision process, which brings considerable complexity reduction. Experimental results demonstrate that the proposed method can achieve average 20.4% of encoding time saving for dependent texture views with negligible rate distortion performance loss. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Song, Yu-xin; Jia, Ke-bin] Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Jia, KB (corresponding author), Beijing Univ Technol, Coll Elect Informat & Control Engn, Beijing 100124, Peoples R China.
EM syx99839@sina.com; kebinj@bjut.edu.cn
FU Project for the National Key Technology RD Program [2011BAC12B03];
   Innovation Team of Beijing; National Natural Science Foundation of China
   [61100131]; Key Project of Beijing Municipal Education Commission
   [KZ201310005004]; Rixin Fund of Beijing University of Technology
   [2012-RX-03]
FX This work was supported in part by the Project for the National Key
   Technology R&D Program under Grant No. 2011BAC12B03, the Innovation Team
   of Beijing, the National Natural Science Foundation of China under Grant
   No. 61100131, the Key Project of Beijing Municipal Education Commission
   under Grant No. KZ201310005004 and the Rixin Fund of Beijing University
   of Technology under Grant No. 2012-RX-03.
CR [Anonymous], P IEEE INT C DIG SIG
   Carranza J, 2003, ACM T GRAPHIC, V22, P569, DOI 10.1145/882262.882309
   Chen Y., 2014, JCT3VI1003
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Ding LF, 2008, IEEE T MULTIMEDIA, V10, P1553, DOI 10.1109/TMM.2008.2007314
   Fehn C, 2002, SIGNAL PROCESS-IMAGE, V17, P705, DOI 10.1016/S0923-5965(02)00079-6
   Lee PJ, 2014, IET SIGNAL PROCESS, V8, P565, DOI 10.1049/iet-spr.2012.0286
   Mueller K., 2014, JCT3VG1100
   Shen LQ, 2011, IEEE T CIRC SYST VID, V21, P837, DOI 10.1109/TCSVT.2011.2130310
   Smolic A, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2161, DOI 10.1109/ICME.2006.262683
   Sullivan GJ, 2013, IEEE J-STSP, V7, P1001, DOI 10.1109/JSTSP.2013.2283657
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tohidypour Hamid Reza, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P895, DOI 10.1109/ICASSP.2014.6853726
   Yeh CH, 2014, IEEE T IND INFORM, V10, P594, DOI 10.1109/TII.2013.2273308
   Zatt B., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P42, DOI 10.1109/PCS.2010.5702527
   Zeng HQ, 2011, IEEE T CIRC SYST VID, V21, P1659, DOI 10.1109/TCSVT.2011.2133350
   Zeng HQ, 2010, IEEE IMAGE PROC, P3405, DOI 10.1109/ICIP.2010.5653326
   Zhang N, 2014, SIGNAL PROCESS-IMAGE, V29, P951, DOI 10.1016/j.image.2014.06.003
   Zhang QW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053017
   Zhao TS, 2013, IEEE T IMAGE PROCESS, V22, P1596, DOI 10.1109/TIP.2012.2235451
   Zhu W, 2010, IEEE T CONSUM ELECTR, V56, P1696, DOI 10.1109/TCE.2010.5606315
NR 21
TC 17
Z9 18
U1 0
U2 11
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD NOV
PY 2015
VL 33
BP 60
EP 68
DI 10.1016/j.jvcir.2015.07.001
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CW4SP
UT WOS:000364982700006
DA 2024-07-18
ER

PT J
AU Ma, XL
   Xie, XD
   Lam, KM
   Hu, JM
   Zhong, YS
AF Ma, Xiaolong
   Xie, Xudong
   Lam, Kin-Man
   Hu, Jianming
   Zhong, Yisheng
TI Saliency detection based on singular value decomposition
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gaussian filter; Saliency detection; Singular value decomposition;
   Human-perception mechanism; Learning-based; Human-eye fixations;
   Salient-object detection; Visual attention
ID VISUAL-ATTENTION
AB Saliency detection has gained popularity in many applications, and many different approaches have been proposed. In this paper, we propose a new approach based on singular value decomposition (SVD) for saliency detection. Our algorithm considers both the human-perception mechanism and the relationship between the singular values of an image decomposed by SVD and its salient regions. The key concept of our proposed algorithms is based on the fact that salient regions are the important parts of an image. The singular values of an image are divided into three groups: large, intermediate, and small singular values. We propose the hypotheses that the large singular values mainly contain information about the non-salient background and slight information about the salient regions, while the intermediate singular values contain most or even all of the saliency information. The small singular values contain little or even none of the saliency information. These hypotheses are validated by experiments. By regularization based on the average information, regularization using the leading largest singular values or regularization based on machine learning, the salient regions will become more conspicuous. In our proposed approach, learning-based methods are proposed to improve the accuracy of detecting salient regions in images. Gaussian filters are also employed to enhance the saliency information. Experimental results prove that our methods based on SVD achieve superior performance compared to other state-of-the-art methods for human-eye fixations, as well as salient-object detection, in terms of the area under the receiver operating characteristic (ROC) curve (AUC) score, the linear correlation coefficient (CC) score, the normalized scan-path saliency (NSS) score, the F-measure score, and visual quality. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Ma, Xiaolong; Xie, Xudong; Hu, Jianming; Zhong, Yisheng] Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Ma, Xiaolong; Xie, Xudong; Hu, Jianming; Zhong, Yisheng] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.
   [Ma, Xiaolong; Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
C3 Tsinghua University; Tsinghua University; Hong Kong Polytechnic
   University
RP Xie, XD (corresponding author), Tsinghua Univ, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM ma-xl11@mails.tsinghua.edu.cn; xdxie@mail.tsinghua.edu.cn;
   kin.man.lam@polyu.edu.hk; zys-dau@mail.tsinghua.edu.cn
FU National Basic Research Program of China (973 Project) [2012CB725405];
   Hi-Tech Research and Development Program of China (863 Project)
   [2011AA110405]; National Natural Science Foundation China [61273238];
   Henry Fok Foundation [122010]; Hong Kong Polytechnic University, Hong
   Kong [G-UA42]
FX This work was supported in part by National Basic Research Program of
   China (973 Project) 2012CB725405, Hi-Tech Research and Development
   Program of China (863 Project) 2011AA110405, National Natural Science
   Foundation China 61273238, the Henry Fok Foundation 122010, and an
   internal grant from The Hong Kong Polytechnic University, Hong Kong
   (Project No. G-UA42).
CR Achanta R., 2008, ICVS
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2003, ACM MULTIMEDIA
   [Anonymous], IEEE CVPR
   [Anonymous], IEEE CVPR
   [Anonymous], 2006, NIPS
   [Anonymous], 2011, CVPR
   [Anonymous], 2011, BMVC
   [Anonymous], 2014, LECT NOTES ELECT ENG
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2009, ICCV
   [Anonymous], 2013, CVPR
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chetverikov D, 2008, LECT NOTES COMPUT SC, P143
   Cui Y, 2012, IEEE RAD CONF
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Feng SH, 2013, J VIS COMMUN IMAGE R, V24, P1031, DOI 10.1016/j.jvcir.2013.06.018
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Goferman S., 2010, IEEE CVPR
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Huang C, 2014, J VIS COMMUN IMAGE R, V25, P1299, DOI 10.1016/j.jvcir.2014.05.002
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jung C, 2012, IEEE T IMAGE PROCESS, V21, P1272, DOI 10.1109/TIP.2011.2164420
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kootstra G., 2008, BMVC
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Luo W, 2012, SIGNAL PROCESS-IMAGE, V27, P238, DOI 10.1016/j.image.2011.10.004
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Margolin R., 2013, IEEE CVPR
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Peng H., 2013, 27 AAAI C ART INT
   Perazzi F., 2012, COMPUT VISION PATTER
   Riche N, 2013, SIGNAL PROCESS-IMAGE, V28, P642, DOI 10.1016/j.image.2013.03.009
   Rudz S, 2009, LECT NOTES COMPUT SC, V5807, P12
   Scharfenberger C., 2013, IEEE CVPR
   Schauerte B., 2012, EUR C COMP VIS ECCV
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Song R, 2012, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2012.6247836
   Sun X., 2012, IEEE CVPR
   Tian H., 2014, TIP
   Toet A, 2011, IEEE T PATTERN ANAL, V33, P2131, DOI 10.1109/TPAMI.2011.53
   Tsapatsoulis N, 2007, INT J NEURAL SYST, V17, P289, DOI 10.1142/S0129065707001147
   Vig E, 2012, IEEE T PATTERN ANAL, V34, P1080, DOI 10.1109/TPAMI.2011.198
   Waldemar P, 1997, INT CONF ACOUST SPEE, P2713, DOI 10.1109/ICASSP.1997.595349
   Wang J., 2010, IS T SPIE ELECT IMAG
   Xu M, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6116510
   Yan Q., 2013, COMPUT VISION PATTER
   Yang HY, 2014, J VIS COMMUN IMAGE R, V25, P1308, DOI 10.1016/j.jvcir.2014.05.003
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 54
TC 17
Z9 18
U1 1
U2 22
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 95
EP 106
DI 10.1016/j.jvcir.2015.08.003
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300008
DA 2024-07-18
ER

PT J
AU Nie, XS
   Liu, J
   Wang, Q
   Zeng, WJ
AF Nie, Xiushan
   Liu, Ju
   Wang, Qian
   Zeng, Wenjun
TI Graph-based video fingerprinting using double optimal projection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Video copy detection; Content protection; Video fingerprinting;
   Dimensionality reduction; Double optimal projection; Graph model;
   Intra-cluster; Inter-cluster
ID COPY DETECTION; ROBUST
AB A double optimal projection method that involves projections for intra-cluster and inter-cluster dimensionality reduction are proposed for video fingerprinting. The video is initially set as a graph with frames as its vertices in a high-dimensional space. A similarity measure that can compute the weights of the edges is then proposed. Subsequently, the video frames are partitioned into different clusters based on the graph model. Double optimal projection is used to explore the optimal mapping points in a low-dimensional space to reduce the video dimensions. The statistics and geometrical fingerprints are generated to determine whether a query video is copied from one of the videos in the database. During matching, the video can be roughly matched by utilizing the statistics fingerprint. Further matching is thereafter performed in the corresponding group using geometrical fingerprints. Experimental results show the good performance of the proposed video fingerprinting method in robustness and discrimination. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Nie, Xiushan; Wang, Qian] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
   [Liu, Ju] Shandong Univ, Sch Informat Sci & Engn, Jinan 250100, Peoples R China.
   [Zeng, Wenjun] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
C3 Shandong University of Finance & Economics; Shandong University;
   University of Missouri System; University of Missouri Columbia
RP Nie, XS (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan 250014, Peoples R China.
RI Nie, Xiushan/AAZ-6410-2020
FU scientific research foundation for the excellent middle-aged and youth
   scientists of Shandong province [BS2013DX013, BS2013DX040]; national
   natural science foundation of China [61101162]
FX We thank Roberto Olmi for sharing his codes for identifying the maximum
   independent set. This work was supported partially by the scientific
   research foundation for the excellent middle-aged and youth scientists
   of Shandong province (Grant Nos. BS2013DX013 and BS2013DX040) and the
   national natural science foundation of China (Grant No. 61101162).
CR Balaji S., 2010, Adv. Model. Optim., V12, P107
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bruske J, 1998, IEEE T PATTERN ANAL, V20, P572, DOI 10.1109/34.682189
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   Costa JA, 2004, IEEE T SIGNAL PROCES, V52, P2210, DOI 10.1109/TSP.2004.831130
   Diao MG, 2013, INT SYMP IMAGE SIG, P290
   Esmaeili MM, 2011, IEEE T INF FOREN SEC, V6, P213, DOI 10.1109/TIFS.2010.2097593
   He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692
   Lee S, 2006, P ITN C AC SPEECH, V2, P401, DOI DOI 10.1109/ICASSP.2006.1660364
   Liu XC, 2013, IEEE SIGNAL PROC LET, V20, P1253, DOI 10.1109/LSP.2013.2287006
   Maani E, 2008, IEEE IMAGE PROC, P1716, DOI 10.1109/ICIP.2008.4712105
   Nie XS, 2014, IET IMAGE PROCESS, V8, P655, DOI 10.1049/iet-ipr.2013.0689
   Nie XS, 2010, INT CONF SIGN PROCES, P1837, DOI 10.1109/ICOSP.2010.5656914
   Nie XS, 2011, IEEE SIGNAL PROC LET, V18, P307, DOI 10.1109/LSP.2011.2126020
   Oostveen J., 2002, Recent Advances in Visual Information Systems. 5th International Conference VISUAL 2002. Proceedings (Lecture Notes in Computer Science Vol.2314), P117
   Rubini M. R. G., 2012, INT J COMPUTER SCI E, V2, P45
   Tan HK, 2010, IEEE T CIRC SYST VID, V20, P1486, DOI 10.1109/TCSVT.2010.2077531
   vander Maaten L., 2009, J MACH LEARN RES, V10, P13, DOI [10.1080/13506280444000102, DOI 10.1080/13506280444000102]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wiselin D. G., 2012, INT J EMERGING TECHN, V2, P293
   Yu LJ, 2005, P SOC PHOTO-OPT INS, V5681, P68, DOI 10.1117/12.587708
   Zhou XB, 2005, LECT NOTES ARTIF INT, V3802, P80
NR 22
TC 3
Z9 3
U1 0
U2 6
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2015
VL 32
BP 120
EP 129
DI 10.1016/j.jvcir.2015.08.001
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CS9DC
UT WOS:000362388300010
DA 2024-07-18
ER

PT J
AU Liu, HX
   Song, B
   Tian, F
   Qin, H
   Liu, X
AF Liu, Haixiao
   Song, Bin
   Tian, Fang
   Qin, Hao
   Liu, Xiao
TI Optimal-correlation-based reconstruction for distributed compressed
   video sensing
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Compressed sensing; Distributed video coding; Bregman iteration;
   Correlation model; Spatial/temporal redundancy; Joint reconstruction;
   Optimal-correlation-based; Inter-signal correlation
AB Distributed compressed video sensing (DCVS) is a framework that integrates both compressed sensing and distributed video coding characteristics to achieve a low-complexity video coding. However, how to design an efficient joint reconstruction by leveraging more realistic signal models is still an open challenge. In this paper, we present a novel optimal-correlation-based reconstruction method for compressively sampled videos from multiple measurement vectors. In our method, the sparsity is mainly exploited through inter-signal correlations rather than the traditional frequency transform, wherein the optimization is not only over the signal space to satisfy data consistency but also over all possible linear correlation models to achieve minimum-l(1)-norm correlation noise. Additionally, a two-phase Bregman iterative based algorithm is outlined for solving the optimization problem. Simulation results show that our proposal can achieve an improved reconstruction performance in comparison to the conventional approaches, and especially, offer a 0.7-9.9 dB gain in the average PSNR for DCVS. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Liu, Haixiao; Song, Bin; Tian, Fang; Qin, Hao] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
   [Liu, Xiao] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.
C3 Xidian University; Nanjing University of Posts & Telecommunications
RP Song, B (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.
EM hxliu@stu.xdian.edu.cn; bsong@mail.xidian.edu.cn;
   ftian@stu.xidian.edu.cn; hqin@mail.xidian.edu.cn; liux@n-jupt.edu.cn
FU National Natural Science Foundation of China [61271173, 61372068];
   Research Fund for the Doctoral Program of Higher Education of China
   [20130203110005]; Fundamental Research Funds for the Central
   Universities [K5051301033]; 111 Project [B08038]; ISN State Key
   Laboratory
FX This work has been supported by The National Natural Science Foundation
   of China (Nos. 61271173 and 61372068), the Research Fund for the
   Doctoral Program of Higher Education of China (No. 20130203110005), the
   Fundamental Research Funds for the Central Universities (No.
   K5051301033), the 111 Project (No. B08038), and also supported by the
   ISN State Key Laboratory.
CR Anaraki FP, 2013, INT CONF ACOUST SPEE, P5469, DOI 10.1109/ICASSP.2013.6638709
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candès EJ, 2006, COMMUN PUR APPL MATH, V59, P1207, DOI 10.1002/cpa.20124
   Chen Hung-Wei, 2010, SPIE VISUAL COMMUNIC
   Do TT, 2009, IEEE IMAGE PROC, P1393, DOI 10.1109/ICIP.2009.5414631
   Donoho D., SPARSELAB MATLAB SOF
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Hung-Wei Chen, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P210, DOI 10.1109/PCS.2010.5702466
   Liu H., 2011, IEEE INT C SIGN PROC, P670
   Liu HX, 2014, ELECTRON LETT, V50, P83, DOI 10.1049/el.2013.1835
   Liu HX, 2013, J VIS COMMUN IMAGE R, V24, P1232, DOI 10.1016/j.jvcir.2013.08.007
   Liu HX, 2013, IEEE SIGNAL PROC LET, V20, P315, DOI 10.1109/LSP.2013.2245893
   Liu Y, 2013, IEEE T CIRC SYST VID, V23, P438, DOI 10.1109/TCSVT.2012.2207269
   Liu YL, 2012, IEEE T INFORM THEORY, V58, P4201, DOI 10.1109/TIT.2012.2191612
   Liu ZR, 2011, IEEE T CIRC SYST VID, V21, P1704, DOI 10.1109/TCSVT.2011.2133890
   Ma JW, 2012, IEEE T CIRC SYST VID, V22, P1354, DOI 10.1109/TCSVT.2012.2201673
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Prades-Nebot J., 2009, 2009 Picture Coding Symposium, PCS 2009, P1, DOI DOI 10.1109/PCS.2009.5167431
   Pudlewski S, 2013, IEEE COMMUN SURV TUT, V15, P754, DOI 10.1109/SURV.2012.121912.00154
   Pudlewski S, 2012, IEEE T MOBILE COMPUT, V11, P1060, DOI 10.1109/TMC.2011.175
   Thirumalai V, 2013, J VIS COMMUN IMAGE R, V24, P649, DOI 10.1016/j.jvcir.2011.12.004
   Wakin M., 2006, PICT COD S APR
   Xu WB, 2010, IEEE INT SYMP CIRC S, P1145, DOI 10.1109/ISCAS.2010.5537317
   Yin WT, 2013, J SCI COMPUT, V54, P684, DOI 10.1007/s10915-012-9616-5
   Yin WT, 2008, SIAM J IMAGING SCI, V1, P143, DOI 10.1137/070703983
   Zheng J, 2009, OPT ENG, V48, DOI 10.1117/1.3206733
NR 28
TC 4
Z9 5
U1 0
U2 31
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 197
EP 207
DI 10.1016/j.jvcir.2015.06.020
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600018
DA 2024-07-18
ER

PT J
AU Qin, C
   Zhang, XP
AF Qin, Chuan
   Zhang, Xinpeng
TI Effective reversible data hiding in encrypted image with privacy
   protection for image content
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Reversible data hiding; Privacy protection; Image encryption; Data
   embedding; Image decryption; Data extraction; Image recovery; lsophote
   direction
ID DIFFERENCE
AB In this paper, we propose a novel reversible data hiding scheme in encrypted image. The content owner encrypts the original image with the encryption key to achieve privacy protection for image content, and then, each block of the encrypted image is embedded with one secret bit by the data hider using the data-hiding key. Through the elaborate selection for partial pixels to be flipped, data hiding process only conducts slighter modifications to each block, which leads to significant improvement of visual quality for the decrypted image. The receiver can easily decrypt the marked, encrypted image using the encryption key, and then, through the data-hiding key and an adaptive evaluation function of smoothness characteristic along the isophote direction, secret data can be extracted from the decrypted image, and the original image can further be recovered successfully. Experimental results demonstrate the effectiveness of the proposed scheme. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Qin, Chuan] Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Shanghai 200093, Peoples R China.
   [Qin, Chuan] Univ Shanghai Sci & Technol, Engn Res Ctr Opt Instrument & Syst, Minist Educ, Shanghai 200093, Peoples R China.
   [Zhang, Xinpeng] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200072, Peoples R China.
C3 University of Shanghai for Science & Technology; University of Shanghai
   for Science & Technology; Shanghai University
RP Qin, C (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, 516 Jungong Rd, Shanghai 200093, Peoples R China.
EM qin@usst.edu.cn; xzhang@shu.edu.cn
RI Qin, Chuan/C-1106-2017
OI Qin, Chuan/0000-0002-0370-4623
FU National Natural Science Foundation of China [61303203]; Natural Science
   Foundation of Shanghai, China [13ZR1428400]; Innovation Program of
   Shanghai Municipal Education Commission [14YZ087]; Shanghai Engineering
   Center Project of Massive Internet of Things Technology for Smart Home
   [GCZX14014]; Research Base Special Project of Hujiang Foundation
   [C14001]; Hujiang Foundation of China [C14002]
FX This work was supported by the National Natural Science Foundation of
   China (61303203), the Natural Science Foundation of Shanghai, China
   (13ZR1428400), the Innovation Program of Shanghai Municipal Education
   Commission (14YZ087), Shanghai Engineering Center Project of Massive
   Internet of Things Technology for Smart Home (GCZX14014), Research Base
   Special Project of Hujiang Foundation (C14001), and Hujiang Foundation
   of China (C14002).
CR [Anonymous], IEEE TRANS INF FOREN
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   De Vleeschouwer C, 2002, P IEEE, V90, P64, DOI 10.1109/5.982406
   Feng GR, 2012, J SYST SOFTWARE, V85, P392, DOI 10.1016/j.jss.2011.08.033
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Hong WE, 2011, J VIS COMMUN IMAGE R, V22, P131, DOI 10.1016/j.jvcir.2010.11.004
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Lee CF, 2012, DIGIT SIGNAL PROCESS, V22, P941, DOI 10.1016/j.dsp.2012.05.015
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lu TC, 2014, SIGNAL PROCESS, V104, P152, DOI 10.1016/j.sigpro.2014.04.001
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Puech W., 2008, P SOC PHOTO-OPT INS, V6819, P1
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xu DW, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053022
   Xu DW, 2014, IEEE T INF FOREN SEC, V9, P596, DOI 10.1109/TIFS.2014.2302899
   Yang B., 2010, P SOC PHOTO-OPT INS, V7541, P1
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 34
TC 165
Z9 172
U1 1
U2 78
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2015
VL 31
BP 154
EP 164
DI 10.1016/j.jvcir.2015.06.009
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA CO5EE
UT WOS:000359181600014
DA 2024-07-18
ER

PT J
AU Sang, QB
   Qi, HX
   Wu, XJ
   Li, CF
   Bovik, AC
AF Sang, Qingbing
   Qi, Huixin
   Wu, Xiaojun
   Li, Chaofeng
   Bovik, Alan C.
TI No-reference image blur index based on singular value curve
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE No-reference blur index; Image quality assessment; Singular value
   decomposition; Singular value curve; Blind; Image quality; Objective;
   Perception
AB We describe a new no-reference blur index for still images based on a singular value curve (SVC). The algorithm is composed of two steps. First, the singular value decomposition is performed on the image to be blur-assessed. Then an image blur index is constructed from the singular value curve. Experimental results obtained on four simulated blur databases and on the Real Blur Image Database show that the proposed SVC algorithm achieves high correlation against human judgments when assessing the blur distortion of images. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Sang, Qingbing; Qi, Huixin; Wu, Xiaojun; Li, Chaofeng] Jiangnan Univ, Sch Internet Things Engn, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
   [Bovik, Alan C.] Univ Texas Austin, Lab Image & Video Engn, Austin, TX 78712 USA.
C3 Jiangnan University; University of Texas System; University of Texas
   Austin
RP Sang, QB (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
EM sangqb@163.com; bovik@ece.utexas.edu
RI Sang, Qingbing/AAB-4778-2022; Bovik, Alan/B-6717-2012
OI Bovik, Alan/0000-0001-6067-710X
FU National Natural Science Foundation of China [61170120]; Program for New
   Century Excellent Talents in University [NCET-12-0881]; 111 Project
   [B12018]; Natural Science Foundation of Jiangsu Province [BK2011147];
   U.S. National Science Foundation [IIS-1116656]
FX This research is supported in part by the National Natural Science
   Foundation of China (No. 61170120), Program for New Century Excellent
   Talents in University (NCET-12-0881), the 111 Project (B12018), the
   Natural Science Foundation of Jiangsu Province (No. BK2011147). A.C.
   Bovik was supported by the U.S. National Science Foundation under Grant
   IIS-1116656.
CR Ciancio A, 2011, IEEE T IMAGE PROCESS, V20, P64, DOI 10.1109/TIP.2010.2053549
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Hassen R, 2010, INT CONF ACOUST SPEE, P2434, DOI 10.1109/ICASSP.2010.5496297
   Image Coding and Analysis Laboratory Oklahoma State University, CAT SUBJ IM QUAL
   Li C, 2011, ELECTRON LETT, V47, P962, DOI 10.1049/el.2011.0921
   Manish N., 2010, 5 INT WORKSH VID PRO
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ninassi A., 2006, P SPIE HUM VIS EL IM
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
NR 11
TC 42
Z9 48
U1 1
U2 21
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1625
EP 1630
DI 10.1016/j.jvcir.2014.08.002
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100013
DA 2024-07-18
ER

PT J
AU Xu, WZ
   Yu, H
   Lu, DJ
   Song, FL
   Wang, D
   Ye, XC
   Pei, SW
   Fan, DR
   Xie, HT
AF Xu, Weizhi
   Yu, Hui
   Lu, Dianjie
   Song, Fenglong
   Wang, Da
   Ye, Xiaochun
   Pei, Songwei
   Fan, Dongrui
   Xie, Hongtao
TI Fast and scalable lock methods for video coding on many-core
   architecture
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Many-core; Hardware lock; Centralized lock; Distributed lock;
   Micro-benchmarks; Godson-T; Software lock; Single-core processor
ID SHARED-MEMORY MULTIPROCESSORS; HIGHLY PARALLEL FRAMEWORK; DEBLOCKING
   FILTER; HEVC; SYNCHRONIZATION; ALGORITHMS; PROCESSOR; PLATFORM
AB Many-core processors are good candidates for speeding up video coding because the parallelism of these applications can be exploited more efficiently by the many-core architecture. Lock methods are important for many-core architecture to ensure correct execution of the program and communication between threads on chip. The efficiency of lock method is critical to overall performance of chipped many-core processor. In this paper, we propose two types of hardware locks for on-chip many-core architecture, a centralized lock and a distributed lock. First, we design the architectures of centralized lock and distributed lock to implement the two hardware lock methods. Then, we evaluate the performance of the two hardware locks and a software lock by quantitative evaluation micro-benchmarks on a many-core processor simulator Godson-T. The experimental results show that the locks with dedicated hardware support have higher performance than the software lock, and the distributed hardware lock is more scalable than the centralized hardware lock. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Xie, Hongtao] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing, Peoples R China.
   [Xu, Weizhi; Song, Fenglong; Wang, Da; Ye, Xiaochun; Fan, Dongrui] Tsinghua Univ, Inst Microelect, Beijing 100084, Peoples R China.
   [Yu, Hui] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing, Peoples R China.
   [Lu, Dianjie] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Pei, Songwei] Beijing Univ Chem Technol, Dept Comp Sci & Technol, Beijing 100029, Peoples R China.
   [Xu, Weizhi] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Tsinghua University; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS; Shandong Normal University; Beijing University of
   Chemical Technology; Chinese Academy of Sciences; Institute of Computing
   Technology, CAS
RP Xie, HT (corresponding author), Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing, Peoples R China.
EM xiehongtao@iie.ac.cn
RI liu, mengjie/KDN-1890-2024
OI Fan, Dongrui/0000-0001-5219-0908
FU China Major ST Project [2013ZX01033001-001-003]; International S&T
   Cooperation Project of China [2012DFA11170]; Tsinghua Indigenous
   Research Project [20111080997]; National Nature Science Foundation of
   China [61274131, 61303171]
FX This work is supported in part by the China Major S&T Project (No.
   2013ZX01033001-001-003), the International S&T Cooperation Project of
   China Grant (No. 2012DFA11170), the Tsinghua Indigenous Research Project
   (No. 20111080997) and the National Nature Science Foundation of China
   (No. 61274131, No. 61303171).
CR AKGUL BES, 2002, INT J DESIGN AUTOMAT, V7, P139
   ALVERSON R, 1990, INT C SUP JUN, P1
   Anderson T. E., 1990, IEEE Transactions on Parallel and Distributed Systems, V1, P6, DOI 10.1109/71.80120
   [Anonymous], 2006, MIPS RUN, P121
   [Anonymous], 2006, Tech. rep.
   [Anonymous], MIPS R4000 MICROPROC, P286
   Culler D., 1997, PARALLEL COMPUTER AR
   GOODMAN JR, 1989, P 3 INT C ARCH SUPP, P00064
   GRAUNKE G, 1990, COMPUTER, V23, P60, DOI 10.1109/2.55501
   Herlihy Maurice., 1993, SIGARCH Comput. Archit. News, DOI [10.1145/ 173682.165164, DOI 10.1145/173682.165164]
   Kagi Alain, 1997, P 24 ANN INT S COMP, P170
   MELLORCRUMMEY JM, 1991, ACM T COMPUT SYST, V9, P21, DOI 10.1145/103727.103729
   Tullsen DM, 1999, FIFTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE, PROCEEDINGS, P54, DOI 10.1109/HPCA.1999.744326
   Yan C, 2014, ELECTRON LETT, V50, P805, DOI 10.1049/el.2014.0611
   YAN CG, 2013, DAT COMP C SNOWB UT, P530
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yan CG, 2013, IEEE DATA COMPR CONF, P63, DOI 10.1109/DCC.2013.14
   Yan CG, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6011904
   Yu Chenjie, 2009, IEEE T VERY LARGE SC, V17
   Zhang YD, 2012, IEEE T MULTIMEDIA, V14, P510, DOI 10.1109/TMM.2012.2190391
   Zhu Weirong, 2007, P INT S COMP ARCH IS
NR 22
TC 3
Z9 3
U1 0
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD OCT
PY 2014
VL 25
IS 7
BP 1758
EP 1762
DI 10.1016/j.jvcir.2014.06.009
PG 5
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AQ1LO
UT WOS:000342543100024
DA 2024-07-18
ER

PT J
AU Huang, C
   Meng, FM
   Luo, W
   Zhu, SY
AF Huang, Cha
   Meng, Fanman
   Luo, Wang
   Zhu, Shuyuan
TI Bird breed classification and annotation using saliency based graphical
   model
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Graphical model; Saliency; Annotation; Classification; Bird breed; Local
   context; GMS; Segmentation
ID IMAGE; SEGMENTATION; FEATURES
AB Due to the variations among the birds, bird breed classification is still a challenging task. In this paper, we propose a saliency based graphical model (GMS), which can precisely annotate the object on the pixel level. In the proposed method, we first over-segment the image into several regions. Then, GMS extracts the object and classifies the image based on the local context, global context and saliency of each region. In order to achieve a high precision of classification, we use SVM to classify the image based on the features of the annotated bird. Finally, we employ posterior probability distribution obtained by GMS and SVM to perform the image classification. Experiments on the Caltech-UCSD Birds dataset show that the proposed model can achieve better results compared with existing bird breed classification methods based on graphical model. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Huang, Cha; Meng, Fanman; Luo, Wang; Zhu, Shuyuan] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Huang, C (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 611731, Peoples R China.
EM huangchao_uestc@yahoo.cn
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2007, NIPS
   [Anonymous], 2005, IEEE C COMP VIS PATT
   [Anonymous], 2008, P ADV NEURAL INFORM
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Blei D.M., 2007, JMLR
   Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350
   Carbonetto P., 2004, EUR C COMP VIS ECCV, P306
   Chao Huang, 2013, 2013 10th International Conference on Communications, Circuits and Systems (ICCCAS), P319, DOI 10.1109/ICCCAS.2013.6765346
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Li HL, 2008, J VIS COMMUN IMAGE R, V19, P320, DOI 10.1016/j.jvcir.2008.04.001
   Li HL, 2013, SIGNAL PROCESS-IMAGE, V28, P55, DOI 10.1016/j.image.2012.10.004
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Neal RM, 2000, J COMPUT GRAPH STAT, V9, P249, DOI 10.2307/1390653
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Niu ZX, 2011, PROC CVPR IEEE, P1769, DOI 10.1109/CVPR.2011.5995426
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song TC, 2013, PATTERN RECOGN LETT, V34, P1323, DOI 10.1016/j.patrec.2013.04.020
   Song TC, 2013, IEEE SIGNAL PROC LET, V20, P59, DOI 10.1109/LSP.2012.2229273
   Sudderth EB, 2005, IEEE I CONF COMP VIS, P1331
   Wah Catherine, 2011, CALTECH UCSD BRIDS 2
   Xu L, 2013, J VISUAL COMMUN IMAG
NR 31
TC 14
Z9 14
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1299
EP 1307
DI 10.1016/j.jvcir.2014.05.002
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100002
DA 2024-07-18
ER

PT J
AU Murala, S
   Wu, QMJ
AF Murala, Subrahmanyam
   Wu, Q. M. Jonathan
TI Expert content-based image retrieval system using robust local patterns
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Local binary pattern (LBP); Content based image retrieval (CBIR);
   Texture; Gabor transform (GT); Feature extraction; Multi-scale features;
   Local difference operator (LDO); Database
ID INVARIANT TEXTURE CLASSIFICATION; BINARY PATTERNS; ALGORITHM
AB A new image indexing and retrieval algorithm for content based image retrieval is proposed in this paper. The local region of the image is represented by making the use of local difference operator (LDO), separating it into two components i.e. sign and magnitude. The sign LBP operator (S_LBP) is a generalized LBP operator. The magnitude LBP (M_LBP) operator is calculated using the magnitude of LDO. A robust LBP (RLBP) operator is presented employing robust S_LBP and robust M_LBP. Further, the combination of Gabor transform and RLBP operator has also been presented. The robustness is established by conducting four experiments on different image database i.e. Corel 1000 (DB1), Brodatz texture database (DB2) and MIT VisTex database (DB3) under different lighting (illumination) and noise conditions. Investigations reveal a promising achievement of the technique presented when compared to S_LBP and other existing transform domain techniques in terms of their evaluation measures. (C) 2014 Elsevier Inc. All rights reserved.
C1 [Murala, Subrahmanyam; Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 University of Windsor
RP Wu, QMJ (corresponding author), Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
EM muralasu@uwindsor.ca; jwu@uwindsor.ca
RI Wu, Q.M.Jonathan/O-3234-2017; Murala, Subrahmanyam/D-1397-2017
OI Wu, Q.M. Jonathan/0000-0002-5208-7975; Murala,
   Subrahmanyam/0000-0002-1407-6204
FU Canada Research Chair program; Natural Sciences and Engineering Research
   Council of Canada (NSERC) Discovery Grant
FX This work was supported by the Canada Research Chair program, the
   Natural Sciences and Engineering Research Council of Canada (NSERC)
   Discovery Grant.
CR Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Brodatz P., 1996, TEXTURES PHOTOGRAPHI
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   ElAlami ME, 2011, EXPERT SYST APPL, V38, P3539, DOI 10.1016/j.eswa.2010.08.142
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Huang X., 2004, Proc. Inter. Conf. Image and Graphics, P184
   Kokare M, 2005, IEEE T SYST MAN CY B, V35, P1168, DOI 10.1109/TSMCB.2005.850176
   Kokare M, 2002, IETE J RES, V48, P261, DOI 10.1080/03772063.2002.11416285
   Kokare M, 2007, PATTERN RECOGN LETT, V28, P1240, DOI 10.1016/j.patrec.2007.02.006
   Kokare M, 2006, IEEE T SYST MAN CY B, V36, P1273, DOI 10.1109/TSMCB.2006.874692
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Lategahn H, 2010, IEEE T IMAGE PROCESS, V19, P1548, DOI 10.1109/TIP.2010.2042100
   Li M, 2008, PATTERN RECOGN LETT, V29, P664, DOI 10.1016/j.patrec.2007.12.001
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Moghaddam HA, 2006, INT C PATT RECOG, P925
   Moghaddam HA, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P497
   Murala S, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P1411, DOI 10.1109/IADCC.2009.4809223
   Murala Subrahmanyam, 2013, IEEE J BIOMED HLTH I
   Nezambadi-pour H, 2009, EXPERT SYST APPL, V36, P5948, DOI 10.1016/j.eswa.2008.07.008
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Saadatmand-Tarzjan M, 2007, IEEE T SYST MAN CY B, V37, P139, DOI 10.1109/TSMCB.2006.880137
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Su JH, 2010, EXPERT SYST APPL, V37, P5068, DOI 10.1016/j.eswa.2009.12.003
   Su WT, 2010, EXPERT SYST APPL, V37, P4984, DOI 10.1016/j.eswa.2009.12.015
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 34
TC 26
Z9 28
U1 1
U2 23
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD AUG
PY 2014
VL 25
IS 6
BP 1324
EP 1334
DI 10.1016/j.jvcir.2014.05.008
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AM0LW
UT WOS:000339538100004
DA 2024-07-18
ER

PT J
AU Yan, CC
   Liu, YZ
   Xie, HT
   Liao, ZH
   Yin, J
AF Yan, Chenggang Clarence
   Liu, Yizhi
   Xie, Hongtao
   Liao, Zhuhua
   Yin, Jian
TI Extracting salient region for pornographic image detection
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Salient region detection; Pornographic image detection; Visual attention
   analysis; Region-of-interest (ROI); Skin-color model;
   Bag-of-visual-words (BoVW); Codebook algorithm; Speed up robust features
   (SURF)
ID RETRIEVAL; MODEL
AB Content-based pornographic image detection, in which region-of-interest (ROI) plays an important role, is effective to filter pornography. Traditionally, skin-color regions are extracted as ROI. However, skin-color regions are always larger than the subareas containing pornographic parts, and the approach is difficult to differentiate between human skins and other objects with the skin-colors. In this paper, a novel approach of extracting salient region is presented for pornographic image detection. At first, a novel saliency map model is constructed. Then it is integrated with a skin-color model and a face detection model to capture ROI in pornographic images. Next, a ROI-based codebook algorithm is proposed to enhance the representative power of visual-words. Taking into account both the speed and the accuracy, we fuse speed up robust features (SURF) with color moments (CM). Experimental results show that the precision of our ROI extraction method averagely achieves 91.33%, more precisely than that of using the skin-color model alone. Besides, the comparison with the state-of-the-art methods of pornographic image detection shows that our approach is able to remarkably improve the performance. (c) 2014 Elsevier Inc. All rights reserved.
C1 [Yan, Chenggang Clarence] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Liu, Yizhi; Liao, Zhuhua] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan, Peoples R China.
   [Xie, Hongtao] Chinese Acad Sci, Inst Informat Engn, Natl Engn Lab Informat Secur Technol, Beijing, Peoples R China.
   [Xie, Hongtao] Shandong Univ, Dept Comp, Weihai, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Hunan University of Science & Technology; Chinese Academy of Sciences;
   Institute of Information Engineering, CAS; Shandong University
RP Liu, YZ (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan, Peoples R China.
EM liuyizhi928@gmail.com
FU Hunan Provincial Natural Science Foundation of China [12JJ3059];
   National Nature Science Foundation of China [61272063, 61202330,
   61300129, 61370227, 61303171]
FX This research has been supported by Hunan Provincial Natural Science
   Foundation of China (Grant No. 12JJ3059), and partially supported by
   National Nature Science Foundation of China (Grant Nos. 61272063,
   61202330, 61300129, 61370227 and 61303171).
CR [Anonymous], MULT SIGN PROC 2005
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Deselaers T., 2008, P 19 IEEE INT C PATT, P1
   Donoser M., P IEEE C COMP VIS PA, P1
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   KUAN YH, 2004, P INT C IM SCI SYST
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Liu Y. Z., P 12 INT C COMP INF, P404
   Liu Y.Z., P 3 INT C M IN PRESS
   Liu YZ, 2014, FUTURE GENER COMP SY, V31, P69, DOI 10.1016/j.future.2012.08.012
   Liu YZ, 2010, IFIP ADV INF COMM TE, V340, P316
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Rowley HA, 2006, VISAPP 2006: PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P290
   Shih JL, 2007, PATTERN RECOGN LETT, V28, P2367, DOI 10.1016/j.patrec.2007.08.002
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tang S., P 7 ACM INT C MULT M, P1003
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Yu-shi, 2008, Transactions of Beijing Institute of Technology, V28, P410
   [杨金峰 Yang Jinfeng], 2004, [通信学报, Journal of China Institute of Communications], V25, P93
   Zeng W., P 6 AS C COMP VIS AC, P1080
   Zheng QF, 2006, INT J IMAGE GRAPH, V6, P115, DOI 10.1142/S0219467806002082
   Zhou Q, 2005, MULTIMED TOOLS APPL, V27, P251, DOI 10.1007/s11042-005-2577-z
NR 26
TC 13
Z9 13
U1 0
U2 19
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD JUL
PY 2014
VL 25
IS 5
BP 1130
EP 1135
DI 10.1016/j.jvcir.2014.03.005
PG 6
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AI5FQ
UT WOS:000336891200039
DA 2024-07-18
ER

PT J
AU Dong, L
   Lin, WS
   Fang, YM
   Wu, SQ
   Seah, HS
AF Dong, Lu
   Lin, Weisi
   Fang, Yuming
   Wu, Shiqian
   Seah, Hock Soon
TI Saliency detection in computer rendered images based on object-level
   contrast
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Graphic saliency detection; Human visual system; Visual attention;
   Computer rendered images; Selective image rendering; Dominant color
   descriptor; Object-level contrast; Global contrast
ID VISUAL-ATTENTION; COLOR; MODEL; SENSITIVITY; TRACKING
AB In this work, we propose a novel graphic saliency detection method to detect visually salient objects in images rendered from 3D geometry models. Different from existing graphic saliency detection methods, which estimate saliency based on pixel-level contrast, the proposed method detects salient objects by computing object-level contrast. Given a rendered image, the proposed method first extracts dominant colors from each object, and represents each object with a dominant color descriptor (DCD). Saliency of each object is then calculated by measuring the contrast between the DCD of the object and the DCDs of its surrounding objects. We also design a new iterative suppression operator to enhance the saliency result. Compared with existing graphic saliency detection methods, the proposed method can obtain much better performance in salient object detection. We further apply the proposed method to selective image rendering and achieve better performance over the relevant existing algorithm. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Dong, Lu; Lin, Weisi; Seah, Hock Soon] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Fang, Yuming] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang, Peoples R China.
   [Wu, Shiqian] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
C3 Nanyang Technological University; Jiangxi University of Finance &
   Economics; Agency for Science Technology & Research (A*STAR); A*STAR -
   Institute for Infocomm Research (I2R)
RP Dong, L (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM s090059@e.ntu.edu.sg; wslin@ntu.edu.sg; fa0001ng@e.ntu.edu.sg;
   shiqian@i2r.a-star.edu.sg; ashsseah@n-tu.edu.sg
RI Wu, Shiqian/W-4067-2019; Seah, Hock Soon/AAK-9900-2020; Lin,
   Weisi/A-8011-2012; Lin, Weisi/A-3696-2011
OI Wu, Shiqian/0000-0002-6383-7663; Seah, Hock Soon/0000-0003-2699-7147;
   Lin, Weisi/0000-0001-9866-1947
FU Institute for Media Innovation, Nanyang Technological University,
   Singapore
FX We would like to thank the creators of the models used in this paper:
   Fairy forest scene (Ingo Wald) via the Utah 3D Animation Repository;
   Crytek Sponza (Marko Dabrovic and Frank Meinl) via the AIM@SHAPE
   repository; lotus (M. Nagaramesh), tribal site (Viviano), living room
   (manjeet chakrvarty), gazebo (Gaggi Francesco), kitchen
   (Ashvathnarayana), downloaded from artist-3d.com. This work was funded
   by the Ph.D. Grant from the Institute for Media Innovation, Nanyang
   Technological University, Singapore.
CR Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450
   DUNCAN J, 1984, J EXP PSYCHOL GEN, V113, P501, DOI 10.1037/0096-3445.113.4.501
   Engel S, 1997, NATURE, V388, P68, DOI 10.1038/40398
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Hillaire S, 2012, IEEE T VIS COMPUT GR, V18, P356, DOI 10.1109/TVCG.2011.154
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Lee CH, 2005, ACM T GRAPHIC, V24, P659, DOI 10.1145/1073204.1073244
   Lee S, 2009, IEEE T VIS COMPUT GR, V15, P6, DOI 10.1109/TVCG.2008.82
   Longhurst P., 2006, P 4 INT C COMPUTER G, P21
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   O'Craven KM, 1999, NATURE, V401, P584, DOI 10.1038/44134
   Oliva A., 2003, ICIP
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouerhani N, 2003, LECT NOTES COMPUT SC, V2686, P702
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   Scholl BJ, 2001, COGNITION, V80, P1, DOI 10.1016/S0010-0277(00)00152-9
   Xu M.C.Y., 2007, TRENDS COGN SCI, V13, P167
   Yee H, 2001, ACM T GRAPHIC, V20, P39, DOI 10.1145/383745.383748
NR 21
TC 3
Z9 3
U1 1
U2 15
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD APR
PY 2014
VL 25
IS 3
SI SI
BP 525
EP 533
DI 10.1016/j.jvcir.2013.11.009
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AD0IG
UT WOS:000332917100002
DA 2024-07-18
ER

PT J
AU Zhu, HJ
   Gao, C
   Guo, YC
   Shao, YH
AF Zhu, Hongjun
   Gao, Chao
   Guo, Yongcai
   Shao, Yanhua
TI A rectilinear Gaussian model for estimating straight-line parameters
SO JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION
LA English
DT Article
DE Gaussian model; Parameter estimation; Straight lines; Least square
   algorithm; Ridge edge; Straight-line parameters; Feature description;
   Defocused lines
ID HIGH BREAKDOWN-POINT; TOTAL LEAST-SQUARES; SPREAD-FUNCTION; NOISY IMAGE;
   REGRESSION; ROBUST; ALGORITHM; DEPTH; CALIBRATION; FORMULATION
AB For characterizing straight lines in defocused images, a rectilinear Gaussian model (RGM) is proposed. Based on this model, a novel method for estimating the parameters of straight lines is presented. This method, called gray-scale least square (GLS) method, directly deals with gray-scale image data without requiring any preprocessing and hence no additional noise is introduced. Furthermore, the method is able to simultaneously estimate four parameters of straight lines by performing the algorithm only once, while two parameters can be typically estimated by traditional method. Besides this, all parameters are given in closed-form solution. In order to illustrate the effectiveness of RGM and the GLS method, the experiments are performed on a set of artificial images and natural images. The experimental results show that the GLS method outperforms the traditional method from the point of view of sensitivity to noise and accuracy of parameter estimation. (C) 2013 Elsevier Inc. All rights reserved.
C1 [Zhu, Hongjun; Gao, Chao; Guo, Yongcai; Shao, Yanhua] Chongqing Univ, Minist China, Key Lab Optoelect Technol & Syst Educ, Chongqing 400030, Peoples R China.
C3 Chongqing University
RP Gao, C (corresponding author), Chongqing Univ, Minist China, Key Lab Optoelect Technol & Syst Educ, Chongqing 400030, Peoples R China.
EM redreda@qq.com; gaoc@cqu.edu.cn; ycguo@cqu.edu.cn; shao_yanhua@163.com
RI Zhu, Hongjun/AAG-2799-2021
OI Zhu, Hongjun/0000-0003-2339-8739
CR ABATZOGLOU TJ, 1991, IEEE T SIGNAL PROCES, V39, P1070, DOI 10.1109/78.80955
   Agostinelli C, 1998, STAT PROBABIL LETT, V37, P341, DOI 10.1016/S0167-7152(97)00136-3
   AHUJA N, 1993, IEEE T PATTERN ANAL, V15, P1007, DOI 10.1109/34.254059
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   [Anonymous], P ASA STAT COMP SECT
   Asada N, 1998, INT J COMPUT VISION, V26, P153, DOI 10.1023/A:1007996810301
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Bazan WS, 2008, B CIENC GEOD, V14, P128
   BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cizek P, 2008, APPL MATH-CZECH, V53, P267, DOI 10.1007/s10492-008-0009-x
   Coeurjolly D, 2011, INT J IMAG SYST TECH, V21, P67, DOI 10.1002/ima.20268
   Dahyot R, 2009, IEEE T PATTERN ANAL, V31, P1502, DOI 10.1109/TPAMI.2008.288
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   Drineas P, 2011, NUMER MATH, V117, P219, DOI 10.1007/s00211-010-0331-6
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   EDELSBRUNNER H, 1990, ACM T GRAPHIC, V9, P66, DOI 10.1145/77635.77639
   Gao C, 2012, SIGNAL PROCESS, V92, P2552, DOI 10.1016/j.sigpro.2012.03.002
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Gervini D, 2002, ANN STAT, V30, P583, DOI 10.1214/aos/1021379866
   Hampel F. R., 1975, B INT STAT I, V46, P375, DOI DOI 10.1016/0370-2693(74)90750-3
   He J, 2003, IEEE T CONSUM ELECTR, V49, P257, DOI 10.1109/TCE.2003.1209511
   HORAUD R, 1987, IEEE T PATTERN ANAL, V9, P401, DOI 10.1109/TPAMI.1987.4767922
   HOSSJER O, 1992, STAT PROBABIL LETT, V14, P413, DOI 10.1016/0167-7152(92)90103-C
   Hough P. V. C., 1962, Method and Means for Recognizing Complex Patterns
   HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503
   Jefferys T. H., 1980, ASTRON J, V85, P193
   KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P929, DOI 10.1109/34.35496
   KAMGARPARSI B, 1989, IEEE T PATTERN ANAL, V11, P998, DOI 10.1109/34.35504
   KRASKER WS, 1982, J AM STAT ASSOC, V77, P595, DOI 10.2307/2287719
   Lagunovsky D, 1999, PATTERN RECOGN LETT, V20, P1005, DOI 10.1016/S0167-8655(99)00067-7
   Lemmerling P, 1996, IEEE T SIGNAL PROCES, V44, P2908, DOI 10.1109/78.542454
   Li HL, 2007, IEEE T CIRC SYST VID, V17, P1742, DOI 10.1109/TCSVT.2007.903326
   Li HL, 2011, IEEE T CIRC SYST VID, V21, P1571, DOI 10.1109/TCSVT.2011.2129150
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu WY, 1998, COMPUT VIS IMAGE UND, V70, P420, DOI 10.1006/cviu.1998.0683
   LIU Y, 1991, PATTERN RECOGN, V24, P489, DOI 10.1016/0031-3203(91)90016-X
   LOT RC, 1995, PATTERN RECOGN, V28, P647, DOI 10.1016/0031-3203(94)00127-8
   Manzanares A, 1997, APPL OPTICS, V36, P4362, DOI 10.1364/AO.36.004362
   Meidow J, 2009, ISPRS J PHOTOGRAMM, V64, P125, DOI 10.1016/j.isprsjprs.2008.09.013
   Mount DM, 2007, COMPUT STAT DATA AN, V51, P2461, DOI 10.1016/j.csda.2006.08.033
   NACKEN PFM, 1993, IEEE T PATTERN ANAL, V15, P1312, DOI 10.1109/34.250848
   NEVATIA R, 1982, IEEE T PATTERN ANAL, V4, P476, DOI 10.1109/TPAMI.1982.4767291
   OJEDACASTANEDA J, 1983, OPT LETT, V8, P458, DOI 10.1364/OL.8.000458
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Rajagopalan AN, 1998, INT J COMPUT VISION, V30, P175, DOI 10.1023/A:1008019215914
   ROSSMANN K, 1964, J OPT SOC AM, V54, P187, DOI 10.1364/JOSA.54.000187
   Rousseeuw P. J., 1984, LECTURE NOTES STATIS, V26, P256, DOI [DOI 10.1007/978-1-4615-7821-5_15, 10.1007/978-1-4615-7821-5_15]
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   Rousseuw P.J., 1987, ROBUST REGRESSION OU, V1st
   STEPHENS DW, 1982, BEHAV ECOL SOCIOBIOL, V10, P251, DOI 10.1007/BF00302814
   Van Huffel S., 2002, Total Least Squares and Errors-in-Variables Modeling, Analysis, Algorithms and Applications
   VanHuffel S, 1996, IEEE T SIGNAL PROCES, V44, P2464, DOI 10.1109/78.539031
   VANMIEGHEM JA, 1995, J VIS COMMUN IMAGE R, V6, P59, DOI 10.1006/jvci.1995.1005
   von Gioi RG, 2008, J MATH IMAGING VIS, V32, P313, DOI 10.1007/s10851-008-0102-5
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   WEISS I, 1989, IEEE T PATTERN ANAL, V11, P325, DOI 10.1109/34.21801
   Yang K, 2011, COMPUT VIS IMAGE UND, V115, P1207, DOI 10.1016/j.cviu.2011.03.010
   YOHAI VJ, 1987, ANN STAT, V15, P642, DOI 10.1214/aos/1176350366
   YOHAI VJ, 1988, J AM STAT ASSOC, V83, P406
   Zheng LY, 2011, COMPUT VIS IMAGE UND, V115, P152, DOI 10.1016/j.cviu.2010.11.009
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 64
TC 2
Z9 2
U1 0
U2 16
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1047-3203
EI 1095-9076
J9 J VIS COMMUN IMAGE R
JI J. Vis. Commun. Image Represent.
PD FEB
PY 2014
VL 25
IS 2
BP 510
EP 520
DI 10.1016/j.jvcir.2013.09.007
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science
GA AB3GM
UT WOS:000331679300026
DA 2024-07-18
ER

EF